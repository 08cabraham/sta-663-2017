<doc id="11725" url="https://en.wikipedia.org/wiki?curid=11725" title="Flunitrazepam">
Flunitrazepam

Flunitrazepam , also known as Rohypnol among others, is an intermediate acting benzodiazepine used as an hypnotic, sedative, anticonvulsant, anxiolytic, and skeletal muscle relaxant drug. In general, the prescription of flunitrazepam as a hypnotic is intended to be for short-term treatment of chronic or severe insomniacs not responsive to other hypnotics, especially in inpatients. It is considered to be one of the most effective benzodiazepine hypnotics on a dose basis. Just as with other hypnotics, flunitrazepam should be strictly used only on a short-term basis or in those with chronic insomnia on an occasional basis. It is also known and produced from common precursors to 1,4-benzophenones, in 1963. Flunitrazepam has been referred to as a date rape drug even though its incidence is very rare in cases that have been reported.
Flunitrazepam is classed as a nitro-benzodiazepine. It is the fluorinated "N"-methyl derivative of nitrazepam. Other nitro-benzodiazepines include nitrazepam (the parent compound), nimetazepam (methylamino derivative) and clonazepam (2ʹ-chlorinated derivative).
History.
Flunitrazepam was developed by a team led by Leo Sternbach at Hoffmann La-Roche and produced from common precursors to 1,4-benzophenones, in 1963. Flunitrazepam has been referred to as a date rape drug because of its high potency and ability to cause strong amnesia. However, Robertson's study (in the 1990s) indicated that Flunitrazepam was used in only around 1% of reported date rapes and 0.33% according to urine lab tests done (before 2001) by El Sohly.
Adverse effects.
Adverse effects of flunitrazepam include dependence, both physical and psychological; reduced sleep quality resulting in somnolence; and overdose, resulting in excessive sedation, impairment of balance and speech, respiratory depression or coma, and possibly death. Because of the latter, flunitrazepam is commonly used in suicide. When used in pregnancy, it might cause hypotonia.
Dependence.
Flunitrazepam as with other benzodiazepines can lead to drug dependence and benzodiazepine withdrawal syndrome.
Discontinuation may result in the appearance of withdrawal symptoms when the drug is discontinued. Abrupt withdrawal may lead to a severe benzodiazepine withdrawal syndrome characterised by seizures, psychosis, severe insomnia, and severe anxiety. Rebound insomnia, worse than baseline insomnia, typically occur after discontinuation of flunitrazepam even after short-term single nightly dose therapy.
Sleep depth.
Flunitrazepam produces a decrease in delta wave activity. The effect of benzodiazepine drugs on delta waves, however, may not be mediated via benzodiazepine receptors. Delta activity is an indicator of depth of sleep within non-REM sleep; increased levels of delta sleep reflects better quality of sleep. Thus, flunitrazepam and other benzodiazepines cause a deterioration in sleep quality. Cyproheptadine may be superior to benzodiazepines in the treatment of insomnia as it enhances sleep quality based on EEG studies. This may lead to somnolence.
Paradoxical effects.
Flunitrazepam may cause a paradoxical reaction in some individuals causing symptoms including anxiety, aggressiveness, agitation, confusion, disinhibition, loss of impulse control, talkativeness, violent behavior, and even convulsions. Paradoxical adverse effects may even lead to criminal behaviour.
Hypotonia.
Benzodiazepines such as flunitrazepam are lipophilic and rapidly penetrate membranes and, therefore, rapidly cross over into the placenta with significant uptake of the drug. Use of benzodiazepines including flunitrazepam in late pregnancy, especially high doses, may result in hypotonia, also known as floppy baby syndrome.
Other.
After discontinuation of flunitrazepam, a rebound effect may occur about 4 days after stopping flunitrazepam. (See benzodiazepine withdrawal syndrome)
Flunitrazepam impairs cognitive functions. This may appear as lack of concentration, confusion and anterograde amnesia. It can be described as a hangover-like effect, with impairment of mental arithmetic abilities.
Impaired psychomotor functions is another adverse effect, affecting reaction time and driving skill. This may also be expressed as impaired coordination, impaired balance and dizziness.
Other adverse effects include:
Benzodiazepines require special precaution if used in the elderly, during pregnancy, in children, in alcohol- or drug-dependent individuals, and in individuals with comorbid psychiatric disorders. Impairment of driving skills with a resultant increased risk of road traffic accidents is probably the most important adverse effect. This side-effect is not unique to flunitrazepam but also occurs with other hypnotic drugs. Flunitrazepam seems to have a particularly high risk of road traffic accidents compared to other hypnotic drugs. Extreme caution should be exercised by drivers after taking flunitrazepam.
Flunitrazepam, similar to other benzodiazepines and nonbenzodiazepine hypnotic drugs, causes impairments in body balance and standing steadiness in individuals waking up at night or the next morning. Falls and hip fractures are frequently reported. The combination with alcohol increases these impairments. Partial, but incomplete tolerance develops to these impairments.
Interactions.
The use of flunitrazepam in combination with alcoholic beverages synergizes the adverse effects, and can lead to toxicity and death.
Overdose.
Flunitrazepam is a drug that is frequently involved in drug intoxication, including overdose. Overdose of flunitrazepam may result in excessive sedation, or impairment of balance or speech. This may progress in severe overdoses to respiratory depression or coma and possibly death. The risk of overdose is increased if flunitrazepam is taken in combination with CNS depressants such as ethanol (alcohol) and opioids. Flunitrazepam overdose responds to the benzodiazepine receptor antagonist flumazenil, which thus can be used as a treatment.
Presence in bodily fluids.
Flunitrazepam can be measured in blood or plasma to confirm a diagnosis of poisoning in hospitalized patients, provide evidence in an impaired driving arrest, or assist in a medicolegal death investigation. Blood or plasma flunitrazepam concentrations are usually in a range of 5–20 μg/L in persons receiving the drug therapeutically as a nighttime hypnotic, 10–50 μg/L in those arrested for impaired driving and 100–1000 μg/L in victims of acute fatal overdosage. Urine is often the preferred specimen for routine drug abuse monitoring purposes. The presence of 7-aminoflunitrazepam, a pharmacologically-active metabolite and "in vitro" degradation product, is useful for confirmation of flunitrazepam ingestion. In postmortem specimens, the parent drug may have been entirely degraded over time to 7-aminoflunitrazepam. Other metabolites include desmethylflunitrazepam and 3-hydroxydesmethylflunitrazepam.
Other uses.
Recreational use.
A 1989 journal on Clinical Pharmacology reports that benzodiazepines accounted for 52% of prescription forgeries, suggesting that benzodiazepines was a major prescription drug class of abuse. Nitrazepam accounted for 13% of forged prescriptions.
Flunitrazepam and other sedative hypnotic drugs are detected frequently in cases of people suspected of driving under the influence of drugs. Other benzodiazepines and nonbenzodiazepines (anxiolytic or hypnotic) such as zolpidem and zopiclone (as well as cyclopyrrolones, imidazopyridines, and pyrazolopyrimidines) are also found in high numbers of suspected drugged drivers. Many drivers have blood levels far exceeding the therapeutic dose range suggesting a high degree of abuse potential for benzodiazepines and similar drugs.
Suicide.
In studies in Sweden, flunitrazepam was the second-most-common drug used in suicides, being found in about 16% of cases. In a retrospective Swedish study of 1587 deaths, in 159 cases benzodiazepines were found. In suicides when benzodiazepines were implicated, the benzodiazepines flunitrazepam and nitrazepam were occurring in significantly higher concentrations, compared to natural deaths. In four of the 159 cases, where benzodiazepines were found, benzodiazepines alone were the only cause of death. It was concluded that flunitrazepam and nitrazepam might be more toxic than other benzodiazepines.
Drug-facilitated sexual assault.
Flunitrazepam is known to induce anterograde amnesia in sufficient doses; individuals are unable to remember certain events that they experienced while under the influence of the drug. This effect could be particularly dangerous if flunitrazepam is used to aid in the commission of sexual assault; victims may be unable to clearly recall the assault, the assailant, or the events surrounding the assault.
It is difficult to estimate just how many flunitrazepam-facilitated rapes have occurred. Very often, biological samples are taken from the alleged victim at a time when the effects of the drug would already have passed and only residual amounts would remain in the body fluids. These residual amounts would be difficult, and sometimes impossible, to detect using standard screening assays used in most countries. If flunitrazepam exposure is to be detected at all, urine samples need to be collected within 72 hours and subjected to sensitive analytical tests. The problem is compounded by the onset of amnesia after ingestion of the drug, which causes the victim to be uncertain about the facts surrounding the alleged rape. This uncertainty may lead to critical delays or even reluctance to report the rape and provide appropriate biological samples for testing. If a person suspects that he or she is the victim of a flunitrazepam-facilitated rape, he or she should get laboratory testing for flunitrazepam as soon as possible. In recent news, it has been discovered that scientists can now detect flunitrazepam and related compounds in urine at least up to 5 days after administration of a single dose of Rohypnol and up to a month in hair.
An inability to remember events, including sexual encounters, is not conclusive evidence of having consumed a drugged drink: Psychotropic central nervous system (CNS) depressant drugs such as alcohol can cause blackouts, sleepiness, and a reduction in inhibitions. Only a timely screening for flunitrazepam can demonstrate its use. It has been shown that alcohol alone is the psychotropic substance used in the vast majority of cases of alleged drug-facilitated date-rape. A recent study conducted by doctors in the UK found that none of the subjects reporting spiked drinks had any traces of flunitrazepam or other medications popularly believed to be associated with drug-assisted rape, such as GHB. However, flunitrazepam was prohibited for prescription under the NHS in 1992 (The National Health Service (General Medical Services). Rohypnol (1 mg) is available under private prescription. The study results, however, suggest that binge drinking is more commonly a factor in alleged drug-assisted rapes than pharmaceutical drugs.
Drug-facilitated robbery.
In the United Kingdom, the use of flunitrazepam and other "date rape" drugs have been connected to stealing from sedated victims. An activist quoted by a British newspaper estimated that up to 2,000 individuals are robbed each year after being spiked with powerful sedatives, making drug-assisted robbery a more commonly reported problem than drug-assisted rape.
Flunitrazepam is also known to induce anterograde amnesia making police interrogations more difficult.
Pharmacology.
Benzodiazepines, including flunitrazepam, bind to most glial cell membranes with high affinity in mouse astrocytes. Flunitrazepam induces melanogenesis in B16/C3 mouse melanoma cell cultures via modulating high-affinity binding sites. Benzodiazepines, including flunitrazepam have been shown to act on benzodiazepine binding sites as Ca2+ channel blockers and significantly inhibit depolarization-sensitive calcium uptake in rat brain cell components. This has been conjectured as a mechanism for high-dose effects against seizures in a study.
Mechanism of action.
The main pharmacological effects of flunitrazepam are the enhancement of GABA at the GABA receptor. Like other benzodiazepines, flunitrazepam's pharmacological effects include sedation, muscle relaxation, reduction in anxiety, and prevention of convulsions.
Intermediate-half-life benzodiazepines (such as loprazolam, lormetazepam, and temazepam) are also useful for patients with difficulty in maintaining sleep; these may be preferable to long-half-life benzodiazepines, which typically cause next-day sedation and impairments.
Pharmacokinetics.
While 80% of flunitrazepam that is taken orally is absorbed, bioavailability in suppository form is closer to 50%.
Flunitrazepam has a long half-life of 18–26 hours, which means that flunitrazepam's effects after nighttime administration persist throughout the next day. Residual "hangover" effects after nighttime administration of flunitrazepam, such as sleepiness and impaired psychomotor and cognitive functions, may persist into the next day. This may impair the ability of users to drive safely, and increase risks of falls. This is of particular concern in the elderly where falls are often associated with hip fractures and other injuries.
Flunitrazepam is lipophilic and is metabolised hepatically via oxidative pathways. The enzyme CYP3A4 is the main enzyme in its phase 1 metabolism in human liver microsomes.
History.
Flunitrazepam was first synthesized in 1972 by Roche in Europe and was used in hospitals when deep sedation was needed. It first entered the commercial market in Europe in 1975 as Rohypnol produced by Roche, and in the 1980s it began to be available in other countries. It first appeared in the US in late 1983 – mid 1984. It originally came in doses of 1 mg and 2 mg, but due to its potency and potential for abuse, most European countries changed their drug laws and limited the dose to 1 mg—in many countries, the maximum dose per package was limited to 20 or 30 mg. In Germany there had been two changes in availability during a short period in the late 1990s; the first one restricting the dose to 20 mg per package, and for a short time only 10 tablets with 2 mg were available. Soon another change in the German Narcotic Act limited the dose for each tablet to 1 mg, while ampoules containing the 2 mg solution were not changed by Roche and have been handled as a controlled narcotic like morphine. In the countries where flunitrazepam is available for prescription as both 1 mg and 2 mg tablets, such as the Netherlands, generic alternatives are available for the 2 mg tablets. However, in Asia and South America there are original 2 mg tablets from Roche still available.
The newly designed 1 mg tablets introduced in the late 1990s by Roche for the European market are identical in all countries, only the packaging and packaging size differs since there are different laws in each country. The new tablets, which are green (containing a blue coloring) and are pressed harder during manufacturing (so that the tablets can only dissolve quickly in hot liquids, while turning the drink a blue color and leaving a green residue in the beverage) were introduced to prevent use as a rape drug and abuse on the drug scene. However, there have been only few reported cases in Europe where flunitrazepam was used as a rape drug and in most countries flunitrazepam is still offered as a generic drug with white tablets that can be dissolved easily.
In the 2000s Patrick S. Coined the term of pillow candies. some European countries started to treat flunitrazepam as a strong narcotic, for example Poland in 2004. The most recent change was the change in the German drug law regarding flunitrazepam; since November 2011 the drug is only available with a special narcotic prescription. German Rohypnol tablets disappeared almost overnight from the black market. However it took only a few weeks before organized crime became the major supplier for the drug on the black market, as in the United States. Pillow Candies come from western European countries where it is still available with a normal prescription. Some users living on the borders are driving to these countries and buying the drug on the black market, since there are no border controls within the European Union.
Flunitrazepam is marketed by Roche most commonly under the trade name "Rohypnol". It is also marketed in some countries under the trade names "Flunitrazepam", "Hipnosedon", "Hypnodorm", "Flunipam", "Nilium", "Vulbegal", "Silece", "Darkene", "Ilman", "Insom", "Inervon" and "Fluscand". In street slang, the pharmaceutical is commonly referred to as a "roofie" (USA) or a "roh'ie" (Australia).
Regional use.
Flunitrazepam is currently a Schedule III drug under the international Convention on Psychotropic Substances of 1971; in the United States, it is on Schedule IV.
According to FDA Associate Director for Domestic and International Drug Control Nicholas Reuter:
Rohypnol is currently under consideration to be rescheduled to Schedule I, and is already considered such in the States of Florida, Idaho, Minnesota, New Hampshire, New Mexico, North Dakota, Oklahoma, Pennsylvania, and Virginia.
In Australia, flunitrazepam is a schedule 8 drug, along with substituted amphetamines and opioid analgesics. All other benzodiazepines (except alprazolam) are schedule 4 drugs. Unauthorized possession of certain quantities of the drug is punishable by criminal sanctions in New South Wales under Schedule 1 of the "Drug Misuse and Trafficking Act 1985."
On January 1, 2003, flunitrazepam was moved up one level in the schedule of controlled drugs in Norway, and, on August 1, 2004, the manufacturer Roche removed Rohypnol from the market there altogether.
The Dutch, British and French use a system called the System of Objectified Judgement Analysis for assessing whether drugs should be included in drug formularies based on clinical efficacy, adverse effects, pharmacokinetic properties, toxicity and drug interactions. A Dutch analysis using the system found that flunitrazepam is unsuitable to be included in drug prescribing formularies.
Brand names.
Narcozep, Rohypnol, Rohipnol, Roipnol, Flunipam, "rufies" or "roofies".

</doc>
<doc id="11729" url="https://en.wikipedia.org/wiki?curid=11729" title="Fuel cell">
Fuel cell

A fuel cell is a device that converts the chemical energy from a fuel into electricity through a chemical reaction of positively charged hydrogen ions with oxygen or another oxidizing agent. Fuel cells are different from batteries in that they require a continuous source of fuel and oxygen or air to sustain the chemical reaction, whereas in a battery the chemicals present in the battery react with each other to generate an electromotive force (emf). Fuel cells can produce electricity continuously for as long as these inputs are supplied.
The first fuel cells were invented in 1838. The first commercial use of fuel cells came more than a century later in NASA space programs to generate power for satellites and space capsules. Since then, fuel cells have been used in many other applications. Fuel cells are used for primary and backup power for commercial, industrial and residential buildings and in remote or inaccessible areas. They are also used to power fuel cell vehicles, including forklifts, automobiles, buses, boats, motorcycles and submarines.
There are many types of fuel cells, but they all consist of an anode, a cathode, and an electrolyte that allows positively charged hydrogen ions (or protons) to move between the two sides of the fuel cell. The anode and cathode contain catalysts that cause the fuel to undergo oxidation reactions that generate positively charged hydrogen ions and electrons. The hydrogen ions are drawn through the electrolyte after the reaction. At the same time, electrons are drawn from the anode to the cathode through an external circuit, producing direct current electricity. At the cathode, hydrogen ions, electrons, and oxygen react to form water. As the main difference among fuel cell types is the electrolyte, fuel cells are classified by the type of electrolyte they use and by the difference in startup time ranging from 1 second for proton exchange membrane fuel cells (PEM fuel cells, or PEMFC) to 10 minutes for solid oxide fuel cells (SOFC). Individual fuel cells produce relatively small electrical potentials, about 0.7 volts, so cells are "stacked", or placed in series, to create sufficient voltage to meet an application's requirements. In addition to electricity, fuel cells produce water, heat and, depending on the fuel source, very small amounts of nitrogen dioxide and other emissions. The energy efficiency of a fuel cell is generally between 40–60%, or up to 85% efficient in cogeneration if waste heat is captured for use.
The fuel cell market is growing, and Pike Research has estimated that the stationary fuel cell market will reach 50 GW by 2020.
History.
The first references to hydrogen fuel cells appeared in 1838. In a letter dated October 1838 but published in the December 1838 edition of "The London and Edinburgh Philosophical Magazine and Journal of Science", Welsh physicist and barrister William Grove wrote about the development of his first crude fuel cells. He used a combination of sheet iron, copper and porcelain plates, and a solution of sulphate of copper and dilute acid. In a letter to the same publication written in December 1838 but published in June 1839, German physicist Christian Friedrich Schönbein discussed the first crude fuel cell that he had invented. His letter discussed current generated from hydrogen and oxygen dissolved in water. Grove later sketched his design, in 1842, in the same journal. The fuel cell he made used similar materials to today's phosphoric-acid fuel cell. 9.
In 1939, British engineer Francis Thomas Bacon successfully developed a 5 kW stationary fuel cell. In 1955, W. Thomas Grubb, a chemist working for the General Electric Company (GE), further modified the original fuel cell design by using a sulphonated polystyrene ion-exchange membrane as the electrolyte. Three years later another GE chemist, Leonard Niedrach, devised a way of depositing platinum onto the membrane, which served as catalyst for the necessary hydrogen oxidation and oxygen reduction reactions. This became known as the "Grubb-Niedrach fuel cell". GE went on to develop this technology with NASA and McDonnell Aircraft, leading to its use during Project Gemini. This was the first commercial use of a fuel cell. In 1959, a team led by Harry Ihrig built a 15 kW fuel cell tractor for Allis-Chalmers, which was demonstrated across the U.S. at state fairs. This system used potassium hydroxide as the electrolyte and compressed hydrogen and oxygen as the reactants. Later in 1959, Bacon and his colleagues demonstrated a practical five-kilowatt unit capable of powering a welding machine. In the 1960s, Pratt and Whitney licensed Bacon's U.S. patents for use in the U.S. space program to supply electricity and drinking water (hydrogen and oxygen being readily available from the spacecraft tanks). In 1991, the first hydrogen fuel cell automobile was developed by Roger Billings.
UTC Power was the first company to manufacture and commercialize a large, stationary fuel cell system for use as a co-generation power plant in hospitals, universities and large office buildings.
In recognition of the fuel cell industry and America’s role in fuel cell development, the US Senate recognized October 8, 2015 as National Hydrogen and Fuel Cell Day, passing S. RES 217. The date was chosen in recognition of the atomic weight of hydrogen (1.008).
Types of fuel cells; design.
Fuel cells come in many varieties; however, they all work in the same general manner. They are made up of three adjacent segments: the anode, the electrolyte, and the cathode. Two chemical reactions occur at the interfaces of the three different segments. The net result of the two reactions is that fuel is consumed, water or carbon dioxide is created, and an electric current is created, which can be used to power electrical devices, normally referred to as the load.
At the anode a catalyst oxidizes the fuel, usually hydrogen, turning the fuel into a positively charged ion and a negatively charged electron. The electrolyte is a substance specifically designed so ions can pass through it, but the electrons cannot. The freed electrons travel through a wire creating the electric current. The ions travel through the electrolyte to the cathode. Once reaching the cathode, the ions are reunited with the electrons and the two react with a third chemical, usually oxygen, to create water or carbon dioxide.
The most important design features in a fuel cell are:
A typical fuel cell produces a voltage from 0.6 V to 0.7 V at full rated load. Voltage decreases as current increases, due to several factors:
To deliver the desired amount of energy, the fuel cells can be combined in series to yield higher voltage, and in parallel to allow a higher current to be supplied. Such a design is called a "fuel cell stack". The cell surface area can also be increased, to allow higher current from each cell. Within the stack, reactant gases must be distributed uniformly over each of the cells to maximize the power output.
Proton exchange membrane fuel cells (PEMFCs).
In the archetypical hydrogen–oxide proton exchange membrane fuel cell design, a proton-conducting polymer membrane (typically nafion) contains the electrolyte solution that separates the anode and cathode sides. This was called a "solid polymer electrolyte fuel cell" (SPEFC) in the early 1970s, before the proton exchange mechanism was well-understood. (Notice that the synonyms "polymer electrolyte membrane" and "proton exchange mechanism" result in the same acronym.)
On the anode side, hydrogen diffuses to the anode catalyst where it later dissociates into protons and electrons. These protons often react with oxidants causing them to become what are commonly referred to as multi-facilitated proton membranes. The protons are conducted through the membrane to the cathode, but the electrons are forced to travel in an external circuit (supplying power) because the membrane is electrically insulating. On the cathode catalyst, oxygen molecules react with the electrons (which have traveled through the external circuit) and protons to form water.
In addition to this pure hydrogen type, there are hydrocarbon fuels for fuel cells, including diesel, methanol ("see:" direct-methanol fuel cells and indirect methanol fuel cells) and chemical hydrides. The waste products with these types of fuel are carbon dioxide and water. When hydrogen is used, the CO2 is released when methane from natural gas is combined with steam, in a process called steam methane reforming, to produce the hydrogen. This can take place in a different location to the fuel cell, potentially allowing the hydrogen fuel cell to be used indoors—for example, in fork lifts.
The different components of a PEMFC are
The materials used for different parts of the fuel cells differ by type. The bipolar plates may be made of different types of materials, such as, metal, coated metal, graphite, flexible graphite, C–C composite, carbon–polymer composites etc. The membrane electrode assembly (MEA) is referred as the heart of the PEMFC and is usually made of a proton exchange membrane sandwiched between two catalyst-coated carbon papers. Platinum and/or similar type of noble metals are usually used as the catalyst for PEMFC. The electrolyte could be a polymer membrane.
Phosphoric acid fuel cell (PAFC).
Phosphoric acid fuel cells (PAFC) were first designed and introduced in 1961 by G. V. Elmore and H. A. Tanner. In these cells phosphoric acid is used as a non-conductive electrolyte to pass positive hydrogen ions from the anode to the cathode. These cells commonly work in temperatures of 150 to 200 degrees Celsius. This high temperature will cause heat and energy loss if the heat is not removed and used properly. This heat can be used to produce steam for air conditioning systems or any other thermal energy consuming system. Using this heat in cogeneration can enhance the efficiency of phosphoric acid fuel cells from 40–50% to about 80%. Phosphoric acid, the electrolyte used in PAFCs, is a non-conductive liquid acid which forces electrons to travel from anode to cathode through an external electrical circuit. Since the hydrogen ion production rate on the anode is small, platinum is used as catalyst to increase this ionization rate. A key disadvantage of these cells is the use of an acidic electrolyte. This increases the corrosion or oxidation of components exposed to phosphoric acid.
High-temperature fuel cells.
SOFC.
Solid oxide fuel cells (SOFCs) use a solid material, most commonly a ceramic material called yttria-stabilized zirconia (YSZ), as the electrolyte. Because SOFCs are made entirely of solid materials, they are not limited to the flat plane configuration of other types of fuel cells and are often designed as rolled tubes. They require high operating temperatures (800–1000 °C) and can be run on a variety of fuels including natural gas.
SOFCs are unique since in those, negatively charged oxygen ions travel from the cathode (positive side of the fuel cell) to the anode (negative side of the fuel cell) instead of positively charged hydrogen ions travelling from the anode to the cathode, as is the case in all other types of fuel cells. Oxygen gas is fed through the cathode, where it absorbs electrons to create oxygen ions. The oxygen ions then travel through the electrolyte to react with hydrogen gas at the anode. The reaction at the anode produces electricity and water as by-products. Carbon dioxide may also be a by-product depending on the fuel, but the carbon emissions from an SOFC system are less than those from a fossil fuel combustion plant. The chemical reactions for the SOFC system can be expressed as follows:
SOFC systems can run on fuels other than pure hydrogen gas. However, since hydrogen is necessary for the reactions listed above, the fuel selected must contain hydrogen atoms. For the fuel cell to operate, the fuel must be converted into pure hydrogen gas. SOFCs are capable of internally reforming light hydrocarbons such as methane (natural gas), propane and butane. These fuel cells are at an early stage of development.
Challenges exist in SOFC systems due to their high operating temperatures. One such challenge is the potential for carbon dust to build up on the anode, which slows down the internal reforming process. Research to address this "carbon coking" issue at the University of Pennsylvania has shown that the use of copper-based cermet (heat-resistant materials made of ceramic and metal) can reduce coking and the loss of performance. Another disadvantage of SOFC systems is slow start-up time, making SOFCs less useful for mobile applications. Despite these disadvantages, a high operating temperature provides an advantage by removing the need for a precious metal catalyst like platinum, thereby reducing cost. Additionally, waste heat from SOFC systems may be captured and reused, increasing the theoretical overall efficiency to as high as 80%–85%.
The high operating temperature is largely due to the physical properties of the YSZ electrolyte. As temperature decreases, so does the ionic conductivity of YSZ. Therefore, to obtain optimum performance of the fuel cell, a high operating temperature is required. According to their website, Ceres Power, a UK SOFC fuel cell manufacturer, has developed a method of reducing the operating temperature of their SOFC system to 500–600 degrees Celsius. They replaced the commonly used YSZ electrolyte with a CGO (cerium gadolinium oxide) electrolyte. The lower operating temperature allows them to use stainless steel instead of ceramic as the cell substrate, which reduces cost and start-up time of the system.
Hydrogen-oxygen fuel cell.
The hydrogen-oxygen fuel cell or alkaline fuel cell was designed and first demonstrated publicly by Francis Thomas Bacon in 1959. It was used as a primary source of electrical energy in the Apollo space program. The cell consists of two porous carbon electrodes impregnated with a suitable catalyst such as Pt, Ag, CoO, etc. The space between the two electrodes is filled with a concentrated solution of KOH or NaOH which serves as an electrolyte. 2H gas and O gas are bubbled into the electrolyte through the porous carbon electrodes. Thus the overall reaction involves the combination of hydrogen gas and oxygen gas to form water. The cell runs continuously until the reactant's supply is exhausted. This type of cell operates efficiently in the temperature range 343 K to 413 K and provides a potential of about 0.9 V.
MCFC.
Molten carbonate fuel cells (MCFCs) require a high operating temperature, , similar to SOFCs. MCFCs use lithium potassium carbonate salt as an electrolyte, and this salt liquefies at high temperatures, allowing for the movement of charge within the cell – in this case, negative carbonate ions.
Like SOFCs, MCFCs are capable of converting fossil fuel to a hydrogen-rich gas in the anode, eliminating the need to produce hydrogen externally. The reforming process creates emissions. MCFC-compatible fuels include natural gas, biogas and gas produced from coal. The hydrogen in the gas reacts with carbonate ions from the electrolyte to produce water, carbon dioxide, electrons and small amounts of other chemicals. The electrons travel through an external circuit creating electricity and return to the cathode. There, oxygen from the air and carbon dioxide recycled from the anode react with the electrons to form carbonate ions that replenish the electrolyte, completing the circuit. The chemical reactions for an MCFC system can be expressed as follows:
As with SOFCs, MCFC disadvantages include slow start-up times because of their high operating temperature. This makes MCFC systems not suitable for mobile applications, and this technology will most likely be used for stationary fuel cell purposes. The main challenge of MCFC technology is the cells' short life span. The high-temperature and carbonate electrolyte lead to corrosion of the anode and cathode. These factors accelerate the degradation of MCFC components, decreasing the durability and cell life. Researchers are addressing this problem by exploring corrosion-resistant materials for components as well as fuel cell designs that may increase cell life without decreasing performance.
MCFCs hold several advantages over other fuel cell technologies, including their resistance to impurities. They are not prone to "carbon coking", which refers to carbon build-up on the anode that results in reduced performance by slowing down the internal fuel reforming process. Therefore, carbon-rich fuels like gases made from coal are compatible with the system. The Department of Energy claims that coal, itself, might even be a fuel option in the future, assuming the system can be made resistant to impurities such as sulfur and particulates that result from converting coal into hydrogen. MCFCs also have relatively high efficiencies. They can reach a fuel-to-electricity efficiency of 50%, considerably higher than the 37–42% efficiency of a phosphoric acid fuel cell plant. Efficiencies can be as high as 65% when the fuel cell is paired with a turbine, and 85% if heat is captured and used in a Combined Heat and Power (CHP) system.
FuelCell Energy, a Connecticut-based fuel cell manufacturer, develops and sells MCFC fuel cells. The company says that their MCFC products range from 300 kW to 2.8 MW systems that achieve 47% electrical efficiency and can utilize CHP technology to obtain higher overall efficiencies. One product, the DFC-ERG, is combined with a gas turbine and, according to the company, it achieves an electrical efficiency of 65%.
Efficiency of leading fuel cell types.
Glossary of Terms in table:
For more information see Glossary of fuel cell terms
Theoretical maximum efficiency.
The energy efficiency of a system or device that converts energy is measured by the ratio of the amount of useful energy put out by the system ("output energy") to the total amount of energy that is put in ("input energy") or by useful output energy as a percentage of the total input energy. In the case of fuel cells, useful output energy is measured in electrical energy produced by the system. Input energy is the energy stored in the fuel. According to the U.S. Department of Energy, fuel cells are generally between 40–60% energy efficient. This is higher than some other systems for energy generation. For example, the typical internal combustion engine of a car is about 25% energy efficient. In combined heat and power (CHP) systems, the heat produced by the fuel cell is captured and put to use, increasing the efficiency of the system to up to 85–90%.
The theoretical maximum efficiency of any type of power generation system is never reached in practice, and it does not consider other steps in power generation, such as production, transportation and storage of fuel and conversion of the electricity into mechanical power. However, this calculation allows the comparison of different types of power generation. The maximum theoretical energy efficiency of a fuel cell is 83%, operating at low power density and using pure hydrogen and oxygen as reactants (assuming no heat recapture) According to the World Energy Council, this compares with a maximum theoretical efficiency of 58% for internal combustion engines. While these efficiencies are not approached in most real world applications, high-temperature fuel cells (solid oxide fuel cells or molten carbonate fuel cells) can theoretically be combined with gas turbines to allow stationary fuel cells to come closer to the theoretical limit. A gas turbine would capture heat from the fuel cell and turn it into mechanical energy to increase the fuel cell's operational efficiency. This solution has been predicted to increase total efficiency to as much as 80%.
In practice.
In a fuel-cell vehicle the tank-to-wheel efficiency is greater than 45% at low loads and shows average values of about 36% when a driving cycle like the NEDC (New European Driving Cycle) is used as test procedure. The comparable NEDC value for a Diesel vehicle is 22%. In 2008 Honda released a demonstration fuel cell electric vehicle (the Honda FCX Clarity) with fuel stack claiming a 60% tank-to-wheel efficiency.
It is also important to take losses due to fuel production, transportation, and storage into account. Fuel cell vehicles running on compressed hydrogen may have a power-plant-to-wheel efficiency of 22% if the hydrogen is stored as high-pressure gas, and 17% if it is stored as liquid hydrogen. Fuel cells cannot store energy like a battery, except as hydrogen, but in some applications, such as stand-alone power plants based on discontinuous sources such as solar or wind power, they are combined with electrolyzers and storage systems to form an energy storage system. Most hydrogen, however, is produced by steam methane reforming, and so most hydrogen production emits carbon dioxide. The overall efficiency (electricity to hydrogen and back to electricity) of such plants (known as "round-trip efficiency"), using pure hydrogen and pure oxygen can be "from 35 up to 50 percent", depending on gas density and other conditions. While a much cheaper lead–acid battery might return about 90%, the electrolyzer/fuel cell system can store indefinite quantities of hydrogen, and is therefore better suited for long-term storage.
Solid-oxide fuel cells produce exothermic heat from the recombination of the oxygen and hydrogen. The ceramic can run as hot as 800 degrees Celsius. This heat can be captured and used to heat water in a micro combined heat and power (m-CHP) application. When the heat is captured, total efficiency can reach 80–90% at the unit, but does not consider production and distribution losses. CHP units are being developed today for the European home market.
Professor Jeremy P. Meyers, in the Electrochemical Society journal "Interface" in 2008, wrote, "While fuel cells are efficient relative to combustion engines, they are not as efficient as batteries, due primarily to the inefficiency of the oxygen reduction reaction (and ... the oxygen evolution reaction, should the hydrogen be formed by electrolysis of water)... hey make the most sense for operation disconnected from the grid, or when fuel can be provided continuously. For applications that require frequent and relatively rapid start-ups ... where zero emissions are a requirement, as in enclosed spaces such as warehouses, and where hydrogen is considered an acceptable reactant, a EM fuel cel is becoming an increasingly attractive choice f exchanging batteries is inconvenien". In 2013 military organisations are evaluating fuel cells to significantly reduce the battery weight carried by soldiers.
Applications.
Power.
Stationary fuel cells are used for commercial, industrial and residential primary and backup power generation. Fuel cells are very useful as power sources in remote locations, such as spacecraft, remote weather stations, large parks, communications centers, rural locations including research stations, and in certain military applications. A fuel cell system running on hydrogen can be compact and lightweight, and have no major moving parts. Because fuel cells have no moving parts and do not involve combustion, in ideal conditions they can achieve up to 99.9999% reliability. This equates to less than one minute of downtime in a six-year period.
Since fuel cell electrolyzer systems do not store fuel in themselves, but rather rely on external storage units, they can be successfully applied in large-scale energy storage, rural areas being one example. There are many different types of stationary fuel cells so efficiencies vary, but most are between 40% and 60% energy efficient. However, when the fuel cell's waste heat is used to heat a building in a cogeneration system this efficiency can increase to 85%. This is significantly more efficient than traditional coal power plants, which are only about one third energy efficient. Assuming production at scale, fuel cells could save 20–40% on energy costs when used in cogeneration systems. Fuel cells are also much cleaner than traditional power generation; a fuel cell power plant using natural gas as a hydrogen source would create less than one ounce of pollution (other than ) for every 1,000 kW·h produced, compared to 25 pounds of pollutants generated by conventional combustion systems. Fuel Cells also produce 97% less nitrogen oxide emissions than conventional coal-fired power plants.
One such pilot program is operating on Stuart Island in Washington State. There the Stuart Island Energy Initiative has built a complete, closed-loop system: Solar panels power an electrolyzer, which makes hydrogen. The hydrogen is stored in a tank at , and runs a ReliOn fuel cell to provide full electric back-up to the off-the-grid residence. Another closed system loop was unveiled in late 2011 in Hempstead, NY.
Fuel cells can be used with low-quality gas from landfills or waste-water treatment plants to generate power and lower methane emissions. A 2.8 MW fuel cell plant in California is said to be the largest of the type.
Cogeneration.
Combined heat and power (CHP) fuel cell systems, including Micro combined heat and power (MicroCHP) systems are used to generate both electricity and heat for homes (see home fuel cell), office building and factories. The system generates constant electric power (selling excess power back to the grid when it is not consumed), and at the same time produces hot air and water from the waste heat. As the result CHP systems have the potential to save primary energy as they can make use of waste heat which is generally rejected by thermal energy conversion systems. A typical capacity range of home fuel cell is 1–3 kW / 4–8 kW. CHP systems linked to absorption chillers use their waste heat for refrigeration.
The waste heat from fuel cells can be diverted during the summer directly into the ground providing further cooling while the waste heat during winter can be pumped directly into the building. The University of Minnesota owns the patent rights to this type of system
Co-generation systems can reach 85% efficiency (40–60% electric + remainder as thermal). Phosphoric-acid fuel cells (PAFC) comprise the largest segment of existing CHP products worldwide and can provide combined efficiencies close to 90%. Molten Carbonate (MCFC) and Solid Oxide Fuel Cells (SOFC) are also used for combined heat and power generation and have electrical energy efficiences around 60%. Disadvantages of co-generation systems include slow ramping up and down rates, high cost and short lifetime. Also their need to have a hot water storage tank to smooth out the thermal heat production was a serious disadvantage in the domestic market place where space in domestic properties is at a great premium.
Delta-ee consultants stated in 2013 that with 64% of global sales the fuel cell micro-combined heat and power passed the conventional systems in sales in 2012. The Japanese ENE FARM project will pass 100,000 FC mCHP systems in 2014, 34.213 PEMFC and 2.224 SOFC were installed in the period 2012-2014, 30,000 units on LNG and 6,000 on LPG.
Fuel cell electric vehicles (FCEVs).
Automobiles.
As of 2015, two fuel cell vehicles have been introduced for commercial lease and sale in limited quantities: the Toyota Mirai and the Hyundai ix35 FCEV. Additional demonstration models include the Honda FCX Clarity, and Mercedes-Benz F-Cell. As of June 2011 demonstration FCEVs had driven more than , with more than 27,000 refuelings. Demonstration fuel cell vehicles have been produced with "a driving range of more than between refueling". They can be refueled in less than 5 minutes. The U.S. Department of Energy's Fuel Cell Technology Program claims that, as of 2011, fuel cells achieved 53–59% efficiency at one-quarter power and 42–53% vehicle efficiency at full power, and a durability of over with less than 10% degradation. In a Well-to-Wheels simulation analysis that "did not address the economics and market constraints", General Motors and its partners estimated that per mile traveled, a fuel cell electric vehicle running on compressed gaseous hydrogen produced from natural gas could use about 40% less energy and emit 45% less greenhouse gasses than an internal combustion vehicle. A lead engineer from the Department of Energy whose team is testing fuel cell cars said in 2011 that the potential appeal is that "these are full-function vehicles with no limitations on range or refueling rate so they are a direct replacement for any vehicle. For instance, if you drive a full sized SUV and pull a boat up into the mountains, you can do that with this technology and you can't with current battery-only vehicles, which are more geared toward city driving."
In 2014, Toyota introduced its first fuel cell vehicle in Japan, the Mirai, at a price of less than , although former European Parliament President Pat Cox estimates that Toyota will initially lose about $100,000 on each Mirai sold. Hyundai introduced the limited production Hyundai ix35 FCEV. Other manufacturers that have announced intentions to sell fuel cell electric vehicles commercially by 2016 include General Motors, Honda, Mercedes-Benz, and Nissan.
Criticism.
Some experts believe that fuel cell cars will never become economically competitive with other technologies or that it will take decades for them to become profitable. Elon Musk stated in 2015 that fuel cells for use in cars will never be commercially viable because of the inefficiency of producing, transporting and storing hydrogen and the flammability of the gas, among other reasons. Professor Jeremy P. Meyers estimated in 2008 that cost reductions over a production ramp-up period will take about 20 years after fuel-cell cars are introduced before they will be able to compete commercially with current market technologies, including gasoline internal combustion engines. In 2011, the chairman and CEO of General Motors, Daniel Akerson, stated that while the cost of hydrogen fuel cell cars is decreasing: "The car is still too expensive and probably won't be practical until the 2020-plus period, I don't know."
In 2012, Lux Research, Inc. issued a report that stated: "The dream of a hydrogen economy ... is no nearer". It concluded that "Capital cost ... will limit adoption to a mere 5.9 GW" by 2030, providing "a nearly insurmountable barrier to adoption, except in niche applications". The analysis concluded that, by 2030, PEM stationary market will reach $1 billion, while the vehicle market, including forklifts, will reach a total of $2 billion. Other analyses cite the lack of an extensive hydrogen infrastructure in the U.S. as an ongoing challenge to Fuel Cell Electric Vehicle commercialization. In 2006, a study for the IEEE showed that for hydrogen produced via electrolysis of water: "Only about 25% of the power generated from wind, water, or sun is converted to practical use." The study further noted that "Electricity obtained from hydrogen fuel cells appears to be four times as expensive as electricity drawn from the electrical transmission grid. ... Because of the high energy losses ydroge cannot compete with electricity." Furthermore, the study found: "Natural gas reforming is not a sustainable solution". "The large amount of energy required to isolate hydrogen from natural compounds (water, natural gas, biomass), package the light gas by compression or liquefaction, transfer the energy carrier to the user, plus the energy lost when it is converted to useful electricity with fuel cells, leaves around 25% for practical use."
Joseph Romm, the author of "The Hype About Hydrogen" (2005), devoted two articles in 2014 to updating his critique of the use of fuel cells in cars. He stated that FCVs still had not overcome the following issues: high cost of the vehicles, high fueling cost, and a lack of fuel-delivery infrastructure. "It would take several miracles to overcome all of those problems simultaneously in the coming decades." Most importantly, he said, "FCVs aren't green" because of escaping methane during natural gas extraction and when hydrogen is produced, as 95% of it is, using the steam reforming process. He concluded that renewable energy cannot economically be used to make hydrogen for an FCV fleet "either now or in the future." Greentech Media's analyst reached similar conclusions in 2014. In 2015, "Clean Technica" listed some of the disadvantages of hydrogen fuel cell vehicles. So did "Car Throttle". Another "Clean Technica" writer concluded, "while hydrogen may have a part to play in the world of energy storage (especially seasonal storage), it looks like a dead end when it comes to mainstream vehicles."
Buses.
, there were a total of approximately 100 fuel cell buses deployed around the world. Most buses are produced by UTC Power, Toyota, Ballard, Hydrogenics, and Proton Motor. UTC buses had accumulated over of driving by 2011. Fuel cell buses have a 39–141% higher fuel economy than diesel buses and natural gas buses. Fuel cell buses have been deployed around the world including in Whistler, Canada; San Francisco, United States; Hamburg, Germany; Shanghai, China; London, England; and São Paulo, Brazil.
The Fuel Cell Bus Club is a global cooperative effort in trial fuel cell buses. Notable projects include:
The first Brazilian hydrogen fuel cell bus prototype in Brazil was deployed in São Paulo. The bus was manufactured in Caxias do Sul and the hydrogen fuel will be produced in São Bernardo do Campo from water through electrolysis. The program, called "Ônibus Brasileiro a Hidrogênio" (Brazilian Hydrogen Autobus), includes three additional buses.
Forklifts.
A fuel cell forklift (also called a fuel cell lift truck) is a fuel cell-powered industrial forklift truck used to lift and transport materials. In 2013 there were over 4,000 fuel cell forklifts used in material handling in the US, of which only 500 received funding from DOE (2012). The global market is 1 million fork lifts per year. Fuel cell fleets are operated by various companies, including Sysco Foods, FedEx Freight, GENCO (at Wegmans, Coca-Cola, Kimberly Clark, and Whole Foods), and H-E-B Grocers. Europe demonstrated 30 fuel cell forklifts with Hylift and extended it with HyLIFT-EUROPE to 200 units, with other projects in France and Austria. Pike Research stated in 2011 that fuel cell-powered forklifts will be the largest driver of hydrogen fuel demand by 2020.
Most companies in Europe and the US do not use petroleum-powered forklifts, as these vehicles work indoors where emissions must be controlled and instead use electric forklifts. Fuel cell-powered forklifts can provide benefits over battery-powered forklifts as they can work for a full 8-hour shift on a single tank of hydrogen and can be refueled in 3 minutes. Fuel cell-powered forklifts can be used in refrigerated warehouses, as their performance is not degraded by lower temperatures. The FC units are often designed as drop-in replacements.
Motorcycles and bicycles.
In 2005 a British manufacturer of hydrogen-powered fuel cells, Intelligent Energy (IE), produced the first working hydrogen run motorcycle called the ENV (Emission Neutral Vehicle). The motorcycle holds enough fuel to run for four hours, and to travel in an urban area, at a top speed of . In 2004 Honda developed a fuel-cell motorcycle that utilized the Honda FC Stack.
Other examples of motorbikes and bicycles that use hydrogen fuel cells include the Taiwanese company APFCT's scooter using the fueling system from Italy's Acta SpA and the Suzuki Burgman scooter with an IE fuel cell that received EU Whole Vehicle Type Approval in 2011. Suzuki Motor Corp. and IE have announced a joint venture to accelerate the commercialization of zero-emission vehicles.
Airplanes.
Boeing researchers and industry partners throughout Europe conducted experimental flight tests in February 2008 of a manned airplane powered only by a fuel cell and lightweight batteries. The fuel cell demonstrator airplane, as it was called, used a proton exchange membrane (PEM) fuel cell/lithium-ion battery hybrid system to power an electric motor, which was coupled to a conventional propeller. In 2003, the world's first propeller-driven airplane to be powered entirely by a fuel cell was flown. The fuel cell was a stack design that allowed the fuel cell to be integrated with the plane's aerodynamic surfaces.
Fuel cell-powered unmanned aerial vehicles (UAV) include a Horizon fuel cell UAV that set the record distance flown for a small UAV in 2007. The military is interested in this application because of its low noise, low thermal signature and ability to attain high altitude. In 2009 the Naval Research Laboratory's (NRL's) Ion Tiger utilized a hydrogen-powered fuel cell and flew for 23 hours and 17 minutes. Fuel cells are also in use to provide auxiliary power in aircraft, replacing fossil fuel generators that were previously used to start the engines and power on board electrical needs.
In January 2016 a Raptor E1 drone made a successful test flight using a that was lighter than the lithium-ion battery it replaced. The flight lasted 10 minutes at an altitude of , although the fuel cell reportedly had enough fuel to fly for two hours. The fuel was contained in approximately 100 solid pellets composed of a proprietary chemical within an unpressurized cartridge. The pellets are physically robust and operate at temperatures as warm as . The cell was from Arcola Energy.
Boats.
The world's first fuel-cell boat HYDRA used an AFC system with 6.5 kW net output. Iceland has committed to converting its vast fishing fleet to use fuel cells to provide auxiliary power by 2015 and, eventually, to provide primary power in its boats. Amsterdam recently introduced its first fuel cell-powered boat that ferries people around the city's famous and beautiful canals.
Submarines.
The Type 212 submarines of the German and Italian navies use fuel cells to remain submerged for weeks without the need to surface.
The U212A is a non-nuclear submarine developed by German naval shipyard Howaldtswerke Deutsche Werft. The system consists of nine PEM fuel cells, providing between 30 kW and 50 kW each. The ship is silent, giving it an advantage in the detection of other submarines. A naval paper has theorized about the possibility of a nuclear-fuel cell hybrid whereby the fuel cell is used when silent operations are required and then replenished from the Nuclear reactor (and water).
Portable power systems.
Portable power systems that use fuel cells can be used in the leisure sector (i.e. RVs, cabins, marine), the industrial sector (i.e. power for remote locations including gas/oil wellsites, communication towers, security, weather stations), and in the military sector. SFC Energy is a German manufacturer of direct methanol fuel cells for a variety of portable power systems. Ensol Systems Inc. is an integrator of portable power systems, using the SFC Energy DMFC.
Fueling stations.
There were over 85 hydrogen refueling stations in the U.S. in 2010. Some of these have closed, and In November 2013, "The New York Times" reported that there were "10 hydrogen stations available to the public in the entire United States: one in Columbia, S.C., eight in Southern California and the one in Emeryville". In 2013 the Department of Energy launched H2USA focused on advancing the hydrogen infrastructure. As of July 2015, there were 12 public hydrogen fueling stations in the US, 10 of which were in California.
The first public hydrogen refueling station in Iceland operated from 2003 to 2007. It served three buses in the public transport net of Reykjavík. The station produced its own hydrogen with an electrolyzing unit. The 14 stations in Germany were planned to be expanded to 50 by 2015 through its public private partnership Now GMBH.
Japan has a hydrogen highway, as part of the Japan hydrogen fuel cell project. Twelve hydrogen fueling stations had been built in 11 cities in Japan by 2012. Canada, Sweden and Norway also had planned hydrogen highways.
Markets and economics.
In 2012, fuel cell industry revenues exceeded $1 billion market value worldwide, with Asian pacific countries shipping more than 3/4 of the fuel cell systems worldwide. However, as of January 2014, no public company in the industry had yet become profitable. There were 140,000 fuel cell stacks shipped globally in 2010, up from 11,000 shipments in 2007, and from 2011 to 2012 worldwide fuel cell shipments had an annual growth rate of 85%. Tanaka Kikinzoku expanded its manufacturing facilities in 2011. Approximately 50% of fuel cell shipments in 2010 were stationary fuel cells, up from about a third in 2009, and the four dominant producers in the Fuel Cell Industry were the United States, Germany, Japan and South Korea. The Department of Energy Solid State Energy Conversion Alliance found that, as of January 2011, stationary fuel cells generated power at approximately $724 to $775 per kilowatt installed. In 2011, Bloom Energy, a major fuel cell supplier, said that its fuel cells generated power at 9–11 cents per kilowatt-hour, including the price of fuel, maintenance, and hardware.
Industry groups predict that there are sufficient platinum resources for future demand, and in 2007, research at Brookhaven National Laboratory suggested that platinum could be replaced by a gold-palladium coating, which may be less susceptible to poisoning and thereby improve fuel cell lifetime. Another method would use iron and sulphur instead of platinum. This would lower the cost of a fuel cell (as the platinum in a regular fuel cell costs around , and the same amount of iron costs only around ). The concept was being developed by a coalition of the John Innes Centre and the University of Milan-Bicocca. PEDOT cathodes are immune to monoxide poisoning.

</doc>
<doc id="11732" url="https://en.wikipedia.org/wiki?curid=11732" title="Finlandization">
Finlandization

Finlandization (; ; ) is the process by which one powerful country strongly influences the policies of a smaller neighboring country, while allowing it to keep its independence and its own political system. The term literally means "to become like Finland" referring to the influence of the Soviet Union on Finland's policies during the Cold War.
The term is generally considered pejorative, originating in West German political debate of the late 1960s and 1970s. As the term was used in Germany and other NATO countries, it referred to the decision of a country not to challenge a more powerful neighbour in foreign politics, while maintaining national sovereignty. It is commonly used in reference to Finland's policies in relation to the Soviet Union during the Cold War, but it can refer more generally to similar international relations, such as Denmark's attitude toward Germany between 1871 and 1940, or the policies of the Swiss government towards the German Nazi regime immediately before World War II.
Origin and international usage.
In Germany, the term was used mainly by proponents of closer adaptation to US policies, chiefly Franz Josef Strauss, but was initially coined in scholarly debate, and made known by the German political scientists Walter Hallstein and Richard Löwenthal, reflecting feared effects of withdrawal of US troops from Germany. It came to be used in the debate of the NATO countries in response to Willy Brandt's attempts to normalise relations with East Germany, and the following widespread scepticism in Germany against NATO's Dual-Track Decision. Later, after the fall of the Soviet Union, the term has been used in Finland for the post-1968 radicalisation in the latter half of the Urho Kekkonen era.
Finnish perception.
In Finland, the term "Finlandization" was perceived as blunt criticism, stemming from an inability to understand the practicalities of how a small nation needs to deal with an adjacent superpower without losing its sovereignty. These practicalities existed especially because of the lingering effect of Russian rule in their time, before the Finns first gained sovereignty, and because of the precarious power balance eastwards, springing from a geographically extended yet sparsely populated state with a traditionally imperialist superpower right across the eastern border.
The reason Finland engaged in Finlandization was primarily Realpolitik: to survive. On the other hand, the threat of the Soviet Union was used also in Finland's domestic politics in a way that possibly deepened Finlandization (playing the so-called "idänkortti", "east card"). Finland cut such a deal with Joseph Stalin's government in the late 1940s, and it was largely respected by both parties—and to the gain of both parties—until the fall of the Soviet Union in 1991. While the Finnish political and intellectual elite mostly understood the term to refer more to the foreign policy problems of other countries, and meant mostly for domestic consumption in the speaker's own country, many ordinary Finns considered the term highly offensive. The Finnish political cartoonist Kari Suomalainen once explained Finlandization as "the art of bowing to the East without mooning the West".
Historical background.
Finland's foreign politics before this deal had been varied: independence from Imperial Russia with support of Imperial Germany in 1917; participation in the Russian Civil War (without official declaration of war) alongside the Triple Entente 1918–1920; a non-ratified alliance with Poland in 1922; association with the neutralist and democratic Scandinavian countries in the 1930s ended by the Winter War (1939); and finally in 1940, a rapprochement with Nazi Germany, the only power able and willing to help Finland against the expansionist Soviet Union, leading to the Continuation War in 1941.
The Wehrmacht's defeat in the Battle of Stalingrad led Finland to basically revert to its 19th-century traditions, which had been perceived as highly successful until the Russification of Finland (1899–1905). Finland's leaders realised that opposing the Soviets head-on was no longer feasible. No international power was able to give the necessary support. Nazi Germany, Finland's chief supporter against Russia, was losing the war. Sweden was not big enough, and its leadership was wary of confronting Russia. The western powers were allied with the Soviet Union. Thus Finland had to face its big neighbour on its own, without any greater power's protection. As in the 19th century, Finland chose not to challenge Imperial Russia's foreign policy, but exerted caution to keep its independence.
Paasikivi doctrine.
After the Paris Peace Treaty of 1947, Finland succeeded in retaining democracy and parliamentarism, despite the heavy political pressure on Finland's foreign and internal affairs by the Soviet Union. Finland's foreign relations were guided by the doctrine formulated by Juho Kusti Paasikivi, emphasising the necessity to maintain a good and trusting relationship with the Soviet Union.
Finland signed an Agreement of Friendship, Cooperation, and Mutual Assistance with the Soviet Union in April 1948, under which Finland was obliged to resist armed attacks by "Germany or its allies" against Finland, or against the Soviet Union through Finland, and, if necessary, ask for Soviet military aid to do so. At the same time, the agreement recognised Finland's desire to remain outside great power conflicts, allowing the country to adopt a policy of neutrality during the Cold War.
As a consequence, Finland did not participate in the Marshall Plan and took neutral positions on Soviet overseas initiatives. By keeping very cool relations to NATO and western military powers in general, Finland could fend off Soviet pressure for affiliation to the Warsaw Pact.
Self-censorship and excessive Soviet adaptation.
However, from the political scene following the post-1968 radicalisation, the Soviet adaptation spread to the editors of mass media, sparking strong forms of self-control, self-censorship and pro-Soviet attitudes. Most of the élite of media and politics shifted their attitudes to match the values that the Soviets were thought to favor and approve.
Only after the ascendancy of Mikhail Gorbachev to Soviet leadership in 1985 did mass media in Finland gradually begin to criticise the Soviet Union more. When the Soviet Union allowed non-communist governments to take power in Eastern Europe, Gorbachev suggested they could look to Finland as an example to follow.
Censorship.
In the years immediately after the war (1944–1946), the Soviet part of the allied control commission demanded that public libraries should remove from circulation more than 1,700 books that were deemed anti-Soviet, and bookstores were given catalogs of banned books. The Finnish Board of Film Classification likewise banned movies that it considered to be anti-Soviet. Banned movies included "One, Two, Three" (1961 film), directed by Billy Wilder, "The Manchurian Candidate", directed by John Frankenheimer in 1962, "One Day in the Life of Ivan Denisovich" 1970 by Finnish director Caspar Wrede and "Born American" by Finnish director Renny Harlin in 1986.
Criticism.
United States foreign policy experts consistently feared that Western Europe and Japan would be Finlandized, leading to a situation in which these key allies no longer supported the United States against the Soviet Union. The theory of bandwagoning provided support for the idea that if the United States was not able to provide strong and credible support for the anti-communist positions of its allies, NATO and the U.S.–Japan alliance could collapse.
However, foreign policy scholars such as Eric Nordlinger in his book "Isolationism Reconfigured" have argued that "a vision of Finlandization in America's absence runs up squarely against the European states' long-standing Communist antipathies and wariness of Moscow's peaceful wiles, valued national traditions and strong democratic institutions, as well as their size and wherewithal".

</doc>
<doc id="11734" url="https://en.wikipedia.org/wiki?curid=11734" title="Fred Singer">
Fred Singer

Siegfried Fred Singer (born September 27, 1924) is an Austrian-born American physicist and emeritus professor of environmental science at the University of Virginia. Singer trained as an atmospheric physicist and is known for his work in space research, atmospheric pollution, rocket and satellite technology, his questioning of the link between UV-B and melanoma rates, and that between CFCs and stratospheric ozone loss, his public denial of the health risks of passive smoking, and as an advocate for climate change denial. He is the author or editor of several books including "Global Effects of Environmental Pollution" (1970), "The Ocean in Human Affairs" (1989), "Global Climate Change" (1989), "The Greenhouse Debate Continued" (1992), and "Hot Talk, Cold Science" (1997). He has also co-authored "" (2007) with Dennis Avery, and "Climate Change Reconsidered" (2009) with Craig Idso.
Singer has had a varied career, serving in the armed forces, government, and academia. He designed mines for the U.S. Navy during World War II, before obtaining his Ph.D. in physics from Princeton University in 1948 and working as a scientific liaison officer in the U.S. Embassy in London. He became a leading figure in early space research, was involved in the development of earth observation satellites, and in 1962 established the National Weather Bureau's Satellite Service Center. He was the founding dean of the University of Miami School of Environmental and Planetary Sciences in 1964, and held several government positions, including deputy assistant administrator for the Environmental Protection Agency, and chief scientist for the Department of Transportation. He held a professorship with the University of Virginia from 1971 until 1994, and with George Mason University until 2000.
In 1990 Singer founded the Science & Environmental Policy Project, and in 2006 was named by the Canadian Broadcasting Corporation as one of a minority of scientists said to be creating a stand-off on a consensus on climate change. Singer argues there is no evidence that global warming is attributable to human-caused increases in atmospheric carbon dioxide, and that humanity would benefit if temperatures do rise.
He is an opponent of the Kyoto Protocol, and has claimed that climate models are neither based on reality nor evidence.
Early life and education.
Singer was born in Vienna, Austria, where his father was a jeweler and his mother a homemaker. When the Nazis invaded, the family fled, Singer leaving on a children's transport train with other Jewish children. He ended up in England, where he lived in Northumberland, working for a time as a teenage optician. Several years later he emigrated to Ohio and became an American citizen in 1944. He received a B.E.E. in electrical engineering from Ohio State University in 1943, and an A.M. in physics from Princeton in 1944. He taught physics at Princeton while he worked on his masters and his doctorate, obtaining his Ph.D. there in 1948. His doctoral thesis was titled, ""The density spectrum and latitude dependence of extensive cosmic ray air showers"." His supervisor was John Archibald Wheeler, and his thesis committee included J. Robert Oppenheimer and Niels Bohr.
Career.
1950: United States Navy.
After his masters, Singer joined the Armed Forces, working for the United States Navy on mine warfare and countermeasures from 1944 until 1946. While with the Naval Ordnance Laboratory he developed an arithmetic element for an electronic digital calculator that he called an "electronic brain." He was discharged in 1946 and joined the Upper Atmosphere Rocket Program at the Johns Hopkins University Applied Physics Laboratory in Silver Spring, Maryland, working there until 1950. He focused on ozone, cosmic rays, and the ionosphere, all measured using balloons and rockets launched from White Sands, New Mexico, or from ships out at sea. Rachel White Scheuering writes that for one mission to launch a rocket, he sailed with a naval operation to the Arctic, and also conducted rocket launching from ships at the equator.
From 1950 to 1953, he was attached to the U.S. Embassy in London as a scientific liaison officer with the Office of Naval Research, where he studied research programs in Europe into cosmic radiation and nuclear physics. While there, he was one of eight delegates with a background in guided weapons projects to address the Fourth International Congress of Astronautics in Zurich in August 1953, at a time when, as "The New York Times" reported, most scientists saw space flight as thinly disguised science fiction.
1951: Design of early satellites.
Singer was one of the first scientists to urge the launching of earth satellites for scientific observation during the 1950s. In 1951 or 1952 he proposed the MOUSE ("Minimal Orbital Unmanned Satellite, Earth"), a satellite that would contain Geiger counters for measuring cosmic rays, photo cells for scanning the Earth, telemetry electronics for sending data back to Earth, a magnetic data storage device, and rudimentary solar energy cells. Although MOUSE never flew, the "Baltimore News Post" reported in 1957 that had Singer's arguments about the need for satellites been heeded, the U.S. could have beaten Russia by launching the first earth satellite. He also proposed (along with R. C. Wentworth) that satellite measurement of ultraviolet backscatter could be used as a method to measure atmospheric ozone profiles. This technique was later used on early weather satellites.
1953: University of Maryland.
Singer moved back to the United States in 1953, where he took up an associate professorship in physics at the University of Maryland, and at the same time served as the director of the Center for Atmospheric and Space Physics. Scheuering writes that his work involved conducting experiments on rockets and satellites, remote sensing, radiation belts, the magnetosphere, and meteorites. He developed a new method of launching rockets into space: firing them from a high-flying plane, both with and without a pilot. The Navy adopted the idea and Singer supervised the project. He received a White House Special Commendation from President Eisenhower in 1954 for his work.
He became one of 12 board members of the American Astronautical Society, an organization formed in 1954 to represent the country's 300 leading scientists and engineers in the area of guided missiles—he was one of seven members of the board to resign in December 1956 after a series of disputes about the direction and control of the group.
In November 1957 Singer and other scientists at the university successfully designed and fired three new "Oriole" rockets off the Virginia Capes. The rockets weighed less than and could be built for around $2000. Fired from a converted Navy LSM, they could reach an altitude of and had a complete telemetry system to send back information on cosmic, ultraviolet and X-rays. Singer said that the firings placed "the exploration of outer space with high altitude rockets on the same basis, cost-wise and effort-wise, as low atmosphere measurements with weather balloons. From now on, we can fire thousands of these rockets all over the world with very little cost."
In February 1958, when he was head of the cosmic ray group of the University of Maryland's physics department, he was congratulated in a telegram to the president of the university from President Eisenhower for his work in satellite research. In April 1958, he was appointed as a consultant to the House Committee on Astronautics and Space Exploration, which was preparing to hold hearings on President Eisenhower's proposal for a new agency to handle space research, and a month later received the Ohio State University's Distinguished Alumnus Award. He became a full professor at Maryland in 1959, and was chosen that year by the United States Junior Chamber of Commerce as one of the country's ten outstanding young men.
In a January 1960 presentation to the American Physical Society, Singer sketched out his vision of what the environment around the earth might consist of, extending up to into space. He became known for his early predictions about the properties of the electrical particles trapped around the earth, which were partly verified by later discoveries in satellite experiments. In December 1960, he suggested the existence of a shell of visible dust particles around the earth some 600 to in space, beyond which there was a layer of smaller particles, a micrometre or less in diameter, extending 2,000 to . In March 1961 Singer and another University of Maryland physicist, E. J. Opik, were given a $97,000 grant by NASA to conduct a three-year study of interplanetary gas and dust.
1960: Artificial Phobos hypothesis.
In a 1960 "Astronautics" newsletter, Singer commented on Iosif Shklovsky's hypothesis that the orbit of the Martian moon Phobos suggests that it is hollow, which implies it is of artificial origin. Singer wrote: "My conclusion there is, and here I back Shklovsky, that if the satellite is indeed spiraling inward as deduced from astronomical observation, then there is little alternative to the hypothesis that it is hollow and therefore martian made. The big 'if' lies in the astronomical observations; they may well be in error. Since they are based on several independent sets of measurements taken decades apart by different observers with different instruments, systematic errors may have influenced them." Later measurements confirmed Singer's "big "if"" caveat: Shklovsky overestimated Phobos' rate of altitude loss due to bad early data. Photographs by probes beginning 1972 show a natural stony surface with craters. Ufologists continue to present Singer as an unconditional supporter of Shklovsky's artificial Phobos hypothesis.
"Time" magazine wrote in 1969 that Singer had had a lifelong fascination with Phobos and Mars's second moon, Deimos. He told "Time" it might be possible to pull Deimos into the Earth's orbit so it could be examined. During an international space symposium in May 1966, attended by space scientists from the United States and Soviet Union, he first proposed that manned landings on the Martian moons would be a logical step after a manned landing on the Earth's moon. He pointed out that the very small sizes of Phobos and Deimos—approximately and eight miles (13 km) in diameter and sub milli-g surface gravity—would make it easier for a spacecraft to land and take off again.
1962: National Weather Center and University of Miami.
In 1962, on leave from the university, Singer was named as the first director of meteorological satellite services for the National Weather Satellite Center, now part of the National Oceanic and Atmospheric Administration, and directed a program for using satellites to forecast the weather. He stayed there until 1964. He told "Time" magazine in 1969 that he enjoyed moving around. "Each move gave me a completely new perspective," he said. "If I had sat still, I'd probably still be measuring cosmic rays, the subject of my thesis at Princeton. That's what happens to most scientists." When he stepped down as director he received a Department of Commerce Gold Medal Award for Distinguished Federal Service.
In 1964, he became the first dean of the School of Environmental and Planetary Sciences at the University of Miami in 1964, the first school of its kind in the country, dedicated to space-age research. In December 1965, "The New York Times" reported on a conference Singer hosted in Miami Beach during which five groups of scientists, working independently, presented research identifying what they believed was the remains of a primordial flash that occurred when the universe was born.
1967: Department of Interior and EPA.
In 1967 he accepted the position of deputy assistant secretary with the U.S. Department of the Interior, where he was in charge of water quality and research. When the U.S. Environmental Protection Agency was created on 1970, he became its deputy assistant administrator of policy.
1971–1994 University of Virginia.
Singer accepted a professorship in Environmental Sciences at the University of Virginia in 1971, a position he held until 1994, where he taught classes on environmental issues such as ozone depletion, acid rain, climate change, population growth, and public policy issues related to oil and energy. In 1987 he took up a two-year post as chief scientist at the Department of Transportation, and in 1989 joined the Institute of Space Science and Technology in Gainesville, Florida where he contributed to a paper on the results from the Interplanetary Dust Experiment using data from the Long Duration Exposure Facility satellite. When he retired from Virginia in 1994, he became Distinguished Research Professor at the Institute for Humane Studies at George Mason University until 2000.
Naomi Oreskes and Erik Conway say that Singer was involved in the Reagan administration's efforts to prevent regulatory action to reduce acid rain.
Consultancies.
Singer has worked as a consultant for several government agencies, including the House Select Committee on Space, NASA, the Government Accountability Office, the National Science Foundation, the United States Atomic Energy Commission, National Research Council, the Department of Defense Strategic Defense Initiative, Department of Energy Nuclear Waste Panel, and the Department of the Treasury. Other clients have included the states of Virginia, Alaska, and Pennsylvania. In the private sector he has worked for Mitre Corp., GE, Ford, General Motors; during the late 1970s Singer consulted with Exxon, Shell, Unocal Sun Oil, and ARCO; and Lockheed Martin, Martin–Marietta, McDonnell-Douglas, ANSER, and IBM on space research. He has also advised the Independent Institute, the American Council on Science and Health, and Frontiers of Freedom.
Public debates.
Writing.
Throughout his academic career Singer has written frequently in the mainstream press, including "The New York Times", "The Washington Post", and "Wall Street Journal", often striking up positions that go against mainstream thinking. His overall position one of distrust of federal regulations and a faith in the free market. He believes in what Rachel White Scheuering calls "free market environmentalism": that market principles and incentives should be sufficient to lead to the protection of the environment and conservation of resources. Regular themes in his articles have been energy, oil embargoes, OPEC, Iran, and rising prices. Throughout the 1970s, for example, he downplayed the idea of an energy crisis and said it was largely a media event. In several papers in the 1990s and 2000s he struck up other positions against the mainstream, questioning the link between UV-B and melanoma rates, and that between CFCs and stratospheric ozone loss.
In October 1967, Singer wrote an article for "The Washington Post" from the perspective of 2007. His predictions included that planets had been explored but not colonized, and although rockets had become more powerful they had not replaced aircraft and ramjet vehicles. None of the fundamental laws of physics had been overturned. There was increased reliance on the electronic computer and data processor; the most exciting development was the increase in human intellect by direct electronic storage of information in the brain—the coupling of the brain to an external computer, thereby gaining direct access to an information library.
During Operation Desert Storm in 1991, he argued that smoke from the Kuwaiti oil fires would have little impact, in opposition to most commentators. He debated the astronomer Carl Sagan on ABC's "Nightline", Sagan arguing that, if enough fire-fighting teams were not assembled in short order, and if many fires were left to burn over a period of months to possibly a year, the smoke might loft into the upper atmosphere and lead to massive agricultural failures over South Asia. Singer argued that it would rise to then be rained out after a few days. In fact, both Sagan and Singer were incorrect; smoke plumes from the oil fires rose to 10,000–12,000 feet and lingered for nearly a month, but despite absorbing 75–80% of the sun's radiation in the Persian Gulf area the plumes had little global effect.
The public debates in which Singer has received most criticism have been about second-hand smoke and global warming. He has questioned the link between second-hand smoke and lung cancer, and has been an outspoken opponent of the mainstream scientific view on climate change; he argues there is no evidence that increases in carbon dioxide produced by human beings is causing global warming and that the temperature of the earth has always varied. A CBC "Fifth Estate" documentary in 2006 linked these two debates, naming Singer as a scientist who has acted as a consultant to industry in both areas, either directly or through a public relations firm. Naomi Oreskes and Erik Conway named Singer in their book, "Merchants of Doubt", as one of three contrarian physicists—along with Fred Seitz and Bill Nierenberg—who regularly injected themselves into the public debate about contentious scientific issues, positioning themselves as skeptics, their views gaining traction because the media gives them equal time out of a sense of fairness.
Second-hand smoke.
According to David Biello and John Pavlus in "Scientific American", Singer is best known for his denial of the health risks of passive smoking. He was involved in 1994 as writer and reviewer of a report on the issue by the Alexis de Tocqueville Institution, where he was a senior fellow. The report criticized the Environmental Protection Agency (EPA) for their 1993 study about the cancer risks of passive smoking, calling it "junk science". Singer told CBC's "The Fifth Estate" in 2006 that he stood by the position that the EPA had "cooked the data" to show that second-hand smoke causes lung cancer. CBC said that tobacco money had paid for Singer's research and for his promotion of it, and that it was organized by APCO. Singer told CBC it made no difference where the money came from. "They don't carry a note on a dollar bill saying 'This comes from the tobacco industry,'" he said. "In any case I was not aware of it, and I didn't ask APCO where they get their money. That's not my business." In December 2010 he wrote in "American Thinker" that he is nonsmoker who finds second-hand smoke an unpleasant irritant that cannot be healthy; he also wrote that his father, a heavy smoker, died of emphysema when relatively young. According to Singer, he serves on the advisory board of an anti-smoking organization, and has never been paid by Philip Morris or the tobacco lobby.
Global warming.
In a 2003 letter to the "Financial Times", Singer wrote that "there is no convincing evidence that the global climate is actually warming." In 2006, the CBC's "Fifth Estate" named Singer as one of a small group of scientists who have created what the documentary called a stand-off that is undermining the political response to global warming. The following year he appeared on the British Channel 4 documentary "The Great Global Warming Swindle". Singer argues there is no evidence that the increases in carbon dioxide produced by humans cause global warming, and that if temperatures do rise it will be good for humankind. He told CBC: "It was warmer a thousand years ago than it is today. Vikings settled Greenland. Is that good or bad? I think it's good. They grew wine in England, in northern England. I think that's good. At least some people think so." "We are certainly putting more carbon dioxide in the atmosphere," he told "The Daily Telegraph" in 2009. "However there is no evidence that this high CO is making a detectable difference. It should in principle, however the atmosphere is very complicated and one cannot simply argue that just because CO is a greenhouse gas it causes warming." He believes that radical environmentalists are exaggerating the dangers. "The underlying effort here seems to be to use global warming as an excuse to cut down the use of energy," he said. "It's very simple: if you cut back the use of energy, then you cut back economic growth. And believe it or not, there are people in the world who believe we have gone too far in economic growth."
Singers's opinions conflict with the scientific opinion on climate change, where there is overwhelming consensus for anthropogenic global warming, and a decisive link between carbon dioxide concentration and global average temperatures, as well as consensus that such a change to the climate will have dangerous consequences. In 2005 Mother Jones magazine described Singer as a "godfather of global warming denial." However, Singer characterizes himself as a "skeptic" rather than a "denier" of global climate change. In an article in "American Thinker", he complains about bad arguments used by the "deniers," saying that "Climate deniers are giving us skeptics a bad name."
SEPP and funding.
In 1990 Singer set up the Science & Environmental Policy Project (SEPP) to argue against preventive measures against global warming. After the 1991 United Nations Conference on Environment and Development, the Earth Summit, Singer started writing and speaking out to cast doubt on the science. He predicted disastrous economic damage from any restrictions on fossil fuel use, and argued that the natural world and its weather patterns are complex and ill-understood, and that little is known about the dynamics of heat exchange from the oceans to the atmosphere, or the role of clouds. As the scientific consensus grew, he continued to argue from a skeptical position. He has repeatedly criticized the climate models that predict global warming. In 1994 he compared model results to observed temperatures and found that the predicted temperatures for 1950–1980 deviated from the temperatures that had actually occurred, from which he concluded in his regular column in "The Washington Times"—with the headline that day "Climate Claims Wither under the Luminous Lights of Science"—that climate models are faulty. In 2007 he collaborated on a study that found tropospheric temperature trends of "Climate of the 20th Century" models differed from satellite observations by twice the model mean uncertainty.
Rachel White Scheuering writes that, when SEPP began, it was affiliated with the Washington Institute for Values in Public Policy, a think tank founded by Unification Church leader Sun Myung Moon. A 1990 article for the Cato Institute identifies Singer as the director of the science and environmental policy project at the Washington Institute for Values in Public Policy, on leave from the University of Virginia. Scheuering writes that Singer had cut ties with the institute, and is funded by foundations and oil companies. She writes that he has been a paid consultant for many years for ARCO, ExxonMobil, Shell, Sun Oil Company, and Unocal, and that SEPP has received grants from ExxonMobil. Singer has said his financial relationships do not influence his research. Scheuering argues that his conclusions concur with the economic interests of the companies that pay him, in that the companies want to see a reduction in environmental regulation.
In August 2007 "Newsweek" reported that in April 1998 a dozen people from what it called "the denial machine" met at the American Petroleum Institute's Washington headquarters. The meeting included Singer's group, the George C. Marshall Institute, and ExxonMobil. Newsweek said that, according to an eight-page memo that was leaked, the meeting proposed a $5-million campaign to convince the public that the science of global warming was controversial and uncertain. The plan was leaked to the press and never implemented. The week after the story, "Newsweek" published a contrary view from Robert Samuelson, one of its columnists, who said the story of an industry-funded denial machine was contrived and fundamentally misleading. ABC News reported in March 2008 that Singer said he is not on the payroll of the energy industry, but he acknowledged that SEPP had received one unsolicited charitable donation of $10,000 from ExxonMobil, and that it was one percent of all donations received. Singer said that his connection to Exxon was more like being on their mailing list than holding a paid position. The relationships have discredited Singer's research among members of the scientific community, according to Scheuering. Congresswoman Lynn Rivers questioned Singer's credibility during a congressional hearing in 1995, saying he had not been able to publish anything in a peer-reviewed scientific journal for the previous 15 years, except for one technical comment.
Criticism of the IPCC.
In 1995 the Intergovernmental Panel on Climate Change (IPCC) issued a report reflecting the scientific consensus that the balance of evidence suggests there is a discernible human influence on global climate. Singer responded with a letter to "Science" saying the IPCC report had presented material selectively. He wrote: "the Summary does not even mention the existence of 18 years of weather satellite data that show a slight global cooling trend, contradicting all theoretical models of climate warming." Scheuering writes that Singer acknowledges the surface thermometers from weather stations show warming, but he argues that the satellites provide better data because their measurements cover pole to pole.
According to Edward Parson and Andrew Dessler, the satellite data did not show surface temperatures directly, but had to be adjusted using models. When adjustment was made for transient events the data showed a slight warming, and research suggested that the discrepancy between surface and satellite data was largely accounted for by problems such as instrument differences between satellites.
Singer wrote the "Leipzig Declaration on Global Climate Change in the U.S." in 1995, updating it in 1997 to rebut the Kyoto Protocol. The Kyoto Protocol was the result of an international convention held in Kyoto, Japan, during which several industrialized nations agreed to reduce their greenhouse gas emissions. Singer's declaration read: "Energy is essential for economic growth ... We understand the motivation to eliminate what are perceived to be the driving forces behind a potential climate change; but we believe the Kyoto Protocol—to curtail carbon dioxide emissions from only a part of the world community—is dangerously simplistic, quite ineffective, and economically destructive to jobs and standards-of-living."
Scheuering writes that Singer circulated this in the United States and Europe and gathered 100 signatories, though she says some of the signatories' credentials were questioned. At least 20 were television weather reporters, some did not have science degrees, and 14 were listed as professors without specifying a field. According to Scheuering, some of them later said they believed they were signing a document in favour of action against climate change.
Singer set up the Nongovernmental International Panel on Climate Change (NIPCC) after a 2004 United Nations climate conference in Milan. NIPCC organized an international climate workshop in Vienna in April 2007, to provide what they called an independent examination of the evidence for climate change. Singer prepared an NIPCC report called "Nature, Not Human Activity, Rules the Climate," published in March 2008 by The Heartland Institute, a conservative think tank. ABC News said the same month that unnamed climate scientists from NASA, Stanford, and Princeton who spoke to ABC about the report dismissed it as "fabricated nonsense." In a letter of complaint to ABC News, Singer said their piece used "prejudicial language, distorted facts, libelous insinuations, and anonymous smears."
On September 18, 2013, the NIPCC's fourth report, entitled "Climate Change Reconsidered II: Physical Science," was published. As with previous NIPCC reports, environmentalists criticized it upon its publication; for example, David Suzuki wrote that it was "full of long-discredited claims, including that carbon dioxide emissions are good because they stimulate life." After the report received favorable coverage from Fox News Channel's Doug McKelway, climate scientists Kevin Trenberth and Michael Oppenheimer criticized this coverage, with Trenberth calling it "irresponsible journalism" and Oppenheimer calling it "flat out wrong."
Climategate.
In December 2009, after the Climatic Research Unit email controversy, Singer wrote an opinion piece for Reuters in which he said the scientists had misused peer review, pressured editors to prevent publication of alternative views, and smeared opponents. He said the leaked e-mails showed that the "surface temperature data that IPCC relies on is based on distorted raw data and algorithms that they will not share with the science community." He argued that the incident exposed a flawed process, and that the temperature trends were heading downwards even as greenhouse gases like CO were increasing in the atmosphere. He wrote: "This negative correlation contradicts the results of the models that IPCC relies on and indicates that anthropogenic global warming (AGW) is quite small," concluding "and now it turns out that global warming might have been 'man made' after all." A British House of Commons Science and Technology Select Committee later issued a report that exonerated the scientists, 
and eight committees investigated the allegations, finding no evidence of fraud or scientific misconduct.

</doc>
<doc id="11736" url="https://en.wikipedia.org/wiki?curid=11736" title="Frederik Pohl">
Frederik Pohl

Frederik George Pohl, Jr. (; November 26, 1919 – September 2, 2013) was an American science fiction writer, editor and fan, with a career spanning more than seventy-five years—from his first published work, the 1937 poem "Elegy to a Dead Satellite: Luna", to the 2011 novel "All the Lives He Led" and articles and essays published in 2012.
From about 1959 until 1969, Pohl edited "Galaxy" and its sister magazine "If"; the latter won three successive annual Hugo Awards as the year's best professional magazine. His 1977 novel "Gateway" won four "year's best novel" awards: the Hugo voted by convention participants, the Locus voted by magazine subscribers, the Nebula voted by American science fiction writers, and the juried academic John W. Campbell Memorial Award. He won the Campbell Memorial Award again for the 1984 collection of novellas "Years of the City", one of two repeat winners during the first forty years. For his 1979 novel "Jem", Pohl won a U.S. National Book Award in the one-year category Science Fiction. It was a finalist for three other years' best novel awards. He won four Hugo and three Nebula Awards.
The Science Fiction Writers of America named Pohl its 12th recipient of the Damon Knight Memorial Grand Master Award in 1993 and he was inducted by the Science Fiction and Fantasy Hall of Fame in 1998, its third class of two dead and two living writers.
Pohl won the Hugo Award for Best Fan Writer in 2010, for his blog, "The Way the Future Blogs".
Early life and family.
Pohl was the son of Frederik George Pohl (a salesman of Germanic descent) and Anna Jane Mason. Pohl Sr. held various jobs, and the Pohls lived in such wide-flung locations as Texas, California, New Mexico and the Panama Canal Zone. The family settled in Brooklyn when Pohl was around seven.
He attended Brooklyn Technical High School, and dropped out at 17. In 2009, he was awarded an honorary diploma from Brooklyn Tech.
While a teenager, he co-founded the New York–based Futurians fan group, and began lifelong friendships with Donald Wollheim, Isaac Asimov and others who would become important writers and editors. Pohl later said that other "friends came and went and were gone, u many of the ones I met through fandom were friends all their lives – Isaac, Damon Knight, Cyril Kornbluth, Dirk Wylie, Dick Wilson. In fact, there are one or two – Jack Robins, Dave Kyle – whom I still count as friends, seventy-odd years later..." He published a science fiction fanzine called "Mind of Man."
During 1936, Pohl joined the Young Communist League because of its positions for unions and against racial prejudice, Adolf Hitler and Benito Mussolini. He became president of the local Flatbush III Branch of the YCL in Brooklyn. Pohl has said that after the Molotov–Ribbentrop Pact of 1939, the party line changed and he could no longer support it, at which point he left.
Pohl served in the United States Army from April 1943 until November 1945, rising to sergeant as an air corps weatherman. After training in Illinois, Oklahoma, and Colorado, he was mainly stationed in Italy with the 456th Bombardment Group.
Pohl was married five times. His first wife, Leslie Perri, was another Futurian; they were married in August 1940, and divorced in 1944. He then married Dorothy LesTina in Paris in August 1945 while both were serving in the military in Europe; the marriage ended in 1947. During 1948, he married Judith Merril; they had a daughter, Ann. Pohl and Merril divorced in 1952. In 1953, he married Carol M. Ulf Stanton, with whom he had three children and collaborated on several books; they separated in 1977 and were divorced in 1983. From 1984 until his death, Pohl was married to science-fiction expert and academic Elizabeth Anne Hull, PhD.
He fathered four children – Ann (m. Walter Weary), Frederik III (deceased), Frederik IV and Kathy. Grandchildren include Canadian writer Emily Pohl-Weary and chef Tobias Pohl-Weary.
From 1984 on, he lived in Palatine, Illinois, a suburb of Chicago. He was previously a resident of Middletown, New Jersey.
Career.
Early career.
Pohl began writing in the late 1930s, using pseudonyms for most of his early works. His first publication was the poem "Elegy to a Dead Satellite: Luna" under the name of Elton Andrews, in the October 1937 issue of "Amazing Stories", edited by T. O'Conor Sloane. His first story, the collaboration with C.M. Kornbluth "Before the Universe", appeared in 1940 under the pseudonym S.D. Gottesman.
Work as editor and agent.
From 1939 to 1943, Pohl was the editor of two pulp magazines, "Astonishing Stories" and "Super Science Stories". Stories by Pohl often appeared in these science fiction magazine, but never under his own name. Work written in collaboration with Cyril M. Kornbluth was credited to S. D. Gottesman or Scott Mariner; other collaborative work (with any combination of Kornbluth, Dirk Wylie or Robert A. W. Lownes) was credited to Paul Dennis Lavond. For Pohl's solo work, stories were credited to James MacCreigh (or, for one story only, Warren F. Howard.) Works by "Gottesman", "Lavond", and "MacCreigh" continued to appear in various science fiction pulp magazines throughout the 1940s.
In his autobiography, Pohl said that he stopped editing the two magazines at roughly the time of the German invasion of the Soviet Union in 1941.
Pohl started a career as a literary agent in 1937, but it was a sideline for him until after World War II, when he began doing it full-time. He ended up "representing more than half the successful writers in science fiction": For a short time, he was the only agent Isaac Asimov ever had, though his agency did not succeed financially, and he closed it down in the early 1950s.
Pohl co-founded the Hydra Club, a loose collection of science fiction professionals and fans which met during the late 1940s and 1950s.
From the early 1960s until 1969, Pohl served as editor of "Galaxy Science Fiction" and "Worlds of if" magazines, taking over after the ailing H. L. Gold could no longer continue working "around the end of 1960". Under his leadership, "if" won the Hugo Award for Best Professional Magazine for 1966, 1967 and 1968. Pohl hired Judy-Lynn del Rey as his assistant editor at "Galaxy" and "if". He also served as editor of "Worlds of Tomorrow" from its first issue in 1963 until it was merged into "if" in 1967.
In the mid-1970s, Pohl acquired and edited novels for Bantam Books, published as "Frederik Pohl Selections"; notable were Samuel R. Delany's "Dhalgren" and Joanna Russ's "The Female Man". He also edited a number of science fiction anthologies.
Later career.
After World War II, Pohl worked as an advertising copywriter and then as a copywriter and book editor for "Popular Science". Following the war, Pohl began publishing material under his own name, much in collaboration with his fellow Futurian, Cyril Kornbluth.
Though the pen-names of "Gottesman", "Lavond" and "MacCreigh" were retired by the early 1950s, Pohl still occasionally used pseudonyms, even after he began to publish work under his real name. These occasional pseudonyms, all of which date from the early 1950s to the early 1960s, included Charles Satterfield, Paul Flehr, Ernst Mason, Jordan Park (two collaborative novels with Kornbluth) and Edson McCann (one collaborative novel with Lester del Rey).
In the 1970s, Pohl reemerged as a novel writer in his own right, with books such as "Man Plus" and the "Heechee" series. He won back-to-back Nebula Awards with "Man Plus" in 1976 and "Gateway", the first "Heechee" novel, in 1977. In 1978, "Gateway" swept the other two major novel honors, also winning the Hugo Award for Best Novel and John W. Campbell Memorial Award for the best science-fiction novel. Two of his stories have also earned him Hugo Awards: "The Meeting" (with Kornbluth) tied in 1973 and "Fermi and Frost" won in 1986. Another award-winning novel is "Jem" (1980), winner of the National Book Award.
His works include not only science fiction, but also articles for "Playboy" and "Family Circle" magazines and nonfiction books. For a time, he was the official authority for "Encyclopædia Britannica" on the subject of Emperor Tiberius. (He wrote a book on the subject of Tiberius, as "Ernst Mason".)
Some of his short stories take a satirical look at consumerism and advertising in the 1950s and 1960s: "The Wizards of Pung's Corners", where flashy, over-complex military hardware proved useless against farmers with shotguns, and "The Tunnel under the World", where an entire community of seeming-humans is held captive by advertising researchers. ("The Wizards of Pung's Corners" was freely translated into Chinese and then freely translated back into English as "The Wizard-Masters of Peng-Shi Angle" in the first edition of "Pohlstars" (1984)).
Pohl's Law is either "No one is ever ready for anything" or "Nothing is so good that somebody, somewhere will not hate it".
He was a frequent guest on Long John Nebel's radio show from the 1950s to the early 1970s, and an international lecturer.
Starting in 1995, when the Theodore Sturgeon Memorial Award became a juried award, Pohl served first with James Gunn and Judith Merril, and since then with several others until retiring in 2013. Pohl was associated with Gunn since the 1940s, becoming involved in 1975 with what later became Gunn's Center for the Study of Science Fiction at the University of Kansas. There he presented many talks, recorded a discussion about "The Ideas in Science Fiction" in 1973 for the Literature of Science Fiction Lecture Series, and served the Intensive Institute on Science Fiction and Science Fiction Writing Workshop.
Pohl received the second annual J. W. Eaton Lifetime Achievement Award in Science Fiction from the University of California, Riverside Libraries at the 2009 Eaton Science Fiction Conference, "Extraordinary Voyages: Jules Verne and Beyond".
Pohl's work has been an influence on a wide variety of other science fiction writers, some of whom appear in the 2010 anthology, "Gateways: Original New Stories Inspired by Frederik Pohl", edited by Elizabeth Anne Hull.
Pohl's last novel, "All the Lives He Led", was released on April 12, 2011.
By the time of his death, he was working to finish a second volume of his autobiography "The Way the Future Was" (1979), along with an expanded version of the latter.
Collaborative work.
In addition to his solo writings, Pohl was also well known for his collaborations, beginning with his first published story. Before and following the war, Pohl did a series of collaborations with his friend Cyril Kornbluth, including a large number of short stories and several novels, among them "The Space Merchants," a dystopian satire of a world ruled by the advertising agencies.
In the mid-1950s he began a long-running collaboration with Jack Williamson, eventually resulting in ten collaborative novels over five decades.
Other collaborations included a novel with Lester Del Rey, "Preferred Risk" (1955). This novel was solicited for a contest by Galaxy–Simon & Schuster when the judges did not think any of the contest submissions were good enough to win their contest, it was published under the joint pseudonym "Edson McCann". He also collaborated with Thomas T. Thomas on a sequel to his award-winning novel "Man Plus."
He finished a novel begun by Arthur C. Clarke, "The Last Theorem", which was published on August 5, 2008.
Death.
Pohl went to the hospital in respiratory distress on the morning of September 2, 2013, and died that afternoon at the age of 93.

</doc>
<doc id="11740" url="https://en.wikipedia.org/wiki?curid=11740" title="Forrest J Ackerman">
Forrest J Ackerman

Forrest J Ackerman (born Forrest James Ackerman; November 24, 1916 – December 4, 2008) was an American magazine editor, science fiction writer and literary agent, a founder of science fiction fandom, a leading expert on science fiction and fantasy films, and acknowledged as the world's most avid collector of genre books and movie memorabilia. He was based in Los Angeles, California.
During his career as a literary agent, Ackerman represented such science fiction authors as Ray Bradbury, Isaac Asimov, A.E. Van Vogt, Curt Siodmak and L. Ron Hubbard. He was, for over seven decades, one of science fiction's staunchest spokesmen and promoters.
Ackerman was the editor and principal writer of the American magazine "Famous Monsters of Filmland", as well as an actor, from the 1950s into the 21st Century, and appears in at least two documentaries related to this period in popular culture: Director Michael R. MacDonald, and writer, Ian Johnston's "Famous Monster: Forrest J Ackerman", which premiered at the Egyptian Theatre in March, 2009, during the Forrest J Ackerman Tribute, writer and filmmaker Jason V Brock's "The Ackermonster Chronicles!", (a 2012 documentary about Ackerman) and "Charles Beaumont: The Life of Twilight Zones Magic Man", about the late author Charles Beaumont, a former client of The Ackerman Agency.
Also called "Forry," "The Ackermonster," "4e" and "4SJ," Ackerman was central to the formation, organization, and spread of science fiction fandom, and a key figure in the wider cultural perception of science fiction as a literary, art and film genre. Famous for his word play and neologisms, he coined the genre nickname "sci-fi". In 1953, he was voted "#1 Fan Personality" by the members of the World Science Fiction Society, a unique Hugo Award never granted to anyone else.
He was also among the first and most outspoken advocates of Esperanto in the science fiction community.
Early years.
Ackerman was born Forrest James Ackerman (though he would refer to himself from the early 1930s on as "Forrest J Ackerman" with no period after the middle initial), on November 24, 1916, in Los Angeles, to Carroll Cridland (née Wyman; 1883–1977) and William Schilling Ackerman (1892–1951). His father was from New York and his mother was from Ohio (the daughter of architect George Wyman); she was nine years older than William.
Ackerman attended the University of California at Berkeley for a year (1934–1935), then worked as a movie projectionist and at odd jobs with fan friends prior to spending three years in the U.S. Army after enlisting on August 15, 1942., where he rose to the rank of Staff Sergeant, held the position of editor of his base's newspaper, and passed his entire time in service at Fort MacArthur, California.
Career and fandom.
Ackerman saw his first "imagi-movie" in 1922 ("One Glorious Day"), purchased his first science fiction magazine, "Amazing Stories", in 1926, created The Boys' Scientifiction Club in 1930 ("girl-fans were as rare as unicorn's horns in those days"). He contributed to both of the first science fiction fanzines, "The Time Traveller", and the Science Fiction Magazine, published and edited by Shuster & Siegel of Superman fame, in 1932, and by 1933 had 127 correspondents around the world. His name was used for the character of the reporter in the original Superman story "The Reign of the Superman" in issue 3 of Science Fiction magazine. He was one of the early members of the Los Angeles Science Fantasy Society, and remained active in it for many decades.
He attended the 1st World Science Fiction Convention in 1939, where he wore the first "futuristicostume" (designed and created by Myrtle R. Douglas) and sparked fan costuming, the latest incarnation of which is cosplay. He attended every Worldcon but two thereafter during his lifetime. Ackerman invited Ray Bradbury to attend the Los Angeles Chapter of the Science Fiction League, then meeting weekly at Clifton's Cafeteria in downtown Los Angeles. The club changed its name to the Los Angeles Science Fantasy Society during the period it was meeting at the restaurant. (There never was a "Clifton’s Cafeteria Science Fiction Club.") Among the writers frequenting the club were Robert A. Heinlein, Emil Petaja, Fredric Brown, Henry Kuttner, Leigh Brackett, and Jack Williamson. Bradbury often attended meetings with his friend Ray Harryhausen; the two Rays had been introduced to each other by Ackerman. With $90 from Ackerman, Bradbury launched a fanzine, "Futuria Fantasia", in 1939.
Ackerman was an early member of the Los Angeles Chapter of the Science Fiction League, and became so active in and important to the club, that in essence he ran it, including after the name change the Los Angeles Science Fantasy Society, a prominent regional organization, as well as the National Fantasy Fan Federation (N3F).
Ackerman amassed an extremely large and complete collection of science fiction, fantasy and horror film memorabilia, which, until 2002, he maintained in a remarkable 18-room home and museum known as the "Son of Ackermansion." (The original Ackermansion where he lived from the early 1950s until the mid-1970s was at 915 S. Sherbourne Drive in Los Angeles; the site is now an apartment building.) This second house, in the Los Feliz district of Los Angeles, contained some 300,000 books and pieces of movie and science-fiction memorabilia. From 1951 to 2002, Ackerman entertained some 50,000 fans at open houses - including, on one such evening, a group of 186 fans and professionals, including astronaut Buzz Aldrin. Ackerman was a board member of the Seattle Science Fiction Museum and Hall of Fame, where many items of his collection are now displayed.
He knew most of the writers of science fiction in the first half of the twentieth-century. As a literary agent, he represented some 200 writers, and he served as agent of record for many long lost authors, thereby allowing their work to be reprinted in anthologies. He was Ed Wood's "illiterary" agent. Ackerman was credited with nurturing and even inspiring the careers of several early contemporaries like Ray Bradbury, Ray Harryhausen, Charles Beaumont, Marion Zimmer Bradley and L. Ron Hubbard. He kept all of the stories submitted to his magazine, even the ones he rejected; Stephen King has stated that Ackerman showed up to a King book signing with a copy of a story King had submitted for publication when he was 11.
Ackerman had 50 stories published, including collaborations with A. E. van Vogt, Francis Flagg, Robert A. W. Lowndes, Marion Zimmer Bradley, Donald Wollheim and Catherine Moore and the world's shortest – one letter of the alphabet. His stories have been translated into six languages. Ackerman named the sexy comic-book character Vampirella and wrote the origin story for the comic.
He also authored several lesbian stories under the name "Laurajean Ermayne" for Vice Versa and provided publishing assistance in the early days of the Daughters of Bilitis. He was dubbed an "honorary lesbian" at a DOB party.
Through his magazine, "Famous Monsters of Filmland" (1958–1983), Ackerman introduced the history of the science fiction, fantasy and horror film genres to a generation of young readers. At a time when most movie-related publications glorified the stars in front of the camera, "Uncle Forry", as he was referred to by many of his fans, promoted the behind-the-scenes artists involved in the magic of movies. In this way, Ackerman provided inspiration to many who would later become successful artists, including Joe Dante, Peter Jackson, Steven Spielberg, Tim Burton, Stephen King, Donald F. Glut, Penn & Teller, Billy Bob Thornton, Gene Simmons (of the band Kiss), Rick Baker, George Lucas, Danny Elfman, Frank Darabont, John Landis and countless other writers, directors, artists and craftsmen.
He also contributed to film magazines from all around the world, including Spanish speaking "" magazine, from Argentina, where he had a monthly column for over four years.
In the 1960s, Ackerman organized the publication of an English translation in the U.S. of the German science fiction series "Perry Rhodan", the longest science fiction series in history. These were published by Ace Books from 1969 through 1977. Ackerman's German-speaking wife Wendayne ("Wendy") did most of the translation. The American books were issued with varying frequency from one to as many as four per month. Ackerman also used the paperback series to promote science fiction short stories, including his own on occasion. These "magabooks" or "bookazines" also included a film review section, known as "Scientifilm World", and letters from readers. The American series came to an end when the management of Ace changed, and the new management decided that the series was too juvenile for their taste. The last Ace issue was #118, which corresponded to German issue #126 as some of the Ace editions contained two of the German issues, and three of the German issues had been skipped. Forry later published translations of German issues #127 through #145 on his own under the Master Publications imprint. (The original German series continues today and passed issue #2800 in 2015.)
Appearances in film, television and music.
A lifelong fan of science fiction "B-movies", Ackerman had cameos in over 210 films, including bit parts in many monster movies and science fiction films ("The Howling", "Innocent Blood", "Return of the Living Dead Part II"), more traditional "imagi-movies" "The Time Travelers", "Future War", spoofs and comedies ("Amazon Women on the Moon", "Attack of the 60 Foot Centerfold", "The Wizard of Speed and Time", "Curse of the Queerwolf"), and at least one major music video ("Michael Jackson's Thriller"). His Bacon number is 2.
In 1961, Ackerman narrated the record "Music for Robots" created by Frank Allison Coe. The cover featured Forrest Ackerman's face superimposed on the movie robot "Tobor the Great". The record was reissued on CD in 2005.
Ackerman himself appeared as a character in "The Vampire Affair" by David McDaniel (a novel in the "Man from U.N.C.L.E." series), and Philip José Farmer's novel "Blown". A character based on Ackerman, and his "Ackermansion", appears in the Niven/Pournelle/Flynn collaboration "Fallen Angels". Another character, Eccar the Man, is mentioned in the Niven/Gerrold collaboration "The Flying Sorcerers".
He appeared on the intro track of Ohio horror punk music group Manimals' 1999 album "Horrorcore".
In 2001 Ackerman played the part of an old wax museum caretaker in the camp comedy film "The Double-D Avenger" directed by William Winckler and starring Russ Meyer stars Kitten Natividad, Haji, and Raven De La Croix. Ackerman played a crazy old man who was in love with Kitten Natividad's character, The Double-D Avenger, and he also talked to the Frankenstein figure and other wax monsters in the museum's chamber of horrors.
Ackerman appeared extensively on-screen discussing his life and the history of science fiction fandom in the 2006 documentary film "Finding the Future".
In 2007, Roadhouse Films of Canada released a documentary, "Famous Monster: Forrest J Ackerman". The documentary, available on DVD only in the UK, airs regularly on the BRAVO channel.
In the 2012 action film "Premium Rush", the character of the corrupt policeman Bobby Monday (played by Michael Shannon) repeatedly uses the alias "Forrest J. Ackerman".
Personal life.
Ackerman was married to a German-born teacher and translator, Mathilda Wahrman (1912–1990), whom he met in the early 1950s while she was working in a book store he happened to visit. He eventually dubbed her "Wendayne" or, less formally, "Wendy", by which name she became most generally known within SF and film fandoms, after the character in Peter Pan, his favorite fantasy. Although they went through a period of separation during the late 1950s and early 1960s, they remained officially married until her death: she suffered serious internal injuries when she was violently mugged while visiting Italy in 1990, and irreparable damage to her kidneys led to her death. They had no children of their own by choice, but Wahrman did have a son by an earlier marriage, Michael Porges, who did not get along with Ackerman and would not live in Ackerman's home.
Ackerman was fluent in the international language Esperanto, and claimed to have walked down Hollywood Boulevard arm-in-arm with Leo G. Carroll singing "La Espero", the hymn of Esperanto.
Ackerman was an atheist but did not emphasize that fact in his public life, and welcomed people of all faiths as well as no faith into his home and personal circle equally.
His first public stance on any political issue was in opposition to the Vietnam War.
Death.
In 2003, Ackerman said, "I aim at hitting 100 and becoming the George Burns of science fiction". His health, however, had been failing. He was susceptible to infection in his later life and, after one final trip to the hospital in October 2008, informed his best friend and caregiver Joe Moe that he didn't want to go on. Honoring his wishes, his friends brought him home to hospice care. However, it turned out that in order to get Ackerman home, the hospital had cured his infection with antibiotics. So Ackerman went on for a few more weeks holding what he delighted in calling "a living funeral". In his final days he saw everyone he wanted to say good-bye to. Fans were encouraged to send messages of farewell by mail.
While there were several premature reports of his death in the month prior, Ackerman died a minute before midnight on December 4, 2008, at the age of 92. From his "Acker-mini-mansion" in Hollywood, he had entertained and inspired fans weekly with his collection of memorabilia and his stories.
Ackerman is interred at Forest Lawn Memorial Park (Glendale) with his wife. His plaque simply reads, "Sci-Fi Was My High."
A 2013 rebroadcast of the PBS program "Visiting... with Huell Howser," originally airing in 2000, which featured Ackerman and highlighted his memorabilia collection, was revised to indicate that Ackerman had since died and his collection had been auctioned off.

</doc>
<doc id="11741" url="https://en.wikipedia.org/wiki?curid=11741" title="Fantasy film">
Fantasy film

Fantasy films are films that belong to the fantasy genre with fantastic themes, usually involving magic, supernatural events, mythology, folklore, or exotic fantasy worlds. The genre is considered a form of speculative fiction alongside science fiction films and horror films, although the genres do overlap. Fantasy films often have an element of magic, myth, wonder, escapism, and the extraordinary.
Subgenres.
Several sub-categories of fantasy films can be identified, although the delineations between these subgenres, much as in fantasy literature, are somewhat fluid.
The most common fantasy subgenres depicted in movies are High Fantasy and Sword and Sorcery. Both categories typically employ quasi-medieval settings, wizards, magical creatures and other elements commonly associated with fantasy stories.
High Fantasy films tend to feature a more richly developed fantasy world, and may also be more character-oriented or thematically complex. Often, they feature a hero of humble origins and a clear distinction between good and evil set against each other in an epic struggle. Many scholars cite J. R. R. Tolkien's "The Lord of the Rings" novel as the prototypical modern example of High Fantasy in literature, and the recent Peter Jackson film adaptation of the books is a good example of the High Fantasy subgenre on the silver screen.
Sword and Sorcery movies tend to be more plot-driven than high fantasy and focus heavily on action sequences, often pitting a physically powerful but unsophisticated warrior against an evil wizard or other supernaturally endowed enemy. Although Sword and Sorcery films sometimes describe an epic battle between good and evil similar to those found in many High Fantasy movies, they may alternately present the hero as having more immediate motivations, such as the need to protect a vulnerable maiden or village, or even being driven by the desire for vengeance.
The 1982 film adaptation of Robert E. Howard's "Conan the Barbarian", for example, is a personal (non-epic) story concerning the hero's quest for revenge and his efforts to thwart a single megalomaniac—while saving a beautiful princess in the process. Some critics refer to such films by the term Sword and Sandal rather than Sword and Sorcery, although others would maintain that the Sword and Sandal label should be reserved only for the subset of fantasy films set in ancient times on the planet Earth, and still others would broaden the term to encompass films that have no fantastic elements whatsoever. To some, the term Sword and Sandal has pejorative connotations, designating a film with a low-quality script, bad acting and poor production values.
Another important subgenre of fantasy films that has become more popular in recent years is contemporary fantasy. Such films feature magical effects or supernatural occurrences happening in the "real" world of today.
Films with live action and animation such as Disney's "Mary Poppins", "Pete's Dragon", "Enchanted" and the Robert Zemeckis film "Who Framed Roger Rabbit" are also fantasy films although are more often referred to as Live action/animation hybrids (2 of those are also classified as a musicals).
Fantasy films set in the afterlife, called Bangsian Fantasy, are less common, although films such as the 1991 Albert Brooks comedy "Defending Your Life" would likely qualify. Other uncommon subgenres include Historical Fantasy and Romantic Fantasy, although 2003's "" successfully incorporated elements of both.
As noted above, superhero movies and fairy tale films might each be considered subgenres of fantasy films, although most would classify them as altogether separate movie genres.
Fantasy movies and the film industry.
As a cinematic genre, fantasy has traditionally not been regarded as highly as the related genre of science fiction film. Undoubtedly, the fact that until recently fantasy films often suffered from the "Sword and Sandal" afflictions of inferior production values, over-the-top acting and decidedly poor special effects was a significant factor in fantasy film's low regard.
Since the late 1990s, however, the genre has gained new respectability in a way, driven principally by the successful adaptations of J.R.R. Tolkien's "The Lord of the Rings" and J.K. Rowling's "Harry Potter" series. Jackson's "The Lord of the Rings" trilogy is notable due to its ambitious scope, serious tone and thematic complexity. These pictures achieved phenomenal commercial and critical success, and the of the trilogy became the first fantasy film ever to win the Academy Award for Best Picture. The Harry Potter series has been a tremendous financial success, has achieved critical acclaim, and boasts an enormous and loyal fanbase.
Following the success of these ventures, Hollywood studios have greenlighted additional big-budget productions in the genre. These have included adaptations of the first, second, and third books in C. S. Lewis' "The Chronicles of Narnia" series and the teen novel "Eragon", as well as adaptations of Susan Cooper's "The Dark Is Rising", Cornelia Funke's "Inkheart", Philip Pullman's "The Golden Compass", Holly Black's "The Spiderwick Chronicles", Nickolodeon's TV show "" and the "Fantasia" segment (along with Johann Wolfgang von Goethe's original poem) "The Sorcerer's Apprentice"
Fantasy movies in recent years, such as the "Lord of the Rings" films, the first and third "Narnia" adaptations, and the first second, fourth and seventh "Harry Potter" adaptations have most often been released in November and December. This is in contrast to science fiction films, which are often released during the northern hemisphere summer (June - August). All 3 installments of the "Pirates of the Caribbean" fantasy films, however, were released in July 2003, July 2006 and May 2007 respectively, and the latest releases in the "Harry Potter" series were released in July, 2007 and July 2009. The huge commercial success of these pictures may indicate a change in Hollywood's approach to big-budget fantasy film releases.
History.
Fantasy films have a history almost as old as the medium itself. However, fantasy films were relatively few and far between until the 1980s, when high-tech filmmaking techniques and increased audience interest caused the genre to flourish.
What follows are some notable Fantasy films. For a more complete list see: List of fantasy films
1900-1920s.
In the era of silent film the earliest fantasy films were those made by French film pioneer Georges Méliès from 1903. The most famous of these was 1902's "A Trip to the Moon". In the Golden Age of Silent film (1918–1926) the most outstanding fantasy films were Douglas Fairbanks' "The Thief of Bagdad" (1924) and Fritz Lang's "Die Nibelungen" (1924) and "Destiny" (1921). other notables in the genre were F.W. Murnau's romantic ghost story "Phantom", "Tarzan of the Apes" starring Elmo Lincoln, and D. W. Griffith's "The Sorrows of Satan".
1930s.
Following the advent of sound films, audiences of all ages were introduced to 1939's "The Wizard of Oz". Also notable of the era, the iconic 1933 film "King Kong" borrows heavily from the Lost World subgenre of fantasy fiction as does such films as the 1935 adaption of H. Rider Haggard's novel "She" about an African expedition that discovers an immortal queen known as Ayesha "She who must be obeyed". Frank Capra's 1937 picture "Lost Horizon" transported audiences to the Himalayan fantasy kingdom of Shangri-La, where the residents magically never age. Other noteworthy fantasy film of the 30s include "Tarzan the Ape Man" in 1932 starring Johnny Weissmuller starting a successful series of talking pictures based on the fantasy-adventure novels by Edgar Rice Burroughs and the G. W. Pabst directed "The Mistress of Atlantis" from 1932. 1932 saw the release of the Universal Studios monster movie "The Mummy" which combined horror with a romantic fantasy twist. more light-hearted and comedic affairs from the decade include films like 1934s romantic drama film Death Takes a Holiday where Fredric March plays Death who takes a human body to experience life for three days, and 1937s "Topper" where a man is haunted by two fun loving ghosts who try to make his life a little more exciting.
1940s.
The 1940s then saw several full color fantasy films produced by Alexander Korda, including "The Thief of Bagdad" (1940), a film on par with "The Wizard of Oz", and "Jungle Book" (1942). In 1946, Jean Cocteau's classic adaptation of "Beauty and the Beast" won praise for its surreal elements and for transcending the boundaries of the fairy tale genre. "Sinbad the Sailor" (1947), starring Douglas Fairbanks, Jr., has the feel of a fantasy film though it does not actually have any fantastic elements. Conversely, "It's a Wonderful Life" and "A Matter of Life and Death", both from 1946, do not feel like fantasy films yet both feature supernatural elements and the latter movie could reasonably be cited as an example of Bangsian fantasy.
Several other pictures featuring supernatural encounters and aspects of Bangsian fantasy were produced in the 1940s during World War II. These include "Beyond Tomorrow", "The Devil and Daniel Webster", and "Here Comes Mr. Jordan", all from 1941, "Heaven Can Wait" the musical "Cabin in the Sky" (1943), the comedy "The Horn Blows at Midnight" and romances such as "The Ghost and Mrs. Muir" (1947), "One Touch of Venus" and "Portrait of Jennie", both 1948.
Although it's not classified as a fantasy film, Gene Kelly's "Anchors Aweigh" had a fantasy sequence called "The King who Couldn't Dance" in which Gene did a song and dance number with Jerry Mouse from Tom and Jerry.
Because these movies do not feature elements common to high fantasy or sword and sorcery pictures, some modern critics do not consider them to be examples of the fantasy genre.
1950s.
In the 1950s there were a few major fantasy films, including "Darby O'Gill and the Little People" and "The 5000 Fingers of Dr. T", the latter penned by Dr. Seuss. Jean Cocteau's Orphic Trilogy, begun in 1930 and completed in 1959, is based on Greek mythology and could be classified either as fantasy or surrealist film, depending on how the boundaries between these genres are drawn. Russian fantasy director Aleksandr Ptushko created three mythological epics from Russian fairytales, "Sadko" (1953), "Ilya Muromets" (1956), and "Sampo" (1959). Japanese director Kenji Mizoguchi's 1953 film "Ugetsu Monogatari" draws on Japanese classical ghost stories of love and betrayal.
Other notable pictures from the 1950s that feature fantastic elements and are sometimes classified as fantasy are: "Harvey" (1950), featuring a púca of Celtic mythology; "Scrooge", the 1951 adaptation of Charles Dickens' "A Christmas Carol"; and Ingmar Bergman's 1957 masterpiece, "The Seventh Seal". Disney's 1951 animated film "Alice in Wonderland" is also a fantasy classic.
There were also a number of lower budget fantasies produced in the 1950s, typically based on Greek or Arabian legend. The most notable of these may be 1958's "The 7th Voyage of Sinbad", featuring special effects by Ray Harryhausen and music by Bernard Herrmann.
1960s.
Harryhausen worked on a series of fantasy films in the 1960s, most importantly "Jason and the Argonauts" (1963). Many critics have identified this film as Harryhausen's masterwork for its stop-motion animated statues, skeletons, harpies, hydra, and other mythological creatures. Other Harryhausen fantasy and science fantasy collaborations from the decade include the 1961 adaptation of Jules Verne's "Mysterious Island", the critically panned "One Million Years B.C." starring Raquel Welch, and "The Valley of Gwangi" (1969).
Capitalising on the success of the sword and sandal genre several Italian B-movies based on classical myth were made, including the "Maciste" series. Otherwise, the 1960s were almost entirely devoid of fantasy films. The fantasy picture "7 Faces of Dr. Lao", in which Tony Randall portrayed several characters from Greek mythology, was released in 1964. But the 1967 adaptation of the Broadway musical "Camelot" removed most of the fantasy elements from T. H. White's classic "The Once and Future King", on which the musical had been based. The 1960s also saw a new adaption of Haggard's "She" in 1965 starring Ursula Andress as the immortal "She who must be obeyed" and was followed by a sequel in 1968 "The Vengeance of She" based loosely on the novel both produced by Hammer Film Productions, 1968 also saw the release of "Chitty Chitty Bang Bang" based on a story by Ian Fleming with a script from Roald Dahl.
1970s.
Fantasy elements of Arthurian legend were again featured, albeit absurdly, in 1975's "Monty Python and the Holy Grail". Harryhausen also returned to the silver screen in the 1970s with two additional "Sinbad" fantasies, "The Golden Voyage of Sinbad" (1974) and "Sinbad and the Eye of the Tiger" (1977). The animated movie "Wizards" (1977) had limited success at the box office but achieved status as a cult film. There was also "The Noah" (1975) which was never released theatrically but became a cult favorite when it was finally released on DVD in 2006. Some would consider 1977's "Oh God!", starring George Burns to be a fantasy film, and "Heaven Can Wait" (1978) was a successful Bangsian fantasy remake of 1941's "Here Comes Mr. Jordan" (not 1943's "Heaven Can Wait").
A few low budget "Lost World" pictures were made in the 1970s, such as 1975's "The Land That Time Forgot". Otherwise, the fantasy genre was largely absent from mainstream movies in this decade, although 1971's "Bedknobs and Broomsticks" and "Willy Wonka & the Chocolate Factory" were two fantasy pictures in the public eye the former being predominantly from the same team who did "Mary Poppins" the latter again being from Roald Dahl in both script and novel.
1980s.
\ Arthurian lore returned to the screen in John Boorman's 1981 "Excalibur", while films such as Ridley Scott's 1985 "Legend" and Terry Gilliam's 1981–1986 trilogy of fantasy epics ("Time Bandits", "Brazil", and "The Adventures of Baron Munchausen") explored a new artist-driven style featuring surrealist imagery and thought-provoking plots. The modern sword and sorcery boom began around the same time with 1982's "Conan the Barbarian" followed by "Krull" and "Fire and Ice" in 1983, as well as a boom in fairy tale-like fantasy films such as "Ladyhawke" (1985), "The Princess Bride" (1987), and "Willow" (1988).
The 80s also started a trend in mixing modern settings and action movie effects with exotic fantasy-like concepts. "Big Trouble in Little China" (1986), directed by John Carpenter and starring Kurt Russell, combined humor, martial arts and classic Chinese folklore in a modern Chinatown setting. "Highlander", a film about immortal Scottish swordsmen, was released the same year.
Jim Henson produced two iconic fantasy films in the 80s, the solemn "The Dark Crystal" and the more whimsical and lofty "Labyrinth". Meanwhile, Robert Zemeckis helmed "Who Framed Roger Rabbit", featuring various famous cartoon characters from animation's "Golden Age," including Mickey Mouse, Minnie Mouse, Donald Duck, Bugs Bunny, Daffy Duck, Droopy, Wile E. Coyote and Road Runner, Sylvester the Cat, Tweety Pie and Jiminy Cricket, among others.

</doc>
<doc id="11742" url="https://en.wikipedia.org/wiki?curid=11742" title="Finite set">
Finite set

In mathematics, a finite set is a set that has a finite number of elements. For example,
is a finite set with five elements. The number of elements of a finite set is a natural number (a non-negative integer) and is called the cardinality of the set. A set that is not finite is called infinite. For example, the set of all positive integers is infinite:
Finite sets are particularly important in combinatorics, the mathematical study of counting. Many arguments involving finite sets rely on the pigeonhole principle, which states that there cannot exist an injective function from a larger finite set to a smaller finite set.
Definition and terminology.
Formally, a set is called finite if there exists a bijection
for some natural number . The number is the set's cardinality, denoted as ||. The empty set {} or Ø is considered finite, with cardinality zero.
If a set is finite, its elements may be written — in many ways — in a sequence:
In combinatorics, a finite set with elements is sometimes called an "-set" and a subset with elements is called a "-subset". For example, the set {5,6,7} is a 3-set – a finite set with three elements – and {6,7} is a 2-subset of it.
Basic properties.
Any proper subset of a finite set "S" is finite and has fewer elements than "S" itself. As a consequence, there cannot exist a bijection between a finite set "S" and a proper subset of "S". Any set with this property is called Dedekind-finite. Using the standard ZFC axioms for set theory, every Dedekind-finite set is also finite, but this requires at least the axiom of countable choice.
Any injective function between two finite sets of the same cardinality is also a surjective function (a surjection). Similarly, any surjection between two finite sets of the same cardinality is also an injection.
The union of two finite sets is finite, with
In fact:
More generally, the union of any finite number of finite sets is finite. The Cartesian product of finite sets is also finite, with:
Similarly, the Cartesian product of finitely many finite sets is finite. A finite set with "n" elements has 2 distinct subsets. That is, the
power set of a finite set is finite, with cardinality 2.
Any subset of a finite set is finite. The set of values of a function when applied to elements of a finite set is finite.
All finite sets are countable, but not all countable sets are finite. (Some authors, however, use "countable" to mean "countably infinite", so do not consider finite sets to be countable.)
The free semilattice over a finite set is the set of its non-empty subsets, with the join operation being given by set union.
Necessary and sufficient conditions for finiteness.
In Zermelo–Fraenkel set theory without the axiom of choice (ZF), the following conditions are all equivalent:
If the axiom of choice is also assumed (the axiom of countable choice is sufficient), then the following conditions are all equivalent:
Foundational issues.
Georg Cantor initiated his theory of sets in order to provide a mathematical treatment of infinite sets. Thus the distinction between the finite and the infinite lies at the core of set theory. Certain foundationalists, the strict finitists, reject the existence of infinite sets and thus advocate a mathematics based solely on finite sets. Mainstream mathematicians consider strict finitism too confining, but acknowledge its relative consistency: the universe of hereditarily finite sets constitutes a model of Zermelo–Fraenkel set theory with the axiom of infinity replaced by its negation.
Even for those mathematicians who embrace infinite sets, in certain important contexts, the formal distinction between the finite and the infinite can remain a delicate matter. The difficulty stems from Gödel's incompleteness theorems. One can interpret the theory of hereditarily finite sets within Peano arithmetic (and certainly also vice versa), so the incompleteness of the theory of Peano arithmetic implies that of the theory of hereditarily finite sets. In particular, there exists a plethora of so-called non-standard models of both theories. A seeming paradox, non-standard models of the theory of hereditarily finite sets contain infinite sets --- but these infinite sets look finite from within the model. (This can happen when the model lacks the sets or functions necessary to witness the infinitude of these sets.) On account of the incompleteness theorems, no first-order predicate, nor even any recursive scheme of first-order predicates, can characterize the standard part of all such models. So, at least from the point of view of first-order logic, one can only hope to characterize finiteness approximately.
More generally, informal notions like set, and particularly finite set, may receive interpretations across a range of formal systems varying in their axiomatics and logical apparatus. The best known axiomatic set theories include Zermelo-Fraenkel set theory (ZF), Zermelo-Fraenkel set theory with the Axiom of Choice (ZFC), Von Neumann–Bernays–Gödel set theory (NBG), Non-well-founded set theory, Bertrand Russell's Type theory and all the theories of their various models. One may also choose among classical first-order logic, various higher-order logics and intuitionistic logic.
A formalist might see the meaning of "set" varying from system to system. A Platonist might view particular formal systems as approximating an underlying reality.
Set-theoretic definitions of finiteness.
In contexts where the notion of natural number sits logically prior to any notion of set, one can define a set "S" as finite if "S" admits a bijection to some set of natural numbers of the form formula_8. Mathematicians more typically choose to ground notions of number in set theory, for example they might model natural numbers by the order types of finite well-ordered sets. Such an approach requires a structural definition of finiteness that does not depend on natural numbers.
Interestingly, various properties that single out the finite sets among all sets in the theory ZFC turn out logically inequivalent in weaker systems such as ZF or intuitionistic set theories. Two definitions feature prominently in the literature, one due to Richard Dedekind, the other to Kazimierz Kuratowski. (Kuratowski's is the definition used above.)
A set "S" is called Dedekind infinite if there exists an injective, non-surjective function formula_9. Such a function exhibits a bijection between "S" and a proper subset of "S", namely the image of "f". Given a Dedekind infinite set "S", a function "f", and an element "x" that is not in the image of "f", we can form an infinite sequence of distinct elements of "S", namely formula_10. Conversely, given a sequence in "S" consisting of distinct elements formula_11, we can define a function "f" such that on elements in the sequence formula_12 and "f" behaves like the identity function otherwise. Thus Dedekind infinite sets contain subsets that correspond bijectively with the natural numbers. Dedekind finite naturally means that every injective self-map is also surjective.
Kuratowski finiteness is defined as follows. Given any set "S", the binary operation of union endows the powerset "P(S)" with the structure of a semi-lattice. Writing "K(S)" for the sub-semi-lattice generated by the empty set and the singletons, call set "S" Kuratowski finite if "S" itself belongs to "K(S)". Intuitively, "K(S)" consists of the finite subsets of "S". Crucially, one does not need induction, recursion or a definition of natural numbers to define "generated by" since one may obtain "K(S)" simply by taking the intersection of all sub-semi-lattices containing the empty set and the singletons.
Readers unfamiliar with semi-lattices and other notions of abstract algebra may prefer an entirely elementary formulation. Kuratowski finite means "S" lies in the set "K(S)", constructed as follows. Write "M" for the set of all subsets "X" of P("S") such that:
Then "K(S)" may be defined as the intersection of "M".
In ZF, Kuratowski finite implies Dedekind finite, but not vice versa. In the parlance of a popular pedagogical formulation, when the axiom of choice fails badly, one may have an infinite family of socks with no way to choose one sock from more than finitely many of the pairs. That would make the set of such socks Dedekind finite: there can be no infinite sequence of socks, because such a sequence would allow a choice of one sock for infinitely many pairs by choosing the first sock in the sequence. However, Kuratowski finiteness would fail for the same set of socks.
Other concepts of finiteness.
In ZF set theory without the axiom of choice, the following concepts of finiteness for a set "S" are distinct. They are arranged in strictly decreasing order of strength. In other words, if a set "S" meets one of the criteria in this list, it meets all of the criteria which follow that one. In the absence of the axiom of choice, the reverse implications are all unprovable. If the axiom of choice is assumed, then all of these concepts are equivalent. (Note that none of these definitions need the set of finite ordinal numbers to be defined first. They are all pure "set-theoretic" definitions in terms of the equality and element-of relations, not involving ω.)
The forward implications (from strong to weak) are theorems within ZF. Counter-examples to the reverse implications (from weak to strong) are found using model theory.
Most of these finiteness definitions and their names are attributed to by . However, definitions I, II, III, IV and V were presented in , together with proofs (or references to proofs) for the forward implications. At that time, model theory was not sufficiently advanced to find the counter-examples.

</doc>
<doc id="11745" url="https://en.wikipedia.org/wiki?curid=11745" title="Farmer Giles of Ham">
Farmer Giles of Ham

"Farmer Giles of Ham" is a comic Medieval fable written by J. R. R. Tolkien in 1937 and published in 1949. The story describes the encounters between Farmer Giles and a wily dragon named Chrysophylax, and how Giles manages to use these to rise from humble beginnings to rival the king of the land. It is cheerfully anachronistic and light-hearted, set in Britain in an imaginary period of the Dark Ages, and featuring mythical creatures, medieval knights, and primitive firearms. It is only tangentially connected with the author's Middle-earth legendarium: both were originally intended as essays in "English mythology".
The book was originally illustrated by Pauline Baynes. The story has appeared with other works by Tolkien in omnibus editions, including "The Tolkien Reader" and "Tales from the Perilous Realm".
Plot summary.
Farmer Giles ("Ægidius Ahenobarbus Julius Agricola de Hammo", "Giles Bronze-beard Julius Farmer of Ham") is not a hero. He is fat and red-bearded and enjoys a slow, comfortable life. But a rather deaf and short-sighted giant blunders on to his land, and Giles manages to ward him away with a blunderbuss shot in his general direction. The people of the village cheer: Farmer Giles has become a hero. His reputation spreads across the kingdom, and he is rewarded by the King with a sword named Caudimordax ("Tailbiter")—which turns out to be a powerful weapon against dragons.
The giant, on returning home, relates to his friends that there are no more knights in the Middle Kingdom, just stinging flies—actually the scrap metal shot from the blunderbuss—and this entices a dragon, Chrysophylax Dives, to investigate the area. The terrified neighbours all expect the accidental hero Farmer Giles to deal with him.
The story parodies the great dragon-slaying traditions. The knights sent by the King to pursue the dragon are useless fops, more intent on "precedence and etiquette" than on the huge dragon footprints littering the landscape. The only part of a 'dragon' they know is the annual celebratory dragon-tail cake. Giles by contrast clearly recognises the danger, and resents being sent along to face it. But hapless farmers can be forced to become heroes, and Giles shrewdly makes the best of the situation.
It has been suggested that the Middle Kingdom is based on early Mercia, and that Giles's break-away realm (the Little Kingdom) is based on Frithuwald's Surrey.
Philological humour.
Tolkien, himself a philologist, sprinkled several philological jokes into the tale, including a variety of ingeniously fake etymologies. Almost all the place-names are supposed to occur relatively close to Oxford, along the Thames, or along the route to London. At the end of the story, Giles is made Lord of Tame, and Count of Worminghall. The village of Oakley, burnt to the ground by the dragon early in the story, may also be named after Oakley, Buckinghamshire, near to Thame.
Tolkien insists, tongue in cheek, that the village of Thame originally referred to the Tame Dragon housed in it, and that "tame with an h is a folly without warrant." Another joke puts a question concerning the definition of blunderbuss to "the four wise clerks of Oxenford" (a reference to Chaucer's Clerk; Tolkien had worked for Henry Bradley, one of the four main editors of the "Oxford English Dictionary"):
A short gun with a large bore firing many balls or slugs, and capable of doing execution within a limited range without exact aim. (Now superseded, in civilised countries, by other firearms.)
and then satirises it with application to the situation at hand:
However, Farmer Giles's blunderbuss had a wide mouth that opened like a horn, and it did not fire balls or slugs, but anything that he could spare to stuff in. And it did not do execution, because he seldom loaded it, and never let it off. The sight of it was usually enough for his purpose. And this country was not yet civilised, for the blunderbuss was not superseded: it was indeed the only kind of gun that there was, and rare at that. 
As Tom Shippey points out: "Giles's blunderbuss ... defies the definition and works just the same." (Introduction to "Tales from the Perilous Realm").
Chrysophylax Dives.
Chrysophylax Dives is a comically villainous dragon. He stands midway between Smaug, evil and greedy, and The Reluctant Dragon, comical and timid. "Chrysophylax" (Χρυσοφύλαξ) is Greek for "gold-guard" and "dīves" is Latin for "rich". (The classical pronunciation is ).
Chrysophylax comes across as a pompous aristocrat—rich, vain, and arrogant, but capable of compromise if handled correctly. Farmer Giles learns that he can be bullied, but is smart enough not to push him to desperation.
Caudimordax.
Caudimordax is the Latin name of "Tailbiter", the sword of Farmer Giles. The sword cannot be sheathed when a dragon comes within five miles of its bearer's presence. Four generations earlier, the sword belonged to Bellomarius, "the greatest of all the dragon-slayers" in the Middle Kingdom. Farmer Giles is granted this antiquated sword—by then become unfashionable—as a reward for driving off a giant from his fields with his blunderbuss. He later uses the sword to capture and control the dragon.
Garm.
Garm is the talking dog in J.R.R. Tolkien's short story Farmer Giles of Ham. The dog is both vain of his master and cowardly. The name is derived from the Norse mythological dog of the same name, Garm.
Pauline Baynes drew Garm as a Greyhound, but Alan Lee drew him as a Mastiff.
Tales from the Perilous Realm.
This 2008 reprint:
50th Anniversary Edition.
This special edition was published in 1999 to celebrate the Golden Anniversary of this classic. The publisher in the USA is Houghton Mifflin. The edition includes:

</doc>
<doc id="11748" url="https://en.wikipedia.org/wiki?curid=11748" title="List of freshwater aquarium fish species">
List of freshwater aquarium fish species

A vast number of aquatic species have successfully adapted to live in the freshwater aquarium. This list gives some examples of the most common species found in home aquariums.

</doc>
<doc id="11749" url="https://en.wikipedia.org/wiki?curid=11749" title="List of chess players">
List of chess players

This list of chess players includes people who are primarily known as chess players and have an article on the English Wikipedia.
Famous people connected with chess.
The people in this list are famous in other areas of activity, but are known to have played chess, or have declared an interest in the game, or created works of art and literature in which the game is prominently featured.

</doc>
<doc id="11751" url="https://en.wikipedia.org/wiki?curid=11751" title="Foresight Institute">
Foresight Institute

The Foresight Institute is a Palo Alto, California-based nonprofit organization for promoting transformative technologies. They sponsor conferences on molecular nanotechnology, publish reports, and produce a newsletter.
The Foresight Institute has several running prizes, including the annual Feynman Prizes given in experimental and theory categories, and the $250,000 Feynman Grand Prize for demonstrating two molecular machines capable of nanoscale positional accuracy and computation.
History.
The Institute was founded in 1986 by Christine Peterson, who serves on the Board of Directors, and K. Eric Drexler, who is no longer with the Institute.
Two sister organizations were formed: the Institute for Molecular Manufacturing and the Center for Constitutional Issues in Technology.
Foresight Institute was founded "to guide emerging technologies to improve the human condition" but focused "its efforts upon nanotechnology, the coming ability to build materials and products with atomic precision, and upon systems that will enhance knowledge exchange and critical discussion". In May 2005, the Foresight Institute changed its name to "Foresight Nanotech Institute" and narrowed its mission to "ensure beneficial implementation of nanotechnology. Foresight is accomplishing this by providing balanced, accurate and timely information to help society understand and utilize nanotechnology through public policy activities, publications, guidelines, networking events, tutorials, conferences, roadmaps and prizes."
In June 2009, the institute reverted to its original name, and broadened its mission to "studying transformative technologies".
Mission.
The mission of Foresight is to promote the development and beneficial use of nanotechnologies and to reduce the potential for misuse and accidents associated with them. Foresight is committed to promoting the use of nanotechnology to provide renewable clean energy, supply clean water, improve health and longevity, heal and preserve the environment, make information technology available to all, and to enable space settlement.

</doc>
<doc id="11752" url="https://en.wikipedia.org/wiki?curid=11752" title="List of freshwater aquarium invertebrate species">
List of freshwater aquarium invertebrate species

This is a list of invertebrates, animals without a backbone, that are commonly kept in freshwater aquaria by hobby aquarists. Numerous shrimp species of various kinds, crayfish, a number of freshwater snail species, and at least one freshwater clam species are found in freshwater aquaria.

</doc>
<doc id="11753" url="https://en.wikipedia.org/wiki?curid=11753" title="List of freshwater aquarium plant species">
List of freshwater aquarium plant species

Aquatic plants are used to give the freshwater aquarium a natural appearance, oxygenate the water, and provide habitat for fish, especially fry (babies) and for invertebrates. Some aquarium fish and invertebrates also eat live plants. Hobbyists use aquatic plants for aquascaping, of several aesthetic styles.
Most of these plant species are found either partially or fully submersed in their natural habitat. Although there are a handful of obligate aquatic plants that must be grown entirely under water, most can grow fully emersed if the soil is moist.
Listed alphabetically by scientific name.
The taxonomy of most plant genera is not final. Scientific names listed here may therefore contradict other sources.
Common aquarium plant species:
False aquatics or pseudo-aquarium plants.
Several species of terrestrial plants are frequently sold as "aquarium plants". While such plants are beautiful and can survive and even flourish for months under water, they will eventually die and must be removed so their decay does not contaminate the aquarium water.

</doc>
<doc id="11754" url="https://en.wikipedia.org/wiki?curid=11754" title="Fonni">
Fonni

Fonni () is a town and "comune" in Sardinia, in the province of Nuoro (Italy).
It is the highest town in Sardinia, and situated among fine scenery with some chestnut woods. Fonni is a winter sports centre with a ski lift to Monte Spada and Bruncu Spina.
Etymology.
The term "Fonni" probably derives from the Latin "fons", meaning "fountain" or "god of the sources". In fact the village contains numerous spring water fountains.
Main sights.
Fonni's territory is home to the very important Sanctuary of the Vergine dei Martiri, Fonni from the 17th century which is a destination for pilgrims right next to the Franciscans Convent. The church was built in 1708 in Baroque style and contains some curious paintings by local artists.
Another important church built in the 14th century is the Patron Saint church of San Giovanni Battista, located in the oldest section of the village also known as "Su Piggiu".
A little to the south of Fonni stood the Roman station of Sorabile, mentioned in the Antonine Itinerary as situated some 100 km from Caralis on the road to Olbia. Excavations made in 1879 and 1880 led to the discovery of the remains of this station, arranged round three sides of a courtyard some 100 ft. square, including traces of baths and other buildings, and a massive embanking wall above them, some 150 ft. in length, to protect them from landslips, while a discharge certificate (tabula honestae missionis) of sailors who had served in the Ravenna's fleet was found in some ruins here or hereabouts. Near Fonni, too, are several menhirs (called "pietre celtiche" in the district) and other prehistoric remains like nuraghes.
Costumes.
The local costumes are extremely picturesque, and are well seen on the day of St John the Baptist, the patron saint. The men's costume is similar to that worn in the district generally; the linen trousers are long and black gaiters are worn. The women wear a white chemise; over that a very small corselet, and over that a red jacket with blue and black velvet facings. The skirt is brown above and red below, with a blue band between the two colours; it is accordion-pleated. Two identical skirts are often worn, one above the other. The unmarried girls wear white kerchiefs, the married women black.
Neighborhoods.
Neighborhoods in Fonni are called "Rioni" of these the oldest is called "su piggiu" or the skin, probably derived by the fact this is the highest and first layer of the village. Others include "puppuai" and "cresiedda" to the south, "logotza" to the east.

</doc>
<doc id="11755" url="https://en.wikipedia.org/wiki?curid=11755" title="Fasces">
Fasces

Fasces (, (, , a "plurale tantum", from the Latin word "fascis", meaning "bundle") is a bound bundle of wooden rods, sometimes including an axe with its blade emerging. The fasces had its origin in the Etruscan civilization, and was passed on to ancient Rome, where it symbolized a magistrate's power and jurisdiction. The image has survived in the modern world as a representation of magisterial or collective power. The fasces frequently occurs as a charge in heraldry, it is present on an older design of the Mercury dime and behind the podium in the United States House of Representatives, it is used as the symbol of a number of Italian syndicalist groups, including the Unione Sindacale Italiana, and it was the origin of the name of the National Fascist Party in Italy (from which the term fascism is derived).
It should not be confused with the related term "fess", which in French heraldry is called a "fasce".
Origin and symbolism.
Although little is known about the Etruscans, a few artifacts have been found showing a thin bundle of rods surrounding a two-headed axe. Fasces-symbolism might derive—via the Etruscans—from the eastern Mediterranean, with the labrys, the Anatolian and Minoan double-headed axe, later incorporated into the praetorial fasces. There is little archaeological evidence.
By the time of the Roman Republic, the "fasces" had evolved into a thicker bundle of birch rods, sometimes surrounding a single-headed axe and tied together with a red leather ribbon into a cylinder. On certain special occasions, the fasces might be decorated with a laurel wreath.
The symbolism of the fasces suggested strength through unity (see Unity makes strength); a single rod is easily broken, while the bundle is very difficult to break. This symbolism occurs in one of Aesop's Fables, The Old Man and his Sons. A similar story is told about the Bulgar Khan Kubrat, giving rise to the Bulgarian National motto, "Union gives strength" (Съединението прави силата). The axe represented the power over life or death through the death penalty, although after the laws of the twelve tables, no Roman magistrate could summarily execute a Roman citizen. Bundled birch twigs symbolise corporal punishment (see birching).
Republican Rome.
The "fasces lictoriae" ("bundles of the lictors") symbolised power and authority ("imperium") in ancient Rome, beginning with the early Roman Kingdom and continuing through the Republican and Imperial periods. By Republican times, use of the fasces was surrounded with tradition and protocol. A corps of "apparitores" (subordinate officials) called lictors each carried fasces before a magistrate, in a number corresponding to his rank. Lictors preceded consuls (and proconsuls), praetors (and propraetors), dictators, curule aediles, quaestors, and the Flamen Dialis during Roman triumphs (public celebrations held in Rome after a military conquest)
According to Livy, the lictors were likely an Etruscan tradition, adopted by Rome. The highest magistrate, the "dictator", was entitled to twenty-four lictors and fasces, the consul to twelve, the proconsul eleven, the praetor six (two within the "pomerium"), the propraetor five, and the curule aediles two.
Another part of the symbolism developed in Republican Rome was the inclusion of a single-headed axe in the fasces, with the blade projecting from the bundle. The axe indicated that the magistrate's judicial powers ("imperium") included capital punishment. Fasces carried within the "Pomerium"—the boundary of the sacred inner city of Rome—had their axe blades removed; within the city, the power of life and death rested with the people through their assemblies. During times of emergency, however, the Roman Republic might choose a dictator to lead for a limited time period, who was the only magistrate to be granted capital punishment authority within the Pomerium. Lictors attending the dictator kept the axes in their fasces even inside the Pomerium—a sign that the dictator had the ultimate power in his own hands. There were exceptions to this rule: in 48 BC, guards holding bladed fasces guided Vatia Isauricus to the tribunal of Marcus Caelius, and Vatia Isauricus used one to destroy Caelius's magisterial chair ("sella curulis").
An occasional variation on the fasces was the addition of a laurel wreath, symbolizing victory. This occurred during the celebration of a "Triumph" - essentially a victory parade through Rome by a returning victorious general. Previously, all Republican Roman commanding generals had held high office with imperium, and so, already were entitled to the lictors and fasces.
Usage.
The term is related to the modern Italian word "fascio", used in the twentieth century to designate peasant cooperatives and industrial workers' unions.
Numerous governments and other authorities have used the image of the "fasces" for a symbol of power since the end of the Roman Empire. It also has been used to hearken back to the Roman republic, particularly by those who see themselves as modern-day successors to the old republic and/or its ideals. 
The Ecuadorian coat of arms incorporated the fasces in 1830, although it had already been in use in the coat of arms of Gran Colombia since 1821.
Italian Fascism, which derives its name from the "fasces", arguably used this symbolism the most in the twentieth century. The British Union of Fascists also used it in the 1930s. The "fasces", as a widespread and long-established symbol in the West, however, has avoided the stigma associated with much of fascist symbolism, and many authorities continue to display them, including the federal government of the United States.
Fasces in the United States.
Several offices and institutions in the United States have incorporated representations of the "fasces" into their iconography.
Fasces in France.
A review of the images included in "Les Grands Palais de France "Fontainebleau" " reveals that French architects used the Roman fasces ("faisceaux romains") as a decorative device as early as the reign of Louis XIII (1610–1643) and continued to employ it through the periods of Napoleon I's Empire (1804–1815).
The fasces typically appeared in a context reminiscent of the Roman Republic and/or of the Roman Empire. The French Revolution has used many references to the ancient Roman Republic in its imagery. During the First Republic, topped by the Phrygian cap, the fasces is a tribute to the Roman Republic and means that power belongs to the people. It also symbolizes the "unity and indivisibility of the Republic", as stated in the French Constitution. In 1848 and after 1870, it appears on the seal of the French Republic, held by Liberty. There is the fasces in the arms of the French Republic with the "RF" for "République française" (see image below), surrounded by leaves of olive tree (as a symbol of peace) and oak (as a symbol of justice). While it is used widely by French officials, this symbol never was officially adopted by the government.
The fasces appears on the helmet and the buckle insignia of the French Army's Autonomous Corps of Military Justice, as well as on that service's distinct cap badges for the prosecuting and defending lawyers in a court-martial.
The following cases all involve the adoption of the fasces as a symbol or icon, although no physical re-introduction has occurred. 

</doc>
<doc id="11757" url="https://en.wikipedia.org/wiki?curid=11757" title="Fast combat support ship">
Fast combat support ship

The fast combat support ship (US Navy hull classification symbol: AOE) is the United States Navy's largest combat logistics ship, designed as an oiler, ammunition and supply ship. All fast combat support ships currently in service are operated by Military Sealift Command. The AOE has the speed to keep up with carrier battle groups and the capacity to fully support their needs. It receives petroleum products, ammunition and stores from various shuttle ships and redistributes these items when needed to ships in the carrier battle group. This greatly reduces the number of service ships needed to travel with carrier battle groups. 
The four ships of the were 53,000 tons at full load, 796 feet overall length, and carried two Boeing Vertol CH-46 Sea Knight helicopters. The "Sacramento" class was retired in 2005.
The ships displace 48,800 tons full load and operate two Sikorsky MH-60S Knighthawk helicopters.

</doc>
<doc id="11758" url="https://en.wikipedia.org/wiki?curid=11758" title="FASA">
FASA

FASA Corporation was an American publisher of role-playing games, wargames and board games between 1980 and 2001, after which they closed publishing operations for several years, becoming an IP holding company under the name FASA Inc. In 2012, a wholly owned subsidiary called FASA Games Inc. went into operation, using the name and logo with permission of the parent company. FASA Games Inc. works alongside Ral Partha Europe, also a subsidiary of FASA Inc., to bring out new editions of existing properties such as Earthdawn and Demonworld, and to develop new properties within the FASA cosmology.
FASA first appeared as a "Traveller" licensee, producing supplements for that Game Designers' Workshop role-playing game, especially the work of the Keith Brothers. The company went on to establish itself as a major gaming company with the publication of the first licensed "Star Trek" RPG, then several successful original games. Noteworthy lines included "BattleTech" and "Shadowrun". Their "Star Trek" role-playing supplements and tactical ship game enjoyed popularity outside the wargaming community since, at the time, official descriptions of the "Star Trek" universe were not common, and the gaming supplements offered details fans craved.
The highly successful "BattleTech" line led to a series of video games, some of the first virtual reality gaming suites, called Virtual World (created by a subdivision of the company known at the time of development as ESP, an acronym for "Extremely Secret Project") and a Saturday-morning .
Originally the name FASA was an acronym for "Freedonian Aeronautics and Space Administration", a joking allusion to the Marx Brothers film "Duck Soup". This tongue-in-cheek attitude was carried over in humorous self-references in its games. For example, in "Shadowrun", a tactical nuclear device was detonated near FASA's offices at 1026 W. Van Buren St in Chicago, Illinois.
History.
FASA Corporation was founded by Jordan Weisman and L. Ross Babcock III in 1980 with a starting capital of $350. The two were fellow gamers at the United States Merchant Marine Academy. Mort Weisman, Jordan's father, joined the company in 1985 to lead the company's operational management having sold his book publishing business, Swallow Press.
Under the new commercial direction and with Mort's capital injection, the company diversified into books and miniature figures. After consulting their UK distributor, Chart Hobby Distributors, FASA licensed the manufacture of its "BattleTech" figurines to Miniature Figurines (also known as Minifigs). FASA would later acquire the U.S. figures manufacturer Ral Partha, which was the US manufacturer of Minifigs. While Mort ran the paper and metal based sides of the business, the company's founders focused on the development of computer-based games. They were particularly interested in virtual reality (particularly the BattleTech Centers / Virtual World) but also developed desktop computer games.
When Microsoft acquired the FASA Interactive subsidiary, Babcock went with that company. After the sale of Virtual World, Jordan turned his attention to the founding of a new games venture called WizKids.
Current status and intellectual property.
FASA unexpectedly ceased active operations on April 30, 2001, but still exists as a corporation holding intellectual property rights, which it licenses to other publishers. Contrary to popular belief, the company did not go bankrupt. Allegedly the owners decided to quit while the company was still financially sound in a market they perceived as going downhill. Mort Weisman had been talking of retirement for some years and his confidence in the future of the paper-based games business was low. He considered the intellectual property of FASA to be of high value but did not wish to continue working as he had been for the last decade or more. Unwilling to wrestle with the complexities of dividing up the going concern, the owners issued a press release on January 25, 2001 announcing the immediate closure of the business.
The "BattleTech" and "Shadowrun" properties were sold to WizKids, who in turn licensed their publication to FanPro LLC and then to Catalyst Game Labs. The "Earthdawn" license was sold to WizKids, and then back to FASA. Living Room Games published "Earthdawn" (Second Edition), RedBrick Limited published "Earthdawn" (Third Edition), but the license has now returned to FASA Corporation, and FASA Games, Inc. is the current license holder for new material. "Crimson Skies" was originally developed by Zipper Interactive under the FASA Interactive brand in late 2000 and used under license by FASA; FASA Interactive had been purchased by Microsoft, so rights to "Crimson Skies" stayed with Microsoft. Rights to the miniatures game "" reverted to the designer Mike "Skuzzy" Nielsen, but it has not been republished in any form due partly to legal difficulties. Microsoft officially closed the FASA team in the company's gaming division on September 12, 2007.
On December 6, 2007, FASA founder Jordan Weisman announced that his new venture, Smith & Tinker, had licensed the electronic gaming rights to "MechWarrior", "Shadowrun", and "Crimson Skies" from Microsoft. On April 28, 2008 Mike "Skuzzy" Nielsen announced plans to create " 2.0".
At Gen Con 2012, FASA Games, Inc. was revealed, which includes FASA Corporation co-founder Ross Babcock on the Board of Directors. While FASA Corporation still manages the FASA IP and brands, FASA Games, Inc. has announced its intention to develop new games under the FASA banner.

</doc>
<doc id="11759" url="https://en.wikipedia.org/wiki?curid=11759" title="McDonnell Douglas F-4 Phantom II">
McDonnell Douglas F-4 Phantom II

The McDonnell Douglas F-4 Phantom II is a tandem two-seat, twin-engine, all-weather, long-range supersonic jet interceptor aircraft/fighter-bomber originally developed for the United States Navy by McDonnell Aircraft. It first entered service in 1960 with the U.S. Navy. Proving highly adaptable, it was also adopted by the U.S. Marine Corps and the U.S. Air Force, and by the mid-1960s had become a major part of their respective air wings.
The Phantom is a large fighter with a top speed of over Mach 2.2. It can carry more than 18,000 pounds (8,400 kg) of weapons on nine external hardpoints, including air-to-air missiles, air-to-ground missiles, and various bombs. The F-4, like other interceptors of its time, was designed without an internal cannon. Later models incorporated an M61 Vulcan rotary cannon. Beginning in 1959, it set 15 world records for in-flight performance, including an absolute speed record, and an absolute altitude record.
During the Vietnam War, the F-4 was used extensively; it served as the principal air superiority fighter for both the Navy and Air Force, and became important in the ground-attack and aerial reconnaissance roles late in the war. The Phantom has the distinction of being the last U.S. fighter flown to attain ace status in the 20th century. During the Vietnam War, the U.S. Air Force had one pilot and two weapon systems officers (WSOs), and the US Navy had one pilot and one radar intercept officer (RIO) become aces by achieving five aerial kills against enemy fighter aircraft. The F-4 continued to form a major part of U.S. military air power throughout the 1970s and 1980s, being gradually replaced by more modern aircraft such as the F-15 Eagle and F-16 in the U.S. Air Force, the Grumman F-14 Tomcat in the U.S. Navy, and the F/A-18 Hornet in the U.S. Navy and U.S. Marine Corps.
The F-4 Phantom II remained in use by the U.S. in the reconnaissance and Wild Weasel (Suppression of Enemy Air Defenses) roles in the 1991 Gulf War, finally leaving service in 1996. It was also the only aircraft used by both U.S. flight demonstration teams: the USAF Thunderbirds (F-4E) and the US Navy Blue Angels (F-4J). The F-4 was also operated by the armed forces of 11 other nations. Israeli Phantoms saw extensive combat in several Arab–Israeli conflicts, while Iran used its large fleet of Phantoms in the Iran–Iraq War. Phantoms remain in front line service with seven countries, and in use as a target drone in the U.S. Air Force. Phantom production ran from 1958 to 1981, with a total of 5,195 built, making it the most numerous American supersonic military aircraft.
Development.
Origins.
In 1952, McDonnell's Chief of Aerodynamics, Dave Lewis, was appointed by CEO Jim McDonnell to be the company's preliminary design manager. With no new aircraft competitions on the horizon, internal studies concluded the Navy had the greatest need for a new and different aircraft type: an attack fighter.
In 1953, McDonnell Aircraft began work on revising its F3H Demon naval fighter, seeking expanded capabilities and better performance. The company developed several projects including a variant powered by a Wright J67 engine, and variants powered by two Wright J65 engines, or two General Electric J79 engines. The J79-powered version promised a top speed of Mach 1.97. On 19 September 1953, McDonnell approached the United States Navy with a proposal for the "Super Demon". Uniquely, the aircraft was to be modular—it could be fitted with one- or two-seat noses for different missions, with different nose cones to accommodate radar, photo cameras, four 20 mm (.79 in) cannon, or 56 FFAR unguided rockets in addition to the nine hardpoints under the wings and the fuselage. The Navy was sufficiently interested to order a full-scale mock-up of the F3H-G/H, but felt that the upcoming Grumman XF9F-9 and Vought XF8U-1 already satisfied the need for a supersonic fighter.
The McDonnell design was therefore reworked into an all-weather fighter-bomber with 11 external hardpoints for weapons and on 18 October 1954, the company received a letter of intent for two YAH-1 prototypes. On 26 May 1955, four Navy officers arrived at the McDonnell offices and, within an hour, presented the company with an entirely new set of requirements. Because the Navy already had the Douglas A-4 Skyhawk for ground attack and F-8 Crusader for dogfighting, the project now had to fulfill the need for an all-weather fleet defense interceptor. A second crewman was added to operate the powerful radar.
XF4H-1 prototype.
The XF4H-1 was designed to carry four semi-recessed AAM-N-6 Sparrow III radar-guided missiles, and to be powered by two J79-GE-8 engines. As in the McDonnell F-101 Voodoo, the engines sat low in the fuselage to maximize internal fuel capacity and ingested air through fixed geometry intakes. The thin-section wing had a leading edge sweep of 45° and was equipped with blown flaps for better low-speed handling.
Wind tunnel testing had revealed lateral instability requiring the addition of 5° dihedral to the wings. To avoid redesigning the titanium central section of the aircraft, McDonnell engineers angled up only the outer portions of the wings by 12°, which averaged to the required 5° over the entire wingspan. The wings also received the distinctive "dogtooth" for improved control at high angles of attack. The all-moving tailplane was given 23° of anhedral to improve control at high angles of attack while still keeping the tailplane clear of the engine exhaust. In addition, air intakes were equipped with variable geometry ramps to regulate airflow to the engines at supersonic speeds. All-weather intercept capability was achieved thanks to the AN/APQ-50 radar. To accommodate carrier operations, the landing gear was designed to withstand landings with a sink rate of , while the nose strut could extend by some to increase angle of attack at takeoff.
On 25 July 1955, the Navy ordered two XF4H-1 test aircraft and five YF4H-1 pre-production examples. The Phantom made its maiden flight on 27 May 1958 with Robert C. Little at the controls. A hydraulic problem precluded retraction of the landing gear but subsequent flights went more smoothly. Early testing resulted in redesign of the air intakes, including the distinctive addition of 12,500 holes to "bleed off" the slow-moving boundary layer air from the surface of each intake ramp. Series production aircraft also featured splitter plates to divert the boundary layer away from the engine intakes. The aircraft soon squared off against the XF8U-3 Crusader III. Due to operator workload, the Navy wanted a two-seat aircraft and on 17 December 1958 the F4H was declared a winner. Delays with the J79-GE-8 engines meant that the first production aircraft were fitted with J79-GE-2 and −2A engines, each having 16,100 lbf (71.8 kN) of afterburning thrust. In 1959, the Phantom began carrier suitability trials with the first complete launch-recovery cycle performed on 15 February 1960 from .
There were proposals to name the F4H "Satan" and "Mithras". In the end, the aircraft was given the less controversial name "Phantom II", the first "Phantom" being another McDonnell jet fighter, the FH-1 Phantom. The Phantom II was briefly given the designation F-110A and the name "Spectre" by the USAF, but neither name was officially used.
Production.
Early in production, the radar was upgraded to a larger Westinghouse AN/APQ-72, necessitating the bulbous nose, and the canopy was reworked to improve visibility and make the rear cockpit less claustrophobic. During its career the Phantom underwent many changes in the form of numerous variants developed.
The USAF received Phantoms as the result of Defense Secretary Robert McNamara's push to create a unified fighter for all branches of the military. After an F-4B won the "Operation Highspeed" fly-off against the Convair F-106 Delta Dart, the USAF borrowed two Naval F-4Bs, temporarily designating them F-110A "Spectre" in January 1962, and developed requirements for their own version. Unlike the navy's focus on interception, the USAF emphasized a fighter-bomber role. With McNamara's unification of designations on 18 September 1962, the Phantom became the F-4 with the naval version designated F-4B and USAF F-4C. The first air force Phantom flew on 27 May 1963, exceeding Mach 2 on its maiden flight.
The USN operated the F4H-1 (re-designated F-4A in 1962) with J79-GE-2 and -2A engines of 16,100 lbf (71.62 kN) thrust and later builds receiving -8 engines. A total of 45 F-4As were built and none saw combat and most ended up as test or training aircraft. The USN and USMC received the first definitive Phantom, the F-4B which was equipped with the Westinghouse APQ-72 radar (pulse only), a Texas Instruments AAA-4 Infra-red search and track pod under the nose, an AN/AJB-3 bombing system and powered by J79-GE-8,-8A and -8B engines of 10,900 lbf (48.5 kN) dry and 16,950 lbf (75.4 kN) afterburner (reheat) with the first flight on 25 March 1961. 649 F-4Bs were built with deliveries beginning in 1961 and VF-121 Pacemakers receiving the first examples at NAS Miramar.
The F-4J had improved air-to-air and ground-attack capability; deliveries begun in 1966 and ended in 1972 with 522 built. It was equipped with J79-GE-10 engines with 17,844 lbf (79.374 kN) thrust, the Westinghouse AN/AWG-10 Fire Control System (making the F-4J the first fighter in the world with operational look-down/shoot-down capability), a new integrated missile control system and the AN/AJB-7 bombing system for expanded ground attack capability.
The F-4N (updated F-4Bs) with smokeless engines and F-4J aerodynamic improvements started in 1972 under a U.S. Navy-initiated refurbishment program called "Project Bee Line" with 228 converted by 1978. The F-4S model resulted from the refurbishment of 265 F-4Js with J79-GE-17 smokeless engines of 17,900 lbf (79.379 kN), AWG-10B radar with digitized circuitry for improved performance and reliability, Honeywell AN/AVG-8 Visual Target Acquisition Set or VTAS (world's first operational Helmet Sighting System), classified avionics improvements, airframe reinforcement and leading edge slats for enhanced maneuvering. The USMC also operated the RF-4B with reconnaissance cameras with 46 built.
Phantom II production ended in the United States in 1979 after 5,195 had been built (5,057 by McDonnell Douglas and 138 in Japan by Mitsubishi). Of these, 2,874 went to the USAF, 1,264 to the Navy and Marine Corps, and the rest to foreign customers. The last U.S.-built F-4 went to South Korea, while the last F-4 built was an F-4EJ built by Mitsubishi Heavy Industries in Japan and delivered on 20 May 1981. As of 2008, 631 Phantoms were in service worldwide, while the Phantom also remains in use as a target drone operated by the U.S. military.
World records.
To show off their new fighter, the Navy led a series of record-breaking flights early in Phantom development: All in all, the Phantom set 16 world records. Except for Skyburner, all records were achieved in unmodified production aircraft. Five of the speed records remained unbeaten until the F-15 Eagle appeared in 1975.
Design.
Overview.
The F-4 Phantom is a tandem-seat fighter-bomber designed as a carrier-based interceptor to fill the U.S. Navy's fleet defense fighter role. Innovations in the F-4 included an advanced pulse-Doppler radar and extensive use of titanium in its airframe.
Despite imposing dimensions and a maximum takeoff weight of over 60,000 lb (27,000 kg), the F-4 has a top speed of Mach 2.23 and an initial climb rate of over 41,000 ft/min (210 m/s). The F-4's nine external hardpoints have a capability of up to 18,650 pounds (8,480 kg) of weapons, including air-to-air and air-to-surface missiles, and unguided, guided, and thermonuclear weapons. Like other interceptors of its day, the F-4 was designed without an internal cannon.
The baseline performance of a Mach 2-class fighter with long range and a bomber-sized payload would be the template for the next generation of large and light/middle-weight fighters optimized for daylight air combat.
Flight characteristics.
In air combat, the Phantom's greatest advantage was its thrust, which permitted a skilled pilot to engage and disengage from the fight at will. The massive aircraft, designed to fire radar-guided missiles from beyond visual range, lacked the agility of its Soviet opponents and was subject to adverse yaw during hard maneuvering. Although thus subject to irrecoverable spins during aileron rolls, pilots reported the aircraft to be very communicative and easy to fly on the edge of its performance envelope. In 1972, the F-4E model was upgraded with leading edge slats on the wing, greatly improving high angle of attack maneuverability at the expense of top speed.
The J79 engines produced noticeable amounts of black smoke (at mid-throttle/cruise settings), a severe disadvantage in that the enemy could spot the aircraft. This was solved on the F-4S fitted with the −10A engine variant which used a smokeless combustor.
The F-4's biggest weakness, as it was initially designed, was its lack of an internal cannon. For a brief period, doctrine held that turning combat would be impossible at supersonic speeds and little effort was made to teach pilots air combat maneuvering. In reality, engagements quickly became subsonic, as pilots would slow down in an effort to get behind their adversaries. Furthermore, the relatively new heat-seeking and radar-guided missiles at the time were frequently reported as unreliable and pilots had to use multiple shots (also known as ripple-firing), just to hit one enemy fighter. To compound the problem, rules of engagement in Vietnam precluded long-range missile attacks in most instances, as visual identification was normally required. Many pilots found themselves on the tail of an enemy aircraft but too close to fire short-range Falcons or Sidewinders. Although by 1965 USAF F-4Cs began carrying SUU-16 external gunpods containing a 20 mm (.79 in) M61A1 Vulcan Gatling cannon, USAF cockpits were not equipped with lead-computing gunsights until the introduction of the SUU-23, virtually assuring a miss in a maneuvering fight. Some Marine Corps aircraft carried two pods for strafing. In addition to the loss of performance due to drag, combat showed the externally mounted cannon to be inaccurate unless frequently boresighted, yet far more cost-effective than missiles. The lack of a cannon was finally addressed by adding an internally mounted 20 mm (.79 in) M61A1 Vulcan on the F-4E.
Costs.
Note: Original amounts were in 1965 United States dollars. The figures in these tables have been adjusted for inflation.
Operational history.
United States Navy.
On 30 December 1960, the VF-121 "Pacemakers" at NAS Miramar became the first Phantom operator with its F4H-1Fs (F-4As). The VF-74 "Be-devilers" at NAS Oceana became the first deployable Phantom squadron when it received its F4H-1s (F-4Bs) on 8 July 1961. The squadron completed carrier qualifications in October 1961 and Phantom's first full carrier deployment between August 1962 and March 1963 aboard . The second deployable U.S. Atlantic Fleet squadron to receive F-4Bs was the VF-102 "Diamondbacks", who promptly took their new aircraft on the shakedown cruise of . The first deployable U.S. Pacific Fleet squadron to receive the F-4B was the VF-114 "Aardvarks", which participated in the September 1962 cruise aboard .
By the time of the Tonkin Gulf incident, 13 of 31 deployable navy squadrons were armed with the type. F-4Bs from made the first Phantom combat sortie of the Vietnam War on 5 August 1964, flying bomber escort in Operation Pierce Arrow. The first Phantom air-to-air victory of the war took place on 9 April 1965 when an F-4B from VF-96 "Fighting Falcons" piloted by Lieutenant (junior grade) Terence M. Murphy and his RIO, Ensign Ronald Fegan, shot down a Chinese MiG-17 "Fresco". The Phantom was then shot down, probably by an AIM-7 Sparrow from one of its wingmen. There continues to be controversy over whether the Phantom was shot down by MiG guns or, as enemy reports later indicated, an AIM-7 Sparrow III from one of Murphy's and Fegan's wingmen. On 17 June 1965, an F-4B from VF-21 "Freelancers" piloted by Commander Louis Page and Lieutenant John C. Smith shot down the first North Vietnamese MiG of the war.
On 10 May 1972, Lieutenant Randy "Duke" Cunningham and Lieutenant (junior grade) William P. Driscoll flying an F-4J, call sign "Showtime 100", shot down three MiG-17s to become the first American flying aces of the war. Their fifth victory was believed at the time to be over a mysterious North Vietnamese ace, Colonel Nguyen Toon, now considered mythical. On the return flight, the Phantom was damaged by an enemy surface-to-air missile. To avoid being captured, Cunningham and Driscoll flew their burning aircraft using only the rudder and afterburner (the damage to the aircraft rendered conventional control nearly impossible), until they could eject over water.
During the war, U.S. Navy F-4 Phantom squadrons participated in 84 combat tours with F-4Bs, F-4Js, and F-4Ns. The navy claimed 40 air-to-air victories at a cost of 73 Phantoms lost in combat (seven to enemy aircraft, 13 to SAMs, and 53 to AAA). An additional 54 Phantoms were lost in mishaps.
In 1984, the F-4Ns had been retired, and by 1987 the last F-4Ss were retired in the US Navy deployable squadrons. On 25 March 1986, an F-4S belonging to the VF-151 "Vigilantes," became the last active duty U.S. Navy Phantom to launch from an aircraft carrier, in this case, . On 18 October 1986, an F-4S from the VF-202 "Superheats", a Naval Reserve fighter squadron, made the last-ever Phantom carrier landing while operating aboard . In 1987, the last of the Naval Reserve-operated F-4S aircraft were replaced by F-14As. The last Phantoms in service with the Navy were QF-4 target drones operated by the Naval Air Warfare Center at NAS Point Mugu, California. These airframes were subsequently retired in 2004.
United States Marine Corps.
The Marine Corps received its first F-4Bs in June 1962, with the "Black Knights" of VMFA-314 at Marine Corps Air Station El Toro, California becoming the first operational squadron. Marine Phantoms from VMFA-531 'Gray Ghosts' were assigned to Da Nang airbase on South Vietnam's northeast coast on 10 May 1965 and were initially assigned to provide air defense for the USMC. They soon began close air support missions (CAS) and VMFA-314 'Black Knights', VMFA-323 'Death Rattlers', and VMFA-542 'Bengals' soon arrived at the primitive airfield. Marine F-4 pilots claimed three enemy MiGs (two while on exchange duty with the USAF) at the cost of 75 aircraft lost in combat, mostly to ground fire, and four in accidents. VMCJ-1 Golden Hawks (now VMAQ-1 and VMAQ-4 which has the old RM tailcode) flew the first RF-4B photo recon mission on 3 November 1966 from Da Nang and remained there until 1970 with no RF-4B losses and one damaged by AAA. VMCJ-2 and VMCJ-3 (now VMAQ-3) provided aircraft for VMCJ-1 in Da Nang and VMFP-3 was formed in 1975 at MCAS El Toro, CA consolidating all USMC RF-4-Bs in one unit that became known as "The Eyes of the Corps." VMFP-3 disestablished in August 1990 after the Advanced Tactical Airborne Reconnaissance System was introduced for the F/A-18 Hornet. The F-4 continued to equip fighter-attack squadrons in both Marine Corps active and reserve units throughout the 1960s, 1970s and 1980s and into the early 1990s. In the early 1980s, these squadrons began to transition to the F/A-18 Hornet, starting with the same squadron that introduced the F-4 to the Marine Corps, VMFA-314 at MCAS El Toro, California. On 18 January 1992, the last Marine Corps Phantom, an F-4S in the Marine Corps Reserve, was retired by the "Cowboys" of VMFA-112, after which the squadron was re-equipped with F/A-18 Hornets.
United States Air Force.
In USAF service, the F-4 was initially designated the F-110 Spectre prior to the introduction of the 1962 United States Tri-Service aircraft designation system. The USAF quickly embraced the design and became the largest Phantom user. The first USAF Phantoms in Vietnam were F-4Cs from the 555th Tactical Fighter Squadron "Triple Nickel", which arrived in December 1964.
Unlike the U.S. Navy and U.S. Marine Corps, which flew the Phantom with a Naval Aviator (pilot) in the front seat and a Naval Flight Officer as a radar intercept officer (RIO) in the back seat, the USAF initially flew its Phantoms with a rated Air Force Pilot in front and back seats. While the rear pilot (GIB, or "guy in back") could fly and ostensibly land the aircraft, he had fewer flight instruments and a very restricted forward view. The Air Force later assigned a rated Air Force Navigator qualified as a weapon/targeting systems officer (later designated as weapon systems officer or WSO) in the rear seat instead of another pilot. However, all USAF Phantoms retained dual flight controls throughout their service life.
On 10 July 1965, F-4Cs of the 45th Tactical Fighter Squadron, 15th TFW, on temporary assignment in Ubon, Thailand, scored the USAF's first victories against North Vietnamese MiG-17s using AIM-9 Sidewinder air-to-air missiles. On 26 April 1966, an F-4C from the 480th Tactical Fighter Squadron scored the first aerial victory by a U.S. aircrew over a North Vietnamese MiG-21 "Fishbed". On 24 July 1965, another Phantom from the 45th Tactical Fighter Squadron became the first American aircraft to be downed by an enemy SAM, and on 5 October 1966 an 8th Tactical Fighter Wing F-4C became the first U.S. jet lost to an air-to-air missile, fired by a MiG-21.
Early aircraft suffered from leaks in wing fuel tanks that required re-sealing after each flight and 85 aircraft were found to have cracks in outer wing ribs and stringers. There were also problems with aileron control cylinders, electrical connectors, and engine compartment fires. Reconnaissance RF-4Cs made their debut in Vietnam on 30 October 1965, flying the hazardous post-strike reconnaissance missions. The USAF Thunderbirds used the F-4E from the 1969 season until 1974.
Although the F-4C was essentially identical to the Navy/Marine Corps F-4B in flight performance and carried the AIM-9 Sidewinder missiles, USAF-tailored F-4Ds initially arrived in June 1967 equipped with AIM-4 Falcons. However, the Falcon, like its predecessors, was designed to shoot down heavy bombers flying straight and level. Its reliability proved no better than others and its complex firing sequence and limited seeker-head cooling time made it virtually useless in combat against agile fighters. The F-4Ds reverted to using Sidewinders under the "Rivet Haste" program in early 1968, and by 1972 the AIM-7E-2 "Dogfight Sparrow" had become the preferred missile for USAF pilots. Like other Vietnam War Phantoms, the F-4Ds were urgently fitted with radar homing and warning (RHAW) antennas to detect the Soviet-built S-75 Dvina SAMs.
From the initial deployment of the F-4C to Southeast Asia, USAF Phantoms performed both air superiority and ground attack roles, supporting not only ground troops in South Vietnam but also conducting bombing sorties in Laos and North Vietnam. As the F-105 force underwent severe attrition between 1965 and 1968, the bombing role of the F-4 proportionately increased until after November 1970 (when the last F-105D was withdrawn from combat) it became the primary USAF tactical ordnance delivery system. In October 1972 the first squadron of EF-4C Wild Weasel aircraft deployed to Thailand on temporary duty. The "E" prefix was later dropped and the aircraft was simply known as the F-4C Wild Weasel.
Sixteen squadrons of Phantoms were permanently deployed between 1965 and 1973, and 17 others deployed on temporary combat assignments. Peak numbers of combat F-4s occurred in 1972, when 353 were based in Thailand. A total of 445 Air Force Phantom fighter-bombers were lost, 370 in combat and 193 of those over North Vietnam (33 to MiGs, 30 to SAMs, and 307 to AAA).
The RF-4C was operated by four squadrons, and of the 83 losses, 72 were in combat including 38 over North Vietnam (seven to SAMs and 65 to AAA). By war's end, the U.S. Air Force had lost a total of 528 F-4 and RF-4C Phantoms. When combined with U.S. Navy and Marine Corps losses of 233 Phantoms, 761 F-4/RF-4 Phantoms were lost in the Vietnam War.
On 28 August 1972, Captain Steve Ritchie became the first USAF ace of the war. On 9 September 1972, WSO Capt Charles B. DeBellevue became the highest-scoring American ace of the war with six victories. and WSO Capt Jeffrey Feinstein became the last USAF ace of the war on 13 October 1972. Upon return to the United States, DeBellevue and Feinstein were assigned to undergraduate pilot training (Feinstein was given a vision waiver) and requalified as USAF pilots in the F-4. USAF F-4C/D/E crews scored 107½ MiG kills in Southeast Asia (50 by Sparrow, 31 by Sidewinder, five by Falcon, 15.5 by gun, and six by other means).
On 31 January 1972, the 170th Tactical Fighter Squadron/183d Tactical Fighter Group of the Illinois Air National Guard became the first Air National Guard unit to transition to Phantoms from Republic F-84F Thunderstreaks which were found to have corrosion problems. Phantoms would eventually equip numerous tactical fighter and tactical reconnaissance units in the USAF active, National Guard, and reserve.
On 2 June 1972, a Phantom flying at supersonic speeds shot down a MiG-19 over Thud Ridge in Vietnam for the "first supersonic gun kill". With a recorded speed of Mach 1.2, Major Phil Handley's shoot down was the first and only recorded gun kill while flying at over supersonic speeds.
On 15 August 1990, 24 F-4G Wild Weasel Vs and six RF-4Cs were deployed to Shaikh Isa AB, Bahrain, for Operation Desert Storm. The F-4G was the only aircraft in the USAF inventory equipped for the Suppression of Enemy Air Defenses (SEAD) role, and was needed to protect coalition aircraft from Iraq's extensive air defense system. The RF-4C was the only aircraft equipped with the ultra-long-range KS-127 LOROP (long-range oblique photography) camera, and was used for a variety of reconnaissance missions. In spite of flying almost daily missions, only one RF-4C was lost in a fatal accident before the start of hostilities. One F-4G was lost when enemy fire damaged the fuel tanks and the aircraft ran out of fuel near a friendly airbase. The last USAF Phantoms, F-4G Wild Weasel Vs from 561st Fighter Squadron, were retired on 26 March 1996. The last operational flight of the F-4G Wild Weasel was from the 190th Fighter Squadron, Idaho Air National Guard, in April 1996. The last operational USAF/ANG F-4 to land was flown by Maj Mike Webb and Maj Gary Leeder of the Idaho ANG.
Like the Navy, the Air Force has operated QF-4 target drones, serving with the 82d Aerial Targets Squadron at Tyndall Air Force Base, Florida, and Holloman Air Force Base, New Mexico. It was expected that the F-4 would remain in the target role with the 82d ATRS until at least 2015, when they would be replaced by early versions of the F-16 Fighting Falcon converted to a QF-16 configuration. Several QF-4s also retain capability as manned aircraft and are maintained in historical color schemes, being displayed as part of Air Combat Command's Heritage Flight at air shows, base open houses, and other events while serving as non-expendable target aircraft during the week. On 19 November 2013, BAE Systems delivered the last QF-4 aerial target to the Air Force. The example had been in storage for over 20 years before being converted. Over 16 years, BAE had converted 314 F-4 and RF-4 Phantom IIs into QF-4s and QRF-4s, with each aircraft taking six months to adapt. As of December 2013, QF-4 and QRF-4 aircraft had flown over 16,000 manned and 600 unmanned training sorties, with 250 unmanned aircraft being shot down in firing exercises. The remaining QF-4s and QRF-4s held their training role until the first of 126 QF-16s were delivered by Boeing. The final flight of an Air Force QF-4 from Tyndall AFB took place on 27 May 2015 to Holloman AFB. After Tyndall AFB ceased operations, the 53d Weapons Evaluation Group at Holloman became the fleet of 22 QF-4s' last remaining operator. The base will continue using them to fly manned test and unmanned live fire test support and Foreign Military Sales testing until January 2017, when the remaining airframes will be demilitarized.
Non-U.S. air forces.
The Phantom has served with the air forces of many countries, including Australia, Egypt, Germany, United Kingdom, Greece, Iran, Israel, Japan, Spain, South Korea and Turkey.
Australia.
The Royal Australian Air Force (RAAF) leased 24 USAF F-4Es from 1970 to 1973 while waiting for their order for the General Dynamics F-111C to be delivered. They were so well-liked that the RAAF considered retaining the aircraft after the F-111Cs were delivered. They were operated from RAAF Amberley by No. 1 Squadron and No. 6 Squadron.
Egypt.
In 1979, the Egyptian Air Force purchased 35 former USAF F-4Es along with a number of Sparrow, Sidewinder, and Maverick missiles from the U.S. for $594 million as part of the "Peace Pharaoh" program. An additional seven surplus USAF aircraft were purchased in 1988. Three attrition replacements had been received by the end of the 1990s.
Germany.
The German Air Force ("Luftwaffe") initially ordered the reconnaissance RF-4E in 1969, receiving a total of 88 aircraft from January 1971. In 1982, the initially unarmed RF-4Es were given a secondary ground attack capability; these aircraft were later retired in 1994.
In 1973, under the "Peace Rhine" program, the "Luftwaffe" purchased the lightened and simplified F-4F which was upgraded in the mid-1980s. 24 German F-4F Phantom IIs were operated by the 49th Tactical Fighter Wing of the USAF at Holloman AFB to train "Luftwaffe" crews until December 2004. In 1975, Germany also received 10 F-4Es for training in the U.S. In the late 1990s, these were withdrawn from service after being replaced by F-4Fs. Germany also initiated the Improved Combat Efficiency (ICE) program in 1983. The 110 ICE-upgraded F-4Fs entered service in 1992, and were expected to remain in service until 2012. All the remaining Luftwaffe Phantoms were based at Wittmund with Jagdgeschwader 71 (fighter wing 71) in Northern Germany and WTD61 at Manching. The German Air Force retired its last F-4Fs on 29 June 2013. German F-4Fs flew 279,000 hours from entering service on 31 August 1973 until retirement.
Greece.
In 1971, the Hellenic Air Force ordered brand new F-4E Phantoms, with deliveries starting in 1974. In the early 1990s, the Hellenic AF acquired surplus RF-4Es and F-4Es from the "Luftwaffe" and U.S. ANG.
Following the success of the German ICE program, on 11 August 1997, a contract was signed between DASA of Germany and Hellenic Aerospace Industry for the upgrade of 39 aircraft to the very similar "Peace Icarus 2000" standard. The Hellenic AF operates 34 upgraded "F-4E-PI2000" (338 and 339 Squadrons) and 12 RF-4E aircraft (348 Squadron) as of September 2013.
Iran.
In the 1960s and 1970s when the U.S. and Iran were on friendly terms, the U.S. sold 225 F-4D, F-4E, and RF-4E Phantoms to Iran. The Imperial Iranian Air Force saw at least one engagement, resulting in a loss, after an RF-4C was rammed by a Soviet MiG-21 during Project Dark Gene, an ELINT operation during the Cold War.
The Islamic Republic of Iran Air Force Phantoms saw heavy action in the Iran–Iraq War in the 1980s and are kept operational by overhaul and servicing from Iran's aerospace industry. Notable operations of Iranian F-4s during the war included Operation Scorch Sword, an attack by two F-4s against the Iraqi Osirak nuclear reactor site near Baghdad on 30 September 1980, and the attack on H3, a 4 April 1981 strike by eight Iranian F-4s against the H-3 complex of air bases in the far west of Iraq, which resulted in many Iraqi aircraft being destroyed or damaged for no Iranian losses. Iranian F-4s were in use as of late 2014; the aircraft reportedly conducted air strikes on ISIS targets in the eastern Iraqi province of Diyala.
Israel.
The Israeli Air Force was the largest foreign operator of the Phantom, flying both newly built and ex-USAF aircraft, as well as several one-off special reconnaissance variants. The first F-4Es, nicknamed ""Kurnass" (Sledgehammer), and RF-4Es, nicknamed "Orev"" (Raven), were delivered in 1969 under the "Peace Echo I" program. Additional Phantoms arrived during the 1970s under "Peace Echo II" through "Peace Echo V" and "Nickel Grass" programs. Israeli Phantoms saw extensive combat during Arab–Israeli conflicts, first seeing action during the War of Attrition. In the 1980s, Israel began the "Kurnass 2000" modernization program which significantly updated avionics. The last Israeli F-4s were retired in 2004.
Japan.
From 1968, the Japan Air Self-Defense Force purchased a total of 140 F-4EJ Phantoms without aerial refueling, Bullpup ASM system, nuclear control system and ground attack capabilities. Mitsubishi built 138 under license in Japan and 14 unarmed reconnaissance RF-4Es were imported. Of these, 96 F-4EJs have since been modified to the F-4EJ standard. 15 F-4EJs were converted to reconnaissance aircraft designated RF-4EJ, with similar upgrades as the F-4EJ Kai. Japan had a fleet of 90 F-4s in service in 2007. It has been studying several replacement fighters.
South Korea.
The Republic of Korea Air Force purchased its first batch of secondhand USAF F-4D Phantoms in 1968 under the "Peace Spectator" program. The F-4Ds continued to be delivered until 1988. The "Peace Pheasant II" program also provided new-built and former USAF F-4Es.
Spain.
The Spanish Air Force acquired its first batch of ex-USAF F-4C Phantoms in 1971 under the "Peace Alfa" program. Designated C.12, the aircraft were retired in 1989. At the same time, the air arm received a number of ex-USAF RF-4Cs, designated CR.12. In 1995–1996, these aircraft received extensive avionics upgrades. Spain retired its RF-4s in 2002.
Turkey.
The Turkish Air Force (TAF) received 40 F-4Es in 1974, with a further 32 F-4Es and 8 RF-4Es in 1977–78 under the "Peace Diamond III" program, followed by 40 ex-USAF aircraft in "Peace Diamond IV" in 1987, and a further 40 ex-U.S. Air National Guard Aircraft in 1991. A further 32 RF-4Es were transferred to Turkey after being retired by the Luftwaffe between 1992 and 1994. In 1995, IAI of Israel implemented an upgrade similar to Kurnass 2000 on 54 Turkish F-4Es which were dubbed the F-4E 2020 Terminator. Turkish F-4s, and more modern F-16s have been used to strike Kurdish PKK bases in ongoing military operations in Northern Iraq. On 22 June 2012, a Turkish RF-4E was shot down by Syrian air defenses while flying a reconnaissance flight near the Turkish-Syrian border. Turkey has stated the reconnaissance aircraft was in international airspace when it was shot down, while Syrian authorities stated it was inside Syrian airspace. Turkish F-4s remained in use as of 2015. On 24 February 2015, two RF-4E's crashed in the Malatya region in the southeast of Turkey, under yet unknown circumstances, killing both crew of two each. On 5 March 2015, an F-4E-2020 crashed in central Anatolia killing both crew. After the recent accidents, the TAF withdrew RF-4Es from active service. Turkey was reported to have used F-4 jets to attack PKK separatists and the ISIS capital on 19 September 2015.
United Kingdom.
The United Kingdom bought versions based on the U.S. Navy's F-4J for use with the Royal Air Force and the Royal Navy's Fleet Air Arm. The main differences were the use of the British Rolls-Royce Spey engines and of British-made avionics. The RN and RAF versions were given the designation F-4K and F-4M respectively, and entered service with the British military aircraft designations Phantom FG.1 (fighter/ground attack) and Phantom FGR.2 (fighter/ground attack/reconnaissance). Initially, the FGR.2 was used in the ground attack and reconnaissance role, primarily with RAF Germany, while 43 Squadron was formed in the air defence role using the FG.1s that had been intended for the Fleet Air Arm for use aboard . The superiority of the Phantom over the English Electric Lightning in terms of both range and weapon load, combined with the successful introduction of the SEPECAT Jaguar, meant that, during the mid-1970s, most of the ground attack Phantoms in Germany were redeployed to the UK to replace air defence Lightning squadrons. A second RAF squadron, 111 Squadron, was formed on the FG.1 in 1979 after the disbandment of 892 NAS.
In 1982, during the Falklands War, three Phantom FGR2s of No. 29 Squadron were on active Quick Reaction Alert duty on Ascension Island to protect the base from air attack. After the Falklands War, 15 upgraded ex-USN F-4Js, known as the F-4J(UK) entered RAF service to compensate for one interceptor squadron redeployed to the Falklands.
Around 15 RAF squadrons received various marks of Phantom, many of them based in Germany. The first to be equipped was No. 6 Squadron at RAF Leuchars in July 1969. One noteworthy deployment was to No. 43 Squadron where Phantom FG1s remained the squadron equipment for 20 years, arriving in September 1969 and departing in July 1989. During this period the squadron was based at Leuchars.
The interceptor Phantoms were replaced by the Panavia Tornado F3 from the late 1980s onwards, and the last British Phantoms were retired in October 1992 when No. 74 Squadron was disbanded.
Civilian use.
Sandia National Laboratories used an F-4 mounted on a "rocket sled" in a crash test to see the results of an aircraft hitting a reinforced concrete structure, such as a nuclear power plant.
One aircraft, an F-4D (civilian registration N749CF), is operated by the Massachusetts-based non-profit organization Collings Foundation as a "living history" exhibit. Funds to maintain and operate the aircraft, which is based in Houston, Texas, are raised through donations/sponsorships from public and commercial parties.
NASA used the F-4 to photograph and film Titan II missiles after launch from Cape Canaveral during the 1960s. Retired US Air Force Colonel Jack Petry described how he put his F-4 into a Mach 1.2 dive synchrionized to the launch countdown, then "'walked the (rocket's) contrail' up to the intercept, tweaking closing speed and updating mission control while camera pods mounted under each wing shot film at 900 frames per second." Petry's Phantom stayed with the Titan for 90 seconds, then broke away as the missile continued into space. NASA's Dryden Flight Research Center acquired an F-4A on 3 December 1965. It made 55 flights in support of short programs, chase on X-15 missions and lifting body flights. The F-4 also supported a biomedical monitoring program involving 1,000 flights by NASA Flight Research Center aerospace research pilots and students of the USAF Aerospace Research Pilot School flying high-performance aircraft. The pilots were instrumented to record accurate and reliable data of electrocardiogram, respiration rate and normal acceleration. In 1967, the Phantom supported a brief military-inspired program to determine whether an airplane's sonic boom could be directed and whether it could be used as a weapon of sorts, or at least an annoyance. NASA also flew an F-4C in a spanwise blowing study from 1983 to 1985, after which it was returned.
Culture.
Nicknames.
The Phantom gathered a number of nicknames during its career. Some of these names included "Snoopy", "Rhino", "Double Ugly", "Old Smokey", the "Flying Anvil", "Flying Footlocker", "Flying Brick", "Lead Sled", the "Big Iron Sled" and the "St. Louis Slugger". In recognition of its record of downing large numbers of Soviet-built MiGs, it was called the "World's Leading Distributor of MiG Parts". As a reflection of excellent performance in spite of its bulk, the F-4 was dubbed "the triumph of thrust over aerodynamics." German "Luftwaffe" crews called their F-4s the "Eisenschwein" ("Iron Pig"), "Fliegender Ziegelstein" ("Flying Brick") and "Luftverteidigungsdiesel" ("Air Defense Diesel").
Imitating the spelling of the aircraft's name, McDonnell issued a series of patches. Pilots became "Phantom Phlyers", backseaters became "Phantom Pherrets", fans of the F-4 "Phantom Phanatics", and call it the "Phabulous Phantom". Ground crewmen who worked on the aircraft are known as "Phantom Phixers".
The Spook.
The aircraft's emblem is a whimsical cartoon ghost called "The Spook", which was created by McDonnell Douglas technical artist, Anthony "Tony" Wong, for shoulder patches. The name "Spook" was coined by the crews of either the 12th Tactical Fighter Wing or the 4453rd Combat Crew Training Wing at MacDill AFB. The figure is ubiquitous, appearing on many items associated with the F-4. The Spook has followed the Phantom around the world adopting local fashions; for example, the British adaptation of the U.S. "Phantom Man" is a Spook that sometimes wears a bowler hat and smokes a pipe.
Aircraft on display.
Worldwide there are several F-4 Phantom IIs on display. For example, a Phantom II F-4C-15-MC, "63-7699", which is on loan from the USAF Museum, is on display at the Midland Air Museum, Coventry, England; a Phantom II F4H-1, BuNo "145310", U.S. Navy, is located at French Valley Airport, Murrieta, California, USA; and there is a dwindling number of reserve F-4s stored at Davis-Monthan Air Force Base, Arizona, USA. The Museum of Flight at Boeing Field in Seattle has an F-4C Phantom II on display. This F-4C was built in 1965 and served in Vietnam, shooting down three MiG-21s. The United States Air Force Academy has an F-4 on display in the south-east corner of the Terrazzo with six MiG kills during the Vietnam War to its credit. Luke AFB also has a Phantom on display, having facilitated the F-4 training mission there for several years before the initial adaptation of the F-15 training mission, said training mission later assumed by Holloman AFB, then Tyndall AFB and finally Kingsley Field ANGB.
The Collings Foundation operates one aircraft, an F-4D, as a "living history" exhibit.

</doc>
<doc id="11761" url="https://en.wikipedia.org/wiki?curid=11761" title="McDonnell FH Phantom">
McDonnell FH Phantom

The McDonnell FH Phantom was a twin-engined jet fighter aircraft designed and first flown during World War II for the United States Navy. The Phantom was the first purely jet-powered aircraft to land on an American aircraft carrier and the first jet deployed by the United States Marine Corps. Although with the end of the war, only 62 FH-1s were built, it helped prove the viability of carrier-based jet fighters. As McDonnell's first successful fighter, leading to the development of the follow-on F2H Banshee which was one of the two most important naval jet fighters of the Korean War it would also establish McDonnell as an important supplier of Navy aircraft. When McDonnell chose to bring the name back with the Mach 2 class McDonnell Douglas F-4 Phantom II it launched what would become the most versatile and widely used western combat aircraft of the Vietnam War era, adopted by the USAF and the US Navy.
The FH Phantom was originally designated the FD Phantom, but the designation was changed as the aircraft entered production.
Design and development.
In early 1943, aviation officials at the United States Navy were impressed with McDonnell's audacious XP-67 Bat project. McDonnell was invited by the Navy to cooperate in the development of a shipboard jet fighter, using an engine from the turbojets under development by Westinghouse Electric Corporation. Three prototypes were ordered on 30 August 1943 and the designation XFD-1 was assigned. Under the 1922 United States Navy aircraft designation system, the letter "D" before the dash designated the aircraft's manufacturer. The Douglas Aircraft Company had previously been assigned this letter, but the USN elected to reassign it to McDonnell because Douglas had not provided any fighters for Navy service in years.
McDonnell engineers evaluated a number of engine combinations, varying from eight 9.5 in (24 cm) diameter engines down to two engines of 19 inch (48 cm) diameter. The final design used the two 19 in (48 cm) engines after it was found to be the lightest and simplest configuration. The engines were buried in the wing root to keep intake and exhaust ducts short, offering greater aerodynamic efficiency than underwing nacelles, and the engines were angled slightly outwards to protect the fuselage from the hot exhaust blast. Placement of the engines in the middle of the airframe allowed the cockpit with its bubble-style canopy to be placed ahead of the wing, granting the pilot excellent visibility in all directions. This engine location also freed up space under the nose, allowing designers to use tricycle gear, thereby elevating the engine exhaust path and reducing the risk that the hot blast would damage the aircraft carrier deck. The construction methods and aerodynamic design of the Phantom were fairly conventional for the time; the aircraft had unswept wings, a conventional empennage, and an aluminum monocoque structure with flush riveted aluminum skin. Folding wings were used to reduce the width of the aircraft in storage configuration. Provisions for four .50-caliber (12.7 mm) machine guns were made in the nose, while racks for eight 5 in (127 mm) High Velocity Aircraft Rockets could be fitted under the wings, although these were seldom used in service. Adapting a jet to carrier use was a much greater challenge than producing a land-based fighter because of slower landing and takeoff speeds required on a small carrier deck. The Phantom used split flaps on both the folding and fixed wing sections to enhance low-speed landing performance, but no other high-lift devices were used. Provisions were also made for Rocket Assisted Take Off (RATO) bottles to improve takeoff performance.
When the first XFD-1, serial number "48235", was completed in January 1945, only one Westinghouse 19XB-2B engine was available for installation. Ground runs and taxi tests were conducted with the single engine, and such was the confidence in the aircraft that the first flight on 26 January 1945 was made with only the one turbojet engine. During flight tests, the Phantom became the first naval aircraft to exceed 500 mph (434 kn, 805 kph). With successful completion of tests, a production contract was awarded on 7 March 1945 for 100 FD-1 aircraft. With the end of the war, the Phantom production contract was reduced to 30 aircraft, but was soon increased back to 60.
The first prototype was lost in a fatal crash on 1 November 1945, but the second and final Phantom prototype (serial number "48236") was completed early the next year and became the first purely jet-powered aircraft to operate from an American aircraft carrier, completing four successful takeoffs and landings on 21 July 1946, from near Norfolk, Virginia. At the time, she was the largest carrier serving with the U.S. Navy, allowing the aircraft to take off without assistance from a catapult. The second prototype crashed on 26 August 1946.
Production Phantoms incorporated a number of design improvements. These included provisions for a flush-fitting centerline drop tank, an improved gunsight, and the addition of speed brakes. Production models used Westinghouse J30-WE-20 engines with 1,600 lbf (7.1 kN) of thrust per engine. The top of the vertical tail had a more square shape than the rounder tail used on the prototypes, and a smaller rudder was used to resolve problems with control surface clearance discovered during test flights. The horizontal tail surfaces were shortened slightly, while the fuselage was stretched by 19 in (48 cm). The amount of framing in the windshield was reduced to enhance pilot visibility.
Halfway through the production run, the Navy reassigned the designation letter "D" back to Douglas, with the Phantom being redesignated FH-1. Including the two prototypes, a total of 62 Phantoms were finally produced, with the last FH-1 rolling off the assembly line in May 1948.
Realizing that the production of more powerful jet engines was imminent, McDonnell engineers proposed a more powerful variant of the Phantom while the original aircraft was still under development – a proposal that would lead to the design of the Phantom's replacement, the F2H Banshee. Although the new aircraft was originally envisioned as a modified Phantom, the need for heavier armament, greater internal fuel capacity, and other improvements eventually led to a substantially heavier and bulkier aircraft that shared few parts with its agile predecessor. Despite this, the two aircraft were similar enough that McDonnell was able to complete its first F2H-1 in August 1948, a mere three months after the last FH-1 had rolled off the assembly line.
Operational history.
The first Phantoms were delivered to USN fighter squadron VF-17A (later redesignated VF-171) in August 1947; the squadron received a full complement of 24 aircraft on 29 May 1948. Beginning in November 1947, Phantoms were delivered to United States Marine Corps squadron VMF-122, making it the first USMC combat squadron to deploy jets. VF-17A became the USN's first fully operational jet carrier squadron when it deployed aboard on 5 May 1948.
The Phantom was one of the first jets used by the U.S. military for exhibition flying. Three Phantoms used by the Naval Air Test Center were used by a unique demonstration team called the Gray Angels, whose members consisted entirely of naval aviators holding the rank of Rear Admiral (Daniel V. Gallery, Apollo Soucek and Edgar A. Cruise.) The team's name was an obvious play on the name of the recently formed U.S. Navy Blue Angels, who were still flying propeller-powered Grumman F8F Bearcats at the time. The "Grays" flew in various air shows during the summer of 1947, but the team was abruptly disbanded after their poorly timed arrival at a September air show in Cleveland, Ohio nearly caused a head-on low-altitude collision with a large formation of other aircraft; their Phantoms were turned over to test squadron VX-3. The VMF-122 Phantoms were later used for air show demonstrations until they were taken out of service in 1949, with the team being known alternately as the Marine Phantoms or the Flying Leathernecks.
The Phantom's service as a frontline fighter would be short-lived. Its limited range and light armament – notably, its inability to carry bombs – made it best suited for duty as a point-defence interceptor aircraft. However, its speed and rate of climb were only slightly better than existing propeller-powered fighters and fell short of other contemporary jets, such as the Lockheed P-80 Shooting Star, prompting concerns that the Phantom would be outmatched by future enemy jets it might soon face. Moreover, recent experience in World War II had demonstrated the value of naval fighters that could double as fighter-bombers, a capability the Phantom lacked. Finally, the aircraft exhibited some design deficiencies – its navigational avionics were poor, it could not accommodate newly developed ejection seats, and the location of the machine guns in the upper nose caused pilots to be dazzled by muzzle flash.
The F2H Banshee and Grumman F9F Panther, both of which began flight tests around the time of the Phantom's entry into service, better satisfied the Navy's desire for a versatile, long-range, high-performance jet. Consequently, the FH-1 saw little weapons training, and was primarily used for carrier qualifications to transition pilots from propeller-powered fighters to jets in preparation for flying the Panther or Banshee. In June 1949, VF-171 (VF-17A) re-equipped with the Banshee, and their Phantoms were turned over to VF-172; this squadron, along with the NATC, VX-3, and VMF-122, turned over their Phantoms to the United States Naval Reserve by late 1949 after receiving F2H-1 Banshees. The FH-1 would see training duty with the USNR until being replaced by the F9F Panther in July 1954; none ever saw combat, having been retired from frontline service prior to the outbreak of the Korean War.
Civilian use.
In 1964, Progressive Aero, Incorporated of Fort Lauderdale, Florida purchased three surplus Phantoms, intending to use them to teach civilians how to fly jets. A pair were stripped of military equipment and restored to flying condition, but the venture was unsuccessful, and the aircraft were soon retired once again.

</doc>
<doc id="11762" url="https://en.wikipedia.org/wiki?curid=11762" title="Fricative consonant">
Fricative consonant

Fricatives are consonants produced by forcing air through a narrow channel made by placing two articulators close together. These may be the lower lip against the upper teeth, in the case of ; the back of the tongue against the soft palate, in the case of German , the final consonant of "Bach"; or the side of the tongue against the molars, in the case of Welsh , appearing twice in the name "Llanelli". This turbulent airflow is called frication. A particular subset of fricatives are the sibilants. When forming a sibilant, one still is forcing air through a narrow channel, but in addition, the tongue is curled lengthwise to direct the air over the edge of the teeth. English , , , and are examples of this.
Two other terms are spirant and strident, but their usage is less standardized. The former can be used synonymously with "fricative", or (as in e.g. Uralic linguistics) to refer to non-sibilant fricatives only. The latter can be used synonymously with "sibilant", but some authors include also labiodental, lateral or uvular fricatives in the class.
All sibilants are coronal, but may be dental, alveolar, postalveolar, or palatal (retroflex) within that range. However, at the postalveolar place of articulation, the tongue may take several shapes: domed, laminal, or apical, and each of these is given a separate symbol and a separate name. Prototypical retroflexes are subapical and palatal, but they are usually written with the same symbol as the apical postalveolars. The alveolars and dentals may also be either apical or laminal, but this difference is indicated with diacritics rather than with separate symbols.
The IPA also has letters for epiglottal fricatives,
with allophonic trilling, but these might be better analyzed as pharyngeal trills.
The lateral fricative occurs as the "ll" of Welsh, as in Lloyd, Llewelyn, and the town of Machynlleth (), as the unvoiced 'hl' and voiced 'dl' or 'dhl' in the several languages of Southern Africa (such as Xhosa and Zulu), and in Mongolian.
No language distinguishes voiced fricatives from approximants at these places, so the same symbol is used for both. For the pharyngeal, approximants are more numerous than fricatives. A fricative realization may be specified by adding the uptack to the letters, . Likewise, the downtack may be added to specify an approximant realization, .
In many languages, such as English, the glottal "fricatives" are unaccompanied phonation states of the glottis, without any accompanying manner, fricative or otherwise. However, in languages such as Arabic, they are true fricatives.
Types.
Pseudo-fricatives.
In addition, is usually called a "voiceless labial-velar fricative", but it is actually an approximant. True doubly articulated fricatives may not occur in any language; but see voiceless palatal-velar fricative for a putative (and rather controversial) example.
Aspirated fricatives.
Fricatives are very commonly voiced, though cross-linguistically voiced fricatives are not nearly as common as tenuis ("plain") fricatives. Other phonations are common in languages that have those phonations in their stop consonants. However, phonemically aspirated fricatives are rare. contrasts with in Korean; aspirated fricatives are also found in a few Sino-Tibetan languages, in some Oto-Manguean languages, and in the Siouan language Ofo ( and ). The record may be Cone Tibetan, which has four contrastive aspirated fricatives: , , and .
Nasalized fricatives.
Phonemically nasalized fricatives are rare. Some South Arabian languages have , Umbundu has , and Kwangali and Souletin Basque have . In Coatzospan Mixtec, appear allophonically before a nasal vowel, and in Igbo nasality is a feature of the syllable; when occur in nasal syllables they are themselves nasalized.
Occurrence.
"H" is not a fricative in English (see ). 
Until its extinction, Ubykh may have been the language with the most fricatives (29 not including ), some of which did not have dedicated symbols or diacritics in the IPA. This number actually outstrips the number of all consonants in English (which has 24 consonants). By contrast, approximately 8.7% of the world's languages have no phonemic fricatives at all. This is a typical feature of Australian Aboriginal languages, where the few fricatives that exist result from changes to plosives or approximants, but also occurs in some indigenous languages of New Guinea and South America that have especially small numbers of consonants. However, whereas is "entirely" unknown in indigenous Australian languages, most of the other languages without true fricatives do have in their consonant inventory.
Voicing contrasts in fricatives are largely confined to Europe, Africa, and Western Asia. Languages of South and East Asia, such as the Dravidian and Austronesian languages, typically do not have such voiced fricatives as and , which are familiar to many European speakers. These voiced fricatives are also relatively rare in indigenous languages of the Americas. Overall, voicing contrasts in fricatives are much rarer than in plosives, being found only in about a third of the world's languages as compared to 60 percent for plosive voicing contrasts.
About 15 percent of the world's languages, however, have "unpaired voiced fricatives", i.e. a voiced fricative without a voiceless counterpart. Two-thirds of these, or 10 percent of all languages, have unpaired voiced fricatives but no voicing contrast between any fricative pair.
This phenomenon occurs because voiced fricatives have developed from lenition of plosives or fortition of approximants. This phenomenon of unpaired voiced fricatives is scattered throughout the world, but is confined to nonsibilant fricatives with the exception of a couple of languages that have but lack . (Relatedly, several languages have the voiced affricate but lack .) The fricatives that occur most often without a voiceless counterpart are, in order of ratio of unpaired occurrences to total occurrences, , , , and .

</doc>
<doc id="11763" url="https://en.wikipedia.org/wiki?curid=11763" title="Frost">
Frost

Frost is the coating or deposit of ice that may form in humid air in cold conditions, usually overnight. In temperate climates it most commonly appears as fragile white crystals or frozen dew drops near the ground, but in cold climates it occurs in a greater variety of forms. Frost is composed of delicate branched patterns of ice crystals formed as the result of fractal process development.
Frost is known to damage crops or reduce future crop yields, therefore farmers in those regions where frost is a problem often invest substantial means to prevent its formation.
Introduction.
Frost forms when the temperature of a solid surface in the open cools to below the freezing point of water and for the most clearly crystalline forms of frost in particular, below the frost point in still air. In most temperate countries such temperatures usually are the result of heat loss by radiation at night, so those types of frost sometimes are called radiation frost.
Types of frost include crystalline hoar frost from deposition of water vapor from air of low humidity, white frost in humid conditions, window frost on glass surfaces, advection frost from cold wind over cold surfaces, black frost without visible ice at low temperatures and very low humidity, and rime under supercooled wet conditions.
The size of frost crystals varies depending on the time they have been building up and the amount of water vapor available. Frost crystals may be clear or translucent, but, like snow, a mass of frost crystals will scatter light in all directions, so that a coating of frost appears white.
Formation.
If a solid surface is chilled below the dew point of the surrounding humid air and the surface itself is colder than freezing, ice will form on it. If the water deposits as a liquid that then freezes, it forms a coating that may look glassy, opaque, or crystalline, depending on its type. Depending on context, that process also may be called atmospheric icing. The ice it produces differs in some ways from crystalline frost, which consists of spicules of ice that typically project from the solid surface on which they grow.
The main difference between the ice coatings and frost spicules arises from the fact that the crystalline spicules grow directly from desublimation of water vapour from air, and desublimation is not a factor in icing of freezing surfaces. For desublimation to proceed the surface must be below the frost point of the air, meaning that it is sufficiently cold for ice to form without passing through the liquid phase. The air must be humid, but not sufficiently humid to permit the condensation of liquid water, or icing will result instead of desublimation. The size of the crystals depends largely on the temperature, the amount of water vapor available, and how long they have been growing undisturbed.
As a rule, except in conditions where supercooled droplets are present in the air, frost will form only if the deposition surface is colder than the surrounding air. For instance frost may be observed around cracks in cold wooden sidewalks when humid air escapes from the warmer ground beneath. Other objects on which frost commonly forms are those with low specific heat or high thermal emissivity, such as blackened metals; hence the accumulation of frost on the heads of rusty nails.
The apparently erratic occurrence of frost in adjacent localities is due partly to differences of elevation, the lower areas becoming colder on calm nights. Where static air settles above an area of ground in the absence of wind, the absorptivity and specific heat of the ground strongly influence the temperature that the trapped air attains.
Types.
Hoar frost.
Hoar frost (also hoarfrost, radiation frost, or pruina) refers to white ice crystals, deposited on the ground or loosely attached to exposed objects such as wires or leaves. They form on cold, clear nights when conditions are such that heat radiates out to the open sky faster than it can be replaced from nearby sources such as wind or warm objects. Under suitable circumstances, objects cool to below the frost point of the surrounding air, well below the freezing point of water. Such freezing may be promoted by effects such as flood frost or frost pocket. These occur when ground-level radiation losses cool air till it flows downhill and accumulates in pockets of very cold air in valleys and hollows. Hoar frost may freeze in such low-lying cold air even when the air temperature a few feet above ground is well above freezing.
The name hoar comes from an Old English adjective that means "showing signs of old age"; in this context it refers to the frost that makes trees and bushes look like white hair. 
Hoar frost may have different names depending on where it forms:
When surface hoar covers sloping snowbanks, the layer of frost crystals may create an avalanche risk; when heavy layers of new snow cover the frosty surface, furry crystals standing out from the old snow hold off the falling flakes, forming a layer of voids that prevent the new snow layers from bonding strongly to the old snow beneath. Ideal conditions for hoarfrost to form on snow are cold clear nights, with very light, cold air currents conveying humidity at the right rate for growth of frost crystals. Wind that is too strong or warm destroys the furry crystals, and thereby may permit a stronger bond between the old and new snow layers. However, if the winds are strong enough and cold enough to lay the crystals flat and dry, carpeting the snow with cold, loose crystals without removing or destroying them or letting them warm up and become sticky, the frost interface between the snow layers still may present an avalanche danger, because the texture of the frost crystals differs from the snow texture and the dry crystals will not stick to fresh snow. Such conditions still prevent a strong bond between the snow layers.
In very low temperatures where fluffy surface hoar crystals form without subsequently being covered with snow, strong winds may break them off, forming a dust of ice particles and blowing them over the surface. The ice dust then may form yukimarimo, as has been observed in parts of Antarctica, in a process similar to the formation of dust bunnies and similar structures.
Hoar frost and white frost also occurs in man-made environments such as in freezers or industrial cold storage facilities. If such cold spaces or the pipes serving them are not well insulated and are exposed to ambient humidity, the moisture will freeze instantly depending on the freezer temperature. The frost may coat pipes thickly, partly insulating them, but such inefficient insulation still is a source of heat loss.
Advection frost.
Advection frost (also called wind frost) refers to tiny ice spikes that form when there is a very cold wind blowing over branches of trees, poles and other surfaces. It looks like rimming on the edge of flowers and leaves and usually it forms against the direction of the wind. It can occur at any hour, day or night.
Window frost.
Window frost (also called fern frost or ice flowers) forms when a glass pane is exposed to very cold air on the outside and warmer, moderately moist air on the inside. If the pane is not a good insulator (for example, if it is a single pane window), water vapour condenses on the glass forming frost patterns. With very low temperatures outside, frost can appear on the bottom of the window even with double pane energy efficient windows because the air convection between two panes of glass ensures that the bottom part of the glazing unit is colder than the top part. On unheated motor vehicles the frost will usually form on the outside surface of the glass first. The glass surface influences the shape of crystals, so imperfections, scratches, or dust can modify the way ice nucleates. The patterns in window frost form a fractal with a fractal dimension greater than one but less than two. This is a consequence of the nucleation process being constrained to unfold in two dimensions, unlike a snowflake which is shaped by a similar process but forms in three dimensions and has a fractal dimension greater than two.
If the indoor air is very humid, rather than moderately so, water will first condense in small droplets and then freeze into clear ice.
Similar patterns of freezing may occur on other smooth vertical surfaces, but they seldom are as obvious or spectacular as on clear glass.
White frost.
White frost is a solid deposition of ice which forms directly from water vapour contained in air.
White frost forms when there is a relative humidity above 90% and a temperature below −8 °C (18 °F) and it grows against the wind direction, since air arriving from windward has a higher humidity than leeward air, but the wind must not be strong or it damages the delicate icy structures as they begin to form. White frost resembles a heavy coating of hoar frost with big, interlocking crystals, usually needle-shaped.
Rime.
Rime is a type of ice deposition that occurs quickly, often under conditions of heavily saturated air and windy conditions. Technically speaking, it is not a type of frost, since usually supercooled water drops are involved, in contrast to the formation of hoar frost, in which water vapour desublimates slowly and directly. Ships travelling through Arctic seas may accumulate large quantities of rime on the rigging. Unlike hoar frost, which has a feathery appearance, rime generally has an icy solid appearance.
Black frost.
Black frost (or "killing frost") is not strictly speaking frost at all, because it is the condition seen in crops when the humidity is too low for frost to form, but the temperature falls so low that plant tissues freeze and die, becoming blackened, hence the term "black frost". Black frost often is called "killing frost" because white frost tends to be less cold, partly because the latent heat of freezing of the water reduces the temperature drop.
Effect on plants.
Overview.
Many plants can be damaged or killed by freezing temperatures or frost. This varies with the type of plant, the tissue exposed, and how low temperatures get: a "light frost" of will damage fewer types of plants than a "hard frost" below .
Plants likely to be damaged even by a light frost include vines—such as beans, grapes, squashes, melons—along with nightshades such as tomatoes, eggplants and peppers. Plants that may tolerate (or even benefit) from frosts include:
Even those plants that tolerate frost may be damaged once temperatures drop even lower (below ). Hardy perennials, such as "Hosta", become dormant after the first frosts and regrow when spring arrives. The entire visible plant may turn completely brown until the spring warmth, or may drop all of its leaves and flowers, leaving the stem and stalk only. Evergreen plants, such as pine trees, withstand frost although all or most growth stops. Frost crack is a bark defect caused by a combination of low temperatures and heat from the winter sun.
Vegetation is not necessarily damaged when leaf temperatures drop below the freezing point of their cell contents. In the absence of a site nucleating the formation of ice crystals, the leaves remain in a supercooled liquid state, safely reaching temperatures of . However, once frost forms, the leaf cells may be damaged by sharp ice crystals. Hardening is the process by which a plant becomes tolerant to low temperatures. See also cryobiology.
Certain bacteria, notably "Pseudomonas syringae", are particularly effective at triggering frost formation, raising the nucleation temperature to about . Bacteria lacking ice nucleation-active proteins (ice-minus bacteria) result in greatly reduced frost damage.
Protection methods.
Typical measures to prevent frost or reduce its severity include one or more of:
Such measures need to be applied with discretion, because they may do more harm than good; for example, spraying crops with water can cause damage if the plants become overburdened with ice. An effective low cost method for small crop farms and plant nurseries, exploits the latent heat of freezing. A pulsed irrigation timer delivers water through existing overhead sprinklers at a low volumes to combat frosts down to . If the water freezes it giving off its latent heat, preventing the temperature of the foliage from falling much below zero.
Personifications.
Frost is personified in Russian culture as Ded Moroz. Indigenous peoples of Russia such as the Mordvins have their own traditions of frost deities.
English folklore tradition holds that Jack Frost, an elfish creature, is responsible for feathery patterns of frost found on windows on cold mornings.

</doc>
<doc id="11768" url="https://en.wikipedia.org/wiki?curid=11768" title="Franz Schmidt">
Franz Schmidt

Franz Schmidt (22 December 187411 February 1939) was an Austrian composer, cellist and pianist.
Life.
Schmidt was born in Pozsony (known in German as Pressburg), in the Hungarian part of the Austro-Hungarian Empire (the city is now Bratislava, capital of Slovakia). His father was half Hungarian and his mother entirely Hungarian. He was a Roman Catholic.
His earliest teacher was his mother, Mária Ravasz, an accomplished pianist, who gave him a systematic instruction in the keyboard works of J. S. Bach. He received a thorough foundation in theory from Brother Felizian Moczik, the outstanding organist at the Franciscan church in Pressburg. He studied piano briefly with Theodor Leschetizky, with whom he clashed. He moved to Vienna with his family in 1888, and studied at the Vienna Conservatory (composition with Robert Fuchs, cello with Ferdinand Hellmesberger and theory (the counterpoint class) with Anton Bruckner), graduating "with excellence" in 1896.
He beat 13 other applicants and obtained a post as cellist with the Vienna Court Opera Orchestra, where he played until 1914, often under Gustav Mahler. Mahler habitually had Schmidt play all the cello solos, even though Friedrich Buxbaum was the principal cellist. Schmidt was also in demand as a chamber musician. Schmidt and Arnold Schoenberg maintained cordial relations despite their vast differences in style. Also a brilliant pianist, in 1914 Schmidt took up a professorship in piano at the Vienna Conservatory, which had been recently renamed Imperial Academy of Music and the Performing Arts. (Apparently, when asked who the greatest living pianist was, Leopold Godowsky replied, "The other one is Franz Schmidt.") In 1925 he became Director of the Academy, and from 1927 to 1931 its Rector.
As teacher of piano, cello and counterpoint and composition at the Academy, Schmidt trained numerous musicians, conductors and composers who later achieved fame. Among his best-known students were the pianist Friedrich Wührer and Alfred Rosé (son of Arnold Rosé, the legendary founder of the Rosé Quartet, Konzertmeister of the Vienna Philharmonic and brother-in-law of Gustav Mahler). Among the composers were Theodor Berger, Marcel Rubin and Alfred Uhl. He received many tokens of the high esteem in which he was held, notably the Franz-Josef Order, and an Honorary Doctorate from the University of Vienna.
Schmidt's private life was in stark contrast to the success of his distinguished professional career, and was overshadowed by tragedy. His first wife was, from 1919, confined in the Vienna mental hospital Am Steinhof, and three years after his death was murdered under the Nazi euthanasia program. His daughter Emma died unexpectedly after the birth of her first child. Schmidt experienced a spiritual and physical breakdown after this, but achieved an artistic revival and resolution in his Fourth Symphony of 1933 (which he inscribed as "Requiem for my Daughter") and, especially, in his oratorio The Book With Seven Seals. His second marriage, to a successful young piano student, for the first time brought some desperately needed stability into the private life of the artist, who was plagued by many serious health problems.
Schmidt's worsening health forced his retirement from the Academy in early 1937. In the last year of his life Austria was brought into the German Reich by the Anschluss, and Schmidt was fêted by the Nazi authorities as the greatest living composer of the so-called Ostmark. He was given a commission to write a cantata entitled "The German Resurrection", which, after 1945, was taken by many as a reason to brand him as having been tainted by Nazi sympathy. However, Schmidt left this composition unfinished, and in the summer and autumn of 1938, a few months before his death, set it aside to devote himself to two other commissioned works for the one-armed pianist Paul Wittgenstein, for whom he had often composed: the Clarinet Quintet in A major and the solo Toccata in D minor. Schmidt died on 11 February 1939.
Musical works.
As a composer, Schmidt was slow to develop, but his reputation, at least in Austria, saw a steady growth from the late 1890s until his death in 1939. In his music, Schmidt continued to develop the Viennese classic-romantic traditions he inherited from Schubert, Brahms and his own master, Bruckner. He also takes forward the exotic ‘gypsy’ style of Liszt and Brahms. His works are monumental in form and firmly tonal in language, though quite often innovative in their designs and clearly open to some of the new developments in musical syntax initiated by Mahler and Schoenberg. Although Schmidt did not write a lot of chamber music, what he did write, in the opinion of such critics as Wilhelm Altmann, was important and of high quality. Although Schmidt's organ works may resemble others of the era in terms of length, complexity, and difficulty, they are forward-looking in being conceived for the smaller, clearer, classical-style instruments of the "Orgelbewegung", which he advocated. Schmidt worked mainly in large forms, including four symphonies (1899, 1913, 1928 and 1933) and two operas: "Notre Dame" (1904-6) and "Fredigundis" (1916–21). A CD recording of "Notre Dame" has been available for many years, starring Dame Gwyneth Jones and James King.
"Fredigundis".
No really adequate recording has been made of Schmidt's second and last opera "Fredigundis", of which there has been but one "unauthorized" release in the early 1980s on the Voce label of an Austrian Radio broadcast of a 1979 Vienna performance under the direction of Ernst Märzendorfer. Aside from numerous "royal fanfares" (Fredigundis held the French throne in the sixth century) the score contains some fine examples of Schmidt's later style. "New Grove" encyclopaedia states that "Fredigundis" was a critical and popular failure, which may be partly attributable to the fact that Fredigundis (Fredegund, the widow of Chilperic I), is presented as a murderous and sadistic feminine monster. Add to this some structural problems with the libretto, and the opera's failure to make headway - despite an admirable and impressive score - becomes comprehensible.
"The Book with Seven Seals".
Schmidt's crowning achievement was the oratorio "Das Buch mit sieben Siegeln" (1935–37), a setting of passages from the Book of Revelation. His choice of subject was prophetic: with hindsight the work appears to foretell, in the most powerful terms, the disasters that were shortly to be visited upon Europe in the Second World War. Here his invention rises to a sustained pitch of genius. A narrative upon the text of the oratorio was provided by the composer.
Schmidt's oratorio stands in the Austro-German tradition stretching back to the time of J. S. Bach and Handel. He was the first to write an oratorio fully on the subject of the Book of Revelation (as opposed to a Last Judgement in a "Requiem" like that of Giuseppe Verdi). Far from glorifying its subject, it is a mystical contemplation, a horrified warning, and a prayer for salvation. The premiere was held in Vienna on 15 June 1938, with the Vienna Symphony Orchestra under Oswald Kabasta: the soloists were Rudolf Gerlach (John), Erika Rokyta, Enid Szantho, Anton Dermota, Josef von Manowarda and with Franz Schütz at the organ.
Symphonies.
Schmidt is generally, if erroneously, regarded as a conservative composer (such labels rest upon yet-to-be-resolved aesthetic/stylistic arguments), but the rhythmic subtlety and harmonic complexity of much of his music belie this. His music is modern without being modernist, combining a reverence for the great Austro-German lineage of composers with very personal innovations in harmony and orchestration (showing an awareness of the output of composers such as Debussy and Ravel, whose piano music he greatly admired, along with a knowledge of more recent composers in his own German-speaking realm, such as Schoenberg, Berg, Hindemith, etc.). The considerable technical accomplishment of his music ought to compel respect, but he seems to have fallen between two stools: his works are too complex for the conservatively minded, yet too obviously traditional for the avant-garde (they are also notoriously difficult to perform). Since the 1970s his music has enjoyed a modest revival which looks set to continue as it is rediscovered and re-evaluated.
Schmidt and Nazism.
Schmidt's premiere of "Das Buch mit sieben Siegeln" was made much of by the Nazis (who had annexed Austria shortly before in the Anschluss), and Schmidt was seen (according to a report by Georg Tintner, who revered Schmidt and intended to record his symphonies until prevented by his own death) to give the Nazi salute. His conductor Oswald Kabasta was apparently an enthusiastic Nazi who, being prohibited from conducting in 1946 during de-nazification, committed suicide. These facts long placed Schmidt's posthumous reputation under a cloud. His lifelong friend and colleague Oskar Adler, who fled the Nazis in 1938, wrote afterwards that Schmidt was never a Nazi and never antisemitic but was extremely naïve about politics. Hans Keller gave similar endorsement. Regarding Schmidt's political naivety, Michael Steinberg, in his magisterial book, "The Symphony", tells of Schmidt's recommending "Variations on a Hebrew Theme" by his student Israel Brandmann to a musical group associated with the proto-Nazi German National Party. Most of Schmidt's principal musical friends were Jews, and they benefited from his generosity.
Schmidt's last work, the cantata "German Resurrection", was composed to a Nazi text. As one of the most famous living Austrian composers, Schmidt was well-known to Hitler and received this commission after the Anschluss. He left it unfinished, to be completed later by Robert Wagner. Already seriously ill, Schmidt worked instead on other compositions such as a piano quintet. His failure to complete the cantata is likely to be a further indication that he was not committed to the Nazi cause; such, at any rate, was the opinion of his friend Oskar Adler.
Listing of works.
Operas
Oratorio
Cantata
Symphonies
Piano Concerti
Various Orchestral Works
Chamber music
Music for Trumpets
Music for Organ and Trumpet
Piano music
Organ works

</doc>
<doc id="11772" url="https://en.wikipedia.org/wiki?curid=11772" title="Finnish Civil War">
Finnish Civil War

The Finnish Civil War (27 January – 15 May 1918) concerned leadership and control of Finland during its transition from a Grand Duchy of the Russian Empire to an independent state. The conflict formed a part of the national, political, and social turmoil caused by World War I (Eastern Front) in Europe. The war was fought between the "Reds", led by the Social Democratic Party and the "Whites", led by the non-socialist, conservative-led Senate. The paramilitary Red Guards, composed of industrial and agrarian workers, controlled the towns and industrial centres of southern Finland. The paramilitary White Guards, composed of peasants and middle- and upper-class factions, controlled rural central and northern Finland.
Finnish society had experienced - by 1917, under the Russian regime - rapid population growth, industrialisation, preurbanization and the rise of a comprehensive labour movement. The country's political and governmental systems were in an unstable phase of democratisation and modernization, while the people's socioeconomic condition and national-cultural status gradually improved. World War I led to the collapse of the Russian Empire and a power struggle, militarization, and escalating crisis between the left-leaning Finnish labor movement and the Finnish conservatives. Finland's declaration of independence on 6 December 1917 failed to halt the disintegration of the society and the push towards war.
The Reds carried out an unsuccessful general offensive in February 1918, supplied with weapons by Soviet Russia. A counteroffensive by the Whites began in March, reinforced by an Imperial German Army squad in April. The decisive military actions of the war were the Battles of Tampere and Viipuri, won by the Whites, and the Battles of Helsinki and Lahti, won by German troops, leading to victory of the Whites and the German forces. Both the Reds and Whites engaged in political terror. A large number of Reds perished due to malnutrition and disease in prison camps. Altogether, around 39,000 people died in the war, including 36,000 Finns—out of a population of 3,000,000.
In the aftermath, the Finns passed from Russian rule to the German Empire's sphere of power. The conservative Finnish Senate attempted to establish a Finnish monarchy, but the plan was aborted by the defeat of Germany in World War I. Finland emerged as an independent, democratic republic. The war divided the nation for many years and remains one of the most emotionally charged events in Finnish history. The society was reunited through social compromises based on a long-term culture of moderate politics and religion, the outcome of World War I, and the postwar economic recovery.
Background.
The main factor behind the Finnish Civil War was World War I; the Russian Empire collapsed under the pressures of the war, leading to the February and October Revolutions in 1917. The breakdown caused a large power vacuum and subsequent power struggle in Eastern Europe. The Grand Duchy of Finland, a part of the Russian Empire since 1809, became embroiled in the struggle for power. Geopolitically less important Finland was a peaceful sidefront until early 1918, but the war between the German Empire and Russia had indirect effects on the Finns. Since the end of 19th century, the Grand Duchy had become a vital source of raw materials, industrial products, food and labor for the growing Imperial Russian capital Petrograd (Saint Petersburg), and World War I emphasized the role. Strategically, the Finnish territory was the northern section of the Estonian–Finnish gateway and buffer zone to and from Petrograd via the Gulf of Finland, the Narva area and the Karelian Isthmus.
The German Empire saw Eastern Europe—mainly Russia—as a major source of vital products and raw materials, both during World War I and in the future. Her resources overstretched by the two-front war, Germany pursued a policy of breaking up Russia from within by providing financial support to revolutionary groups such as the Bolsheviks, Socialist Revolutionary Party (SRs) and separatist factions such as the Finnish Activists leaning toward Germanism. From 30–40 million marks were spent on Russia. Controlling the Finnish area would allow the Imperial German Army to enter Russia at Saint Petersburg and to penetrate northeast towards the Kola Peninsula, an area rich in raw materials for the mining industry. Finland itself had large ore reserves and a well-developed forest industry.
From 1809 to 1898, a period called "Pax Russica", the peripheral power of the Finns gradually increased, and the Russian-Finnish relations were exceptionally peaceful compared with other parts of the Russian Empire. Russia's defeat in the Crimean War in the 1850s led to attempts to speed up the modernization of the country. This caused more than 50 years of economic, industrial, cultural and educational progress in the Grand Duchy of Finland, including improvement in the status of the Finnish language. All this encouraged Finnish nationalism and cultural unity through the birth of the Fennoman movement, which bound the Finns to the domestic governmental system and led to the idea that the Finnish Grand Duchy was an increasingly autonomous state of the Russian Empire.
In 1899, the Russian Empire initiated a policy of integration through the Russification of Finland, aiming at an increase of military and administrative control over the Grand Duchy. The military and strategic situation of Russia became more difficult due of the rise of Germany and Japan, and Russian administration and the idea of Pan-Slavism strengthened in St. Petersburg. The central power of the "Russian Multinational Dynastic Union" planned to unite the large, heterogeneous country. The Finns called the integration policy "the First Period of Oppression, 1899–1905", and plans for disengagement from Russia or sovereignty for Finland were drawn up for the first time. The power struggle led to the rise of different Finnish political groups regarding Russia. The most radical one, the Activist movement, included anarchistic groups from the working class and the Swedish-speaking intelligentsia and engaged in terrorist attacks. During World War I and the rise of Germanism, the Svecomans began their covert collaboration with Imperial Germany, and from 1915 to 1917, a Finnish "Jäger" "(Jääkärit)" battalion consisting of 1900 volunteers were trained in Germany.
Politics.
The major reasons for rising political tensions among the Finns were the autocratic rule of the Russian Czar and the undemocratic class system of the estates of the realm. The system originated in the Swedish Empire regime, preceding the Russian power, and divided the Finnish people into two groups, separated economically, socially and politically. Finland's population grew rapidly in the 19th century (from 860,000 in 1810 to 3,130,000 in 1917), and a class of industrial and agrarian workers and property-less peasants emerged. The Industrial Revolution was rapid in Finland, though it started later than in the rest of Western Europe. Industrialization was financed by the state, and some of the social problems associated with the industrial process were diminished via control of the administration. Among urban workers, socioeconomic problems steepened during periods of industrial depression. The position of rural workers had worsened since the end of the 19th century, as farming became more efficient and market-oriented and the gradually developing industry did not fully utilize the rapid population growth of the countryside.
The difference between Scandinavian-Finnish (Finno-Ugric peoples) and Russian-Slavic culture had an impact on the nature of Finnish national integration; the social upper faction took the lead, though it gained domestic might from the Russian Czar in 1809. The estates planned to build up an increasingly autonomous Finnish state, led by the elite and intelligentsia. The Fennomans aimed to include the common people in a nonpolitical role in order to reduce unrest due to social problems; the labor movement, youth associations and temperance movement were initially led "from above."
Social conditions, the standard of living and the self-confidence of the workers gradually improved due to industrialization between 1870–1916 but, while the standard of living rose among the common people, the rift between rich and poor deepened markedly. The common people's rising awareness of the socioeconomic and political questions interacted with the ideas of socialism, social liberalism and nationalism (Fennomania). The commoners' responses and the corresponding counteracts of the dominating upper factions steepened the social relations in Finland.
The Finnish labor movement, which emerged at the end of the 19th century from folk, temperance and religious movements, as well as Fennomania, had a Finnish nationalist, working-class character. From 1899–1906 the labor movement became conclusively independent, shedding the patriarchal thinking of the Fennoman estates, and it was represented by the Finnish Social Democratic Party, established in 1899. Workers' activism directed both toward opposing Russification and in developing a domestic policy that tackled social problems and responded to the demand for democracy. This was a reaction to the domestic dispute, ongoing since the 1880s, between the Finnish nobility-burghers and the labor movement concerning voting rights for the common people. Besides their obligations as obedient, peaceful and nonpolitical inhabitants of the Grand Duchy, who had a few decades earlier accepted the class system as the natural order of their life, the commoners had begun to ask for and then demand their civil rights and citizenship in Finnish society. The power struggle between the Finnish estates and the Russian administration gave a concrete role model and free space for the labor movement. On the other side, due to at least a century-long tradition and experience of administrative leadership, the Finnish elite saw itself as the inherent natural power in the Grand Duchy.
The political struggle for democracy was solved outside Finland, via international power politics; the Russian Empire's failed 1904–1905 war against Japan led to the 1905 Revolution in Russia and to a general strike in Finland. In an attempt to quell the general unrest, the system of estates was abolished in the Parliamentary Reform of 1906, which introduced universal suffrage. The general strike increased support for the Social Democrats substantially, as a proportion of the population, the party was the most powerful socialist movement in the world.
The Reform of 1906 was a giant leap in the political and social liberalization of the common Finnish people; the Russian royal family had been the most autocratic and conservative rulers in Europe. The Finns adopted a unicameral parliamentary system with all political rights for female citizens, increasing the number of voters from 126,000 to 1,273,000. This produced around 50% turnouts for the Social Democrats, but the Czar regained his authority after the revolutionary crisis of 1905, reclaimed his role as the Grand Duke of Finland and, during the second period of Russification between 1908 and 1917, neutralized the functions and powers of the new parliament. The Emperor saw the Parliament as having merely an advisory role. He alone determined the composition of the Finnish Senate, which did not correlate with the assembly of the Parliament, prohibiting true parliamentarism. The Czar dissolved the Parliament and ordered new parliamentary elections almost annually between 1908–1916.
The capacity of the Parliament to solve major socioeconomic problems was stymied by confrontations between the representatives of the largely uneducated common man and the representatives of the former estates, accustomed to autocratic rule and attitudes. At the same time, conflict grew between industrial employers and their workers as the industrialists denied collective bargaining and the right of the labour unions to represent working people; the employers essentially dictated contracts signed on the personal level. Although the parliamentary process disappointed the labour movement, dominance in the Finnish Parliament and in legislation was the workers' pathway to reach a more balanced society - they identified themselves powerfully to the state. Altogether, these political developments led to conditions that encouraged a struggle for leadership of the Finnish state, during the ten years before the collapse of the Russian Empire.
February Revolution.
The more severe programme of Russification, called "the Second Period of Oppression, 1908–1917" by the Finns, was halted on 15 March 1917 by the removal of the Russian Czar Nicholas II. The immediate reason for the collapse of the Russian Empire was crisis caused by military defeats in the war against Imperial Germany and war-weariness among the Russians. The deeper causes lay in the collision between the most conservative and autocratic regime in Europe and the Russian people urging for socio-economic modernization. The Czar's power was transferred to the Russian Parliament, the Duma and the right-wing Provisional Government but it was challenged by the Petrograd Soviet, leading to dual power in the country.
Autonomous status was returned to the Finns in March 1917, and the revolt in Russia handed to the Finnish Parliament true political power for the first time. The political left, consisting mainly of Social Democrats, covered a wide spectrum from moderate to revolutionary socialists. The political right was even more diverse, ranging from social liberals and moderate conservatives to rightist conservative elements. The four main parties were:
The Finns faced a detrimental interaction of power struggle and breakdown of society during 1917. The collapse of Russia induced a chain reaction of disintegration, starting from the government, military power and economy, and spreading downwards to all fields of the society such as local administration and workplaces, and finally to the level of individual citizens as changes and questions of freedom, responsibility and morality. The Social Democrats aimed at retaining the political rights of the labor movement already achieved, and gaining power over the people and society. The conservatives were fearful of losing their long-held socioeconomic might. Both factions, with groups aiming at major supremacy, collaborated with the corresponding political forces in Russia, deepening the split in the nation.
As a consequence of the unbalanced social development and the labour movement's continuous position in the political opposition, the Social Democratic Party had gained an absolute majority in the new Parliament of Finland, in the general parliamentary elections of 1916. The new Senate was formed in March 1917 by Social Democrat and trade union leader Oskari Tokoi. His cabinet did not reflect the assembly of the Finnish parliament, with the socialists' absolute majority. It comprised six representatives from the Social Democrats and six from non-socialist parties. In theory, the new Senate consisted of a broad national coalition, but in practice, with the main political groups unwilling to compromise and the most experienced politicians remaining outside it, the cabinet proved unable to solve any major local Finnish problems. After the First Russian Revolution of 1917 in February, real political power shifted to the street level in the form of mass meetings, strike organizations, and the street councils formed by workers and soldiers, and to active organizations of the employers, all of which served to undermine the authority of the state.
The rapid economic growth stimulated by World War I, which had raised the incomes of industrial workers and profits of the employers during 1915 and 1916, collapsed with the February Revolution. The consequent decrease in production and economy led to unemployment and high inflation. For those who had a job, the February revolution gave freedom to reach for resolving long-term problems of their laborious working life; the workers called for eight-hour-per-day working limits, better working conditions, and higher wages. The demands led to demonstrations and large-scale strikes in both industry and agriculture throughout Finland.
The food supply of the country depended on cereals produced in southern Russia, while the Finns had specialized in milk and butter production. The cessation of the cereal imports from disintegrating Russia led to food shortages in Finland. The Senate responded by introducing rationing and price controls. The farmers opposed the state control; a black market with sharply rising food prices formed and export to free market of the Petrograd area increased. Food supply, prices, and in the end the fear of starvation became emotional political issues between farmers and industrial workers, in particular the unemployed ones. The common people, their fears exploited by the politicians and the political media, took to the streets. Despite the food shortages, no large-scale starvation hit southern Finland before the war. Economic factors remained a supporting factor in the crisis of 1917, but only a secondary part of the power struggle of the state.
Battle for leadership.
The passing of the Tokoi Senate bill, called the "Power Act", in July 1917 became the first one of the three culminations of the power struggle between the Social Democrats and the conservatives during the political crisis from March 1917 to the end of January 1918. The fall of the Russian emperor opened the question of who would hold the highest political power in the former Grand Duchy. Although the Finns had accepted the liberating manifesto (from the period of 1908–1916) of March 1917 issued by the Russian Provisional Government, they planned at least an expansion of the former autonomy.
The February Revolution offered the Finnish Social Democrats momentum: they had the exceptional absolute majority in the Parliament and a narrow dominance in the Senate. After the decades of political disappointments, the Social Democrats had an opportunity to take power. Conservatives were alarmed by the continuous increase of the socialists' support during 1899–1916, which had climaxed in 1917 with their dominance in the Parliament and Senate, without the offsetting control of the Emperor and Russian administration; the socialists had to be halted before they were able to markedly alter the power structure of the country.
The "Power Act" incorporated a plan by the Social Democrats to substantially increase and concentrate the power of Parliament, as a reaction to the non-parliamentary and conservative leadership of the Finnish Senate between 1906 and 1916. The bill also furthered Finnish autonomy by restricting Russia's influence on domestic Finnish affairs: the Provisional Government of Russia would determine only the foreign and military policies of Finland. In Parliament, the bill was adopted with the support of the Social Democrats, the Agrarian League, and some rightist activists and other non-socialists eager for Finnish sovereignty. The conservatives opposed the bill and some of the most right-wing representatives resigned from Parliament.
In Petrograd, the Social Democrats' plan had the backing of Vladimir Lenin and the Bolsheviks, who by July 1917 were plotting a revolt against the Provisional Government. In the end, the Government still had the support of the Russian military; Lenin was thwarted during the "July Days" and forced to flee to Finland. As the Russians' war against Germany came increasingly closer to total defeat, the significance of the Finnish area as a buffer zone protecting Petrograd was highlighted, the Provisional Government disapproved the "Power Act" and sent more Russian Provisional Government troops to Finland. There, with the demands and co-operation of Finnish conservatives, the Finnish Parliament was dissolved and new elections announced. In the October 1917 elections, the Social Democrats lost their absolute majority, which radicalized the labor movement and decreased support for relying on parliamentary means of achieving its aims. The events of July 1917 did not bring about the Red Revolution in January 1918 on their own, but together with political development based on the labor movement's interpretation of the ideas of Fennomania and socialism since the 1880s, these events were decisive for the goals of a Finnish revolution. In order to win power, the socialists had to overcome the Finnish Parliament.
The collapse of Russia in the February Revolution resulted in a loss of institutional authority in Finland and the dissolution of the police force, creating fear and uncertainty. In response, both the right and left began assembling their own security groups, which were initially local and largely unarmed. By Autumn 1917, in the power struggle and vacuum following the dissolution of Parliament, and in the absence of a stable government or a Finnish army, such forces began assuming a paramilitary character. The Civil/White Guards were organized by local men of influence, conservative academics, industrialists, major landowners and activists, and were armed by the Germans. The Workers' Security/Red Guards were recruited through their local party sections and the labor unions, and were armed by the Russians.
October Revolution.
Vladimir Lenin's Bolshevik October/November Revolution on 7 November transferred political power in Petrograd to the radical, left-wing socialists. In the end, the German Empire's intrigue, based on idea that Lenin was the most powerful weapon they could launch against Russia, to finance the Bolsheviks and arrange safe conduct of Lenin and his comrades from exile in Switzerland to Petrograd in April 1917, was a success. An armistice between Germany and the Bolshevik regime came into force on 6 December and peace negotiations began on 22 December 1917 at Brest-Litovsk.
November 1917 saw the second turning point in the 1917–1918 rivalry for the leadership of Finland. After the dissolution of the Finnish Parliament, polarization between the Social Democrats and Conservatives increased dramatically, including political violence. An agricultural worker was shot during a local strike on 9 August at Ypäjä and a Civil Guard member was killed in aftermath of local political crisis at "Malmi" on 24 September 1917. After the October 1917 Parliamentary elections, non-socialists established an informal truce with the Russian Provisional Government. The situation was disrupted by the October Revolution; the new Finnish Parliament took power on 15 November, on the model of the "Power Act" of the socialists, and promptly accepted the Social Democratic proposals from July 1917 for an eight-hour working day and universal suffrage in local elections.
On 27 November the conservatives tried to hold onto power with the appointment of a purely conservative cabinet, led by Pehr Evind Svinhufvud. The government decided to separate Finland from Russia and strengthen the military power of the Civil Guards. The first Finnish Jägers and German weapons arrived in Finland in October–November 1917, on a ship "Equity" and a German U-boat (SM UC-57). There were around 50 Jägers in Finland by the end of 1917. Finnish conservatives were concerned of German-Russian armistice and peace negotiations, fearing they would restrict Germany's ability to provide assistance to the Whites. Germans agreed to sell 70,000 rifles, 70 machine guns and artillery to the White Guards and arrange the safe return of the Jäger battalion to Finland. There were 149 Civil-White Guards in Finland (local units in towns and rural communes) on 31 August 1917, 251 on 30 September, 315 on 31 October, 380 on 30 November 1917 and 408 on 26 January 1918. The first attempt at serious military training among the Civil Guards was the establishment of a 200-strong "cavalry school" at the Saksanniemi estate, in the vicinity of the town of Porvoo, in September 1917.
After the political defeats in July and October 1917, on 1 November the Social Democrats put forward an uncompromising program called "We Demand" in order to push for political concessions. They demanded annulment of the result of the October Parliamentary elections and disbanding of the Civil Guards, which the right refused. Following the October Revolution, Finnish socialists planned to ask the Bolsheviks for acceptance of Finland's sovereignty in a manifesto on 10 November, but the uncertain situation in Petrograd stalled it. After the "We Demand" program had failed, the socialists initiated a general strike on 14–19 November 1917. The moderate left aimed to put political pressure on the non-socialists to include a large number of socialists in the new Finnish Senate.
Revolution had been the goal of the radical left since the loss of the political power in July and October 1917, and November 1917 seemed to offer momentum for a revolt. At this phase, Lenin and Joseph Stalin among others, under threat in Petrograd, urged the Social Democrats to seize power in Finland, which was an important defensive area against the German threat and a vital backup zone for the Bolsheviks in and around Petrograd. The majority of Finnish socialists were moderate and preferred parliamentary methods, prompting Lenin to label them "reluctant revolutionaries." This reluctance diminished as the general strike appeared to take effect; the strike leadership voted by a narrow majority to seize power on 16 November, but the proposed revolution had to be called off the same day, due to lack of true revolutionaries for executing the decision.
The moderate socialists won a repeated vote over revolutionary versus parliamentary means at a special party meeting in the end of November 1917, but when they tried to pass a resolution to completely abandon the idea of a socialist revolution in Finland, the party representatives voted it down. The Finnish labor movement wanted thus to sustain a military force of its own and keep the revolutionary road open too. The repercussions of these events had an effect on near future of the movement, with several powerful leaders staking positions within the moderate and radical party members. The Finnish socialists' lack of interest in revolutionary activity was a disappointment to Lenin. He lost his faith in them finally in December 1917 and shifted his energies toward encouraging the Finnish Bolsheviks in Petrograd.
Among the labor movement, a more marked consequence of Autumn 1917 was the rise of the Workers' Guards. There were approximately 20–60 Guards of the Working class in Finland between 31 August and 30 September 1917, but on 20 October, after the defeat in the October Parliamentary elections, the Finnish Labor Union proclaimed the need to establish more Guards in the country. The announcement led to a rush of recruits to the Guards; on 31 October their number was 100–150, 342 on 30 November 1917 and 375 on 26 January 1918. There were two parts to the Workers' Guards since May 1917, most of them being Security Guards. The minority were Red Guards; partly secret groups formed in industrialized towns and industrial centres including Helsinki, Kotka, Tampere, Turku, Viipuri and the Kymenlaakso area, on the model of the domestic Red Guards built up during 1905–1906 in Finland.
The presence of the two opposing armed forces in Finland, the Red and the White Guards, imposed a state of dual power and multiple sovereignty on Finnish society, typically the prelude to a civil war. The decisive cleavage between the two guards broke out during the general strike, when the radical elements of the Red Guards and Workers' Security Guards executed several political opponents in the main cities of southern Finland, and the first armed clashes between White Guards and Workers' Guards broke out; in total 34 casualties were reported. In the end, the political rivalries of 1917 led to a race for weapons and an escalation towards civil war.
Finnish sovereignty.
The disintegration of Russia offered the Finns a historic opportunity to gain independence, but after the October Revolution, the positions of the conservatives and the Social Democrats on the sovereignty issue became reversed. The right was now eager for secession from Russia as it would assist them in controlling the left and in minimizing the influence of revolutionary Bolsheviks. The Social Democrats tried to increase liberty of the Finns since the spring 1917, but now they could not use it for the direct political benefit of their party, and had either to adjust to the right's dominance or try to change everything via a revolution. Nationalism had become a "civic religion" among the Finns by the end of the 19th century, but their main goal, particularly during the first period of Russification and the general strike in 1905, was a return to the autonomy of 1809–1898, not independence. Since 1809, under the less uniform Russian rule, the domestic power of the Finns increased substantially, compared to the unitary Swedish regime. In economy the Grand Duchy benefited from an independent domestic state budget, its own currency (the markka, since 1860) and customs organization, and the industrial progress during 1860–1916. The economy of the Grand Duchy was dependent on the huge Russian market, and separation from Russia would create a risk of losing Finland's preferred position. The economic collapse of Russia and the political power struggle of the Finnish state during 1917 were among the key factors that brought sovereignty to the fore in Finland.
P.E. Svinhufvud's Senate proposed Finland's declaration of independence, which the Parliament adopted on 6 December 1917. The Social Democrats voted against the Svinhufvud proposal while presenting an alternative declaration of independence containing no substantial differences. The socialists feared a further loss of support (as in the October elections) among nationalistic commoners and hoped to gain a political majority in the future. They sent two delegations during December 1917 to Petrograd to ask Lenin to approve Finnish independence. Both political groups agreed on the need for Finnish sovereignty, despite strong disagreement on the selection of its leadership.
The establishment of an independent state was not a foregone conclusion for the small Finnish nation; recognition by Russia and the major European powers was essential. Three weeks after the declaration of independence, Svinhufvud's cabinet concluded, under pressure from Germany, that it would have to negotiate with Lenin for Russian recognition. In December 1917 the Bolsheviks were themselves under intense pressure from the Germans to conclude peace negotiations at Brest-Litovsk, and Russia Bolshevism was in deep crisis, with a demoralized army and the fate of the October Revolution in doubt. Lenin calculated that the Bolsheviks could perhaps hold central parts of Russia but would have to give up some territories on its periphery, including Finland in the geopolitically less important north-western corner. As a result, Svinhufvud and his senate delegation won Lenin's concession of sovereignty on 31 December 1917.
By the beginning of the Civil War, Austria-Hungary, Denmark, France, Germany, Greece, Norway, Sweden and Switzerland had recognized Finnish independence. The United Kingdom and United States did not approve it; they were standing by and following political and military relations between Finland and the German empire the main enemy of the Allies, which hoped to override Lenin's regime, and get Russia back into the war against Germany. As to Finland's separation from Russia, Germany had hastened it, in order to get Finland within the German sphere of power. France broke off diplomatic relations to the White government later, during the war of 1918, as a consequence of White Finland's co-operation with Germany.
Warfare.
Escalation.
The final escalation towards war began in early January 1918, as each military or political act of the Reds or the Whites resulted in a corresponding counteraction by their opponents. Both sides justified these acts as defensive measures, particularly to their own supporters. On the left, the vanguard of the war of 1918 was the most radical urban Red Guards and Workers' Security Guards from Helsinki, Kotka and Turku; they led the rural Reds, and convinced those leaders of the Social Democrats who wavered between peace and war to support revolution. On the right, the vanguard of the war was the Finnish "Jägers" who had been moved to Finland by the end of 1917, and the most active volunteer White Guards of Viipuri province in the southeastern corner of Finland, southwestern Finland and southern Ostrobothnia.
The Svinhufvud Senate and the Parliament decided on 12 January 1918 to create a strong police authority, an initiative which the Red Guards saw as a step towards legalizing the White Guards. On 15 January, Carl Gustaf Emil Mannerheim, a former, competent, general of the Imperial Russian Army, was appointed supreme commander of the White Guards, and on 25 January the Senate renamed the White Guards the Finnish White Army. The Red Guards, led by Ali Aaltonen, refused to recognise the title, and decided to establish a military authority of their own. Mannerheim established a major power base in Vaasa-Seinäjoki area, while Aaltonen located that of the Reds in Helsinki. The third and final culmination of the power struggle between the Finns and the disintegration of Finnish society had begun.
The first serious local battles were fought during 9–21 January in southern and southeastern Finland, mainly to win the race for weapons and for control of the vital southeastern town of Viipuri. The White order to engage was issued on 25 January. The Whites gained weaponry by disarmament of Russian garrisons during 21–28 January, in particular in southern Ostrobothnia. The Red Order of Revolution was issued on 26 January 1918, and a red lantern, symbolic indicator of the coup d'état, was lit in the tower of the Helsinki Workers' Hall. The large scale mobilization of the Reds began in the late evening of 27 January, but the Helsinki Guard and some of the Guards located along the Viipuri-Tampere railway became active on 23–26 January, in order to safeguard vital positions and escort a heavy railroad shipment of Bolsheviks' weapons from Petrograd to Finland. White troops tried to capture the shipment; 20–30 Finns, Red and White, died in the "Battle of the Rahja Trains" in the Karelian Isthmus on 27 January 1918.
Finland divided into White and Red.
At the beginning of the war, a discontinuous front line ran through southern Finland from west to east, dividing the country into White Finland and Red Finland. The Red Guards controlled the area to the south, including nearly all the major towns and industrial centres, and the largest estates and farms with high numbers of crofters and tenant farmers. The White Army controlled the area to the north, which was predominantly agrarian with small or medium-sized farms and tenant farmers, and where crofters were few, or held a better social position than in the south. Enclaves of the opposing forces existed on both sides of the front line: within the White area lay the industrial towns of Varkaus, Kuopio, Oulu, Raahe, Kemi and Tornio; within the Red area lay Porvoo, Kirkkonummi and Uusikaupunki. The elimination of these strongholds was a priority for both armies in February 1918.
Red Finland, called also the Finnish Socialist Workers' Republic, was led by the People's Delegation, established on 28 January, in Helsinki. The delegation sought democratic socialism based on the Finnish Social Democratic ethos; their visions differed from Lenin's dictatorship of the proletariat. Otto Ville Kuusinen formulated a proposal for a new constitution, influenced by those of Switzerland and the United States. Political power was to be concentrated to Parliament, with a lesser role for Senate. The proposal included a multi-party system, freedom of assembly, freedom of speech and press, and the use of referenda in political decision making. In order to ensure the power of the labour movement, the common people would have a right to "continuous revolution". The Reds' plans concerning private property rights were in conflict with their plans for an "ultrademocratic" and free society; the state and local administration of municipalities would have had true property rights. In agriculture the crofters were liberated from the control of the landowners at the beginning of the war, but they were allowed a right of containment of the farms under the plans of a later general socialization in the country. All these plans, including the new constitution, remained unfulfilled, as the Reds lost the 1918 war.
In foreign policy Red Finland leaned on Bolshevist Russia. A Finnish-Russian Red treaty and peace agreement was signed on 1 March 1918. The negotiations for the treaty revealed, that, as in World War I in general, nationalism was more important for both sides than the principles of international socialism. The Red Finns did not accept alliance with the Bolsheviks and major disputes appeared e.g. over demarcation of the border between Red Finland and Soviet Russia. The bargaining sides exchanged land areas; an artillery base, Ino, located in the Karelian Isthmus, was transferred to Russia, while Finland received Petsamo in north-eastern Lapland. The significance of the Russian-Finnish Treaty evaporated soon, due to the signing of the Treaty of Brest-Litovsk between the Bolsheviks and the German Empire on 3 March 1918.
V. I. Lenin's policy of the right of nations to self-determination aimed at preventing the disintegration of Russia during its period of military weakness. He tried to utilize the power vacuums and political rivalries commonly formed inside fledgling nations as they separated from major, splintering countries. Lenin expected that in the political circumstances of Europe at the time, the proletariat of free nations would carry out socialist revolutions, and unite with Soviet Russia later. The majority of the Finnish labor movement supported Finland's independence. The Finnish Bolsheviks, influential though few in number, favoured annexation of Finland by Russia. The question of annexation, in the aftermath of WWI, was resolved by the defeat of Red Finland and weakness of Russia.
The government of White Finland, Pehr Evind Svinhufvud's first senate, was called "the Vaasa Senate" after relocation to the west-coast city of Vaasa, acting as the capital of the Whites from 29 January to 3 May. In domestic policy the White Senate's main goal was to return the political right to power in Finland. The conservatives planned a monarchist political system, with a lesser role for Parliament. A section of the conservatives had always been against democracy; others had approved parliamentarianism since the revolutionary reform of 1906, but after the crisis of 1917 and the outbreak of the 1918 war, had concluded that empowering the common people would not work. Social liberals and reformist, moderate non-socialists opposed any restriction of parliamentarianism. They initially resisted German military help, but the prolonged warfare changed their stance.
In foreign policy, the Vaasa Senate leaned on the German Empire for military and political aid, in order to defeat the Finnish Red Guards, end the influence of Bolshevist Russia in Finland, and expand Finnish territory to Russian Karelia, which held geopolitical significance, and was home to people speaking Finno-Ugric languages (Irredentist campaigns/Heimosodat). The weakness of Russia induced an idea of Greater Finland among the expansive factions of both the right and left; the Reds had claims concerning the same areas. General Mannerheim agreed on the need to take over eastern Karelia and for German weapons, but opposed German intervention in Finland. Mannerheim recognized the lack of combat skills of the Finnish Red Guards, and he leaned on the high military skills of the Finnish Jägers. As a former Russian army officer, Mannerheim was well aware of the demoralization of the Russian army. He co-operated with White Russian officers in Finland and Russia.
The competing parties' war propaganda aimed to prove their support of democracy and liberty and their ability to represent the whole Finnish nation. Both failed by allowing the political crisis to end up in the bloody Civil War and a comprehensive terror, instead of reaching a compromise to accomplish a peaceful political settlement.
Soldiers on rails.
The number of Finnish troops on each side varied from 70,000 to 90,000; both sides had around 100,000 rifles, 300-400 machine guns and a few hundred cannons. While the Red Guards consisted mostly of volunteers (wages paid at the beginning of the war), the White Army contained only 11,000–15,000 volunteers, the remainder being conscripts. The main motives for volunteering were economic factors (salary, food), idealism, and peer pressure. The Red Guards included 2,000 female troops, mostly girls recruited from the industrial centres of southern Finland. Urban and agricultural workers constituted the majority of the Red Guards, whereas land-owning farmers and well-educated people formed the backbone of the White Army.
Both armies used child soldiers, mainly between 14 and 17 years of age. The usage of juvenile soldiers was not rare in World War I; children of that time were under the absolute authority of adults and generally were not shielded against exploitation. In the Finnish case, chaotic conditions, particularly at the start of the war, provided an additional reason to recruit child soldiers; military leaders took whoever they could get their hands on. In the Red Guards there was also the chance for salary and food supplies.
The Finnish Civil War was fought primarily along the railways, the vital means of transporting troops and supplies. One of the most important objectives for both Guards was the seizure of Haapamäki, a railway junction northeast of Tampere which connected both western-eastern and southern-northern Finland. The Whites captured the junction at the end of January 1918, leading to fierce battles at Vilppula. The Whites' bridgehead south of the River Vuoksi at Antrea on the Karelian Isthmus threatened the railway connection Viipuri-Petrograd also. The other vital railway junctions during the war were Kouvola, Riihimäki, Tampere and Toijala. The significance of the railways is well symbolized by the most frightening weapon used in the turmoil: armoured train, carrying light cannons and heavy machine guns.
Red Guards and the Russian troops.
The Finnish Red Guards seized the early initiative in the war, taking control of Helsinki on 28 January, and with a general attack phase lasting from February till early March 1918. The Reds were relatively well armed, but a chronic shortage of skilled leaders, both at command level and in the field, left them unable to capitalize on their initial momentum, and most of the offensives finally came to nothing. For the Red Guards, the military hierarchy and implementation of orders functioned effectively only at company and platoon level; even there, leadership and authority were weak, as most company and platoon commanders were chosen by the vote of the troopers. The Red troopers were not professional soldiers but armed civilians, whose military training, discipline and combat morale were mostly both inadequate and low.
Ali Aaltonen found himself rapidly replaced in command of the Red troops by Eero Haapalainen, who in turn was replaced by the triumvirate of Eino Rahja, Adolf Taimi and Evert Eloranta. The last commander of the Red Guards was Kullervo Manner, who led the final retreat into Russia. Some talented men with a high sense of responsibility such as Hugo Salmela rose up to take the lead, but they could not change the course of the war. The Red Guards achieved victories, only at local level, as they retreated from southern Finland towards Russia; they won German troops in the fierce battles on 28–29 April 1918 at Hauho and Tuulos, Syrjäntaka, where female Red Guard platoons played a combat role.
Although some 60,000 Russian soldiers of the former Czar's army remained stationed in Finland at the start of the Civil War, the Russian contribution to the Red Guards' cause was to prove negligible. When the conflict began, Lenin tried to commit the army on behalf of Red Finland, but the troops were demoralized, war-weary and home-sick after years of World War I. The majority of the soldiers had returned to Russia by the end of March 1918. As a result, only 7,000 to 10,000 troops participated in the Finnish Civil War, of which no more than 4,000, in separate smaller units of 100–1,000 men, could be persuaded to fight in the front line. The Russian revolutions split the Russian army officers politically and their attitude toward the Finnish civil war varied; Mikhail Svechnikov led Finnish Red troops in western Finland in February and "Konstantin Yeremejev" the Russian forces in the Karelian Isthmus, while other officers were mistrustful of their revolutionary underlings and co-operated with their former colleague General Mannerheim, assisting the Whites in the disarmament of the Russian garrisons in Finland. On 30 January 1918 General Mannerheim proclaimed to Russian soldiers in Finland that the White army did not fight against Russia: the goal of the White campaign was to beat the Finnish Red rebels and the Russian troops supporting them.
The number of Russian soldiers active in the Civil War declined markedly once Germany attacked Russia on 18 February 1918. The German-Russian Treaty of Brest-Litovsk of 3 March, effectively restricted the Bolsheviks' ability to support the Finnish Red Guards with anything more than weapons and supplies. The Russians remained active on the south-eastern front, defending the approaches to Petrograd.
White Guards and Sweden's role.
While the conflict has been called by some "The War of the Amateurs", the White Army had two major advantages over the Red Guards in the war: the professional military leadership of General Mannerheim and his staff—which included 84 Swedish volunteer officers and former Finnish officers of the Czar's army—and 1,450 soldiers of the 1,900-strong, elite Jäger "(Jääkärit)" battalion. This battalion was trained in Germany during 1915–1917, and battle-hardened on the Eastern Front. The main part of the battalion arrived in Vaasa on 25 February 1918. On the battlefield the Jägers provided strong leadership that made disciplined action by the common White soldiers possible. The White troopers were similar to those of the Red Guards: most of them had brief and inadequate training. At the beginning of the war, the leadership of the White Guards had little authority over volunteer White Guard platoons and companies, which obeyed only their dominant, local leaders. In the end of February, the Jägers started rapid training of six Jäger Regiments, with conscripts.
Even the Jäger battalion was divided in the same way that the rest of the country was: 450 mostly socialist soldiers of the unit remained stationed in Germany as they could have chosen the Red side in the conflict. The leaders of the White Guards faced a similar problem with drafting young men to the army in February 1918: 30,000 obvious supporters of the Finnish labor movement never showed up. The White Guard leadership was also uncertain whether common troopers drafted from the small-sized and poor farms of central and northern Finland had strong enough motivation to fight the Finnish Reds. Accordingly, the propaganda of the Whites promoted a nationalist war against the Red, Bolshevist Russians, and belittled the significance of the Red Finns. Social divisions did appear both between southern and northern Finland and within rural Finland. The economy and society of the north had modernized more slowly than those of the south, there was a more pronounced conflict between Christianity and socialism in the north, and farmland had a major social status; ownership of even a small parcel of land created a motivation to fight against the Reds.
Sweden declared neutrality during WWI and the Finnish Civil War. The general opinion, in particular among the Swedish elite was divided between supporters of the Allies and the Central powers, Germanism being somewhat more popular. Three war-time priorities determined pragmatic policy of the Swedish liberal-social democratic government; sound economics, via export of iron-ore and foodstuff to Germany, sustaining tranquility of the Swedish society and geopolitics. The government accepted participation of Swedish volunteer officers and soldiers in the Finnish Civil War, on the White side, in order to block expansion of revolutionary unrest to Scandinavia. A 800–1,000-strong "Swedish Brigade", led by Hjalmar Frisell, took part in the battles of Tampere and those fought in the area south of the town. In February 1918, the Swedish Navy escorted the German naval squadron, transporting Finnish Jägers and German weapons, and allowed it to pass through Swedish territorial waters. The Swedish socialists did not aid the Finnish Reds but tried to open peace negotiations between the Whites and Reds. The weakness of Finland gave Sweden a chance to take-over geopolitically vital Finnish Åland islands, east of Stockholm, but the German army's Finland-operation stalled the plan.
Battle of Tampere.
In February 1918 General Mannerheim weighed the question of where to focus the general offensive of the Whites, between two strategically vital enemy strongholds: Tampere, Finland's major industrial town in the south-west, and Viipuri, Karelia's main city. Although seizing Viipuri offered major advantages, the lack of combat skills of his army and potential for a major counterattack by the enemy in the area or in the south-west made it too risky.
Mannerheim decided to strike first at Tampere. He launched the attack on 16 March at Längelmäki, 65 km north-east of the town. At the same time, the White Army began advancing along a northern and north-western frontline, through Vilppula–Kuru–"Kyröskoski"–Suodenniemi. Many Red Guard units collapsed and retreated in panic under the weight of the assault, while some detachments defended their posts relentlessly, and were able to slow the advance of the White Guards, who were unaccustomed to offensive warfare. Eventually, the Whites lay siege to Tampere. They cut off the Reds southward connection in Lempäälä on 24 March and westward in "Siuro" (Nokia, Finland) and Ylöjärvi on 25 March.
The battle for Tampere was fought between 16,000 White and 14,000 Red soldiers. It was Finland's first large scale urban battle, and, along with the battles of Helsinki and Viipuri, one of the three decisive military engagements of the 1918 war. The fight for the Tampere town area began on 28 March, on the eve of Easter 1918, later called the "Bloody Maundy Thursday", in the Kalevankangas graveyard. After this fierce combat, won by the Whites, with more than 50% losses in some of the attacking units, the White army re-organized the troops and plans, and attacked the town centre, in the early hours of 3 April. After a heavy, concentrated artillery barrage, the White Guards began advancing from house to house and street to street, as the Red Guards retreated. In the late evening of 3 April the Whites reached the eastern river banks of Tammerkoski. The Reds' major attempts to break the siege of Tampere from outside, along the Helsinki-Tampere railway, failed. The Red Guards lost the western parts of the town between 4 and 5 April. The Tampere City Hall was among the last strongholds of the Red troops. The battle ended 6 April 1918 with the surrender of Red forces in the Pyynikki and Pispala sections of Tampere.
In the battle, the Reds, now on the defensive, had shown markedly increased motivation to fight. General Mannerheim had been compelled to deploy parts of his best trained detachments, the fresh Jäger regiments, which he had initially hoped to conserve for later use in the Viipuri area. The fighting in Tampere was purely a civil war—Finn against Finn, "brother rising against brother"—as most of the Russian army had retreated to Russia in March and the German troops had yet to arrive in Finland. The Battle of Tampere was the bloodiest action of the Civil War. The White Army lost 700–900 men, including 50 Jägers, the highest number of deaths the former Jäger battalion suffered in a single battle of the 1918 war. The Red Guards lost 1,000–1,500 soldiers, with a further 11,000–12,000 captured. 71 civilians died, mainly due to artillery fire. The eastern parts of the city, consisting mostly of wooden buildings, were destroyed completely.
After their defeat in Tampere, the Red Guards began a slow retreat eastwards. As the German army seized Helsinki, the White Army shifted its military focus to Viipuri, taking it on 29 April 1918 with a major attack of 18,500 men, against 15,000 Red troopers. 500–800 Reds died, and 12,000–15,000 were imprisoned.
German intervention.
The German Empire intervened in the Finnish Civil War on the side of the White Army in March 1918. The Finnish Activists leaning on Germanism had been seeking German aid in freeing Finland from Russian hegemony since Autumn 1917, but the Germans did not want to prejudice their armistice and peace negotiations with Russia because of the pressure they were facing at the Western front. The German stance was altered radically after 10 February when Leon Trotsky, despite the weakness of the Bolsheviks' position, broke off negotiations, hoping revolutions would break out in the German Empire and change everything. The German government promptly decided to teach Russia a lesson and, as a pretext for aggression, invited "requests for help" from the smaller countries west of Russia. Representatives of White Finland in Berlin duly requested help on 14 February; on 13 February the German Imperial Military Council had made the decision to send troops to Finland.
The Germans attacked Russia on 18 February; the offensive led to a rapid collapse and retreat of the Russian troops and to signature of the first Treaty of Brest-Litovsk by the Bolsheviks on 3 March 1918. Finland, the Baltic countries, Poland and Ukraine were transferred to the German power sphere. The economic and political investments that Germany had made in Vladimir Lenin had paid off. The German army did not alter its military plans concerning Finland after the peace treaty with the Bolsheviks because the Civil War of the Finns had opened an easy access with low costs to Fennoscandia, where the geopolitical status altered as troops of a British Naval squadron invaded the harbour of Murmansk on the northwestern coast of Russia by the Arctic Ocean on 9 March 1918.
On 5 March a German naval squadron landed in the southwestern archipelago of Finland, on the Åland Islands, which the Swedish military expedition had taken over in mid-February. On 3 April 1918, the 10,000-strong Baltic Sea Division, led by Rüdiger von der Goltz, launched the main attack, west of Helsinki at Hanko, followed on 7 April by the 3,000-strong Detachment Brandenstein taking the town of Loviisa on the south-eastern coast. The main German formations advanced rapidly eastwards from Hanko and took Helsinki on 12–13 April. The "Brigade Brandenstein" overran the town of Lahti on 19 April, cutting the connection between the western and eastern Red Guards. The main German detachment advanced northwards from Helsinki and took Hyvinkää and Riihimäki on 21–22 April, followed by Hämeenlinna on 26 April. The efficient performance of the German top detachments contrasted strikingly with that of the demoralized Russian troops. The final blow to the cause of the Finnish Reds was dealt when the Bolsheviks broke off the peace negotiations at Brest-Litovsk, leading to the German eastern offensive in February 1918.
Battle of Helsinki.
After peace talks between the Germans and the Finnish Reds were broken off on 11 April, the true battle for the capital of Finland began. On 12 April, at 5 a.m. 2,000–3,000 German soldiers from the "Brigade von Tshirsky" attacked the city from the north-west, supported via the Helsinki-Turku railway. The Germans broke through the area between Munkkiniemi and Pasila, and advanced on the central-western parts of the town. The German naval squadron Meurer blocked the city harbour, bombarded the southern town area, and landed naval troops at Katajanokka. Around 7,000 Finnish Reds defended Helsinki, but their best troops fought on the main fronts of the war. The main strongholds of the Red defence were the Workers Hall, the Railway station, the Red Headquarters of "Smolna" (the former palace of the Russian governor-general, in southern Esplanade), the Senate-University area, and the former Russian garrisons in Helsinki. By the late evening of 12 April most of the major southern parts and all the western area of the city had been occupied by the Germans, who cleared the city house by house, street by street. Local Helsinki White Guards, hidden in the city during the war, joined the battle as the Germans advanced through the town. On 13 April German troops took over the Market Square, "Smolna", the Presidential Palace, and the Senate-Ritarihuone area. Toward the end, the "Brigade Wolff" with 2,000–3,000 soldiers joined the battle. The units rushed from north to the eastern parts of Helsinki, pushing into the working-class neighborhoods of Hermanni, Kallio and Sörnäinen. German artillery bombarded and destroyed the Helsinki Workers' Hall, and put out the Red lantern of the Finnish revolution. The eastern parts of the town surrendered around 2 p.m., 13 April; a white flag was raised in the tower of the Kallio Church, but sporadic fighting lasted until the evening. In total, 60 Germans, 300–400 Reds and 23 White Guard troopers were killed in the battle. Around 7,000 Reds were captured. The German army celebrated the victory and demonstrated its might with a major military parade in the centre of Helsinki on 14 April 1918.
Red and White terror.
During the civil war, the White Army and the Red Guards both perpetrated acts of terror, called the "Red terror" and "White terror". The threshold of political violence had been crossed in the primarily peaceful Grand Duchy of Finland during the first period of Russification 1899–1905; the Finnish Activists murdered a Russian governor-general, police officers and a Finnish civil servant. World War I enhanced the potential of terror as it was widespread between the Allies and the Central Powers. The February Revolution in 1917 initiated a comprehensive terror in Finland; the Russian army common soldiers murdered several Russian army officers in March 1917. The first Finnish socialist victim was killed at the beginning of August and the first non-socialist victim was killed at the end of September 1917. The general strike in November 1917 led to a marked political terror; the Workers' Guards murdered 27 Finns.
During the war of 1918 there were two kinds of Red and White political violence: (i) a calculated part of the general warfare, (ii) local, personal murders and corresponding acts of revenge. In the former, the highest staffs of both sides planned and organized these actions and gave orders to the lower level. At least a third of the Red terror and most of the White terror was centrally led. At first the governments of White Finland and Red Finland officially opposed acts of terror, but such operational decisions were made at the military level. The main purpose of the Red and White terror was to destroy the power structure of the opponent, clear and secure the areas governed by the armies since the beginning of the war and the areas seized and occupied by the common units during the conflict. Another goal of the terror was to create shock and fear among the civil population and the opposing soldiers. The common troopers' paramilitary nature and lack of combat skills, in the both armies, led and created the opportunity to use terror as a military weapon. Terror achieved some of the intended military objectives, but also gave additional motivation to each side to fight against an enemy perceived to be inhuman and cruel. The propaganda of the Reds and Whites utilized the terror acts of the opponent effectively, which increased the local political violence and the spiral of revenge.
The number of casualties and the timing of the terror differed markedly between the Reds and Whites.
The level of killings by the Red Guards varied over the months because the Reds could never seize and occupy new areas outside Red Finland, and they had to focus their efforts on the industrialized southern Finland, where they faced the establishment of Finland, and because in the end the Reds retreated from southern Finland. The Red Guards were less organized than the White army in respect to the political terror. The level of killings by the Whites varied over the months of the war because they occupied southern Finland, and initially did not encounter marked resistance from the area of White Finland. The comprehensive White terror started with the general offensive of the Whites in March 1918, increased constantly, culminated in the end of the war, and ceased soon after the enemy had been sent to the prison camps.
The Red Guards executed the representatives of economic and/or social power in Finland, including politicians, major landowners, industrialists, police officers, civil servants, teachers, and leaders and members of the White Guards. Ten priests of the Evangelical Lutheran Church of Finland and 90 (moderate) socialists were executed also. The two major sites of the Red terror were Toijala and Kouvola. There 300–350 Whites were executed between February and April 1918.
The White Guards executed Red Guard and party leaders, Social Democratic representatives of the Finnish parliament and local Red administrations, members of the Red tribunals and police, and common troopers of the Red Guards, and those who had participated in a way or another to the Red Terror. During the peak of the White terror, between the end of April and the beginning of May, 200 Reds were shot per day. The White terror hit particularly strong against the Russian soldiers who fought with the Finnish Red Guards, and several Russian non-socialist civilians were executed in the aftermath of the Battle for Viipuri.
Most of the terror was undertaken by "flying detachments" deployed by the both armies. These were cavalry units, usually consisting of 10 to 80 soldiers aged 15 to 20, under the absolute authority of an experienced adult leader. The detachments, specialising in search-and-destroy operations behind the front lines and during and after battles, have been described as death squads. They resembled German "Sturmbattalions" and Russian "Assault units" organized during WWI.
In total, 1,650 Whites died in the "Red terror" and 10,000 Reds perished in the "White terror". The White victims have been recorded quite exactly, but there are questions and permanent uncertainty about the Red victims of the terror. It is unclear which of the victims died in the battles and which of them were executed immediately after the battles. Together with the prison camp experiences of the Reds later in 1918, the terror caused the deepest mental wounds and scars of the Civil War among the majority of the Finns regardless of their political allegiance. Some of those, who carried out the terror were seriously traumatized, a phenomenon that was later to become well-documented.
End.
After the defeat in Tampere and under the threat of invasion by the German division on the south coast, the People's Delegation retreated from Helsinki to Viipuri on 8 April. After the loss of Helsinki, most of them, only Edvard Gylling standing by his warriors, moved to Petrograd on 25 April 1918. The escape of the Red leadership made the ranks of the Red soldiers bitter and resentful. At the end of April, thousands of them, without true leadership, tried to flee to Petrograd from Red Finland, but the majority of the refugees were besieged by the White and the German troops. The Reds surrendered on 1–2 May in the Lahti area. The long caravans of the Reds included women and children, who experienced a desperate, chaotic escape with several human losses due to the attacks of the enemy. It was a "road of tears" for the Reds, for the Whites the long enemy caravans heading east was a victorious scene. The Red Guards' last stronghold in south-east Finland, the area between Kouvola and Kotka, fell by 5 May. The war of 1918 ended on 15 May, when the Whites took over Ino, a Russian coastal artillery base on the Karelian Isthmus, from the Russian troops. White Finland and General Mannerheim celebrated the victory with a large military parade in Helsinki on 16 May 1918.
The Red Guards had been defeated. The initially pacifist Finnish labour movement had lost the Civil War, several of its military leaders committed suicide and a majority of the Reds were sent to prison camps. The Vaasa Senate returned to Helsinki on 4 May 1918, but the capital was under the control of the German army. White Finland had become a protectorate of the German Empire. General Rüdiger von der Goltz was called "the true Regent of Finland." No armistice or peace negotiations were carried out between the Whites and Reds, and an official peace treaty in order to end the Finnish Civil War was never signed.
Aftermath.
Bitter legacy.
The Civil War was a catastrophe for Finland; around 36,000 people, 1.2 percent of the nation's total population, perished. The war left about 15,000 children orphaned. As is often the case during (civil) war, most of the deaths occurred outside the battlefields, in the terror campaigns and from the appalling conditions in the prison camps. Many Red Finland supporters fled to Russia at the end of the war and during the period that followed. The traumatic war deepened the divisions within Finnish society, many moderate-neutral Finns identifying themselves as "citizens of two nations."
The war of 1918 led also to disintegration within both socialist and the non-socialist factions. The power political shift toward the right caused a dispute between conservatives and liberals on the best system of government for Finland to adopt: the former demanded monarchy and restricted parliamentarianism, the latter demanded a Finnish republic with full-scale democracy and social reforms. In the conflict both sides justified their views both via political and legal grounds. The monarchists claimed that the law of 1772 constituting monarchy (from the Swedish period) was still in effect, the declaration of independence on 6 December 1917 determining only "a principle of republic," and the constitution had to be altered via the year 1772 law. They proposed a modernized monarchist constitution for Finland. The republicans argued that the law of 1772 lost its status in the February Revolution, the power and authority of the Russian Czar was assumed by the Finnish parliament through the proclamation of 15 November 1917 and Finnish republic was accepted in the declaration of independence. The republicans were able to postpone processing of the monarchists' proposal in the parliament, and in the end a new monarchist constitution was not accepted in Finland. The monarchists responded by applying directly the 1772 law to select a new monarch for the country.
A major consequence of the 1918 conflict was the breakup of the Finnish labour movement into three parts: moderate Social Democrats and left-wing socialists in Finland, and communists acting in Soviet Russia with the support of the Bolsheviks. The Social Democratic Party had its first official party meeting after the civil war on 25 December 1918, and the party proclaimed its commitment to parliamentary means and a moderate political program was composed, The Social Democrats disclaimed Bolshevism and communism. The leaders of Red Finland who had fled to Russia, on the other hand, established the Communist Party of Finland in Moscow on 29 August 1918. After the power struggle of 1917 and the bloody civil war, the former Fennomans and Social Democrats, who had supported "ultrademocratic" means in Red Finland, declared now to have committed to revolutionary Bolshevism-communism and to dictatorship of proletariat, under the control of V.I. Lenin.
A new conservative Senate, with a monarchist majority, was formed by JK Paasikivi in May 1918. All members of parliament who had taken part in the revolt were removed from office. This left only one Social Democrat later to be joined by two more. Accordingly, the parliament was named a "rump parliament." At the end of May 1918, the Senate asked the German troops to remain in the country. Overall, the 3 March Treaty of Brest-Litovsk had placed White Finland in the sphere of influence of the German Empire and the agreements signed with the Germans on 7 March 1918 in return for the military intervention had bound Finland politically, economically and militarily to Germany. In summer 1918 Germany proposed a further military pact, as a part of the plan to secure food products for the Germans and raw materials for their industry from eastern Europe and tighten their control over Russia. General Mannerheim resigned his post on 25 May after disagreements with the Senate about German hegemony over the country, and about his planned attacks on Petrograd to repulse the Bolsheviks, and to Russian Karelia. The Germans opposed these attacks under the peace treaties they had signed with Russia.
On 9 October, under pressure from Germany, the monarchist Senate and the rump parliament chose a German prince, Friedrich Karl, brother-in-law of German Emperor William II, to become the King of Finland. In the end, General Rüdiger von der Goltz had been able to utilize the power vacuum and the dual power formed within the Finns during 1917–1918, for the power political benefit of the German Empire. All of these measures diminished Finnish sovereignty. The Finns, both right and left, had achieved independence on 6 December 1917 without a gunshot, but then compromised that independence by allowing the Germans to enter the country without difficulty during the Civil War.
The economic condition of the country had deteriorated so drastically that recovery to pre-conflict levels was not achieved until 1925. The most acute crisis was in the food supply, already deficient in 1917, though starvation had at that time been avoided in southern Finland. The Civil War, according to the leaders of Red Finland and White Finland, would solve all past problems; instead it led to starvation in southern Finland too. Late in 1918, Finnish politician Rudolf Holsti appealed for relief to Herbert Hoover, the American chairman of the Committee for Relief in Belgium: Hoover arranged for food shipments and persuaded the Allies to relax their blockade of the Baltic Sea, which had obstructed food supplies to Finland, to allow the food in.
Prison camps.
The White Army and the German troops captured around 80,000 Red war prisoners, including 5,000 women, 1,500 children and 8,000 Russians. The largest prison camps were Suomenlinna, an island facing Helsinki, Hämeenlinna, Lahti, Riihimäki, Tammisaari (Ekenäs), Tampere and Viipuri. The Senate decided to keep the prisoners detained until each person's guilt could be investigated; a law for a "Tribunal of Treason" was enacted on 29 May 1918. The Tribunal did not meet all the standards of neutral justice, due to the mental atmosphere of White Finland after the war. In total 76,000 cases were examined and 68,000 Reds were convicted, primarily for complicity to treason; 39,000 got out on parole and mean punishment of the rest was 2–4 years in "penitentiary". 555 people were sentenced to death, of which 113 were executed. The trials revealed that also some innocent adults had been imprisoned.
Combined with the severe food shortage, the mass imprisonment led to high mortality rates in the camps, and the catastrophe was compounded by a mentality of punishment, anger and indifference on the part of the victors. Many prisoners felt that they were abandoned by their own leaders, who had fled to Russia. The physical and mental condition of the prisoners declined rapidly in May as food supplies had disrupted during the Red Guards' chaotic retreat in April, and a high number of Red prisoners had been sent to the less organized prison camps already during the first half of April in Tampere and Helsinki. As a consequence, in June 2,900 starved to death or died as a result of diseases caused by malnutrition and Spanish flu, 5,000 in July, 2,200 in August, and 1,000 in September. The mortality rate was highest in the Tammisaari camp at 34 percent, while in the others the rate varied between 5 percent and 20 percent. In total around 13,000 Finns perished (3,000–4,000 due to Spanish influenza). The dead were buried in mass graves near the camps.
The majority of the prisoners were paroled or pardoned by the end of 1918, after the change in the political situation. There were 6,100 Red prisoners left at the end of the year, 4,000 at the end of 1919 (3,000 pardoned in January 1920, at the same time civil rights were given back to 40,000 prisoners), 500 in 1923, and in 1927 the last 50 prisoners were pardoned by the Social Democratic government led by Väinö Tanner. In 1973, the Finnish government paid reparations to 11,600 persons imprisoned in the camps after the civil war. Several reasons for the long-term and relatively high support of communism in Finland can be found; for the civil war generation of the left, the traumatic hardships of the prison camps were decisive.
Compromise.
Just as the fate of the Finns was decided outside Finland in Saint Petersburg on 15 March 1917, so it was decided outside Finland again on 11 November 1918, this time in Berlin, as Germany accepted defeat in World War I. The grand plans of the German Empire had come to nothing, and revolution had spread among the German people due to lack of food, war-weariness, and defeat in the battles on the Western Front. General Rüdiger von der Goltz and the German troops left Helsinki on 16 December, and Prince Friedrich Karl, who had not yet been crowned, left his post on 20 December. Finland's status altered from a monarchist protectorate of the German Empire to an independent democratic republic, with a modernizing civil society. The system of government, the primary Constitution of Finland, was confirmed on 17 July 1919.
The first local elections based on universal suffrage in the history of Finland were held during 17–28 December 1918, and the first parliamentary election after the Civil War on 3 March 1919. The United States and the United Kingdom recognised Finnish sovereignty on 6–7 May 1919. The Western powers demanded establishment of democratic republics in post-war Europe in order to calm down the widespread revolutionary movements in Europe. The Finnish-Russian Treaty of Tartu (Russian-Finnish) signed on 14 October 1920 aimed to stabilize the political relations and settle the border line between the former Grand Duchy and its mainland.
At the beginning of 1919 a moderate Social Democrat, Väinö Voionmaa, wrote: "Those who still trust in the future of this nation must have an exceptionally strong faith. This young independent country has lost almost everything due to the war..." He was a vital companion for the leader of the reformed Social Democratic Party, Väinö Tanner. In April 1918, a social liberal, non-socialist, the eventual first president of Finland, K.J. Ståhlberg, elected 25 July 1919, wrote: "It is urgent to get the life and development in this country back on the path that we had already reached in 1906 and which the turmoil of war turned us away from." He was supported by Santeri Alkio, the leader of the Agrarian League. Alkio's party colleague Kyösti Kallio gave his "Nivala address" on 5 May 1918 saying: "We must rebuild a Finnish nation, which is not divided into the Reds and Whites...We must establish a democratic Finnish republic, where all the Finns can feel that we are true citizens and members of this society." In the end, many of the moderate Finnish conservatives followed the thinking of Lauri Ingman, who wrote in spring 1918: "A political turn more to the right will not help us now, instead it would strengthen the support of socialism in this country."
Together with the other broader-minded Finns, the new partnership constructed a Finnish compromise which eventually delivered stable and broad parliamentary democracy. This compromise was based both on the defeat of Red Finland in the Civil War and the fact that most of the political goals of White Finland had not been achieved. After the foreign forces left Finland, the militant factions of the Red and the White lost their backup, while the pre-1918 cultural and national integrity, and the legacy of Fennomania, stood out among the Finns. The weakness of both Germany and Russia after World War I empowered Finland and made a peaceful, domestic Finnish social and political settlement possible. The reconciliation led to a slow and painful, but steady, national unification. In the end, the power vacuum and interregnum of 1917–1919 gave way to the Finnish compromise. From 1919 to 1991, the democracy and sovereignty of the Finns withstood challenges from right-wing and left-wing political radicalism, the crisis of World War II, and pressure from the Soviet Union during the Cold War.
In popular culture.
Between 1918 and 1950s the mainstream of literature and poetry presented the 1918 war from the point of view of the White victors; e.g. "Psalm of the Cannons" (Finnish: Tykkien virsi) by Arvi Järventaus in 1918. In poetry, Bertel Gripenberg, who had volunteered for the White army, celebrated its cause in "The Great Age" (Swedish: Den stora tiden) in 1928 and V.A. Koskenniemi in "Young Anthony" (Finnish: Nuori Anssi) in 1918. The war tales of the Red side were kept in silence or hidden at home or inside spheres of the workers. The first neutral-critical books were written soon after the war: "Devout Misery" (Finnish: Hurskas kurjuus) written by the Nobel Laureate in Literature Frans Emil Sillanpää in 1919, "Dead Apple trees" (Finnish: Kuolleet omenapuut) by Joel Lehtonen in 1918 and "Home coming" (Swedish: Hemkomsten) by Runar Schildt in 1919. They were followed by Jarl Hemmer in 1931 with the book "A man and his conscience" (Swedish: En man och hans samvete) and Oiva Paloheimo in 1942 with "Restless childhood" (Finnish: Levoton lapsuus). Lauri Viita's book "Scrambled ground" (Finnish: Moreeni) from 1950, presented life and experiences of a worker family in Tampere in 1918, including a point of view of outsiders in the Civil War.
Between 1959 and 1962, Väinö Linna, in his trilogy "Under the North Star" (Finnish: Täällä Pohjantähden alla), described the Civil War and World war II from the point of view of the common people. Part II of Linna's work markedly opened the larger view and the tales of the Reds in the 1918 war, and it had a significant mental effect in Finland. At the same time, a new point of view for the war was opened by the books of Paavo Haavikko "Private matters"(Finnish: Yksityisiä asioita), by Veijo Meri "The events of 1918" (Finnish: Vuoden 1918 tapahtumat) and Paavo Rintala "My grandmother and Mannerheim" (Finnish: Mummoni ja Mannerheim), all published in 1960. In poetry Viljo Kajava, who had experienced the horrors of the Battle of Tampere at the age of nine, presented a pacifist view of the civil war in his "Poems of Tampere 1918" (Finnish: Tampereen runot) in 1966. The similar point of view, in the same battle, is emphasized in the novel "Corpse bearer" (Finnish: Kylmien kyytimies) by Antti Tuuri from 2007. Väinö Linna's trilogy turned the general tide, and several books were written mainly from the point of view of the Red side in 1918: e.g. "Tampere"-trilogy by Erkki Lepokorpi in 1977, "John" (Finnish: Juho) by Juhani Syrjä in 1998 and "The Command" (Finnish: Käsky) by Leena Lander in 2003. Kjell Westö's epic novel "Where We Once Went" (Swedish: Där vi en gång gått) published in 2006 deals with the Finnish civil war, following individuals and families from both the Red and the White sides of the spectrum, before, during and after the war period. Kjell Westö's book "Mirage 38" (Swedish: Hägring 38) from 2013 describes Finnish pre-World War II mental atmosphere and post-war traumas of the 1918 war. F.E. Sillanpää's, Väinö Linna's, Lauri Viita's, Jarl Hemmer's, Paavo Rintala's, Leena Lander's and Kjell Westö's stories have been utilized in motion picture and in theatre.

</doc>
<doc id="11773" url="https://en.wikipedia.org/wiki?curid=11773" title="Flynn effect">
Flynn effect

The Flynn effect is the substantial and long-sustained increase in both fluid and crystallized intelligence test scores measured in many parts of the world from roughly 1930 to the present day. When intelligence quotient (IQ) tests are initially standardized using a sample of test-takers, by convention the average of the test results is set to 100 and their standard deviation is set to 15 or 16 IQ points. When IQ tests are revised, they are again standardized using a new sample of test-takers, usually born more recently than the first. Again, the average result is set to 100. However, when the new test subjects take the older tests, in almost every case their average scores are significantly above 100.
Test score increases have been continuous and approximately linear from the earliest years of testing to the present. For the Raven's Progressive Matrices test, subjects born over a 100-year period were compared in Des Moines, Iowa, and separately in Dumfries, Scotland. Improvements were remarkably consistent across the whole period, in both countries. This effect of an apparent increase in IQ has also been observed in various other parts of the world, though the rates of increase vary.
There are numerous proposed explanations of the Flynn effect, as well as some skepticism about its implications. Similar improvements have been reported for other cognitions such as semantic and episodic memory. Recent research suggests that the Flynn effect may have ended in at least a few developed nations, possibly allowing national differences in IQ scores to diminish if the Flynn effect continues in nations with lower average national IQs.
Origin of term.
The Flynn effect is named for James R. Flynn, who did much to document it and promote awareness of its implications. The term itself was coined by Richard Herrnstein and Charles Murray, authors of "The Bell Curve". Although the general term for the phenomenon referring to no researcher in particular continues to be "secular rise in IQ scores", many textbooks on psychology and IQ testing have now followed the lead of Herrnstein and Murray in calling the phenomenon the Flynn effect.
Rise in IQ.
IQ tests are updated periodically. For example, the Wechsler Intelligence Scale for Children (WISC), originally developed in 1949, was updated in 1974, in 1991, 2003 and again in 2014. The revised versions are standardized based on the performance of test-takers in standardization samples. A standard score of IQ 100 is defined as the median performance of the standardization sample. Thus one way to see changes in norms over time is to conduct a study in which the same test-takers take both an old and new version of the same test. Doing so confirms IQ gains over time. Some IQ tests, for example tests used for military draftees in NATO countries in Europe, report raw scores, and those also confirm a trend of rising scores over time. The average rate of increase seems to be about three IQ points per decade in the United States, as scaled by the Wechsler tests. The increasing test performance over time appears on every major test, in every age range, at every ability level, and in every modern industrialized country, although not necessarily at the same rate as in the United States. The increase has been continuous and roughly linear from the earliest days of testing to the present. Though the effect is most associated with IQ increases, a similar effect has been found with increases in attention and of semantic and episodic memory.
Ulric Neisser estimated that using the IQ values of 1997 the average IQ of the United States in 1932, according to the first Stanford–Binet Intelligence Scales standardization sample, was 80. Neisser states that "Hardly any of them would have scored 'very superior', but nearly one-quarter would have appeared to be 'deficient.'" He also wrote that "Test scores are certainly going up all over the world, but whether intelligence itself has risen remains controversial."
Raven (2000) found that, as Flynn suggested, data interpreted as showing a decrease in many abilities with increasing age must be re-interpreted as showing that there has been a dramatic increase of these abilities with date of birth. On many tests this occurs at all levels of ability.
Some studies have found the gains of the Flynn effect to be particularly concentrated at the lower end of the distribution. Teasdale and Owen (1989), for example, found the effect primarily reduced the number of low-end scores, resulting in an increased number of moderately high scores, with no increase in very high scores. In another study, two large samples of Spanish children were assessed with a 30-year gap. Comparison of the IQ distributions indicated that the mean IQ-scores on the test had increased by 9.7 points (the Flynn effect), the gains were concentrated in the lower half of the distribution and negligible in the top half, and the gains gradually decreased as the IQ of the individuals increased. Some studies have found a reverse Flynn effect with declining scores for those with high IQ.
In 1987, Flynn took the position that the very large increase indicates that IQ tests do not measure intelligence but only a minor sort of "abstract problem-solving ability" with little practical significance. He argued that if IQ gains do reflect intelligence increases, there would have been consequent changes of our society that have not been observed (a presumed non-occurrence of a "cultural renaissance"). Flynn no longer endorses this view of intelligence and has since elaborated and refined his view of what rising IQ scores mean.
Precursors to Flynn's publications.
Earlier investigators had discovered rises in raw IQ test scores in some study populations, but had not published general investigations of that issue in particular. Historian Daniel C. Calhoun cited earlier psychology literature on IQ score trends in his book "The Intelligence of a People" (1973). R. L. Thorndike drew attention to rises in Stanford-Binet scores in a 1975 review of the history of intelligence testing.
Intelligence.
There is debate about whether the rise in IQ scores also corresponds to a rise in general intelligence, or only a rise in special skills related to taking IQ tests. Because children attend school longer now and have become much more familiar with the testing of school-related material, one might expect the greatest gains to occur on such school content-related tests as vocabulary, arithmetic or general information. Just the opposite is the case: abilities such as these have experienced relatively small gains and even occasional decreases over the years. Recent meta-analytic findings indicate that Flynn effects occur for tests assessing both fluid and crystallized abilities. For example, Dutch conscripts gained 21 points during only 30 years, or 7 points per decade, between 1952 and 1982. But this rise in IQ test scores is not wholly explained by an increase in general intelligence. Studies have shown that while test scores have improved over time, the improvement is not fully correlated with latent factors related to intelligence. Rushton have shown that the gains in IQ over time (the Lynn-Flynn effect) are unrelated to "g". Researchers have shown that the IQ gains described by the Flynn effect are due in part to increasing intelligence, and in part to increases in test-specific skills.
Proposed explanations.
Attempted explanations have included improved nutrition, a trend toward smaller families, better education, greater environmental complexity, and heterosis (the occurrence of offspring with more pronounced phenotypical traits from mixing the genes of its parents). Another proposition is the gradual spread of test-taking skills. The Flynn effect has been too rapid for genetic selection to be the cause.
Schooling and test familiarity.
Duration of average schooling has increased steadily. One problem with this explanation is that if in the US comparing older and more recent subjects with similar educational levels, then the IQ gains appear almost undiminished in each such group considered individually.
Many studies find that children who do not attend school score lower on the tests than their regularly attending peers. During the 1960s, when some Virginia counties closed their public schools to avoid racial integration, compensatory private schooling was available only for Caucasian children. On average, the scores of African-American children who did not receive formal education during that period decreased at a rate of about six IQ points per year.
Another explanation is an increased familiarity of the general population with tests and testing. For example, children who take the very same IQ test a second time usually gain five or six points. However, this seems to set an upper limit on the effects of test sophistication. One problem with this explanation and others related to schooling is, as noted above, that in the US those subsets one would expect to be affected the most show the least increases.
Early intervention programs have shown mixed results. Some preschool (ages 3–4) intervention programs like "Head Start" do not produce lasting changes of IQ, although they may confer other benefits. The "Abecedarian Early Intervention Project", an all-day program that provided various forms of environmental enrichment to children from infancy onward, showed IQ gains that did not diminish over time. The IQ difference between the groups, although only five points, was still present at age 12. Not all such projects have been successful. Also, such IQ gains can diminish until age 18.
Citing a high correlation between rising literacy rates and gains in IQ, David Marks has argued that the Flynn effect is caused by changes in literacy rates.
Generally more stimulating environment.
Still another theory is that the general environment today is much more complex and stimulating. One of the most striking 20th century changes of the human intellectual environment has come from the increase of exposure to many types of visual media. From pictures on the wall to movies to television to video games to computers, each successive generation has been exposed to richer optical displays than the one before and may have become more adept at visual analysis. This would explain why visual tests like the Raven's have shown the greatest increases. This explanation may imply that IQ tests do not necessarily measure a general intelligence factor, especially not Raven's as often argued, but instead may measure different types of intelligence that are developed by different experiences (this argument is against the notion of an underlying general intelligence, or g factor). An increase only of particular form(s) of intelligence would explain why the Flynn effect has not caused a "cultural renaissance too great to be overlooked."
In 2001, Dickens and Flynn presented a model for resolving several contradictory findings regarding IQ. They argue that the measure "heritability" includes both a direct effect of the genotype on IQ and also indirect effects such that the genotype changes the environment, thereby affecting IQ. That is, those with a greater IQ tend to seek stimulating environments that further increase IQ. These reciprocal effects result in gene environment correlation. The direct effect could initially have been very small, but feedback can create large differences of IQ. In their model, an environmental stimulus can have a very great effect on IQ, even for adults, but this effect also decays over time unless the stimulus continues (the model could be adapted to include possible factors, like nutrition during early childhood, that may cause permanent effects). The Flynn effect can be explained by a generally more stimulating environment for all people. The authors suggest that any program designed to increase IQ may produce long-term IQ gains if that program teaches children how to replicate the types of cognitively demanding experiences that produce IQ gains outside the program. To maximize lifetime IQ, the programs should also motivate them to continue searching for cognitively demanding experiences after they have left the program.
Flynn in his 2007 book "What Is Intelligence?" further expanded on this theory. Environmental changes resulting from modernization — such as more intellectually demanding work, greater use of technology and smaller families — have meant that a much larger proportion of people are more accustomed to manipulating abstract concepts such as hypotheses and categories than a century ago. Substantial portions of IQ tests deal with these abilities. Flynn gives, as an example, the question 'What do a dog and a rabbit have in common?' A modern respondent might say they are both mammals (an abstract, or "a priori" answer, which depends only on the meanings of the words 'dog' and 'rabbit' ), whereas someone a century ago might have said that humans catch rabbits with dogs (a concrete, or "a posteriori" answer, which depended on what happened to be the case at that time).
Nutrition.
Improved nutrition is another possible explanation. Today's average adult from an industrialized nation is taller than a comparable adult of a century ago. That increase of stature, likely the result of general improvements of nutrition and health, has been at a rate of more than a centimeter per decade. Available data suggest that these gains have been accompanied by analogous increases of head size, and by an increase in the average size of the brain. This argument had been thought to suffer the difficulty that groups who tend to be of smaller overall body size (e.g. women, or people of Asian ancestry) do not have lower average IQs. Richard Lynn, however, claims that while people of East Asian origin may often have smaller bodies, they tend to have larger brains and higher IQs than average whites.
A 2005 study presented data supporting the nutrition hypothesis, which predicts that gains will occur predominantly at the low end of the IQ distribution, where nutritional deprivation is probably most severe. An alternative interpretation of skewed IQ gains could be that improved education has been particularly important for this group. Richard Lynn makes the case for nutrition, arguing that cultural factors cannot typically explain the Flynn effect because its gains are observed even at infant and preschool levels, with rates of IQ test score increase about equal to those of school students and adults. Lynn states that "This rules out improvements in education, greater test sophistication, etc. and most of the other factors that have been proposed to explain the Flynn effect. He proposes that the most probable factor has been improvements in pre-natal and early post-natal nutrition."
A century ago, nutritional deficiencies may have limited body and organ functionality, including skull volume. The first two years of life is a critical time for nutrition. The consequences of malnutrition can be irreversible and may include poor cognitive development, educability, and future economic productivity. On the other hand, Flynn has pointed to 20-point gains on Dutch military (Raven's type) IQ tests between 1952, 1962, 1972, and 1982. He observes that the Dutch 18-year-olds of 1962 had a major nutritional handicap. They were either in the womb, or were recently born, during the great Dutch famine of 1944 – when German troops monopolized food and 18,000 people died of starvation. Yet, concludes Flynn, "they do not show up even as a blip in the pattern of Dutch IQ gains. It is as if the famine had never occurred." It appears that the effects of diet are gradual, taking effect over decades (affecting mother as well as child) rather than a few months .
In support of the nutritional hypothesis, it is known that, in the United States, the average height before 1900 was about 10 cm (∼4 inches) shorter than it is today. Possibly related to the Flynn effect is a similar change of skull size and shape during the last 150 years. Though the idea that brain size is unrelated to race and intelligence was popularized in the 1980s, studies continue to show significant correlations. (Note, however, that size isn't everything—or maybe anything significant at all. For example, the overall size and asymmetrical shape of Albert Einstein's brain were normal; whereas the prefrontal, somatosensory, primary motor, parietal, temporal and occipital cortices were extraordinary.)
A Norwegian study found that height gains were strongly correlated with intelligence gains until the cessation of height gains in military conscript cohorts towards the end of the 1980s.<ref name="doi10.1016/j.intell.2004.06.004"></ref> Both height and skull size increases probably result from a combination of phenotypic plasticity and genetic selection over this period. With only five or six human generations in 150 years, time for natural selection has been very limited, suggesting that increased skeletal size resulting from changes in population phenotypes is more likely than recent genetic evolution.
It is well known that micronutrient deficiencies change the development of intelligence. For instance, one study has found that iodine deficiency causes a fall, in average, of 12 IQ points in China.
Scientists James Feyrer, Dimitra Politi, and David N. Weil have found in the U.S. that the proliferation of iodized salt increased IQ by 15 points in some areas. Journalist Max Nisen has stated that, with this type of salt becoming popular, that "the aggregate effect has been extremely positive."
Infectious diseases.
Eppig, Fincher, and Thornhill (2009) argue that "From an energetics standpoint, a developing human will have difficulty building a brain and fighting off infectious diseases at the same time, as both are very metabolically costly tasks" and that "the Flynn effect may be caused in part by the decrease in the intensity of infectious diseases as nations develop." They suggest that improvements in gross domestic product (GDP), education, literacy, and nutrition may have an effect on IQ mainly through reducing the intensity of infectious diseases.
Eppig, Fincher, and Thornhill (2011) in a similar study instead looking at different US states found that states with a higher prevalence of infectious diseases had lower average IQ. The effect remained after controlling for the effects of wealth and educational variation.
Atheendar Venkataramani (2010) studied the effect of malaria on IQ in a sample of Mexicans. Exposure during the birth year to malaria eradication was associated with increases in IQ. It also increased the probability of employment in a skilled occupation. The author suggests that this may be one explanation for the Flynn effect and that this may be an important explanation for the link between national malaria burden and economic development. A literature review of 44 papers states that cognitive abilities and school performance were shown to be impaired in sub-groups of patients (with either cerebral malaria or uncomplicated malaria) when compared with healthy controls. Studies comparing cognitive functions before and after treatment for acute malarial illness continued to show significantly impaired school performance and cognitive abilities even after recovery. Malaria prophylaxis was shown to improve cognitive function and school performance in clinical trials when compared to placebo groups.
Heterosis.
Heterosis, or hybrid vigor associated with historical reductions of the levels of inbreeding, has been proposed by Michael Mingroni as an alternative explanation of the Flynn effect. However, James Flynn has pointed out that even if everyone mated with a sibling in 1900, subsequent increases in heterosis would not be a sufficient explanation of the observed IQ gains.
Possible end of progression.
Jon Martin Sundet and colleagues (2004) examined scores on intelligence tests given to Norwegian conscripts between the 1950s and 2002. They found that the increase of scores of general intelligence stopped after the mid-1990s and declined in numerical reasoning sub-tests.
Teasdale and Owen (2005) examined the results of IQ tests given to Danish male conscripts. Between 1959 and 1979 the gains were 3 points per decade. Between 1979 and 1989 the increase approached 2 IQ points. Between 1989 and 1998 the gain was about 1.3 points. Between 1998 and 2004 IQ declined by about the same amount as it gained between 1989 and 1998. They speculate that "a contributing factor in this recent fall could be a simultaneous decline in proportions of students entering 3-year advanced-level school programs for 16–18-year-olds." The same authors in a more comprehensive 2008 study, again on Danish male conscripts, found that there was a 1.5 points increase between 1988 and 1998, but a 1.5 points decrease between 1998 and 2003/2004. A possible contributing factor to the recent decline may be changes in the Danish educational system. Another may be the rising proportion of immigrants or their immediate descendants in Denmark. This is supported by data on Danish draftees where first or second generation immigrants with Danish nationality score below average.
In Australia, 6–11-year-olds' IQ, as measured by the Colored Progressive Matrices, has shown no increase from 1975–2003.
In the United Kingdom, a study by Flynn (2009) found that tests carried out in 1980 and again in 2008 show that the IQ score of an average 14-year-old dropped by more than two points over the period. For the upper half of the results the performance was even worse. Average IQ scores declined by six points. However, children aged between five and 10 saw their IQs increase by up to half a point a year over the three decades. Flynn argues that the abnormal drop in British teenage IQ could be due to youth culture having "stagnated" or even dumbed down. He also states that the youth culture is more oriented towards computer games than towards reading and holding conversations. Researcher Richard Gray, commenting on the study, also mentions the computer culture diminishing reading books as well as a tendency towards teaching to the test.
Lynn and Harvey have argued that the causes of the above are difficult to interpret since these countries have had significant recent immigration from countries with lower average national IQs. Nevertheless, they expect that similar patterns will occur, or have occurred, first in other developed nations and then in the developing world as there is a limit to how much environmental factors can improve intelligence. Furthermore, during the last century there is a negative correlation between fertility and intelligence although there is not yet any conclusive evidence of the association between the two. They estimate that there has been a dysgenic decline in the world's genotypic IQ (masked by the Flynn effect for the phenotype) of 0.86 IQ points per decade for the years 1950–2000.
IQ group differences.
If the Flynn effect has ended in developed nations, then this may possibly allow national differences in IQ scores to diminish if the Flynn effect continues in nations with lower average national IQs.
Also, if the Flynn effect has ended for the majority in developed nations, it may still continue for minorities, especially for groups like immigrants where many may have received poor nutrition during early childhood or have had other disadvantages. A study in the Netherlands found that children of non-Western immigrants had improvements for "g", educational achievements, and work proficiency compared to their parents, although there were still remaining differences compared to ethnic Dutch.
There is a controversy as to whether the US racial gap in IQ scores is diminishing. If that is the case then this may or may not be related to the Flynn effect. Flynn has commented that he never claimed that the Flynn effect has the same causes as the black-white gap, but that it shows that environmental factors can create IQ differences of a magnitude similar to the gap.
The Flynn effect has also been part of the discussions regarding Spearman's hypothesis, which states that differences in the g factor are the major source of differences between blacks and whites observed in many studies of race and intelligence.

</doc>
<doc id="11774" url="https://en.wikipedia.org/wiki?curid=11774" title="Field ion microscope">
Field ion microscope

Field ion microscopy (FIM) is an analytical technique used in materials science. The field ion microscope is a type of microscope that can be used to image the arrangement of atoms at the surface of a sharp metal tip. It was the first technique by which individual atoms could be spatially resolved.
On October 11, 1955, Müller and Kanwar Bahadur (Pennsylvania State University) observed individual tungsten (W) atoms on the surface of a sharply pointed W tip by cooling it to 78 K and employing helium as the imaging gas. Müller & Bahadur were the first persons to observe individual atoms directly; to do so, they used an FIM, which Müller had invented in 1951.
Introduction.
In FIM, a sharp (<50 nm tip radius) metal tip is produced and placed in an ultra high vacuum chamber, which is backfilled with an imaging gas such as helium or neon. The tip is cooled to cryogenic temperatures (20–100 K). A positive voltage of 5 to 10 kilovolts is applied to the tip. Gas atoms adsorbed on the tip are ionized by the strong electric field in the vicinity of the tip (thus, "field ionization"), becoming positively charged and being repelled from the tip. The curvature of the surface near the tip causes a natural magnification — ions are repelled in a direction roughly perpendicular to the surface (a "point projection" effect). A detector is placed so as to collect these repelled ions; the image formed from all the collected ions can be of sufficient resolution to image individual atoms on the tip surface.
Unlike conventional microscopes, where the spatial resolution is limited by the wavelength of the particles which are used for imaging, the FIM is a projection type microscope with atomic resolution and an approximate magnification of a few million times.
Design, limitations and applications.
FIM like Field Emission Microscopy (FEM) consists of a sharp sample tip and a fluorescent screen (now replaced by a multichannel plate) as the key elements. However, there are some essential differences as follows:
Like FEM, the field strength at the tip apex is typically a few V/Å. The experimental set-up and image formation in FIM is illustrated in the accompanying figures.
In FIM the presence of a strong field is critical. The imaging gas atoms (He, Ne) near the tip are polarized by the field and since the field is non-uniform the polarized atoms are attracted towards the tip surface. The imaging atoms then lose their kinetic energy performing a series of hops and accommodate to the tip temperature. Eventually, the imaging atoms are ionized by tunneling electrons into the surface and the resulting positive ions are accelerated along the field lines to the screen to form a highly magnified image of the sample tip.
In FIM, the ionization takes place close to the tip, where the field is strongest. The electron that tunnels from the atom is picked up by the tip. There is a critical distance, xc, at which the tunneling probability is a maximum. This distance is typically about 0.4 nm. The very high spatial resolution and high contrast for features on the atomic scale arises from the fact that the electric field is enhanced in the vicinity of the surface atoms because of the higher local curvature. The resolution of FIM is limited by the thermal velocity of the imaging ion. Resolution of the order of 1Å (atomic resolution) can be achieved by effective cooling of the tip.
Application of FIM, like FEM, is limited by the materials which can be fabricated in the shape of a sharp tip, can be used in an ultra high vacuum (UHV) environment, and can tolerate the high electrostatic fields. For these reasons, refractory metals with high melting temperature (e.g. W, Mo, Pt, Ir) are conventional objects for FIM experiments. Metal tips for FEM and FIM are prepared by electropolishing (electrochemical polishing) of thin wires. However, these tips usually contain many asperities. The final preparation procedure involves the in situ removal of these asperities by field evaporation just by raising the tip voltage. Field evaporation is a field induced process which involves the removal of atoms from the surface itself at very high field strengths and typically occurs in the range 2-5 V/Å. The effect of the field in this case is to reduce the effective binding energy of the atom to the surface and to give, in effect, a greatly increased evaporation rate relative to that expected at that temperature at zero fields. This process is self-regulating since the atoms that are at positions of high local curvature, such as adatoms or ledge atoms, are removed preferentially. The tips used in FIM is sharper (tip radius is 100~300 Å) compared to those used in FEM experiments (tip radius ~1000 Å).
FIM has been used to study dynamical behavior of surfaces and the behavior of adatoms on surfaces. The problems studied include adsorption-desorption phenomena, surface diffusion of adatoms and clusters, adatom-adatom interactions, step motion, equilibrium crystal shape, etc. However, there is the possibility of the results being affected by the limited surface area (i.e. edge effects) and by the presence of large electric field.

</doc>
<doc id="11775" url="https://en.wikipedia.org/wiki?curid=11775" title="First Battle of El Alamein">
First Battle of El Alamein

The First Battle of El Alamein (1–27 July 1942) was a major battle of the Western Desert Campaign of the Second World War, fought on the northern coast of Egypt between Axis forces (Germany and Italy) of the Panzer Army Africa ("Panzerarmee Afrika") (also known as the Africa Corps) commanded by Field Marshal ("Generalfeldmarschall") Erwin Rommel nicknamed "The Desert Fox" and Allied (specifically British Imperial) forces (Britain, British India, Australia, South Africa and New Zealand) of the Eighth Army, commanded by General Claude Auchinleck. The British prevented a second advance by the Axis forces into Egypt.
Axis positions near El Alamein, only from Alexandria, were dangerously close to the ports and cities of Egypt, the base facilities of the Commonwealth forces and the Suez Canal and the Axis forces were too far from their base at Tripoli in Libya, to remain at El Alamein indefinitely, which led both sides to accumulate supplies for more offensives, against the constraints of time and distance. At the Battle of Alam el Halfa and the Second Battle of El Alamein the Axis army was defeated and driven out of Egypt for good.
Background.
Retreat from Gazala.
Following its defeat at the Battle of Gazala in Eastern Libya in June 1942, the British Eighth Army had retreated east from the Gazala line into north-western Egypt as far as Mersa Matruh, roughly inside the border. Lieutenant-General Neil Ritchie had decided not to hold the defences on the Egyptian border, because the defensive plan there relied on his infantry holding defended localities, while a strong armoured force was held back in reserve to foil any attempts to penetrate or outflank the fixed defences. Since Ritchie had virtually no armoured units left fit to fight, the infantry positions would be defeated in detail. The Mersa defence plan also included an armoured reserve but in its absence Ritchie believed he could organise his infantry to cover the minefields between the defended localities to prevent Axis engineers from having undisturbed access.
To defend the Matruh line, Ritchie placed 10th Indian Infantry Division (in Matruh itself) and 50th (Northumbrian) Infantry Division (some down the coast at Gerawla) under X Corps HQ, newly arrived from Syria. Inland from X Corps would be XIII Corps with 5th Indian Infantry Division (with only one infantry brigade, 29th Indian, and two artillery regiments) around Sidi Hamza about inland, and the newly arrived 2nd New Zealand Division (short one brigade, the 6th, which had been left out of combat in case the division was captured and it would form the nucleus of a new division) at Minqar Qaim (on the escarpment inland) and 1st Armoured Division in the open desert to the south. The 1st Armoured had taken over 4th and 22nd Armoured Brigades from 7th Armoured Division which by this time had only three tank regiments between them.
On 25 June, General Claude Auchinleck—Commander-in-Chief (C-in-C) Middle East Command—relieved Ritchie and assumed direct command of Eighth Army himself. He decided not to seek a decisive confrontation at the Mersa Matruh position. He concluded that his inferiority in armour after the Gazala defeat, meant he would be unable to prevent Rommel either breaking through his centre or enveloping his open left flank to the south in the same way he had at Gazala. He decided instead to employ delaying tactics while withdrawing a further or more east to a more defensible position near El Alamein on the Mediterranean coast. Only to the south of El Alamein, the steep slopes of the Qattara Depression ruled out the possibility of Axis armour moving around the southern flank of his defences and limited the width of the front he had to defend.
Battle of Mersa Matruh.
While preparing the Alamein positions, Auchinleck fought strong delaying actions, first at Mersa Matruh on 26–27 June and then Fuka on 28 June. The late change of orders resulted in some confusion in the forward formations (X Corps and XIII Corps) between the desire to inflict damage on the enemy and the intention not to get trapped in the Matruh position but retreat in good order. The result was poor co-ordination between the two forward Corps and units within them.
Late on 26 June, the 90th Light and 21st "Panzer" Divisions managed to find their way through the minefields in the centre of the front. Early on 27 June, resuming its advance, the 90th Light was checked by British 50th Division's artillery. Meanwhile, the 15th and 21st "Panzer" Divisions advanced east above and below the escarpment. The 15th "Panzer" were blocked by 4th Armoured and 7th Motor Brigades, but the 21st "Panzer" were ordered on to attack Minqar Qaim. Rommel ordered 90th Light to resume its advance, requiring it to cut the coast road behind 50th Division by the evening.
As the 21st "Panzer" moved on Minqar Qaim, the 2nd New Zealand Division found itself surrounded. It succeeded in breaking out on the night of 27 June without serious losses and withdraw east. Auchinleck had planned a second delaying position at Fuka, some east of Matruh, and at 21:20 he issued the orders for a withdrawal to Fuka. Confusion in communication led the division withdrawing immediately to the El Alamein position.
X Corps meanwhile, having made an unsuccessful attempt to secure a position on the escarpment, were out of touch with Eighth Army from 19:30 until 04:30 the next morning. Only then did they discover that the withdrawal order had been given. The withdrawal of XIII Corps had left the southern flank of X Corps on the coast at Matruh exposed and their line of retreat compromised by the cutting of the coastal road east of Matruh. They were ordered to break out southwards into the desert and then make their way east. Auchinleck ordered XIII Corps to provide support but they were in no position to do so. At 21:00 on 28 June, X Corps—organised into brigade groups—headed south. In the darkness, there was considerable confusion as they came across enemy units laagered for the night. In the process, 5th Indian Division in particular sustained heavy casualties, including the destruction of the 29th Indian Infantry Brigade at Fuka. Axis forces captured more than 6,000 prisoners, in addition to 40 tanks and an enormous quantity of supplies.
Prelude.
Defences at El Alamein.
Alamein itself was an insignificant railway station on the coast. Some to the south lay the Ruweisat Ridge, a low stony ridge that nonetheless gave excellent observation for many miles over the surrounding desert. to the south of that lay the Qattara Depression. The line the British chose to defend stretched between the sea and the Qattara Depression, which meant that Rommel could outflank it only by taking a significant detour to the south and crossing the Sahara Desert. The British Army in Egypt recognised this before the war and had the Eighth Army begin construction of several "boxes" (localities with dug-outs and surrounded by minefields and barbed wire), the most developed being around the railway station at Alamein. Most of the "line", however, was just open, empty desert. Lieutenant-General William Norrie (GOC XXX Corps) organised the position and started to construct three defended "boxes". The first and strongest, at El Alamein on the coast, had been partly wired and mined by 1st South African Division. The Bab el Qattara box—some from the coast and south-west of the Ruweisat Ridge—had been dug but had not been wired or mined, while at the Naq Abu Dweis box (on the edge of the Qattara Depression), from the coast, very little work had been done.
The British position in Egypt was in a critical state. The rout from Mersa Matruh had created a panic in the British headquarters at Cairo, something later called "the Flap". On what came to be referred to as "Ash Wednesday", at British headquarters, rear echelon units, and the British Embassy, the British frantically burned confidential papers in anticipation of the entry of Axis troops into the city. Auchinleck—although believing he could stop Rommel at Alamein—felt he could not ignore the possibility that he might once more be outmanoeuvered or outfought. He therefore believed that, to maintain his army, plans must be made for the possibility of a further retreat whilst maintaining morale and retaining the support and co-operation of the Egyptians. Defensive positions were constructed west of Alexandria and on the approaches to Cairo while considerable areas in the Nile delta were flooded. The Axis, too, believed that the capture of Egypt was imminent; Italian leader Benito Mussolini—sensing an historic moment—flew to Libya to prepare for his triumphal entry to Cairo.
The scattering of X Corps at Mersa Matruh disrupted Auchinleck's plan for occupying the Alamein defences. On 29 June, he ordered XXX Corps—South African 1st, Indian 5th and 10th Infantry Divisions—to take the coastal sector on the right of the front and XIII Corps—New Zealand and Indian 5th Divisions—to be on the left. The remains of 1st and 7th Armoured Divisions were to be held as a mobile army reserve. His intention was for the fixed defensive positions to canalise and disorganise the enemy's advance while mobile units would attack their flanks and rear.
On 30 June, Rommel's "Panzer" Army Africa approached the Alamein position. The Axis forces were exhausted and understrength. Rommel had driven them forward ruthlessly, being confident that, provided he struck quickly before Eighth Army had time to settle, his momentum would take him through the Alamein position and he could then advance to the Nile with little further opposition. Supplies remained a problem because the Axis staff had originally expected a pause of six weeks after the capture of Tobruk. Furthermore, German air units were also exhausted and providing little help against the RAF's all-out attack on the Axis supply lines which, with the arrival of United States Army Air Forces heavy bombers, could reach as far as Benghazi. While captured supplies proved useful, water and ammunition were constantly in short supply while a shortage of transport impeded the distribution of the supplies that the Axis forces did have.
Axis plan of attack.
Rommel's plan was for the 90th Light Division and the two "Afrika Korps" armoured divisions—15th and 21st "Panzer"—to penetrate the Eighth Army lines between the Alamein box and Deir el Abyad (which he believed was defended). The 90th Light was then to veer north to cut the coastal road and trap the defenders of the Alamein box (which Rommel thought was occupied by the remains of 50th Infantry Division) and the "Afrika Korps" would veer right to attack the rear of XIII Corps. An Italian division was to attack the Alamein box from the west and another was to follow 90th Light. Italian XX Corps was to follow the "Afrika Korps" and deal with the Qattara box while the Italian "Littorio" Armoured Division and German reconnaissance units would protect the right flank. Rommel had planned to attack on 30 June but supply and transport difficulties had resulted in a day's delay, vital to the defending forces reorganising on the Alamein line. On 30 June 90th Light Infantry Division was still short of its start line, 21st "Panzer" Division was immobilised through lack of fuel and the promised air support had yet to move into its advanced airfields.
Battle.
Panzer Army Africa attacks.
At 03:00 on 1 July, 90th Light Infantry Division advanced east but strayed too far north and ran into the 1st South African Division's defences and became pinned down. The 15th and 21st "Panzer" Divisions of the "Afrika Korps" were delayed by a sandstorm and then a heavy air attack. It was broad daylight by the time they circled round the back of Deir el Abyad where they found the feature to the east of it occupied by 18th Indian Infantry Brigade which, after a hasty journey from Iraq, had occupied the exposed position just west of Ruweisat Ridge and east of Deir el Abyad at Deir el Shein late on 28 June to create one of Norrie's additional defensive boxes.
At about 10:00 on 1 July, 21st "Panzer" Division attacked Deir el Shein. 18th Indian Infantry Brigade—supported by 23 25-pounder gun-howitzers, 16 of the new 6-pounder anti-tank guns and nine Matilda tanks—held out the whole day in desperate fighting but by evening the Germans succeeded in over-running them. The time they bought allowed Auchinleck to organise the defence of the western end of Ruweisat Ridge. The 1st Armoured Division had been sent to intervene at Deir el Shein. They ran into 15th "Panzer" Division just south of Deir el Shein and drove it west. By the end of the day's fighting, the "Afrika Korps" had 37 tanks left out of its initial complement of 55.
During the early afternoon, 90th Light had extricated itself from the El Alamein box defences and resumed its move eastward. It came under artillery fire from the three South African brigade groups and was forced to dig in.
On 2 July, Rommel ordered the resumption of the offensive. Once again, 90th Light failed to make progress so Rommel called the "Afrika Korps" to abandon its planned sweep southward and instead join the effort to break through to the coast road by attacking east toward Ruweisat Ridge. The British defence of Ruweisat Ridge relied on an improvised formation called "Robcol", comprising a regiment each of field artillery and light anti-aircraft artillery and a company of infantry. Robcol—in line with normal British Army practice for "ad hoc" formations—was named after its commander, Brigadier Robert Waller, the Commander Royal Artillery of the 10th Indian Infantry Division. Robcol was able to buy time, and by late afternoon the two British armoured brigades joined the battle with 4th Armoured Brigade engaging 15th "Panzer" and 22nd Armoured Brigade 21st "Panzer" respectively. They drove back repeated attacks by the Axis armour, who then withdrew before dusk. The British reinforced Ruweisat on the night of 2 July. The now enlarged Robcol became "Walgroup". Meanwhile, the Royal Air Force (RAF) made heavy air attacks on the Axis units.
The next day, 3 July, Rommel ordered the "Afrika Korps" to resume its attack on the Ruweisat ridge with the Italian XX Motorised Corps on its southern flank. Italian X Corps, meanwhile were to hold El Mreir. By this stage the "Afrika Korps" had only 26 operational tanks. There was a sharp armoured exchange south of Ruweisat ridge during the morning and the main Axis advance was held. On 3 July, the RAF flew 780 sorties.
To relieve the pressure on the right and centre of the Eighth Army line, XIII Corps on the left advanced from the Qattara box (known to the New Zealanders as the Kaponga box). The plan was that the New Zealand 2nd Division—with the remains of Indian 5th Division and 7th Motor Brigade under its command—would swing north to threaten the Axis flank and rear. This force encountered the "Ariete" Armoured Division's artillery, which was driving on the southern flank of the division as it attacked Ruweisat. The Italian commander ordered his battalions to fight their way out independently but the "Ariete" lost 531 men (about 350 were prisoners), 36 pieces of artillery, six (or eight?) tanks, and 55 trucks. By the end of the day, the "Ariete" Division had only five tanks. The day ended once again with the "Afrika Korps" and "Ariete" coming off second best to the superior numbers of the British 22nd Armoured and 4th Armoured Brigades, frustrating Rommel's attempts to resume his advance. The RAF once again played its part, flying 900 sorties during the day.
To the south, on 5 July the New Zealand group resumed its advance northwards towards El Mreir intending to cut the rear of the "Ariete" Division. Heavy fire from the Italian "Brescia" Motorised Division at El Mreir, however, north of the Qattara box, checked their progress and led XIII Corps to call off its attack.
Rommel digs in.
 At this point, Rommel decided his exhausted forces could make no further headway without resting and regrouping. He reported to the German High Command that his three German divisions numbered just 1,200–1,500 men each and resupply was proving highly problematic because of enemy interference from the air. He expected to have to remain on the defensive for at least two weeks.
Rommel was by this time suffering from the extended length of his supply lines. The Allied Desert Air Force (DAF) was concentrating fiercely on his fragile and elongated supply routes while British mobile columns moving west and striking from the south were causing havoc in the Axis rear echelons. Rommel could afford these losses even less since shipments from Italy had been substantially reduced (in June, he received of supplies compared with in May and 400 vehicles (compared with 2,000 in May). Meanwhile, the Eighth Army was reorganising and rebuilding, benefiting from its short lines of communication. By 4 July, the Australian 9th Division had entered the line in the north, and on 9 July the Indian 5th Infantry Brigade also returned, taking over the Ruweisat position. At the same time, the fresh Indian 161st Infantry Brigade reinforced the depleted Indian 5th Infantry Division.
Tel el Eisa.
On 8 July, Auchinleck ordered the new XXX Corps commander—Lieutenant-General William Ramsden—to capture the low ridges at Tel el Eisa and Tel el Makh Khad and then to push mobile battle groups south toward Deir el Shein and raiding parties west toward the airfields at El Daba. Meanwhile, XIII Corps would prevent the Axis from moving troops north to reinforce the coastal sector. Ramsden tasked the Australian 9th Division with 44th Royal Tank Regiment under command with the Tel el Eisa objective and the South African 1st Division with eight supporting tanks, Tel el Makh Khad. The raiding parties were to be provided by 1st Armoured Division.
Following a bombardment which started at 03:30 on 10 July, the Australian 26th Brigade launched an attack against the ridge north of Tel el Eisa station along the coast (Trig 33). The bombardment was the heaviest barrage yet experienced in North Africa, which created panic in the inexperienced soldiers of the Italian 60th Infantry Division "Sabratha" who had only just occupied sketchy defences in the sector. The Australian attack took more than 1,500 prisoners, routed an Italian Division and overran the German Signals Intercept Company 621. Meanwhile, the South Africans had by late morning taken Tel el Makh Khad and were in covering positions.
Elements of the German 164th Light Division and Italian 101st Motorised Division "Trieste" arrived to plug the gap torn in the Axis defences. That afternoon and evening, tanks from the German 15th "Panzer" and Italian "Trieste" Divisions launched counter-attacks against the Australian positions, the counter-attacks failing in the face of overwhelming Allied artillery and the Australian anti-tank guns.
At first light on 11 July, the Australian 2/24th Battalion supported by tanks from 44th Royal Tank Regiment attacked the western end of Tel el Eisa hill (Point 24). By early afternoon, the feature was captured and was then held against a series of Axis counter-attacks throughout the day. A small column of armour, motorised infantry, and guns then set off to raid Deir el Abyad and caused a battalion of Italian infantry to surrender. Its progress was checked at the Miteirya ridge and it was forced to withdraw that evening to the El Alamein box. During the day, more than 1,000 Italian prisoners were taken.
On 12 July, the 21st "Panzer" Division launched a counter-attack against Trig 33 and Point 24, which was beaten off after a 2½-hour fight, with more than 600 German dead and wounded left strewn in front of the Australian positions. The next day, 21. "Panzerdivision" launched an attack against Point 33 and South African positions in the El Alamein box. The attack was halted by intense artillery fire from the defenders. Rommel was still determined to drive the British forces from the northern salient. Although the Australian defenders had been forced back from Point 24, heavy casualties had been inflicted on 21st "Panzer" Division. Another attack was mounted on 15 July but made no ground against tenacious resistance. On 16 July, the Australians—supported by British tanks—launched an attack to try to take Point 24 but were forced back by German counter-attacks, suffering nearly fifty percent casualties.
After seven days of fierce fighting, the battle in the north for Tel el Eisa salient petered out. Australian 9th Division estimated at least 2,000 Axis troops had been killed and more than 3,700 prisoners of war taken in the battle. Possibly the most important feature of the battle, however, was that the Australians had captured Signals Intercept Company 621. This unit had provided Rommel with priceless intelligence, gleaned from intercepting British radio communications. That source of intelligence was now lost to Rommel.
First Battle of Ruweisat Ridge.
As the Axis forces dug in, Auchinleck—having drawn a number of German units to the coastal sector during the Tel el Eisa fighting—developed a plan—codenamed Operation Bacon—to attack the Italian "Pavia" and "Brescia" Divisions in the centre of the front at the Ruweisat ridge. Signals intelligence was giving Auchinleck clear details of the Axis order of battle and force dispositions. His policy was to "...hit the Italians wherever possible in view of their low morale and because the Germans cannot hold extended fronts without them."
The intention was for the 4th New Zealand Brigade and 5th New Zealand Brigade (on 4th Brigade's right) to attack north-west to seize the western part of the ridge and on their right the Indian 5th Infantry Brigade to capture the eastern part of the ridge in a night attack. Then 2nd Armoured Brigade would pass through the centre of the infantry objectives to exploit toward Deir el Shein and the Miteirya Ridge. On the left, the 22nd Armoured Brigade would be ready to move forward to protect the infantry as they consolidated on the ridge.
The attack commenced at 23:00 on 14 July. The two New Zealand brigades shortly before dawn on 15 July took their objectives, but minefields and pockets of resistance created disarray among the attackers. A number of pockets of resistance were left behind the forward troops' advance which impeded the move forward of reserves, artillery, and support arms. As a result, the New Zealand brigades occupied exposed positions on the ridge without support weapons except for a few anti-tank guns. More significantly, communications with the two British armoured brigades failed, and the British armour did not move forwards to protect the infantry. At first light, a detachment from 15th "Panzer" division's 8th "Panzer" Regiment launched a counter-attack against New Zealand 4th Brigade's 22nd Battalion. A sharp exchange knocked out their anti-tank guns and the infantry found themselves exposed in the open with no alternative but to surrender. About 350 New Zealanders were taken prisoner.
While the 2nd New Zealand Division attacked the western slopes of Ruweisat Ridge, the Indian 5th Brigade made small gains on Ruweisat ridge to the east. By 07:00, word was finally got to 2nd Armoured Brigade which started to move north west. Two regiments became embroiled in a minefield but the third was able to join Indian 5th Infantry 5th Brigade as it renewed its attack. With the help of the armour and artillery, the Indians were able to take their objectives by early afternoon. Meanwhile, the 22nd Armoured Brigade had been engaged at Alam Nayil by 90th Light Division and the "Ariete" Armoured Division, advancing from the south. While—with help from mobile infantry and artillery columns from 7th Armoured Division—they pushed back the Axis probe with ease, they were prevented from advancing north to protect the New Zealand flank.
Seeing the "Brescia" and "Pavia" under pressure, Rommel rushed German troops to Ruweisat. By 15:00, the 3rd Reconnaissance Regiment and part of 21st "Panzer" Division from the north and 33rd Reconnaissance Regiment and the Baade Group comprising elements from 15th "Panzer" Division from the south were in place under Lieutenant-General ("General der Panzertruppe") Walther Nehring. At 17:00, Nehring launched his counter-attack. 4th New Zealand Brigade were still short of support weapons and also, by this time, ammunition. Once again, the anti-tank defences were overwhelmed and about 380 New Zealanders were taken prisoner including Captain Charles Upham who gained a second Victoria Cross for his actions including destroying a German tank and several guns and vehicles with grenades despite being shot through the elbow by a machine gun bullet and having his arm broken. At about 18:00, the brigade HQ was overrun. At about 18:15, 2nd Armoured Brigade engaged the German armour and halted the Axis eastward advance. At dusk, Nehring broke off the action.
Early on 16 July, Nehring renewed his attack. Indian 5th Infantry Brigade pushed them back but it was clear from intercepted radio traffic that a further attempt would be made. Accordingly, strenuous preparations to dig in anti-tank guns were made, artillery fire plans organised and a regiment from 22nd Armoured Brigade was sent to reinforce 2nd Armoured Brigade. When Nehring's renewed attack came late in the afternoon, it was repulsed. After the battle, the Indians counted 24 destroyed tanks, as well as armoured cars and numerous anti-tank guns left on the battlefield.
In three day's fighting, the Allies captured more than 2,000 Axis prisoners of war, mostly from the Italian "Brescia" and "Pavia" Divisions; the New Zealand division suffered 1,405 casualties. The fighting at Tel el Eisa and Ruweisat had seen the destruction of three Italian divisions and forced Rommel to redeploy his armour from the south and made it necessary to lay minefields in front of the remaining Italian divisions and stiffen them with detachments of German troops.
Miteirya Ridge (Ruin Ridge).
To relieve pressure on Ruweisat ridge, Auchinleck ordered the Australian 9th Division to make another attack from the north. In the early hours of 27 July, the Australian 24th Brigade—supported by 44th Royal Tank Regiment (RTR) and strong fighter cover from the air—assaulted Miteirya ridge (known as "Ruin ridge" to the Australians). The initial night attack went well, with 736 prisoners taken, mostly from the Italian "Trento" and "Trieste" motorised divisions. Once again, however, a critical situation for the Axis forces was retrieved by vigorous counter-attacks from hastily assembled German and Italian forces, which forced the Australians to withdraw back to their start line with 300 casualties. Although the Australian Official History of the 24th Brigade's 2/32nd Battalion describes the counter-attack force as "German", the Australian historian Mark Johnston reports that German records indicate that it was the "Trento" Division that overran the Australian battalion.
Second Battle of Ruweisat Ridge (El Mreir).
The Eighth Army now enjoyed a massive superiority in material over the Axis forces: 1st Armoured Division had 173 tanks and more in reserve or in transit, including 61 Grants while Rommel possessed only 38 German tanks and 51 Italian tanks although his armoured units had some 100 tanks awaiting repair.
Auchinleck’s plan was for Indian Infantry 161st Brigade to attack along Ruweisat ridge to take Deir el Shein, while the New Zealand 6th Brigade attacked from south of the ridge to the El Mreir depression. At daylight, two British armoured brigades—2nd Armoured Brigade and the fresh 23rd Armoured Brigade—would sweep through the gap created by the infantry. The plan was complicated and ambitious.
The infantry night attack began at 16:30 on 21 July. The New Zealand attack took their objectives in the El Mreir depression but, once again, many vehicles failed to arrive and they were short of support arms in an exposed position. At daybreak on 22 July, the British armoured brigades again failed to advance. At daybreak on 22 July, Nehring's 5th and 8th "Panzer" Regiments responded with a rapid counter-attack which quickly overran the New Zealand infantry in the open, inflicting more than 900 casualties on the New Zealanders. 2nd Armoured Brigade sent forward two regiments to help but they were halted by mines and anti-tank fire.
The attack by Indian 161st Brigade had mixed fortunes. On the left, the initial attempt to clear the western end of Ruweisat failed but at 08:00 a renewed attack by the reserve battalion succeeded. On the right, the attacking battalion broke into the Deir el Shein position but was driven back in hand-to-hand fighting.
Compounding the disaster at El Mreir, at 08:00 the commander of 23rd Armoured Brigade ordered his brigade forward, intent on following his orders to the letter. Major-General Gatehouse—commanding 1st Armoured Division—had been unconvinced that a path had been adequately cleared in the minefields and had suggested the advance be cancelled. However, XIII Corps commander—Lieutenant-General William Gott—rejected this and ordered the attack but on a centre line south of the original plan which he incorrectly believed was mine-free. These orders failed to get through and the attack went ahead as originally planned. The brigade found itself mired in mine fields and under heavy fire. They were then counter-attacked by 21st Panzer at 11:00 and forced to withdraw. The 23rd Armoured Brigade was destroyed, with the loss of 40 tanks destroyed and 47 badly damaged.
At 17:00, Gott ordered 5th Indian Infantry Division to execute a night attack to capture the western half of Ruweisat ridge and Deir el Shein. 3/14th Punjab Regiment from 9th Indian Infantry Brigade attacked at 02:00 on 23 July but failed as they lost their direction. A further attempt in daylight succeeded in breaking into the position but intense fire from three sides resulted in control being lost as the commanding officer was killed, and four of his senior officers were wounded or went missing.
Attack on Tel el Eisa resumed.
To the north, Australian 9th Division continued its attacks. At 06:00 on 22 July, Australian 26th Brigade attacked Tel el Eisa and Australian 24th Brigade attacked Tel el Makh Khad toward Miteirya (Ruin Ridge). It was during this fighting that Arthur Stanley Gurney performed the actions for which he was posthumously awarded the Victoria Cross. The fighting for Tel el Eisa was costly, but by the afternoon the Australians controlled the feature. That evening, Australian 24th Brigade attacked Tel el Makh Khad with the tanks of 50th RTR in support. The tank unit had not been trained in close infantry support and failed to co-ordinate with the Australian infantry. The result was that the infantry and armour advanced independently and having reached the objective 50th RTR lost 23 tanks because they lacked infantry support.
Once more, the Eighth Army had failed to destroy Rommel’s forces, despite its overwhelming superiority in men and equipment. On the other hand, for Rommel the situation continued to be grave as, despite successful defensive operations, his infantry had suffered heavy losses and he reported that "the situation is critical in the extreme".
Operation Manhood.
On 26/27 July, Auchinleck launched Operation Manhood in the northern sector in a final attempt to break the Axis forces. XXX Corps was reinforced with 1st Armoured Division (less 22nd Armoured Brigade), 4th Light Armoured Brigade, and 69th Infantry Brigade. The plan was to break the enemy line south of Miteirya ridge and exploit north-west. The South Africans were to make and mark a gap in the minefields to the south-east of Miteirya by midnight of 26/27 July. By 01:00 on 27 July, 24th Australian Infantry Brigade was to have captured the eastern end of the Miteirya ridge and would exploit toward the north-west. The 69th Infantry Brigade would pass through the minefield gap created by the South Africans to Deir el Dhib and clear and mark gaps in further minefields. The 2nd Armoured Brigade would then pass through to El Wishka and would be followed by 4th Light Armoured Brigade which would attack the Axis lines of communication.
This was the third attempt to break through in the northern sector, and the Axis defenders were expecting the attack. Like the previous attacks, it was hurriedly and therefore poorly planned. The Australian 24th Brigade managed to take their objectives on Miteirya Ridge by 02:00 of 27 July. To the south, the British 69th Brigade set off at 01:30 and managed to take their objectives by about 08:00. However, the supporting anti-tank units became lost in the darkness or delayed by minefields, leaving the attackers isolated and exposed when daylight came. There followed a period during which reports from the battlefront regarding the minefield gaps were confused and conflicting. As a consequence, the advance of 2nd Armoured Brigade was delayed. Rommel launched an immediate counter-attack and the German armoured battlegroups overran the two forward battalions of 69th Brigade. Meanwhile, 50th RTR supporting the Australians was having difficulty locating the minefield gaps made by Australian 2/24th Battalion. They failed to find a route through and in the process were caught by heavy fire and lost 13 tanks. The unsupported 2/28th Australian battalion on the ridge was overrun. The 69th Brigade suffered 600 casualties and the Australians 400 for no gain.
The Eighth Army was exhausted, and on 31 July Auchinleck ordered an end to offensive operations and the strengthening of the defences to meet a major counter-offensive.
Rommel was later to blame the failure to break through to the Nile on how the sources of supply to his army had dried up and how:
Rommel complained bitterly about the failure of important Italian convoys to get through to him desperately needed tanks and supplies, always blaming the Italian Supreme Command, never suspecting British code breaking.
Aftermath.
The battle was a stalemate, but it had halted the Axis advance on Alexandria (and then Cairo and ultimately the Suez Canal). The Eighth Army had suffered over 13,000 casualties in July including 4,000 in the 2nd New Zealand Division, 3,000 in the 5th Indian Infantry Division and 2,552 battle casualties in the 9th Australian Division but had taken 7,000 prisoners and inflicted heavy damage on Axis men and machines. In his appreciation of 27 July Auchinleck wrote that Eighth Army would not be ready to attack again until mid-September at the earliest. He believed that because Rommel understood that with the passage of time the Allied situation would only improve, he was compelled to attack as soon as possible and before the end of August when he would have superiority in armour. Auchinleck therefore made plans for a defensive battle.
In early August, Winston Churchill and Alan Brooke—the Chief of the Imperial General Staff—visited Cairo on their way to meet Joseph Stalin in Moscow. They decided to replace Auchinleck, appointing the XIII Corps commander, William Gott, to the Eighth Army command and General Sir Harold Alexander as C-in-C Middle East Command. Persia and Iraq were to be split from Middle East Command as a separate Persia and Iraq Command and Auchinleck was offered the post of C-in-C (which he refused). Gott was killed on the way to take up his command when his aircraft was shot down. Lieutenant-General Bernard Montgomery was appointed in his place and took command on 13 August.

</doc>
<doc id="11776" url="https://en.wikipedia.org/wiki?curid=11776" title="First Italo-Ethiopian War">
First Italo-Ethiopian War

The First Italo-Ethiopian War was fought between Italy and Ethiopia from 1895 to 1896. It originated from a disputed treaty which, the Italians claimed, turned the country into an Italian protectorate. Much to their surprise, they found that Ethiopian ruler Menelik II, rather than opposed by some of his traditional enemies, was supported by them, and so the Italian army, invading Ethiopia from Italian Eritrea in 1893, faced a more united front than they expected. In addition, Ethiopia was supported by Russia with military advisers and the sale of weapons for Ethiopian forces during the war. Full-scale war broke out in 1895, when Ethiopian troops counterattacked Italian positions and besieged the Italian fort of Meqele, forcing its surrender. Italian defeat came about after the Battle of Adwa, where the Ethiopian army dealt the outnumbered Italians a heavy loss and forced their retreat back into Eritrea.
This was not the first African victory over Western colonizers, but it was the first time such a military put a definitive stop to a colonizing nation's efforts. According to one historian, "In an age of relentless European expansion, Ethiopia alone had successfully defended its independence".
Background.
On March 25, 1889, the Shewa ruler Menelik II, having conquered Tigray and Amhara, declared himself Emperor of Ethiopia (or "Abyssinia", as it was commonly called in Europe at the time). Barely a month later, on May 2, he signed the Treaty of Wuchale with the Italians, which apparently gave them control over Eritrea, the Red Sea coast to the northeast of Ethiopia, in return for recognition of Menelik's rule. Menelik II continued the policy of Tewodros I of integrating Ethiopia.
However, the bilingual treaty did not say the same thing in Italian and Amharic; the Italian version did not give the Ethiopians the "significant autonomy" written into the Amharic translation. The former text established an Italian protectorate over Ethiopia, but the Amharic version merely stated that Menelik could contact foreign powers and conduct foreign affairs through Italy if he so chose. Italian diplomats, however, claimed that the original Amharic text included the clause and Menelik knowingly signed a modified copy of the Treaty.
Because of the Ethiopian refusal to abide by the Italian version of the treaty and despite economic handicaps at home, the Italian government decided on a military solution to force Ethiopia to abide by the Italian version of the treaty. In doing so, they believed that they could exploit divisions within Ethiopia and rely on tactical and technological superiority to offset any inferiority in numbers.
There was a broader, European background as well: the Triple Alliance of Germany, Austria–Hungary, and Italy was under some stress, with Italy being courted by England. Two secret Anglo-Italian protocols in 1891, left most of Ethiopia in Italy's sphere of influence. France, one of the members of the opposing Franco-Russian Alliance, had its own claims on Eritrea and was bargaining with Italy over giving up those claims in exchange for a more secure position in Tunisia. Meanwhile, Russia was supplying weapons and other aid to Ethiopia. It had been trying to gain a foothold in Ethiopia, and in 1894, after denouncing the Treaty of Wuchale in July, it received an Ethiopian mission in St. Petersburg and sent arms and ammunition to Ethiopia. This support continued after the war ended.
Opening phase.
In 1893, judging that his power over Ethiopia was secure, Menelik repudiated the treaty; in response the Italians ramped up the pressure on his domain in a variety of ways, including the annexation of small territories bordering their original claim under the Treaty of Wuchale, and finally culminating with a military campaign and across the Mareb River into Tigray (on the border with Eritrea) in December 1894. The Italians expected disaffected potentates like Negus Tekle Haymanot of Gojjam, Ras Mengesha Yohannes, and the Sultan of Aussa to join them; instead, all of the ethnic Tigrayan or Amharic peoples flocked to the Emperor Menelik's side in a display of both nationalism and anti-Italian feeling, while other peoples of dubious loyalty (e.g. the Sultan of Aussa), were watched by Imperial garrisons. Further, Menelik had spent much of the previous four years building up a supply of modern weapons and ammunition, acquired from the French, British, and the Italians themselves, as the European colonial powers sought to keep each other's North African aspirations in check. They also used the Ethiopians as a proxy army against the Sudanese Mahdists.
In December 1894, Bahta Hagos led a rebellion against the Italians in Akkele Guzay, claiming support of Mengesha. Units of General Oreste Baratieri's army under Major Pietro Toselli crushed the rebellion and killed Bahta at the Battle of Halai. The Italian army then occupied the Tigrian capital, Adwa. Baratieri suspected that Mengesha would invade Eritrea, and met him at the Battle of Coatit in January 1895. The victorious Italians chased a retreating Mengesha, capturing weapons and important documents proving his complicity with Menelik. The victory in this campaign, along with previous victories against the Sudanese Mahdists, led the Italians to underestimate the difficulties to overcome in a campaign against Menelik. At this point, Emperor Menelik turned to France, offering a treaty of alliance; the French response was to abandon the Emperor to secure Italian approval of the Treaty of Bardo which would secure French control of Tunisia. Virtually alone, on 17 September 1895, Emperor Menelik issued a proclamation calling up the men of Shewa to join his army at Were Ilu.
As the Italians were poised to enter Ethiopian territory, the Ethiopians underwent mass mobilization all over the country. Helping it was the newly updated imperial fiscal and taxation system. As a result, a hastily mobilized army of 196,000 men, in which more than half were armed with modern rifles, gathered from all parts of Abyssinia rallied at Addis Ababa in support of the Emperor and defense of their country.
The unique Eurasian ally of Ethiopia was Russia. The Ethiopian emperor sent his first diplomatic mission to St. Petersburg in 1895. In June 1895, the newspapers in St. Petersburg wrote, "Along with the expedition, Menelik II sent his diplomatic mission to Russia, including his princes and his bishop". Many citizens of the capital came to meet the train that brought Prince Damto, General Genemier, Prince Belyakio, Bishop of Harer Gabraux Xavier and other members of the delegation to St. Petersburg. On the eve of War, an agreement about rendering the military help for Ethiopia was concluded.
The next clash came at Amba Alagi on 7 December 1895, when Ethiopian soldiers overran the Italian positions dug in on the natural fortress, and forced the Italians to retreat back to Eritrea. The remaining Italian troops under General Giuseppe Arimondi reached the unfinished Italian fort at Meqele. Arimondi left there a small garrison of approximately 1,150 askaris and 200 Italians, commanded by Major Giuseppe Galliano, and took the bulk of his troops to Adigrat, where Oreste Baratieri, the Italian commander, was concentrating the Italian Army.
The first Ethiopian troops reached Maqele in the following days. Ras Makonnen surrounded the fort at Meqele on 18 December, but the Italian commander adroitly used promises of a negotiated surrender to prevent the Ras from attacking the fort. By the first days of January, Emperor Menelik, accompanied by his Queen Taytu Betul, had led large forces into Tigray, and besieged the Italians for sixteen days (6–21 January 1896), making several unsuccessful attempts to carry the fort by storm, until the Italians surrendered with permission from the Italian Headquarters. Menelik allowed them to leave Meqele with their weapons, and even provided the defeated Italians mules and pack animals to rejoin Baratieri. While some historians read this generous act as a sign that Emperor Menelik still hoped for a peaceful resolution to the war, Harold Marcus points out that this escort allowed him a tactical advantage: "Menelik craftily managed to establish himself in Hawzien, at Gendepata, near Adwa, where the mountain passes were not guarded by Italian fortifications."
Heavily outnumbered, Baratieri refused to engage, knowing that due to their lack of infrastructure the Ethiopians could not keep large numbers of troops in the field much longer. However, Baratieri also never knew about the true numerical strength of the Ethiopian army that was to face his army, so he rather further fortified his positions in the Tigray. But the Italian government of Francesco Crispi was unable to accept being stymied by non-Europeans. The prime minister specifically ordered Baratieri to advance deep into enemy territory and bring about a battle.
Battle of Adwa.
The decisive battle of the war was the Battle of Adwa on March 1, 1896, which took place in mountainous country north of actual town of Adwa (or Adowa). The Italian army comprised four brigades totalling approximately 17,700 men, with fifty-six artillery pieces; the Ethiopian army comprised several brigades numbering between 73,000 and 120,000 men (80–100,000 with firearms: according to Pankhurst, the Ethiopians were armed with approximately 100,000 rifles of which about half were "fast firing"), with almost fifty artillery pieces.
General Baratieri planned to surprise the larger Ethiopian force with an early morning attack, expecting his enemy to be asleep. However, the Ethiopians had risen early for Church services and, upon learning of the Italian advance, promptly attacked. The Italian forces were hit by wave after wave of attacks, until Menelik released his reserve of 25,000 men, destroying an Italian brigade. Another brigade was cut off, and destroyed by a cavalry charge. The last two brigades were destroyed piecemeal. By noon, the Italian survivors were in full retreat.
While Menelik's victory was in a large part due to sheer force of numbers, his troops were well-armed because of his careful preparations. The Ethiopian army only had a feudal system of organization, but proved capable of properly executing the strategic plan drawn up in Menelik's headquarters. However, the Ethiopian army also had its problems. The first was the quality of its arms, as the Italian and British colonial authorities could sabotage the transportation of 30,000–60,000 modern Mosin–Nagant rifles and Berdan rifles from Russia into landlocked Ethiopia. Secondly, the Ethiopian army's feudal organization meant that nearly the entire force was composed of peasant militia. Russian military experts advising Menelik II suggested a full contact battle with Italians, to neutralize the Italian fire superiority, instead of engaging in a campaign of harassment designed to nullify problems with arms, training, and organization.
Some Russian councilors of Menelik II and a team of fifty Russian volunteers participated in the battle, among them Nikolay Leontiev, an officer of the Kuban Cossack army. Russian support for Ethiopia also led to a Russian Red Cross mission, which arrived in Addis Ababa some three months after Menelik's Adwa victory.
The Italians suffered about 7,000 killed and 1,500 wounded in the battle and subsequent retreat back into Eritrea, with 3,000 taken prisoner; Ethiopian losses have been estimated around 4,000–5,000 killed and 8,000 wounded. In addition, 2,000 Eritrean askaris were killed or captured. Italian prisoners were treated as well as possible under difficult circumstances, but 800 captured askaris, regarded as traitors by the Ethiopians, had their right hands and left feet amputated.
Outcome and consequences.
Menelik retired in good order to his capital, Addis Ababa, and waited for the fallout of the victory to hit Italy. The casualty rate suffered by Italian forces at the Battle of Adwa was greater than any other major European battle of the 19th century, beyond even the Napoleonic Era's Waterloo and Eylau. Riots broke out in several Italian cities, and within two weeks, the Crispi government collapsed amidst Italian disenchantment with "foreign adventures".
Menelik secured the Treaty of Addis Ababa in October, which delineated the borders of Eritrea and forced Italy to recognize the independence of Ethiopia. Delegations from the United Kingdom and France—whose colonial possessions lay next to Ethiopia—soon arrived in the Ethiopian capital to negotiate their own treaties with this newly proven power.

</doc>
<doc id="11778" url="https://en.wikipedia.org/wiki?curid=11778" title="Frederick Soddy">
Frederick Soddy

Frederick Soddy FRS (2 September 1877 – 22 September 1956) was an English radiochemist who explained, with Ernest Rutherford, that radioactivity is due to the transmutation of elements, now known to involve nuclear reactions. He also proved the existence of isotopes of certain radioactive elements.
Biography.
Soddy was born at 5 Bolton Road, Eastbourne, England. He went to school at Eastbourne College, before going on to study at University College of Wales at Aberystwyth and at Merton College, Oxford, where he graduated in 1898 with first class honors in chemistry. He was a researcher at Oxford from 1898 to 1900.
Scientific career.
In 1900 he became a demonstrator in chemistry at McGill University in Montreal, Quebec, where he worked with Ernest Rutherford on radioactivity.
He and Rutherford realized that the anomalous behaviour of radioactive elements was because they decayed into other elements.
This decay also produced alpha, beta, and gamma radiation. When radioactivity was first discovered, no one was sure what the cause was. It needed careful work by Soddy and Rutherford to prove that atomic transmutation was in fact occurring.
In 1903, with Sir William Ramsay at University College London, Soddy showed that the decay of radium produced helium gas. In the experiment a sample of radium was enclosed in a thin-walled glass envelope sited within an evacuated glass bulb. After leaving the experiment running for a long period of time, a spectral analysis of the contents of the former evacuated space revealed the presence of helium. Later in 1907, Rutherford and Thomas Royds showed that the helium was first formed as positively charged nuclei of helium (He) which were identical to alpha particles, which could pass through the thin glass wall but were contained within the surrounding glass envelope.
From 1904 to 1914, Soddy was a lecturer at the University of Glasgow. 
In May 1910 Soddy was elected a Fellow of the Royal Society. In 1914 he was appointed to a chair at the University of Aberdeen, where he worked on research related to World War I.
The work that Soddy and his research assistant Ada Hitchins did at Glasgow and Aberdeen showed that uranium decays to radium. It also showed that a radioactive element may have more than one atomic mass though the chemical properties are identical. Soddy named this concept isotope meaning 'same place'. The word 'isotope' was initially suggested to him by Margaret Todd. Later, J.J. Thomson showed that non-radioactive elements can also have multiple isotopes.
In 1913, Soddy also showed that an atom moves lower in atomic number by two places on alpha emission, higher by one place on beta emission. This was discovered at about the same time by Kazimierz Fajans, and is known as the radioactive displacement law of Fajans and Soddy, a fundamental step toward understanding the relationships among families of radioactive elements. Soddy published "The Interpretation of Radium" (1909) and "Atomic Transmutation" (1953).
In 1918 he announced discovery of a stable isotope of Protactinium, working with John Arnold Cranston. This slightly post-dated its discovery by German counterparts, however, it is said their discovery was actually made in 1915 but its announcement was delayed due to Cranston's notes being locked away whilst on active service in the First World War.
In 1919 he moved to the University of Oxford as Dr Lee's Professor of Chemistry, where, in the period up till 1936, he reorganized the laboratories and the syllabus in chemistry. He received the 1921 Nobel Prize in chemistry for his research in radioactive decay and particularly for his formulation of the theory of isotopes.
Satoyasu Iimori, who was a Japanese chemist from RIKEN, learned under Soddy in 1920–21.
His work and essays popularising the new understanding of radioactivity was the main inspiration for H. G. Wells's "The World Set Free" (1914), which features atomic bombs dropped from biplanes in a war set many years in the future. Wells's novel is also known as "The Last War" and imagines a peaceful world emerging from the chaos. In "Wealth, Virtual Wealth and Debt" Soddy praises Wells’s "The World Set Free". He also says that radioactive processes probably power the stars.
Economics.
In four books written from 1921 to 1934, Soddy carried on a "campaign for a radical restructuring of global monetary relationships", offering a perspective on economics rooted in physics—the laws of thermodynamics, in particular—and was "roundly dismissed as a crank". While most of his proposals - "to abandon the gold standard, let international exchange rates float, use federal surpluses and deficits as macroeconomic policy tools that could counter cyclical trends, and establish bureaus of economic statistics (including a consumer price index) in order to facilitate this effort" - are now conventional practice, his critique of fractional-reserve banking still "remains outside the bounds of conventional wisdom". Soddy wrote that financial debts grew exponentially at compound interest but the real economy was based on exhaustible stocks of fossil fuels. Energy obtained from the fossil fuels could not be used again. This criticism of economic growth is echoed by his intellectual heirs in the now emergent field of ecological economics.
Anti-semitic views.
In "Wealth, Virtual Wealth and Debt" Soddy cites the Protocols of the Learned Elders of Zion as evidence to support the existence of a widespread belief in a "financial conspiracy to enslave the world". While he does not overtly state that he shares this belief, he does use the imagery of a Jewish conspiracy to bolster his claim that "A corrupt monetary system strikes at the very life of the nation." In the same document, he makes reference to "the semi-Oriental" who is "supreme" in "high finance" and to an "iridescent bubble of beliefs blown around the world by the Hebraic hierarchy". Later in life he published a pamphlet "Abolish Private Money, or Drown in Debt" (1939) with a noted publisher of anti-semitic texts. The influence of his writing is shown, for example, in this quote from Ezra Pound:
"Professor Frederick Soddy states that the Gold Standard monetary system has wrecked a scientific age! ... The world's bankers ... have not been content to take their share of modern wealth production -- great as it has been -- but they have refused to allow the masses of mankind to receive theirs."
Descartes' theorem.
He rediscovered the Descartes' theorem in 1936 and published it as a poem, "The Kiss Precise", quoted at Problem of Apollonius. The kissing circles in this problem are sometimes known as Soddy circles.
Honours and awards.
He received the Nobel Prize in Chemistry in 1921 and the same year he was elected member of the International Atomic Weights Committee. A small crater on the far side of the Moon as well as the radioactive Uranium mineral Soddyite are named after him; his contributions to his field were significant enough that the IUPAC would likely have named an element for him were it not for the orthographic and phonetic similarity and confusability between "soddium" and "sodium."
Personal life.
Soddy married Winifred Beilby, the daughter of Sir George Beilby, in 1908. He died in Brighton, England in 1956.

</doc>
<doc id="11780" url="https://en.wikipedia.org/wiki?curid=11780" title="Fur seal">
Fur seal

Fur seals are any of nine species of pinnipeds in the Otariidae family. One species, the northern fur seal ("Callorhinus ursinus") inhabits the North Pacific, while seven species in the "Arctocephalus" genus are found primarily in the Southern Hemisphere. They are much more closely related to sea lions than true seals, and share with them external ears (pinnae), relatively long and muscular foreflippers, and the ability to walk on all fours. They are marked by their dense underfur, which made them a long-time object of commercial hunting.
Taxonomy.
Until recently, fur seals were all grouped under a single subfamily of Pinnipedia, called Arctocephalinae, to contrast them with Otariinae – the sea lions – based on the most prominent common feature, namely the coat of dense underfur intermixed with guard hairs. Recent genetic evidence, however, suggests "Callorhinus" is more closely related to some sea lion species, and the fur seal/sea lion subfamily distinction has been eliminated from many taxonomies. Nonetheless, all fur seals have certain features in common: the fur, generally smaller sizes, farther and longer foraging trips, smaller and more abundant prey items and greater sexual dimorphism. For these reasons, the distinction remains useful.
Physical appearance.
Fur seals share with other otariids the ability to turn their rear limbs forward and move on all fours. Fur seals are generally smaller than sea lions. At under , the Galápagos fur seal is the smallest of all pinnipeds. However, their flippers tend to be proportionately longer, their pelage tends to be darker, and their vibrissae are more prominent. Males are often more than five times heavier than the females, making them among the most sexually dimorphic of all mammal groups.
Behavior and ecology.
Typically, fur seals gather during the summer in large assemblages at specific beaches or rocky outcrops to give birth and breed. All species are polygynous, meaning dominant males reproduce with more than one female. For most species, total gestation lasts about 11.5 months, including a several-month period of delayed implantation of the embryo. While northern fur seal males aggressively select and defend the specific females in their harems, males of southern species of fur seals tend to protect spatial territories, and females are free to choose or switch their mates according to their own preferences or social hierarchy. After several continuous days of nursing the newborn pups, females go on extended foraging trips that can last as long as a week, returning to the rookery to feed their pups until they are weaned. Males fast during the reproductive season, unwilling to leave their females or territories.
The remainder of the year, fur seals lead a largely pelagic existence in the open sea, pursuing their prey wherever it is abundant. Fur seals feed on moderately sized fish, squid, and krill. Several species of the southern fur seal also have sea birds, especially penguins, as part of their diets. The fur seals, in turn, are preyed upon by sharks, killer whales, and occasionally by larger sea lions.
When fur seals were hunted in the late 18th and early 19th centuries, they hauled out on remote islands where no predators were present. The hunters reported being able to club the unwary animals to death one after another, making the hunt profitable, though the price per seal skin was low.
Exploitation.
Many fur seal species were heavily exploited by commercial sealers, especially during the 19th century when their fur was highly valued. Beginning in the 1790s, the ports of Stonington and New Haven, Connecticut, were leaders of the American fur seal trade, which primarily entailed clubbing fur seals to death on uninhabited South Pacific islands, skinning them, and selling the hides in China. Many populations, notably the Guadalupe fur seal, northern fur seal, and Cape fur seal, suffered dramatic declines and are still recovering. Currently, most species are protected and hunting is mostly limited to subsistence harvest. Globally, most populations can be considered healthy, mostly because they often prefer remote habitats that are relatively inaccessible to humans. Nonetheless, environmental degradation, competition with fisheries, and climate change potentially pose threats to some populations.

</doc>
<doc id="11781" url="https://en.wikipedia.org/wiki?curid=11781" title="Frisian">
Frisian

Frisian usually refers to:
Frisian or Friesian may also refer to:

</doc>
<doc id="11784" url="https://en.wikipedia.org/wiki?curid=11784" title="Fauna (disambiguation)">
Fauna (disambiguation)

Fauna is a collective term for animal life.
Fauna may also refer to:

</doc>
<doc id="11786" url="https://en.wikipedia.org/wiki?curid=11786" title="Federico Fellini">
Federico Fellini

Federico Fellini (; 20 January 1920 – 31 October 1993) was an Italian film director and screenwriter. Known for his distinct style that blends fantasy and baroque images with earthiness, he is recognized as one of the most influential filmmakers of all time. Some of his films are placed in polls such as in "Cahiers du cinéma" and "Sight & Sound" as some of the greatest films of all time, with his 1963 film "8½" being listed as the 10th greatest film of all time by "Sight & Sound".
In a career spanning almost fifty years, Fellini won the Palme d'Or for "La Dolce Vita", was nominated for twelve Academy Awards, and directed four motion pictures that won Oscars in the category of Best Foreign Language Film. In 1993, he was awarded an honorary Oscar for Lifetime Achievement at the 65th Annual Academy Awards in Los Angeles.
Early life and education.
Rimini (1920–1938).
Fellini was born on 20 January 1920, to middle-class parents in Rimini, then a small town on the Adriatic Sea. His father, Urbano Fellini (1894–1956), born to a family of Romagnol peasants and small landholders from Gambettola, moved to Rome in 1915 as a baker apprenticed to the Pantanella pasta factory. His mother, Ida Barbiani (1896–1984), came from a bourgeois Catholic family of Roman merchants. Despite her family's vehement disapproval, she had eloped with Urbano in 1917 to live at his parents' home in Gambettola. A civil marriage followed in 1918 with the religious ceremony held at Santa Maria Maggiore in Rome a year later.
The couple settled in Rimini where Urbano became a traveling salesman and wholesale vendor. Fellini had two siblings: Riccardo (1921–1991), a documentary director for RAI Television, and Maria Maddalena (m. Fabbri; 1929–2002).
In 1924, Fellini started primary school in an institute run by the nuns of San Vincenzo in Rimini, attending the Carlo Tonni public school two years later. An attentive student, he spent his leisure time drawing, staging puppet shows, and reading "Il corriere dei piccoli", the popular children’s magazine that reproduced traditional American cartoons by Winsor McCay, George McManus and Frederick Burr Opper. (Opper’s Happy Hooligan would provide the visual inspiration for Gelsomina in Fellini's 1954 film "La Strada"; McCay’s "Little Nemo" would directly influence his 1980 film "City of Women".) In 1926, he discovered the world of Grand Guignol, the circus with Pierino the Clown, and the movies. Guido Brignone’s "Maciste all’Inferno" (1926), the first film he saw, would mark him in ways linked to Dante and the cinema throughout his entire career.
Enrolled at the Ginnasio Giulio Cesare in 1929, he made friends with Luigi ‘Titta’ Benzi, later a prominent Rimini lawyer (and the model for young Titta in "Amarcord" (1973)). In Mussolini’s Italy, Fellini and Riccardo became members of the "Avanguardista", the compulsory Fascist youth group for males. He visited Rome with his parents for the first time in 1933, the year of the maiden voyage of the transatlantic ocean liner "SS Rex" (which is shown in "Amarcord"). The sea creature found on the beach at the end of "La Dolce Vita" (1960) has its basis in a giant fish marooned on a Rimini beach during a storm in 1934.
Although Fellini adapted key events from his childhood and adolescence in films such as "I Vitelloni" (1953), "8½" (1963), and "Amarcord" (1973), he insisted that such autobiographical memories were inventions: 
In 1937, Fellini opened Febo, a portrait shop in Rimini. with the painter Demos Bonini. His first humorous article appeared in the "Postcards to Our Readers" section of Milan’s "Domenica del Corriere". Deciding on a career as a caricaturist and gag writer, Fellini travelled to Florence in 1938, where he published his first cartoon in the weekly "420". Failing his military culture exam, he graduated from high school in July 1938 after doubling the exam.
Rome (1939).
In September 1939, he enrolled in law school at the University of Rome to please his parents. Biographer Hollis Alpert reports that "there is no record of his ever having attended a class". Installed in a family pensione, he met another lifelong friend, the painter Rinaldo Geleng. Desperately poor, they unsuccessfully joined forces to draw sketches of restaurant and café patrons. Fellini eventually found work as a cub reporter on the dailies "Il Piccolo" and "Il Popolo di Roma" but quit after a short stint, bored by the local court news assignments.
Four months after publishing his first article in "Marc’Aurelio", the highly influential biweekly humour magazine, he joined the editorial board, achieving success with a regular column titled "But Are You Listening?" Described as “the determining moment in Fellini’s life”, the magazine gave him steady employment between 1939 and 1942, when he interacted with writers, gagmen, and scriptwriters. These encounters eventually led to opportunities in show business and cinema. Among his collaborators on the magazine’s editorial board were the future director Ettore Scola, Marxist theorist and scriptwriter Cesare Zavattini, and Bernardino Zapponi, a future Fellini screenwriter. Conducting interviews for "CineMagazzino" also proved congenial: when asked to interview Aldo Fabrizi, Italy’s most popular variety performer, he established such immediate personal rapport with the man that they collaborated professionally. Specializing in humorous monologues, Fabrizi commissioned material from his young protégé.
Career and later life.
Early screenplays (1940–1943).
Retained on business in Rimini, Urbano sent wife and family to Rome in 1940 to share an apartment with his son. Fellini and Ruggero Maccari, also on the staff of "Marc’Aurelio", began writing radio sketches and gags for films.
Not yet twenty and with Fabrizi’s help, Fellini obtained his first screen credit as a comedy writer on Mario Mattoli’s "Il pirata sono io" ("The Pirate's Dream"). Progressing rapidly to numerous collaborations on films at Cinecittà, his circle of professional acquaintances widened to include novelist Vitaliano Brancati and scriptwriter Piero Tellini. In the wake of Mussolini’s declaration of war against France and England on 10 June 1940, Fellini discovered Kafka’s "The Metamorphosis", Gogol, John Steinbeck and William Faulkner along with French films by Marcel Carné, René Clair, and Julien Duvivier. In 1941 he published "Il mio amico Pasqualino", a 74-page booklet in ten chapters describing the absurd adventures of Pasqualino, an alter ego.
Writing for radio while attempting to avoid the draft, Fellini met his future wife Giulietta Masina in a studio office at the Italian public radio broadcaster EIAR in the autumn of 1942. Well-paid as the voice of Pallina in Fellini's radio serial, "Cico and Pallina", Masina was also well known for her musical-comedy broadcasts which cheered an audience depressed by the war. In November 1942, Fellini was sent to Libya, occupied by Fascist Italy, to work on the screenplay of "I cavalieri del deserto" ("Knights of the Desert", 1942), directed by Osvaldo Valenti and Gino Talamo. Fellini welcomed the assignment as it allowed him "to secure another extension on his draft order". Responsible for emergency re-writing, he also directed the film's first scenes. When Tripoli fell under siege by British forces, he and his colleagues made a narrow escape by boarding a German military plane flying to Sicily. His African adventure, later published in "Marc’Aurelio" as "The First Flight", marked “the emergence of a new Fellini, no longer just a screenwriter, working and sketching at his desk, but a filmmaker out in the field”.
The apolitical Fellini was finally freed of the draft when an Allied air raid over Bologna destroyed his medical records. Fellini and Giulietta hid in her aunt’s apartment until Mussolini's fall on 25 July 1943. After dating for nine months, the couple were married on 30 October 1943. Several months later, Masina fell down the stairs and suffered a miscarriage. She gave birth to a son, Pierfederico, on 22 March 1945, but the child died of encephalitis a month later on 24 April 1945. The tragedy had enduring emotional and artistic repercussions.
Neorealist apprenticeship (1944–1949).
After the Allied liberation of Rome on 4 June 1944, Fellini and Enrico De Seta opened the Funny Face Shop where they survived the postwar recession drawing caricatures of American soldiers. He became involved with Italian Neorealism when Roberto Rossellini, at work on "Stories of Yesteryear" (later "Rome, Open City"), met Fellini in his shop proposing he contribute gags and dialogue for the script . Aware of Fellini’s reputation as Aldo Fabrizi’s “creative muse”, Rossellini also requested he try to convince the actor to play the role of Father Giuseppe Morosini, the parish priest executed by the SS on 4 April 1944.
In 1947, Fellini and Sergio Amidei received an Oscar nomination for the screenplay of "Rome, Open City".
Working as both screenwriter and assistant director on Rossellini’s "Paisà" ("Paisan") in 1946, Fellini was entrusted to film the Sicilian scenes in Maiori. In February 1948, he was introduced to Marcello Mastroianni, then a young theatre actor appearing in a play with Giulietta Masina. Establishing a close working relationship with Alberto Lattuada, Fellini co-wrote the director’s "Senza pietà" ("Without Pity") and "Il mulino del Po" ("The Mill on the Po"). Fellini also worked with Rossellini on the anthology film "L'Amore" (1948), co-writing the screenplay and in one segment titled, "The Miracle", acting opposite Anna Magnani. To play the role of a vagabond rogue mistaken by Magnani for a saint, Fellini had to bleach his black hair blond.
Early films (1950–1953).
In 1950 Fellini co-produced and co-directed with Alberto Lattuada "Variety Lights" ("Luci del varietà"), his first feature film. A backstage comedy set among the world of small-time travelling performers, it featured Giulietta Masina and Lattuada’s wife, Carla del Poggio. Its release to poor reviews and limited distribution proved disastrous for all concerned. The production company went bankrupt, leaving both Fellini and Lattuada with debts to pay for over a decade. In February 1950, "Paisà" received an Oscar nomination for the screenplay by Rossellini, Sergio Amidei, and Fellini.
After travelling to Paris for a script conference with Rossellini on "Europa '51", Fellini began production on "The White Sheik" in September 1951, his first solo-directed feature. Starring Alberto Sordi in the title role, the film is a revised version of a treatment first written by Michelangelo Antonioni in 1949 and based on the "fotoromanzi", the photographed cartoon strip romances popular in Italy at the time. Producer Carlo Ponti commissioned Fellini and Tullio Pinelli to write the script but Antonioni rejected the story they developed. With Ennio Flaiano, they re-worked the material into a light-hearted satire about newlywed couple Ivan and Wanda Cavalli (Leopoldo Trieste, Brunella Bovo) in Rome to visit the Pope. Ivan’s prissy mask of respectability is soon demolished by his wife’s obsession with the White Sheik. Highlighting the music of Nino Rota, the film was selected at Cannes (among the films in competition was Orson Welles’s "Othello") and then retracted. Screened at the 13th Venice International Film Festival, it was razzed by critics in "the atmosphere of a soccer match”. One reviewer declared that Fellini had “not the slightest aptitude for cinema direction".
In 1953, "I Vitelloni" found favour with the critics and public. Winning the Silver Lion Award in Venice, it secured Fellini’s first international distributor.
Beyond neorealism (1954–1960).
Fellini directed "La Strada" based on a script completed in 1952 with Pinelli and Flaiano. During the last three weeks of shooting, Fellini experienced the first signs of severe clinical depression. Aided by his wife, he undertook a brief period of therapy with Freudian psychoanalyst Emilio Servadio.
Fellini cast American actor Broderick Crawford to interpret the role of an aging swindler in "Il Bidone". Based partly on stories told to him by a petty thief during production of "La Strada", Fellini developed the script into a con man’s slow descent towards a solitary death. To incarnate the role’s "intense, tragic face", Fellini’s first choice had been Humphrey Bogart but after learning of the actor’s lung cancer, chose Crawford after seeing his face on the theatrical poster of "All the King’s Men" (1949). The film shoot was wrought with difficulties stemming from Crawford’s alcoholism. Savaged by critics at the 16th Venice International Film Festival, the film did miserable box office and did not receive international distribution until 1964.
During the autumn, Fellini researched and developed a treatment based on a film adaptation of Mario Tobino’s novel, "The Free Women of Magliano". Located in a mental institution for women, financial backers considered the subject had no potential and the project was abandoned.
While preparing "Nights of Cabiria" in spring 1956, Fellini learned of his father’s death by cardiac arrest at the age of sixty-two. Produced by Dino De Laurentiis and starring Giulietta Masina, the film took its inspiration from news reports of a woman’s severed head retrieved in a lake and stories by Wanda, a shantytown prostitute Fellini met on the set of "Il Bidone". Pier Paolo Pasolini was hired to translate Flaiano and Pinelli’s dialogue into Roman dialect and to supervise researches in the vice-afflicted suburbs of Rome. The movie won the Academy Award for Best Foreign Language Film at the 30th Academy Awards and brought Masina the Best Actress Award at Cannes for her performance.
With Pinelli, he developed "Journey with Anita" for Sophia Loren and Gregory Peck. An "invention born out of intimate truth", the script was based on Fellini's return to Rimini with a mistress to attend his father's funeral. Due to Loren’s unavailability, the project was shelved and resurrected twenty-five years later as "Lovers and Liars" (1981), a comedy directed by Mario Monicelli with Goldie Hawn and Giancarlo Giannini. For Eduardo De Filippo, he co-wrote the script of "Fortunella", tailoring the lead role to accommodate Masina’s particular sensibility.
The Hollywood on the Tiber phenomenon of 1958 in which American studios profited from the cheap studio labour available in Rome provided the backdrop for photojournalists to steal shots of celebrities on the via Veneto. The scandal provoked by Turkish dancer Haish Nana’s improvised striptease at a nightclub captured Fellini’s imagination: he decided to end his latest script-in-progress, "Moraldo in the City", with an all-night "orgy" at a seaside villa. Pierluigi Praturlon’s photos of Anita Ekberg wading fully dressed in the Trevi Fountain provided further inspiration for Fellini and his scriptwriters. Changing the title of the screenplay to "La Dolce Vita", Fellini soon clashed with his producer on casting: the director insisted on the relatively unknown Mastroianni while De Laurentiis wanted Paul Newman as a hedge on his investment. Reaching an impasse, De Laurentiis sold the rights to publishing mogul Angelo Rizzoli. Shooting began on 16 March 1959 with Anita Ekberg climbing the stairs to the cupola of Saint Peter’s in a mammoth décor constructed at Cinecittà. The statue of Christ flown by helicopter over Rome to Saint Peter's Square was inspired by an actual media event on 1 May 1956, which Fellini had witnessed. The film wrapped August 15 on a deserted beach at Passo Oscuro with a bloated mutant fish designed by Piero Gherardi.
"La Dolce Vita" broke all box office records. Despite scalpers selling tickets at 1000 lire, crowds queued in line for hours to see an “immoral movie” before the censors banned it. At an exclusive Milan screening on 5 February 1960, one outraged patron spat on Fellini while others hurled insults. Denounced in parliament by right-wing conservatives, undersecretary Domenico Magrì of the Christian Democrats demanded tolerance for the film’s controversial themes. The Vatican's official press organ, "l'Osservatore Romano", lobbied for censorship while the Board of Roman Parish Priests and the Genealogical Board of Italian Nobility attacked the film. In one documented instance involving favourable reviews written by the Jesuits of San Fedele, defending "La Dolce Vita" had severe consequences. In competition at Cannes alongside Antonioni’s "L’Avventura", the film won the Palme d'Or awarded by presiding juror Georges Simenon. The Belgian writer was promptly “hissed at” by the disapproving festival crowd.
Art films and dreams (1961–1969).
A major discovery for Fellini after his Italian neorealism period (1950–1959) was the work of Carl Jung. After meeting Jungian psychoanalyst Dr. Ernst Bernhard in early 1960, he read Jung's autobiography, "Memories, Dreams, Reflections" (1963). Bernhard also recommended that Fellini consult the "I Ching" and keep a record of his dreams. What Fellini formerly accepted as "his extrasensory perceptions" were now interpreted as psychic manifestations of the unconscious. Bernhard’s focus on Jungian depth psychology proved to be the single greatest influence on Fellini’s mature style and marked the turning point in his work from neorealism to filmmaking that was "primarily oneiric". As a consequence, Jung's seminal ideas on the "anima" and the "animus", the role of archetypes and the collective unconscious directly influenced such films as "8½" (1963), "Juliet of the Spirits" (1965), "Fellini Satyricon" (1969), "Casanova" (1976), and "City of Women" (1980). Other key influences on his work include Luis Buñuel, Charlie Chaplin, Sergei Eisenstein, Buster Keaton, Laurel and Hardy, the Marx Brothers, and Roberto Rossellini.
Exploiting "La Dolce Vita"’s success, financier Angelo Rizzoli set up Federiz in 1960, an independent film company, for Fellini and production manager Clemente Fracassi to discover and produce new talent. Despite the best intentions, their overcautious editorial and business skills forced the company to close down soon after cancelling Pasolini’s project, "Accattone" (1961).
Condemned as a "public sinner" for "La Dolce Vita", Fellini responded with "The Temptations of Doctor Antonio", a segment in the omnibus "Boccaccio '70". His first colour film, it was the sole project green-lighted at Federiz. Infused with the surrealistic satire that characterized the young Fellini’s work at "Marc’Aurelio", the film ridiculed a crusader against vice, interpreted by Peppino De Filippo, who goes insane trying to censor a billboard of Anita Ekberg espousing the virtues of milk.
In an October 1960 letter to his colleague Brunello Rondi, Fellini first outlined his film ideas about a man suffering creative block: "Well then - a guy (a writer? any kind of professional man? a theatrical producer?) has to interrupt the usual rhythm of his life for two weeks because of a not-too-serious disease. It’s a warning bell: something is blocking up his system." Unclear about the script, its title, and his protagonist’s profession, he scouted locations throughout Italy “looking for the film” in the hope of resolving his confusion. Flaiano suggested "La bella confusione" (literally "The Beautiful Confusion") as the movie’s title. Under pressure from his producers, Fellini finally settled on "8½", a self-referential title referring principally (but not exclusively) to the number of films he had directed up to that time.
Giving the order to start production in spring 1962, Fellini signed deals with his producer Rizzoli, fixed dates, had sets constructed, cast Mastroianni, Anouk Aimée, and Sandra Milo in lead roles, and did screen tests at the Scalera Studios in Rome. He hired cinematographer Gianni Di Venanzo, among key personnel. But apart from naming his hero Guido Anselmi, he still couldn't decide what his character did for a living. The crisis came to a head in April when, sitting in his Cinecittà office, he began a letter to Rizzoli confessing he had "lost his film" and had to abandon the project. Interrupted by the chief machinist requesting he celebrate the launch of "8½", Fellini put aside the letter and went on the set. Raising a toast to the crew, he "felt overwhelmed by shame… I was in a no exit situation. I was a director who wanted to make a film he no longer remembers. And lo and behold, at that very moment everything fell into place. I got straight to the heart of the film. I would narrate everything that had been happening to me. I would make a film telling the story of a director who no longer knows what film he wanted to make".
Shooting began on 9 May 1962. Perplexed by the seemingly chaotic, incessant improvisation on the set, Deena Boyer, the director’s American press officer at the time, asked for a rationale. Fellini told her that he hoped to convey the three levels "on which our minds live: the past, the present, and the conditional - the realm of fantasy". After shooting wrapped on 14 October, Nino Rota composed various circus marches and fanfares that would later become signature tunes of the maestro’s cinema. Nominated for four Oscars, "8½" won awards for best foreign language film and best costume design in black-and-white. In California for the ceremony, Fellini toured Disneyland with Walt Disney the day after.
Increasingly attracted to parapsychology, Fellini met the Turin magician Gustavo Rol in 1963. Rol, a former banker, introduced him to the world of Spiritism and séances. In 1964, Fellini took LSD under the supervision of Emilio Servadio, his psychoanalyst during the 1954 production of "La Strada". For years reserved about what actually occurred that Sunday afternoon, he admitted in 1992 that
objects and their functions no longer had any significance. All I perceived was perception itself, the hell of forms and figures devoid of human emotion and detached from the reality of my unreal environment. I was an instrument in a virtual world that constantly renewed its own meaningless image in a living world that was itself perceived outside of nature. And since the appearance of things was no longer definitive but limitless, this paradisiacal awareness freed me from the reality external to my self. The fire and the rose, as it were, became one.
Fellini's hallucinatory insights were given full flower in his first colour feature "Juliet of the Spirits" (1965), depicting Giulietta Masina as Juliet, a housewife who rightly suspects her husband's infidelity and succumbs to the voices of spirits summoned during a séance at her home. Her sexually voracious next door neighbor Suzy (Sandra Milo) introduces Juliet to a world of uninhibited sensuality but Juliet is haunted by childhood memories of her Catholic guilt and a teenaged friend who committed suicide. Complex and filled with psychological symbolism, the film is set to a jaunty score by Nino Rota.
Nostalgia, sexuality, and politics (1970–1980).
To help promote "Satyricon" in the United States, Fellini flew to Los Angeles in January 1970 for interviews with Dick Cavett and David Frost. He also met with film director Paul Mazursky who wanted to star him alongside Donald Sutherland in his new film, "Alex in Wonderland". In February, Fellini scouted locations in Paris for "The Clowns", a docufiction both for cinema and television, based on his childhood memories of the circus and a "coherent theory of clowning." As he saw it, the clown "was always the caricature of a well-established, ordered, peaceful society. But today all is temporary, disordered, grotesque. Who can still laugh at clowns?... All the world plays a clown now."
In March 1971, Fellini began production on "Roma", a seemingly random collection of episodes informed by the director's memories and impressions of Rome. The "diverse sequences," writes Fellini scholar Peter Bondanella, "are held together only by the fact that they all ultimately originate from the director’s fertile imagination." The film’s opening scene anticipates "Amarcord" while its most surreal sequence involves an ecclesiastical fashion show in which nuns and priests roller skate past shipwrecks of cobwebbed skeletons.
Over a period of six months between January and June 1973, Fellini shot the Oscar-winning "Amarcord". Loosely based on the director’s 1968 autobiographical essay "My Rimini", the film depicts the adolescent Titta and his friends working out their sexual frustrations against the religious and Fascist backdrop of a provincial town in Italy during the 1930s. Produced by Franco Cristaldi, the seriocomic movie became Fellini’s second biggest commercial success after "La Dolce Vita". Circular in form, "Amarcord" avoids plot and linear narrative in a way similar to "The Clowns" and "Roma". The director's overriding concern with developing a poetic form of cinema was first outlined in a 1965 interview he gave to "The New Yorker" journalist Lillian Ross: "I am trying to free my work from certain constrictions – a story with a beginning, a development, an ending. It should be more like a poem with metre and cadence."
Late films and projects (1981–1990).
Organized by his publisher Diogenes Verlag in 1982, the first major exhibition of 63 drawings by Fellini was held in Paris, Brussels, and the Pierre Matisse Gallery in New York. A gifted caricaturist, much of the inspiration for his sketches was derived from his own dreams while the films-in-progress both originated from and stimulated drawings for characters, decor, costumes and set designs. Under the title, "I disegni di Fellini" (Fellini’s Designs), he published 350 drawings executed in pencil, watercolours, and felt pens.
On 6 September 1985 Fellini was awarded the Golden Lion for lifetime achievement at the 42nd Venice Film Festival. That same year, he became the first non-American to receive the Film Society of Lincoln Center’s annual award for cinematic achievement.
Long fascinated by Carlos Castaneda’s "", Fellini accompanied the Peruvian author on a journey to the Yucatán to assess the feasibility of a film. After first meeting Castaneda in Rome in October 1984, Fellini drafted a treatment with Pinelli titled "Viaggio a Tulun". Producer Alberto Grimaldi, prepared to buy film rights to all of Castaneda’s work, then paid for pre-production research taking Fellini and his entourage from Rome to Los Angeles and the jungles of Mexico in October 1985. When Castaneda inexplicably disappeared and the project fell through, Fellini’s mystico-shamanic adventures were scripted with Pinelli and serialized in "Corriere della Sera" in May 1986. A barely veiled satirical interpretation of Castaneda's work, "Viaggio a Tulun" was published in 1989 as a graphic novel with artwork by Milo Manara and as "Trip to Tulum" in America in 1990.
For "Intervista", produced by Ibrahim Moussa and RAI Television, Fellini intercut memories of the first time he visited Cinecittà in 1939 with present-day footage of himself at work on a screen adaptation of Franz Kafka’s "Amerika". A meditation on the nature of memory and film production, it won the special 40th Anniversary Prize at Cannes and the 15th Moscow International Film Festival Golden Prize. In Brussels later that year, a panel of thirty professionals from eighteen European countries named Fellini the world’s best director and "8½" the best European film of all time.
In early 1989 Fellini began production on "The Voice of the Moon", based on Ermanno Cavazzoni’s novel, "Il poema dei lunatici" ("The Lunatics' Poem"). A small town was built at Empire Studios on the via Pontina outside Rome. Starring Roberto Benigni as Ivo Salvini, a madcap poetic figure newly released from a mental institution, the character is a combination of "La Strada"'s Gelsomina, Pinocchio, and Italian poet Giacomo Leopardi. Fellini improvised as he filmed, using as a guide a rough treatment written with Pinelli. Despite its modest critical and commercial success in Italy, and its warm reception by French critics, it failed to interest North American distributors.
Fellini won the "Praemium Imperiale", the equivalent of the Nobel Prize in the visual arts, awarded by the Japan Art Association in 1990.
Final years (1991–1993).
In July 1991 and April 1992, Fellini worked in close collaboration with Canadian filmmaker Damian Pettigrew to establish "the longest and most detailed conversations ever recorded on film". Described as the "Maestro's spiritual testament” by his biographer Tullio Kezich, excerpts culled from the conversations later served as the basis of their feature documentary, ' (2002) and the book, '. Finding it increasingly difficult to secure financing for feature films, Fellini developed a suite of television projects whose titles reflect their subjects: "Attore", "Napoli", "L’Inferno", "L’opera lirica", and "L’America".
In April 1993 Fellini received his fifth Oscar, for lifetime achievement, "in recognition of his cinematic accomplishments that have thrilled and entertained audiences worldwide". On 16 June, he entered the Cantonal Hospital in Zurich for an angioplasty on his femoral artery but suffered a stroke at the Grand Hotel in Rimini two months later. Partially paralyzed, he was first transferred to Ferrara for rehabilitation and then to the Policlinico Umberto I in Rome to be near his wife, also hospitalized. He suffered a second stroke and fell into an irreversible coma. Fellini died in Rome on 31 October at the age of 73, a day after his fiftieth wedding anniversary. The memorial service was held in Studio 5 at Cinecittà attended by an estimated 70,000 people. At the request of Giulietta Masina, trumpeter Mauro Maur played the "Improvviso dell'Angelo" by Nino Rota during the funeral ceremony. Five months later on 23 March 1994, Giulietta Masina died of lung cancer.
Fellini, Masina and their son Pierfederico are buried in a bronze sepulchre sculpted by Arnaldo Pomodoro. Designed as a ship's prow, the tomb is located at the main entrance to the Cemetery of Rimini. The Federico Fellini Airport in Rimini is named in his honour.
Political views.
Despite various famous Italian actors favouring the Communists, Fellini, who was not left-wing, supported Christian Democracy (DC), opposed the '68 Movement, and befriended Giulio Andreotti. Apart from satirizing Silvio Berlusconi and mainstream television in "Ginger and Fred", Fellini rarely expressed his political views in public and never directed a political film. He also directed two electoral television spots during the 1990s: one for DC and another for the Italian Republican Party or PRI.
His slogan, "Non si interrompe un'emozione" ("Don't interrupt an emotion"), was directed against the excessive use of advertisements in TV. The slogan was also used by the Democratic Party of the Left in the referendums of 1995.
Influence and legacy.
Personal and highly idiosyncratic visions of society, Fellini's films are a unique combination of memory, dreams, fantasy and desire. The adjectives "Fellinian" and "Felliniesque" are "synonymous with any kind of extravagant, fanciful, even baroque image in the cinema and in art in general". "La Dolce Vita" contributed the term "paparazzi" to the English language, derived from Paparazzo, the photographer friend of journalist Marcello Rubini (Marcello Mastroianni).
Contemporary filmmakers such as Tim Burton, Terry Gilliam, Emir Kusturica, and David Lynch, have cited Fellini's influence on their work.
Polish director Wojciech Has, whose two major films, "The Saragossa Manuscript" (1965) and "The Hour-Glass Sanatorium" (1973), are examples of modernist fantasies, has been compared to Fellini for the sheer "luxuriance of his images".
"I Vitelloni" inspired European directors Juan Antonio Bardem, Marco Ferreri, and Lina Wertmüller and had an influence on Martin Scorsese's "Mean Streets" (1973), George Lucas's "American Graffiti" (1974), Joel Schumacher's "St. Elmo's Fire" (1985), and Barry Levinson's "Diner" (1987), among many others. When the American magazine "Cinema" asked Stanley Kubrick in 1963 to name his favorite films, the film director listed "I Vitelloni" as number one in his Top 10 list.
"Nights of Cabiria" was adapted as the Broadway musical "Sweet Charity" and the movie "Sweet Charity" (1969) by Bob Fosse starring Shirley MacLaine. "City of Women" was adapted for the Berlin stage by Frank Castorf in 1992.
"8½" inspired among others: "Mickey One" (Arthur Penn, 1965), "Alex in Wonderland" (Paul Mazursky, 1970), "Beware of a Holy Whore" (Rainer Werner Fassbinder, 1971), "Day for Night" (François Truffaut, 1973), "All That Jazz" (Bob Fosse, 1979), "Stardust Memories" (Woody Allen, 1980), "Sogni d'oro" (Nanni Moretti, 1981), "Parad Planet" (Vadim Abdrashitov, 1984), "La Pelicula del rey" (Carlos Sorin, 1986), "Living in Oblivion" (Tom DiCillo, 1995), "8½ Women" (Peter Greenaway, 1999), "Falling Down" (Joel Schumacher, 1993), along with the successful Broadway musical, "Nine" (Maury Yeston and Arthur Kopit, 1982). "Yo-Yo Boing!" (1998), a Spanish novel by Puerto Rican writer Giannina Braschi, features a dream sequence with Fellini that was inspired by "8½".
Fellini’s work is referenced on the albums "Fellini Days" (2001) by Fish, "Another Side of Bob Dylan" (1964) by "Bob Dylan" with "Motorpsycho Nitemare", "Funplex" (2008) by the B-52's with the song "Juliet of the Spirits", and in the opening traffic jam of the music video "Everybody Hurts" by R.E.M. American singer Lana Del Rey has cited Fellini as an influence. It also influenced two American TV shows, "Northern Exposure" and "Third Rock from the Sun". Wes Anderson's short film "Castello Cavalcanti" (2013) is in many places a direct homage to Fellini's work.
Various film related material and personal papers of Fellini are contained in the Wesleyan University Cinema Archives to which scholars and media experts from around the world may have full access. In October 2009, the Jeu de Paume in Paris opened an exhibit devoted to Fellini that included ephemera, television interviews, behind-the-scenes photographs, "Book of Dreams" (based on 30 years of the director's illustrated dreams and notes), along with excerpts from "La dolce vita" and "8½".
In 2014, the Blue Devils Drum and Bugle Corps of Concord, California performed a show themed around Fellini's works, entitled "Felliniesque", with which the Blue Devils won a record 16th Drum Corps International World Class championship with a record score of 99.650. That same year, the weekly entertainment-trade magazine "Variety" announced that French director Sylvain Chomet was moving forward with the project, "The Thousand Miles", based on various works of Fellini including his unpublished drawings and writings.
Further reading.
General

</doc>
<doc id="11787" url="https://en.wikipedia.org/wiki?curid=11787" title="Fleetwood Mac">
Fleetwood Mac

Fleetwood Mac are a British-American rock band formed in July 1967, in London. The band have sold more than 100 million records worldwide, making them one of the best-selling bands of all time. In 1998, selected members of Fleetwood Mac were inducted into the Rock and Roll Hall of Fame, and received the Brit Award for Outstanding Contribution to Music.
The two most successful periods for the band were during the late 1960s British blues boom, when they were led by guitarist Peter Green and achieved a UK number one with "Albatross"; and from 1975 to 1987, as a more pop-oriented act, featuring Christine McVie, Lindsey Buckingham and Stevie Nicks. Fleetwood Mac's second album after the incorporation of Buckingham and Nicks, 1977's "Rumours", produced four U.S. Top 10 singles (including Nicks' song "Dreams"), and remained at No. 1 on the American albums chart for 31 weeks, as well as reaching the top spot in various countries around the world. To date, the album has sold over 40 million copies worldwide, making it the eighth-highest-selling album of all time.
The band achieved more modest success between 1971 and 1974, when the line-up included Bob Welch, during the 1990s in between the departure and return of Nicks and Buckingham, and during the 2000s between the departure and return of Christine McVie.
Due to numerous lineup changes, the only original member present in the band is drummer Mick Fleetwood. Although band founder Green named the group by combining the surnames of two of his former bandmates (Fleetwood and McVie) from John Mayall's Bluesbreakers, bassist John McVie played neither on their first single nor at their first concerts, as he initially decided to stay with Mayall. Keyboardist Christine McVie, who joined the band in 1970 while married to John McVie, has appeared on every album except the debut album, either as a member or as a session musician. She left the band in 1998 but returned in 2014.
History.
Formation and early years (1967–71).
Fleetwood Mac were formed in July 1967 in London when Peter Green left the British blues band John Mayall & the Bluesbreakers. Green had replaced guitarist Eric Clapton in the Bluesbreakers, and received critical acclaim for his work on their album "A Hard Road". After he had been in the Bluesbreakers for some time, Green asked if drummer Mick Fleetwood could replace Aynsley Dunbar. Green had been in two bands with Fleetwood—Peter B's Looners and the subsequent Shotgun Express (which featured a young Rod Stewart as vocalist). John Mayall agreed and Fleetwood became a member of the band.
The Bluesbreakers now consisted of Green, Fleetwood, John McVie and Mayall. Mayall gave Green free recording time as a gift, in which Fleetwood, McVie and Green recorded five songs. The fifth song was an instrumental which Green named after the rhythm section, "Fleetwood Mac".
Soon after, Green contacted Fleetwood to form a new band. The pair wanted McVie on bass guitar and even named the band 'Fleetwood Mac' as a way to entice him. However, McVie opted to keep his steady income with Mayall rather than take a risk with a new band. In the meantime Peter Green and Mick Fleetwood teamed up with slide guitarist Jeremy Spencer and bassist Bob Brunning, who was in the band on the understanding that he would leave if McVie agreed to join. The Green, Fleetwood, Spencer, Brunning version of the band made its debut on 13 August 1967 at the Windsor Jazz and Blues Festival as Peter Green's Fleetwood Mac featuring Jeremy Spencer. Within weeks of this show, John McVie agreed to join the band as permanent bassist.
Fleetwood Mac's first album, "Fleetwood Mac", was a no-frills blues album and was released on the Blue Horizon label in February 1968. In fact there were no other players on the album (except for the song "Long Grey Mare", which was recorded with Brunning on bass). The album was successful in the UK, hitting No. 4, though it did not have any singles on it. The band soon released two singles "Black Magic Woman" (later a big hit for Santana) and "Need Your Love So Bad".
The band's second album, "Mr. Wonderful", was released in August 1968. Like the first it was an all-blues album, but this time they made a few changes. The album was recorded live in the studio with miked amplifiers and PA system, rather than plugged into the board. This method provided the ideal environment for producing this style of music, and gave it an authentically vintage sound. They also added horns and featured a friend of the band on keyboards, Christine Perfect of Chicken Shack prior to her marriage to John McVie.
Shortly after the release of their second album Fleetwood Mac added guitarist Danny Kirwan, then just eighteen years old, to their line-up, recruited from the South London blues trio Boilerhouse, consisting of Kirwan on guitar with Trevor Stevens on bass and Dave Terrey on drums. Green and Fleetwood had been to watch Boilerhouse rehearse in a basement boiler-room and Green was so impressed, he invited the band to play support slots for Fleetwood Mac. Green wanted Boilerhouse to become a professional band but Stevens and Terrey were not prepared to turn professional at the time, so Green sought to find another rhythm section by placing an ad in Melody Maker. There were over 300 applicants, but when Green and Fleetwood ran auditions at the Nag's Head in Battersea (home of the Mike Vernon Blue Horizon Club), the hard to please Green could not find anyone good enough to replace the pair, so he invited Kirwan to join Fleetwood Mac as their third guitarist.
Green had been frustrated that Jeremy Spencer had little desire to contribute to Green's songs. A mature and accomplished self-taught guitarist, Kirwan's signature vibrato and unique style added a new dimension to an already complete band. With Kirwan the band released their first number one single in Europe, "Albatross". Around this time they released their second American album, "English Rose", which contained half of "Mr. Wonderful", new songs from Kirwan, and their third European album called "The Pious Bird of Good Omen", which was a collection of singles, B-sides, and a selection of some work the band did with Eddie Boyd.
When the band went to the United States in January 1969 they recorded many songs at the soon-to-close Chess Records Studio, with some blues legends of Chicago including Willie Dixon, Buddy Guy and Otis Spann. These would prove, however, to be Fleetwood Mac's last all-blues recordings. Along with their change of style the band was also going through some label changes. Up until this point they had been on Blue Horizon. With Kirwan in the band, however, the musical possibilities were too great for them to stay on a blues-only label. The band signed with the Immediate Records label and released "Man of the World", another British and European hit single. For the B-side Spencer fronted Fleetwood Mac as "Earl Vince and the Valiants" and recorded "Somebody's Gonna Get Their Head Kicked In Tonite", typifying the more raucous rock 'n' roll side of the band. Immediate Records was in bad shape and the band shopped around for a new deal. Even though The Beatles wanted the band on Apple Records (Mick Fleetwood and George Harrison were brothers-in-law), the band's manager Clifford Davis decided to go with Warner Bros. Records (through Reprise Records, a Frank Sinatra-founded label), the label they have stayed with ever since.
Fleetwood Mac's first album for Reprise, released in September 1969, was the well-regarded "Then Play On". Although the initial pressing of the American release of this album was the same as the British version, it was altered to contain the song "Oh Well", featured consistently in live performances from the time of its release through 1997 and then again starting in 2009. "Then Play On", which was the band's first rock album, featured only the songs of Kirwan and Green. Jeremy Spencer, meanwhile, recorded a solo album (he was backed by the rest of the band) which consisted of many 1950s-style rock and roll songs.
In July 1969, Fleetwood Mac opened for Ten Years After at the Schaefer Music Festival at New York City's Wollman Rink. They re-appeared at the festival in 1970.
Fleetwood Mac were an extremely popular band in Europe at the time. However, Peter Green, the frontman of the band, was not in good health. He had taken LSD in Munich, which may have contributed to the onset of his schizophrenia. German author and filmmaker Rainer Langhans mentions in his autobiography that he and Uschi Obermaier met Peter Green in Munich, where they invited him to their "High-Fish-Commune". They were not really interested in Green; they just wanted to get in contact with Mick Taylor: Langhans and Obermaier wished to organise a "Bavarian Woodstock". They wanted Jimi Hendrix and The Rolling Stones to be the leading acts of their Bavarian open air festival. They needed Green just to get in contact with The Rolling Stones via Mick Taylor.
Green's last hit with Fleetwood Mac was "The Green Manalishi (With the Two-Prong Crown)" (first recorded at the Boston Tea Party in February 1970 and later recorded by Judas Priest). This recording was released as Green's mental stability deteriorated, and he wanted to give all of the band's money to charity. Other members of the band did not agree, and subsequently Green decided to leave the band. His last show with Fleetwood Mac was on 20 May 1970. During that show, the band went past their allotted time and the power was shut off, although Mick Fleetwood kept drumming. Some of the Boston Tea Party recordings (5/6/7 February 1970) were eventually released in the 1980s as the "Live in Boston" album, with a more complete remastered 3-volume compilation released by Snapper Music in the late 90s.
Transitional era (1970–74).
Kirwan and Spencer were left with the task of having to fill up Peter's space in their live shows and on their recordings. In September 1970, Fleetwood Mac released "Kiln House." Kirwan's songs moved the band in the direction of rock. Meanwhile, Spencer's contributions focused on re-creating the country-tinged "Sun Sound" of the late 1950s. Christine Perfect, who had retired from the music business after one unsuccessful solo album, contributed to "Kiln House", singing backup vocals, and drawing the album cover. Since Fleetwood Mac were progressing and developing a new sound, Perfect was asked to join the band. They also released a single at that time; "Dragonfly" b/w "The Purple Dancer" in the U.K. and certain European countries. Despite good notices in the press, the single was not a success and the B-side has been reissued only once, on a Reprise German-only "Best of" album, making it one of their most obscure songs.
Christine Perfect, who was married to bassist John McVie, made her first appearance with the band as Christine McVie at Bristol University in May 1969 just as she was leaving Chicken Shack. She had success with the Etta James classic, "I'd Rather Go Blind", and was twice voted female artist of the year in England. Christine McVie played her first gig as an official member on 6 August 1970 in New Orleans. CBS Records, which now owned Blue Horizon (except in the US and Canada), released an album of previously unreleased material from the original Fleetwood Mac called "The Original Fleetwood Mac". The album was relatively successful, and the band continued to gain popularity.
While on tour in February 1971, Jeremy Spencer said he was going out to "get a magazine", but never returned. After several days of frantic searching, the band discovered that Spencer had joined a religious group, the Children of God. Liable for the remaining shows on the tour, they convinced Peter Green to help finish the tour. He brought along his friend, Nigel Watson, who played the congas (twenty-five years later Green and Watson collaborated again to form the Peter Green Splinter Group). Green, however, would only be back with Fleetwood Mac temporarily, so the band decided to search for a new guitarist.
In the summer of 1971, the band held auditions for a guitarist in their large country home, "Benifold", which they bought prior to the "Kiln House" tour. A friend of the band named Judy Wong recommended her high school friend, Bob Welch, who was living in Paris at the time. The band had a few meetings with Welch and decided to hire him, without actually playing with him or listening to any of his recordings.
In September 1971, the band released "Future Games". Due to Welch's arrival and Spencer's departure, the album was different from anything the band had done up to that point, and there were many new fans in America who were becoming more and more interested in the band. In Europe, CBS released Fleetwood Mac's first Greatest Hits package, which was predominantly composed of songs by Peter Green, though there was one song by Spencer and one by Kirwan.
In 1972, six months after the release of "Future Games", the band released the well-received album "Bare Trees". Though mostly composed by Kirwan, "Bare Trees" featured Welch's "Sentimental Lady", which would be a much bigger hit for him five years later when he re-recorded it for his solo album "French Kiss", backed with Mick Fleetwood and Christine McVie. It also featured "Spare Me a Little of Your Love", a bright Christine McVie tune that became a staple of the band's live act throughout the early to mid-1970s.
While the band was doing well in the studio, their tours were more problematic. Danny Kirwan developed an alcohol dependency and became alienated from Welch and the McVies. It was not until he smashed his Les Paul Custom guitar before a concert, refused to go on stage, and criticised the band afterwards that Fleetwood was finally convinced that he had no choice but to fire Kirwan.
The next two and a half years proved to be the most challenging for the band. In the three albums they released in this period, they constantly changed line-ups. In September 1972, the band added guitarist Bob Weston and vocalist Dave Walker, formerly of Savoy Brown and Idle Race. Bob Weston was well known for playing slide guitar and had known the band from his touring period with Long John Baldry. Fleetwood Mac also hired Savoy Brown's road manager, John Courage. Mick, John, Christine, Welch, Weston, and Walker recorded "Penguin", which was released in January 1973. After the tour, the band fired Walker because his vocal style and attitude did not fit in with the rest of the band.
The remaining five carried on and recorded "Mystery to Me" six months later. This album contained Welch's song "Hypnotized" which got a lot of airplay on the radio and became one of the band's most successful songs to date in the US. The band was proud of the new album and anticipated that it would be a hit. However, things were not well within the band. The McVies' marriage at this time was under a lot of stress, which was aggravated by their constant working with each other, and John McVie's considerable alcohol abuse. During the tour, Weston had an affair with Fleetwood's wife, Jenny Boyd Fleetwood, the sister of Pattie Boyd Harrison. Fleetwood soon fired Weston and the tour was cancelled. Due to lack of touring, the album sold less than its predecessor.
The fake Fleetwood Mac (1974).
In 1974, the band's manager, Clifford Davis, then claimed that he owned the name Fleetwood Mac, and recruited members of a band called Legs (which had recently issued one single under Davis' management) to tour as Fleetwood Mac.
The fake Fleetwood Mac consisted of Elmer Gantry (vocals, guitar), Kirby Gregory (guitar), Paul Martinez (bass), John Wilkinson (keyboards) and Australian-born drummer Craig Collinge (formerly of The Librettos, Procession and Third World War). Fans were told that Bob Welch and John McVie had quit the group, and that Mick Fleetwood and Christine McVie would be joining the band at a later date, after getting some rest. The members of the fake Fleetwood Mac apparently had themselves been told that Mick Fleetwood would join them on later dates, and averred that Fleetwood had been involved in the early planning stages of the tour before dropping out.
As the tour got underway, Fleetwood Mac's road manager, John Courage, worked one show before he realised that the line-up being used was a lie. Courage ended up hiding the real Fleetwood Mac's equipment, which helped shorten the tour by the fake band, which soon dissolved. But the lawsuit that followed—regarding who actually owned the rights to the band name "Fleetwood Mac"—put the real Fleetwood Mac out of commission for almost a year. While the band was named after Mick Fleetwood and John McVie, they had signed contracts that showed the band forfeited the rights to the name.
In the aftermath of the dissolution of the fake Fleetwood Mac, nobody from that lineup was ever officially made a part of the real Fleetwood Mac, although some of them later acted as Danny Kirwan's studio band. Gantry and Gregory went on to become members of Stretch, whose 1975 UK hit single "Why Did You Do It" was written about the fake Fleetwood Mac touring debacle. Gantry later joined The Alan Parsons Project. Fake Fleetwood Mac bassist Martinez, meanwhile, eventually went on to play with Paice Ashton Lord and Robert Plant's backing band.
Return of the real Fleetwood Mac (1974).
During the fake Fleetwood Mac months, Welch stayed in Los Angeles and connected with entertainment attorneys. He swiftly realised that the band was being neglected by Warner Bros., and that if they wanted to change that, they would have to change their base of operation from England to Los Angeles, to which the rest of the band agreed immediately. Rock promoter Bill Graham wrote a letter to Warner Bros. to convince them that the real Fleetwood Mac were in fact Fleetwood, Welch and the McVies, but while this did not end the legal battle, the band was able to record as Fleetwood Mac again. Instead of getting another manager, Fleetwood Mac decided to manage themselves.
In September 1974, Fleetwood Mac signed a new recording contract with Warner Bros., but remained on the Reprise imprint. The quartet released their album "Heroes Are Hard to Find" in September 1974 and for the first time in its history, the band had only one guitarist. While on tour they added a second keyboardist, Doug Graves, who had been an engineer on "Heroes Are Hard to Find." Bobby Hunt, who had been in the band Head West with Bob Welch back in 1970 was the original solo keyboardist. Neither musician, however, proved to be a long-term addition to the line-up, although Graves was preparing to be a full member of the band following the US tour in late 1974. At the time he said:
However, Graves did not ultimately join full-time and Welch left soon after the tour ended (on 5 December 1974 at Cal State Univ. Chico), having tired of the touring and legal struggles. Nevertheless, the tour enabled the "Heroes" album to reach a higher position on the American charts than any of the band's previous records.
Mainstream success (1975–87).
After Welch announced that he was leaving the band, Fleetwood began searching for a possible replacement. While Fleetwood was checking out Sound City Studios in L.A., the house engineer, Keith Olsen, played him a track which he had recorded in the studio, "Frozen Love", from the album "Buckingham Nicks" (1973). Fleetwood liked it, and was introduced to the guitarist from the band, Lindsey Buckingham, who coincidentally was at Sound City that day recording some demos. Fleetwood soon asked him to join. Buckingham agreed, on the condition that his musical partner and girlfriend, Stephanie "Stevie" Nicks, also become part of the band; Fleetwood agreed. Buckingham and Nicks joined the band on New Year's Eve 1974 (within 4 weeks of the previous incarnation splitting).
In 1975, the new line-up released the eponymous "Fleetwood Mac". The album proved to be a breakthrough for the band and became a huge hit, reaching No.1 in the US and selling over 5 million copies. Among the hit singles from this album were Christine McVie's "Over My Head" and "Say You Love Me", and Stevie Nicks' "Rhiannon" and "Landslide" (actually a hit twenty years later on "The Dance" album).
Behind the scenes the band was fraying apart in 1976; with the success of the band also came the end of John and Christine McVie's marriage, as well as Buckingham and Nicks' long term romantic relationship. Even Fleetwood was in the midst of divorce proceedings from his wife, Jenny. The pressure put on Fleetwood Mac to release a successful follow-up album, combined with their new-found wealth, led to creative and personal tensions, fuelled by high consumption of drugs and alcohol.
The album "Rumours" (the band's first release on the main Warners label after Reprise was retired and all of its acts were reassigned to the parent label) was released in the spring of 1977, in which the band members laid bare the emotional turmoil experienced at that time. Critically acclaimed, it was the recipient of the Grammy Award for Album of the Year for 1977. The album generated multiple Top Ten singles, including Buckingham's "Go Your Own Way", Nicks' U.S. No.1 "Dreams" (), and Christine McVie's "Don't Stop" and "You Make Loving Fun". Buckingham's "Second Hand News", Nicks' "Gold Dust Woman" and "The Chain" (the only song written by all five bandmates) also received significant radio airplay. By 2003, "Rumours" had sold over 19 million copies in the U.S. alone (certified as a diamond album by the RIAA), and a total of 40 million copies worldwide, making it the second biggest selling album of all time. Fleetwood Mac supported the album with a lucrative tour.
Buckingham was able to convince Fleetwood to allow his work on their next album to be more experimental and to work on tracks at home, then bring them to the band in the studio. His expanded creative role for the next album was influenced by an appreciation for new wave music. The result of this was the quirky 20-track double album, "Tusk", released in 1979. It spawned three hit singles; Lindsey Buckingham's "Tusk" (U.S. No. 8), which featured the USC Trojan Marching Band; Christine McVie's "Think About Me" (U.S. No. 20); and Stevie Nicks' 6½ minute opus "Sara" (U.S. No. 7). The last of those three was cut to 4½ minutes for both the hit single and the first CD-release of the album, but the unedited version has since been restored on the 1988 "Greatest Hits" compilation and the 2004 reissue of "Tusk" as well as Fleetwood Mac's 2002 release of "The Very Best of Fleetwood Mac". Original guitarist Green also took part in the sessions of "Tusk", but his playing for the Christine McVie track "Brown Eyes" is not credited on the album.
"Tusk" remains one of Fleetwood Mac's most ambitious albums to date, although selling only four million copies worldwide. This, in comparison to the huge sales of "Rumours", inclined the label to deem the project a failure, laying the blame squarely on Buckingham. Fleetwood, however, blames the album's relative failure on the RKO radio chain playing the album in its entirety prior to release, thus allowing mass home taping. In addition, "Tusk" was a double album, with a high list price of $15.98 ().
The band embarked on a huge 18-month tour to support and promote "Tusk". They travelled extensively across the world, including the USA, Australia, New Zealand, Japan, France, Belgium, Germany, the Netherlands, and the United Kingdom. In Germany they shared the bill with reggae superstar Bob Marley. It was on this world tour that the band recorded music for the "Fleetwood Mac Live" album, which was released at the end of 1980.
The next album, 1982's "Mirage", following 1981 solo turns by Nicks ("Bella Donna") and Buckingham ("Law and Order"), was a return to the more conventional. Buckingham had been chided by critics, fellow band members and music business managers for the lesser commercial success enjoyed by "Tusk". Recorded at Château d'Hérouville in France and produced by Richard Dashut, "Mirage" was an attempt to recapture the huge success of "Rumours". Its hits included Christine McVie's "Hold Me" and "Love In Store" (each song being co-written by Robbie Patton and Jim Recor, respectively), Stevie Nicks' "Gypsy", and Lindsey Buckingham's "Oh Diane", which made the Top 10 in the UK. A minor hit was also scored by Buckingham's "Eyes Of The World" and "Can't Go Back".
In contrast to the "Tusk" Tour, the band only embarked on a short tour of 18 American cities, the Los Angeles show being recorded and released on video. They also headlined the first US Festival, on 5 September 1982, for which the band was paid $500,000 ($ today). "Mirage" was certified double platinum in the U.S.
Following "Mirage", the band went on hiatus, which allowed members to pursue solo careers. Stevie Nicks released two more solo albums (1983's "The Wild Heart" and 1985's "Rock a Little"), Lindsey Buckingham issued "Go Insane" in 1984, the same year that Christine McVie made an eponymous album (yielding the Top 10 hit "Got A Hold On Me" and the Top 40 hit "Love Will Show Us How"). All three met with success and it was Nicks who became the most popular. However, also during this period, Mick Fleetwood had filed for bankruptcy, Nicks was admitted to the Betty Ford Clinic for addiction problems, and John McVie had suffered an addiction-related seizure—all attributed to the lifestyle of excess afforded to them by their worldwide success. It was rumoured that Fleetwood Mac had finally broken up; however, Buckingham commented that he was unhappy to allow "Mirage" to remain as the band's last effort.
The "Rumours" line-up of Fleetwood Mac recorded one more album for the time being, "Tango in the Night", in 1987. Initially, as with various other Fleetwood Mac albums, the material started off as a Buckingham solo album before becoming a group project. The album went on to become their best-selling release since "Rumours", especially in the UK where it hit No. 1 three times over the following year. The album sold three million copies in the USA and contained four hits: Christine McVie's "Little Lies" and "Everywhere" (the former being co-written with McVie's new husband Eddy Quintela), Sandy Stewart and Stevie Nicks' "Seven Wonders", and Lindsey Buckingham's "Big Love". "Family Man" Richard Dashut, "Isn't It Midnight", and the title track were also released as singles, with lesser success.
Departure of Buckingham and Nicks (1987–95).
Although a ten-week tour was scheduled, Buckingham backed out at the last minute. He tried to explain to his bandmates that he felt his creativity was being stifled by his remaining in the band. A group meeting at Christine McVie's house on 7 August 1987 resulted in much rancour and recrimination, as well as an alleged (in Mick Fleetwood's autobiography) physical altercation between Buckingham and Nicks. Buckingham left the band the following day. Following Buckingham's departure, Fleetwood Mac added two new guitarists to the band, Billy Burnette and Rick Vito. Burnette was mainly added for his singing and songwriting skills and Vito for his lead guitar abilities.
Burnette is the son of Dorsey Burnette and nephew of Johnny Burnette, both of The Rock and Roll Trio. He had already worked with Mick Fleetwood in Zoo, with Christine McVie as part of her solo band, did some session work with Stevie Nicks and even backed Lindsey Buckingham on "Saturday Night Live". Furthermore, Fleetwood and Christine McVie played on his "Try Me" album in 1985. Vito, a Peter Green admirer, played with many artists from Bonnie Raitt to John Mayall, and even worked with John McVie on two Mayall albums.
The 1987–88 "Shake the Cage" tour was the first outing for this line-up, and was successful enough to warrant the release of a concert video (simply titled "Tango in the Night"), filmed at San Francisco's Cow Palace arena in December 1987.
Capitalising on the success of "Tango in the Night", the band continued with a "Greatest Hits" album in 1988. It featured singles from the 1975–88 era, and included two new compositions: "No Questions Asked" written by Nicks, and "As Long as You Follow" written by McVie and Quintela, which was released as a single in 1988 but only made No.43 in the US and No.66 in the UK. It did, however, reach No.1 on the US Adult Contemporary charts. The "Greatest Hits" album, which peaked at No.3 in the UK and No.14 in the US (though has since sold over 8 million copies there), was dedicated to Buckingham by the band, with whom they had now reconciled.
Following the "Greatest Hits" collection, Fleetwood Mac recorded "Behind the Mask". With this album, the band veered away from the stylised sound that Buckingham had evolved during his tenure in the band (also evident in his solo works), and ended up with a more adult contemporary style from producer Greg Ladanyi. However, the album yielded only one Top 40 hit, McVie's "Save Me". "Behind the Mask" only achieved Gold album status in the US, peaking at No.18 on the "Billboard" album chart, though it entered the UK Albums Chart at No. 1. It received mixed reviews, and was seen by some music critics as a low point for the band in the absence of Lindsey Buckingham (who had actually made a "guest appearance" by playing on the title track). However, "Rolling Stone" magazine said that Vito and Burnette were "the best thing to ever happen to Fleetwood Mac" and the British "Q" magazine also praised the album in their review. The subsequent "Behind the Mask" tour saw the band play sold out shows at London's Wembley Stadium, and on the final show in Los Angeles, the band were joined onstage by Buckingham. The two women of the band, McVie and Nicks, had decided that the tour would be their last (McVie's father died during the tour) though both stated that they would still record with the band. However, in 1991, both Nicks and Rick Vito announced they were leaving Fleetwood Mac altogether.
In 1992, Fleetwood himself arranged a 4-disc box set spanning highlights from the band's 25-year history, titled "25 Years – The Chain" (an edited 2-disc set was also available). A notable inclusion in the box set was "Silver Springs", a Stevie Nicks composition that was recorded during the "Rumours" sessions but was omitted from the album and used as the B-side of "Go Your Own Way" instead. Nicks had requested use of the track for her 1991 best-of compilation "TimeSpace", but Fleetwood had refused her request as he had planned to include it in this collection as something of a rarity. The disagreement between Nicks and Fleetwood garnered press coverage, and is believed to be the main catalyst for Nicks leaving the band in 1991. The box set, however, also included a brand new Stevie Nicks/Rick Vito composition, "Paper Doll", which was released in the US as a single. As both members had left the band by this point, the track was presumably a leftover from the "Behind the Mask" sessions. There were also two new Christine McVie compositions, "Heart of Stone" and "Love Shines", the latter of which was released as a single in the UK and certain other territories. Lindsey Buckingham also contributed a new song, "Make Me a Mask", which bore all the markings of an insular Buckingham studio creation, devoid of input from other band members. Mick Fleetwood also released a deluxe hardcover companion book to coincide with the release of the box set, titled "My 25 Years in Fleetwood Mac". The volume featured many rare photographs and notes (written by Fleetwood himself) detailing the band's 25-year history.
Some months after this, the Buckingham/Nicks/McVie/McVie/Fleetwood line-up reunited at the request of U.S. President Bill Clinton for his first Inaugural Ball in 1993. Clinton had made Fleetwood Mac's "Don't Stop" his campaign theme song. His subsequent request to perform it at the Inauguration Ball was met with enthusiasm by the band, however this line-up had no intention to reunite again.
Inspired by the new interest in the band, Mick Fleetwood, John McVie, and Christine McVie recorded another album as Fleetwood Mac, with Billy Burnette taking on lead guitar duties. However, just as they made the decision to continue, Billy Burnette announced in March 1993, that he was leaving the band to pursue a country album and an acting career. Bekka Bramlett, who had worked a year earlier with Mick Fleetwood's Zoo, was recruited. Solo singer/songwriter/guitarist and Traffic's Dave Mason, who had worked with Bekka's parents Delaney & Bonnie twenty five years earlier, was subsequently added. By March 1994, Billy Burnette, himself a good friend and co-songwriter with Delaney Bramlett, returned with Fleetwood's blessing.
The band, minus Christine McVie, toured in 1994, opening for Crosby, Stills, & Nash, and in 1995 as part of a package with REO Speedwagon and Pat Benatar. The tour saw the band perform classic Fleetwood Mac songs from the initial 1967–1974 era. In 1995, at a concert in Tokyo, the band was greeted by former member Jeremy Spencer, who performed a few songs with them.
On 10 October 1995, Fleetwood Mac released the unsuccessful "Time" album. Although hitting the UK Top 60 for one week the album had zero impact in the US. It failed even to graze the "Billboard" Top 200 albums chart, a stunning reversal for a band that had been a mainstay on that chart for most of the previous two decades. Shortly after the album's release, Christine McVie informed the band that the album was her last. Bramlett and Burnette subsequently formed a country music duo, Bekka & Billy.
Break-up (1995–97).
Just weeks after disbanding Fleetwood Mac, Mick Fleetwood announced that he was working with Lindsey Buckingham again. John McVie was soon added to the sessions, and later Christine McVie. Stevie Nicks also enlisted Lindsey Buckingham to produce a song for a soundtrack.
In May 1996, Mick Fleetwood, John McVie, Christine McVie and Stevie Nicks made an appearance at a private party in Louisville, Kentucky prior to the Kentucky Derby (with Steve Winwood filling in for Lindsey Buckingham). A week later, the "Twister" film soundtrack was released, which featured the Stevie Nicks-Lindsey Buckingham duet, "Twisted", with Mick Fleetwood on drums. This eventually led to a full "Rumours" line-up reunion when the band officially reformed in March 1997.
Reunion and Christine McVie's departure (1997–2007).
The regrouped Mac performed a live concert recorded on a Warner Bros. Burbank, California soundstage on 22 May, and from this performance came the 1997 live album "The Dance", bringing Fleetwood Mac back to the top of the US album charts for the first time in 15 years. The album returned Fleetwood Mac to their superstar commercial status that they had not enjoyed since their "Tango in the Night" album. The album was certified a 5 million seller by the RIAA. A successful arena tour followed the MTV premiere of "The Dance", which kept the reunited Mac on the road throughout much of 1997, the 20th anniversary of their "Rumours" album. With the added ensemble of Neale Heywood on guitar, Brett Tuggle on keyboards, Lenny Castro on percussion, and Sharon Celani (she had toured with Fleetwood Mac in the late 80s) and Mindy Stein on backing vocals, this would, however, be the final foray of the classic line-up with Christine McVie for 16 years. As of 2015, Brett Tuggle, Neale Heywood, and Sharon Celani still perform with Fleetwood Mac as touring musicians.
In 1998, Fleetwood Mac were inducted into the Rock and Roll Hall of Fame. Members inducted included the original band – Mick Fleetwood, John McVie, Peter Green, Jeremy Spencer and Danny Kirwan – and "Rumours"-era members Christine McVie, Stevie Nicks and Lindsey Buckingham, but not Bob Welch, despite his key role in keeping the band alive during the early 1970s. The "Rumours"-era version of the band performed both at the induction ceremony and at the Grammy Awards program that year. Peter Green attended the induction ceremony but did not perform with his former bandmates, opting instead to perform his composition "Black Magic Woman" with Santana, who were inducted the same night. Neither Jeremy Spencer or Danny Kirwan attended. Fleetwood Mac were also the recipients of the "Outstanding Contribution to Music" award at the BRIT Awards (British Phonographic Industry Awards) the same year.
In 1998, Christine McVie left the band permanently to retire from touring (though not from the music business entirely as she created a new album, "In the Meantime", in 2004). Her departure left Buckingham and Nicks to sing all the lead vocals for the band's 2003 album, "Say You Will", although Christine did contribute some backing vocals and keyboards. The album debuted at No.3 on the "Billboard" 200 chart (No. 6 in the UK) and yielded chart hits with "Peacekeeper" and the title track, and a successful world arena tour which lasted through 2004. The tour grossed $27,711,129 and was ranked No. 21 in the 'top 25 grossing tours of 2004'.
Around 2004–2005, there were rumours of a reunion of the early line-up of Fleetwood Mac, involving Peter Green and Jeremy Spencer. Whilst these two guitarists and vocalists apparently remained unconvinced of the merits of such a project, In April 2006, during a question-and-answer session on the "Penguin" Fleetwood Mac fan website, bassist John McVie said of the reunion idea:
In interviews given in November 2006 to support his solo album "Under the Skin", Buckingham stated that plans for the band to reunite once more for a 2008 tour were still on the cards. Recording plans have been put on hold for the foreseeable future. In a September 2007 interview Stevie Nicks gave to the UK newspaper "The Daily Telegraph", she noted that she was unwilling to carry on with the band unless Christine McVie returned.
However, in a more recent interview, Mick Fleetwood said "... be very happy and hopeful that we will be working again. I can tell you everyone's going to be extremely excited about what's happening with Fleetwood Mac."
Unleashed Tour and Extended Play (2008–2014).
On 14 March 2008, the Associated Press reported Sheryl Crow as saying that she would be working with Fleetwood Mac in 2009. Crow and Stevie Nicks collaborated a great deal in the past and she has stated that Nicks has been a great teacher and inspiration for her. In a subsequent interview with Buckingham, he said after discussions between the band and Crow, the potential collaboration with Crow "lost its momentum". However, in a June 2008 interview, Nicks denied that Crow would be joining Fleetwood Mac as a replacement for Christine McVie. According to Nicks, "the group will start working on material and recording probably in October, and finish an album." On 7 October 2008, Mick Fleetwood confirmed on the BBC's "The One Show" that the band were working in the studio and also announced plans for a world tour in 2009.
In late 2008, Fleetwood Mac announced that the band would tour in 2009, beginning in March. As per the 2003–2004 tour, Christine McVie would not be featured in the line-up. The tour was branded as a 'greatest hits' show entitled "Unleashed", although they played album tracks such as "Storms" and "I Know I'm Not Wrong". The first show was on 1 March 2009, and in February they announced a slew of new dates.
During their show on 20 June 2009 in New Orleans, Louisiana, Stevie Nicks premiered part of a new song that she had written about Hurricane Katrina. The song was later released as "New Orleans" on Stevie Nicks' 2011 album "In Your Dreams" with Mick Fleetwood on drums.
In October 2009, the band began a tour of Europe which carried on into early November, followed by a tour of Australia and New Zealand in December. Also in October, "The Very Best of Fleetwood Mac" was re-released in an extended two-disc format (this format having been released in the US in 2002), premiering at number six on the UK Albums Chart.
On 1 November 2009, a new one-hour documentary, "Fleetwood Mac: Don't Stop", was broadcast in the UK on BBC One, which featured recent interviews with all four current band members. During the documentary, Nicks gave a candid summary of the current state of her relationship with Buckingham, stating "Maybe when we're 75 and Fleetwood Mac is a distant memory, we might be friends ...".
On 6 November 2009, Fleetwood Mac played the last show of the European leg of their "Unleashed" tour at London's Wembley Arena. Christine McVie was present in the audience, so Stevie Nicks paid a tribute from the stage to a standing ovation from the audience, stating that she thought about her former bandmate "every day", and went on to dedicate that night's performance of "Landslide" to McVie.
On 19 December 2009, Fleetwood Mac played the second to last act of their "Unleashed" tour to a sell-out crowd at what was originally intended to be a one-off event at the TSB Bowl of Brooklands, New Plymouth, New Zealand. Tickets, after pre-sales, sold out within twelve minutes of public release, and another date (Sunday 20 December), which also sold out, was added. The tour grossed $84,900,000 and was ranked No. 13 in the highest grossing worldwide tours of 2009.
On 19 October 2010, Fleetwood Mac played a private show at the Phoenician Hotel in Scottsdale, Arizona for TPG (Texas Pacific Group).
On 3 May 2011, the Fox Network broadcast an episode of "Glee" entitled "Rumours" that featured six songs from the band's 1977 album. The show sparked renewed interest in the band and its most commercially successful album, and "Rumours" reentered the "Billboard" 200 chart at No. 11, the same week that Stevie Nicks' new solo album "In Your Dreams" debuted at No. 6. (Nicks was quoted by "Billboard" saying that her new album was "my own little "Rumours"." ) The two recordings sold about 30,000 and 52,000 units, respectively. Music downloads accounted for ninety-one percent of the "Rumours" sales. The spike in sales for "Rumours" represented an uptick of 1,951%. It was the highest chart entry by a previously issued album since "The Rolling Stones"'s reissue of "Exile On Main St." reentered the chart at No. 2 on 5 June 2010.
In a July 2012 interview, Nicks confirmed that the band would reunite for a tour in 2013.
Original Fleetwood Mac bassist Bob Brunning died on 18 October 2011, at the age of 68. Former guitarist and singer Bob Weston was found dead on 3 January 2012, at the age of 64. Former singer and guitarist Bob Welch was found dead from a self-inflicted gunshot wound on 7 June 2012, at the age of 66. A spokesman at the scene Don Aaron states "He died from an apparent self inflicted gunshot wound to the chest," Aaron said. "A suicide note was found in the residence" (Tennessean Music Team). The musician had been struggling with health issues and was dealing with depression. His wife was the one to discover the body.
The band's 2013 tour, which covered 34 cities, started on 4 April in Columbus, OH. The band performed two new songs ("Sad Angel" and "Without You"), which Buckingham described as some of the most 'Fleetwood Mac-y' sounding songs since "Mirage", with the latter song re-recorded from the Buckingham Nicks era.
The band released their first new studio material in 10 years, "Extended Play", on 30 April 2013. The EP debuted and peaked at No. 48 in the US, and produced one single, "Sad Angel".
On 25 and 27 September 2013, the second and third nights of the band's London O2 shows, Christine McVie joined them onstage for Don't Stop.
On 27 October, the band announced that John McVie had been diagnosed with cancer, and that they were cancelling their New Zealand and Australian performances in order for him to undergo treatment. They stated that "We are sorry to not be able to play these Australian and New Zealand dates. We hope our Australian and New Zealand fans as well as Fleetwood Mac fans everywhere will join us in wishing John and his family all the best."
According to an article in "The Guardian" on 22 November 2013, Christine McVie stated that she would like to return to Fleetwood Mac if they wanted her, and also affirmed that John McVie's prognosis was "really good."
Return of Christine McVie (2014–present).
On 11 January 2014, Mick Fleetwood announced that Christine McVie would be rejoining Fleetwood Mac, and the news was confirmed on 13 January by the band's primary publicist, Liz Rosenberg. Rosenberg also stated that an official announcement regarding a new album and tour would be forthcoming. On October 2014, Stevie Nicks appeared on an FX TV show called "American Horror Story: Coven" right after their 2014 tour ended. Stevie Nicks appeared in the show while Fleetwood Mac's song "Seven Wonders" was playing in the background.
On with the Show, a 33-city North American Tour opened in Minneapolis, Minnesota on 30 September 2014. A series of May–June 2015 arena dates in the United Kingdom went on sale on 14 November, selling out in minutes. Additional dates for the tour have continued to be added, extending into November.
In January 2015, Buckingham suggested that the new album and the new tour might be Fleetwood Mac's last act and that the band will cease to operate in 2015 or soon afterwards. He concluded: "We're going to continue working on the new album, and the solo stuff will take a back seat for a year or two. A beautiful way to wrap up this last act". On the other hand, Mick Fleetwood stated that the new album may take a few years to complete and that they are waiting for contributions from Stevie Nicks, who has been ambivalent about committing to a new record.
In December 2015, Stevie Nicks announced that she would commit to recording a new Fleetwood Mac album.
Remasters.
The 1967–69 era Blue Horizon albums ("Fleetwood Mac", "Mr. Wonderful", "The Pious Bird of Good Omen" and "Fleetwood Mac in Chicago") and 1971 outtakes album "The Original Fleetwood Mac" have been remastered and reissued on CD, as have the 1975–79 era Warner Brothers albums "Fleetwood Mac", "Rumours", and "Tusk". Remasters were planned for the Reprise/Warner Brothers albums from 1971–1974 and 1980–1995, but were shelved. In 2013, "Then Play On" was remastered, which included four bonus tracks, and peaked at No. 112 in the UK. In 2015, a 5CD/1DVD/2 LP deluxe edition, a 3CD expanded edition, plus a 1CD remaster of "Tusk" was released.

</doc>
<doc id="11788" url="https://en.wikipedia.org/wiki?curid=11788" title="Frederick I, Margrave of Brandenburg-Ansbach">
Frederick I, Margrave of Brandenburg-Ansbach

Frederick I of Ansbach and Bayreuth (also known as Frederick V; or ; 8 May 1460 – 4 April 1536) was born at Ansbach as the eldest son of Albert III, Margrave of Brandenburg by his second wife Anna, daughter of Frederick II, Elector of Saxony. His elder half-brother was the Elector Johann Cicero of Brandenburg. Friedrich succeeded his father as Margrave of Ansbach in 1486 and his younger brother as Margrave of Bayreuth in 1495.
Family and children.
On 14 February 1479 at Frankfurt (Oder) he was married to Sophia of Poland (6 April 1464 – 5 October 1512), daughter of King Casimir IV of Poland by his wife Elisabeth of Habsburg, and sister of King Sigismund I of Poland. They had seventeen children:
Ancestry.
 

</doc>
<doc id="11790" url="https://en.wikipedia.org/wiki?curid=11790" title="F-Zero: Maximum Velocity">
F-Zero: Maximum Velocity

F-Zero Maximum Velocity, released in Japan as F-Zero for Game Boy Advance, is a futuristic racing video game developed by Nd Cube and published by Nintendo for the Game Boy Advance (GBA). The game was released in Japan, North America and Europe in 2001. It is the first to be released on a handheld game console.
"Maximum Velocity" takes place twenty-five years after "F-Zero", in yet another F-Zero Grand Prix. The past generations of F-Zero had "piloted their way to fame", so it is the only "F-Zero" game without Captain Falcon, Samurai Goroh, Pico, or Dr. Stewart. Players control fast hovering crafts and use their speed-boosting abilities to navigate through the courses as quickly as possible.
Gameplay.
Every race consists of five laps around a race track. A player will lose the race if his or her machine explodes due to either taking too much damage or landing outside of the track, gets ejected from the race due to falling to 20th place or due to completing a lap with a rank outside of the rank limit of that lap, or he or she decides to give up. In the single player Grand Prix mode, all of these conditions requires the player to use an extra machine if and only if he or she has one or more spare machines to try again.
For each lap completed the player is rewarded with a speed boost, to be used once any time, one of the "SSS" marks will be shaded green to indicate that it can be used. A boost will dramatically increase a player's speed, but will decrease their ability to turn. A boost used before a jump will make the player jump farther, which could allow the player to use a shortcut with the right vehicle. Boost time and speed varies according to the machine, and is usually tuned for proper balance. For example, one machine boasts a boost time of twelve seconds, yet has the slowest boost speed of the entire game. Players can also take advantage of the varying deceleration of each vehicle. Some vehicles, such as the Jet Vermilion, take longer than others to decelerate from top boost speed to normal speed, once the boost has been used up. Players can also take advantage of this effect on boost pads.
The Grand Prix is the main single player component of "Maximum Velocity". It consists of four series named after chess pieces: "Pawn", "Knight", "Bishop" and "Queen". The latter of these can be unlocked by winning the others on "Expert" mode. They have five races in four difficulty settings, "Master" mode is unlocked by winning expert mode in each series, the player unlocks a new machine after completing it. The player needs to be in the top three at the end of the last lap in order to continue to the next race. If the player is unable to continue, the player will lose a machine and can try the race again. If the player runs out of machines, then the game ends, and the player has to start the series from the beginning.
Championship is another single player component. It is basically the same as a "Time Attack" mode, except the player can only race on one, special course: the Synobazz Championship Circuit. This special course is not selectable in any other modes.
Multiplayer.
"Maximum Velocity" can be played in two multiplayer modes using the Game Boy Advance link cable, with one cartridge, or one cartridge per player. Two to four Players can play in both modes.
In single cart, only one player needs to have a cartridge. The other players will boot off the link cable network from the player with the cart using the GBA's netboot capability. All players drive a generic craft, and the game can only be played on one level, Silence. Silence, along with Fire Field, are the only areas to return from previous games. Aptly, Silence in "Maximum Velocity" has no background music, unlike in most other F-Zero games.
In multi cart, each player needs to have a cartridge to play. This has many advantages over single cart: All players can use any machine in this game that has been unlocked by another player. Players can select any course in this game. After race is finished, all of the player's ranking data are mixed and shared ("Mixed ranking" stored in each cart).
Development.
"F-Zero: Maximum Velocity" is one of first titles to have been developed by Nd Cube. Like the original "F-Zero" for SNES, "Maximum Velocity" implements a pseudo-3D visual technique based on the scaling and rotation effects of bitmap graphics. In this game, this technique consists of a double-layer; one of which gives the illusion of depth.
Release.
"Maximum Velocity" is one of ten Game Boy Advance games released on December 16, 2011 to Nintendo 3DS Ambassadors, a program to give free downloadable games to early adopters who bought a Nintendo 3DS before its price drop.It was also released on the Wii U Virtual Console on April 3, 2014 in Japan and April 17, 2014 in North America and Europe.
Reception.
On release, "Famitsu" magazine scored the game a 31 out of 40. "F-Zero: Maximum Velocity" went on to sell 334,145 copies in Japan and 273,229 copies in the U.S. as of 2005. It also got 86% on Metacritic and 83.37% on Game Rankings

</doc>
<doc id="11794" url="https://en.wikipedia.org/wiki?curid=11794" title="Frederick William I of Prussia">
Frederick William I of Prussia

Frederick William I () (14 August 1688 – 31 May 1740), known as the 'Soldier King,' was the King in Prussia and Elector of Brandenburg from 1713 until his death. He was in personal union the sovereign prince of the Principality of Neuchâtel.
Reign.
He was born in Berlin to Frederick I of Prussia and Sophia Charlotte of Hanover. His father had successfully acquired the title King for the margraves of Brandenburg.
During his own reign, Frederick William I did much to centralize and improve Prussia. He replaced mandatory military service among the middle class with an annual tax, established schools, and resettled East Prussia (which had been devastated by the plague in 1709).
The king encouraged farming, reclaimed marshes, stored grain in good times and sold it in bad times. He dictated the manual of Regulations for State Officials, containing 35 chapters and 297 paragraphs in which every public servant in Prussia could find his duties precisely set out: a minister or councillor failing to attend a committee meeting, for example, would lose six months' pay; if he absented himself a second time, he would be discharged from the royal service.
In short, Frederick William I concerned himself with every aspect of his relatively small country, planning to satisfy all that was needed for Prussia to defend itself. His rule was absolutist and he was a firm autocrat. He practiced rigid, frugal economy, never started a war, and led a simple and austere lifestyle, in contrast to the lavish court his father had presided over. At his death, there was a large surplus in the royal treasury (which was kept in the cellar of the royal palace). He intervened briefly in the Great Northern War in order to gain a portion of Swedish Pomerania. More significantly, the "Soldier-King" had made considerable reforms to the Prussian army's training, tactics and conscription program—introducing the canton system and leaving his son Frederick with a formidable weapon with which to build Prussia's power. The observation that "the pen is mightier than the sword" has sometimes been attributed to him. ("See as well:" “Prussian virtues”.) Although a highly effective ruler, Frederick William had a violent temper; this was exacerbated by his inherited porphyritic illness, which gave him gout, obesity and frequent stomach pains.
Burial and reburials.
Frederick William died in 1740 at age 51 and was interred at the Garrison Church in Potsdam. During World War II, in order to protect it from advancing allied forces, Hitler ordered the king’s coffin, as well as those of Frederick the Great and Paul von Hindenburg, into hiding, first to Berlin and later to a salt mine outside of Bernterode. The coffins were later discovered by occupying American Forces, who re-interred the bodies in St. Elisabeth's Church in Marburg in 1946. In 1953 the coffin was moved to Burg Hohenzollern, where it remained until 1991, when it was finally laid to rest on the steps of the altar in the Kaiser Friedrich Mausoleum in the Church of Peace on the palace grounds of Sanssouci. The original black marble sarcophagus collapsed at Burg Hohenzollern—the current one is a copper copy.
Relationship with Frederick II.
His eldest surviving son was Frederick II (Fritz), born in 1712. Frederick William wanted him to become a fine soldier. As a small child, Fritz was awakened each morning by the firing of a cannon. At the age of 6, he was given his own regiment of children to drill as cadets, and a year later, he was given a miniature arsenal.
The love and affection Frederick William had for his heir initially was soon destroyed due to their increasingly different personalities. Frederick William ordered Fritz to undergo a minimal education, live a simple Protestant lifestyle, and focus on the Army and statesmanship as he had. However, the intellectual Fritz was more interested in music, books and French culture, which were forbidden by his father as decadent and unmanly. As Fritz's defiance for his father's rules increased, Frederick William would frequently beat or humiliate Fritz (he preferred his younger sibling August William). Fritz was beaten for being thrown off a bolting horse and wearing gloves in cold weather. After the prince attempted to flee to England with his tutor, Hans Hermann von Katte, the enraged King had Katte executed before the eyes of the prince, who himself was court-martialled. The court declared itself not competent in this case. Whether it was the king's intention to have his son executed as well (as Voltaire claims) is not clear. However, the Holy Roman Emperor Charles VI intervened, claiming that a prince could only be tried by the Imperial Diet of the Holy Roman Empire itself. Frederick was imprisoned in the Fortress of Küstrin from 2 September to 19 November 1731 and exiled from court until February 1732, during which time he was rigorously schooled in matters of state. After achieving a measure of reconciliation, Frederick William had his son married to Princess Elizabeth of Brunswick-Wolfenbüttel, whom Frederick despised, but then allowed him to indulge in his musical and literary interests again.
Although the relationship between Frederick William and Frederick was clearly hostile, Frederick himself later wrote that his father "penetrated and understood great objectives, and knew the best interests of his country better than any minister or general."
Marriage and family.
Frederick William married his first cousin Sophia Dorothea of Hanover, George II's younger sister (daughter of his uncle, King George I of Great Britain and Sophia Dorothea of Celle) on 28 November 1706. Frederick William was faithful and loving to his wife but they did not have a happy relationship: Sophia Dorothea feared his unpredictable temper and resented him, both for allowing her no influence at court and for refusing to marry her children to their English cousins. She also abhorred his cruelty towards their son and heir Frederick (with whom she was close), although rather than trying to mend the relationship between father and son she frequently spurred Frederick on in his defiance. They had fourteen children, including:

</doc>
<doc id="11795" url="https://en.wikipedia.org/wiki?curid=11795" title="Felsic">
Felsic

In geology felsic refers to igneous rocks that are relatively rich in elements that form feldspar and quartz. It is contrasted with mafic rocks, which are relatively richer in magnesium and iron (ferric). It refers to those rocks rich in silicate minerals, magma, and rocks which are enriched in the lighter elements such as silicon, oxygen, aluminium, sodium, and potassium.
They are usually light in color and have specific gravities less than 3. The most common felsic rock is granite. Common felsic minerals include quartz, muscovite, orthoclase, and the sodium-rich plagioclase feldspars. In terms of chemistry, felsic minerals and rocks are at the other end of the elemental spectrum from the mafic minerals and rocks.
Terminology.
In modern usage, the term "acid rock", although sometimes used as a synonym, refers to a high-silica-content (greater than 63% SiO by weight) volcanic rock, such as rhyolite. 
The term was used more broadly in older geologic literature. It is considered archaic now, as the terms "acidic" and "basic rock" were based on an incorrect idea, dating from the 19th century, that silicic acid was the chief form of silicon occurring in rocks.
The term "felsic" combines the words "feldspar" and "silica". The similarity of the term "felsic" to the German words "Fels", meaning "rock", and "felsig", meaning "rocky", is purely accidental, as "feldspar" is a borrowing from German "Feldspat", which derives from German "Feld", meaning "field".
Classification of felsic rocks.
In order for a rock to be classified as felsic, it generally needs to contain more than 75% felsic minerals; namely quartz, orthoclase and plagioclase. Rocks with greater than 90% felsic minerals can also be called "leucocratic", meaning 'light-coloured'.
Felsite is a petrologic field term used to refer to very fine-grained or aphanitic, light-colored volcanic rocks which might be later reclassified after a more detailed microscopic or chemical analysis.
In some cases, felsic volcanic rocks may contain phenocrysts of mafic minerals, usually hornblende, pyroxene or a feldspar mineral, and may need to be named after their phenocryst mineral, such as 'hornblende-bearing felsite'.
The chemical name of a felsic rock is given according to the TAS classification of Le Maitre (1975). However, this only applies to volcanic rocks. If the rock is analyzed and found to be felsic but is metamorphic and has no definite volcanic protolith, it may be sufficient to simply call it a 'felsic schist'. There are examples known of highly sheared granites which can be mistaken for rhyolites.
For phaneritic felsic rocks, the QAPF diagram should be used, and a name given according to the granite nomenclature. Often the species of mafic minerals is included in the name, for instance, hornblende-bearing granite, pyroxene tonalite or augite megacrystic monzonite, because the term "granite" already assumes content with feldspar and quartz.
The rock texture thus determines the basic name of a felsic rock.

</doc>
<doc id="11797" url="https://en.wikipedia.org/wiki?curid=11797" title="Frisians">
Frisians

The Frisians are a Germanic ethnic group native to the coastal parts of the Netherlands and Germany. They inhabit an area known as Frisia and are concentrated in the Dutch provinces of Friesland and Groningen and, in Germany, East Frisia and North Frisia (which was a part of Denmark until 1864). The Frisian languages are still used by 500,000 speakers; dialects of Frisian are recognized as official languages in both the Netherlands and Germany.
History.
The ancient Frisii enter recorded history in the Roman account of Drusus's 12 BC war against the Rhine Germans and the Chauci. They occasionally appear in the accounts of Roman wars against the Germanic tribes of the region, up to and including the Revolt of the Batavi around 70 AD. Frisian mercenaries were hired to assist the Roman invasion of Britain in the capacity of cavalry. They are not mentioned again until c. 296, when they were deported into Roman territory as "laeti" (i.e., Roman-era serfs; see Binchester Roman Fort and Cuneus Frisionum). The discovery of a type of earthenware unique to 4th century Frisia, called "terp Tritzum", shows that an unknown number of them were resettled in Flanders and Kent, probably as "laeti" under Roman coercion.
From the 3rd through the 5th centuries Frisia suffered marine transgressions that made most of the land uninhabitable, aggravated by a change to a cooler and wetter climate. Whatever population that the Romans had allowed to remain dropped dramatically, and the coastal lands remained largely unpopulated for the next two centuries. When conditions improved, Frisia received an influx of new settlers, mostly Angles and Saxons, who intermarried with what remained of the earlier population. These people would eventually be referred to as 'Frisians', though they were not necessarily descended from the ancient Frisii. It is these 'new Frisians' who are largely the ancestors of the medieval and modern Frisians.
By the end of the 6th century, Frisian territory had expanded westward to the North Sea coast and, in the 7th century, southward down to Dorestad. This farthest extent of Frisian territory is sometimes referred to as "Frisia Magna". Early Frisia was ruled by a High King, with the earliest reference to a 'Frisian King' being dated 678.
In the early 8th century the Frisian nobles came into increasing conflict with the Franks to their south, resulting in a series of wars in which the Frankish Empire eventually subjugated Frisia in 734. These wars benefited attempts by Anglo-Irish missionaries (which had begun with Saint Boniface) to convert the Frisian populace to Christianity, in which Saint Willibrord largely succeeded.
Some time after the death of Charlemagne, the Frisian territories were in theory under the control of the Count of Holland, but in practice the Hollandic counts, starting with Count Arnulf in 993, were unable to assert themselves as the sovereign lords of Frisia. The resulting stalemate resulted in a period of time called the 'Frisian freedom', a period in which feudalism and serfdom (as well as central or judicial administration) did not exist, and in which the Frisian lands only owed their allegiance to the Holy Roman Emperor.
During the 13th century, however, the counts of Holland became increasingly powerful and, starting in 1272, sought to reassert themselves as rightful lords of the Frisian lands in a series of wars, which (with a series of lengthy interruptions) ended in 1422 with the Hollandic conquest of Western Frisia and with the establishment of a more powerful noble class in Central and Eastern Frisia.
In 1524 Frisia became part of the Seventeen Provinces and in 1568 joined the Dutch revolt against Philip II, king of Spain, heir of the Burgundian territories; Central Frisia has remained a part of the Netherlands ever since. The eastern periphery of Frisia would become part of various German states (later Germany) and Denmark. An old tradition existed in the region of exploitation of peatlands.
Language.
As both the Anglo-Saxons of England and the early Frisians were formed from largely identical tribal confederacies, their respective languages were very similar. Old Frisian is the most closely related language to Old English and the modern Frisian dialects are in turn the closest related languages to contemporary English.
The Frisian language group itself is divided into three mutually unintelligible languages:
Of these three languages both Saterland Frisian (2,000 speakers) and North Frisian (10,000 speakers) are endangered. West Frisian is spoken by around 354,000 native speakers and is not threatened.
Identity.
Today there exists a tripartite division of the Frisians, into North Frisians, East Frisians and West Frisians, caused by Frisia's constant loss of territory in the Middle Ages. The West Frisians in general do not see themselves as part of a larger group of Frisians, and, according to a 1970 poll, identify themselves more with the Dutch than with the East or North Frisians. Therefore, the term 'Frisian', when applied to the speakers of all three Frisian languages, is a linguistic and to some extent cultural concept, not a political one.
Culturally, modern West Frisians and the (Northern) Dutch are rather similar, the main and generally most important difference being that West Frisians speak West Frisian, one of the three subbranches of the Frisian languages, alongside Dutch. Because of centuries of cohabitation and active participation in Dutch society, as well as being bilingual, these Frisians are not treated as a separate group in Dutch official statistics.

</doc>
<doc id="11800" url="https://en.wikipedia.org/wiki?curid=11800" title="Futurism (disambiguation)">
Futurism (disambiguation)

Futurism was an artistic and social movement that originated in Italy in the early 20th century.
A Futurist may be:
Futurism or futurist may also refer to:

</doc>
<doc id="11801" url="https://en.wikipedia.org/wiki?curid=11801" title="Filippo Tommaso Marinetti">
Filippo Tommaso Marinetti

Filippo Tommaso Emilio Marinetti (; 22 December 1876 – 2 December 1944) was an Italian poet and editor, the founder of the Futurist movement. He was associated with the utopian and Symbolists artistic and literary community Abbaye de Créteil between 1907 and 1908. Marinetti is best known as the author of the first "Futurist Manifesto", which was written and published in 1909.
Childhood and adolescence.
Emilio Angelo Carlo Marinetti (some documents give his name as "Filippo Achille Emilio Marinetti") spent the first years of his life in Alexandria, Egypt, where his father (Enrico Marinetti) and his mother (Amalia Grolli) lived together "more uxorio" (as if married). Enrico was a lawyer from Piedmont, and his mother was the daughter of a literary professor from Milan. They had come to Egypt in 1865, at the invitation of Khedive Isma'il Pasha, to act as legal advisers for foreign companies that were taking part in his modernization program.
His love for literature developed during the school years. His mother was an avid reader of poetry, and introduced the young Marinetti to the Italian and European classics. At age seventeen he started his first school magazine, "Papyrus"; the Jesuits threatened to expel him for publicizing Émile Zola's scandalous novels in the school.
He first studied in Egypt then in Paris, obtaining a "baccalauréat" degree in 1894 at the Sorbonne, and in Italy, graduating in law at the University of Pavia in 1899.
He decided not to be a lawyer but to develop a literary career. He experimented with every type of literature (poetry, narrative, theatre, "words in liberty"), signing everything "Filippo Tommaso Marinetti".
Futurism.
Marinetti and Constantin Brâncuși were visitors of the Abbaye de Créteil c. 1908 along with young writers like Roger Allard (one of the first to defend Cubism), Pierre Jean Jouve, and Paul Castiaux, who wanted to publish their works through the Abbaye. The Abbaye de Créteil was a "phalanstère" community founded in the autumn of 1906 by the painter Albert Gleizes, and the poets , , Alexandre Mercereau and Charles Vildrac. The movement drew its inspiration from the "Abbaye de Thélème," a fictional creation by Rabelais in his novel "Gargantua". It was closed down by its members early in 1908.
Marinetti is known best as the author of the "Futurist Manifesto", which he wrote in 1909. It was published in French on the front page of the most prestigious French daily newspaper, "Le Figaro", on 20 February 1909. In "The Founding and Manifesto of Futurism", Marinetti declared that "Art, in fact, can be nothing but violence, cruelty, and injustice." George Sorel, who influenced the entire political spectrum from anarchism to Fascism, also argued for the importance of violence. Futurism had both anarchist and Fascist elements; Marinetti later became an active supporter of Benito Mussolini.
Marinetti, who admired speed, had a minor car accident outside Milan in 1908 when he veered into a ditch to avoid two cyclists. He referred to the accident in the Futurist Manifesto: the Marinetti who was helped out of the ditch was a new man, determined to end the pretense and decadence of the prevailing Liberty style. He discussed a new and strongly revolutionary programme with his friends, in which they should end every artistic relationship with the past, "destroy the museums, the libraries, every type of academy". Together, he wrote, "We will glorify war—the world's only hygiene—militarism, patriotism, the destructive gesture of freedom-bringers, beautiful ideas worth dying for, and scorn for woman".
The Futurist Manifesto was read and debated all across Europe, but Marinetti's first 'Futurist' works were not as successful. In April, the opening night of his drama "Le Roi bombance" (The Feasting King), written in 1905, was interrupted by loud, derisive whistling by the audience... and by Marinetti himself, who thus introduced another element of Futurism, "the desire to be heckled". Marinetti did, however, fight a duel with a critic he considered too harsh.
His drama "La donna è mobile" (Poupées électriques), first presented in Turin, was not successful either. Nowadays, the play is remembered through a later version, named "Elettricità sessuale" (Sexual Electricity), and mainly for the appearance onstage of humanoid automatons, ten years before the Czech writer Karel Čapek would invent the term "robot".
In 1910, his first novel "Mafarka il futurista" was cleared of all charges by an obscenity trial. That year, Marinetti discovered some allies in three young painters, (Umberto Boccioni, Carlo Carrà, Luigi Russolo), who adopted the Futurist philosophy. Together with them (and with poets such as Aldo Palazzeschi), Marinetti began a series of Futurist Evenings, theatrical spectacles in which Futurists declaimed their manifestos in front of a crowd that in part attended the performances in order to throw vegetables at them.
The most successful "happening" of that period was the publicization of the "Manifesto Against Past-Loving Venice" in Venice. In the flier, Marinetti demands "fill(ing) the small, stinking canals with the rubble from the old, collapsing and leprous palaces" to "prepare for the birth of an industrial and militarized Venice, capable of dominating the great Adriatic, a great Italian lake".
In 1911, the Italo-Turkish War began and Marinetti departed for Libya as war correspondent for a French newspaper. His articles were eventually collected and published in "The Battle Of Tripoli". He then covered the First Balkan War of 1912-13, witnessing the surprise success of Bulgarian troops against the Ottoman Empire in the Siege of Adrianople. In this period he also made a number of visits to London, which he considered 'the Futurist city par excellence', and where a number of exhibitions, lectures and demonstrations of Futurist music were staged. However, although a number of artists, including Wyndham Lewis, were interested in the new movement, only one British convert was made, the young artist C.R.W. Nevinson. Nevertheless, Futurism was an important influence upon Lewis's Vorticist philosophy.
About the same time Marinetti worked on a very anti-Roman Catholic and anti-Austrian verse-novel, "Le monoplan du Pape" ("The Pope's Aeroplane", 1912) and edited an anthology of futurist poets. But his attempts to renew the style of poetry did not satisfy him. So much so that, in his foreword to the anthology, he declared a new revolution: it was time to be done with traditional syntax and to use "words in freedom" ("parole in libertà"). His sound-poem "Zang Tumb Tumb", an account of the Battle of Adrianople, exemplifies words in freedom. Recordings can be heard of Marinetti reading some of his sound poems: "Battaglia, Peso + Odore" (1912); "Dune, parole in libertà" (1914); "La Battaglia di Adrianopoli" (1926) (recorded 1935).
Wartime.
Marinetti agitated for Italian involvement in The Great War, and once Italy was engaged, promptly volunteered for service. In the Fall of 1915 he and several other Futurists who were members of the Lombard Volunteer Cyclists were stationed at Lake Garda, in Trentino province, high in the mountains along the Italo-Austrian border. They endured several weeks of fighting in harsh conditions before the cyclists units, deemed inappropriate for mountain warfare, were disbanded.
Marinetti spent most of 1916 supporting Italy's war effort with speeches, journalism, and theatrical work, then returned to military service as a regular army officer in 1917. In May of that year he was seriously wounded while serving with an artillery battalion on the Isonzo front; he returned to service after a long recovery, and participated in the decisive Italian victory at Vittorio Veneto in October 1918.
Marriage.
After an extended courtship, in 1923 Marinetti married Benedetta Cappa (1897–1977), a writer and painter and a pupil of Giacomo Balla. Born in Rome, she had joined the Futurists in 1917. They'd met in 1918, moved in together in Rome, and chose to marry only to avoid legal complications on a lecture tour of Brazil. They would have three daughters: Vittoria, Ala, and Luce.
Cappa and Marinetti collaborated on a genre of mixed-media assemblages in the mid-1920s they called "tattilismo" ("Tactilism"), and she was a strong proponent and practitioner of the aeropittura movement after its inception in 1929. She also produced three experimental novels. Cappa's major public work is likely a series of five murals at the Palermo Post Office (1926–1935) for the Fascist public-works architect Angiolo Mazzoni.
Marinetti and Fascism.
In early 1918 he founded the "Partito Politico Futurista" or Futurist Political Party, which only a year later merged with Benito Mussolini's "Fasci Italiani di Combattimento". Marinetti was one of the first affiliates of the Italian Fascist Party. In 1919 he co-wrote with Alceste De Ambris the Fascist Manifesto, the original manifesto of Italian Fascism. He opposed Fascism's later exaltation of existing institutions, terming them "reactionary," and, after walking out of the 1920 Fascist party congress in disgust, withdrew from politics for three years. However, he remained a notable force in developing the party philosophy throughout the regime's existence. For example, at the end of the "Congress of Fascist Culture" that was held in Bologna on 30 March 1925, Giovanni Gentile addressed Sergio Panunzio on the need to define Fascism more purposefully by way of Marinetti's opinion, stating, "Great spiritual movements make recourse to precision when their primitive inspirations—what F. T. Marinetti identified this morning as artistic, that is to say, the creative and truly innovative ideas, from which the movement derived its first and most potent impulse—have lost their force. We today find ourselves at the very beginning of a new life and we experience with joy this obscure need that fills our hearts—this need that is our inspiration, the genius that governs us and carries us with it."
During the Fascist regime Marinetti sought to make Futurism the official state art of Italy but failed to do so. Mussolini was personally uninterested in art and chose to give patronage to numerous styles in order to keep artists loyal to the regime. Opening the exhibition of art by the Novecento Italiano group in 1923, he said: "I declare that it is far from my idea to encourage anything like a state art. Art belongs to the domain of the individual. The state has only one duty: not to undermine art, to provide humane conditions for artists, to encourage them from the artistic and national point of view." Mussolini's mistress, Margherita Sarfatti, successfully promoted the rival Novecento Group, and even persuaded Marinetti to be part of its board.
In Fascist Italy, modern art was tolerated and even approved by the Fascist hierarchy. Towards the end of the 1930s, some Fascist ideologues (for example, the ex-Futurist Ardengo Soffici) wished to import the concept of "degenerate art" from Germany to Italy and condemned modernism, although their demands were ignored by the regime. In 1938, hearing that Adolf Hitler wanted to include Futurism in a traveling exhibition of degenerate art, Marinetti persuaded Mussolini to refuse to let it enter Italy. During the same year he protested publicly against anti-Semitism.
Marinetti made numerous attempts to ingratiate himself with the regime, becoming less radical and avant garde with each. He relocated from Milan to Rome. He became an academician despite his condemnation of academies, saying, “It is important that Futurism be represented in the Academy.” He was an atheist but became reconciled to the Catholic Church. However, in Gazzetta del Popolo, 23 June 1931, Marinetti expressed he's view that it was not essential to practise the Catholic religion in order to create masterpieces of sacred art.
There were other contradictions in his character: despite his nationalism, he was international, educated in Egypt and France, writing his first poems in French, publishing the Futurist Manifesto in a French newspaper and traveling to promote his ideas.
Marinetti volunteered for active service in the Second Italo-Abyssinian War and the Second World War, serving on the Eastern Front for a few weeks in the Summer and Autumn of 1942, despite his advanced age.
He died of cardiac arrest in Bellagio on 2 December 1944 while working on a collection of poems praising the wartime achievements of the Decima Flottiglia MAS.

</doc>
<doc id="11803" url="https://en.wikipedia.org/wiki?curid=11803" title="Franz Mesmer">
Franz Mesmer

Franz Anton Mesmer (; ; May 23, 1734 – March 5, 1815) was a German physician with an interest in astronomy, who theorised that there was a natural energetic transference that occurred between all animated and inanimate objects that he called animal magnetism, sometimes later referred to as "mesmerism". The theory attracted a wide following between about 1780 and 1850, and continued to have some influence until the end of the century. In 1843 the Scottish physician James Braid proposed the term hypnosis for a technique derived from animal magnetism; today this is the usual meaning of "mesmerism".
Early life.
Mesmer was born in the village of Iznang, on the shore of Lake Constance in Swabia, Germany, a son of master forester Anton Mesmer (1701—after 1747) and his wife, Maria/Ursula (née Michel; 1701—1770). After studying at the Jesuit universities of Dillingen and Ingolstadt, he took up the study of medicine at the University of Vienna in 1759. In 1766 he published a doctoral dissertation with the Latin title "De planetarum influxu in corpus humanum" ("On the Influence of the Planets on the Human Body"), which discussed the influence of the Moon and the planets on the human body and on disease. This was not medical astrology. Building largely on Newton's theory of the tides, Mesmer expounded on certain tides in the human body that might be accounted for by the movements of the sun and moon. Evidence assembled by Frank A. Pattie suggests that Mesmer plagiarized his dissertation from a work by Richard Mead, an eminent English physician and Newton's friend. However, in Mesmer's day doctoral theses were not expected to be original.
In January 1768, Mesmer married Anna Maria von Posch, a wealthy widow, and established himself as a physician in the Austrian capital Vienna. In the summers he lived on a splendid estate and became a patron of the arts. In 1768, when court intrigue prevented the performance of "La finta semplice" (K. 51), for which the twelve-year-old Wolfgang Amadeus Mozart had composed 500 pages of music, Mesmer is said to have arranged a performance in his garden of Mozart's "Bastien und Bastienne" (K. 50), a one-act opera, though Mozart's biographer Nissen has stated that there is no proof that this performance actually took place. Mozart later immortalized his former patron by including a comedic reference to Mesmer in his opera "Così fan tutte".
The advent of animal magnetism.
In 1774, Mesmer produced an "artificial tide" in a patient, Francisca Österlin, who suffered from hysteria, by having her swallow a preparation containing iron and then attaching magnets to various parts of her body. She reported feeling streams of a mysterious fluid running through her body and was relieved of her symptoms for several hours. Mesmer did not believe that the magnets had achieved the cure on their own. He felt that he had contributed animal magnetism, which had accumulated in his work, to her. He soon stopped using magnets as a part of his treatment.
Same year he collaborated with Maximilian Hell.
In 1775, Mesmer was invited to give his opinion before the Munich Academy of Sciences on the exorcisms carried out by Johann Joseph Gassner, a priest and healer, and also a Swabian. Mesmer said that while Gassner was sincere in his beliefs, his cures resulted because he possessed a high degree of animal magnetism. This confrontation between Mesmer's secular ideas and Gassner's religious beliefs marked the end of Gassner's career as well as, according to Henri Ellenberger, the emergence of dynamic psychiatry.
The scandal that followed Mesmer's unsuccessful attempt to treat the blindness of an 18-year-old musician, Maria Theresia Paradis, led him to leave Vienna in 1777. In February 1778 Mesmer moved to Paris, rented an apartment in a part of the city preferred by the wealthy and powerful, and established a medical practice. Paris soon divided into those who thought he was a charlatan who had been forced to flee from Vienna and those who thought he had made a great discovery.
In his first years in Paris, Mesmer tried and failed to get either the Royal Academy of Sciences or the Royal Society of Medicine to provide official approval for his doctrines. He found only one physician of high professional and social standing, Charles d'Eslon, to become a disciple. In 1779, with d'Eslon's encouragement, Mesmer wrote an 88-page book, "Mémoire sur la découverte du magnétisme animal", to which he appended his famous 27 Propositions. These propositions outlined his theory at that time. Some contemporary scholars equate Mesmer’s animal magnetism with the Qi (chi) of Traditional Chinese Medicine and mesmerism with medical Qigong practices.
According to d'Eslon, Mesmer understood health as the free flow of the process of life through thousands of channels in our bodies. Illness was caused by obstacles to this flow. Overcoming these obstacles and restoring flow produced crises, which restored health. When Nature failed to do this spontaneously, contact with a conductor of animal magnetism was a necessary and sufficient remedy. Mesmer aimed to aid or provoke the efforts of Nature. To cure an insane person, for example, involved causing a fit of madness. The advantage of magnetism involved accelerating such crises without danger.
Procedure.
Mesmer treated patients both individually and in groups. With individuals he would sit in front of his patient with his knees touching the patient's knees, pressing the patient's thumbs in his hands, looking fixedly into the patient's eyes. Mesmer made "passes", moving his hands from patients' shoulders down along their arms. He then pressed his fingers on the patient's hypochondrium region (the area below the diaphragm), sometimes holding his hands there for hours. Many patients felt peculiar sensations or had convulsions that were regarded as crises and supposed to bring about the cure. Mesmer would often conclude his treatments by playing some music on a glass armonica.
By 1780 Mesmer had more patients than he could treat individually and he established a collective treatment known as the "baquet." An English physician who observed Mesmer described the treatment as follows:
In the middle of the room is placed a vessel of about a foot and a half high which is called here a "baquet". It is so large that twenty people can easily sit round it; near the edge of the lid which covers it, there are holes pierced corresponding to the number of persons who are to surround it; into these holes are introduced iron rods, bent at right angles outwards, and of different heights, so as to answer to the part of the body to which they are to be applied. Besides these rods, there is a rope which communicates between the baquet and one of the patients, and from him is carried to another, and so on the whole round. The most sensible effects are produced on the approach of Mesmer, who is said to convey the fluid by certain motions of his hands or eyes, without touching the person. I have talked with several who have witnessed these effects, who have convulsions occasioned and removed by a movement of the hand...
Investigation.
In 1784, without Mesmer requesting it, King Louis XVI appointed four members of the Faculty of Medicine as commissioners to investigate animal magnetism as practiced by d'Eslon. At the request of these commissioners the King appointed five additional commissioners from the Royal Academy of Sciences. These included the chemist Antoine Lavoisier, the physician Joseph-Ignace Guillotin, the astronomer Jean Sylvain Bailly, and the American ambassador Benjamin Franklin.
The commission conducted a series of experiments aimed, not at determining whether Mesmer's treatment worked, but whether he had discovered a new physical fluid. The commission concluded that there was no evidence for such a fluid. Whatever benefit the treatment produced was attributed to "imagination." But one of the commissioners, the botanist Antoine Laurent de Jussieu took exception to the official reports. He wrote a dissenting opinion that declared Mesmer's theory credible and worthy of further investigation. 
The commission did not examine Mesmer, but investigated the practice of d'Eslon.
In August 1784 Mesmer visited Mesmeric society in Lyon. In 1785 Mesmer left Paris. In 1790 he was in Vienna again to settle the estate of his deceased wife Maria Anna. When he sold his house in Vienna in 1801 he was in Paris. 
Mesmer was driven into exile soon after the investigations on animal magnetism. His exact activities during the last twenty years of his life are largely unknown. He died in 1815 in Meersburg, Germany.
Abbe Faria, an Indo-Portuguese monk in Paris and a contemporary of Mesmer, emphasized that "nothing comes from the magnetizer; everything comes from the subject and takes place in his imagination i.e., autosuggestion generated from within the mind."

</doc>
<doc id="11806" url="https://en.wikipedia.org/wiki?curid=11806" title="Foix–Alajouanine syndrome">
Foix–Alajouanine syndrome

Foix–Alajouanine syndrome is a disorder caused by an arteriovenous malformation of the spinal cord. The patients present with symptoms indicating spinal cord involvement (paralysis of arms and legs, numbness and loss of sensation and sphincter dysfunction), and pathological examination reveals disseminated nerve cell death in the spinal cord and abnormally dilated and tortuous vessels situated on the surface of the spinal cord. Surgical treatment can be tried in some cases. If surgical intervention is contraindicated, corticosteroids may be used.
The condition is named after Charles Foix and Théophile Alajouanine.

</doc>
<doc id="11807" url="https://en.wikipedia.org/wiki?curid=11807" title="Ferromagnetism">
Ferromagnetism

Ferromagnetism is the basic mechanism by which certain materials (such as iron) form permanent magnets, or are attracted to magnets. In physics, several different types of magnetism are distinguished. Ferromagnetism (including ferrimagnetism) is the strongest type: it is the only one that typically creates forces strong enough to be felt, and is responsible for the common phenomena of magnetism in magnets encountered in everyday life. Substances respond weakly to magnetic fields with three other types of magnetism, paramagnetism, diamagnetism, and antiferromagnetism, but the forces are usually so weak that they can only be detected by sensitive instruments in a laboratory. An everyday example of ferromagnetism is a refrigerator magnet used to hold notes on a refrigerator door. The attraction between a magnet and ferromagnetic material is "the quality of magnetism first apparent to the ancient world, and to us today".
Permanent magnets (materials that can be magnetized by an external magnetic field and remain magnetized after the external field is removed) are either ferromagnetic or ferrimagnetic, as are other materials that are noticeably attracted to them. Only a few substances are ferromagnetic. The common ones are iron, nickel, cobalt and most of their alloys, some compounds of rare earth metals, and a few naturally-occurring minerals such as lodestone.
Ferromagnetism is very important in industry and modern technology, and is the basis for many electrical and electromechanical devices such as electromagnets, electric motors, generators, transformers, and magnetic storage such as tape recorders, and hard disks.
History and distinction from ferrimagnetism.
Historically, the term "ferromagnetism" was used for any material that could exhibit spontaneous magnetization: a net magnetic moment in the absence of an external magnetic field. This general definition is still in common use. More recently, however, different classes of spontaneous magnetization have been identified when there is more than one magnetic ion per primitive cell of the material, leading to a stricter definition of "ferromagnetism" that is often used to distinguish it from ferrimagnetism. In particular,
These alignment effects only occur at temperatures below a certain critical temperature, called the Curie temperature (for ferromagnets and ferrimagnets) or the Néel temperature (for antiferromagnets).
Among the first investigations of ferromagnetism are the pioneering works of Aleksandr Stoletov on measurement of the magnetic permeability of ferromagnetics, known as the Stoletov curve.
Ferromagnetic materials.
The table on the right lists a selection of ferromagnetic and ferrimagnetic compounds, along with the temperature above which they cease to exhibit spontaneous magnetization (see Curie temperature).
Ferromagnetism is a property not just of the chemical make-up of a material, but of its crystalline structure and microstructure. There are ferromagnetic metal alloys whose constituents are not themselves ferromagnetic, called Heusler alloys, named after Fritz Heusler. Conversely there are non-magnetic alloys, such as types of stainless steel, composed almost exclusively of ferromagnetic metals.
One can also make amorphous (non-crystalline) ferromagnetic metallic alloys by very rapid quenching (cooling) of a liquid alloy. These have the advantage that their properties are nearly isotropic (not aligned along a crystal axis); this results in low coercivity, low hysteresis loss, high permeability, and high electrical resistivity. One such typical material is a transition metal-metalloid alloy, made from about 80% transition metal (usually Fe, Co, or Ni) and a metalloid component (B, C, Si, P, or Al) that lowers the melting point.
A relatively new class of exceptionally strong ferromagnetic materials are the rare-earth magnets. They contain lanthanide elements that are known for their ability to carry large magnetic moments in well-localized f-orbitals.
Actinide ferromagnets.
A number of actinide compounds are ferromagnets at room temperature or exhibit ferromagnetism upon cooling. PuP is a paramagnet with cubic symmetry at room temperature, but which undergoes a structural transition into a tetragonal state with ferromagnetic order when cooled below its T = 125 K. In its ferromagnetic state, PuP's easy axis is in the <100> direction.
In NpFe the easy axis is <111>. Above T ~500 K NpFe is also paramagnetic and cubic. Cooling below the Curie temperature produces a rhombohedral distortion wherein the rhombohedral angle changes from 60° (cubic phase) to 60.53°. An alternate description of this distortion is to consider the length c along the unique trigonal axis (after the distortion has begun) and a as the distance in the plane perpendicular to c. In the cubic phase this reduces to formula_1 = 1.00. Below the Curie temperature
which is the largest strain in any actinide compound. NpNi undergoes a similar lattice distortion below T = 32 K, with a strain of (43 ± 5) × 10. NpCo is a ferrimagnet below 15 K.
Lithium gas.
In 2009, a team of MIT physicists demonstrated that a lithium gas cooled to less than one kelvin can exhibit ferromagnetism. The team cooled fermionic lithium-6 to less than 150 billionths of one kelvin above absolute zero using infrared laser cooling. This demonstration is the first time that ferromagnetism has been demonstrated in a gas.
Explanation.
The Bohr–van Leeuwen theorem, discovered in the 1910s, showed that classical physics theories are unable to account for any form of magnetism, including ferromagnetism. Magnetism is now regarded as a purely quantum mechanical effect. Ferromagnetism arises due to two effects from quantum mechanics: spin and the Pauli exclusion principle.
Origin of magnetism.
One of the fundamental properties of an electron (besides that it carries charge) is that it has a magnetic dipole moment, i.e., it behaves like a tiny magnet. This dipole moment comes from the more fundamental property of the electron that it has quantum mechanical spin. Due to its quantum nature, the spin of the electron can be in one of only two states; with the magnetic field either pointing "up" or "down" (for any choice of up and down). The spin of the electrons in atoms is the main source of ferromagnetism, although there is also a contribution from the orbital angular momentum of the electron about the nucleus. When these magnetic dipoles in a piece of matter are aligned, (point in the same direction) their individually tiny magnetic fields add together to create a much larger macroscopic field.
However, materials made of atoms with filled electron shells have a total dipole moment of zero, because every electron's magnetic moment is cancelled by the opposite moment of the second electron in the pair. Only atoms with partially filled shells (i.e., unpaired spins) can have a net magnetic moment, so ferromagnetism only occurs in materials with partially filled shells. Because of Hund's rules, the first few electrons in a shell tend to have the same spin, thereby increasing the total dipole moment.
These unpaired dipoles (often called simply "spins" even though they also generally include angular momentum) tend to align in parallel to an external magnetic field, an effect called paramagnetism. Ferromagnetism involves an additional phenomenon, however: The dipoles tend to align spontaneously, giving rise to a spontaneous magnetization, even when there is no applied field.
Exchange interaction.
When two nearby atoms have unpaired electrons, whether the electron spins are parallel or antiparallel affects whether the electrons can share the same orbit as a result of the quantum mechanical effect called the exchange interaction. This in turn affects the electron location and the Coulomb (electrostatic) interaction and thus the energy difference between these states. This energy difference can be orders of magnitude larger than the energy differences associated with the magnetic dipole-dipole interaction due to dipole orientation, which tends to align the dipoles antiparallel. As a result, in ferromagnetic materials, nearby spins tend to align in the same direction. In certain doped semiconductor oxides RKKY interactions have been shown to bring about periodic longer-range magnetic interactions, a phenomenon of significance in the study of spintronic materials.
The exchange interaction is related to the Pauli exclusion principle, which says that two electrons with the same spin cannot also have the same "position". Therefore, under certain conditions, when the orbitals of the unpaired outer valence electrons from adjacent atoms overlap, the distributions of their electric charge in space are farther apart when the electrons have parallel spins than when they have opposite spins. This reduces the electrostatic energy of the electrons when their spins are parallel compared to their energy when the spins are anti-parallel, so the parallel-spin state is more stable. In simple terms, the electrons, which repel one another, can move "further apart" by aligning their spins, so the spins of these electrons tend to line up. This difference in energy is called the exchange energy.
The materials in which the exchange interaction is much stronger than the competing dipole-dipole interaction are frequently called "magnetic materials". For instance, in iron (Fe) the exchange force is about 1000 times stronger than the dipole interaction. Therefore, below the Curie temperature virtually all of the dipoles in a ferromagnetic material will be aligned. The exchange interaction is also responsible for the other types of spontaneous ordering of atomic magnetic moments occurring in magnetic solids, antiferromagnetism and ferrimagnetism.
There are different exchange interaction mechanisms which create the magnetism in different ferromagnetic, ferrimagnetic, and antiferromagnetic substances. These mechanisms include direct exchange, RKKY exchange, double exchange, and superexchange.
Magnetic anisotropy.
Although the exchange interaction keeps spins aligned, it does not align them in a particular direction. Without magnetic anisotropy, the spins in a magnet randomly change direction in response to thermal fluctuations and the magnet is superparamagnetic. There are several kinds of magnetic anisotropy, the most common of which is magnetocrystalline anisotropy. This is a dependence of the energy on the direction of magnetization relative to the crystallographic lattice. Another common source of anisotropy, inverse magnetostriction, is induced by internal strains. Single-domain magnets also can have a "shape anisotropy" due to the magnetostatic effects of the particle shape. As the temperature of a magnet increases, the anisotropy tends to decrease, and there is often a blocking temperature at which a transition to superparamagnetism occurs.
Magnetic domains.
The above would seem to suggest that every piece of ferromagnetic material should have a strong magnetic field, since all the spins are aligned, yet iron and other ferromagnets are often found in an "unmagnetized" state. The reason for this is that a bulk piece of ferromagnetic material is divided into tiny regions called "magnetic domains" (also known as "Weiss domains"). Within each domain, the spins are aligned, but (if the bulk material is in its lowest energy configuration, i.e. "unmagnetized"), the spins of separate domains point in different directions and their magnetic fields cancel out, so the object has no net large scale magnetic field.
Ferromagnetic materials spontaneously divide into magnetic domains because the "exchange interaction" is a short-range force, so over long distances of many atoms the tendency of the magnetic dipoles to reduce their energy by orienting in opposite directions wins out. If all the dipoles in a piece of ferromagnetic material are aligned parallel, it creates a large magnetic field extending into the space around it. This contains a lot of magnetostatic energy. The material can reduce this energy by splitting into many domains pointing in different directions, so the magnetic field is confined to small local fields in the material, reducing the volume of the field. The domains are separated by thin domain walls a number of molecules thick, in which the direction of magnetization of the dipoles rotates smoothly from one domain's direction to the other.
Magnetized materials.
Thus, a piece of iron in its lowest energy state ("unmagnetized") generally has little or no net magnetic field. However, if it is placed in a strong enough external magnetic field, the domain walls will move, reorienting the domains so more of the dipoles are aligned with the external field. The domains will remain aligned when the external field is removed, creating a magnetic field of their own extending into the space around the material, thus creating a "permanent" magnet. The domains do not go back to their original minimum energy configuration when the field is removed because the domain walls tend to become 'pinned' or 'snagged' on defects in the crystal lattice, preserving their parallel orientation. This is shown by the Barkhausen effect: as the magnetizing field is changed, the magnetization changes in thousands of tiny discontinuous jumps as the domain walls suddenly "snap" past defects.
This magnetization as a function of the external field is described by a hysteresis curve. Although this state of aligned domains found in a piece of magnetized ferromagnetic material is not a minimal-energy configuration, it is metastable, and can persist for long periods, as shown by samples of magnetite from the sea floor which have maintained their magnetization for millions of years.
Heating and then cooling (annealing) a magnetized material, subjecting it to vibration by hammering it, or applying a rapidly oscillating magnetic field from a degaussing coil tends to release the domain walls from their pinned state, and the domain boundaries tend to move back to a lower energy configuration with less external magnetic field, thus "demagnetizing" the material.
Commercial magnets are made of "hard" magnetic materials with very large magnetic anisotropy, such as alnico and hard ferrites, with a very strong tendency for the magnetization to be pointed along one axis of the crystal, the "easy axis". During manufacture the materials are subjected to various metallurgical processes in a powerful magnetic field, which aligns the crystal grains so their "easy" axes of magnetization all point in the same direction. Thus the magnetization, and the resulting magnetic field, is "built in" to the crystal structure of the material, making it very difficult to demagnetize.
Curie temperature.
As the temperature increases, thermal motion, or entropy, competes with the ferromagnetic tendency for dipoles to align. When the temperature rises beyond a certain point, called the Curie temperature, there is a second-order phase transition and the system can no longer maintain a spontaneous magnetization, so its ability to be magnetized or attracted to a magnet disappears, although it still responds paramagnetically to an external field. Below that temperature, there is a spontaneous symmetry breaking and magnetic moments become aligned with their neighbors. The Curie temperature itself is a critical point, where the magnetic susceptibility is theoretically infinite and, although there is no net magnetization, domain-like spin correlations fluctuate at all length scales.
The study of ferromagnetic phase transitions, especially via the simplified Ising spin model, had an important impact on the development of statistical physics. There, it was first clearly shown that mean field theory approaches failed to predict the correct behavior at the critical point (which was found to fall under a "universality class" that includes many other systems, such as liquid-gas transitions), and had to be replaced by renormalization group theory.

</doc>
<doc id="11809" url="https://en.wikipedia.org/wiki?curid=11809" title="Francesco Cossiga">
Francesco Cossiga

Francesco Cossiga, (; , 1928 – , 2010) was an Italian politician of the Christian Democracy party. He was the 42nd Prime Minister of Italy from 1979 to 1980 and the eighth President of Italy from 1985 to 1992. He was also a professor of constitutional law at the University of Sassari.
Cossiga was born in Sassari in the north of Sardinia. He started his political career during World War II. His name is now usually pronounced , but it was originally pronounced , with the stress on the first syllable, meaning "Corsica" in Sassarese. He was the cousin of Enrico Berlinguer.
Minister for the Christian Democrats.
He was a minister several times for the Democrazia Cristiana party (DC), notably during his stay at Viminale (Ministry for internal affairs) where he re-structured the Italian police, civil protection and secret services.
He was in office at the time of the kidnapping and murder of Aldo Moro by Red Brigades, and resigned when Moro was found dead in 1978. According to Italian journalist Enrico Deaglio, Cossiga, to justify his lack of action, "accused the leaders of CGIL and of the Italian Communist Party of knowing where Moro was detained". Cossiga was also minister of internal affairs when Fascist terrorists bombed Bologna station in 1980. 
Francesco Cossiga first assumed the explosion to have been caused by an accident (the explosion of an old boiler located in the basement of the station). Later, in a special session to the Senate, Cossiga supported the theory that neofascists were behind the attack, "unlike leftist terrorism, which strikes at the heart of the state through its representatives, black terrorism prefers massacre because it promotes panic and impulsive reactions."
Cossiga was elected President of the Italian Senate 1983, a position he held until 1985, when he became the President of Italy.
Election as President of Italy.
Following his resignation as president of the Senate in 1985, Cossiga was elected as President of Italy. This was the first time an Italian presidential candidate had won on the first ballot (where a two thirds majority is necessary).
It was not until his last two years as President that Cossiga began to express some unusual opinions regarding the Italian political system. He opined that the Italian parties, especially the DC (his own party) and Italian Communist Party, had to take into account the deep changes brought about by the fall of the Berlin Wall and the end of the Cold War.
These statements, soon dubbed "esternazioni", or "mattock blows" ("picconate"), were considered by many to be inappropriate for a President, and often beyond his constitutional powers; also, his mental health was doubted and Cossiga had to declare "I am the fake madman who speaks the truth." Cossiga suffered from bipolar disorder and depression in the last years of his life.
Tension developed between Cossiga and Prime Minister Giulio Andreotti. This tension emerged when Andreotti revealed the existence of Gladio, a stay-behind organization with the official aim of countering a possible Soviet invasion through sabotage and guerrilla warfare behind enemy lines. Cossiga acknowledged his involvement in the establishment of the organization. The Democratic Party of the Left (successor to the Communist Party) started the procedure of impeachment (Presidents of Italy can be impeached only for high treason against the State or for an attempt to overthrow the Constitution). Although he threatened to prevent the impeachment procedure by dissolving Parliament, the impeachment request was ultimately dismissed.
Cossiga resigned two months before the end of his term, on 1992.
Life senator.
According to the Italian Constitution, after his resignation from the office of President, Cossiga became lifetime senator, joining his predecessors in the upper house of parliament, with whom he also shared the title of President Emeritus of the Italian Republic.
In February 1998, Cossiga created the Unione Democratica per la Repubblica (a political party), declaring it to be politically central. The UDR was a crucial component of the majority that supported the D'Alema government in October 1998, after the fall of the Prodi government which lost a vote of confidence.
Cossiga declared that his support for D'Alema was intended to end the conventional exclusion of the former Communist Party (PCI) leaders from the premiership in Italy.
In 1999 UDR was dissolved and Cossiga returned to his activities as a senator, with competences in the Military Affairs' Commission.
In May 2006 he brought in a bill that would allow the region of South Tyrol to hold a referendum, where the local electorate could decide whether to remain within the Republic of Italy, take independence, or become part of Austria again.
On 27 November 2006, he resigned from his position as a lifetime senator. His resignation was, however, rejected on 2007 by a vote of the Senate.
Cossiga died on 17 August 2010 from respiratory problems.
Controversies.
In 2007, Cossiga wrote: "all democratic circles in America and of Europe, especially those of the Italian centre-left, now know that the disastrous attack was planned and realized by the American CIA and Mossad with the help of the Zionist world, to place the blame on Arab countries and to persuade the Western powers to intervene in Iraq and Afghanistan". However, the previous year Cossiga had stated that he rejects theoretical conspiracies and that it "seems unlikely that September 11 was the result of an American plot."
In the same statement, Cossiga claimed that a video tape circulated by Osama bin Laden's al Qaeda and containing threats against Silvio Berlusconi was "produced in the studios of Mediaset in Milan" and forwarded to the "Islamist Al-Jazeera television network." The purpose of that video tape (which was actually an audio tape) was to raise "a wave of solidarity to Berlusconi" who was, at the time, facing political difficulties.
In 2008, Francesco Cossiga said that Mario Draghi was "a craven moneyman".
Cossiga attributed the cause of the crash of the Aerolinee Itavia Flight 870, killing all on board, while en route from Bologna to Palermo, in 1980, to a missile fired from a French Navy aircraft. On 23 January 2013 Italy’s top criminal court ruled that there was "abundantly" clear evidence that the flight was brought down by a missile.
Honours and awards.
As President of the Republic, Cossiga was Head (and also Knight Grand Cross with Grand Cordon) of the Order of Merit of the Italian Republic (from 3 July 1985 to 28 April 1992), Military Order of Italy, Order of the Star of Italian Solidarity, Order of Merit for Labour and Order of Vittorio Veneto and Grand Cross of Merit of the Italian Red Cross. He has also been given honours and awards by other countries.

</doc>
<doc id="11812" url="https://en.wikipedia.org/wiki?curid=11812" title="Lockheed Martin F-35 Lightning II">
Lockheed Martin F-35 Lightning II

The Lockheed Martin F-35 Lightning II is a family of single-seat, single-engine, all-weather stealth multirole fighters undergoing final development and testing by the United States. The fifth generation combat aircraft is designed to perform ground attack, aerial reconnaissance, and air defense missions. The F-35 has three main models: the F-35A conventional takeoff and landing (CTOL) variant, the F-35B short take-off and vertical-landing (STOVL) variant, and the F-35C carrier-based Catapult Assisted Take-Off But Arrested Recovery (CATOBAR) variant. On 31 July 2015, the first squadron was declared ready for deployment after intensive testing by the United States.
The F-35 is descended from the X-35, which was the winning design of the Joint Strike Fighter (JSF) program. It is being designed and built by an aerospace industry team led by Lockheed Martin. Other major F-35 industry partners include Northrop Grumman, Pratt & Whitney and BAE Systems. The F-35 took its first flight on 15 December 2006. The United States plans to buy 2,457 aircraft. The F-35 variants are intended to provide the bulk of the manned tactical airpower of the U.S. Air Force, Navy, Marine Corps over the coming decades. Deliveries of the F-35 for the U.S. military are scheduled to be completed in 2037.
F-35 JSF development is being principally funded by the United States with additional funding from partners. The partner nations are either NATO members or close U.S. allies. The United Kingdom, Italy, Australia, Canada, Norway, Denmark, the Netherlands, and Turkey are part of the active development program; several additional countries have ordered, or are considering ordering, the F-35.
The program is the most expensive military weapons system in history, and it has been the object of much criticism from those inside and outside government — in the US and in allied countries. Critics argue that the plane is "plagued with design flaws," with many blaming the procurement process in which Lockheed was allowed "to design, test, and produce the F-35 all at the same time, instead of ... dentifying and fixin defects before firing up its production line." By 2014, the program was "$163 billion over budget n seven years behind schedule." Critics further contend that the program's high sunk costs and political momentum make it "too big to kill."
Development.
JSF program requirements and selection.
The JSF program was designed to replace the United States military F-16, A-10, F/A-18 (excluding newer E/F "Super Hornet" variants) and AV-8B tactical fighter and attack aircraft. To keep development, production, and operating costs down, a common design was planned in three variants that share 80 percent of their parts:
George Standridge, Vice President of Strategy and Business Development for Lockheed Martin Aeronautics, and a naval aviator who flew the F/A-18 Hornet in both the U.S. Navy and the Naval Reserve, predicted in 2006 that the F-35 would be four times more effective than legacy fighters in air-to-air combat, eight times more effective in air-to-ground combat, and three times more effective in reconnaissance and Suppression of Enemy Air Defenses – while having better range and requiring less logistics support and having around the same procurement costs (if development costs are ignored) as legacy fighters. The design goals call for the F-35 to be the premier strike aircraft through 2040 and to be second only to the F-22 Raptor in air supremacy.
The JSF development contract was signed on 16 November 1996, and the contract for System Development and Demonstration (SDD) was awarded on 26 October 2001 to Lockheed Martin, whose X-35 beat the Boeing X-32. Although both aircraft met or exceeded requirements, the X-35 design was considered to have less risk and more growth potential. The designation of the new fighter as "F-35" is out-of-sequence with standard DoD aircraft numbering, by which it should have been "F-24". It came as a surprise even to the company, which had been referring to the aircraft in-house by this expected designation.
The development of the F-35 is unusual for a fighter aircraft in that no two-seat trainer versions have been built for any of the variants; advanced flight simulators mean that no trainer versions were deemed necessary. Instead F-16s have been used as bridge trainers between the T-38 and the F-35. The T-X was intended to be used to train future F-35 pilots, but this might succumb to budget pressures in the USAF.
Design phase.
Based on wind tunnel testing, Lockheed Martin slightly enlarged its X-35 design into the F-35. The forward fuselage is longer to make room for avionics. Correspondingly, the horizontal stabilators were moved rearward to retain balance and control. The top surface of the fuselage was raised by along the center line. Also, it was decided to increase the size of the F-35B STOVL variant's weapons bay to be common with the other two variants. Manufacturing of parts for the first F-35 prototype airframe began in November 2003. Because the X-35 did not have weapons bays, their addition in the F-35 would cause design changes which would lead to later weight problems.
The F-35B STOVL variant was in danger of missing performance requirements in 2004 because it weighed too much; reportedly, by or 8 percent. In response, Lockheed Martin added engine thrust and thinned airframe members; reduced the size of the common weapons bay and vertical stabilizers; re-routed some thrust from the roll-post outlets to the main nozzle; and redesigned the wing-mate joint, portions of the electrical system, and the portion of the aircraft immediately behind the cockpit. Many of the changes were applied to all three variants to maintain high levels of commonality. By September 2004, the weight reduction effort had reduced the aircraft's design weight by , but the redesign cost $6.2 billion and delayed the project by 18 months.
On 7 July 2006, the U.S. Air Force, the lead service for the aircraft, officially announced the name of the F-35: "Lightning II", in honor of Lockheed's World War II-era twin-propeller Lockheed P-38 Lightning for the United States Army Air Forces and the Cold War-era jet, the English Electric Lightning for the Royal Air Force.
Lockheed Martin Aeronautics is the prime contractor and performs aircraft final assembly, overall system integration, mission system, and provides forward fuselage, wings and aircraft flight control system. Northrop Grumman provides active electronically scanned array (AESA) radar, electro-optical AN/AAQ-37 Distributed Aperture System (DAS), Communications, Navigation, Identification (CNI), center fuselage, weapons bay, and arrestor gear. BAE Systems provides the Flight Control Software (FCS1), the electronic warfare systems, crew life support and escape systems, aft fuselage, empennages as well as the horizontal and vertical tails. Alenia will perform final assembly for Italy and, according to an Alenia executive, assembly of all European aircraft with the exception of Turkey and the United Kingdom. The F-35 program has seen a great deal of investment in automated production facilities. For example, Handling Specialty produced the wing assembly platforms for Lockheed Martin.
On 19 December 2008, Lockheed Martin rolled out the first weight-optimized F-35A, designated AF-1. It was the first F-35 built at full production speed, and is structurally identical to the production F-35As that were delivered starting in 2010. On 5 January 2009, six F-35s had been built, including AF-1; another 13 pre-production test aircraft and four production aircraft were being manufactured. On 6 April 2009, U.S. Secretary of Defense Robert Gates proposed speeding up production for the U.S. to buy 2,443 F-35s.
Program cost increases and delays.
The F-35 program has experienced a number of cost overruns and developmental delays. The program's delays have come under fire from the U.S. Congress and some U.S. Department of Defense officials. The program has undergone a number of reassessments and changes since 2006. The Government Accountability Office (GAO) warned in March 2006 that excessive concurrency ("an overlap of flight testing and initial production") might result in expensive refits for several hundred F-35 aircraft that are planned for production before design testing is completed. In 2010, acquisition chief Ashton Carter issued an Acquisition Decision Memorandum restructuring the F-35 program. In November 2010, the GAO found that "Managing an extensive, still-maturing global network of suppliers adds another layer of complexity to producing aircraft efficiently and on-time" and that "due to the extensive amount of testing still to be completed, the program could be required to make alterations to its production processes, changes to its supplier base, and costly retrofits to produced and fielded aircraft, if problems are discovered." USAF budget data in 2010, along with other sources, projected the F-35 to have a flyaway cost from US$89 million to US$200 million over the planned production run. In February 2011, the Pentagon put a price of $207.6 million on each of the 32 aircraft to be acquired in FY2012, rising to $304.16 million ($9,732.8 million ÷ 32 aircraft) if its share of research, development, test and evaluation (RDT&E) spending is included.
On 21 April 2009, media reports, citing Pentagon sources, said that during 2007 and 2008, spies downloaded several terabytes of data related to the F-35's design and electronics systems, potentially compromising the aircraft and aiding the development of defense systems against it. Lockheed Martin rejected suggestions that the project was compromised, stating it "does not believe any classified information had been stolen". Other sources suggested that the incident caused both hardware and software redesigns to be more resistant to cyber attack. In March 2012, BAE Systems was reported to be the target of cyber espionage. BAE Systems refused to comment on the report, although they did state, "u own cyber security capability can detect, prevent and rectify such attacks."
On 9 November 2009, Ashton Carter, under-secretary of defense for acquisition, technology and logistics, acknowledged that the Pentagon "joint estimate team" (JET) had found possible future cost and schedule overruns in the project and that he would be holding meetings to attempt to avoid these. On 1 February 2010, Gates removed the JSF Program Manager, U.S. Marine Corps Major General David Heinz, and withheld $614 million in payments to Lockheed Martin because of program costs and delays.
On 11 March 2010, a report from the Government Accountability Office to United States Senate Committee on Armed Services projected the overall unit cost of an F-35A to be $113 million in today's money. In 2010, Pentagon officials disclosed that the F-35 program has exceeded its original cost estimates by more than 50 percent. An internal Pentagon report critical of the JSF project states that "affordability is no longer embraced as a core pillar". In 2010, Lockheed Martin expected to reduce government cost estimates by 20 percent. On 24 March 2010, Gates termed the cost overruns and delays as "unacceptable" in a testimony before the U.S. Congress; and characterized previous cost and schedule estimates as "overly rosy". Gates insisted the F-35 would become "the backbone of U.S. air combat for the next generation" and informed the Congress that he had expanded the development period by an additional 13 months and budgeted $3 billion more for the testing program while slowing down production. In August 2010, Lockheed Martin announced delays in resolving a "wing-at-mate overlap" production problem, which would slow initial production.
In November 2010, as part of a cost-cutting measure, the co-chairs of the National Commission on Fiscal Responsibility and Reform suggested cancelling the F-35B and halving orders of F-35As and F-35Cs. "Air Force Magazine" reported that "Pentagon officials" were considering canceling the F-35B because its short range meant that the forward bases or amphibious ships it would operate from would be in range of hostile tactical ballistic missiles. Lockheed Martin consultant Loren B. Thompson said that this rumor was a result of the usual tensions between the U.S. Navy and Marine Corps, and there was no alternative to the F-35B as an AV-8B Harrier II replacement. He also confirmed further delays and cost increases because of technical problems with the aircraft and software, blaming most of the delays and extra costs on redundant flight tests.
In November 2010, the Center for Defense Information estimated that the program would be restructured with an additional year of delay and $5 billion in additional costs. On 5 November 2010, the Block 1 software flew for the first time on BF-4. As of the end of 2010, only 15% of the software remained to be written, but this was reported to include the most difficult sections such as data fusion. In 2011, it was revealed that 50% of the eight million lines of code had been written and that it would take another six years to complete the software to the new schedule. By 2012, the total estimated lines of code for the entire program (onboard and offboard) had grown from 15 million lines to 24 million lines.
In 2011, the program head and Commander of the Naval Air Systems Command, Vice Admiral David Venlet, confirmed that the concurrency built into the program "was a miscalculation". This was during a contract dispute where the Pentagon insisted that Lockheed Martin help cover the costs of applying fixes found during testing to aircraft already produced. Lockheed Martin objected that the cost sharing posed an uninsurable unbounded risk that the company could not cover, and later responded that the "concurrency costs for F-35 continue to reduce". The Senate Armed Services Committee strongly backed the Pentagon position. In December 2011, Lockheed Martin accepted a cost sharing agreement. The Aerospace Industries Association warned that such changes would force them to anticipate cost overruns in future contract bids. As of 2012, problems found in flight testing were expected to continue to lead to higher levels of engineering changes through 2019. The total additional cost for concurrency in the program is around $1.3 billion. By the next year the cost had grown to $1.7 billion.
In January 2011, Defense Secretary Robert Gates expressed the Pentagon's frustration with the rising costs of the F-35 program when he said, "The culture of endless money that has taken hold must be replaced by a culture of restraint." Focusing his attention on the troubled F-35B, Gates ordered "a two-year probation", saying it "should be canceled" if corrections are unsuccessful. Gates has stated his support for the program. Some private analysts, such as Richard Aboulafia, of the Teal Group state that the F-35 program is becoming a money pit. Gates' successor, Leon Panetta, ended the F-35B's probation on 20 January 2012, stating "The STOVL variant has made—I believe and all of us believe—sufficient progress."
Former Pentagon manager Paul G. Kaminski has said that the lack of a complete test plan has added five years to the JSF program. Initial operating capability (IOC) will be determined by software development rather than by hardware production or pilot training. , the USMC plan an IOC in "mid-2015" for the F-35B with Block 2B software which gives basic air-to-air and air-to-ground capability. It has been reported that the USAF is planning to bring forward IOC for the F-35A to the Block 3I software in mid-2016 rather than waiting for the full-capability Block 3F in mid-2017; the F-35C will not enter service with the USN until mid-2018. The $56.4 billion development project for the aircraft should be completed in 2018 when the Block five configuration is expected to be delivered—several years late and considerably over budget.
Delays in the F-35 program may lead to a "fighter gap" where the United States and other countries will lack sufficient fighters to cover their requirements. Israel may seek to buy second-hand F-15Es, while Australia also sought additional F/A-18 Super Hornets in the face of F-35 delays.
In May 2011, the Pentagon's top weapons buyer Ashton Carter said that its new $133 million unit price was not affordable. In 2011, "The Economist" warned that the F-35 was in danger of slipping into a "death spiral" where increasing per-aircraft costs would lead to cuts in number of aircraft ordered, leading to further cost increases and further order cuts. Later that year, four aircraft were cut from the fifth Low Rate Initial Production (LRIP) order to pay for cost overruns; in 2012, a further two aircraft were cut. Lockheed Martin acknowledged that the slowing of purchases would increase costs. David Van Buren, U.S. Air Force acquisition chief, said that Lockheed Martin needed to cut infrastructure to match the reduced market for their aircraft. The company said that the slowdown in American orders will free up capacity to meet the urgent short-term needs of foreign partners for replacement fighters. Air Force Secretary Michael Donley said that no more money was available and that future price increases would be matched with cuts in the number of aircraft ordered. Later that month, the Pentagon reported that costs had risen another 4.3 percent, partially resulting from production delays. In 2012, the purchase of six out of 31 aircraft was tied to performance metrics of the program. In 2013, Bogdan repeated that no more money was available, but that he hoped to avoid the death spiral. In 2014 it was reported that another eight aircraft would be cut from the next year's order.
Japan has warned that it may halt their purchase if unit costs increase, and Canada has indicated it is not committed to a purchase yet. The United States is projected to spend an estimated $323 billion for development and procurement on the program, making it the most expensive defense program ever. Testifying before a Canadian parliamentary committee in 2011, Rear Admiral Arne Røksund of Norway estimated that his country's 52 F-35 fighter jets will cost $769 million each over their operational lifetime. In 2012, the total life-cycle cost for the entire U.S. fleet was estimated at US$1.51 trillion over a 50-year life, or $618 million per plane. To reduce this high life-cycle cost over a 50-year lifetime, the USAF is considering reducing Lockheed Martin's role in contractor logistics support. The company has responded that this cost estimate relies on future costs beyond its control such as USAF reorganizations and yet to be specified upgrades. Delays have negatively affected the program's worldwide supply chain and partner organizations.
In 2012, General Norton A. Schwartz decried the "foolishness" of reliance on computer models to settle the final design of the aircraft before flight testing found the issues that needed redesign. In 2013, JSF project team leader USAF Lieutenant General Chris Bogdan said that "A large amount of concurrency, that is, beginning production long before your design is stable and long before you've found problems in test, creates downstream issues where now you have to go back and retrofit airplanes and make sure the production line has those fixes in them. And that drives complexity and cost". Bogdan praised the improvement in the program ever since Lockheed Martin was forced to assume some of the financial risks.
In 2012, in order to avoid further redesign delays, the U.S. DoD accepted a reduced combat radius for the F-35A and a longer takeoff run for the F-35B. The F-35B's estimated radius has also decreased by 15 percent. In a meeting in Sydney in March, the United States pledged to eight partner nations that there would be no more program delays.
In May 2012, Lockheed Martin Chief Executive Bob Stevens complained that the Defense Department's requirements for cost data were driving up program cost. Stevens also admitted that a strike might cause a production shortfall of the target of 29 F-35s that year. Striking workers questioned the standards of replacement workers, as even their own work had been cited for "inattention to production quality" with a 16% rework rate. The workers went on strike to protect pensions whose costs have been the subject of negotiations with the Department of Defense over the next batch of aircraft. These same pension costs were cited by Fitch in their downgrade of the outlook for Lockheed Martin's stock price. Stevens said that while he hoped to bring down program costs, the industrial base was not capable of meeting the government's expectations of affordability.
According to a June 2012 Government Accountability Office report, the F-35's unit cost has almost doubled, an increase of 93% over the program's 2001 baseline cost estimates. In 2012, Lockheed Martin reportedly feared that the tighter policies for award fees of the Obama administration would reduce their profits by $500 million over the following five years. This was demonstrated in 2012 when the Pentagon withheld the maximum $47 million allowed for the company's failure to certify its program to track project costs and schedules. The GAO has also faulted the USAF and USN for not fully planning the costs of extending legacy F-16 and F-18 fleets to cover for the delayed F-35. Due to cost cutting measures, the U.S. Government and the GAO have stated that the flyaway cost (including engines) has been dropping. The U.S. Government estimates that in 2020 an "F-35 will cost some $85m each or less than half of the 2009 initial examples cost. Adjusted to today’s dollars the 2020 price would be $75m each."
In 2013, Lockheed Martin began to lay off workers at the Fort Worth plant where the F-35s were assembled. They said that the currently estimated concurrency costs of refitting the 187 aircraft built by the time testing concludes in 2016 are now less than previously feared. The GAO's Michael Sullivan said that the company had failed to get an early start on the systems engineering and had not understood the requirements or the technologies involved at the program's start. The Pentagon vowed to continue funding the program during budget sequestration if possible. The U.S. budget sequestration in 2013 could slow development of critical software, and the Congress has ordered another study to be made on the software development delays. As of 2014, software development remains the "number one technical challenge" for the F-35.
In June 2013, Frank Kendall, Pentagon acquisition, technology and logistics chief, declared "major advances" had been made in the F-35 program over the last three years; and that he intended to approve production rate increases in September. Air Force Lt. Gen. Christopher Bogdan, program executive officer, reported far better communications between government and vendor managers, and that negotiations over Lot 6 and 7 talks were moving fast. It was also stated that operating costs had been better understood since training started, and he predicted "we can make a substantial dent in projections" of operating costs.
In July 2013, further doubt was cast on the latest (long delayed) schedule, with further software delays, and sensor, display and wing buffet problems continuing. In August it was revealed that the Pentagon was weighing cancellation of the program as one possible response to the budget sequestration, and the United States Senate Appropriations Subcommittee on Defense voted to cut advanced procurement for the fighter.
On 21 August 2013, C-Span reported that "Congressional Quarterly" and the Government Accountability Office were indicating the "total estimated program cost now is $400b—nearly twice the initial cost". The current investment was documented as approximately $50 billion. The projected $316 billion cost in development and procurement spending was estimated through 2037 at an average of $12.6 billion per year. These were confirmed by Steve O'Bryan, Vice President of Lockheed Martin on the same date.
In 2013, a RAND study found that during development the three different versions had drifted so far apart from each other that having a single base design might now be more expensive than if the three services had simply built entirely different aircraft tailored to their own requirements.
In 2014, the airframe cost went below $100 million for the first time, and the Air Force expected unit costs to fall.
A 2014 Center for International Policy study cast doubt on the number of indirect jobs created by the program, which has been a key selling point for the F-35 to Congress. Lockheed stood by their job numbers and said that their accounting was in line with industry norms.
A January 2014 report by J. Michael Gilmore said that new software delays could delay Block 2B release by 13 months; this was reduced to 4 months in the DOTE report from November 2014. The F-35 program office considers software to be the top technical risk to the program, and the USMC has maintained their expectation of an IOC in July 2015.
In 2014, U.S. Senator John McCain blamed cost increases in the program on "cronyism".
In 2014, the GAO found that the F-35 fleet would have operating costs 79% higher than the aircraft it replaced. The latest Selected Acquisition Report stated that the program cost has increased 43% from 2001 with Program Acquisition Unit Cost up 68% and Unit Recurring Flyaway up 41%. The F-35A's cost per flying hour is $32.5k while the F-16C/D is $25.5k but each F-35A will only fly 250 hours a year to the F-16's 316 hours resulting in the same yearly operating cost.
In July 2014, Lockheed Martin, Northrop Grumman, and BAE Systems announced they would invest a combined $170M into the program, which is anticipated to save over $10M per aircraft. This initiative has set the project on track for an $80M (including engine) price tag per aircraft (F-35A), by 2018 when full production starts.
The December 2014 "Selected Acquisition Report" listed a cost decrease of $7.5 billion against a program cost of $391.1 billion ($320 billion in 2012 dollars). Lockheed Martin stated that there would be a decrease of nearly $60 billion to the operations and support costs.
The 2015 DoD annual report stated that the current schedule to complete System Development and Demonstration (SDD) and enter IOT&E by August 2017 is unrealistic, instead the program will likely not finish Block 3F development and flight testing prior to January 2018. Based on these projected completion dates for Block 3F developmental testing, IOT&E would not start earlier than August 2018.
Concerns over performance and safety.
A Lockheed Martin press release points to USAF simulations regarding the F-35's air-to-air performance against adversaries described as "4th generation" fighters, in which it states the F-35 is "400 percent" more effective. Major General Charles R. Davis, USAF, the F-35 program executive officer, has stated that the "F-35 enjoys a significant Combat Loss Exchange Ratio advantage over the current and future air-to-air threats, to include Sukhois".
In September 2008, in reference to the original plan to fit the F-35 with only two air-to-air missiles (internally), Major Richard Koch, chief of USAF Air Combat Command’s advanced air dominance branch is reported to have said that "I wake up in a cold sweat at the thought of the F-35 going in with only two air-dominance weapons." The Norwegians have been briefed on a plan to equip the F-35 with six AIM-120D missiles by 2019. Former RAND author John Stillion has written of the F-35A's air-to-air combat performance that it "can't turn, can't climb, can't run"; Lockheed Martin test pilot Jon Beesley has stated that in an air-to-air configuration the F-35 has almost as much thrust as weight and a flight control system that allows it to be fully maneuverable even at a 50-degree angle of attack. Consultant to Lockheed Martin Loren B. Thompson has said that the "electronic edge F-35 enjoys over every other tactical aircraft in the world may prove to be more important in future missions than maneuverability".
In an April 2009 interview with the state-run "Global Times", Chen Hu, editor-in-chief of World Military Affairs magazine said that the F-35 is too costly because it attempts to provide the capabilities needed for all three American services in a common airframe. U.S. defense specialist Winslow T. Wheeler and aircraft designer Pierre Sprey have commented of the F-35 being "heavy and sluggish" and possessing "pitifully small load for all that money", further criticizing the value for money of the stealth measures as well as lacking fire safety measures; his final conclusion was that any air force would be better off maintaining its fleets of F-16s and F/A-18s compared to buying into the F-35 program. A senior U.S. defense official was quoted as saying that the F-35 will be "the most stealthy, sophisticated and lethal tactical fighter in the sky," and added "Quite simply, the F-15 will be no match for the F-35." After piloting the aircraft, RAF Squadron Leader Steve Long said that, over its existing aircraft, the F-35 will give "the RAF and Navy a quantum leap in airborne capability."
In November 2009, Jon Schreiber, head of F-35 international affairs program for the Pentagon, said that the U.S. will not share the software code for the F-35 with its allies. The US plans to set up a reprogramming facility that will develop JSF software and distribute it to allies.
In 2011, Canadian politicians raised the issue of the safety of the F-35's reliance on a single engine (as opposed to a twin-engine configuration, which provides a backup in case of an engine failure). Canada, and other operators, had previous experience with a high-accident rate with the single-engine Lockheed CF-104 Starfighter with many accidents related to engine failures. When asked what would happen if the F-35's single engine fails in the Far North, Defence Minister Peter MacKay stated "It won’t".
In November 2011, a Pentagon study team identified 13 areas of concern that remained to be addressed in the F-35.
In May 2012, Michael Auslin of the American Enterprise Institute questioned the capability of the F-35 to engage modern air defenses. In July 2012, the Pentagon awarded Lockheed Martin $450 million to improve the F-35 electronic warfare systems and incorporate Israeli systems.
In a negative assessment of the Joint Strike Fighter, the think tank Air Power Australia declared that the Joint Strike Fighter is not designed to perform air superiority roles and also is not adapted to performing the long-range penetration strike role filled by previous Australian aircraft like the General Dynamics F-111C. Critically, they also stated that the F-35’s "intended survivability and lethality are mismatched against the operational environment in which the aircraft is intended to be used."
In June 2012, Australia's Air Vice Marshal Osley responded to Air Power Australia's criticisms by saying "Air Power Australia (Kopp and Goon) claim that the F-35 will not be competitive in 2020 and that Air Power Australia's criticisms mainly center around F-35's aerodynamic performance and stealth capabilities." Osley continued with, "these are inconsistent with years of detailed analysis that has been undertaken by Defence, the JSF program office, Lockheed Martin, the U.S. services and the eight other partner nations. While aircraft developments, such as the Russian PAK-FA or the Chinese J20, as argued by Airpower Australia, show that threats we could potentially face are becoming increasingly sophisticated, there is nothing new regarding development of these aircraft to change Defence's assessment." He then said that he thinks that the Air Power Australia's "analysis is basically flawed through incorrect assumptions and a lack of knowledge of the classified F-35 performance information."
In a report released in 2013, it was stated that flaws in the fuel tank and fueldraulic (fuel-based hydraulic) systems have left it considerably more vulnerable to lightning strikes and other fire sources, including enemy fire, than previously revealed, especially at lower altitudes. This report updated a separate report from 2010, in which Lockheed Martin spokesman John Kent said that adding fire-suppression systems would offer "very small" improvement to survivability. The same 2010 report also noted performance degradation of the three variants; the sustained turn rates had been reduced to 4.6 g for the F-35A, 4.5 g for the F-35B, and 5.0 g for the F-35C. The acceleration performance of all three variants was also downgraded, with the F-35C taking 43 seconds longer than an F-16 to accelerate from Mach 0.8 to Mach 1.2; this was judged by several fighter pilots to be a lower performance level than expected from a fourth generation fighter. On 30 August 2013, it was reported that the F-35B and F-35C models take several complex maneuvers in order to "accelerate" to their top speed of Mach 1.6, which consumed almost all of the onboard fuel. The F-35 program office is reconsidering addition of previously removed safety equipment. In 2012, Lockheed Martin program manager Tom Burbage said that while the relatively large cross-sectional area of the fighter that was required by the internal weapons bays gave it a disadvantage against fourth generation fighters that were operating in a clear configuration, the F-35 armed with weapons carried internally had the advantage over fighters carrying their weapons outside the aircraft.
In March 2013, USAF test pilots, flying with pre-operational software that did not utilize the all-aspect infrared AAQ-37 DAS sensor, noted a lack of visibility from the F-35 cockpit during evaluation flights, which would get them consistently shot down in combat. Defense spending analyst Winslow Wheeler concluded from flight evaluation reports that the F-35A "is flawed beyond redemption"; in response, program manager Bogdan suggested that pilots worried about being shot down should fly cargo aircraft instead. The same report found (in addition to the usual problems with the aircraft listed above):
The JPO responded that more experienced pilots would be able to safely operate the aircraft and that procedures would improve over time.
Even in the final "3F" software version, the F-35 will lack ROVER, in spite of having close air support as one of its primary missions.
In 2014, David Axe stated design flaws related to its single-engine configuration could vex the F-35 for decades to come, forcing the Pentagon to suspend flying too often for the majority of its fighter fleet.
In November 2014, China unveiled the portable JY-26 Skywatch-U UHF 3-D long-range surveillance radar system, specifically designed to defeat stealth aircraft like the F-35. Responding to a reporter's question about the High-Frequency radar threat General Welsh said "while we may have a new radar developed that allows an acquisition radar to see an airplane, that doesn't mean you can pass the track off to a radar that will then guide a weapon to be able to destroy the airplane. As long as we break the kill chain sometime between when you arrive in the battle space and when the enemy weapon approaches your airplane, you're successful at using stealth."
A 2014 Pentagon report found these issues:
A 2015 Pentagon report found these issues:
Three different types of data "massaging" are identified in the DOT&E report: moving failures from one category to another, less important one; ignoring repetitive failures, thus inflating numbers of failure-free hours; and improper scoring of reliability. Maintenance problems were determined to be so severe that the F-35 is only able to fly twice a week. To address the issue of wing drop and buffet maneuvering, the required control law modifications will reduce the maneuverability of the F-35, "only exacerbating the plane’s performance problems in this area". The F-35C's wing drop problem is "worse than other variants". Testing to investigate the impact of buffet and transonic roll-off (TRO or “wing drop”) on the helmet-mounted display and offensive and defensive maneuvering found that “buffet affected display symbology, and would have the greatest impact in scenarios where a pilot was maneuvering to defeat a missile shot.” Buffeting also degrades the gyroscopes in the inertial platforms which are essential for flight control, navigation, and weapons aiming. DOT&E explained that this was an ongoing issue: “In heavy buffet conditions, which occur between 20 and 26 degrees angle of attack, faults occurred in the inertial measurement units (IMUs) in the aircraft that degraded the flight control system (two of three flight control channels become disabled), requiring a flight abort.”
In early 2015 the AF-2 F-35A, the primary flight sciences loads and flutter evaluation aircraft, was flown by Lockheed Martin F-35 site lead test pilot David “Doc” Nelson in air-to-air combat maneuvers against F-16s for the first time and, based on the results of these and earlier flight-envelope evaluations, said the aircraft can be cleared for greater agility as a growth option. AF-2 was the first F-35 to be flown to 9g+ and -3g, and to roll at design-load factor. Departure/spin resistance was also proven during high angle-of-attack (AOA) testing which eventually went as high as 110 deg. AOA. “When we did the first dogfight in January, they said, ‘you have no limits,’” says Nelson. “It was loads monitoring, so they could tell if we ever broke something. It was a confidence builder for the rest of the fleet because there is no real difference structurally between AF-2 and the rest of the airplanes.” “Pilots really like maneuverability, and the fact that the aircraft recovers so well from a departure allows us to say o the designers of the flight control system law, ‘you don’t have to clamp down so tight,’” says Nelson.
With the full flight envelope now opened to an altitude of 50,000 ft, speeds of Mach 1.6/700 KCAS and loads of 9 g, test pilots also say improvements to the flight control system have rendered the transonic roll-off (TRO) issue tactically irrelevant. Highlighted as a “program concern” in the Defense Department’s Director of Operational Test and Evaluation (DOT&E) 2014 report, initial flight tests showed that all three F-35 variants experienced some form of wing drop in high-speed turns associated with asymmetrical movements of shock waves. However, TRO “has evolved into a non-factor,” says Nelson, who likens the effect to a momentary “tug” on one shoulder harness. “You have to pull high-g to even find it.” The roll-off phenomena exhibits itself as “less than 10 deg./sec. for a fraction of a second. We have been looking for a task it affects and we can’t find one.”
In July 2015, Lockheed Martin confirmed the authenticity of a leaked report showing the F-35 to be less maneuverable than an older F-16D with wing tanks. The pilot who flew the mission reported inferior energy maneuverability, a limited pitch rate and flying qualities that were "not intuitive or favorable" in a major part of the air-combat regime gave the F-16 the tactical advantage. In general the high AoA capabilities of the jet could not be used in an effective way without significantly reducing follow-on maneuvering potential. In an interview with CBC Radio broadcast 2 July 2015, military journalist David Axe claimed to have read the leaked report and stated: "Against a determined foe, the F-35 is in very big trouble." However, the F-35 used was a flight test aircraft with a restricted flight envelope and lacked some features present on the operational aircraft. The Pentagon, JPO, and defense analysts have defended the F-35's utility in spite of the report's assertion that it lacks maneuverability by saying it was designed primarily to disrupt the kill chain of advanced air defenses while the F-22 would handle close-in dogfighting, it poses advanced sensor and information fusion capabilities to detect and engage enemy aircraft at long ranges before it can be seen and merged with, and that most air combat in recent decades has focused on sensors and weapons that achieved long-range kills rather than close combat.
In the report's conclusions and recommendations it was noted that loads remained below limits, which implied there may be more maneuverability available to the airframe. There were five recommendations made: to increase pitch rate and available Nz (Normal Acceleration g) to provide the pilot with more maneuverability options given the inherent energy deficit; consider increasing alpha onset to also help offset the energy maneuverability deficit; consider increasing the beginning of the high AoA blended region to 30 degrees or greater to make high AoA maneuvering more predictable and intuitive; consider increasing pilot yaw rate to remove the gradual sluggish yaw response; and improve HMD Boresight performance to account for dynamic maneuvers and consider improving rearward visibility by creating more space for helmet motion.
Pentagon−Lockheed Martin relation issues.
In September 2012, the Pentagon criticized, quite publicly, Lockheed Martin's performance on the F-35 program and stated that it would not bail out the program again if problems with the plane's systems, particularly the helmet-mounted display, were not resolved. The deputy F-35 program manager said that the government's relationship with the company was the "worst I've ever seen" in many years of working on complex acquisition programs. Air Force Secretary Michael Donley told reporters the Pentagon had no more money to pour into the program after three costly restructurings in recent years. He said the department was done with major restructuring and that there was no further flexibility or tolerance for that approach. This criticism followed a "very painful" 7 September review that focused on an array of ongoing program challenges. Lockheed Martin responded with a brief statement saying it would continue to work with the F-35 program office to deliver the new fighter.
On 28 September 2012, the Pentagon announced that the F-35 Joint Strike Fighter support program would become an open competition. They invited companies to participate in a two-day forum on 14–15 November for possible opportunities to compete for work managing the supply chain of the aircraft. Their reason is to reduce F-35 life-cycle costs by creating competition within the program and to refine its acquisition strategy and evaluate alternatives that will deliver the best value, long-term F-35 sustainment solution. This could be hazardous to Lockheed Martin, the current prime contractor for sustainment of all three variants, and selection of another company could reduce their revenues.
In 2013, the officer in charge of the program blamed Lockheed Martin and Pratt & Whitney for gouging the government on costs, instead of focusing on the long-term future of the program.
In 2014, Lockheed was reported to be having problems with build quality, including one aircraft with a valve installed backwards and another with gaps in the stealth coating.
Upgrades.
Lockheed Martin's development roadmap extends until 2021, including a Block 6 engine improvement in 2019. The aircraft are expected to be upgraded throughout their operational lives.
In September 2013, Northrop Grumman revealed the development of a company-funded Directional Infrared Counter Measures system in anticipation of a requirement to protect the F-35 from heat-seeking missiles. A laser jammer is expected to be part of the F-35 Block 5 upgrade; it must meet low-observability (LO) requirements and fit in the F-35's restricted space. Called the Threat Nullification Defensive Resource (ThNDR), it is to have a small, powerful laser, beam steering and LO window, use liquid cooling, and fit alongside the distributed aperture system (DAS) to provide spherical coverage with minimal changes; the DAS would provide missile warning and cue the jam head.
Combat capabilities of the F-35 are made possible through software increments to advance technical abilities. Block 2A software enhanced simulated weapons, data link capabilities, and early fused sensor integration. Block 2B software enables the F-35 to provide basic close air support with certain JDAMs and the 500 lb GBU-12 Paveway II, as well as fire the AIM-120 AMRAAM. The Air Force is to declare the F-35 initially operational with Block 3i software. Full operational capability will come from Block 3F software; Block 3F enhances its ability to suppress enemy air defenses and enables the Lightning II to deploy the 500 lb JDAM, the GBU-53/B SDB II, and the AIM-9X Sidewinder. Block 4 software will increase the weapons envelope of the F-35 and is made to counter air defenses envisioned to be encountered past the 2040s. Block 4 upgrades will be broken into two increments; Block 4A in 2021 and Block 4B in 2023. This phase will also include usage of weaponry unique to British, Turkish, and other European countries who will operate Lightning II.
Lockheed has offered the potential of "Higher Definition Video, longer range target detection and identification, Video Data Link, and Infrared (IR) Marker and Pointer" for the EOTS in future upgrades.
Design.
Overview.
The F-35 resembles a smaller, single-engine sibling of the twin-engine Lockheed Martin F-22 Raptor and drew elements from it. The exhaust duct design was inspired by the General Dynamics Model 200 design, proposed for a 1972 supersonic VTOL fighter requirement for the Sea Control Ship. Although several experimental designs have been developed since the 1960s, such as the unsuccessful Rockwell XFV-12, the F-35B is to be the first operational supersonic, STOVL stealth fighter.
Acquisition deputy to the assistant secretary of the Air Force, Lt. Gen. Mark D. "Shack" Shackelford has said that the F-35 is designed to be America's "premier surface-to-air missile killer and is uniquely equipped for this mission with cutting edge processing power, synthetic aperture radar integration techniques, and advanced target recognition." Lockheed Martin states the F-35 is intended to have close- and long-range air-to-air capability second only to that of the F-22 Raptor. Lockheed Martin has said that the F-35 has the advantage over the F-22 in basing flexibility and "advanced sensors and information fusion". Lockheed Martin has suggested that the F-35 could replace the USAF's F-15C/D fighters in the air superiority role and the F-15E Strike Eagle in the ground attack role.
Some improvements over current-generation fighter aircraft are:
Structural composites in the F-35 are 35% of the airframe weight (up from 25% in the F-22). The majority of these are bismaleimide (BMI) and composite epoxy material. The F-35 will be the first mass produced aircraft to include structural nanocomposites, namely carbon nanotube reinforced epoxy. Experience of the F-22's problems with corrosion led to the F-35 using a gap filler that causes less galvanic corrosion to the airframe's skin, designed with fewer gaps requiring filler and implementing better drainage. The relatively short 35-foot wingspan of the A and B variants is set by the F-35B's requirement to fit inside the Navy's current amphibious assault ship parking area and elevators; the F-35C's longer wing is considered to be more fuel efficient.
A United States Navy study found that the F-35 will cost 30 to 40 percent more to maintain than current jet fighters; not accounting for inflation over the F-35's operational lifetime. A Pentagon study concluded a $1 trillion maintenance cost for the entire fleet over its lifespan, not accounting for inflation. The F-35 program office found that as of January 2014, costs for the F-35 fleet over a 53-year life cycle was $857 billion. Costs for the fighter have been dropping and accounted for the 22 percent life cycle drop since 2010. Lockheed stated that by 2019, pricing for the fifth-generation aircraft will be less than fourth-generation fighters. An F-35A in 2019 is expected to cost $85 million per unit complete with engines and full mission systems, inflation adjusted from $75 million in December 2013.
Engines.
The Pratt & Whitney F135 powers the F-35. An alternative engine, the General Electric/Rolls-Royce F136, was being developed until it was cancelled by its manufacturers in December 2011 due to lack of funding from the Pentagon. The F135 and F136 engines are not designed to supercruise. However, the F-35 can briefly fly at Mach 1.2 for 150 miles. The F135 is the second (radar) stealthy afterburning jet engine. Like the Pratt & Whitney F119 from which it was derived, the F135 has suffered afterburner pressure pulsations, or 'screech' at low altitude and high speed. The F-35 has a maximum speed of over Mach 1.6. With a maximum takeoff weight of 60,000 lb (27,000 kg), the Lightning II is considerably heavier than the lightweight fighters it replaces.
The STOVL F-35B is outfitted with the Rolls-Royce LiftSystem, designed by Lockheed Martin and developed by Rolls-Royce. This system more resembles the German VJ 101D/E than the preceding STOVL Harrier Jump Jet and the Rolls-Royce Pegasus engine. The Lift System is composed of a lift fan, drive shaft, two roll posts and a "Three Bearing Swivel Module" (3BSM). The 3BSM is a thrust vectoring nozzle which allows the main engine exhaust to be deflected downward at the tail of the aircraft. The lift fan is near the front of the aircraft and provides a counterbalancing thrust using two counter-rotating blisks. It is powered by the engine's low-pressure (LP) turbine via a drive shaft and gearbox. Roll control during slow flight is achieved by diverting unheated engine bypass air through wing-mounted thrust nozzles called Roll Posts.
F136 funding came at the expense of other program elements, impacting on unit costs. The F136 team stated their engine had a greater temperature margin, potentially critical for VTOL operations in hot, high altitude conditions. Pratt & Whitney tested higher thrust versions of the F135, partly in response to GE's statements that the F136 is capable of producing more thrust than the of early F135s. In testing, the F135 has demonstrated a maximum thrust of over ; making it the most powerful engine ever installed in a fighter aircraft as of 2010. It is much heavier than previous fighter engines; the Heavy Underway Replenishment system needed to transfer the F135 between ships is an unfunded USN requirement. Thermoelectric-powered sensors monitor turbine bearing health.
Armament.
The F-35A is armed with a GAU-22/A, a four-barrel version of the 25 mm GAU-12 Equalizer cannon. The cannon is mounted internally with 182 rounds for the F-35A or in an external pod with 220 rounds for the F-35B and F-35C; the gun pod has stealth features. The F-35 has two internal weapons bays, and external hardpoints for mounting up to four underwing pylons and two near wingtip pylons. The two outer hardpoints can carry pylons for the AIM-9X Sidewinder and AIM-132 ASRAAM short-range air-to-air missiles (AAM) only. The other pylons can carry the AIM-120 AMRAAM BVR AAM, , AGM-158 Joint Air to Surface Stand-off Missile (JASSM) cruise missile, and guided bombs. The external pylons can carry missiles, bombs, and external fuel tanks at the expense of increased radar cross-section, and thus reduced stealth.
There are a total of four weapons stations between the two internal bays. Two of these can carry air-to-surface missiles up to in A and C models, or two bombs up to in the B model; the other two stations are for smaller weapons such as air-to-air missiles. The weapon bays can carry AIM-120 AMRAAM, AIM-132 ASRAAM, the Joint Direct Attack Munition (JDAM), Paveway series of bombs, the Joint Standoff Weapon (JSOW), Brimstone anti-tank missiles, and cluster munitions (Wind Corrected Munitions Dispenser). An air-to-air missile load of eight AIM-120s and two AIM-9s is possible using internal and external weapons stations; a configuration of six bombs, two AIM-120s and two AIM-9s can also be arranged. The Terma A/S multi-mission pod (MMP) could be used for different equipment and purposes, such as electronic warfare, aerial reconnaissance, or rear-facing tactical radar.
Lockheed Martin states that the weapons load can be configured as all-air-to-ground or all-air-to-air, and has suggested that a Block 5 version will carry three weapons per bay instead of two, replacing the heavy bomb with two smaller weapons such as AIM-120 AMRAAM air-to-air missiles. Upgrades are to allow each weapons bay to carry four GBU-39 Small Diameter Bombs (SDB) for A and C models, or three in F-35B. Another option is four GBU-53/B Small Diameter Bomb IIs in each bay on all F-35 variants. The F-35A has been outfitted with four SDB II bombs and an AMRAAM missile to test adequate bay door clearance, as well as the C-model, but the VTOL F-35B will not be able to carry the required load of four SDB IIs in each weapons bay upon reaching IOC due to weight and dimension constraints; F-35B bay changes are to be incorporated to increase SDB II loadout around 2022 in line with the Block 4 weapons suite. The Meteor air-to-air missile may be adapted for the F-35, a modified Meteor with smaller tailfins for the F-35 was revealed in September 2010; plans call for the carriage of four Meteors internally. The United Kingdom planned to use up to four AIM-132 ASRAAM missiles internally, later plans call for the carriage of two internal and two external ASRAAMs. The external ASRAAMs are planned to be carried on "stealthy" pylons; the missile allows attacks to slightly beyond visual range without employing radar.
Norway and Australia are funding an adaptation of the Naval Strike Missile (NSM) for the F-35. Under the designation Joint Strike Missile (JSM), it is to be the only cruise missile to fit the F-35's internal bays; according to studies two JSMs can be carried internally with an additional four externally. The F-35 is expected to take on the Wild Weasel mission, though there are no planned anti-radiation missiles for internal carriage. The B61 nuclear bomb was initially scheduled for deployment in 2017; as of 2012 it was expected to be in the early 2020s, and in 2014 Congress moved to cut funding for the needed weapons integration work. Norton A. Schwartz agreed with the move and said that "F-35 investment dollars should realign to the long-range strike bomber". NATO partners who are buying the F-35 but cannot afford to make them dual-capable want the USAF to fund the conversions to allow their Lightning IIs to carry thermonuclear weapons. The USAF is trying to convince NATO partners who can afford the conversions to contribute to funding for those that cannot. The F-35 Block 4B will be able to carry two B61 nuclear bombs internally by 2024.
According to reports in 2002, solid-state lasers were being developed as optional weapons for the F-35. Lockheed is studying integrating a fiber laser onto the aircraft that uses spectral beam combining to channel energy from a stack of individual laser modules into a single, high-power beam, which can be scaled up or down for various levels of effects. Adding a laser would give the F-35 the ability to essentially burn missiles and other aircraft out of the sky. The F-35 is also one of the target platforms for the High Speed Strike Weapon if hypersonic missile development is successful.
The Air Force plans to use the F-35A to primarily take up the close air support (CAS) mission in contested environments. Amid criticism that the aircraft is not well suited for the role compared to a dedicated attack platform, Air Force chief of staff Mark Welsh is putting focus on weapons for the F-35 to employ on CAS sorties including guided rockets, fragmentation rockets that would shatter into individual projectiles before impact, and lighter, smaller ammunition in higher capacity gun pods. Fragmentary rocket warheads would have greater effects than cannon shells fired from a gun because a single rocket would create a "thousand-round burst," delivering more projectiles than a strafing run could. Other weapons could take advantage of the aircraft's helmet-mounted cueing system to aim rather than needing to point the nose at a target.
Stealth and signatures.
Radar.
The F-35 has been designed to have a low radar cross-section primarily due to the shape of the aircraft and the use of stealthy radar-absorbent materials in its construction, including fiber-mat. Unlike the previous generation of fighters, the F-35 was designed for very-low-observable characteristics. Besides radar stealth measures, the F-35 incorporates infrared signature and visual signature reduction measures.
The Fighter Teen Series (F-14, F-15, F-16, F/A-18) carried large external fuel tanks, but to avoid negating its stealth characteristics the F-35 must fly most missions without them. Unlike the F-16 and F/A-18, the F-35 lacks leading edge extensions and instead uses stealth-friendly chines for vortex lift in the same fashion as the SR-71 Blackbird. The small bumps just forward of the engine air intakes form part of the diverterless supersonic inlet (DSI) which is a simpler, lighter means to ensure high-quality airflow to the engine over a wide range of conditions. These inlets also crucially improve the aircraft's very-low-observable characteristics (by eliminating radar reflections between the diverter and the aircraft's skin). Additionally, the "bump" surface reduces the engine's exposure to radar, significantly reducing a strong source of radar reflection because they provide an additional shielding of engine fans against radar waves. The Y-duct type air intake ramps also help in reducing radar cross-section (RCS), because the intakes run parallel and not directly into the engine fans.
The F-35's radar-absorbent materials are designed to be more durable and less maintenance-intensive than those of its predecessors. At optimal frequencies, the F-35 compares favorably to the F-22 in stealth, according to General Mike Hostage, Commander of the Air Combat Command. Like other stealth fighters, however, the F-35 is more susceptible to detection by Low-frequency radars due to the Rayleigh scattering resulting from the aircraft's physical size. However, such radars are also conspicuous, susceptible to clutter, and have low precision. Although fighter-sized stealth aircraft could be detected by low-frequency radar, missile lock and targeting sensors primarily operate in the X-band, which F-35 RCS reduction is made for, so they cannot engage unless at close range. Because the aircraft's shape is important to the RCS, special care must be taken to match the "boilerplate" during production. Ground crews require Repair Verification Radar (RVR) test sets to verify the RCS after performing repairs, which is not a concern for non-stealth aircraft.
Acoustic.
In 2008, the Air Force revealed that the F-35 would be about twice as loud at takeoff as the McDonnell Douglas F-15 Eagle and up to four times as loud during landing. Residents near Luke Air Force Base, Arizona and Eglin Air Force Base, Florida, possible F-35 bases, requested environmental impact studies be conducted regarding the F-35's noise levels. In 2009, the city of Valparaiso, Florida, adjacent to Eglin AFB, threatened to sue over the impending F-35 arrival; this lawsuit was settled in March 2010. In 2009, testing reportedly revealed the F-35 to be: "only about as noisy as an F-16 fitted with a Pratt & Whitney F100-PW-200 engine...quieter than the Lockheed Martin F-22 Raptor and the Boeing F/A-18E/F Super Hornet." An acoustics study by Lockheed Martin and the Air Force found F-35's noise levels to be comparable to the F-22 and F/A-18E/F. A USAF environmental impact study found that replacing F-16s with F-35s at Tucson International Airport would subject more than 21 times as many residents to extreme noise levels. The USN will need to redesign hearing protection for sailors to protect against the "thundering 152 decibels" of the F-35. The Joint Strike Fighter program office found in October 2014 that the F-35B's take-off noise was only two decibels higher than a Super Hornet, a virtually indistinguishable difference to the human ear, and is even 10 decibels quieter when flying formations or landing.
Cockpit.
The F-35 features a full-panel-width glass cockpit touchscreen "panoramic cockpit display" (PCD), with dimensions of 20 by 8 inches (50 by 20 centimeters). A cockpit speech-recognition system (DVI) provided by Adacel has been adopted on the F-35 and the aircraft will be the first operational U.S. fixed-wing aircraft to employ this DVI system, although similar systems have been used on the AV-8B Harrier II and trialled in previous aircraft, such as the F-16 VISTA.
A helmet-mounted display system (HMDS) will be fitted to all models of the F-35. While some fighters have offered HMDS along with a head up display (HUD), this will be the first time in several decades that a front line fighter has been designed without a HUD. The F-35 is equipped with a right-hand HOTAS side stick controller. The Martin-Baker US16E ejection seat is used in all F-35 variants. The US16E seat design balances major performance requirements, including safe-terrain-clearance limits, pilot-load limits, and pilot size; it uses a twin-catapult system housed in side rails. This industry standard ejection seat can cause the heavier than usual helmet to inflict serious injury on lightweight pilots. The F-35 employs an oxygen system derived from the F-22's own system, which has been involved in multiple hypoxia incidents on that aircraft; unlike the F-22, the flight profile of the F-35 is similar to other fighters that routinely use such systems.
Sensors and avionics.
The F-35's sensor and communications suite has situational awareness, command and control and network-centric warfare capabilities. The main sensor on board is the AN/APG-81 Active electronically scanned array-radar, designed by Northrop Grumman Electronic Systems. It is augmented by the nose-mounted Electro-Optical Targeting System (EOTS), it provides the capabilities of an externally mounted Sniper Advanced Targeting Pod pod with a reduced radar cross-section. The AN/ASQ-239 (Barracuda) system is an improved version of the F-22's AN/ALR-94 electronic warfare suite, providing sensor fusion of Radio frequency and Infrared tracking functions, advanced radar warning receiver including geolocation targeting of threats, multispectral image countermeasures for self-defense against missiles, situational awareness and electronic surveillance, employing 10 radio frequency antennae embedded into the edges of the wing and tail. In September 2015, Lockheed unveiled the "Advanced EOTS" that offers short-wave infrared, high-definition television, infrared marker, and superior image detector resolution capabilities. Offered for the Block 4 configuration, it fits into the same area as the baseline EOTS with minimal changes while preserving stealth features.
Six additional passive infrared sensors are distributed over the aircraft as part of Northrop Grumman's electro-optical AN/AAQ-37 Distributed Aperture System (DAS), which acts as a missile warning system, reports missile launch locations, detects and tracks approaching aircraft spherically around the F-35, and replaces traditional night vision devices. All DAS functions are performed simultaneously, in every direction, at all times. The electronic warfare systems are designed by BAE Systems and include Northrop Grumman components. Functions such as the Electro-Optical Targeting System and the electronic warfare system are not usually integrated on fighters. The F-35's DAS is so sensitive, it reportedly detected the launch of an air-to-air missile in a training exercise from away, which in combat would give away the location of an enemy aircraft even if it had a very low radar cross-section.
The communications, navigation and identification (CNI) suite is designed by Northrop Grumman and includes the Multifunction Advanced Data Link (MADL), as one of a half dozen different physical links. The F-35 will be the first fighter with sensor fusion that combines radio frequency and IR tracking for continuous all-direction target detection and identification which is shared via MADL to other platforms without compromising low observability. The non-encrypted Link 16 is also included for communication with legacy systems. The F-35 has been designed with synergy between sensors as a specific requirement, the aircraft's "senses" being expected to provide a more cohesive picture of the battlespace around it and be available for use in any possible way and combination with one another; for example, the AN/APG-81 multi-mode radar also acts as a part of the electronic warfare system. The Program Executive Officer (PEO) General Bogdan has described the sensor fusion software as one of the most difficult parts of the program.
Much of the F-35's software is written in C and C++ due to programmer availability, Ada83 code also is reused from the F-22. The Integrity DO-178B real-time operating system (RTOS) from Green Hills Software runs on COTS Freescale PowerPC processors. The final Block 3 software is planned to have 8.6 million lines of code. In 2010, Pentagon officials discovered that additional software may be needed. General Norton Schwartz has said that the software is the biggest factor that might delay the USAF's initial operational capability. In 2011, Michael Gilmore, Director of Operational Test & Evaluation, wrote that, "the F-35 mission systems software development and test is tending towards familiar historical patterns of extended development, discovery in flight test, and deferrals to later increments."
The electronic warfare and electro-optical systems are intended to detect and scan aircraft, allowing engagement or evasion of a hostile aircraft prior to being detected. The CATbird avionics testbed has proved capable of detecting and jamming radars, including the F-22's AN/APG-77. The F-35 was previously considered a platform for the Next Generation Jammer; attention shifted to using unmanned aircraft in this capacity instead. Several subsystems use Xilinx FPGAs; these COTS components enable supply refreshes from the commercial sector and fleet software upgrades for the software-defined radio systems.
Lockheed Martin's Dave Scott stated that sensor fusion boosts engine thrust and oil efficiency, increasing the aircraft's range. Air Force official Ellen M. Pawlikowski has proposed using the F-35 to control and coordinate multiple unmanned combat aerial vehicles (UCAVs). Using its sensors and communications equipment, a single F-35 could orchestrate an attack made by up to 20 armed UCAVs.
Helmet-mounted display system.
The F-35 does not need to be physically pointing at its target for weapons to be successful. Sensors can track and target a nearby aircraft from any orientation, provide the information to the pilot through their helmet (and therefore visible no matter which way the pilot is looking), and provide the seeker-head of a missile with sufficient information. Recent missile types provide a much greater ability to pursue a target regardless of the launch orientation, called "High Off-Boresight" capability. Sensors use combined radio frequency and infra red (SAIRST) to continually track nearby aircraft while the pilot's helmet-mounted display system (HMDS) displays and selects targets; the helmet system replaces the display-suite-mounted head-up display used in earlier fighters. Each helmet costs $400,000.
The F-35's systems provide the edge in the "observe, orient, decide, and act" OODA loop; stealth and advanced sensors aid in observation (while being difficult to observe), automated target tracking helps in orientation, sensor fusion simplifies decision making, and the aircraft's controls allow the pilot to keep their focus on the targets, rather than the controls of their aircraft.
Problems with the Vision Systems International helmet-mounted display led Lockheed Martin-Elbit Systems to issue a draft specification for alternative proposals in early 2011, to be based around the Anvis-9 night vision goggles. BAE Systems was selected to provide the alternative system in late 2011. The BAE Systems alternative helmet was to include all the features of the VSI system. However, adopting the alternative helmet would have required a cockpit redesign, but in 2013 development on the alternative helmet was halted due to progress on the baseline helmet.
In 2011, Lockheed Martin-Elbit granted VSI a contract to fix the vibration, jitter, night-vision and sensor display problems in their helmet-mounted display. A speculated potential improvement is the replacement of Intevac’s ISIE-10 day/night camera with the newer ISIE-11 model. In October 2012, Lockheed Martin-Elbit stated that progress had been made in resolving the technical issues of the helmet-mounted display, and cited positive reports from night flying tests; it had been questioned whether the helmet system allows pilots enough visibility at night to carry out precision tasks. In 2013, in spite of continuing problems with the helmet display, the F-35B model completed 19 nighttime vertical landings onboard the USS "Wasp" at sea, by using the DAS instead of the helmet's built-in night vision capabilities, which offer at best 20/35 vision.
In October 2013, development of the alternate helmet was halted. The current Gen 2 helmet is expected to meet the requirements to declare, in July 2015, that the F-35 has obtained initial operational capability. Beginning in 2016 with low rate initial production (LRIP) lot 7, the program will introduce a Gen 3 helmet that features an improved night vision camera, new liquid crystal displays, automated alignment and other software enhancements.
In July 2015, an F-35 pilot commented that the helmet may have been one of the issues that the F-35 faced while dogfighting against an F-16 during a test; "The helmet was too large for the space inside the canopy to adequately see behind the aircraft. There were multiple occasions when the bandit would've been visible (not blocked by the seat) but the helmet prevented getting in a position to see him (behind the high side of the seat, around the inside of the seat, or high near the lift vector)."
Maintenance.
The program's maintenance concept is for any F-35 to be maintained in any F-35 maintenance facility and that all F-35 parts in all bases will be globally tracked and shared as needed. The commonality between the different variants has allowed the USMC to create their first aircraft maintenance Field Training Detachment to directly apply the lessons of the USAF to their F-35 maintenance operations. The aircraft has been designed for ease of maintenance, with 95% of all field replaceable parts "one deep" where nothing else has to be removed to get to the part in question. For instance the ejection seat can be replaced without removing the canopy, the use of low-maintenance electro-hydrostatic actuators instead of hydraulic systems and an all-composite skin without the fragile coatings found on earlier stealth aircraft.
The F-35 Joint Program Office has stated that the aircraft has received good reviews from pilots and maintainers, suggesting it is performing better than its predecessors did at a similar stage of development, and that the stealth type has proved relatively stable from a maintenance standpoint. This reported improvement is attributed to better maintenance training, as F-35 maintainers have received far more extensive instruction at this early stage of the program than on the F-22 Raptor. The F-35's stealth coatings are much easier to work with than those used on the Raptor. Cure times for coating repairs are lower and many of the fasteners and access panels are not coated, further reducing the workload for maintenance crews. Some of the F-35's radar-absorbent materials are baked into the jet's composite skin, which means its stealthy signature is not easily degraded. It is still harder to maintain (due to its stealth) than fourth-generation aircraft.
However, the DOT&E Report on the F-35 program published in January 2015 determined that the plane has not, in fact, reached any of the nine reliability measures the program was supposed to achieve by this point in its development and that the Joint Program Office has been re-categorizing failure incidents to make the plane look more reliable than it actually is. Further, the complexity of maintaining the F-35 means that, currently, none of the Services are ready to keep it in working order and instead “rely heavily on contractor support and unacceptable workarounds.” DOT&E found that the program achieved 61 percent of planned flight hours and that the average rate of availability was as low as 28 percent for the F-35A and 33 percent for the F-35B. The program created a new “modeled achievable” flight hour projection “since low availability was preventing the full use of bed-down plan flight hours.” According to the Assistant Secretary of the Air Force for Financial Management, in FY2014, each non-test F-35 flew only 7.7 hours per month, which amounts to approximately one sortie every 5.5 days—for combat purposes, a sortie rate so low as to be crippling. Mean flight hours between removal (MFHBR) have increased, but are still only 59 percent to 65 percent of the required threshold. DOT&E found that mean corrective maintenance time for critical failures got worse for the F-35A and the F-35C over the last year. Structural cracking is also proving to be a recurring and enduring problem that is not yet resolved.
Operational history.
Testing.
The first F-35A (designated AA-1) was rolled out in Fort Worth, Texas, on 19 February 2006. In September 2006, the first engine run of the F135 in an airframe took place. On 15 December 2006, the F-35A completed its maiden flight. A modified Boeing 737–300, the Lockheed CATBird has been used as an avionics test-bed for the F-35 program, including a duplication of the cockpit.
The first F-35B (designated BF-1) made its maiden flight on 11 June 2008, piloted by BAE Systems' test pilot Graham Tomlinson. Flight testing of the STOVL propulsion system began on 7 January 2010. The F-35B's first hover was on 17 March 2010, followed by its first vertical landing the next day. During a test flight on 10 June 2010, the F-35B STOVL aircraft achieved supersonic speeds as had the X-35B before. In January 2011, Lockheed Martin reported that a solution had been found for the cracking of an aluminum bulkhead during ground testing of the F-35B. In 2013, the F-35B suffered another bulkhead cracking incident. This will require redesign of the aircraft, which is already very close to the ultimate weight limit.
By June 2009, many of the initial flight test targets had been accomplished but the program was behind schedule. During 2008, a Pentagon Joint Estimate Team (JET) estimated that the program was two years behind the public schedule, a revised estimate in 2009 predicted a 30-month delay. Delays reduced planned production numbers by 122 aircraft through 2015 to provide an addition 2.8 billion for development; internal memos suggested that the official timeline would be extended by 13 months. The success of the JET led Ashton Carter calling for more such teams for other poorly performing projects.
Nearly 30 percent of test flights required more than routine maintenance to make the aircraft flightworthy again. As of March 2010, the F-35 program had used a million more man-hours than predicted. The United States Navy projected that lifecycle costs over a 65-year fleet life for all American F-35s to be $442 billion higher than U.S. Air Force projections. F-35 delays have led to shortfall of up to 100 jet fighters in the Navy/Marines team, although measures have been taken using existing assets to manage and reduce this shortfall.
The F-35C's maiden flight took place on 7 June 2010, at NAS Fort Worth JRB. A total of 11 U.S. Air Force F-35s arrived in fiscal year 2011. On 9 March 2011, all F-35s were grounded after a dual generator failure and oil leak in flight; the cause of the incident was discovered to have been the result of faulty maintenance. In 2012, Navy Commander Erik Etz of the F-35 program office commented that rigorous testing of the F-35's sensors had taken place during exercise Northern Edge 2011, and had served as a significant risk-reduction step.
On 2 August 2011, an F-35's integrated power package (IPP) failure during a standard engine test at Edwards Air Force Base led to the F-35 being immediately grounded for two weeks. On 10 August 2011, ground operations were re-instituted; preliminary inquiries indicated that a control valve did not function properly, leading to the IPP failure. On 18 August 2011, the flight ban was lifted for 18 of the 20 F-35s; two aircraft remained grounded due to a lack of monitoring systems. The IPP suffered a second software-related incident in 2013, this resulted in no disruption as the fleet was already grounded due to separate engine issues.
On 25 October 2011, the F-35A reached its designed top speed of Mach 1.6 for the first time. Further testing demonstrated Mach 1.61 and 9.9g. On 11 February 2013, an F-35A completed its final test mission for clean wing flutter, reporting to be clear of flutter at speeds up to Mach 1.6. On 15 August 2012, an F-35B completed airborne engine start tests.
During testing in 2011, all eight landing tests of the F-35C failed to catch the arresting wire; a redesigned tail hook was developed and delivered two years later in response. In October 2011, two F-35Bs conducted three weeks of initial sea trials aboard .
On 6 October 2012, the F-35A dropped its first bomb, followed three days later by an AIM-120 AMRAAM. On 28 November 2012, an F-35C performed a total of eleven weapon releases, ejecting a GBU-31 JDAM and GBU-12 Paveway from its weapons bay in the first ground weapons ejections for the F-35C. On 5 June 2013, an F-35A at the Point Mugu Sea Test Range completed the first in-flight missile launch of an AIM-120 C5 AAVI (AMRAAM Air Vehicle Instrumented). It was launched from the internal weapons bay.
On 16 November 2012, the U.S. Marines received the first F-35B at MCAS Yuma, and the VMFA(AW)-121 unit is to be redesignated from a Boeing F/A-18 Hornet unit to an F-35B squadron. A February 2013 "Time" article revealed that Marine pilots are not allowed to perform a vertical landing—the maneuver is deemed too dangerous, and it is reserved only for Lockheed test pilots. On 10 May 2013, the F-35B completed its first vertical takeoff test. On 3 August 2013, the 500th vertical landing of an F-35 took place.
On 18 January 2013, the F-35B was grounded after the failure of a fueldraulic line in the propulsion system on 16 January. The problem was traced to an "improperly crimped" fluid line manufactured by Stratoflex. The Pentagon cleared all 25 F-35B aircraft to resume flight tests on 12 February 2013. On 22 February 2013, the U.S. Department of Defense grounded the entire fleet of 51 F-35s after the discovery of a cracked turbine blade in a U.S. Air Force F-35A at Edwards Air Force Base. On 28 February 2013, the grounding was lifted after an investigation concluded that the cracks in that particular engine resulted from stressful testing, including excessive heat for a prolonged period during flight, and did not reflect a fleetwide problem. The F-35C Lightning II carrier variant Joint Strike Fighter conducted its first carrier-based night flight operations aboard an aircraft carrier off the coast of San Diego on 13 November 2014.
On 5 June 2015, the U. S. Air Education and Training Command Accident Investigation Board reported that catastrophic engine failure had led to the destruction of on an Air Force F-35A assigned to the 58th Fighter Squadron at Eglin Air Force Base, Florida, on 23 June 2014. The third-stage forward integral arm of a rotor had fractured and broke free during the takeoff roll. Pieces cut through the engine's fan case, engine bay, internal fuel tank and hydraulic and fuel lines before leaving through the aircraft's upper fuselage. Leaked fuel and hydraulic fluid ignited the fire, which destroyed the rear two-thirds of the aircraft. The destruction of the airframe resulted in the cancelation of the F-35's international debut at the 2014 Farnborough Airshow in England, the temporary grounding of the F-35 fleet and ongoing restrictions in the flight envelope.
On 19 June 2015 the RAF successfully launched two 500 lb Paveway IV precision-guided bombs, making the test the first time non-US munitions were deployed by the aircraft.
The US Marines declared the aircraft had met initial operational capability on 31 July 2015, despite shortcomings in night operations, communications, software and weapons carriage capabilities. However, J. Michael Gilmore, director of the Pentagon’s Operational Test and Evaluation Office, criticized the operational trials as not valid. In an internal memo, Gilmore concluded "the exercise was so flawed that it 'was not an operational test … in either a formal or informal sense of the term.' Furthermore, the test 'did not — and could not — demonstrate' that the version of the F-35 that was evaluated 'is ready for real-world operational deployments, given the way the event was structured.'"
Training.
In 2011, the Director of Operational Test and Evaluation warned that the USAF's plan to start unmonitored flight training "risks the occurrence of a serious mishap". The leaders of the United States Senate Committee on Armed Services called on Defense Secretary Leon Panetta to address the issue. Despite the objections, expanded trial flights began in September 2012.
The F-35A and F-35B were cleared for flight training in early 2012. A military flight release for the F-35A was issued on 28 February 2012. The aircraft were restricted to basic maneuvers with no tactical training allowed. On 24 August 2012, an F-35 flew its 200th sortie while at Eglin Air Force Base, flown by a Marine pilot. The pilot said, "The aircraft have matured dramatically since the early days. The aircraft are predictable and seem to be maintainable, which is good for the sortie production rate. Currently, the flight envelope for the F-35 is very, very restricted, but there are signs of improvement there too." The F-35s at the base no longer need to fly with a chase aircraft and are operating in a normal two-ship element.
On 21 August 2012, J. Michael Gilmore wrote that he would not approve the Operational Test and Evaluation master plan until his concerns about electronic warfare testing, budget and concurrency were addressed. On 7 September 2012, the Pentagon failed to approve a comprehensive operational testing plan for the F-35. Instead, on 10 September 2012, the USAF began an operational utility evaluation (OUE) of the F-35A entire system, including logistical support and maintenance, maintenance training, pilot training, and pilot execution. By 1 October, the OUE was reported as "proceeding smoothly", pilots started on simulators prior to flying on 26 October. The OUE was completed on 14 November with the 24th flight, the four pilots involved having completed six flights each.
During the Low Rate Initial Production (LRIP) phase of the aircraft, the U.S. had taken a tri-service approach to developing tactics and procedures for the F-35 using flight simulators prior to the type entering service. Simulated flights had tested the flight controls' effectiveness, helping to discover technical problems and refine aircraft design. Maintenance personnel have discovered that it is possible to correct deficiencies in the F-35, which is a software-defined aircraft, simply by rebooting the aircraft's software and onboard systems.
Air Force pilot training F-35A began in January 2013 at Eglin Air Force Base; the program currently has a maximum capacity of 100 military pilots and 2,100 maintainer students.
On 23 June 2014, an F-35A experienced a fire in the engine area during its takeoff at Eglin AFB. In response, the Pentagon's Joint Program Office halted training in all F-35 models the next day, and on 3 July, the F-35 fleet was formally grounded. The fleet was returned to flight on 15 July, but the engine inspection regimen caused the aircraft's debut at the Farnborough 2014 Air Show to be canceled.
In 2013, Lockheed Martin produced and delivered 36 F-35s, increasing the total number of F-35s produced to 101 (46 F-35As, 42 F-35Bs, and 13 F-35Cs). However in November 2014, the total number of F-35s produced, has increased minimally to 115.
Basing plans for future US F-35s.
On 9 December 2010, a media report stated that the "USMC will base 216 F-35Bs on the East Coast and 184 of them on the West Coast, documents showed." This report continued to state that, "Cherry Point will get 128 jets to form eight squadrons; Beaufort will have three squadrons and a pilot training center using 88 aircraft; Miramar will form six operational squadrons with 96 jets and 88 F-35s will go to Yuma for five operational squadrons with an additional test and evaluation unit."
In 2011, the USMC and USN signed an agreement that the USMC will purchase 340 F-35B and 80 F-35C fighters. The five squadrons of USMC F-35Cs would be assigned to Navy carriers while F-35Bs would be used ashore.
In February 2014 the USAF announced the first US Air Force Air National Guard unit to fly the new F-35 Lightning II will be the 158th Fighter Wing of the Vermont Air National Guard based at the Burlington Air Guard Station. The 158th currently flies the F-16 Fighting Falcon, which are nearing the end of their useful service lives. Burlington Air Guard Station is expected to receive 18 F-35As, replacing the 18 F-16 fighting Falcons currently assigned to the 158th Fighter Wing. The F-35A is expected to arrive in 2020.
On 11 March 2014, the first F-35A Lightning II assigned to Luke Air Force Base arrived at the base. A total of 16 F-35s are to be delivered to the base by the end of 2014, with 144 Lightning IIs to be stationed there arriving over the course of the next decade.
On 8 January 2015, the Royal Air Force base, RAF Lakenheath in the UK, was chosen as the first U.S. Air Force European base to station two F-35 squadrons, following an announcement by the Pentagon. A total of 48 F-35s, making up two squadrons, will add to the 48th Fighter Wing's already existing F-15C and F-15E Strike Eagle jets.
Procurement and international participation.
While the United States is the primary customer and financial backer, the United Kingdom, Italy, the Netherlands, Canada, Turkey, Australia, Norway, and Denmark have agreed to contribute US$4.375 billion towards development costs. Total development costs are estimated at more than US$40 billion. The purchase of an estimated 2,400 aircraft is expected to cost an additional US$200 billion. The initial plan was that the nine major partner nations would acquire over 3,100 F-35s through 2035. Sales to partner nations are made through the Pentagon's Foreign Military Sales program.
There are three levels of international participation. The levels generally reflect financial stake in the program, the amount of technology transfer and subcontracts open for bid by national companies, and the order in which countries can obtain production aircraft. The United Kingdom is the sole "Level 1" partner, contributing US$2.5 billion, which was about 10% of the planned development costs under the 1995 Memorandum of Understanding that brought the UK into the project. Level 2 partners are Italy, which is contributing US$1 billion; and the Netherlands, US$800 million. Level 3 partners are Turkey, US$195 million; Canada, US$160 million; Australia, US$144 million; Norway, US$122 million and Denmark, US$110 million. Israel and Singapore have joined as Security Cooperative Participants (SCP). Japan announced on 20 December 2011 its intent to purchase 42 F-35s with deliveries beginning in 2016 to replace the F-4 Phantom II; Japan seeks 38 F-35s, to be assembled domestically.
By 2012, many changes had occurred in the order book. Italy became the first country to announce a reduction of its overall fleet procurement, cutting its buy from 131 to 90 aircraft. Other nations reduced initial purchases or delayed orders while still intending to purchase the same final numbers. The United States canceled the initial purchase of 13 F-35s and postponed orders for another 179. The United Kingdom cut its initial order and delayed a decision on future orders. Australia decided to buy the Boeing F/A-18E/F Super Hornet as an interim measure. Turkey also cut its initial order of four aircraft to two, but confirmed plans to purchase 100 F-35As. Turkey will buy four F-35s to be delivered in 2015 and 2016, while the order may be increased from 100 to 120 aircraft. These changes resulted in increased procurement prices, and increased the likelihood of further cuts.
On 3 April 2012, the Auditor General of Canada Michael Ferguson published a report outlining problems with Canada's procurement of the jet, including misinformation over the final cost. According to the Auditor General, the government knowingly understated the final price of the 65 jets by $10 billion. Canada's Conservative government had stated it would not reduce its order, and anticipated a $75–80 million unit cost; the procurement was termed a "scandal" and "fiasco" by the media and faced a full review to determine any Canadian F-35 purchase. On 13 December 2012, in a scathing editorial published by CBC News, journalist Brian Stewart termed the F-35 project a "global wrecking ball" due to its run-away costs and lack of affordability for many participating nations.
In May 2013, Lockheed Martin declared that Turkey is projected to earn $12 billion from licensed production of F-35 components.
In November 2014, the United Kingdom confirmed its first order for 14 F-35Bs to be delivered in 2016.
Procurement costs.
Estimated cost of airplane in Low Rate Initial Production (LRIP) and Full Rate Production (FRP) batches:
Variants.
The F-35 is being built in three different main versions to suit various combat missions.
F-35A.
The F-35A is the conventional takeoff and landing (CTOL) variant intended for the U.S. Air Force and other air forces. It is the smallest, lightest F-35 version and is the only variant equipped with an internal cannon, the GAU-22/A. This 25 mm cannon is a development of the GAU-12 carried by the USMC's AV-8B Harrier II. It is designed for increased effectiveness against ground targets compared to the 20 mm M61 Vulcan cannon carried by other USAF fighters.
The F-35A is expected to match the F-16 in maneuverability and instantaneous high-g performance, and outperform it in stealth, payload, range on internal fuel, avionics, operational effectiveness, supportability, and survivability. It is expected to match an F-16 that is carrying the usual external fuel tank in acceleration performance.
The A variant is primarily intended to replace the USAF's F-16 Fighting Falcon. At one point it was also intended to replace the A-10 Thunderbolt II starting in 2028. The F-35A can be outfitted to receive fuel via either of the two main aerial refueling methods; this was a consideration in the Canadian procurement and a deciding factor for the Japanese purchase. On 18 December 2013, the Netherlands became the second partner country to operate the F-35A, when Maj. Laurens J.W. Vijge of the Royal Netherlands Air Force took off from Eglin Air Force Base.
On 27 January 2014, General Mike Hostage, head of Air Combat Command, stated he would fight "to the death" to not have a single plane of the USAF's planned 1,763 F-35 purchase be cut, because the allies and partners of the US got "weak in the knees" when seeing the USAF "back away" from the F-35. He said the F-15 and F-16 fleets would become tactically obsolete in the middle of the next decade regardless of improvements. Hostage also commented that the F-35 would be "irrelevant" without the F-22 fleet being viable as the F-35 was not an air superiority fighter, and that a F-35 pilot who attempted a dogfight would be making a mistake.
The F-35As for the Royal Norwegian Air Force will have drag chute installed. Norway will be the first country to adopt the drag chute pod.
F-35B.
The F-35B is the short takeoff and vertical landing (STOVL) variant of the aircraft. Similar in size to the A variant, the B sacrifices about a third of the other version's fuel volume to accommodate the vertical flight system. Vertical takeoffs and landings are riskier due to threats such as foreign object damage. Whereas the F-35A is stressed to 9 g, the F-35B's stress goal is 7 g. , the F-35B is limited to 4.5 g and 400 knots. Next software upgrade includes weapons, 5.5 g and Mach 1.2, with a final target of 7 g and Mach 1.6. The first test flight of the F-35B was conducted on 11 June 2008. Another milestone, the first successful ski-jump launch was carried out by BAE test pilot Peter Wilson on 24 June 2015.
Unlike other variants, the F-35B has no landing hook. The "STOVL/HOOK" control instead engages conversion between normal and vertical flight. Jet thrust is sent directly downwards during vertical flight; the nozzle is being redesigned to spread the output across an oval rather than circular shape in order to limit damage to asphalt and ship decks. The variant's three-bearing swivel nozzle that directs the full thrust of the engine is moved by a “fueldraulic” actuator using pressurized fuel.
The United States Marine Corps plans to purchase 340 F-35Bs, to replace current inventories of both the F/A-18 Hornet (A, B, C and D-models), and the AV-8B Harrier II, in the fighter and attack roles. The Marines plan to use the F-35B from "unimproved surfaces at austere bases" but with "special, high-temperature concrete designed to handle the heat." The USMC declared Initial Operational Capability with about 50 F-35s running interim Block 2B software on 31 July 2015. The USAF had considered replacing the A-10 with the F-35B, but will not do so due to the F-35B's inability to generate enough sorties.
On 6 January 2011, Gates said that the 2012 budget would call for a two-year pause in F-35B production during which the aircraft faced redesign, or cancellation if unsuccessful. In 2011, Lockheed Martin executive vice president Tom Burbage and former Pentagon director of operational testing Tom Christie stated that most program delays were due to the F-35B, which forced massive redesigns of other versions. Lockheed Martin Vice President Steve O’Bryan has said that most F-35B landings will be conventional to reduce stress on vertical lift components. These conventional mode takeoffs and landings cause "an unacceptable wear rate" to the aircraft's poorly designed tires. USMC Lt. Gen. Robert Schmidle has said that the vertical lift components would only be used "a small percentage of the time" to transfer the aircraft from carriers to land bases. On 3 October 2011, the F-35B began its initial sea-trials by performing a vertical landing on the deck of the amphibious assault ship , to continue in 2015. Probation status was reportedly ended by Defense Secretary Leon Panetta in January 2012 due to progress made. A heat-resistant anti-skid material called Thermion is being tested on Wasp, also useful against the V-22 exhaust.
The Royal Air Force and Royal Navy plan for the F-35B is to replace the Harrier GR9s, which were retired in 2010. One of the Royal Navy requirements for the F-35B design was a Shipborne Rolling and Vertical Landing (SRVL) mode to increase maximum landing weight to bring back unused ordnance by using wing lift during landing. In July 2013, Chief of the Air Staff, Air Chief Marshal Sir Stephen Dalton announced that 617 Squadron would be the first operational Royal Air Force squadron to receive the F-35. The second operational squadron will be the Fleet Air Arm's 809 NAS. As of June 2013, the Royal Air Force has received three aircraft of the 48 on order, the three aircraft were based at Eglin Air Force base. The aircraft are projected to be operational in 2018. In June 2015, the F-35B undertook its first launches from a ski-jump, when one of the UK's aircraft took off using a ramp constructed at NAS Patuxent River. Both the Royal Navy and the Marina Militare will operate the F-35B from ships fitted with ski-jumps. In 2011, the Marina Militare was preparing Grottaglie Air Station for F-35B operations; they are to receive 22 aircraft between 2014 and 2021, with the aircraft carrier "Cavour" set to be modified to operate them by 2016.
Commandant of the U.S. Marine Corps, General James Amos has said that, in spite of increasing costs and schedule delays, there is no plan B to the F-35B. The F-35B is larger than the aircraft it replaces, which required to be designed without well deck capabilities. In 2011, the USMC and USN signed an agreement that the USMC will purchase 340 F-35B and 80 F-35C fighters while the USN will purchase 260 F-35C fighters. The five squadrons of USMC F-35Cs will be assigned to Navy carriers while F-35Bs will be used on amphibious ships and ashore.
Although the Australian ships were not originally planned to operate fixed-wing aircraft, in May 2014, the Minister for Defence David Johnston stated in media interviews that the government was considering acquiring F-35B fighters for "Canberra"s, and Prime Minister Tony Abbott instructed 2015 Defence White Paper planners to consider the option of embarking F-35B squadrons aboard the two ships. Supporters of the idea stated that providing fixed-wing support to amphibious operations would maximize aircraft capability, and the presence of a ski-jump ramp, inherited from the original design, meant that the vessels were better suited to STOVL operations than equivalent ships with flat flight decks. Opponents to the idea countered that embarking enough F-35Bs to be effective required abandoning the ships' amphibious capability and would make the pseudo-carriers more valuable targets, modifications would be required to make the flight deck capable of handling vertical-landing thrust and to increase fuel and ordnance capacity for sustained operations, and that the F-35B project itself has been the most expensive and most problematic of the Joint Strike Fighter variants. In July 2015 Australia ended consideration of buying the F-35B for its two largest assault ships, as the ship modifications were projected to cost more than AUS$5 billion (US$4.4 billion). The plan was opposed by the Royal Australian Air Force, as an F-35B order could have diminished the number of F-35As purchased.
The U.S Marine Corps plans to disperse its F-35Bs among forward deployed bases to enhance survivability while remaining close to a battlespace, similar to RAF Harrier deployment late in the Cold War which relied on the use of off-base locations that offered short runways, shelter, and concealment. Known as distributed STOVL operations (DSO), Marine F-35Bs would sustain operations from temporary bases in allied territory within the range of hostile ballistic and cruise missiles, but be moved between temporary locations inside the enemy's 24-48 hour targeting cycle. This strategy accounts for the F-35B's short range, the shortest of the three variants, with mobile forward arming and refueling points (M-Farps) accommodating KC-130 and MV-22 Osprey aircraft to rearm and refuel the jets, as well as littoral areas for sea links of mobile distribution sites on land. M-Farps could be based on small airfields, multi-lane roads, or damaged main bases, while F-35Bs would return to U.S. Navy ships, rear-area U.S. Air Force bases, or friendly carriers for scheduled maintenance; metal planking would be needed to protect unprepared roads from the F-35B's engine exhaust, which would be moved between sites by helicopters, and the Marines are studying lighter and more heat-resistant products.
F-35C.
Compared to the F-35A, the F-35C carrier variant features larger wings with foldable wingtip sections, larger wing and tail control surfaces for improved low-speed control, stronger landing gear for the stresses of carrier arrested landings, a twin-wheel nose gear, and a stronger tailhook for use with carrier arrestor cables. The larger wing area allows for decreased landing speed while increasing both range and payload.
The United States Navy intends to buy 480 F-35Cs to replace the F/A-18A, B, C, and D Hornets and complement the Super Hornet fleet. On 27 June 2007, the F-35C completed its Air System Critical Design Review (CDR), allowing the production of the first two functional prototypes. The C variant was expected to be available beginning in 2014. The first F-35C was rolled out on 29 July 2009. The United States Marine Corps will also purchase 80 F-35Cs, enough for five squadrons, for use with navy carrier air wings in a joint service agreement signed on 14 March 2011. A recent 2014 document stated that the USMC will also have 4 squadrons of F-35Cs with 10 aircraft per squadron for the Marine Corps' contribution to U.S. Navy carrier air wings.
On 6 November 2010, the first F-35C arrived at Naval Air Station Patuxent River. The replacement engines for at-sea repair are too large to be transported by current underway replenishment systems. In 2011, the F-35Cs were grounded for six days after a software bug was found that could have prevented the control surfaces from being used during flight. On 27 July 2011, the F-35C test aircraft CF-3 completed its first steam catapult launch during a test flight at Naval Air Engineering Station Lakehurst; the TC-13 Mod 2 test steam catapult, representative of current fleet technology, was used. In addition to catapult launches at varying power levels, a three-week test plan included dual-aircraft jet blast deflector testing and catapult launches using a degraded catapult configuration to measure the effects of steam ingestion on the aircraft.
On 13 August 2011, the F-35 successfully completed jet blast deflector (JBD) testing at Lakehurst. F-35C test aircraft CF-1 along with an F/A-18E tested a combined JBD cooling panel configuration. The tests measured temperature, pressure, sound level, velocity, and other environmental data; the JBD model will enable the operation of all carrier aircraft, including the F-35C. Further carrier suitability testing continued in preparation for initial ship trials in 2013. On 18 November 2011, the U.S. Navy used its new Electromagnetic Aircraft Launch System (EMALS) to launch an F-35C into the air for the first time.
On 22 June 2013, Strike Fighter Squadron VFA-101 received the Navy's first F-35C at Eglin Air Force Base, Florida.
The USN is dealing with the following issues in adapting their carriers to operate the F-35C.
In February 2014, Lockheed said the F-35C was on schedule for sea trials after the tailhook was redesigned. The new tailhook has a different shape to better catch arresting wires. Testing on land achieved 36 successful landings. Sea trials were scheduled for October 2014.
On 3 November 2014, an F-35C of VX-23, one of the Navy's flight test units, made its first landing on an aircraft carrier when it recovered aboard ; this started a 2 week deployment of a pair of aircraft for the initial at sea Development Testing I or DTI, the first of three at sea tests planned for the F-35C. The initial deployment was completed on November 14.
The U.S. Navy may use the F-35C as part of its UCLASS effort to operate a carrier-based unmanned aerial vehicle. Though it has been suggested that the UCLASS could carry air-to-air weapons, an unmanned aircraft lacks situational awareness and is more vulnerable to electronic countermeasures than manned aircraft, and autonomy for deploying lethal weapons is not under development. With the F-35C as the center of a network of naval systems, it could feed information to the UCLASS and order it to fire on a certain target. Large numbers of F-35Cs operating in contested environments can generate a clear picture of the battlespace, and share it with unmanned assets that can be directed to attack.
Other versions.
F-35I.
The F-35I is an F-35A with Israeli modifications. A senior Israel Air Force official stated "the aircraft will be designated F-35I, as there will be unique Israeli features installed in them". Despite an initial refusal to allow such modifications, the U.S. has agreed to let Israel integrate its own electronic warfare systems, such as sensors and countermeasures, into the aircraft. The main computer will have a plug-and-play feature to allow add-on Israeli electronics to be used; proposed systems include an external jamming pod, and new Israeli air-to-air missiles and guided bombs in the internal weapon bays. Israeli pilots are scheduled to start F-35 training in December 2016 at Eglin AFB Florida with the first squadron activated about a year later.
Israel Aerospace Industries (IAI) has considered playing a role in the development of a proposed two-seat F-35; an IAI executive stated: "There is a known demand for two seats not only from Israel but from other air forces." IAI plans to produce conformal fuel tanks. A senior IAF official stated that elements of the F-35's stealth may be overcome in 5 to 10 years, while the aircraft will be in service for 30 to 40 years, which is why Israel insisted on installing their own electronic warfare systems: "The basic F-35 design is OK. We can make do with adding integrated software." Israel is interested in purchasing up to 75 F-35s.
CF-35.
The Canadian CF-35 is a proposed variant that would differ from the F-35A through the addition of a drogue parachute and may include an F-35B/C-style refueling probe. In 2012, it was revealed that the CF-35 would employ the same boom refueling system as the F-35A. One alternative proposal would have been the adoption of the F-35C for its probe refueling and lower landing speed; the Parliamentary Budget Officer's report cited the F-35C's limited performance and payload as being too high a price to pay. Following the 2015 Federal Election, in which the Liberal Party, whose campaign had included a pledge to cancel the F-35 procurement, won a majority in the House of Commons, and stated it would run a new competition for an aircraft to replace the existing CF-18 Hornet.
F-35D.
Early-stage design study for a possible upgrade of the F-35A to be fielded by the 2035 target date of the Air Force Future Operating Concept.
Accidents.
On 23 June 2014, an F-35A preparing to take off on a training flight at Eglin Air Force Base experienced a fire in the engine area. The pilot escaped unharmed. The accident caused all training to be halted on 25 June, and all flights halted on 3 July. During the incident investigation, engine parts from the burned aircraft were discovered on the runway, indicating it was a substantial engine failure. The fleet was returned to flight on 15 July with restrictions in the flight envelope. Preliminary findings suggests that excessive rubbing of the engine fan blades created increased stress and wear and eventually resulted in catastrophic failure of the fan.
In Early June 2015, the USAF Air Education and Training Command (AETC) issued its official report on the incident. It found that the incident was the result of a failure of the third stage rotor of the engine's fan module. The report explained that "pieces of the failed rotor arm cut through the engine's fan case, the engine bay, an internal fuel tank, and hydraulic and fuel lines before exiting through the aircraft's upper fuselage". Pratt and Whitney, the engine manufacturers, developed two remedies to the problem. The first is an extended "rub-in" to increase the gap between the second stator and the third rotor integral arm seal. The second is the redesign to pre-trench the stator. Both should be complete by early 2016. Cost of the problem was estimated at USD 50 million. All aircraft resumed operations within 25 days of the incident.

</doc>
<doc id="11815" url="https://en.wikipedia.org/wiki?curid=11815" title="Food additive">
Food additive

Food additives are substances added to food to preserve flavor or enhance its taste and appearance.
Some additives have been used for centuries; for example, preserving food by pickling (with vinegar), salting, as with bacon, preserving sweets or using sulfur dioxide as with wines. With the advent of processed foods in the second half of the twentieth century, many more additives have been introduced, of both natural and artificial origin.
Numbering.
To regulate these additives, and inform consumers, each additive is assigned a unique number, termed as "E numbers", which is used in Europe for all approved additives. This numbering scheme has now been adopted and extended by the "Codex Alimentarius" Commission to internationally identify all additives, regardless of whether they are approved for use.
E numbers are all prefixed by "E", but countries outside Europe use only the number, whether the additive is approved in Europe or not.
For example, acetic acid is written as E260 on products sold in Europe, but is simply known as additive 260 in some countries. Additive 103, alkanet, is not approved for use in Europe so does not have an E number, although it is approved for use in Australia and New Zealand. Since 1987, Australia has had an approved system of labelling for additives in packaged foods. Each food additive has to be named or numbered. The numbers are the same as in Europe, but without the prefix "E".
The United States Food and Drug Administration (FDA) lists these items as "generally recognized as safe" (GRAS); they are listed under both their Chemical Abstracts Service number and FDA regulation under the United States Code of Federal Regulations.
Categories.
Food additives can be divided into several groups, although there is some overlap between them.
Safety.
With the increasing use of processed foods since the 19th century, there has been a great increase in the use of food additives of varying levels of safety. This has led to legislation in many countries regulating their use. For example, boric acid was widely used as a food preservative from the 1870s to the 1920s, but was banned after World War I due to its toxicity, as demonstrated in animal and human studies. During World War II, the urgent need for cheap, available food preservatives led to it being used again, but it was finally banned in the 1950s. Such cases led to a general mistrust of food additives, and an application of the precautionary principle led to the conclusion that only additives that are known to be safe should be used in foods. In the United States, this led to the adoption of the Delaney clause, an amendment to the Federal Food, Drug, and Cosmetic Act of 1938, stating that no carcinogenic substances may be used as food additives. However, after the banning of cyclamates in the United States and Britain in 1969, saccharin, the only remaining legal artificial sweetener at the time, was found to cause cancer in rats. Widespread public outcry in the United States, partly communicated to Congress by postage-paid postcards supplied in the packaging of sweetened soft drinks, led to the retention of saccharin, despite its violation of the Delaney clause. However, in 2000, saccharin was later found to only be carcinogenic to rats due to their unique urine chemistry. 
In September 2007, research financed by Britain's Food Standards Agency and published online by the British medical journal "The Lancet", presented evidence that a mix of additives commonly found in children’s foods increases the mean level of hyperactivity.
The team of researchers concluded that "the finding lends strong support for the case that food additives exacerbate hyperactive behaviors (inattention, impulsivity and overactivity) at least into middle childhood." That study examined the effect of artificial colors and a sodium benzoate preservative, and found both to be problematic for some children. Further studies are needed to find out whether there are other additives that could have a similar effect, and it is unclear whether some disturbances can also occur in mood and concentration in some adults. In the February 2008 issue of its publication, "AAP Grand Rounds", the American Academy of Pediatrics concluded that a low-additive diet is a valid intervention for children with ADHD:
In 2007, Food Standards Australia New Zealand published an official shoppers' guidance with which the concerns of food additives and their labeling are mediated.
There has been significant controversy associated with the risks and benefits of food additives. Some artificial food additives have been linked with cancer, digestive problems, neurological conditions, ADHD, heart disease or obesity. Natural additives may be similarly harmful or be the cause of allergic reactions in certain individuals. For example, safrole was used to flavor root beer until it was shown to be carcinogenic. Due to the application of the Delaney clause, it may not be added to foods, even though it occurs naturally in sassafras and sweet basil.
Blue 1, Blue 2, Red 3, and Yellow 6 are among the food colorings that have been linked to various health risks in animal models. Blue 1 is used to color candy, soft drinks, and pastries and there has been some evidence that it may cause cancer in mice, but studies have not been replicated. Blue 2 can be found in pet food, soft drinks, and pastries, and has shown to cause brain tumors in mice. Red 3, mainly used in cherries for cocktails has been correlated with thyroid tumors in rats. Yellow 6, used in sausages, gelatin, and candy can lead to the attribution of gland and kidney tumors, again in animal models and contains carcinogens, but in minimal amounts. It should be noted that many animal models are poor substitutes for studying carcinogenic effects in humans, because the physiology of rabbits, mice and non-human primates can be very different from humans in the relevant biochemical pathways. There has been no scientific consensus on the carcinogenic properties of these agents in humans and studies are still on-going.
Though food additives may be linked with these diseases and health risks, they also preserve nutrient value by providing vitamins, minerals, and other nutrients to foods such as flour, cereal, margarine and milk which normally would not retain such high levels. Preservatives also reduce spoilage from sources such as air, bacteria, fungi, and yeast. 
In the EU it can take 10 years or more to obtain approval for a new food additive. This includes five years of safety testing, followed by two years for evaluation by the European Food Safety Authority and another three years before the additive receives an EU-wide approval for use in every country in the European Union. Apart from testing and analyzing food products during the whole production process to ensure safety and compliance with regulatory standards, Trading Standards officers (in the UK) protect the public from any illegal use or potentially dangerous mis-use of food additives by performing random testing of food products.
Standardization of its derived products.
ISO has published a series of standards regarding the topic and these standards are covered by ICS 67.220.
Science.
Many food additives absorb radiation in the ultraviolet and / or visible region of the spectrum. This absorbance can be used to determine the concentration of an additive in a sample using external calibration. However, additives may occur together and the absorbance by one could interfere with the absorbance of another. A prior separation stage is necessary and the additives are first separated by high-pressure liquid chromatography (HPLC) and then determined on-line using a UV and/or visible detector.

</doc>
<doc id="11820" url="https://en.wikipedia.org/wiki?curid=11820" title="Fridtjof Nansen">
Fridtjof Nansen

Fridtjof Nansen ( ; 10 October 1861 – 13 May 1930) was a Norwegian explorer, scientist, diplomat, humanitarian and Nobel Peace Prize laureate. In his youth a champion skier and ice skater, he led the team that made the first crossing of the Greenland interior in 1888, cross-country skiing on the island, and won international fame after reaching a record northern latitude of 86°14′ during his North Pole expedition of 1893–96. Although he retired from exploration after his return to Norway, his techniques of polar travel and his innovations in equipment and clothing influenced a generation of subsequent Arctic and Antarctic expeditions.
Nansen studied zoology at the Royal Frederick University in Christiania (renamed Oslo in 1925), and later worked as a curator at the Bergen Museum where his research on the central nervous system of lower marine creatures earned him a doctorate and helped establish modern theories of neurology. After 1896 his main scientific interest switched to oceanography; in the course of his research he made many scientific cruises, mainly in the North Atlantic, and contributed to the development of modern oceanographic equipment. As one of his country's leading citizens, in 1905 Nansen spoke out for the ending of Norway's union with Sweden, and was instrumental in persuading Prince Carl of Denmark to accept the throne of the newly independent Norway. Between 1906 and 1908 he served as the Norwegian representative in London, where he helped negotiate the Integrity Treaty that guaranteed Norway's independent status.
In the final decade of his life, Nansen devoted himself primarily to the League of Nations, following his appointment in 1921 as the League's High Commissioner for Refugees. In 1922 he was awarded the Nobel Peace Prize for his work on behalf of the displaced victims of the First World War and related conflicts. Among the initiatives he introduced was the "Nansen passport" for stateless persons, a certificate recognised by more than 50 countries. He worked on behalf of refugees until his sudden death in 1930, after which the League established the Nansen International Office for Refugees to ensure that his work continued. This office received the Nobel Peace Prize for 1938. Nansen was honoured by many nations, and his name is commemorated in numerous geographical features, particularly in the polar regions.
Family background and childhood.
The Nansen family originated in Denmark. Hans Nansen (1598–1667), a trader, was an early explorer of the White Sea region of the Arctic Ocean. In later life he settled in Copenhagen, becoming the city's "borgmester" in 1654. Later generations of the family lived in Copenhagen until the mid-18th century, when Ancher Antoni Nansen moved to Norway (then ruled by Denmark). His son, Hans Leierdahl Nansen (1764–1821), was a magistrate first in the Trondheim district, later in Jæren. After Norway's separation from Denmark in 1814, he entered national political life as the representative for Stavanger in the first Storting, and became a strong advocate of union with Sweden. After suffering a paralytic stroke in 1821 Hans Leierdahl Nansen died, leaving a four-year-old son, Baldur Fridtjof Nansen, the explorer's father.
Baldur was a lawyer without ambitions for public life, who became Reporter to the Supreme Court of Norway. He married twice, the second time to Adelaide Johanne Thekla Isidore Bølling Wedel-Jarlsberg from Bærum, a niece of Herman Wedel-Jarlsberg who had helped frame the Norwegian constitution of 1814 and was later the Swedish king's Norwegian Viceroy. Baldur and Adelaide settled at Store Frøen, an estate at Aker, a few kilometres north of Norway's capital city, Christiania (since renamed Oslo). The couple had three children; the first died in infancy, the second, born 10 October 1861, was Fridtjof Nansen.
Store Frøen's rural surroundings shaped the nature of Nansen's childhood. In the short summers the main activities were swimming and fishing, while in the autumn the chief pastime was hunting for game in the forests. The long winter months were devoted mainly to skiing, which Nansen began to practice at the age of two, on improvised skis. At the age of 10 he defied his parents and attempted the ski jump at the nearby Huseby installation. This exploit had near-disastrous consequences, as on landing the skis dug deep into the snow, pitching the boy forward: "I, head first, described a fine arc in the air ... hen I came down again I bored into the snow up to my waist. The boys thought I had broken my neck, but as soon as they saw there was life in me ... a shout of mocking laughter went up." Nansen's enthusiasm for skiing was undiminished, though as he records, his efforts were overshadowed by those of the skiers from the mountainous region of Telemark, where a new style of skiing was being developed. "I saw this was the only way", wrote Nansen later.
At school, Nansen worked adequately without showing any particular aptitude. Studies took second place to sports, or to expeditions into the forests where he would live "like Robinson Crusoe" for weeks at a time. Through such experiences Nansen developed a marked degree of self-reliance. He became an accomplished skier and a highly proficient skater. Life was disrupted when, in the summer of 1877, Adelaide Nansen died suddenly. Distressed, Baldur Nansen sold the Store Frøen property and moved with his two sons to Christiania. Nansen's sporting prowess continued to develop; at 18 he broke the world one-mile (1.6 km) skating record, and in the following year won the national cross-country skiing championship, a feat he would repeat on 11 subsequent occasions.
Student and adventurer.
In 1880 Nansen passed his university entrance examination, the "examen artium". He decided to study zoology, claiming later that he chose the subject because he thought it offered the chance of a life in the open air. He began his studies at the Royal Frederick University in Christiania (renamed Oslo in 1925) early in 1881.
Early in 1882 Nansen took "...the first fatal step that led me astray from the quiet life of science." Professor Robert Collett of the university's zoology department proposed that Nansen take a sea voyage, to study Arctic zoology at first hand. Nansen was enthusiastic, and made arrangements through a recent acquaintance, Captain Axel Krefting, commander of the sealer "Viking". The voyage began on 11 March 1882 and extended over the following five months. In the weeks before sealing started, Nansen was able to concentrate on scientific studies. From water samples he showed that, contrary to previous assumption, sea ice forms on the surface of the water rather than below. His readings also demonstrated that the Gulf Stream flows beneath a cold layer of surface water. Through the spring and early summer "Viking" roamed between Greenland and Spitsbergen in search of seal herds. Nansen became an expert marksman, and on one day proudly recorded that his team had shot 200 seal. In July, "Viking" became trapped in the ice close to an unexplored section of the Greenland coast; Nansen longed to go ashore, but this was impossible. However, he began to develop the idea that the Greenland icecap might be explored, or even crossed. On 17 July the ship broke free from the ice, and early in August was back in Norwegian waters.
Nansen did not resume formal studies at the university. Instead, on Collett's recommendation, he accepted a post as curator in the zoological department of the Bergen Museum. He was to spend the next six years of his life there—apart from a six-month sabbatical tour of Europe—working and studying with leading figures such as Gerhard Armauer Hansen, the discoverer of the leprosy bacillus, and Daniel Cornelius Danielssen, the museum's director who had turned it from a backwater collection into a centre of scientific research and education. Nansen's chosen area of study was the then relatively unexplored field of neuroanatomy, specifically the central nervous system of lower marine creatures. In 1886 he stayed in Naples, at the Stazione Zoologica Anton Dohrn. Before leaving for his sabbatical in February 1886 he published a paper summarising his research to date, in which he stated that "anastomoses or unions between the different ganglion cells" could not be demonstrated with certainty. This unorthodox view, confirmed by the simultaneous researches of the embryologist Wilhelm His and the psychiatrist August Forel. Nansen is considered the first Norwegian defender of the neuron theory, originally proposed by Santiago Ramon y Cajal. His subsequent paper, "The Structure and Combination of Histological Elements of the Central Nervous System", published in 1887, became his doctoral thesis.
Crossing of Greenland.
Planning.
The idea of an expedition across the Greenland icecap grew in Nansen's mind throughout his Bergen years. In 1887, after the submission of his doctoral thesis, he finally began organising this project. Before then, the two most significant penetrations of the Greenland interior had been those of Adolf Erik Nordenskiöld in 1883, and Robert Peary in 1886. Both had set out from Disko Bay on the western coast, and had travelled about eastward before turning back. By contrast, Nansen proposed to travel from east to west, ending rather than beginning his trek at Disko Bay. A party setting out from the inhabited west coast would, he reasoned, have to make a return trip, as no ship could be certain of reaching the dangerous east coast and picking them up. By starting from the east—assuming that a landing could be made there—Nansen's would be a one-way journey towards a populated area. The party would have no line of retreat to a safe base; the only way to go would be forward, a situation that fitted Nansen's philosophy completely.
Nansen rejected the complex organisation and heavy manpower of other Arctic ventures, and instead planned his expedition for a small party of six. Supplies would be manhauled on specially designed lightweight sledges. Much of the equipment, including sleeping bags, clothing and cooking stoves, also needed to be designed from scratch. These plans received a generally poor reception in the press; one critic had no doubt that "if h scheme be attempted in its present form ... the chances are ten to one that he will ... uselessly throw his own and perhaps others' lives away". The Norwegian parliament refused to provide financial support, believing that such a potentially risky undertaking should not be encouraged. The project was eventually launched with a donation from a Danish businessman, Augustin Gamél; the rest came mainly from small contributions from Nansen's countrymen, through a fundraising effort organised by students at the university.
Despite the adverse publicity, Nansen received numerous applications from would-be adventurers. He wanted expert skiers, and attempted to recruit from the skiers of Telemark, but his approaches were rebuffed. Nordenskiöld had advised Nansen that Sami people, from Finland in the far north of Norway, were expert snow travellers, so Nansen recruited a pair, Samuel Balto and Ole Nielsen Ravna. The remaining places went to Otto Sverdrup, a former sea-captain who had more recently worked as a forester; Oluf Christian Dietrichson, an army officer, and Kristian Kristiansen, an acquaintance of Sverdrup's. All had experience of outdoor life in extreme conditions, and were experienced skiers. Just before the party's departure, Nansen attended a formal examination at the university, which had agreed to receive his doctoral thesis. In accordance with custom he was required to defend his work before appointed examiners acting as "devil's advocates". He left before knowing the outcome of this process.
Expedition.
On 3 June 1888 Nansen's party was picked up from the north-western Icelandic port of Ísafjörður by the sealer "Jason". A week later the Greenland coast was sighted, but progress was hindered by thick pack ice. On 17 July, with the coast still away, Nansen decided to launch the small boats; they were within sight of the Sermilik Fjord, which Nansen believed would offer a route up on to the icecap.
The expedition left "Jason" "in good spirits and with the highest hopes of a fortunate result", according to "Jason's" captain. There followed days of extreme frustration for the party as, prevented by weather and sea conditions from reaching the shore, they drifted southwards with the ice. Most of this time was spent camping on the ice itself—it was too dangerous to launch the boats. By 29 July they were south of the point where they had left the ship. On that day they finally reached land, but were too far south to begin the crossing. After a brief rest, Nansen ordered the team back into the boats and to begin rowing north.
During the next 12 days the party battled northward along the coast through the ice floes. On the first day they encountered a large Eskimo encampment near Cape Bille, and there were further occasional contacts with the nomadic native population as the journey continued. On 11 August, when they had covered about and had reached Umivik Fjord, Nansen decided that although they were still far south of his intended starting place, they needed to begin the crossing before the season became too advanced for travel. After landing at Umivik, they spent the next four days preparing for their journey, and on the evening of 15 August they set out. They were heading north-west, towards Christianhaab (now Qasigiannguit) on the west Greenland shores of Disko Bay, away.
Over the next few days the party struggled to ascend the inland ice over a treacherous surface with many hidden crevasses. The weather was generally bad; on one occasion all progress was halted for three days by violent storms and continuous rain. On 26 August Nansen concluded that there was now no chance of reaching Christianhaab by mid-September, when the last ship was due to leave. He therefore ordered a change of course, almost due west towards Godthaab (now Nuuk), a shorter journey by at least . The rest of the party, according to Nansen, "hailed the change of plan with acclamation". They continued climbing, until on 11 September they had reached a height of above sea level, the summit of the icecap with temperatures dropping to at night. From then on the downward slope made travelling easier, although the terrain was difficult and the weather remained hostile. Progress was slow because of fresh snowfalls which made dragging the sledges as hard as pulling them through sand. By 26 September they had battled their way down to the edge of a fjord that ran westward towards Godthaab. From their tent, some local willows and parts of the sledges Sverdrup constructed a makeshift boat, and on 29 September Nansen and Sverdrup began the last stage of the journey, rowing down the fjord. Four days later, on 3 October 1888, they reached Godthaab, where they were greeted by the town's Danish representative. His first words were to inform Nansen that he had been awarded his doctorate, a matter that "could not have been more remote from my thoughts at that moment". The crossing had been accomplished in 49 days, making 78 days in total since they had left the "Jason"; throughout the journey the team had maintained careful meteorological, geographical and other records relating to the previously unexplored interior. The rest of the team arrived in Godthaab on 12 October.
Nansen soon learned that no ship was likely to call at Godthaab until the following spring, though they were able to send letters back to Norway via a boat leaving Ivigtut at the end of October. He and his party therefore spent the next seven months in Greenland, hunting, fishing and studying the life of the local inhabitants. On 15 April 1889 the Danish ship "Hvidbjørnen" finally entered the harbour, and Nansen and his comrades prepared to depart. "It was not without sorrow that we left this place and these people, among whom we had enjoyed ourselves so well", Nansen recorded.
Interlude and marriage.
"Hvidbjørnen" reached Copenhagen on 21 May 1889. News of the crossing had preceded its arrival, and Nansen and his companions were feted as heroes. This welcome, however, was dwarfed by the reception in Christiania a week later, when crowds of between thirty and forty thousand—a third of the city's population—thronged the streets as the party made its way to the first of a series of receptions. The interest and enthusiasm generated by the expedition's achievement led directly to the formation that year of the Norwegian Geographical Society.
Nansen accepted the position of curator of the Royal Frederick University's zoology collection, a post which carried a salary but involved no duties; the university was satisfied by the association with the explorer's name. Nansen's main task in the following weeks was writing his account of the expedition, but he found time late in June to visit London, where he met the Prince of Wales (the future King Edward VII), and addressed a meeting of the Royal Geographical Society (RGS).
The RGS president, Sir Mountstuart Elphinstone Grant Duff, said that Nansen has claimed "the foremost place amongst northern travellers", and later awarded him the Society's prestigious Founder's Medal. This was one of many honours Nansen received from institutions all over Europe. He was invited by a group of Australians to lead an expedition to Antarctica, but declined, believing that Norway's interests would be better served by a North Pole conquest.
On 11 August 1889 Nansen announced his engagement to Eva Sars, the daughter of Michael Sars, a zoology professor who had died when Eva was 11 years old. The couple had met some years previously, at the skiing resort of Frognerseteren, where Nansen recalled seeing "two feet sticking out of the snow". Eva was three years older than Nansen, and despite the evidence of this first meeting, was an accomplished skier. She was also a celebrated classical singer who had been coached in Berlin by Désirée Artôt, one-time paramour of Tchaikovsky. The engagement surprised many, since Nansen had previously expressed himself forcefully against the institution of marriage; Otto Sverdrup assumed he had read the message wrongly. The wedding took place on 6 September 1889, less than a month after the engagement.
"Fram" expedition.
Theories and plans.
Nansen first began to consider the possibility of reaching the North Pole by using the natural drift of the polar ice when, in 1884, he read the theories of Henrik Mohn, the distinguished Norwegian meteorologist. Artifacts found on the Greenland coast had been identified as coming from the lost US Arctic exploration vessel "Jeannette", which had been crushed and sunk in June 1881 on the opposite side of the Arctic Ocean, off the Siberian coast. Mohn surmised that the location of the artefacts indicated the existence of an ocean current, flowing from east to west all the way across the polar sea, possibly over the pole itself. A strong enough ship might therefore enter the frozen Siberian sea, and drift to the Greenland coast via the pole.
This idea remained with Nansen during following years. After his triumphant return from Greenland he began to develop a detailed plan for a polar venture, which he made public in February 1890 at a meeting of the recently formed Norwegian Geographical Society. Previous expeditions, he argued, had approached the North Pole from the west, and had failed because they were working "against" the prevailing east-west current. The secret of success was to work "with" this current. A workable plan, Nansen said, would require a small, strong and manoeuvrable ship capable of carrying fuel and provisions for twelve men for five years. The ship would sail to the approximate location of "Jeannette's" sinking, and would enter the ice. It would then drift west with the current towards the pole and beyond it, eventually reaching the sea between Greenland and Spitsbergen.
Many experienced polar hands were dismissive of Nansen's plans. The retired American explorer Adolphus Greely called the idea "an illogical scheme of self-destruction". Sir Allen Young, a veteran of the searches for Sir John Franklin's lost expedition, and Sir Joseph Hooker, who had sailed south with James Clark Ross in 1839–43, were equally dismissive. However, after an impassioned speech Nansen secured the support of the Norwegian parliament, which voted him a grant. The balance of funding was met by private donations and from a national appeal.
Preparations.
Nansen chose Colin Archer, Norway's leading shipbuilder and naval architect, to design and build a suitable ship for the planned expedition. Using the toughest oak timbers available, and an intricate system of crossbeams and braces throughout its length, Archer built a vessel of extraordinary strength. Its rounded hull was designed so that it would slip upwards out of the grip of packing ice. Speed and sailing performance were secondary to the requirement of making the ship a safe and warm shelter during a predicted lengthy confinement. With an overall length of and a beam of , the length-to-beam ratio of just over three gave the ship its stubby appearance, justified by Archer thus: "A ship that is built with exclusive regard to its suitability for ansen' object must differ essentially from any known vessel." The ship was launched by Eva Nansen at Archer's yard at Larvik, on 6 October 1892, and was named "Fram", in English "Forward".
From thousands of applicants, Nansen selected a party of twelve. Otto Sverdrup from the Greenland expedition was appointed captain of "Fram" and second-in-command of the expedition. Competition for places on the voyage was such that reserve Army lieutenant and dog-driving expert Hjalmar Johansen signed on as ship's stoker, the only position available.
Into the ice.
"Fram" left Christiania on 24 June 1893, cheered on by thousands of well-wishers. After a slow journey around the coast, the final port of call was Vardø, in the far north-east of Norway. "Fram" left Vardø on 21 July, following the North-East Passage route pioneered by Nordenskiöld in 1878–79, along the northern coast of Siberia. Progress was impeded by fog and ice conditions in the mainly uncharted seas. The crew also experienced the dead water phenomenon, where a ship's forward progress is impeded by friction caused by a layer of fresh water lying on top of heavier salt water. Nevertheless, Cape Chelyuskin, the most northerly point of the Eurasian continental mass, was passed on 10 September. Ten days later, as "Fram" approached the area in which "Jeannette" had been crushed, heavy pack ice was sighted at around latitude 78°N. Nansen followed the line of the pack northwards to a position recorded as 78°49′N, 132°53′E, before ordering engines stopped and the rudder raised. From this point "Fram's" drift began.
The first weeks in the ice were frustrating, as the drift moved unpredictably, sometimes north, sometimes south; by 19 November "Fram's" latitude was south of that at which she had entered the ice. Only after the turn of the year, in January 1894, did the northerly direction become generally settled; the 80° mark was finally passed on 22 March. Nansen calculated that, at this rate, it might take the ship five years to reach the pole. As the ship's northerly progress continued at a rate rarely above a mile (1.6 km) a day, Nansen began privately to consider a new plan—a dog sledge journey towards the pole. With this in mind he began to practice dog-driving, making many experimental journeys over the ice. In November Nansen announced his plan: when the ship passed latitude 83° he and Hjalmar Johansen would leave the ship with the dogs and make for the pole while "Fram", under Sverdrup, continued its drift until it emerged from the ice in the North Atlantic. After reaching the pole, Nansen and Johansen would make for the nearest known land, the recently discovered and sketchily mapped Franz Josef Land. They would then cross to Spitzbergen where they would find a ship to take them home.
The crew spent the rest of the 1894–95 winter preparing clothing and equipment for the forthcoming sledge journey. Kayaks were built, to be carried on the sledges until needed for the crossing of open water. Preparations were interrupted early in January when violent tremors shook the ship. The crew disembarked, fearing that the vessel would be crushed, but "Fram" proved herself equal to the danger. On 8 January 1895 the ship's position was 83°34′N, above Greely's previous Farthest North record of 83°24.
Dash for the pole.
On 14 March 1895, after two false starts and with the ship's position at 84°4′N, Nansen and Johansen began their journey. Nansen had allowed 50 days to cover the to the pole, an average daily journey of seven nautical miles (13 km; 8.1 mi). After a week of travel a sextant observation indicated that they were averaging nine nautical miles a day, (17 km; 10 mi), putting them ahead of schedule. However, uneven surfaces made skiing more difficult, and their speeds slowed. They also realised that they were marching against a southerly drift, and that distances travelled did not necessarily equate to northerly progression. On 3 April Nansen began to wonder whether the pole was, indeed, attainable. Unless their speed improved, their food would not last them to the pole and then on to Franz Josef Land. He confided in his diary: "I have become more and more convinced we ought to turn before time." On 7 April, after making camp and observing that the way ahead was "a veritable chaos of iceblocks stretching as far as the horizon", Nansen decided to turn south. He recorded the latitude of the final northerly camp as 86°13.6′N, almost three degrees beyond the previous Farthest North mark.
Retreat.
At first Nansen and Johansen made good progress south, but on 13 April suffered a serious setback when both of their chronometers stopped. Without knowing the correct time, it was impossible for them to calculate their longitude and thus navigate their way accurately to Franz Josef Land. They restarted the watches on the basis of Nansen's guess that they were at longitude 86°E, but from then on were uncertain of their true position.
Towards the end of April they observed the tracks of an Arctic fox, the first trace they had seen of a living creature other than their dogs since leaving "Fram". Soon they began to see bear tracks, and by the end of May seals, gulls and whales were in evidence. On 31 May, by Nansen's calculations, they were only from Cape Fligely, the northernmost known point of Franz Josef Land. However, travel conditions worsened as the warmer weather caused the ice to break up. On 22 June the pair decided to rest on a stable ice floe while they repaired their equipment and gathered their strength for the next stage of their journey. They remained on the floe for a month. The day after leaving this camp Nansen recorded: "At last the marvel has come to pass—land, land, and after we had almost given up our belief in it!" Whether this still-distant land was Franz Josef Land or a new discovery they did not know—they had only a rough sketch map to guide them. On 6 August they reached the edge of the ice, where they shot the last of their dogs—they had been killing the weakest regularly since 24 April, to feed the others. They then lashed their two kayaks together, raised a sail and made for the land.
It was soon clear that this land was part of a group of islands. As they moved slowly southwards, Nansen tentatively identified a headland as Cape Felder, on the western edge of Franz Josef Land. Towards the end of August, as the weather grew colder and travel became increasingly difficult, Nansen decided to camp for the winter. In a sheltered cove, with stones and moss for building materials, the pair erected a hut which was to be their home for the next eight months. With ready supplies of bear, walrus and seal to keep their larder stocked, their principal enemy was not hunger but inactivity. After muted Christmas and New Year celebrations, in slowly improving weather they began to prepare to leave their refuge, but it was 19 May 1896 before they were able to resume their journey.
Rescue and return.
On 17 June, during a stop for repairs after the kayaks had been attacked by a walrus, Nansen thought he heard sounds of a dog barking, and of voices. He went to investigate, and a few minutes later saw the figure of a man approaching. It was the British explorer Frederick Jackson, who was leading an expedition to Franz Josef Land and was camped at Cape Flora on the nearby Northbrook Island. The two were equally astonished by their encounter; after some awkward hesitation Jackson asked: "You are Nansen, aren't you?", and received the reply "Yes, I am Nansen." Johansen was soon picked up, and the pair were taken to Cape Flora where, during the following weeks, they recuperated from their ordeal. Nansen later wrote that he could "still scarcely grasp" the sudden change of fortune; had it not been for the walrus attack that caused the delay, the two parties might have been unaware of each other's existence.
On 7 August Nansen and Johansen boarded Jackson's supply ship "Windward", and sailed for Vardø where they arrived on the 13th. They were greeted by Hans Mohn, the originator of the polar drift theory, who was in the town by chance. The world was quickly informed by telegram of Nansen's safe return, but as yet there was no news of "Fram". Taking the weekly mail steamer south, Nansen and Johansen reached Hammerfest on 18 August, where they learned that "Fram" had been sighted. She had emerged from the ice north and west of Spitsbergen, as Nansen had predicted, and was now on her way to Tromsø. She had not passed over the pole, nor exceeded Nansen's northern mark. Without delay Nansen and Johansen sailed for Tromsø, where they were reunited with their comrades.
The homeward voyage to Christiania was a series of triumphant receptions at every port. On 9 September "Fram" was escorted into Christiania's harbour and welcomed by the largest crowds the city had ever seen. The crew were received by King Oscar, and Nansen, reunited with family, remained at the palace for several days as a special guest. Tributes arrived from all over the world; typical was that from the British mountaineer Edward Whymper, who wrote that Nansen had made "almost as great an advance as has been accomplished by all other voyages in the nineteenth century put together".
National figure.
Scientist and polar oracle.
Nansen's first task on his return was to write his account of the voyage. This he did remarkably quickly, producing 300,000 words of Norwegian text by November 1896; the English translation, titled "Farthest North", was ready in January 1897. The book was an instant success, and secured Nansen's long-term financial future. Nansen included without comment the one significant adverse criticism of his conduct, that of Greely, who had written in "Harper's Weekly" on Nansen's decision to leave "Fram" and strike for the pole: "It passes comprehension how Nansen could have thus deviated from the most sacred duty devolving on the commander of a naval expedition."
During the 20 years following his return from the Arctic, Nansen devoted most of his energies to scientific work. In 1897 he accepted a professorship in zoology at the Royal Frederick University, which gave him a base from which he could tackle the major task of editing the reports of the scientific results of the "Fram" expedition. This was a much more arduous task than writing the expedition narrative. The results were eventually published in six volumes, and according to a later polar scientist, Robert Rudmose-Brown, "were to Arctic oceanography what the Challenger expedition results had been to the oceanography of other oceans."
In 1900 Nansen became director of the Christiania-based International Laboratory for North Sea Research, and helped found the International Council for the Exploration of the Sea. Through his connection with the latter body, in the summer of 1900 Nansen embarked on his first visit to Arctic waters since the "Fram" expedition, a cruise to Iceland and Jan Mayen Land on the oceanographic research vessel "Michael Sars", named after Eva's father. Shortly after his return he learned that his Farthest North record had been passed, by members of the Duke of the Abruzzi's Italian expedition. They had reached 86°34N on 24 April 1900, in an attempt to reach the North Pole from Franz Josef Land. Nansen received the news philosophically: "What is the value of having goals for their own sake? They all vanish ... it is merely a question of time.
Nansen was now considered an oracle by all would-be explorers of the north and south polar regions. Abruzzi had consulted him, as had the Belgian Adrien de Gerlache, each of whom took expeditions to the Antarctic. Although Nansen refused to meet his own countryman and fellow-explorer Carsten Borchgrevink (whom he considered a fraud), he gave advice to Robert Falcon Scott on polar equipment and transport, prior to the 1901–04 Discovery Expedition. Nansen's advice that dogs fed by stockfish provided the best means of polar travel was followed verbatim by Scott, with unfortunate consequences; nevertheless the two remained on good terms. At one point Nansen seriously considered leading a South Pole expedition himself, and asked Colin Archer to design two ships. However, these plans remained on the drawing board.
By 1901 Nansen's family had expanded considerably. A daughter, Liv, had been born just before "Fram" set out; a son, Kåre was born in 1897 followed by a daughter, Irmelin, in 1900 and a second son Odd in 1901. The family home, which Nansen had built in 1891 from the profits of his Greenland expedition book, was now too small. Nansen acquired a plot of land in the Lysaker district and built, substantially to his own design, a large and imposing house which combined some of the characteristics of an English manor house with features from the Italian renaissance. The house was ready for occupation by April 1902; Nansen called it "Polhøgda" (in English "polar heights"), and it remained his home for the rest of his life. A fifth and final child, son Asmund, was born at Polhøgda in 1903.
Politician and diplomat.
The union between Norway and Sweden, imposed by the Great Powers in 1814, had been under considerable strain through the 1890s, the chief issue in question being Norway's rights to its own consular service. Nansen, although not by inclination a politician, had spoken out on the issue on several occasions in defence of Norway's interests. It seemed, early in the 20th century that agreement between the two countries might be possible, but hopes were dashed when negotiations broke down in February 1905. The Norwegian government fell, and was replaced by one led by Christian Michelsen, whose programme was one of separation from Sweden.
In February and March Nansen published a series of newspaper articles which placed him firmly in the separatist camp. The new prime minister wanted Nansen in the cabinet, but Nansen had no political ambitions. However, at Michelsen's request he went to Berlin and then to London where, in a letter to "The Times", he presented Norway's legal case for a separate consular service to the English-speaking world.
On 17 May 1905, Norway's Constitution Day, Nansen addressed a large crowd in Christiania, saying:
Now have all ways of retreat been closed. Now remains only one path, the way forward, perhaps through difficulties and hardships, but forward for our country, to a free Norway.
He also wrote a book, "Norway and the Union with Sweden", specifically to promote Norway's case abroad.
On 23 May the Storting passed the Consulate Act establishing a separate consular service. King Oscar, refused his assent; on 27 May the Norwegian cabinet resigned, but the king would not recognise this step. On 7 June the Storting unilaterally announced that the union with Sweden was dissolved. In a tense situation the Swedish government agreed to Norway's request that the dissolution should be put to a referendum of the Norwegian people. This was held on 13 August 1905 and resulted in an overwhelming vote for separation, at which point King Oscar relinquished the crown of Norway while retaining the Swedish throne. A second referendum, held in November, determined that the new independent state should be a monarchy rather than a republic. In anticipation of this, Michelsen's government had been considering the suitability of various princes as candidates for the Norwegian throne. Faced with King Oscar's refusal to allow anyone from his own House of Bernadotte to accept the crown, the favoured choice was Prince Charles of Denmark. In July 1905 Michelsen sent Nansen to Copenhagen on a secret mission to persuade Charles to accept the Norwegian throne. Nansen was successful; shortly after the second referendum Charles was proclaimed king, taking the name Haakon VII. He and his wife, the British princess Maud, were crowned in the Nidaros Cathedral in Trondheim on 22 June 1906.
In April 1906 Nansen was appointed Norway's first Minister in London. His main task was to work with representatives of the major European powers on an Integrity Treaty which would guarantee Norway's position. Nansen was popular in England, and got on well with King Edward, though he found court functions and diplomatic duties disagreeable; "frivolous and boring" was his description. However, he was able to pursue his geographical and scientific interests through contacts with the Royal Geographical Society and other learned bodies. The Treaty was signed on 2 November 1907, and Nansen considered his task complete. Resisting the pleas of, among others, King Edward that he should remain in London, on 15 November Nansen resigned his post. A few weeks later, still in England as the king's guest at Sandringham, Nansen received word that Eva was seriously ill with pneumonia. On 8 December he set out for home, but before he reached Polhøgda he learned, from a telegram, that Eva had died.
Oceanographer and traveller.
After a period of mourning, Nansen returned to London. He had been persuaded by his government to rescind his resignation until after King Edward's state visit to Norway in April 1908. His formal retirement from the diplomatic service was dated 1 May 1908, the same day on which his university professorship was changed from zoology to oceanography. This new designation reflected the general character of Nansen's more recent scientific interests. In 1905 he had supplied the Swedish physicist Walfrid Ekman with the data which established the principle in oceanography known as the Ekman spiral. Based on Nansen's observations of ocean currents recorded during the "Fram" expedition, Ekman concluded that the effect of wind on the sea's surface produced currents which "formed something like a spiral staircase, down towards the depths". In 1909 Nansen combined with Bjørn Helland-Hansen to publish an academic paper, "The Norwegian Sea: its Physical Oceanography", based on the "Michael Sars" voyage of 1900.
Nansen had by now retired from polar exploration, the decisive step being his release of "Fram" to his fellow-Norwegian Roald Amundsen, who was planning a North Pole expedition. When Amundsen made his controversial change of plan and set out for the South Pole, Nansen stood by him. Between 1910 and 1914, Nansen participated in a several oceanographic voyages. In 1910, aboard the Norwegian naval vessel "Fridtjof", he carried out researches in the northern Atlantic, and in 1912 he took his own yacht, "Veslemøy", to Bear Island and Spitsbergen. The main objective of the "Veslemøy" cruise was the investigation of salinity in the North Polar Basin. One of Nansen's lasting contributions to oceanography was his work designing instruments and equipment; the "Nansen bottle" for taking deep water samples remained in use into the 21st century, in a version updated by Shale Niskin.
At the request of the Royal Geographical Society, Nansen began work on a study of Arctic discoveries, which developed into a two-volume history of the exploration of the northern regions up to the beginning of the 16th century. This was published in 1911 as "Nord i Tåkeheimen" ("In Northern Mists"). That year he renewed an acquaintance with Kathleen Scott, wife of Robert Falcon Scott whose Terra Nova Expedition had sailed for Antarctica in 1910. Biographer Roland Huntford has asserted that Nansen and Kathleen Scott enjoyed a brief love affair. Many women were attracted to Nansen, and he had a reputation as a womaniser. His personal life was troubled around this time; in January 1913 he received news of the suicide of Hjalmar Johansen, who had returned in disgrace from Amundsen's successful South Pole expedition. In March 1913, Nansen's youngest son Asmund died after a long illness.
In the summer of 1913 Nansen travelled to the Kara Sea, by the invitation of Jonas Lied, as part of a delegation investigating a possible trade route between Western Europe and the Siberian interior. The party then took a steamer up the Yenisei River to Krasnoyarsk, and travelled on the Trans-Siberian Railway to Vladivostok before turning for home. Nansen published a report from the trip in "Through Siberia". The life and culture of the Russian peoples aroused in Nansen an interest and sympathy he would carry through to his later life. Immediately before the First World War, Nansen joined Helland-Hansen in an oceanographical cruise in eastern Atlantic waters.
Statesman and humanitarian.
On the outbreak of war in 1914 Norway declared its neutrality, alongside Sweden and Denmark. Nansen was appointed president of the Norwegian Union of Defence, but had few official duties, and continued with his professional work as far as circumstances permitted. As the war progressed, the loss of Norway's overseas trade led to acute shortages of food in the country, which became critical in April 1917 when the United States entered the war and placed extra restrictions on international trade. Nansen was dispatched to Washington by the Norwegian government; after months of discussion he secured food and other supplies in return for the introduction of a rationing system. When his government hesitated over the deal, he signed the agreement on his own initiative.
Within a few months of the war's end in November 1918 a draft agreement had been accepted by the Paris Peace Conference to create a League of Nations, as a means of resolving disputes between nations by peaceful means. The foundation of the League at this time was providential as far as Nansen was concerned, giving him a new outlet for his restless energy.
He became president of the Norwegian League of Nations Society, and although the Scandinavian nations with their traditions of neutrality initially held themselves aloof, his advocacy helped to ensure that Norway became a full member of the League in 1920, and he became one of its three delegates to the League's General Assembly.
In April 1920, at the League's request, Nansen began organising the repatriation of around half a million prisoners of war, stranded in various parts of the world. Of these, 300,000 were in Russia which, gripped by revolution and civil war, had little interest in their fate. Nansen was able to report to the Assembly in November 1920 that around 200,000 men had been returned to their homes. "Never in my life", he said, "have I been brought into touch with so formidable an amount of suffering." Nansen continued this work for a further two years until, in his final report to the Assembly in 1922, he was able to state that 427,886 prisoners had been repatriated to around 30 different countries. In paying tribute to his work, the responsible committee recorded that the story of his efforts "would contain tales of heroic endeavour worthy of those in the accounts of the crossing of Greenland and the great Arctic voyage."
Even before this work was complete, Nansen was involved in a further humanitarian effort. On 1 September 1921, prompted by the British delegate Philip Noel-Baker, he accepted the post of the League's High Commissioner for Refugees. His main brief was the resettlement of around two million Russian refugees displaced by the upheavals of the Russian Revolution. At the same time he tried to tackle the urgent problem of famine in Russia; following a widespread failure of crops around 30 million people were threatened with starvation and death. Despite Nansen's pleas on behalf of the starving, Russia's revolutionary government was feared and distrusted internationally, and the League was reluctant to come to its peoples' aid. Nansen had to rely largely on fundraising from private organisations, and his efforts met with limited success. Later he was to express himself bitterly on the matter:
There was in various transatlantic countries such an abundance of maize, that the farmers had to burn it as fuel in their railway engines. At the same time the ships in Europe were idle, for there were no cargoes. Simultaneously there were thousands, nay millions of unemployed. All this, while thirty million people in the Volga region—not far away and easily reached by our ships—were allowed to starve and die.
A major problem impeding Nansen's work on behalf of refugees was that most of them lacked documentary proof of identity or nationality. Without legal status in their country of refuge, their lack of papers meant they were unable to go anywhere else. To overcome this, Nansen devised a document that became known as the "Nansen passport", a form of identity for stateless persons that was in time recognised by more than 50 governments, and which allowed refugees to cross borders legally. Among the more distinguished holders of Nansen passports were the artist Marc Chagall, the composer Igor Stravinsky, and the dancer Anna Pavlova. Although the passport was created initially for refugees from Russia, it was extended to cover other groups. After the Greco-Turkish wars of 1919–1922 Nansen travelled to Constantinople to negotiate the resettlement of hundreds of thousands of refugees, mainly ethnic Greeks who had fled from Turkey after the defeat of the Greek Army. The impoverished Greek state was unable to take them in, and so Nansen devised a scheme for a population exchange whereby half a million Turks in Greece were returned to Turkey, with full financial compensation, while further loans facilitated the absorption of the refugee Greeks into their homeland. Despite some controversy over the principle of a population exchange, the plan was implemented successfully over a period of several years. In November 1922, while attending the Conference of Lausanne, Nansen learned that he had been awarded the Nobel Peace Prize for 1922. The citation referred to "his work for the repatriation of the prisoners of war, his work for the Russian refugees, his work to bring succour to the millions of Russians afflicted by famine, and finally his present work for the refugees in Asia Minor and Thrace". Nansen donated the prize money to international relief efforts.
From 1925 onwards he spent much time trying to help Armenian refugees, victims of Armenian Genocide at the hands of the Ottoman Empire during the First World War and further ill-treatment thereafter. His goal was the establishment of a national home for these refugees, within the borders of Soviet Armenia. His main assistant in this endeavour was Vidkun Quisling, the future Nazi collaborator and head of a Norwegian puppet government during the Second World War. After visiting the region, Nansen presented the Assembly with a modest plan for the irrigation of 36,000 hectares (360 km or 139 square miles) on which 15,000 refugees could be settled. The plan ultimately failed, because even with Nansen's unremitting advocacy the money to finance the scheme was not forthcoming. Despite this failure, his reputation among the Armenian people remains high. Nansen wrote the book, "Armenia and the Near East" in 1923 which describes his sympathies to the plight of the Armenians in the wake of losing its independence to the Soviet Union. The book was translated in many languages including Norwegian, English, French, German, Russian and Armenian. After his visit to Armenia, Nansen wrote two additional books called "Gjennem Armenia" ("Across Armenia"), published in 1927 and "Gjennem Kaukasus til Volga" ("Through Caucasus to Volga").
Within the League's Assembly, Nansen spoke out on many issues besides those related to refugees. He believed that the Assembly gave the smaller countries such as Norway a "unique opportunity for speaking in the councils of the world." He believed that the extent of the League's success in reducing armaments would be the greatest test of its credibility. He was a signatory to the Slavery Convention of 25 September 1926, which sought to outlaw the use of forced labour. He supported a settlement of the post-war reparations issue, and championed Germany's membership of the League, which was granted in September 1926 after intensive preparatory work by Nansen.
Later life.
On 17 January 1919 Nansen married Sigrun Munthe, a long-time friend with whom he had had a love affair in 1905, while Eva was still alive. The marriage was resented by the Nansen children, and proved unhappy; an acquaintance writing of them in the 1920s said Nansen appeared unbearably miserable and Sigrun steeped in hate.
Nansen's League of Nations commitments through the 1920s meant that he was mostly absent from Norway, and was able to devote little time to scientific work. Nevertheless, he continued to publish occasional papers. He entertained the hope that he might travel to the North Pole by airship, but could not raise sufficient funding. In any event he was forestalled in this ambition by Amundsen, who flew over the pole in Umberto Nobile's airship "Norge" in May 1926. Two years later Nansen broadcast a memorial oration to Amundsen, who had disappeared in the Arctic while organising a rescue party for Nobile whose airship had crashed during a second polar voyage. Nansen said of Amundsen:
He found an unknown grave under the clear sky of the icy world, with the whirring of the wings of eternity through space."
In 1926 Nansen was elected Rector of the University of St Andrews in Scotland, the first foreigner to hold this largely honorary position. He used the occasion of his inaugural address to review his life and philosophy, and to deliver a call to the youth of the next generation. He ended:
We all have a Land of Beyond to seek in our life—what more can we ask? Our part is to find the trail that leads to it. A long trail, a hard trail, maybe; but the call comes to us, and we have to go. Rooted deep in the nature of every one of us is the spirit of adventure, the call of the wild—vibrating under all our actions, making life deeper and higher and nobler.
Nansen largely avoided involvement in domestic Norwegian politics, but in 1924 he was persuaded by the long-retired former Prime Minister Christian Michelsen to take part in a new anti-communist political grouping, the Fatherland League. There were fears in Norway that should the Marxist-oriented Labour Party gain power it would introduce a revolutionary programme. At the inaugural rally of the League in Oslo (as Christiania had now been renamed), Nansen declared:
To talk of the right of revolution in a society with full civil liberty, universal suffrage, equal treatment for everyone ... idiotic nonsense." 
Following continued turmoil between the centre-right parties, there was even an independent petition in 1926 gaining some momentum that proposed for Nansen to head a centre-right national unity government on a balanced budget program, an idea he did not reject. He was the headline speaker at the single largest Fatherland League rally with 15,000 attendees in Tønsberg in 1928. In 1929 he went on his final tour for the League on the ship "Stella Polaris", holding speeches from Bergen to Hammerfest.
In between his various duties and responsibilities, Nansen had continued to take skiing holidays when he could. In February 1930, aged 68, he took a short break in the mountains with two old friends, who noted that Nansen was slower than usual and appeared to tire easily. On his return to Oslo he was laid up for several months, with influenza and later phlebitis, and was visited on his sickbed by H.M.K., Haakon VII of Norway.
Death and legacy.
Nansen died of a heart attack, at home, on 13 May 1930. He was given a non-religious state funeral before cremation, after which his ashes were laid under a tree at Polhøgda. Nansen's daughter Liv recorded that there were no speeches, just music: Schubert's "Death and the Maiden", which Eva used to sing. Among the many tributes paid to him subsequently was that of Lord Robert Cecil, a fellow League of Nations delegate, who spoke of the range of Nansen's work, done with no regard for his own interests or health: "Every good cause had his support. He was a fearless peacemaker, a friend of justice, an advocate always for the weak and suffering."
Nansen had been a pioneer and innovator in many fields. As a young man he embraced the revolution in skiing methods that transformed it from a means of winter travel to a universal sport, and quickly became one of Norway's leading skiers. He was later able to apply this expertise to the problems of polar travel, in both his Greenland and his "Fram" expeditions. He invented the "Nansen sledge" with broad, ski-like runners, the "Nansen cooker" to improve the heat efficiency of the standard spirit stoves then in use, and the layer principle in polar clothing, whereby the traditionally heavy, awkward garments were replaced by layers of lightweight material. In science, Nansen is recognised both as one of the founders of modern neurology, and as a significant contributor to early oceanographical science.
Through his work on behalf of the League of Nations, Nansen helped to establish the principle of international responsibility for refugees. Immediately after his death the League set up the Nansen International Office for Refugees, a semi-autonomous body under the League's authority, to continue his work. The Nansen Office faced great difficulties, in part arising from the large numbers of refugees from the European dictatorships during the 1930s. Nevertheless, it secured the agreement of 14 countries (including a reluctant Great Britain) to the Refugee Convention of 1933. It also helped to repatriate 10,000 Armenians to Yerevan in Soviet Armenia, and to find homes for a further 40,000 in Syria and Lebanon. In 1938, the year in which it was superseded by a wider-ranging body, the Nansen Office was awarded the Nobel Peace Prize.
In 1954 the League's successor body, the United Nations, established the Nansen Medal, later named the Nansen Refugee Award, given annually by the United Nations High Commissioner for Refugees to an individual, group or organisation "in recognition of extraordinary and dedicated service to refugees".
A central street in Sofia Bulgaria is named after Fridtiof Nansen, and a memorial plate is mounted on a nearby building.
In his lifetime and thereafter, Nansen received honours and recognition from many countries. Nansen Ski Club, the oldest continually operated ski club in the United States, located in Berlin, New Hampshire, is named in his honour.
Numerous geographical features are named after him: the Nansen Basin and the Nansen-Gakkel Ridge in the Arctic Ocean; Mount Nansen in the Yukon region of Canada; Mount Nansen, Mount Fridtjof Nansen and Nansen Island, all in Antarctica.
Polhøgda is now home to the Fridtjof Nansen Institute, an independent foundation which engages in research on environmental, energy and resource management politics.
In 2004 the Royal Norwegian Navy launched the first of a series of five "Fridtjof Nansen"-class frigates. The lead ship of the group is HNoMS "Fridtjof Nansen"; two others are named after Roald Amundsen and Otto Sverdrup.
In the ocean, Nansen is commemorated by "Nansenia", small mesopelagic fishes of family Microstomatidae.
In space, he is commemorated by asteroid 853 Nansenia. In 1964, the IAU adopted the name Nansen for an impact crater at the Lunar north pole, after the Norwegian explorer.
Family.
He disinherited his son Kåre.

</doc>
<doc id="11824" url="https://en.wikipedia.org/wiki?curid=11824" title="Frederick Augustus II of Saxony">
Frederick Augustus II of Saxony

Frederick Augustus II (full name: "Frederick Augustus Albert Maria Clemens Joseph Vincenz Aloys Nepomuk Johann Baptista Nikolaus Raphael Peter Xavier Franz de Paula Venantius Felix") ( Dresden, 18 May 1797 – Brennbüchel, Karrösten, Tyrol, 9 August 1854) was King of Saxony and a member of the House of Wettin.
He was the eldest son of Maximilian, Prince of Saxony — younger son of the Elector Frederick Christian of Saxony — by his first wife, Caroline of Bourbon, Princess of Parma.
Life.
Early years.
From his birth, it was clear that one day Frederick Augustus would become the ruler of Saxony. His father was the only son of the Elector Frederick Christian of Saxony who left surviving male issue. When the King Frederick Augustus I died (1827) and Anton succeeded him as King, Frederick Augustus became second in line to the throne, preceded only by his father Maximilian.
He was an officer in the War of the Sixth Coalition. However, he had little interest in military affairs.
Co-Regent to the Kingdom.
The July Revolution of 1830 in France marked the beginning of disturbances in Saxony that autumn. The people claimed a change in the constitution and demanded a young regent of the kingdom to share the government with the King Anton. On 1 September the Prince Maximilian renounced his rights of succession in favor of his son Frederick Augustus, who was proclaimed Prince Co-Regent (de: "Prinz-Mitregenten") of Saxony. On 2 February 1832 Frederick Augustus brought Free Autonomy to the cities. Also, by an edict of 17 March of that year, the farmers were freed from the corvée and hereditary submission.
King of Saxony.
On 6 June 1836, King Anton died and Frederick Augustus succeeded him. As an intelligent man, he was quickly popular with the people as he had been since the time of his regency. The new king solved political questions only from a pure sense of duty. Mostly he preferred to leave these things on the hands of his ministers.
A standardized jurisdiction for Saxony created the Criminal Code of 1836. During the Revolutionary disturbances of 1848 (March Revolution), he appointed liberal ministers in the government, lifted censorship, and remitted a liberal electoral law. Later his attitude changed. On 28 April Frederick August II dissolved the Parliament. In 1849, Frederick Augustus was forced to flee to the Königstein Fortress. The May Uprising was crushed by Saxon and Prussian troops and Frederick was able to return after only a few days.
Journey through England and Scotland.
In 1844 Frederick Augustus, accompanied by his personal physician Carl Gustav Carus, made an informal ("incognito") visit to England and Scotland. Among places they visited were Lyme Regis where he purchased from the local fossil collector and dealer, Mary Anning, an ichthyosaur skeleton for his own extensive natural history collection. It was not a state visit, but the King was the guest of Queen Victoria and Prince Albert at Windsor castle, visited many of the sights in London and in the university cities of Oxford and Cambridge, and toured widely in England, Wales and Scotland.
Accidental Death.
During a journey in Tyrol, he had an accident in Brennbüchel in which he fell in front of a horse that stepped on his head. On 8 August 1854, he died in the Gasthof Neuner. He was buried on 16 August in the Katholische Hofkirche of Dresden. In his memory, the Dowager Queen Maria arranged to establish the Königskapelle (King's Chapel) at the accident place, which was consecrated one year later, some of the last members of the Saxon royal family, including Maria Emanuel, Margrave of Meissen, are buried beside the chapel
Marriages.
In Vienna on 26 September 1819 (by proxy) and again in Dresden on 7 October 1819 (in person), Frederick Augustus married firstly with the Archduchess Maria Caroline of Austria (Maria Karoline Ferdinande Theresia Josephine Demetria), daughter of Emperor Francis I of Austria. They had no children.
In Dresden on 24 April 1833 Frederick Augustus married secondly with the Princess Maria of Bavaria (Maria Anna Leopoldine Elisabeth Wilhelmine), daughter of the King Maximilian I Joseph of Bavaria. Like his first marriage, this was childless.
The musician Theodor Uhlig (1822–1853) was an illegitimate son of Frederick Augustus.
Without legitimate issue, after his death Frederick Augustus was succeeded by his younger brother, Johann.

</doc>
<doc id="11826" url="https://en.wikipedia.org/wiki?curid=11826" title="Free market">
Free market

A free market is a system in which the prices for goods and services are set freely by consent between vendors and consumers, in which the laws and forces of supply and demand are free from any intervention by a government, price-setting monopoly, or other authority. It is a result of a need being, then the need being met. A free market contrasts with a regulated market, in which government intervenes in supply and demand through non-market methods such as laws creating barriers to market entry or price fixing. In a free-market economy, prices for goods and services are set freely by the forces of supply and demand and are allowed to reach their point of equilibrium without intervention by government policy, and it typically entails support for highly competitive markets and private ownership of productive enterprises.
Although free markets are commonly associated with capitalism within a market economy in contemporary usage and popular culture, free markets have also been advocated by free-market anarchists, market socialists, and some proponents of cooperatives and advocates of profit sharing.
Economic systems.
Laissez-faire economics.
The laissez-faire principle expresses a preference for an absence of non-market pressures on prices and wages, such as those from discriminatory government taxes, subsidies, tariffs, regulations of purely private behavior, or government-granted or coercive monopolies. Friedrich Hayek argued in "The Pure Theory of Capital" that the goal is the preservation of the unique information contained in the price itself.
The definition of "free market" has been disputed and made complex by collectivist political philosophers and socialist economic ideas. This contention arose from the divergence of classical economists such as Adam Smith, David Ricardo, and Thomas Robert Malthus from the continental economic science developed primarily by the Spanish scholastic and French classical economists, including Richard Cantillon, Anne-Robert-Jacques Turgot, Baron de Laune, Jean-Baptiste Say and Frédéric Bastiat. Adam Smith discarded the subjective theory of value and contended that an unregulated market was prone to the rise of monopolies and was therefore not "free" in this sense.
During the marginal revolution, subjective value theory was rediscovered.
Socialist economics.
Various forms of socialism based on, or which advocate, free markets have existed since the 19th century. Early notable socialist proponents of free markets include Pierre-Joseph Proudhon, Benjamin Tucker, and the Ricardian socialists. These economists believed that genuinely free markets and voluntary exchange could not exist within the exploitative conditions of capitalism.
These proposals ranged from various forms of worker cooperatives operating in a free market economy, such as the Mutualist system proposed by Proudhon, to state-owned enterprises operating in unregulated and open markets. These models of socialism are not to be confused with other forms of market socialism (e.g. the Lange model) where publicly owned enterprises are coordinated by various degrees of economic planning, or where capital good prices are determined through marginal cost pricing.
Advocates of free-market socialism, such as Jaroslav Vanek, argue that genuine free markets are not possible under conditions of private ownership of productive property because the class differences and inequalities in income and power that result from this arrangement enable the interests of the dominant class to skew the market to their favor, either in the form of monopoly and market power, or by utilizing their wealth and resources to legislate government policies that benefit their specific business interests. Additionally, Vanek states that workers in a socialist economy based on cooperative and self-managed enterprises would have stronger incentives to maximize productivity because they would receive a share of the profits (based on the overall performance of their enterprise) in addition to receiving their fixed wage or salary.
Socialists also point out that free market capitalism leads to excessive disparities in the distribution of income, which leads to social instability. As a result, costly corrective measures in the form of social welfare, re-distributive taxation and heavy administrative costs are required, which weakens the incentive to work, invites dishonesty and increases the likelihood of tax evasion. Thus free market capitalism necessitates government regulation of markets to prevent social instability at the cost of reducing the overall efficiency of the market economy.
Geoist Economics.
As explained above, for classical economists such as Adam Smith the term "free market" does not necessarily refer to a market free from government interference, but rather free from all forms of economic privilege, monopolies and artificial scarcities. This implies that economic rents, i.e. profits generated from lack of perfect competition, must be reduced or eliminated as much as possible through free competition.
Economic theory suggests the returns to land and other natural resources are economic rents that cannot be reduced in a such a way because of their perfect inelastic supply. Some economic thinkers emphasize the need to share those rents as an essential requirement for a well functioning market. It is suggested this would both eliminate the need for regular taxes that have a negative effect on trade (see deadweight loss) as well as release land and resources that are speculated upon or monopolised. Two features that improve the competition and free market mechanisms. Winston Churchill supported this view by his statement "Land is the mother of all monopoly".
The American economist and social philosopher Henry George, the most famous proponent of this thesis, wanted to accomplish this through a high land value tax that replaces all other taxes. Followers of his ideas are often called Georgists or Geoists and Geolibertarians.
Léon Walras, one of the founders of the neoclassical economics who helped formulate the general equilibrium theory, had a very similar view. He argued that free competition could only be realized under conditions of state ownership of natural resources and land. Additionally, income taxes could be eliminated because the state would receive income to finance public services through owning such resources and enterprises.
Non-laissez-faire capitalist systems.
The stronger incentives to maximize productivity that Vanek conceives as possible in a socialist economy based on cooperative and self-managed enterprises might be accomplished in a capitalistic free market if employee-owned companies were the norm, as envisioned by various thinkers including Louis O. Kelso and James S. Albus.
Concepts.
Supply and demand.
Demand for an item (such as goods or services) refers to the market pressure from people trying to buy it. Buyers have a maximum price they are willing to pay and sellers have a minimum price they are willing to offer their product. The point at which the supply and demand curves meet is the equilibrium price of the good and quantity demanded. Sellers willing to offer their goods at a lower price than the equilibrium price receive the difference as producer surplus. Buyers willing to pay for goods at a higher price than the equilibrium price receive the difference as consumer surplus.
The model is commonly applied to wages in the market for labor. The typical roles of supplier and consumer are reversed. The suppliers are individuals, who try to sell (supply) their labor for the highest price. The consumers are businesses, which try to buy (demand) the type of labor they need at the lowest price. As more people offer their labor in that market, the equilibrium wage decreases and the equilibrium level of employment increases as the supply curve shifts to the right. The opposite happens if fewer people offer their wages in the market as the supply curve shifts to the left.
In a free market, individuals and firms taking part in these transactions have the liberty to enter, leave and participate in the market as they so choose. Prices and quantities are allowed to adjust according to economic conditions in order to reach equilibrium and properly allocate resources. However, in many countries around the world, governments seek to intervene in the free market in order to achieve certain social or political agendas. Governments may attempt to create social equality or equality of outcome by intervening in the market through actions such as imposing a minimum wage (price floor) or erecting price controls (price ceiling). Other lesser-known goals are also pursued, such as in the United States, where the federal government subsidizes owners of fertile land to not grow crops in order to prevent the supply curve from further shifting to the right and decreasing the equilibrium price. This is done under the justification of maintaining farmers' profits; due to the relative inelasticity of demand for crops, increased supply would lower the price but not significantly increase quantity demanded, thus placing pressure on farmers to exit the market.
Government intervention in the free market can hamper economic growth, entrepreneurship and a healthy economy by disrupting the natural allocation of resources according to supply and demand. Milton Friedman pointed to failures of central planning, price controls and state-owned corporations, particularly in the Soviet Union and Communist China.
Economic equilibrium.
General equilibrium theory has demonstrated, with varying degrees of mathematical rigor over time, that under certain conditions of competition, the law of supply and demand predominates in this ideal free and competitive market, influencing prices toward an equilibrium that balances the demands for the products against the supplies. At these equilibrium prices, the market distributes the products to the purchasers according to each purchaser's preference (or utility) for each product and within the relative limits of each buyer's purchasing power. This result is described as market efficiency, or more specifically a Pareto optimum.
This equilibrating behavior of free markets requires certain assumptions about their agents, collectively known as perfect competition, which therefore cannot be results of the market that they create. Among these assumptions are several which are impossible to fully achieve in a real market, such as complete information, interchangeable goods and services, and lack of market power. The question then is what approximations of these conditions guarantee approximations of market efficiency, and which failures in competition generate overall market failures. Several Nobel Prizes in Economics have been awarded for analyses of market failures due to asymmetric information.
Low barriers to entry.
A free market does not require the existence of competition, however it does require a framework that allows new market entrants. Hence, in the lack of coercive barriers, and in markets with low entry cost it is generally understood that competition flourishes in a free-market environment. It often suggests the presence of the profit motive, although neither a profit motive or profit itself are necessary for a free market. All modern free markets are understood to include entrepreneurs, both individuals and businesses. Typically, a modern free market economy would include other features, such as a stock exchange and a financial services sector, but they do not define it.
Spontaneous order.
Friedrich Hayek popularized the view that market economies promote spontaneous order which results in a better "allocation of societal resources than any design could achieve." According to this view, in market economies are characterized by the formation of complex transactional networks which produce and distribute goods and services throughout the economy. These networks are not designed, but nevertheless emerge as a result of decentralized individual economic decisions. The idea of spontaneous order is an elaboration on the invisible hand proposed by Adam Smith in "The Wealth of Nations". Smith wrote that the individual who:
Smith pointed out that one does not get one's dinner by appealing to the brother-love of the butcher, the farmer or the baker. Rather one appeals to their self-interest, and pays them for their labor.
Supporters of this view claim that spontaneous order is superior to any order that does not allow individuals to make their own choices of what to produce, what to buy, what to sell, and at what prices, due to the number and complexity of the factors involved. They further believe that any attempt to implement central planning will result in more disorder, or a less efficient production and distribution of goods and services.
Critics, such as political economist Karl Polanyi, question whether a spontaneously ordered market can exist, completely free of "distortions" of political policy; claiming that even the ostensibly freest markets require a state to exercise coercive power in some areas – to enforce contracts, to govern the formation of labor unions, to spell out the rights and obligations of corporations, to shape who has standing to bring legal actions, to define what constitutes an unacceptable conflict of interest, etc.
General principles.
The Heritage Foundation, a right-wing think tank, tried to identify the key factors necessary to measure the degree of freedom of economy of a particular country. In 1986 they introduced the Index of Economic Freedom, which is based on some fifty variables. This and other similar indices do not "define" a free market, but measure the "degree" to which a modern economy is free, meaning in most cases free of state intervention. The variables are divided into the following major groups:
Each group is assigned a numerical value between 1 and 5; IEF is the arithmetical mean of the values, rounded to the hundredth. Initially, countries which were traditionally considered capitalistic received high ratings, but the method improved over time. Some economists, like Milton Friedman and other Laissez-faire economists have argued that there is a direct relationship between economic growth and economic freedom, and some studies suggest this is true. Continuous debates among scholars on methodological issues in empirical studies of the connection between economic freedom and economic growth still try to find out what is the relationship, if any.
Criticisms.
Critics of the free market have argued that, in real world situations, it has proven to be susceptible to the development of price fixing monopolies. Such reasoning has led to government intervention, e.g. the United States antitrust law.
Two prominent Canadian authors argue that government at times has to intervene to ensure competition in large and important industries. Naomi Klein illustrates this roughly in her work "The Shock Doctrine" and John Ralston Saul more humorously illustrates this through various examples in "The Collapse of Globalism and the Reinvention of the World". While its supporters argue that only a free market can create healthy competition and therefore more business and reasonable prices, opponents say that a free market in its purest form may result in the opposite. According to Klein and Ralston, the merging of companies into giant corporations or the privatization of government-run industry and national assets often result in monopolies (or oligopolies) requiring government intervention to force competition and reasonable prices. Another form of market failure is speculation, where transactions are made to profit from short term fluctuation, rather from the intrinsic value of the companies or products.
American philosopher and author Cornel West, has derisively termed what he perceives as dogmatic arguments for laissez-faire economic policies as "free-market fundamentalism". West has contended that such mentality "trivializes the concern for public interest" and "makes money-driven, poll-obsessed elected officials deferential to corporate goals of profit – often at the cost of the common good." American political philosopher Michael J. Sandel contends that in the last 30 years the United States has moved beyond just having a market economy and has become a market society where literally everything is for sale, including aspects of social and civic life such as education, access to justice and political influence. The economic historian Karl Polanyi was highly critical of the idea of the market-based society in his book "The Great Transformation", noting that any attempt at its creation would undermine human society and the common good.
Critics of free market economics range from those who reject markets entirely, in favour of a planned economy, as advocated by various Marxists, to those who wish to see market failures regulated to various degrees or supplemented by government interventions. Keynesians support market roles for government, such as using fiscal policy for economic stimulus, when actions in the private sector lead to sub-optimal economic outcomes, such as depressions or recessions. Business cycle theory is used by Keynesians to explain "liquidity traps", by which underconsumption occurs, to argue for government intervention with fiscal policy.

</doc>
<doc id="11830" url="https://en.wikipedia.org/wiki?curid=11830" title="Ford GT40">
Ford GT40

The Ford GT40 is a high performance American-British endurance racing car, built and designed in England (Mk I, Mk II, and Mk III) and in the United States (Mk IV), and powered by a series of American-built engines, which won the 24 Hours of Le Mans four consecutive times, from 1966 to 1969 (1966 being the Mk II, 1967 the Mk IV, and 1968-1969 the oldest chassis design, the Mk I), Including a 1-2-3 finish in 1966. In 1966, with Henry Ford II himself in attendance at Le Mans, the Mk II GT40 provided Ford with the first overall Le Mans victory for an American manufacturer and the first victory for an American manufacturer at a major European race since Jimmy Murphy´s triumph with Duesenberg at the 1921 French Grand Prix. The Mk IV GT40 that won LeMans in 1967 is the only car designed and built entirely in the United States to win the overall title.
The GT40 was originally produced to win long-distance sports car races against Ferrari (who won at Le Mans six times in a row from 1960 to 1965). FORD/Shelby Chassis # P-1075, which won in 1968 and 1969, is the first car in Le Mans history to win the race more than once, with the same chassis. Using an American Ford V-8 engine originally of 4.7-litre displacement capacity (289 cubic inches). It was later enlarged to the 4.9-litre engine (302 cubic inches), with custom designed alloy Gurney-Weslake cylinder heads.
The car was named the GT (for Grand Touring) with the 40 representing its overall height of 40 inches (1.02 m, measured at the windshield) as required by the rules. Large displacement Ford V8 engines (4.2 litre, 4.7 litre and 7 litre) were used, compared with the Ferrari V12 which displaced 3.0 litres or 4.0 litres.
Early cars were simply named "Ford GT". The name "GT40" was the name of Ford's project to prepare the cars for the international endurance racing circuit, and the quest to win the 24 Hours of Le Mans. The first 12 "prototype" vehicles carried serial numbers GT-101 through GT-112. The "production" began and the subsequent cars, the MkI, MkII, and MkIIIs, (with the exception of the MkIV, which were numbered J1-J12) were numbered GT40P/1000 through GT40P/1145, were officially "GT40s". The name of Ford's project, and the serial numbers dispel the story that "GT40" was "only a nickname."
The contemporary Ford GT is a modern homage to the GT40.
History.
Henry Ford II had wanted a Ford at Le Mans since the early 1960s.
In the spring of 1963, Ford reportedly received word through a European intermediary that Enzo Ferrari was interested in selling to Ford Motor Company. Ford reportedly spent several million dollars in an audit of Ferrari factory assets and in legal negotiations, only to have Ferrari unilaterally cut off talks at a late stage due to disputes about the ability to direct open wheel racing. Ferrari, who wanted to remain the sole operator of his company's motor sports division, was angered when he was told that he would not be allowed to race at the Indianapolis 500 if the deal went through since Ford fielded Indy cars using the company's engine, and didn't want competition from Ferrari. Enzo cut the deal off out of spite and Henry Ford II, enraged, directed his racing division to find a company that could build a Ferrari-beater on the world endurance-racing circuit.
To this end Ford began negotiation with Lotus, Lola, and Cooper. Cooper had no experience in GT or prototype and its performances in Formula One were declining.
Lotus was already a Ford partner for their Indy 500 project, but Ford executives doubted the ability of Lotus to handle this new project. Colin Chapman probably had similar views as he asked a high price for his contribution and insisted that the car (which became the Lotus Europa) should be named a Lotus-Ford.
The Lola proposal was chosen, since Lola had used a Ford V8 engine in their mid-engined Lola Mk6 (also known as Lola GT). It was one of the most advanced racing cars of the time, and made a noted performance in Le Mans 1963, even though the car did not finish, due to low gearing and slow revving out on the Mulsanne Straight. However, Eric Broadley, Lola Cars' owner and chief designer, agreed on a short-term personal contribution to the project without involving Lola Cars.
The agreement with Broadley included a one-year collaboration between Ford and Broadley, and the sale of the two Lola Mk 6 chassis builds to Ford. To form the development team, Ford also hired the ex-Aston Martin team manager John Wyer. Ford Motor Co. engineer Roy Lunn was sent to England; he had designed the mid-engined Mustang I concept car powered by a 1.7 litre V4. Despite the small engine of the Mustang I, Lunn was the only Dearborn engineer to have some experience with a mid-engined car.
Overseen by Harley Copp, the team of Broadley, Lunn and Wyer began working on the new car at the Lola Factory in Bromley. At the end of 1963 the team moved to Slough, near Heathrow airport. Ford then established Ford Advanced Vehicles Ltd, a new subsidiary under the direction of Wyer, to manage the project.
The first chassis built by Abbey Panels of Coventry was delivered on March 16, 1963, with fibre-glass mouldings produced by Fibre Glass Engineering Ltd of Farnham. The first "Ford GT" the GT/101 was unveiled in England on April 1 and soon after exhibited in New York. Purchase price of the completed car for competition use was £5,200.
It was powered by the 4.2 L Fairlane engine with a Colotti transaxle, the same power plant was used by the Lola GT and the single-seater Lotus 29 that came in a highly controversial second at the Indy 500 in 1963. (A DOHC head design was used in later years at Indy. It won in 1965 in the Lotus 38.)
Racing history.
The Ford GT40 was first raced in May 1964 at the Nürburgring "1000 km race" where it retired with suspension failure after holding second place early in the event. Three weeks later at the 24 Hours of Le Mans, all three entries retired although the Ginther/Gregory car led the field from the second lap until its first pitstop. After a season-long series of dismal results under John Wyer in 1964, the program was handed over to Carroll Shelby after the 1964 Nassau race. The cars were sent directly to Shelby, still bearing the dirt and damage from the Nassau race. Carroll Shelby was noted for complaining that the cars were poorly maintained when he received them, but later information revealed the cars were packed up as soon as the race was over, and FAV never had a chance to clean, and organize the cars to be transported to Shelby.
Shelby's first victory came on their maiden race with the Ford program, with Ken Miles and Lloyd Ruby taking a Shelby American-entered Ford GT to victory in the Daytona 2000 in February 1965. The rest of the season, however, was a disaster.
The experience gained in 1964 and 1965 allowed the 7-litre Mk II to dominate the following year. In February, the GT40 again won at Daytona. This was the first year Daytona was run in the 24 Hour format and Mk II's finished 1st, 2nd, and 3rd. In March, at the 1966 12 Hours of Sebring, GT40's again took all three top finishes with the X-1 Roadster first, a Mk. II taking second, and a Mk. I in third. Then in June at the 24 Hours of Le Mans the GT40 achieved yet another 1-2-3 result.
The Le Mans finish, however, was clouded in controversy: in the final few hours, the Ford GT of New Zealanders Bruce McLaren and Chris Amon closely trailed the leading Ford GT driven by Englishman Ken Miles and New Zealander Denny Hulme. With a multi-million-dollar program finally on the very brink of success, Ford team officials faced a difficult choice. They could allow the drivers to settle the outcome by racing each other – and risk one or both cars breaking down or crashing. They could dictate a finishing order to the drivers – guaranteeing that one set of drivers would be extremely unhappy. Or they could arrange a tie, with the McLaren/Amon and Miles/Hulme cars crossing the line side-by-side.
The team chose the last and informed McLaren and Miles of the decision just before the two got in their cars for the final stint. Then, not long before the finish, the Automobile Club de l'Ouest (ACO), organizers of the Le Mans event, informed Ford that the geographical difference in starting positions would be taken into account at a close finish – meaning that the McLaren/Amon vehicle, which had started perhaps behind the Hulme-Miles car, would have covered slightly more ground over the 24 hours and would therefore be the winner. Secondly, Ford officials admitted later, the company's contentious relationship with Miles, its top contract driver, placed executives in a difficult position. They could reward an outstanding driver who had been at times extremely difficult to work with, or they could decide in favour of drivers (McLaren/Amon) with less commitment to the Ford program but who had been easier to deal with. Ford stuck with the orchestrated photo finish but Miles, deeply bitter over this decision after his dedication to the program, issued his own protest by suddenly slowing just yards from the finish and letting McLaren across the line first. Miles died in a testing accident in the J-car (later to become the Mk IV) at Riverside (CA) Raceway just two months later.
Miles' death occurred at the wheel of the Ford "J-car", an iteration of the GT40 that included several unique features. These included an aluminum honeycomb chassis construction and a "breadvan" body design that experimented with "kammback" aerodynamic theories. Unfortunately, the fatal Miles accident was attributed at least partly to the unproven aerodynamics of the J-car design, as well as the experimental chassis' strength. The team embarked on a complete redesign of the car, which became known as the Mk IV. The Mk IV, a newer design with a Mk II engine but a different chassis and a different body, won the following year at Le Mans (when four Mark IVs, three Mark IIs and three Mark Is raced). The high speeds achieved in that race caused a rule change, which already came in effect in 1968: the prototypes were limited to the capacity of to 3.0 litre, the same as in Formula One. This took out the V12-powered Ferrari 330P as well as the Chaparral and the Mk. IV.
If at least 50 cars had been built, sportscars like the GT40 and the Lola T70 were allowed, with a maximum of 5.0 L. John Wyer's revised 4.7 litre (bored to 4.9 litres, and o-rings cut and installed between the deck and head to prevent head gasket failure, a common problem found with the 4.7 engine) Mk I. It won the 24 hours of Le Mans race in 1968 against the fragile smaller prototypes. This result, added to four other round wins for the GT40, gave Ford victory in the 1968 International Championship for Makes. The GT40's intended 3.0 L replacement, the Ford P68, and Mirage cars proved a dismal failure. While facing more experienced prototypes and the new yet still unreliable 4.5 L flat-12 powered Porsche 917s, the 1969 24 Hours of Le Mans winners Jacky Ickx/Jackie Oliver managed to beat the remaining 3.0 litre Porsche 908 by just a few seconds with the already outdated GT40 Mk I (in the very car that had won in 1968 - the legendary GT40P/1075). Apart from brake wear in the Porsche and the decision not to change pads so close to the race end, the winning combination was relaxed driving by both GT40 drivers and heroic efforts at the right time by (at that time Le Mans' rookie) Ickx, who won Le Mans five more times in later years. In 1970, the revised Porsche 917 dominated, and the GT40 had become obsolete.
International titles.
In addition to four consecutive overall Le Mans victories, Ford also won the following four FIA international titles (at what was then unofficially known as the World Sportscar Championship) with the GT40:
Versions.
Mk I.
The Mk I was the original Ford GT40. Early prototypes were powered by 4.2 litre (255 cu.in) alloy V8 engines and production models were powered by 4.7 litre (289 cu.in) engines as used in the Ford Mustang. Five prototype models were built with roadster bodywork, including the Ford X-1.
The Mk.I was modified and run by John Wyer in 1968 and 1969, winning Le Mans in both those years and Sebring in 1969. The Mk.II and IV were both obsolete after the FIA had changed the rules to ban unlimited capacity engines; but the Mk.I, with its smaller engine, was legally able to race.
The X-1 was a roadster built to contest the Fall 1965 North American Pro Series, a forerunner of Can-Am, entered by the Bruce McLaren team and driven by Chris Amon. The car had an aluminum chassis built at Abbey Panels and was originally powered by a 4.7 liter (289ci) engine. The real purpose of this car was to test several improvements originating from Kar Kraft, Shelby and McLaren. Several gearboxes were used: a Hewland LG500 and at least one automatic gearbox. It was later upgraded to Mk II specifications with a 7.0 liter (427ci) engine and a standard four ratio Kar Kraft (subsidiary of Ford) gearbox, however the car kept specific features such as its open roof and lightweight aluminum chassis. The car went on to win the 12 Hours of Sebring in 1966. The X-1 was a one-off and was later ordered to be destroyed by customs officials.
Mk II.
The Mk.II was very similar in appearance to the Mk.I, but it actually was a bit different from its predecessor. It used the 7.0 litre FE (427 ci) engine from the Ford Galaxie, which was an engine used in NASCAR at the time—but the engine was modified for road course use. The car's chassis was more or less the same as the British-built Mk.I chassis, but it and other parts of the car had to be re-designed and modified by Carroll Shelby's organization in order to accommodate the larger and heavier 427 engine. A new Kar Kraft-built 4 speed gearbox (same as the one described above) was built to handle the more powerful engine, replacing the ZF 5-speed used in the Mk.I. This car is sometimes referred to as the "Ford Mk.II".
In 1966, the Mk.II began dominating the world famous 24 Hours of Le Mans race in France. In 1966 the Mk.II took Europe by surprise and beat Ferrari to finish 1-2-3 in the standings. Ford GT40's went on to win the race for four consecutive years (1966-1969).
For 1967, the Mk.II's were upgraded to "B" spec; they had re-designed bodywork and twin carburettors for an additional 15 hp. A batch of wrongly heat treated input shafts in the transaxles sidelined virtually every Ford in the race at Daytona, however, and Ferrari won 1-2-3. The Mk.IIB's were also used for Sebring and Le Mans that year, and also it won the Reims 12 Hours in France. For the Daytona 24 Hours, two Mk II models (chassis 1016 and 1047) had their engines re-badged as Mercury engines. Mercury was a Ford Motor Company division at that time, and Mercury's 427 was exactly the same engine as Ford's with different logos. Ford saw a good opportunity to advertise that division of the company.
Mk III.
The Mk III was a road-car only, of which 7 were built. The car had four headlamps, the rear part of the body was expanded to make room for luggage, the 4.7 litre engine was detuned to , the shock absorbers were softened, the shift lever was moved to the center and the car was available with the steering wheel on the left side of the car. As the Mk III looked significantly different from the racing models many customers interested in buying a GT40 for road use chose to buy a Mk I that was available from Wyer Ltd. Of the 7 MK III that were produced 4 were left hand drive. One of these examples is currently on display at the Petersen Automotive Museum.
J-car.
In an effort to develop a car with better aerodynamics and lighter weight, it was decided to retain the 7 litre engine, but redesign the rest of the car and ditch the Mk.I/Mk.II chassis. In order to bring the car more "in house" and lessening partnership with English firms, Ford Advanced Vehicles was sold to John Wyer and the new car was designed by Ford's studios and produced by Ford's subsidiary Kar Kraft under Ed Hull. There was also a partnership with the Brunswick Aircraft Corporation for expertise on the novel use of honeycomb aluminium panels bonded together to form a lightweight but rigid "tub". The car was designated as the J-car, as it was constructed to meet the new Appendix J regulations 
which were introduced by the FIA in 1966.
The first J-car was completed in March, 1966 and set the fastest time at the Le Mans trials that year. The tub weighed only , and the entire car weighed only , less than the Mk II. It was decided to run the MkIIs due to their proven reliability, however, and little or no development was done on the J-car for the rest of the season. Following Le Mans, the development program for the J-car was resumed, and a second car was built. During a test session at Riverside International Raceway in August 1966, with Ken Miles driving, the car suddenly went out of control at the end of Riverside's high-speed, 1-mile-long back straight. The honeycomb chassis did not live up to its design goal, shattering upon impact, bursting into flames and killing Miles. It was determined that the unique, flat-topped "bread van" aerodynamics of the car, lacking any sort of spoiler, were implicated in generating excess lift. Therefore a more conventional but significantly more aerodynamic body was designed for the subsequent development of the J-car which was officially known as the GT40 Mk IV. A total of nine cars were constructed with J-car chassis numbers although six were designated as Mk IVs and one as the G7A.
Mk IV.
The Mk IV was built around a reinforced J chassis powered by the same 7.0 L engine as the Mk II. Excluding the engine, gearbox, some suspension parts and the brakes from the Mk.II, the Mk.IV was totally different from other GT40s, using a specific chassis and specific bodywork. It was undoubtedly the most radical and American variant of all the GT40's over the years. As a direct result of the Miles accident, the team installed a NASCAR-style steel-tube roll cage in the Mk.IV, which made it much safer, but the roll cage was so heavy that it negated most of the weight saving of the then-highly advanced, radically innovative honeycomb-panel construction. The Mk. IV had a long, streamlined shape, which gave it exceptional top speed, crucial to do well at Le Mans in those days (a circuit made up almost entirely of straights)- the race it is was ultimately built for. A 2-speed automatic gearbox was tried, but during the extensive testing of the J-car in 1966 and 1967, it was decided that the 4-speed from the Mk.II would be retained. Dan Gurney often complained about the weight of the Mk.IV, since the car was heavier than the Ferrari 330 P4's. During practice at Le Mans in 1967, in an effort to preserve the highly stressed brakes, Gurney developed a strategy (also adopted by co-driver A.J. Foyt) of backing completely off the throttle several hundred yards before the approach to the Mulsanne hairpin and virtually coasting into the braking area. This technique saved the brakes, but the resulting increase in the car's recorded lap times during practice led to speculation within the Ford team that Gurney and Foyt, in an effort to compromise on chassis settings, had hopelessly "dialed out" their car. The car proved to be fastest in a straight line that year thanks to its streamlined aerodynamics- it did 212 mph on the 3.6 mile Mulsanne Straight.
The Mk. IV ran in only two races, the 1967 12 Hours of Sebring and the 1967 24 Hours of Le Mans and won both events. Only one Mk.IV was completed for Sebring; the pressure from Ford had been amped up considerably after Ford's humiliation at Daytona 2 months earlier. Mario Andretti and Bruce McLaren won Sebring, Dan Gurney and A.J. Foyt won Le Mans (Gurney and Foyt's car was the Mk.IV that was apparently least likely to win), where the Ford-representing Shelby-American and Holman & Moody teams showed up to Le Mans with 2 Mk.IV's each. The installation of the roll cage was ultimately credited by many with saving the life of Andretti, who crashed violently at the Esses during the 1967 Le Mans 24 Hours, but escaped with minor injuries.
Unlike the earlier Mk.I - III cars, which were built in England, the Mk.IVs were built in America by Kar Kraft. Le Mans 1967 remains the only truly all-American victory in Le Mans history - American drivers, team, chassis, engine and tires. A total of 6 Mk IVs were constructed. One of the Mk IVs was rebuilt to the Ford G7 in 1968, and used in the Can-Am series for 1969 and 1970, but with no success. This car is sometimes referred to as the "Ford Mk.IV".
Continuation Models, Replicas & Modernisations.
Several kit cars and replicas inspired by the Ford GT40 have been built. They are generally intended for assembly by the enthusiast in a home workshop or garage. There are two alternatives to the kit car approach, either continuation models (exact and licensed replicas true to the original GT40), or modernizations (replicas with upgraded components, ergonomics & trim for improved usability, drivability and performance).
Ford GT.
At the 1995 Detroit Auto Show, the Ford GT90 concept was shown and at the 2002 show, a new GT40 Concept was unveiled by Ford.
While similar in appearance to the original cars, it was bigger, wider, and three inches taller than the original 40 inches (1.02 m). Three production prototype cars were shown in 2003 as part of Ford's centenary, and delivery of the production Ford GT began in the fall of 2004. The Ford GT was assembled in the Ford Wixom plant and painted by Saleen, Incorporated at their Saleen Special Vehicles plant in Troy, Michigan, USA.
A British company, Safir Engineering, who made continuation GT40s in the 1980s owned the GT40 trademark at that time, and when they completed production, they sold the excess parts, tooling, design, and trademark to a small American company called Safir GT40 Spares based in Ohio. Safir GT40 Spares licensed the use of the GT40 trademark to Ford for the initial 2002 show car, but when Ford decided to make the production vehicle, negotiations between the two failed, and as a result the new Ford GT does not wear the badge GT40. Safir GT40 Spares asked $40 million for the rights, which Ford declined.
Bob Wood, one of three partners who own Safir GT40 Spares, said: "When we talked with Ford, they asked what we wanted. We said that Ford owns Beanstalk in New York, the company that licenses the Blue Oval for Ford on such things as T-shirts. Since Beanstalk gets 7.5 percent of the retail cost of the item for licensing the name, we suggested 7.5 percent on each GT40 sold." At the then-estimated $125,000 per copy, 7.5% of 4,500 vehicles would have totalled approximately $42,187,500. Later models or prototypes have also been called the Ford GT but have had different numbering on them such as the Ford GT90 or the Ford GT70. The GT40 name is currently licensed to Hi-Tech Automotive in South Africa, the manufacturer who builds Superformance.
A second-generation Ford GT was unveiled at the 2015 North American International Auto Show. It features a 3.5L twin-turbocharged V6 engine, carbon fiber monocoque and body panels, pushrod suspension and active aerodynamics. It will compete in the FIA World Endurance Championship and the United SportsCar Championship.

</doc>
<doc id="11835" url="https://en.wikipedia.org/wiki?curid=11835" title="Glycine">
Glycine

Glycine (abbreviated as Gly or G) is the smallest of the 20 amino acids commonly found in proteins, and indeed is the smallest possible (having a hydrogen substituent as its side-chain). The formula is NHCHCOOH. Its codons are GGU, GGC, GGA, GGG of the genetic code.
Glycine is a colourless, sweet-tasting crystalline solid. It is unique among the proteinogenic amino acids in that it is achiral. It can fit into hydrophilic or hydrophobic environments , due to its minimal side chain of only one hydrogen atom.
History and etymology.
Glycine was first isolated from gelatin in 1820. The name comes from the ancient Greek word "γλυκύς" "sweet tasting".
Production.
Glycine was discovered in 1820, by Henri Braconnot who boiled a gelatinous object with sulfuric acid.
Glycine is manufactured industrially by treating chloroacetic acid with ammonia:
About 15 million kg are produced annually in this way.
In the USA (by GEO Specialty Chemicals, Inc.) and in Japan (by Showa Denko KK), glycine is produced via the Strecker amino acid synthesis.
There are two producers of glycine in the United States: Chattem Chemicals, Inc., a subsidiary of Mumbai-based Sun Pharmaceutical, and GEO Specialty Chemicals, Inc., which purchased the glycine and naphthalene sulfonate production facilities of Hampshire Chemical Corp, a subsidiary of Dow Chemical.
Chattem's manufacturing process ("MCA" process) occurs in batches and results in a finished product with some residual chloride but no sulfate, while GEO’s manufacturing process is considered a semi-batch process and results in a finished product with some residual sulfate but no chloride.
Glycine is also cogenerated as an impurity in the synthesis of EDTA, arising from reactions of the ammonia coproduct.<ref name="Ullmann/Roger">Hart, J. Roger (2005) "Ethylenediaminetetraacetic Acid and Related Chelating Agents" in "Ullmann's Encyclopedia of Industrial Chemistry", Wiley-VCH, Weinheim. </ref>
Acid-base properties and structures.
In aqueous solution, glycine itself is amphoteric: at low pH the molecule can be protonated with a pK of about 2.4 and at high pH it loses a proton with a pK of about 9.6 (precise values of pK depend on temperature and ionic strength). The nature of glycine in aqueous solution has been investigated by theoretical methods. In solution the ratio of concentrations of the two isomers is independent of both the analytical concentration and of pH. This ratio is simply the equilibrium constant for isomerization.
Both isomers of glycine have been observed by microwave spectroscopy in the gas phase. The solid-state structure has been analyzed in detail.
Metabolism.
Biosynthesis.
Glycine is not essential to the human diet, as it is biosynthesized in the body from the amino acid serine, which is in turn derived from 3-phosphoglycerate, but the metabolic capacity for glycine biosynthesis does not satisfy the need for collagen synthesis. In most organisms, the enzyme serine hydroxymethyltransferase catalyses this transformation via the cofactor pyridoxal phosphate:
In the liver of vertebrates, glycine synthesis is catalyzed by glycine synthase (also called glycine cleavage enzyme). This conversion is readily reversible:
Glycine is coded by codons GGU, GGC, GGA and GGG. Most proteins incorporate only small quantities of glycine. A notable exception is collagen, which contains about 35% glycine.
Degradation.
Glycine is degraded via three pathways. The predominant pathway in animals and plants involves the glycine cleavage enzyme:
In the second pathway, glycine is degraded in two steps. The first step is the reverse of glycine biosynthesis from serine with serine hydroxymethyl transferase. Serine is then converted to pyruvate by serine dehydratase.
In the third pathway of glycine degradation, glycine is converted to glyoxylate by D-amino acid oxidase. Glyoxylate is then oxidized by hepatic lactate dehydrogenase to oxalate in an NAD-dependent reaction.
The half-life of glycine and its elimination from the body varies significantly based on dose. In one study, the half-life was between 0.5 and 4.0 hours. 
Physiological function.
The principal function of glycine is as a precursor to proteins, such as its periodically repeated role in the formation of the collagen helix in conjunction with Hydroxyproline. It is also a building block to numerous natural products.
As a biosynthetic intermediate.
In higher eukaryotes, δ-aminolevulinic acid, the key precursor to porphyrins, is biosynthesized from glycine and succinyl-CoA by the enzyme ALA synthase. Glycine provides the central CN subunit of all purines.
As a neurotransmitter.
Glycine is an inhibitory neurotransmitter in the central nervous system, especially in the spinal cord, brainstem, and retina. When glycine receptors are activated, chloride enters the neuron via ionotropic receptors, causing an Inhibitory postsynaptic potential (IPSP). Strychnine is a strong antagonist at ionotropic glycine receptors, whereas bicuculline is a weak one. Glycine is a required co-agonist along with glutamate for NMDA receptors. In contrast to the inhibitory role of glycine in the spinal cord, this behaviour is facilitated at the (NMDA) glutamatergic receptors which are excitatory. The of glycine is 7930 mg/kg in rats (oral), and it usually causes death by hyperexcitability.
A 2014 review on sleep aids noted that glycine can improve sleep quality, citing a study in which 3 grams of glycine before bedtime improved sleep quality in humans.
Glycine has also been positively tested as an add-on treatment for schizophrenia.
Uses.
In the US, glycine is typically sold in two grades: United States Pharmacopeia (“USP”), and technical grade. Most glycine is manufactured as USP grade material for diverse uses. USP grade sales account for approximately 80 to 85 percent of the U.S. market for glycine.
Animal and human foods.
Other markets for USP grade glycine include its use an additive in pet food and animal feed. For humans, glycine is sold as a sweetener/taste enhancer. Certain food supplements and protein drinks contain glycine. Certain drug formulations include glycine to improve gastric absorption of the drug.
Cosmetics and miscellaneous applications.
Glycine serves as a buffering agent in antacids, analgesics, antiperspirants, cosmetics, and toiletries.
Many miscellaneous products use glycine or its derivatives, such as the production of rubber sponge products, fertilizers, metal complexants.
Chemical feedstock.
Glycine is an intermediate in the synthesis of a variety of chemical products. It is used in the manufacture of the herbicide glyphosate.
Research and Development.
Glycine is a significant component of some solutions used in the SDS-PAGE method of protein analysis. 
It serves as a buffering agent, maintaining pH and preventing sample damage during electrophoresis. 
Glycine is also used to remove protein-labelling antibodies from Western Blot membranes to enable the probing of numerous proteins of interest from SDS-PAGE gel. This allows more data to be drawn from the same specimen, increasing the reliability of the data, reducing the amount of sample processing, and number of samples required. This process is known as 'stripping'.
Anti-aging properties.
Glycine treatment may help reverse the age-associated defects in human fibroblast. Two genes that regulate mitochondria, GCAT and SHMT2, were found to affect age-associated mitochondrial defects. 
By changing the regulation of these genes, researchers were able to restore mitochondrial function or induce more defects in the fibroblast cell lines. In an interesting finding, the addition of glycine for 10 days to the culture medium of the 97-year-old fibroblast cell line restored its respiratory function.
Presence in space.
The detection of glycine in the interstellar medium has been debated. In 2008, the glycine-like molecule aminoacetonitrile was discovered in the Large Molecule Heimat, a giant gas cloud near the galactic center in the constellation Sagittarius by the Max Planck Institute for Radio Astronomy. In 2009, glycine sampled in 2004 from comet Wild 2 by the NASA spacecraft Stardust was confirmed. This is the first discovery of glycine outside the Earth, however, glycine was identified in the Murchison meteorite in 1970. That mission's results bolstered the theory of panspermia, which claims that the "building-blocks" of life are widespread throughout the universe.
Further reading.
On attempts to detect glycine in interstellar medium

</doc>
<doc id="11839" url="https://en.wikipedia.org/wiki?curid=11839" title="Wikipedia:GNUStufF">
Wikipedia:GNUStufF


</doc>
<doc id="11844" url="https://en.wikipedia.org/wiki?curid=11844" title="GeekSpeak">
GeekSpeak

GeekSpeak is a radio program on the Central Coast of California, broadcast weekly by KUSP in Santa Cruz, California and distributed by podcast by NPR.
GeekSpeak was created and originally broadcast by Chris Neklason and Mark Hanford of Cruzio originally airing in March 1998.
Currently, the host is Lyle Troxell, who took over in September 2000.
GeekSpeak episodes have been distributed as an archive on the internet since 2001. The podcast of the program is now distributed by NPR. 
The program's slogan is "Bridging the gap between geeks and the rest of humanity".
Broadcasts usually conclude with call-in advice, commentary and discussion by telephone and email. A worldwide fanbase has developed and show streams have been downloaded in excess of 100,000 times. 

</doc>
<doc id="11846" url="https://en.wikipedia.org/wiki?curid=11846" title="Guitar">
Guitar

The guitar is a popular musical instrument classified as a string instrument with anywhere from 4 to 18 strings, usually having 6. The sound is projected either acoustically or through electrical amplification (for an acoustic guitar or an electric guitar, respectively). It is typically played by strumming or plucking the strings with the right hand while fretting (or pressing against the frets) the strings with the fingers of the left hand. The guitar is a type of chordophone, traditionally constructed from wood and strung with either gut, nylon or steel strings and distinguished from other chordophones by its construction and tuning. The modern guitar was preceded by the gittern, the vihuela, the four-course Renaissance guitar, and the five-course baroque guitar, all of which contributed to the development of the modern six-string instrument.
There are three main types of modern acoustic guitar: the classical guitar (nylon-string guitar), the steel-string acoustic guitar, and the archtop guitar. The tone of an acoustic guitar is produced by the strings's vibration, amplified by the body of the guitar, which acts as a resonating chamber. The classical guitar is often played as a solo instrument using a comprehensive finger-picking technique. The term "finger-picking" can also refer to a specific tradition of folk, blues, bluegrass, and country guitar playing in the United States.
Electric guitars, introduced in the 1930s, use an amplifier that can electronically manipulate and shape the tone. Early amplified guitars employed a hollow body, but a solid body was eventually found more suitable, as it was less prone to feedback. Electric guitars have had a continuing profound influence on popular culture.
The guitar is used in a wide variety of musical genres worldwide. It is recognized as a primary instrument in genres such as blues, bluegrass, country, flamenco, folk, jazz, jota, mariachi, metal, punk, reggae, rock, soul, and many forms of pop.
History.
Before the development of the electric guitar and the use of synthetic materials, a guitar was defined as being an instrument having "a long, fretted neck, flat wooden soundboard, ribs, and a flat back, most often with incurved sides." The term is used to refer to a number of chordophones that were developed and used across Europe, beginning in the 12th century and, later, in the Americas. A 3,300-year-old stone carving of a Hittite bard playing a stringed instrument is the oldest iconographic representation of a chordophone and clay plaques from Babylonia show people playing an instrument that has a strong resemblance to the guitar, indicating a possible Babylonian origin for the guitar.
The modern word "guitar," and its antecedents, has been applied to a wide variety of chordophones since classical times and as such causes confusion. The English word "guitar," the German "," and the French "" were all adopted from the Spanish "," which comes from the Andalusian Arabic "," "," which in turn came from the Ancient Greek "."
The term "guitar" is descended from the Latin word "cithara," but the modern guitar itself is generally not believed to have descended from the Roman instrument. Many influences are cited as antecedents to the modern guitar. Although the development of the earliest "guitars" is lost in the history of medieval Spain, two instruments are commonly cited as their most influential predecessors, the European lute and its cousin, the four-string oud; the latter was brought to Iberia by the Moors in the 8th century.
At least two instruments called "guitars" were in use in Spain by 1200: the ' (Latin guitar) and the so-called ' (Moorish guitar). The guitarra moresca had a rounded back, wide fingerboard, and several sound holes. The guitarra Latina had a single sound hole and a narrower neck. By the 14th century the qualifiers "moresca" or "morisca" and "latina" had been dropped, and these two cordophones were simply referred to as guitars.
The Spanish vihuela, called in Italian the "", a guitar-like instrument of the 15th and 16th centuries, is widely considered to have been the single most important influence in the development of the baroque guitar. It had six courses (usually), lute-like tuning in fourths and a guitar-like body, although early representations reveal an instrument with a sharply cut waist. It was also larger than the contemporary four-course guitars. By the 16th century, the vihuela's construction had more in common with the modern guitar, with its curved one-piece ribs, than with the viols, and more like a larger version of the contemporary four-course guitars. The vihuela enjoyed only a relatively short period of popularity in Spain and Italy during an era dominated elsewhere in Europe by the lute; the last surviving published music for the instrument appeared in 1576.
Meanwhile, the five-course baroque guitar, which was documented in Spain from the middle of the 16th century, enjoyed popularity, especially in Spain, Italy and France from the late 16th century to the mid-18th century. In Portugal, the word "viola" referred to the guitar, as "guitarra" meant the "Portuguese guitar", a variety of cittern.
Types.
Guitars can be divided into two broad categories, acoustic and electric:
Acoustic guitars.
Acoustic guitars form several notable subcategories within the acoustic guitar group: classical and flamenco guitars; steel-string guitars, which include the flat-topped, or "folk", guitar; twelve-string guitars; and the arched-top guitar. The acoustic guitar group also includes unamplified guitars designed to play in different registers, such as the acoustic bass guitar, which has a similar tuning to that of the electric bass guitar.
Renaissance and Baroque guitars.
Renaissance and Baroque guitars are the gracile ancestors of the modern classical and flamenco guitar. They are substantially smaller, more delicate in construction, and generate less volume. The strings are paired in courses as in a modern 12-string guitar, but they only have four or five courses of strings rather than six single strings normally used now. They were more often used as rhythm instruments in ensembles than as solo instruments, and can often be seen in that role in early music performances. (Gaspar Sanz's "Instrucción de Música sobre la Guitarra Española" of 1674 contains his whole output for the solo guitar.) Renaissance and Baroque guitars are easily distinguished because the Renaissance guitar is very plain and the Baroque guitar is very ornate, with ivory or wood inlays all over the neck and body, and a paper-cutout inverted "wedding cake" inside the hole.
Classical guitars.
Classical guitars, also known as "Spanish" guitars, are typically strung with nylon strings, plucked with the fingers, played in a seated position and are used to play a diversity of musical styles including classical music. The classical guitar's wide, flat neck allows the musician to play scales, arpeggios, and certain chord forms more easily and with less adjacent string interference than on other styles of guitar. Flamenco guitars are very similar in construction, but they are associated with a more percussive tone.
In Portugal, the same instrument is often used with steel strings particularly in its role within fado music. The guitar is called viola, or violão in Brazil, where it is often used with an extra seventh string by choro musicians to provide extra bass support.
In Mexico, the popular mariachi band includes a range of guitars, from the small "requinto" to the "guitarrón," a guitar larger than a cello, which is tuned in the bass register. In Colombia, the traditional quartet includes a range of instruments too, from the small "bandola" (sometimes known as the Deleuze-Guattari, for use when traveling or in confined rooms or spaces), to the slightly larger tiple, to the full-sized classical guitar. The requinto also appears in other Latin-American countries as a complementary member of the guitar family, with its smaller size and scale, permitting more projection for the playing of single-lined melodies. Modern dimensions of the classical instrument were established by the Spaniard Antonio de Torres Jurado (1817–1892).
Extended-range classical guitars.
An extended-range classical guitar is a classical guitar with more than 6 strings, usually up to 13.
Flamenco guitars.
The flamenco guitar is similar to the classical guitar, but of lighter construction, with a cypress body and spruce top. Tuning pegs like those of a violin are traditional, although many modern flamenco guitars have machine heads. A distinguishing feature of all flamenco guitars is the tapping plates ("golpeadores") glued to the table, to protect them against the taps with the fingernails that are an essential feature of the flamenco style.
Flat-top guitars.
Flat-top or steel-string guitars are similar to the classical guitar, however, within the varied sizes of the steel-stringed guitar the body size is usually significantly larger than a classical guitar, and has a narrower, reinforced neck and stronger structural design. The robust X-bracing typical of the steel-string was developed in the 1840s by German-American luthiers, of whom Christian Friedrich "C. F." Martin is the best known. Originally used on gut-strung instruments, the strength of the system allowed the guitar to withstand the additional tension of steel strings when this fortunate combination arose in the early 20th century. The steel strings produce a brighter tone, and according to many players, a louder sound. The acoustic guitar is used in many kinds of music including folk, country, bluegrass, pop, jazz, and blues. Many variations are possible from the roughly classical-sized OO and Parlour to the large Dreadnought (the most commonly available type) and Jumbo. Ovation makes a modern variation, with a rounded back/side assembly molded from artificial materials.
Archtop guitars.
Archtop guitars are steel-string instruments in which the top (and often the back) of the instrument are carved, from a solid billet, into a curved, rather than a flat, shape. This violin-like construction is usually credited to the American Orville Gibson (1856–1918). Lloyd Loar of the Gibson Mandolin-Guitar Mfg. Co introduced the violin-inspired "F"-shaped hole design now usually associated with archtop guitars, after designing a style of mandolin of the same type. The typical archtop guitar has a large, deep, hollow body whose form is much like that of a mandolin or a violin-family instrument. Nowadays, most archtops are equipped with magnetic pickups, and they are therefore both acoustic and electric. F-hole archtop guitars were immediately adopted, upon their release, by both jazz and country musicians, and have remained particularly popular in jazz music, usually with flatwound strings.
Selmer-Maccaferri guitars.
The Selmer-Maccaferri guitar is usually played by those who follow the style of Django Reinhardt. It is an unusual-looking instrument, distinguished by a fairly large body with squarish bouts, and either a "D"-shaped or longitudinal oval soundhole. The strings are gathered at the tail like an archtop guitar, but the top is formed from thin spruce (like a flat-top or classical) forced into a shallow dome. It also has a wide fingerboard and slotted head like a nylon-string guitar. The loud volume and penetrating tone make it suitable for single-note soloing and it is frequently employed as a lead instrument in gypsy swing.
Resonator, resophonic or Dobro guitars.
All three principal types of resonator guitars were invented by the Slovak-American John Dopyera (1893–1988) for the National and Dobro (Dopyera Brothers) companies. Similar to the flat top guitar in appearance, but with a body that may be made of brass, nickel-silver, or steel as well as wood, the sound of the resonator guitar is produced by one or more aluminum resonator cones mounted in the middle of the top. The physical principle of the guitar is therefore similar to the loudspeaker. The original purpose of the resonator was to produce a very loud sound; this purpose has been largely superseded by electrical amplification, but the resonator guitar is still played because of its distinctive tone. Resonator guitars may have either one or three resonator cones. The method of transmitting sound resonance to the cone is either a "biscuit" bridge, made of a small piece of hardwood at the vertex of the cone (Nationals), or a "spider" bridge, made of metal and mounted around the rim of the (inverted) cone (Dobros). Three-cone resonators always use a specialized metal bridge. The type of resonator guitar with a neck with a square cross-section—called "square neck" or "Hawaiian"—is usually played face up, on the lap of the seated player, and often with a metal or glass slide. The round neck resonator guitars are normally played in the same fashion as other guitars, although slides are also often used, especially in blues.
Twelve-string guitars.
The twelve-string guitar usually has steel strings, and it is widely used in folk music, blues, and rock and roll. Rather than having only six strings, the 12-string guitar has six courses made up of two strings each, like a mandolin or lute. The highest two courses are tuned in unison, while the others are tuned in octaves. The 12-string guitar is also made in electric forms. The chime-like sound of the 12-string electric guitar was the basis of jangle pop.
Russian guitars.
These seven-string acoustic guitars were the norm for Russian guitarists throughout the 19th and well into the 20th centuries. The Russian guitar is traditionally tuned to open G major.
Acoustic bass guitars.
The acoustic bass guitar is a bass instrument with a hollow wooden body similar to, though usually somewhat larger than, that of a 6-string acoustic guitar. Like the traditional electric bass guitar and the double bass, the acoustic bass guitar commonly has four strings, which are normally tuned E-A-D-G, an octave below the lowest four strings of the 6-string guitar, which is the same tuning pitch as an electric bass guitar. It can, more rarely, be found with 5 or 6 strings, which provides a wider range of notes to be played with less movement up and down the neck.
Guitarrón.
The "guitarrón" is a very large, deep-bodied Mexican six-string acoustic bass played in mariachi bands. It is fretless with heavy gauge nylon strings, and is usually played by doubling notes at the octave, which is facilitated by the unusual tuning of 
Tenor guitars.
A number of classical guitarists call the Niibori prime guitar a "Tenor Guitar" on the grounds that it sits in pitch between the alto and the bass. Elsewhere the name is taken for a four-string guitar with a scale length of 23" (585 mm)—about the same as a Terz Guitar. The tenor guitar is tuned in fifths, C G D A, as is the tenor banjo and the cello. It is generally accepted that the tenor guitar was created to allow a tenor banjo player to follow the fashion as it evolved from Dixieland Jazz towards the more progressive Jazz that featured guitar. It allows a tenor banjo player to provide a guitar-based rhythm section with little to learn. A small minority of players (such as Nick Reynolds of the Kingston Trio) close tuned the instrument to D G B E to produce a deep instrument that could be played with the four-note chord shapes found on the top four strings of the guitar or ukulele. The deep pitch warrants the wide-spaced chords that the banjo tuning permits, and the close tuned tenor does not have the same full, clear sound.
Harp guitars.
Harp guitars are difficult to classify as there are many variations within this type of guitar. They are typically rare and uncommon in the popular music scene. Most consist of a regular guitar, plus additional "harp" strings strung above the six normal strings. The instrument is usually acoustic and the harp strings are usually tuned to lower notes than the guitar strings, for an added bass range. Normally there is neither fingerboard nor frets behind the harp strings. Some harp guitars also feature much higher pitch strings strung below the traditional guitar strings. The number of harp strings varies greatly, depending on the type of guitar and also the player's personal preference. The Pikasso guitar; 4 necks, 2 sound holes, 42 strings and also the Oracle Harp Sympitar; 24 strings (with 12 sympathetic strings protruding through the neck) are modern examples.
Extended-range guitars.
For well over a century guitars featuring seven, eight, nine, ten or more strings have been used by a minority of guitarists as a means of increasing the range of pitch available to the player. Usually, it is bass strings that are added. Classical guitars with an extended range are useful for playing lute repertoire, some of which was written for lutes with more than six courses. A typical example is the modern 11-string "archguitar," invented and played by Peter Blanchette.
Guitar battente.
The battente, called "chitarra battente" in Italian, is generally smaller than a classical guitar and usually played with four or five single or double course metal strings of equal gauge. It is traditionally played in Southern Italy in the regions of Calabria, Campania, Basilicata, and Apulia to accompany the voice as well as dancing (tarantella, or pizzica). Depending on the region it is from, the battente has either a flat back (fondo piato) or a rounded back (fondo bombato). The term "battente", which means "to beat" in Italian, has do with the style the guitar is generally played in, which is principally as a rhythm instrument. It is very likely that the battente is derived from the baroque guitar, of which is shares many characteristics.
Electric guitars.
Electric guitars can have solid, semi-hollow, or hollow bodies; solid bodies produce little sound without amplification. Electromagnetic pickups convert the vibration of the steel strings into signals, which are fed to an amplifier through a patch cable or radio transmitter. The sound is frequently modified by other electronic devices (effects units) or the natural distortion of valves (vacuum tubes) or the pre-amp in the amplifier. There are two main types of magnetic pickups, single- and double-coil (or humbucker), each of which can be passive or active. The electric guitar is used extensively in jazz, blues, R & B, and rock and roll. The first successful magnetic pickup for a guitar was invented by George Beauchamp, and incorporated into the 1931 Ro-Pat-In (later Rickenbacker) "Frying Pan" lap steel; other manufacturers, notably Gibson, soon began to install pickups in archtop models. After World War II the completely solid-body electric was popularized by Gibson in collaboration with Les Paul, and independently by Leo Fender of Fender Music. The lower fretboard action (the height of the strings from the fingerboard), lighter (thinner) strings, and its electrical amplification lend the electric guitar to techniques less frequently used on acoustic guitars. These include tapping, extensive use of legato through pull-offs and hammer-ons (also known as slurs), pinch harmonics, volume swells, and use of a tremolo arm or effects pedals.
Solid body seven-strings were popularized in the 1980s and 1990s. Other artists go a step further, by using an eight-string guitar with two extra low strings. Although the most common seven-string has a low B string, Roger McGuinn (of The Byrds and Rickenbacker) uses an octave G string paired with the regular G string as on a 12-string guitar, allowing him to incorporate chiming 12-string elements in standard six-string playing. In 1982 Uli Jon Roth developed the "Sky Guitar", with a vastly extended number of frets, which was the first guitar to venture into the upper registers of the violin. Roth's seven-string and 33-fret "Mighty Wing" guitar features a six-octave range.
The electric bass guitar is similar in tuning to the traditional double bass viol. Hybrids of acoustic and electric guitars are also common. There are also more exotic varieties, such as guitars with two, three, or rarely four necks, all manner of alternate string arrangements, fretless fingerboards (used almost exclusively on bass guitars, meant to emulate the sound of a stand-up bass), 5.1 surround guitar, and such.
Some electric guitar and electric bass guitar models feature piezoelectric pickups, which function as transducers to provide a sound closer to that of an acoustic guitar with the flip of a switch or knob, rather than switching guitars. Those that combine piezoelectric pickups and magnetic pickups are sometimes known as hybrid guitars.
Construction and components.
Handedness.
Modern guitars can be constructed to suit both left- and right-handed players. Normally, the dominant hand (in most people, the right hand) is used to pluck or strum the strings. This is similar to the convention of the violin family of instruments where the right hand controls the bow.
Left-handed players sometimes choose an opposite-handed (mirror) instrument, although some play in a standard-handed manner, others play a standard-handed guitar reversed, and still others (for example Jimi Hendrix) play a standard-handed guitar strung in reverse. This last configuration differs from a true opposite handed guitar in that the saddle is normally angled in such a way that the bass strings are slightly longer than the treble strings to improve intonation. Reversing the strings therefore reverses the relative orientation of the saddle (negatively affecting intonation), although in Hendrix's case, this is believed to have been an important element in his unique sound.
Headstock.
The headstock is located at the end of the guitar neck farthest from the body. It is fitted with machine heads that adjust the tension of the strings, which in turn affects the pitch. The traditional tuner layout is "3+3", in which each side of the headstock has three tuners (such as on Gibson Les Pauls). In this layout, the headstocks are commonly symmetrical. Many guitars feature other layouts, including six-in-line tuners (featured on Fender Stratocasters) or even "4+2" (e.g. Ernie Ball Music Man). Some guitars (such as Steinbergers) do not have headstocks at all, in which case the tuning machines are located elsewhere, either on the body or the bridge.
Nut.
The nut is a small strip of bone, plastic, brass, corian, graphite, stainless steel, or other medium-hard material, at the joint where the headstock meets the fretboard. Its grooves guide the strings onto the fretboard, giving consistent lateral string placement. It is one of the endpoints of the strings' vibrating length. It must be accurately cut, or it can contribute to tuning problems due to string slippage or string buzz. To reduce string friction in the nut, which can adversely affect tuning stability, some guitarists fit a roller nut. Some instruments use a zero fret just in front of the nut. In this case the nut is used only for lateral alignment of the strings, the string height and length being dictated by the zero fret.
Fretboard.
The fretboard, also called the "fingerboard", is a piece of wood embedded with metal frets that comprises the top of the neck. It is flat on classical guitars and slightly curved crosswise on acoustic and electric guitars. The curvature of the fretboard is measured by the fretboard radius, which is the radius of a hypothetical circle of which the fretboard's surface constitutes a segment. The smaller the fretboard radius, the more noticeably curved the fretboard is. Most modern guitars feature a 12" neck radius, while older guitars from the 1960s and 1970s usually feature a 6-8" neck radius. Pinching a string against a fret on fretboard effectively shortens the vibrating length of the string, producing a higher pitch. Fretboards are most commonly made of rosewood, ebony, maple, and sometimes manufactured using composite materials such as HPL or resin. See the section "Neck" below for the importance of the length of the fretboard in connection to other dimensions of the guitar.
The fingerboard plays an essential role in the treble tone for acoustic guitars. The quality of vibration of the fingerboard is the principal characteristic for generating the best treble tone. For that reason, ebony wood is better, but because of high use, ebony has become rare and extremely expensive. Most guitar manufacturers have adopted rosewood instead of ebony.
The acoustic guitar neck is built in two pieces. The neck is usually made of mahogany and the fingerboard made of rosewood. Ebony is reserved for expensive guitars.
Many years later, Fender developed a one piece neck for their electric guitars. Maple was the wood used because the quality of vibration was not necessary, because the sound is generated by the pickups. For that reason, there are two kinds of neck, a one piece neck in maple (for electric guitars) and a 2 piece neck, generally mahogany or maple for the neck and rosewood for the fingerboard. However, some guitar manufacturers have adopted maple for the neck on acoustic guitars as well.
Frets.
Frets are metal strips (usually nickel alloy or stainless steel) embedded along the fretboard and located at exact points that divide the scale length in accordance with a specific mathematical formula. Pressing a string against a fret determines the strings's vibrating length and therefore its resultant pitch. The pitch of each consecutive fret is defined at a half-step interval on the chromatic scale. Standard classical guitars have 19 frets and electric guitars between 21 and 24 frets, although guitars have been made with as many as 27 frets.
Frets are laid out to accomplish an equal tempered division of the octave. Each set of twelve frets represents an octave. The twelfth fret divides the scale length exactly into two halves, and the 24th fret position divides one of those halves in half again. The ratio of the spacing of two consecutive frets is formula_1 (twelfth root of two). In practice, luthiers determine fret positions using the constant 17.817—-an approximation to 1/(1-1/formula_1). If the nth fret is a distance x from the bridge, then the distance from the (n+1)th fret to the bridge is x-(x/17.817).
Frets are available in several different gauges and can be fitted according to player preference. Among these are "jumbo" frets, which have much thicker gauge, allowing for use of a slight vibrato technique from pushing the string down harder and softer. "Scalloped" fretboards, where the wood of the fretboard itself is "scooped out" between the frets, allow a dramatic vibrato effect. Fine frets, much flatter, allow a very low string-action but require that other conditions, such as curvature of the neck, be well-maintained to prevent buzz.
On steel-string guitars, frets are eventually bound to wear down; when this happens, frets can be replaced or, to a certain extent, leveled, polished, recrowned, or reshaped as required.
Truss rod.
The truss rod is a metal rod that runs along the inside of the neck. It is used to correct changes to the neck's curvature caused by aging of the neck timbers, changes in humidity, or to compensate for changes in the tension of strings. The tension of the rod and neck assembly is adjusted by a hex nut or an allen-key bolt on the rod, usually located either at the headstock, sometimes under a cover, or just inside the body of the guitar underneath the fretboard and accessible through the sound hole. Some truss rods can only be accessed by removing the neck. The truss rod counteracts the immense amount of tension the strings place on the neck, bringing the neck back to a straighter position. Turning the truss rod clockwise tightens it, counteracting the tension of the strings and straightening the neck or creating a backward bow. Turning the truss rod counter-clockwise loosens it, allowing string tension to act on the neck and creating a forward bow. Adjusting the truss rod affects the intonation of a guitar as well as the height of the strings from the fingerboard, called the action. Some truss rod systems, called "double action" truss systems, tighten both ways, pushing the neck both forward and backward (standard truss rods can only release to a point beyond which the neck is no longer compressed and pulled backward). The artist and luthier Irving Sloane pointed out, in his book "Steel-String Guitar Construction," that truss rods are intended primarily to remedy concave bowing of the neck, but cannot correct a neck with "back bow" or one that has become twisted.
Classical guitars do not require truss rods, as their nylon strings exert a lower tensile force with lesser potential to cause structural problems. However, their necks are often reinforced with a strip of harder wood, such as an ebony strip that runs down the back of a cedar neck. There is no tension adjustment on this form of reinforcement.
Inlays.
Inlays are visual elements set into the exterior surface of a guitar. The typical locations for inlay are on the fretboard, headstock, and on acoustic guitars around the soundhole, known as the rosette. Inlays range from simple plastic dots on the fretboard to intricate works of art covering the entire exterior surface of a guitar (front and back). Some guitar players have used LEDs in the fretboard to produce unique lighting effects onstage.
Fretboard inlays are most commonly shaped like dots, diamond shapes, parallelograms, or large blocks in between the frets. Dots are usually inlaid into the upper edge of the fretboard in the same positions, small enough to be visible only to the player. These usually appear on the odd numbered frets, but also on the 12th fret (the one octave mark) instead of the 11th and 13th frets. Some older or high-end instruments have inlays made of mother of pearl, abalone, ivory, colored wood or other exotic materials and designs. Simpler inlays are often made of plastic or painted. High-end classical guitars seldom have fretboard inlays as a well-trained player is expected to know his or her way around the instrument.
In addition to fretboard inlay, the headstock and soundhole surround are also frequently inlaid. The manufacturer's logo or a small design is often inlaid into the headstock. Rosette designs vary from simple concentric circles to delicate fretwork mimicking the historic rosette of lutes. Bindings that edge the finger and sound boards are sometimes inlaid. Some instruments have a filler strip running down the length and behind the neck, used for strength or to fill the cavity through which the truss rod was installed in the neck.
Elaborate inlays are a decorative feature of many limited edition, high-end and custom-made guitars. Guitar manufacturers often release such guitars to celebrate significant or historic milestones.
Neck.
A guitar's frets, fretboard, tuners, headstock, and truss rod, all attached to a long wooden extension, collectively constitute its neck. The wood used to make the fretboard usually differs from the wood in the rest of the neck. The bending stress on the neck is considerable, particularly when heavier gauge strings are used (see Tuning), and the ability of the neck to resist bending (see Truss rod) is important to the guitar's ability to hold a constant pitch during tuning or when strings are fretted. The rigidity of the neck with respect to the body of the guitar is one determinant of a good instrument versus a poor one. The shape of the neck can also vary, from a gentle "C" curve to a more pronounced "V" curve. There are many different types of neck profiles available, giving the guitarist many options. Some aspects to consider in a guitar neck may be the overall width of the fretboard, scale (distance between the frets), the neck wood, the type of neck construction (for example, the neck may be glued in or bolted on), and the shape (profile) of the back of the neck. Other types of material used to make guitar necks are graphite (Steinberger guitars), aluminum (Kramer Guitars, Travis Bean and Veleno guitars), or carbon fiber (Modulus Guitars and ThreeGuitars).
Double neck electric guitars have two necks, allowing the musician to quickly switch between guitar sounds.
Neck joint or "heel".
This is the point at which the neck is either bolted or glued to the body of the guitar. Almost all acoustic steel-string guitars, with the primary exception of Taylors, have glued (otherwise known as set) necks, while electric guitars are constructed using both types. Most classical guitars have a neck and headblock carved from one piece of wood, known as a "Spanish heel."
Commonly used set neck joints include mortise and tenon joints (such as those used by C. F. Martin & Co.), dovetail joints (also used by C. F. Martin on the D-28 and similar models) and Spanish heel neck joints, which are named after the shoe they resemble and commonly found in classical guitars. All three types offer stability. Bolt-on necks, though they are historically associated with cheaper instruments, do offer greater flexibility in the guitar's set-up, and allow easier access for neck joint maintenance and repairs.
Another type of neck, only available for solid body electric guitars, is the neck-through-body construction. These are designed so that everything from the machine heads down to the bridge are located on the same piece of wood. The sides (also known as wings) of the guitar are then glued to this central piece. Some luthiers prefer this method of construction as they claim it allows better sustain of each note. Some instruments may not have a neck joint at all, having the neck and sides built as one piece and the body built around it.
Strings.
The standard guitar has six strings, but four-, seven-, eight-, nine-, ten-, eleven-, twelve-, thirteen- and eighteen-string guitars are also available.
Classical and flamenco guitars historically used gut strings, but these have been superseded by polymer materials, such as nylon and fluorocarbon.
Modern guitar strings are constructed from metal, polymers, or animal or plant product materials. Instruments utilizing "steel" strings may have strings made from alloys incorporating steel, nickel or phosphor bronze. Bass strings for both instruments are wound rather than monofilament.
Body (acoustic guitar).
In acoustic guitars, string vibration is transmitted through the bridge and saddle to the body via sound board. The sound board is typically made of tone woods such as spruce or cedar. Timbers for tone woods are chosen for both strength and ability to transfer mechanical energy from the strings to the air within the guitar body. Sound is further shaped by the characteristics of the guitar body's resonant cavity.
In electric guitars, transducers known as pickups convert string vibration to an electric signal, which in turn is amplified and fed to speakers, which vibrate the air to produce the sounds we hear. Nevertheless, the body of the electric guitar still performs a role in shaping the resultant tonal signature.
In an acoustic instrument, the body of the guitar is a major determinant of the overall sound quality. The guitar top, or soundboard, is a finely crafted and engineered element made of tonewoods such as spruce and red cedar. This thin piece of wood, often only 2 or 3 mm thick, is strengthened by differing types of internal bracing. Many luthiers consider the top the dominant factor in determining the sound quality. The majority of the instrument's sound is heard through the vibration of the guitar top as the energy of the vibrating strings is transferred to it.
Body size, shape and style has changed over time. 19th century guitars, now known as salon guitars, were smaller than modern instruments. Differing patterns of internal bracing have been used over time by luthiers. Torres, Hauser, Ramirez, Fleta, and C. F. Martin were among the most influential designers of their time. Bracing not only strengthens the top against potential collapse due to the stress exerted by the tensioned strings, but also affects the resonance characteristics of the top. The back and sides are made out of a variety of timbers such as mahogany, Indian rosewood and highly regarded Brazilian rosewood ("Dalbergia nigra"). Each one is primarily chosen for their aesthetic effect and can be decorated with inlays and purfling.
The body of an acoustic guitar has a sound hole through which sound projects. The sound hole is usually a round hole in the top of the guitar under the strings. Air inside the body vibrates as the guitar top and body is vibrated by the strings, and the response of the air cavity at different frequencies is characterized, like the rest of the guitar body, by a number of resonance modes at which it responds more strongly.
Instruments with larger areas for the guitar top were introduced by Martin in an attempt to create louder volume levels. The popularity of the larger "dreadnought" body size amongst acoustic performers is related to the greater sound volume produced.
Body (electric guitar).
Most electric guitar bodies are made of wood and include a plastic pick guard. Boards wide enough to use as a solid body are very expensive due to the worldwide depletion of hardwood stock since the 1970s, so the wood is rarely one solid piece. Most bodies are made from two pieces of wood with some of them including a seam running down the center line of the body. The most common woods used for electric guitar body construction include maple, basswood, ash, poplar, alder, and mahogany. Many bodies consist of good-sounding but inexpensive woods, like ash, with a "top", or thin layer of another, more attractive wood (such as maple with a natural "flame" pattern) glued to the top of the basic wood. Guitars constructed like this are often called "flame tops". The body is usually carved or routed to accept the other elements, such as the bridge, pickup, neck, and other electronic components. Most electrics have a polyurethane or nitrocellulose lacquer finish. Other alternative materials to wood are used in guitar body construction. Some of these include carbon composites, plastic material (such as polycarbonate), and aluminum alloys.
Pickups.
Pickups are transducers attached to a guitar that detect (or "pick up") string vibrations and convert the mechanical energy of the string into electrical energy. The resultant electrical signal can then be electronically amplified. The most common type of pickup is electromagnetic in design. These contain magnets that are tightly wrapped in a coil, or coils, of copper wire. Such pickups are usually placed right underneath the guitar strings. Electromagnetic pickups work on the same principles and in a similar manner to an electrical generator. The vibration of the strings creates a small voltage in the coils surrounding the magnets. This signal voltage is carried to a guitar amplifier that drives a loudspeaker.
Traditional electromagnetic pickups are either single-coil or double-coil. Single-coil pickups are susceptible to noise induced from electric fields, usually mains-frequency (60 or 50 hertz) hum. The introduction of the double-coil humbucker in the mid-1950s did away with this problem through the use of two coils, one of which is wired in a reverse polarity orientation.
The types and models of pickups used can greatly affect the tone of the guitar. Typically, humbuckers, which are two magnet–coil assemblies attached to each other are traditionally associated with a heavier sound. Single-coil pickups, one magnet wrapped in copper wire, are used by guitarists seeking a brighter, twangier sound with greater dynamic range.
Modern pickups are tailored to the sound desired. A commonly applied approximation used in selection of a pickup is that less wire (lower DC resistance) = brighter sound, more wire = "fat" tone. Other options include specialized switching that produces coil-splitting, in/out of phase and other effects. Guitar circuits are either active, needing a battery to power their circuit, or, as in most cases, equipped with a passive circuit.
Fender Stratocaster-type guitars generally utilize three single-coil pickups, while most Gibson Les Paul types use humbucker pickups.
Piezoelectric, or piezo, pickups represent another class of pickup. These employ piezoelectricity to generate the musical signal and are popular in hybrid electro-acoustic guitars. A crystal is located under each string, usually in the saddle. When the string vibrates, the shape of the crystal is distorted, and the stresses associated with this change produce tiny voltages across the crystal that can be amplified and manipulated.
Some piezo-equipped guitars use a hexaphonic pickup. "Hex" is a prefix meaning six. A hexaphonic pickup produces a separate output for each string, usually from a discrete piezoelectric or magnetic pickup for each string. This arrangement lets on-board or external electronics process the strings individually for modeling or MIDI conversion. Roland makes hexaphonic pickups for guitar and bass, and a line of guitar modeling and synthesis products. Line 6's hexaphonic-equipped Variax guitars use on-board electronics to model the sound after various vintage instruments, and vary pitch on individual strings.
MIDI converters use a hexaphonic guitar signal to determine pitch, duration, attack, and decay characteristics. The MIDI (Musical Instrument Digital Interface) sends the note information to an internal or external sound bank device. The resulting sound closely mimics numerous instruments. The MIDI setup can also let the guitar be used as a game controller (i.e., Rock Band Squier) or as an instructional tool, as with the Fretlight Guitar.
Electronics.
On guitars that have them, these components and the wires that connect them allow the player to control some aspects of the sound like volume or tone using knobs, switches, or buttons. The most basic electronic control is a volume knob. Some guitars also have a tone-control knob, and some guitars with multiple pickups have pickup selector switches or knobs to determine which pickup(s) are activated. These at their simplest consist of passive components such as potentiometers and capacitors, but may also include specialized integrated circuits or other active components requiring batteries for power, for preamplification and signal processing, or even for electronic tuning. In many cases the electronics have some sort of shielding to prevent pickup of external interference and noise.
Lining, binding, and purfling.
The top, back and ribs of an acoustic guitar body are very thin (1–2 mm), so a flexible piece of wood called lining is glued into the corners where the rib meets the top and back. This interior reinforcement provides 5 to 20 mm of solid gluing area for these corner joints. Solid linings are often used in classical guitars, while kerfed lining is most often found in steel string acoustics. Kerfed lining is also called kerfing because it is scored, or "kerfed"(incompletely sawn through), to allow it to bend with the shape of the rib).
During final construction, a small section of the outside corners is carved or routed out and filled with binding material on the outside corners and decorative strips of material next to the binding, which are called purfling. This binding serves to seal off the end grain of the top and back. Purfling can also appear on the back of an acoustic guitar, marking the edge joints of the two or three sections of the back.
Binding and purfling materials are generally made of either wood or plastic.
Bridge.
The main purpose of the bridge on an acoustic guitar is to transfer the vibration from the strings to the soundboard, which vibrates the air inside of the guitar, thereby amplifying the sound produced by the strings.
On all electric, acoustic and original guitars, the bridge holds the strings in place on the body. There are many varied bridge designs. There may be some mechanism for raising or lowering the bridge saddles to adjust the distance between the strings and the fretboard (action), or fine-tuning the intonation of the instrument. Some are spring-loaded and feature a "whammy bar", a removable arm that lets the player modulate the pitch by changing the tension on the strings. The whammy bar is sometimes also referred to as a "tremolo bar". (See Tremolo for further discussion of this term—the effect of rapidly changing pitch produced by a whammy bar is more correctly called "vibrato".) Some bridges also allow for alternate tunings at the touch of a button.
On almost all modern electric guitars, the bridge has saddles that are adjustable for each string so that intonation stays correct up and down the neck. If the open string is in tune, but sharp or flat when frets are pressed, the bridge saddle position can be adjusted with a screwdriver or hex key to remedy the problem. In general, flat notes are corrected by moving the saddle forward and sharp notes by moving it backwards. On an instrument correctly adjusted for intonation, the actual length of each string from the nut to the bridge saddle is slightly but measurably longer than the scale length of the instrument. This additional length is called compensation, which flattens all notes a bit to compensate for the sharping of all fretted notes caused by stretching the string during fretting.
Saddle.
The saddle of a guitar refers to the part of the bridge that physically supports the strings. It may be one piece (typically on acoustic guitars) or separate pieces, one for each string (electric guitars and basses). The saddle's basic purpose is to provide the end point for the string's vibration at the correct location for proper intonation, and on acoustic guitars to transfer the vibrations through the bridge into the top wood of the guitar. Saddles are typically made of plastic or bone for acoustic guitars, though synthetics and some exotic animal tooth variations (e.g. fossilized tooth, ivory, etc. ) have become popular with some players. Electric guitar saddles are typically metal, though some synthetic saddles are available.
Pickguard.
The pickguard, also known as the scratchplate, is usually a piece of laminated plastic or other material that protects the finish of the top of the guitar from damage due to the use of a plectrum ("pick") or fingernails. Electric guitars sometimes mount pickups and electronics on the pickguard. It is a common feature on steel-string acoustic guitars. Some performance styles that use the guitar as a percussion instrument (tapping the top or sides between notes, etc.), such as flamenco, require that a scratchplate or pickguard be fitted to nylon-string instruments.
Whammy bar (tremolo arm).
Many electric guitars are fitted with a vibrato and pitch bend device known as a "vibrato bar" or "tremolo bar (or arm)"—and sometimes as a "sissy bar", "wang bar", "slam handle", "whammy handle", and "whammy bar". The latter two terms led stompbox manufacturers to use the term "whammy" in coming up with a pitch-raising effect introduced by popular guitar effects pedal brand Digitech. The tremolo arm is common enough in electric guitars that there is even a term, "hard tail", for an electric guitar without one.
Leo Fender, who did much to create the electric guitar, also created much confusion over the meaning of the terms "tremolo" and "vibrato" by the naming the "tremolo" unit on many of his guitars and also the "vibrato" unit on his "Vibrolux" amps. In general, "vibrato" is a variation in pitch, whereas "tremolo" is a variation in volume, so the tremolo bar is actually a vibrato bar and the "Vibrolux" amps actually had a tremolo effect. However, following Fender's example, electric guitarists traditionally reverse these meanings when speaking of hardware devices and the effects they produce. See "vibrato unit" for a more detailed discussion, and "tremolo arm" for more of the history.
Another type of pitch bender is the B-Bender, a spring and lever device mounted in an internal cavity of a solid body electric guitar that allows the guitarist to bend just the B string of the guitar using a lever connected to the strap handle of the guitar. The resulting pitch bend is evocative of the sound of the pedal steel guitar.
Guitar strap.
A guitar strap is a strip of fabric with a leather or synthetic leather piece on each end. It is made to hold a guitar via the shoulders, at an adjustable length to suit the position favored by the guitarist.
Guitars have varying accommodations for attaching a strap. The most common are strap buttons, also called strap pins, which are flanged steel posts anchored to the guitar with screws. Two strap buttons come pre-attached to virtually all electric guitars, and many steel-string acoustic guitars. Strap buttons are sometimes replaced with "strap locks", which connect the guitar to the strap more securely.
The lower strap button is usually located at the bottom (bridge end) of the body. The upper strap button is usually located near or at the top (neck end) of the body: on the upper body curve, at the tip of the upper "horn" (on a double cutaway), or at the neck joint (heel). Some electrics, especially those with odd-shaped bodies, have one or both strap buttons on the back of the body. Some Steinberger electric guitars, owing to their minimalist and lightweight design, have both strap buttons at the bottom of the body. Rarely, on some acoustics, the upper strap button is located on the headstock.
Some acoustic and classical guitars only have a single strap button at the bottom of the body—the other end must be tied onto the headstock, above the nut and below the machine heads.
Some acoustic and classical guitars come with no strap buttons at all. In this case, one or two strap buttons can usually be added to the guitar, or a "classical guitar strap" (also called a "guitar harness" or "neck strap") can be used, which supports the guitar by hooking into the sound hole.
Self-tuning guitars.
Self-tuning guitars are computerized guitars programmed to tune themselves. The Gibson Robot Guitar, released in 2007, is often mistaken as the first of this kind, but was preceded by the Transperformance system by at least 20 years. Gibson has also released a second, self-tuning model called the Dark Fire.
Tuning.
Notationally, the guitar is considered a transposing instrument. Its pitch sounds one octave lower than it is notated on a score.
Standard.
A variety of tunings may be used. The most common tuning, known as "Standard Tuning", has the strings tuned from a low E, to a high E, traversing a two octave range—EADGBE. When all strings are played open the resulting chord is an Em7/add11.
The pitches are as follows:
The table below shows a pitch's name found over the six strings of a guitar in standard tuning, from the nut (zero), to the twelfth fret.
For four strings, the 5th fret on one string is the same open-note as the next string; for example, a 5th-fret note on the sixth string is the same note as the open fifth string. However, between the second and third strings, an irregularity occurs: The "4th"-fret note on the third string is equivalent to the open second string.
Alternative.
Standard tuning has evolved to provide a good compromise between simple fingering for many chords and the ability to play common scales with reasonable left-hand movement. There are also a variety of commonly used alternative tunings, for example, the classes of "open", "regular", and "dropped" tunings.
"Open tuning" refers to a guitar tuned so that strumming the open strings produces a chord, typically a major chord. The base chord consists of at least 3 notes and may include all the strings or a subset. The tuning is named for the open chord, Open D, open G, and open A are popular tunings. All similar chords in the chromatic scale can then be played by barring a single fret. Open tunings are common in blues and folk music, and they are used in the playing of slide and bottleneck guitars. Many musicians use open tunings when playing slide guitar.
For the standard tuning, there is exactly one interval of a major third between the second and third strings, and all the other intervals are fourths. The irregularity has a price - chords cannot be shifted around the fretboard in the standard tuning E-A-D-G-B-E, which requires four chord-shapes for the major chords. There are separate chord-forms for chords having their root note on the third, fourth, fifth, and sixth strings.
In contrast, "regular" tunings have equal intervals between the strings, and so they have symmetrical scales all along the fretboard. This makes it simpler to translate chords. For the regular tunings, chords may be moved diagonally around the fretboard. The diagonal movement of chords is especially simple for the regular tunings that are repetitive, in which case chords can be moved vertically: Chords can be moved three strings up (or down) in major-thirds tuning and chords can be moved two strings up (or down) in augmented-fourths tuning. Regular tunings thus appeal to new guitarists and also to jazz-guitarists, whose improvisation is simplified by regular intervals.
On the other hand, some chords are more difficult to play in a regular tuning than in standard tuning. It can be difficult to play conventional chords especially in augmented-fourths tuning and all-fifths tuning,
in which the large spacings require hand stretching. Some chords, which are conventional in folk music, are difficult to play even in all-fourths and major-thirds tunings, which do not require more hand-stretching than standard tuning.
Another class of alternative tunings are called drop tunings, because the tuning "drops down" the lowest string. Dropping down the lowest string a whole tone results in the "drop-D" (or "dropped D") tuning. Its open-string notes DADGBE (from low to high) allow for dominant basses in the keys of D and D minor. It simplifies the playing of simple fifths (powerchords). Many contemporary rock bands re-tune all strings by several semi-tones, making, for example, Drop-C or Drop-B tunings.
Scordatura.
Many scordatura have been used on the guitar. A common form of scordatura involves tuning the 3rd string to F to mimic the standard tuning of the lute, especially when playing renaissance repertoire originally written for that instrument.
Guitar accessories.
Though a guitar may be played on its own, there are a variety of common accessories used for holding and playing the guitar.
Capotasto.
A capo (short for "capotasto") is used to change the pitch of open strings. Capos are clipped onto the fretboard with the aid of spring tension, or in some models, elastic tension. To raise the guitar's pitch by one semitone, the player would clip the capo onto the fretboard just below the first fret. Its use allows players to play in different keys without having to change the chord formations they use. Because of the ease with which they allow guitar players to change keys, they are sometimes referred to as "cheaters" or the "hillbilly crutch". Classical performers are known to use them to enable modern instruments to match the pitch of historical instruments such as the renaissance lute.
Slides.
A slide, (neck of a bottle, knife blade or round metal bar) is used in blues and rock to create a glissando or "Hawaiian" effect. The necks of bottles were often used in blues and country music. Modern slides are constructed of glass, plastic, ceramic, chrome, brass or steel, depending on the weight and tone desired. An instrument that is played exclusively in this manner (using a metal bar) is called a steel guitar or pedal steel. Slide playing to this day is very popular in blues music and country music. Some slide players use a so-called Dobro guitar.
Some performers who have become famous for playing slide are Robert Johnson, Elmore James, Ry Cooder, George Harrison, Bonnie Raitt, Derek Trucks, Warren Haynes, Duane Allman, Muddy Waters, Rory Gallagher, and George Thorogood.
Plectrum.
A "guitar pick" or "plectrum" is a small piece of hard material generally held between the thumb and first finger of the picking hand and is used to "pick" the strings. Though most classical players pick with a combination of fingernails and fleshy fingertips, the pick is most often used for electric and steel-string acoustic guitars. Though today they are mainly plastic, variations do exist, such as bone, wood, steel or tortoise shell. Tortoise shell was the most commonly used material in the early days of pick-making, but as tortoises and turtles became endangered, the practice of using their shells for picks or anything else was banned. Tortoise-shell picks made before the ban are often coveted for a supposedly superior tone and ease of use, and their scarcity has made them valuable.
Picks come in many shapes and sizes. Picks vary from the small jazz pick to the large bass pick. The thickness of the pick often determines its use. A thinner pick (between 0.2 and 0.5 mm) is usually used for strumming or rhythm playing, whereas thicker picks (between 0.7 and 1.5+ mm) are usually used for single-note lines or lead playing. The distinctive guitar sound of Billy Gibbons is attributed to using a quarter or peso as a pick. Similarly, Brian May is known to use a sixpence coin as a pick, while noted 1970s and early 1980s session musician David Persons is known for using old credit cards, cut to the correct size, as plectrums.
Thumb picks and finger picks that attach to the finger tips are sometimes employed in finger-picking styles on steel strings. These allow the fingers and thumb to operate independently, whereas a flat pick requires the thumb and one or two fingers to manipulate.

</doc>
<doc id="11856" url="https://en.wikipedia.org/wiki?curid=11856" title="Gnutella">
Gnutella

Gnutella ( with a silent "g", but often ) (possibly by analogy with the GNU Project) is a large peer-to-peer network. It was the first decentralized peer-to-peer network of its kind, leading to other, later networks adopting the model. It celebrated a decade of existence on March 14, 2010 and has a user base in the millions for peer-to-peer file sharing.
In June 2005, gnutella's population was 1.81 million computers increasing to over three million nodes by January 2006. In late 2007, it was the most popular file sharing network on the Internet with an estimated market share of more than 40%.
History.
The first client (also called Gnutella) from which the network got its name was developed by Justin Frankel and Tom Pepper of Nullsoft in early 2000, soon after the company's acquisition by AOL. On March 14, the program was made available for download on Nullsoft's servers. The event was prematurely announced on Slashdot, and thousands downloaded the program that day. The source code was to be released later, under the GNU General Public License (GPL), however the original developers never got the chance to accomplish this purpose.
The next day, AOL stopped the availability of the program over legal concerns and restrained Nullsoft from doing any further work on the project. This did not stop gnutella; after a few days, the protocol had been reverse engineered, and compatible free and open source clones began to appear. This parallel development of different clients by different groups remains the "modus operandi" of gnutella development today.
Among the first independent Gnutella pioneers were Gene Kan and Spencer Kimball, they launched the first portal aimed to assemble the open-source community to work on Gnutella, and also developed "GNUbile", one of the first open-source (GNU-GPL) programs to implement the Gnutella protocol.
The gnutella network is a fully distributed alternative to such semi-centralized systems as FastTrack (KaZaA) and the original Napster. Initial popularity of the network was spurred on by Napster's threatened legal demise in early 2001. This growing surge in popularity revealed the limits of the initial protocol's scalability. In early 2001, variations on the protocol (first implemented in proprietary and closed source clients) allowed an improvement in scalability. Instead of treating every user as client and server, some users were now treated as "ultrapeers", routing search requests and responses for users connected to them.
This allowed the network to grow in popularity. In late 2001, the gnutella client LimeWire Basic became free and open source. In February 2002, Morpheus, a commercial file sharing group, abandoned its FastTrack-based peer-to-peer software and released a new client based on the free and open source gnutella client Gnucleus.
The word "gnutella" today refers not to any one project or piece of software, but to the open protocol used by the various clients.
The name is a portmanteau of "GNU" and "Nutella", the brand name of an Italian hazelnut flavored spread: supposedly, Frankel and Pepper ate a lot of Nutella working on the original project, and intended to license their finished program under the GNU General Public License. Gnutella is not associated with the GNU project or GNU's own peer-to-peer network, GNUnet.
On October 26, 2010, the popular gnutella client LimeWire was ordered shutdown by Judge Kimba Wood of the United States District Court for the Southern District of New York when she signed a Consent Decree to which recording industry plaintiffs and LimeWire had agreed. This event was the likely cause of a notable drop in the size of the network, because, while negotiating the injunction, LimeWire staff had inserted remote-disabling code into the software. As the injunction came into force, users who had installed affected versions (newer than 5.5.10) were cut off from the P2P network. Since LimeWire was free software, nothing had prevented the creation of forks that omitted the disabling code, as long as LimeWire trademarks were not used. The shutdown did not affect, for example, FrostWire, a fork of LimeWire created in 2004 that carries neither the remote-disabling code nor adware.
On November 9, 2010, LimeWire was resurrected by a secret team of developers and named LimeWire Pirate Edition. It was based on LimeWire 5.6 BETA. This version had its server dependencies removed and all the PRO features enabled for free.
Design.
To envision how gnutella originally worked, imagine a large circle of users "(called nodes)," each of whom have gnutella client software. On initial startup, the client software must bootstrap and find at least one other node. Various methods have been used for this, including a pre-existing address list of possibly working nodes shipped with the software, using updated web caches of known nodes (called "Gnutella Web Caches"), UDP host caches and, rarely, even IRC. Once connected, the client requests a list of working addresses. The client tries to connect to the nodes it was shipped with, as well as nodes it receives from other clients, until it reaches a certain quota. It connects to only that many nodes, locally caching the addresses it has not yet tried, and discards the addresses it tried that were invalid.
When the user wants to do a search, the client sends the request to each actively connected node. In version 0.4 of the protocol, the number of actively connected nodes for a client was quite small (around 5), so each node then forwarded the request to all its actively connected nodes, and they in turn forwarded the request, and so on, until the packet reached a predetermined number of "hops" from the sender (maximum 7).
Since version 0.6 (2002), gnutella is a composite network made of leaf nodes and ultra nodes (also called ultrapeers). The leaf nodes are connected to a small number of ultrapeers (typically 3) while each ultrapeer is connected to more than 32 other ultrapeers. With this higher outdegree, the maximum number of "hops" a query can travel was lowered to 4.
Leaves and ultrapeers use the Query Routing Protocol to exchange a Query Routing Table (QRT), a table of 64 Ki-slots and up to 2 Mi-slots consisting of hashed keywords. A leaf node sends its QRT to each of the ultrapeers it is connected to, and ultrapeers merge the QRT of all their leaves (downsized to 128 Ki-slots) plus their own QRT (if they share files) and exchange that with their own neighbours. Query routing is then done by hashing the words of the query and seeing whether all of them match in the QRT. Ultrapeers do that check before forwarding a query to a leaf node, and also before forwarding the query to a peer ultra node provided this is the last hop the query can travel.
If a search request turns up a result, the node that has the result contacts the searcher. In the classic gnutella protocol, response messages were sent back along the route the query came through, as the query itself did not contain identifying information of the node. This scheme was later revised, so that search results now are delivered over User Datagram Protocol (UDP) directly to the node that initiated the search, usually an ultrapeer of the node. Thus, in the current protocol, the queries carry the IP address and port number of either node. This lowers the amount of traffic routed through the gnutella network, making it significantly more scalable.
If the user decides to download the file, they negotiate the file transfer. If the node which has the requested file is not firewalled, the querying node can connect to it directly. However, if the node is firewalled, stopping the source node from receiving incoming connections, the client wanting to download a file sends it a so-called "push request" to the server for the remote client to initiate the connection instead (to "push" the file). At first, these push requests were routed along the original chain it used to send the query. This was rather unreliable because routes would often break and routed packets are always subject to flow control. Therefore, so called "push proxies" were introduced. These are usually the ultrapeers of a leaf node and they are announced in search results. The client connects to one of these "push proxies" using a HTTP request and the proxy sends a "push request" to leaf on behalf of the client. Normally, it is also possible to send a push request over UDP to the push proxy which is more efficient than using TCP. Push proxies have two advantages: First, ultrapeer-leaf connections are more stable than routes which makes push requests much more reliable. Second, it reduces the amount of traffic routed through the gnutella network.
Finally, when a user disconnects, the client software saves the list of nodes that it was actively connected to and those collected from pong packets for use the next time it attempts to connect so that it becomes independent from any kind of bootstrap services.
In practice, this method of searching on the gnutella network was often unreliable. Each node is a regular computer user; as such, they are constantly connecting and disconnecting, so the network is never completely stable. Also, the bandwidth cost of searching on gnutella grew exponentially to the number of connected users, often saturating connections and rendering slower nodes useless. Therefore, search requests would often be dropped, and most queries reached only a very small part of the network. This observation identified the gnutella network as an unscalable distributed system, and inspired the development of distributed hash tables, which are much more scalable but support only exact-match, rather than keyword, search.
To address the problems of bottlenecks, gnutella developers implemented a tiered system of "ultrapeers" and "leaves". Instead of all nodes being considered equal, nodes entering into the network were kept at the 'edge' of the network as a leaf, not responsible for any routing, and nodes which were capable of routing messages were promoted to ultrapeers, which would accept leaf connections and route searches and network maintenance messages. This allowed searches to propagate further through the network, and allowed for numerous alterations in the topology which have improved the efficiency and scalability greatly.
Additionally gnutella adopted a number of other techniques to reduce traffic overhead and make searches more efficient. Most notable are Query Routing Protocol (QRP) and Dynamic Querying (DQ). With QRP a search reaches only those clients which are likely to have the files, so rare files searches grow vastly more efficient, and with DQ the search stops as soon as the program has acquired enough search results, which vastly reduces the amount of traffic caused by popular searches. Gnutella For Users has a vast amount of information about these and other improvements to gnutella in user-friendly style.
One of the benefits of having gnutella so decentralized is to make it very difficult to shut the network down and to make it a network in which the users are the only ones who can decide which content will be available. Unlike Napster, where the entire network relied on the central server, gnutella cannot be shut down by shutting down any one node and it is impossible for any company to control the contents of the network, which is also due to the many free and open source gnutella clients which share the network.
Protocol features and extensions.
Gnutella did once operate on a purely query flooding-based protocol. The outdated gnutella version 0.4 network protocol employs five different packet types, namely
These are mainly concerned with searching the gnutella network. File transfers are handled using HTTP.
The development of the gnutella protocol is currently led by the Gnutella Developers Forum (The GDF). Many protocol extensions have been and are being developed by the software vendors and free gnutella developers of the GDF. These extensions include intelligent query routing, SHA-1 checksums, query hit transmission via UDP, querying via UDP, dynamic queries via TCP, file transfers via UDP, XML meta data, source exchange (also termed "the download mesh") and parallel downloading in slices (swarming).
There are efforts to finalize these protocol extensions in the gnutella 0.6 specification at the gnutella protocol development website. The gnutella 0.4 standard, although still being the latest protocol specification since all extensions only exist as proposals so far, is outdated. In fact, it is hard or impossible to connect today with the 0.4 handshake and according to developers in the GDF, version 0.6 is what new developers should pursue using the work-in-progress specifications.
The gnutella protocol remains under development and in spite of attempts to make a clean break with the complexity inherited from the old gnutella 0.4 and to design a clean new message architecture, it is still one of the most successful file-sharing protocols to date.
Software.
The following tables compare general and technical information for a number of applications supporting the gnutella network. The tables do not attempt to give a complete list of gnutella clients. The tables are limited to clients that can participate in the current gnutella network.
Gnutella2.
The Gnutella2 protocol (often referred to as G2), despite its name, is not a successor protocol of gnutella nor related to the original GNUtella project, but rather is a totally different protocol that forked from the original project and piggybacked in the gnutella name. A sore point with many gnutella developers is that the "Gnutella2" name conveys an upgrade or superiority, which led to a "Gnutella2 flame war". Other criticism included the use of the gnutella network to bootstrap G2 peers and poor documentation of the G2 protocol. Additionally, the search retries of the Shareaza client, which was one of the initial G2 clients, could unnecessarily burden the gnutella network.
The fork took place in 2002 and both protocols have undergone significant iterations since that time. G2 has advantages and disadvantages compared to gnutella. An advantage often cited is Gnutella2's hybrid search is more efficient than the original gnutella query flooding, which was replaced by more efficient search methods, starting with Query Routing in 2002, proposed in 2001 by Limewire developers. An advantage for gnutella is its user population numbers in the millions, whereas the G2 network is approximately an order of magnitude smaller. It is difficult to compare the protocols in their current form; the individual client choice will probably have as much an effect to an end user on either network.

</doc>
<doc id="11857" url="https://en.wikipedia.org/wiki?curid=11857" title="George Lucas">
George Lucas

George Walton Lucas, Jr. (born May 14, 1944) is an American filmmaker and entrepreneur. He is best known as the creator of the "Star Wars" and "Indiana Jones" franchises, as well as the founder of Lucasfilm and Industrial Light & Magic. He led Lucasfilm as chairman and chief executive before selling it to The Walt Disney Company in 2012.
Upon graduating from the University of Southern California in 1967, Lucas co-founded American Zoetrope with fellow filmmaker Francis Ford Coppola. He wrote and directed "THX 1138" (1971), based on his earlier student short "", which was a critical success but a financial failure. Lucas's next work as a writer-director was the film "American Graffiti" (1973), inspired by his teen years in early 1960s Modesto, California, and produced through the newly founded Lucasfilm. The film was critically and commercially successful, and received five Academy Award nominations including Best Picture.
Lucas's next film, an epic space opera then titled "Star Wars" (1977), went through a troubled production process, but was a surprise hit, becoming the highest-grossing film at the time as well as a winner of six Academy Awards and a cultural phenomenon. Following the first "Star Wars" film, Lucas only produced and co-wrote the following installments in the trilogy, "The Empire Strikes Back" (1980) and "Return of the Jedi" (1983). Along with Steven Spielberg, he co-created and wrote the "Indiana Jones" films "Raiders of the Lost Ark" (1981), "Temple of Doom" (1984), and "The Last Crusade" (1989). Lucas also produced a variety of films through Lucasfilm in the 1980s and 1990s.
In 1997, Lucas re-released the original "Star Wars" trilogy as part of a Special Edition, where he made several alterations to the films. These were followed by further changes for home media releases in 2004 and 2011. In 1999, Lucas returned to directing with the "Star Wars" prequel trilogy, consisting of ' (1999), ' (2002), and "" (2005). He later collaborated on the story for the "Indiana Jones" sequel "Kingdom of the Crystal Skull" (2008), and served as the story writer and executive producer for the war film "Red Tails" (2012). Five of his seven features are among the 100 highest-grossing movies at the North American box office, adjusted for ticket-price inflation. Lucas is one of the American film industry's most financially successful filmmakers, and has been personally nominated for four Academy Awards. He is also considered a significant figure in the New Hollywood era.
Early life.
Lucas was born and raised in Modesto, California, the son of Dorothy Ellinore Lucas (née Bomberger) and George Walton Lucas, Sr., who owned a stationery store. He is of German, Swiss-German, English, Scottish, and distant Dutch and French descent. Growing up, Lucas had a passion for cars and motor racing, which would eventually serve as inspiration for his films "" and "American Graffiti". Long before Lucas became obsessed with filmmaking, he wanted to be a race-car driver, and he spent most of his high school years racing on the underground circuit at fairgrounds and hanging out at garages. On June 12, 1962, while driving his souped-up Autobianchi Bianchina, another driver broadsided him, flipping over his car, nearly killing him, causing him to lose interest in racing as a career. He attended Modesto Junior College, where he studied anthropology, sociology, and literature, amongst other subjects. He also began shooting with an 8 mm camera, including filming car races.
At this time, Lucas and his friend John Plummer became interested in Canyon Cinema: screenings of underground, avant-garde 16 mm filmmakers like Jordan Belson, Stan Brakhage and Bruce Conner. Lucas and Plummer also saw classic European films of the time, including Jean-Luc Godard's "Breathless", François Truffaut's "Jules et Jim", and Federico Fellini's "8½". "That's when George really started exploring," Plummer said. Through his interest in autocross racing, Lucas met renowned cinematographer Haskell Wexler, another race enthusiast. Wexler, later to work with Lucas on several occasions, was impressed by Lucas' talent. "George had a very good eye, and he thought visually," he recalled.
Lucas then transferred to the University of Southern California (USC) School of Cinematic Arts. USC was one of the earliest universities to have a school devoted to motion picture film. During the years at USC, Lucas shared a dorm room with Randal Kleiser. Along with classmates such as Walter Murch, Hal Barwood and John Milius, they became a clique of film students known as The Dirty Dozen. He also became good friends with fellow acclaimed student filmmaker and future "Indiana Jones" collaborator, Steven Spielberg. Lucas was deeply influenced by the Filmic Expression course taught at the school by filmmaker Lester Novros which concentrated on the non-narrative elements of Film Form like color, light, movement, space, and time. Another inspiration was the Serbian montagist (and dean of the USC Film Department) Slavko Vorkapich, a film theoretician who made stunning montage sequences for Hollywood studio features at MGM, RKO, and Paramount. Vorkapich taught the autonomous nature of the cinematic art form, emphasizing the unique dynamic quality of movement and kinetic energy inherent in motion pictures.
Film career.
1965–71: Early career.
Lucas saw many inspiring films in class, particularly the visual films coming out of the National Film Board of Canada like Arthur Lipsett's "21-87", the French-Canadian cameraman Jean-Claude Labrecque's cinéma vérité "60 Cycles", the work of Norman McLaren, and the documentaries of Claude Jutra. Lucas fell madly in love with pure cinema and quickly became prolific at making 16 mm nonstory noncharacter visual tone poems and cinéma vérité with such titles as "Look at Life", "Herbie", "", "The Emperor", "Anyone Lived in a Pretty (how) Town", "Filmmaker", and "6-18-67". He was passionate and interested in camerawork and editing, defining himself as a filmmaker as opposed to being a director, and he loved making abstract visual films that created emotions purely through cinema.
After graduating with a bachelor of fine arts in film in 1967, he tried joining the United States Air Force as an officer, but he was immediately turned down because of his numerous speeding tickets. He was later drafted by the Army for military service in Vietnam, but he was exempted from service after medical tests showed he had diabetes, the disease that killed his paternal grandfather.
In 1967, Lucas re-enrolled as a USC graduate student in film production. Working as a teaching instructor for a class of U.S. Navy students who were being taught documentary cinematography, Lucas directed the short film "", which won first prize at the 1967–68 National Student film festival, and was later adapted into his first full-length feature film, "THX 1138". Lucas was awarded a student scholarship by Warner Bros. to observe and work on the making of a film of his choosing. The film he chose was "Finian's Rainbow" (1968) which was being directed by Francis Ford Coppola, who was revered among film school students of the time as a cinema graduate who had "made it" in Hollywood. In 1969, Lucas was one of the camera operators on the classic Rolling Stones concert film "Gimme Shelter".
1971–77: "THX 1138", "American Graffiti", and "Star Wars".
Lucas co-founded the studio American Zoetrope with Coppola—whom he met during his internship at Warner Bros.—hoping to create a liberating environment for filmmakers to direct outside the perceived oppressive control of the Hollywood studio system. His first full-length feature film produced by the studio, "THX 1138", was not a success. Lucas then created his own company, Lucasfilm, Ltd., and directed "American Graffiti" (1973).
Lucas's new-found wealth and reputation enabled him to develop a story set in space. Even so, he encountered difficulties getting "Star Wars" made. It was only because Alan Ladd, Jr., at 20th Century Fox liked "American Graffiti" that he forced through a production and distribution deal for the film, which ended up restoring Fox to financial stability after a number of flops.
"Star Wars" quickly became the highest-grossing film of all-time, displaced five years later by Spielberg's "E.T. the Extra-Terrestrial". After the success of "American Graffiti" and prior to the beginning of filming on "Star Wars", Lucas was encouraged to renegotiate for a higher fee for writing and directing "Star Wars" than the $150,000 agreed. He declined to do so, instead negotiating for advantage in some of the as-yet-unspecified parts of his contract with Fox, in particular ownership of licensing and merchandising rights (for novelizations, T-shirts, toys, etc.) and contractual arrangements for sequels. The studio was unconcerned to relinquish these rights, as its last major attempt in the field, with the 1967 film, "Doctor Dolittle", had proved a discouraging failure. Lucas exploited merchandising rights wisely, and Lucasfilm has earned hundreds of millions of dollars from licensed games, toys, and collectibles created for the franchise.
1977–99: Hiatus from directing, "Indiana Jones".
Over the two decades after the first "Star Wars" film, Lucas worked extensively as a writer and/or producer, including the many Star Wars spinoffs made for film, TV, and other media. Lucas acted as executive producer for the next two "Star Wars" films, commissioning Irvin Kershner to direct "The Empire Strikes Back", and Richard Marquand to direct "Return of the Jedi", while receiving a story credit on the former and sharing a screenwriting credit with Lawrence Kasdan on the latter. He also acted as executive producer and story writer on all four of the "Indiana Jones" films, which he convinced his colleague and good friend, Steven Spielberg, to direct.
Other successful projects where Lucas acted as a producer or executive producer in this period include Kurosawa's "Kagemusha" (1980), Lawrence Kasdan's "Body Heat" (1981), Jim Henson's "Labyrinth" (1986), Godfrey Reggio's "Powaqqatsi" (1986) and the animated film "The Land Before Time" (1988). There were less successful projects, however, including "More American Graffiti" (1979), the ill-fated "Howard the Duck" (1986), which was the biggest flop of his career; "Willow" (1988, which Lucas also wrote); and Coppola's "" (1988).
From 1992 to 1996, Lucas served as executive producer for the "Indiana Jones" television spinoff "The Young Indiana Jones Chronicles". In 1997, as part of the 20th anniversary of "Star Wars," Lucas returned to the original trilogy and made numerous modifications using newly available digital technology, releasing them in theaters as the "Star Wars Special Edition". For DVD releases in 2004 and Blu-ray releases in 2011, the trilogy received further revisions to make them congruent with the prequel trilogy. Besides the additions to the "Star Wars" franchise, Lucas released a "Director's Cut" of "THX 1138" in 2004, with the film re-cut and containing a number of CGI revisions.
The animation studio Pixar was founded as the Graphix Group, one third of the Computer Division of Lucasfilm. Pixar's early computer graphics research resulted in groundbreaking effects in films such as "" and "Young Sherlock Holmes", and the group was purchased in 1986 by Steve Jobs shortly after he left Apple Computer. Jobs paid Lucas US$5 million and put US$5 million as capital into the company. The sale reflected Lucas' desire to stop the cash flow losses from his 7-year research projects associated with new entertainment technology tools, as well as his company's new focus on creating entertainment products rather than tools. A contributing factor was cash-flow difficulties following Lucas' 1983 divorce concurrent with the sudden dropoff in revenues from "Star Wars" licenses following the release of "Return of the Jedi".
The sound equipped system, THX Ltd, was founded by Lucas and Tomlinson Holman. The company was formerly owned by Lucasfilm, and contains equipment for stereo, digital, and theatrical sound for films, and music. Skywalker Sound and Industrial Light & Magic, are the sound and visual effects subdivisions of Lucasfilm, while Lucasfilm Games, later renamed LucasArts, produces products for the gaming industry.
1999–2012: Return to directing, return to "Star Wars" and "Indiana Jones".
After losing much of his fortune in a divorce settlement in 1987, Lucas had no desire to return to "Star Wars", and had unofficially canceled his sequel trilogy by the time of "Return of the Jedi". Nevertheless, the prequels, which were only still a series of basic ideas partially pulled from his original drafts of "The Star Wars", continued to fascinate him with the possibilities of technical advances would make it possible to revisit his 20-year-old material. After "Star Wars" became popular once again, in the wake of Dark Horse's comic book line and Timothy Zahn's trilogy of novels, Lucas saw that there was still a large audience. His children were older, and with the explosion of CGI technology he was now considering returning to directing.
By 1993, it was announced, in "Variety" among other sources, that he would be making the prequels. He began penning more to the story, now indicating the series would be a tragic one examining Anakin Skywalker's fall to the dark side. Lucas also began to change how the prequels would exist relative to the originals; at first they were supposed to be a "filling-in" of history tangential to the originals, but now he saw that they could form the beginning of one long story that started with Anakin's childhood and ended with his death. This was the final step towards turning the film series into a "Saga".
In 1994, Lucas began work on the screenplay of the first prequel, tentatively titled "Episode I: The Beginning". It was finished and released in 1999 as ', which would be the first film he had directed in over two decades. Following the release of the first prequel, Lucas announced that he would also be directing the next two, and began working on "Episode II". The first draft of "Episode II" was completed just weeks before principal photography, and Lucas hired Jonathan Hales, a writer from "The Young Indiana Jones Chronicles", to polish it. It was completed and released in 2002 as '. The final prequel, ', began production in 2002 and was released in 2005. Numerous fans and critics considered the prequels inferior to the original trilogy, though they were box office successes nonetheless. From 2003 to 2005, Lucas also served as an executive producer on ', an animated microseries on Cartoon Network created by Genndy Tartakovsky, that bridged the events between "Attack of the Clones" and "Revenge of the Sith".
Lucas collaborated with Jeff Nathanson as a writer of the 2008 film "Indiana Jones and the Kingdom of the Crystal Skull", directed by Steven Spielberg. Like the "Star Wars" prequels, reception was mixed, with numerous fans and critics once again considering it inferior to its predecessors. From 2008 to 2014, Lucas also served as the executive producer for "", another "Star Wars" animated series on Cartoon Network, which was preceded by a . In 2012, Lucas served as the story-writer and executive producer for the 2012 film "Red Tails", a war film based on the exploits of the Tuskegee Airmen, a group of African American pilots in the United States Army Air Force during the Second World War. He also took over direction of reshoots while director Anthony Hemingway worked on other projects.
2012–present: Semi-retirement.
In January 2012, Lucas announced his retirement from producing large scale blockbuster films and instead re-focusing his career on smaller, independently budgeted features. He did not specify whether or not this would affect his involvement with a fifth installment of the "Indiana Jones" series. In June 2012, it was announced that producer Kathleen Kennedy, a long-term collaborator with Steven Spielberg and a producer of the "Indiana Jones" films, had been appointed as co-chair of Lucasfilm Ltd. It was reported that Kennedy would work alongside Lucas, who would remain chief executive and serve as co-chairman for at least one year, after which she would succeed him as the company's sole leader. With the sale of Lucasfilm to Disney, Lucas is currently Disney's second largest single shareholder after the estate of Steve Jobs.
As of 2014, he is working as a creative consultant on the Star Wars sequel trilogy, with the first movie, "", having been released on December 18, 2015. J. J. Abrams directed "The Force Awakens", while Kathleen Kennedy executive produced, and will do so for all future "Star Wars" films. The new sequel trilogy is being jointly produced by Lucasfilm and The Walt Disney Company, which had acquired Lucasfilm in 2012.
As creative consultant on the film, Lucas's involvement included attending early story meetings; according to Lucas, "I mostly say, 'You can't do this. You can do that.' You know, 'The cars don't have wheels. They fly with antigravity.' There's a million little pieces... I know all that stuff." Lucas's son Jett told "The Guardian "that his father was "very torn" about having sold the rights to the franchise, despite having hand-picked Abrams to direct, and that his father was "there to guide" but that "he wants to let it go and become its new generation." Among the materials turned over to the production team were rough story treatments Lucas developed when he considered creating episodes "VII"–"IX" himself years earlier; in January 2015, Lucas stated that Disney had discarded his story ideas.
In 2015, Lucas wrote the CGI film "Strange Magic", his first musical. The film was produced at Skywalker Ranch. Gary Rydstrom directed the movie.
Philanthropy.
Lucas has pledged to give half of his fortune to charity as part of an effort called The Giving Pledge led by Bill Gates and Warren Buffett to persuade America's richest individuals to donate their financial wealth to charities.
George Lucas Educational Foundation.
In 1991, The George Lucas Educational Foundation was founded as a nonprofit operating foundation to celebrate and encourage innovation in schools. The Foundation's content is available under the brand Edutopia, in an award-winning web site, social media and via documentary films. Lucas, through his foundation, was one of the leading proponents of the E-rate program in the universal service fund, which was enacted as part of the Telecommunications Act of 1996. On June 24, 2008, Lucas testified before the United States House of Representatives subcommittee on Telecommunications and the Internet as the head of his Foundation to advocate for a free wireless broadband educational network.
Proceeds from the sale of Lucasfilm to Disney.
In 2012, Lucas sold Lucasfilm to The Walt Disney Company for a reported sum of $4.05 billion. It was widely reported at the time that Lucas intends to give the majority of the proceeds from the sale to charity. A spokesperson for Lucasfilm said, "George Lucas has expressed his intention, in the event the deal closes, to donate the majority of the proceeds to his philanthropic endeavors." Lucas also spoke on the matter: "For 41 years, the majority of my time and money has been put into the company. As I start a new chapter in my life, it is gratifying that I have the opportunity to devote more time and resources to philanthropy." No announcement has yet been made as to which charities will receive the funds.
Lucas Museum of Narrative Art.
By June 2013, Lucas was considering establishing a museum, the Lucas Cultural Arts Museum, to be built on Crissy Field near the Golden Gate Bridge in San Francisco, which would display his collection of illustrations and pop art, with an estimated value of more than $1 billion. Lucas offered to pay the estimated $300 million cost of constructing the museum, and would endow it with $400 million when it opened, eventually adding an additional $400 million to its endowment. After being unable to reach an agreement with The Presidio Trust, Lucas turned to Chicago. A potential lakefront site on Museum Campus in Chicago was proposed in May 2014. By June 2014, Chicago had been selected, pending approval of the Chicago Plan Commission, which was granted. The museum project was renamed the Lucas Museum of Narrative Art.
Other initiatives.
In 2005, Lucas gave US$1 million to help build the Martin Luther King, Jr. National Memorial on the National Mall in Washington D.C. to commemorate American civil rights leader Martin Luther King, Jr.
On September 19, 2006, USC announced that Lucas had donated $175–180 million to his alma mater to expand the film school. It is the largest single donation to USC and the largest gift to a film school anywhere. Previous donations led to the already existing George Lucas Instructional Building and Marcia Lucas Post-Production building.
In 2013, Lucas and his wife Mellody Hobson donated $25 million to the Chicago-based not-for-profit After School Matters, of which Hobson is the chair.
Personal life.
In 1969, Lucas married film editor Marcia Lou Griffin, who went on to win an Academy Award for her editing work on the original "Star Wars" film. They adopted a daughter, Amanda Lucas, in 1981, and divorced in 1983. Lucas subsequently adopted two more children as a single parent: daughter Katie Lucas, born in 1988, and son Jett Lucas, born in 1993. His three eldest children all appeared in the three "Star Wars" prequels, as did Lucas himself. Following his divorce, Lucas was in a relationship with singer Linda Ronstadt in the 1980s.
Lucas began dating Mellody Hobson, president of Ariel Investments and chair of DreamWorks Animation, in 2006. Lucas and Hobson announced their engagement in January 2013, and married on June 22, 2013, at Lucas's Skywalker Ranch in Marin County, California. They have one daughter together, Everest Hobson Lucas, who was born via gestational carrier on August 12, 2013.
Lucas was born and raised in a Methodist family. The religious and mythical themes in "Star Wars" were inspired by Lucas' interest in the writings of mythologist Joseph Campbell, and he would eventually come to identify strongly with the Eastern religious philosophies he studied and incorporated into his films, which were a major inspiration for "the Force". Lucas has come to state that his religion is "Buddhist Methodist". He resides in Marin County.
Lucas is a major collector of the American illustrator and painter Norman Rockwell. A collection of 57 Rockwell paintings and drawings owned by Lucas and fellow Rockwell collector and film director Steven Spielberg were displayed at the Smithsonian American Art Museum from July 2, 2010 to January 2, 2011 in an exhibition titled "Telling Stories".
Lucas has said that he is a fan of Seth MacFarlane's hit TV show "Family Guy". MacFarlane has said that Lucasfilm was extremely helpful when the "Family Guy" crew wanted to .
Awards and honors.
The American Film Institute awarded Lucas its Life Achievement Award on June 9, 2005. This was shortly after the release of "", about which he joked stating that, since he views the entire "Star Wars" series as one film, he could actually receive the award now that he had finally "gone back and finished the movie."
Lucas was nominated for four Academy Awards: Best Directing and Writing for "American Graffiti", and Best Directing and Writing for "Star Wars". He received the Academy's Irving G. Thalberg Award in 1991. He appeared at the 79th Academy Awards ceremony in 2007 with Steven Spielberg and Francis Ford Coppola to present the Best Director award to their friend Martin Scorsese. During the speech, Spielberg and Coppola talked about the joy of winning an Oscar, making fun of Lucas, who has not won a competitive Oscar.
The Science Fiction Hall of Fame inducted Lucas in 2006, its second "Film, Television, and Media" contributor, after Spielberg. The Discovery Channel named him one of the 100 "Greatest Americans" in September 2008. Lucas served as Grand Marshal for the Tournament of Roses Parade and made the ceremonial coin toss at the Rose Bowl, New Year's Day 2007. In 2009, he was one of 13 California Hall of Fame inductees in The California Museum's yearlong exhibit.
In July 2013, Lucas was awarded the National Medal of Arts by President Barack Obama for his contributions to American cinema.
In October 2014, Lucas received Honorary Membership of the Society of Motion Picture and Television Engineers.
In August 2015, Lucas was inducted as a Disney Legend, and in December 2015 was an honoree at the Kennedy Center Honors.
References.
Explanatory notes
Citations
Sources

</doc>
<doc id="11861" url="https://en.wikipedia.org/wiki?curid=11861" title="Gothenburg">
Gothenburg

Gothenburg (, ) is the second-largest city in Sweden and the fifth-largest in the Nordic countries. Situated by the Kattegat, on the west coast of Sweden, the city proper has a population of 548,190, with 549,839 in the urban area and 982,360 inhabitants in the metropolitan area.
Gothenburg was founded by royal charter in 1621 by King Gustavus Adolphus. At the mouth of the Göta älv, the Port of Gothenburg is the largest port in the Nordic countries.
Gothenburg is home to many students, as the city includes both the University of Gothenburg and Chalmers University of Technology. Volvo was founded in Gothenburg in 1927. The city is a major center for sports and home to the IFK Göteborg, BK Häcken, GAIS, and Örgryte IS association football teams, the handball team Redbergslids IK, as well as the Frölunda HC ice hockey team.
Gothenburg is served by Göteborg Landvetter Airport, located southeast of the city center. The smaller Göteborg City Airport, located from the city center, was closed to regular airline traffic in 2015.
The city hosts some of the largest annual events in Scandinavia. The Gothenburg Film Festival, held in January since 1979, is the leading Scandinavian film festival with over 155,000 visitors each year. In summer, a wide variety of music festivals are held in the city, such as Way Out West and Metaltown. The annual Gothia Cup, is the world's largest football tournament with regards to the number of participants: in 2011, a total of 35,200 players from 1,567 teams and 72 nations participated.
Name.
The city was named after the Geats (), the inhabitants of Gothia, now southern Sweden—i.e. "Geat Castle". The river on which the city sits is the "Göta älv" or Gothia River. "Göta borg" "Gothia Fortress" is the fort on the Göta Älv, built to protect the port.
In Dutch, Scots, and English, all being languages with a long history of being spoken in this trade and maritime-oriented city, the name Gothenburg is used for the city. The French form of the city name is "Gothembourg", but in French texts, the Swedish name "Göteborg" is more frequent. "Gottenburg" can also be seen in some older English texts. These traditional forms are now sometimes replaced with the use of the Swedish "Göteborg", for example by The Göteborg Opera and the Göteborg Ballet. However, "Göteborgs universitet", previously designated as the Göteborg University in English, changed its name to the University of Gothenburg in 2008. The Gothenburg municipality has also reverted to the use of the English name in international contexts. Other old variations in Swedish are "Götheborgh", and the more common "Götheborg". One English text, written in the late 15th century, states the name as "Guthaeborg". 
In 2009, the city council launched a new logotype for Gothenburg. Since the name "Göteborg" contains the Swedish letter "ö" the idea was to make the name more international and up to date by "turning" the "ö" sideways. , the name is spelled "Go:teborg" on a large number of signs in the city.
History.
In the early modern period, the configuration of Sweden's borders made Gothenburg strategically critical as the only Swedish gateway to the North Sea and Atlantic, situated on the west coast in a very narrow strip of Swedish territory between Danish Halland in the south and Norwegian Bohuslän in the north. After several failed attempts, Gothenburg was successfully founded in 1621 by King Gustavus Adolphus (Gustaf II Adolf).
The site of the first church built in Gothenburg, subsequently destroyed by Danish invaders, is marked by a stone near the north end of the Älvsborg Bridge in the Färjenäs Park. The church was built in 1603 and destroyed in 1611. The city was heavily influenced by the Dutch, Germans, and Scots, and Dutch planners and engineers were contracted to construct the city as they had the skills needed to drain and build in the marshy areas chosen for the city. The town was designed like Dutch cities such as Amsterdam, Batavia (Jakarta) and New Amsterdam (Manhattan). The planning of the streets and canals of Gothenburg closely resembled that of Jakarta, which was built by the Dutch around the same time. The Dutchmen initially won political power, and it was not until 1652, when the last Dutch politician in the city's council died, that Swedes acquired political power over Gothenburg. During the Dutch period, the town followed Dutch town laws and Dutch was proposed as the official language in the town. Robust city walls were built during the 17th century. In 1807, a decision was made to tear down most of the city's wall. The work started in 1810, and was carried out by 150 soldiers from the Bohus regiment.
Along with the Dutch, the town also was heavily influenced by Scots who settled down in Gothenburg. Many became people of high profile. William Chalmers, the son of a Scottish immigrant, donated his fortunes to set up what later became the Chalmers University of Technology. In 1841, the Scotsman Alexander Keiller founded the Götaverken shipbuilding company that was in business until 1989. His son James Keiller donated Keiller Park to the city in 1906.
The Gothenburg coat of arms was based on the lion of the coat of arms of Sweden, symbolically holding a shield with the national emblem, the Three Crowns, to defend the city against its enemies.
In the Treaty of Roskilde (1658), Denmark–Norway ceded the then Danish province Halland, in the south, and the Norwegian province of Bohus County or "Bohuslän" in the north, leaving Gothenburg less exposed. Gothenburg was able to grow into a significant port and trade centre on the west coast, because it was the only city on the west coast that, along with Marstrand, was granted the rights to trade with merchants from other countries.
In the 18th century, fishing was the most important industry. However, in 1731, the Swedish East India Company was founded, and the city flourished due to its foreign trade with highly profitable commercial expeditions to China.
The harbour developed into Sweden's main harbour for trade towards the west, and when Swedish emigration to the United States increased, Gothenburg became Sweden's main point of departure for these travelers. The impact of Gothenburg as a main port of embarkation for Swedish emigrants is reflected by Gothenburg, Nebraska, a small Swedish settlement in the United States.
With the 19th century, Gothenburg evolved into a modern industrial city that continued on into the 20th century. The population increased tenfold in the century, from 13,000 (1800) to 130,000 (1900)., In the 20th century, major companies that developed included SKF (1907) and Volvo (1927).
Geography.
Gothenburg is located on the west coast, in southwestern Sweden, about halfway between the capitals Copenhagen, Denmark, and Oslo, Norway. The location at the mouth of the Göta älv, which feeds into Kattegatt, an arm of the North Sea, has helped the city grow in significance as a trading city. The archipelago of Gothenburg consists of rough, barren rocks and cliffs, which also is typical for the coast of Bohuslän. Due to the Gulf Stream, the city has a mild climate and moderately heavy precipitation. It is the second-largest city in Sweden after capital Stockholm.
The Gothenburg Metropolitan Area ("Stor-Göteborg") has 816,931 inhabitants and extends to the municipalities of Ale, Alingsås, Göteborg, Härryda, Kungälv, Lerum, Lilla Edet, Mölndal, Partille, Stenungsund, Tjörn, Öckerö in Västra Götaland County, and Kungsbacka in Halland County.
Angered, a suburb outside Gothenburg, consists of Hjällbo, Eriksbo, Rannebergen, Hammarkullen, Gårdsten, and Lövgärdet. It is a Million Programme part of Gothenburg, like Rosengård in Malmö and Botkyrka in Stockholm. Angered had about 50,000 inhabitants in 2015. It lies north of Gothenburg and is isolated from the rest of the city. Bergsjön is another Million Programme suburb north of Gothenburg, it has 14,000 inhabitants. Biskopsgården is the biggest multicultural suburb on the island of Hisingen, which is a part of Gothenburg but separated from the city by the river.
Climate.
Gothenburg has an oceanic climate according to Köppen climate classification. Despite its northern latitude, temperatures are quite mild throughout the year and much warmer than places in similar latitude, for example Stockholm, or even somewhat further south, mainly because of the moderating influence of the warm Gulf Stream. During the summer, daylight extends 18 hours and 5 minutes, but lasts 6 hours and 32 minutes in late December. The climate has become significantly milder in latter decades, particularly in summer and winter; July temperatures used to be below Stockholm's 1961-1990 averages, but have since been warmer than that benchmark.
Summers are warm and pleasant with average high temperatures of and lows of , but temperatures of occur on many days during the summer.
Winters are cold and windy with temperatures of around , though it rarely drops below . Precipitation is regular but generally moderate throughout the year. Snow mainly occurs from December to March, but is not unusual in November and April and can sometimes occur even in October and May, in extreme cases even in September.
Parks and nature.
Gothenburg has several parks and nature reserves ranging in size from tens of square metres to hundreds of hectares. It also has many green areas that are not designated as parks or reserves.
Selection of parks:
Architecture.
Very few houses are left from the 17th century when the city was founded, since all but the military and royal houses were built of wood. A rare exception is the Skansen Kronan.
The first major architecturally interesting period is the 18th century when the East India Company made Gothenburg an important trade city. Imposing stone houses in Classical style were erected around the canals. One example from this period is the East India House, which today houses the Göteborg City Museum.
In the 19th century, the wealthy bourgeoisie began to move outside the city walls which had protected the city. The style now was an eclectic, academic, somewhat overdecorated style which the middle-class favoured. The working class lived in the overcrowded city district Haga in wooden houses.
In the 19th century, the first comprehensive town plan after the founding of city was created, which led to the construction of the main street, Kungsportsavenyen. Perhaps the most significant type of houses of the city, Landshövdingehusen, were built in the end of the 19th century – three-storey houses with the first floor in stone and the other two in wood.
The early 20th century, characterized by the National Romantic style, was rich in architectural achievements. Masthugg Church is a noted example of the style of this period. In the early 1920s, on the city's 300th anniversary, the Götaplatsen square with its Neoclassical look was built.
After this, the predominant style in Gothenburg and rest of Sweden was Functionalism which especially dominated the suburbs such as Västra Frölunda and Bergsjön. The Swedish functionalist architect Uno Åhrén served as city planner from 1932 through 1943. In the 1950s, the big stadium Ullevi was built when Sweden hosted the 1958 FIFA World Cup.
The modern architecture of the city has been formed by such architects as Gert Wingårdh, who started as a Post-modernist in the 1980s.
Gustaf Adolf Square is a town square located in central Gothenburg. Noted buildings on the square include Gothenburg City Hall (formerly the stock exchange, opened in 1849) and the Nordic Classicism law court. The main canal of Gothenburg also flanks the square.
Characteristic buildings.
The Gothenburg Central Station is in the centre of the city, next to Nordstan and Drottningtorget. The building has been renovated and expanded numerous times since the grand opening in October 1858. In 2003, a major reconstruction was finished which brought the 19th-century building into the 21st century expanding the capacity for trains, travellers, and shopping. Not far from the central station is the Skanskaskrapan, or more commonly known as "The Lipstick". It is high with 22 floors and coloured in red-white stripes. The skyscraper was designed by Ralph Erskine and built by Skanska in the late 1980s as the headquarters for the company.
By the shore of the Göta Älv at Lilla Bommen is The Göteborg Opera. It was completed in 1994. The architect Jan Izikowitz was inspired by the landscape and described his vision as "Something that makes your mind float over the squiggling landscape like the wings of a seagull."
Feskekôrka, or "Fiskhallen", is an indoor fishmarket by the Rosenlundskanalen in central Gothenburg. Feskekôrkan was opened on 1November 1874 and its name from the building's resemblance to a Gothic church. The Gothenburg city hall is in the Beaux-Arts architectural style. The Gothenburg Synagogue at Stora Nygatan, near Drottningtorget, was built in 1855 according to the designs of the German architect August Krüger.
The Gunnebo House is a country house located to the south of Gothenburg, in Mölndal. It was built in a neoclassical architecture towards the end of the 18th century. Created in the early 1900s was the Vasa Church. It is located in Vasastan and is built of granite in a neo-Romanesque style.
Another noted construction is Brudaremossen TV Tower, one of the few partially guyed towers in the world.
Culture.
The sea, trade, and industrial history of the city is evident in the cultural life of Gothenburg. It is also a popular destination for tourists on the Swedish west coast.
Museums.
Many of the cultural institutions, as well as hospitals and the university, were created by donations from rich merchants and industrialists, for example the Röhsska Museum. On 29December 2004, the Museum of World Culture opened near Korsvägen. Museums include the Gothenburg Museum of Art, and several museums of sea and navigation history, natural history, the sciences, and East India. Aeroseum, close to the Göteborg City Airport, is an aircraft museum in a former military underground air force base. The Volvo museum has exhibits of the history of Volvo and the development from 1927 until today. Products shown include cars, trucks, marine engines, and buses.
The Universeum is a public science centre that opened in 2001, the largest of its kind in Scandinavia. It is divided into six sections, each containing experimental workshops and a collection of reptiles, fish, and insects. The Universeum occasionally host debates between Swedish secondary-school students and Nobel Prize laureates or other scholars.
Leisure and entertainment.
The most noted attraction is the amusement park Liseberg, located in the central part of the city. It is the largest amusement park in Scandinavia by number of rides, and was chosen as one of the top ten amusement parks in the world (2005) by "Forbes". It is the most popular attraction in Sweden by number of visitors per year (more than 3 million).
There are a number of independent theatre ensembles in the city, besides institutions such as Gothenburg City Theatre, Backa Theatre (youth theatre), and Folkteatern.
The main boulevard is called Kungsportsavenyn (commonly known as "Avenyn", "The Avenue"). It is about long and starts at Götaplatsen — which is the location of the Gothenburg Museum of Art, the city's theatre, and the city library, as well as the concert hall— and stretches all the way to Kungsportsplatsen in the old city centre of Gothenburg, crossing a canal and a small park. The "Avenyn" was created in the 1860s and 1870s as a result of an international architecture contest, and is the product of a period of extensive town planning and remodelling. "Avenyn" has Gothenburg's highest concentration of pubs and clubs. Sweden's largest shopping centre, Nordstan, is located in central Gothenburg.
Gothenburg's Haga district is known for its picturesque wooden houses and its cafés serving the well-known "Haga bulle" – a large cinnamon roll similar to the "kanelbulle".
Five Gothenburg restaurants have a star in the 2008 "Michelin Guide": 28 +, Basement, Fond, Kock & Vin, Fiskekrogen, and Sjömagasinet.
The city has a number of star chefs – over the past decade, seven of the Swedish Chef of the Year awards have been won by people from Gothenburg.
The Gustavus Adolphus pastry, eaten every 6November in Sweden, Gustavus Adolphus Day, is especially connected to, and appreciated in, Gothenburg because the city was founded by King Gustavus Adolphus.
One of Gothenburg's most popular natural tourist attractions is the Southern Gothenburg Archipelago, which is a set of several islands that can be reached by ferry boats mainly operating from Saltholmen. Within the archipelago are the Älvsborg fortress, Vinga and Styrsö islands.
Festivals and fairs.
The annual Gothenburg Film Festival, is the largest film festival in Scandinavia. Similarly, the Gothenburg Book Fair, held each year in September, is the largest cultural event in Scandinavia.
The International Science Festival in Gothenburg is an annual festival since April 1997, in central Gothenburg with thought-provoking science activities for the public. The festival is visited by about people each year. This makes it the largest popular-science event in Sweden and one of the leading popular-science events in Europe.
Citing the financial crisis, the International Federation of Library Associations and Institutions moved the 2010 World Library and Information Congress, previously to be held in Brisbane, Australia, to Gothenburg. The even took place on 10–15August 2010.
Music.
Gothenburg has a diverse music community—the Gothenburg Symphony Orchestra is the best-known in classical music. Gothenburg also was the birthplace of the Swedish composer Kurt Atterberg. The first internationally successfully Swedish group, instrumental rock group The Spotnicks came from Gothenburg. Bands such as The Soundtrack of Our Lives and Ace of Base are well-known pop representatives of the city. There is also an active indie scene in Gothenburg. For example, the musician Jens Lekman was born in the suburb of Angered and named his 2007 release "Night Falls Over Kortedala" after another suburb, Kortedala. Other internationally acclaimed indie artists include the electro pop duos Studio, The Knife, Air France, The Tough Alliance, songwriter José González, and pop singer El Perro del Mar, as well as genre-bending quartet Little Dragon fronted by vocalist Yukimi Nagano. Another son of the city is one of Sweden's most popular singers, Håkan Hellström, who often includes many places from the city in his songs. The glam rock group Supergroupies derives from Gothenburg.
Gothenburg's own commercially successful At the Gates, In Flames, and Dark Tranquillity are credited with pioneering melodic death metal. Other well-known bands of the Gothenburg scene are thrash metal band The Haunted, progressive power metal band Evergrey, and power metal bands HammerFall and Dream Evil.
Many music festivals take place in the city every year. The Metaltown Festival is a two-day festival featuring heavy metal music bands, held in Gothenburg. It has been arranged annually since 2004, taking place at the Frihamnen venue. In June 2012, the festival included bands such as In Flames, Marilyn Manson, Slayer, Lamb of God, and Mastodon. Another popular festival, Way Out West, focuses more on rock, electronic, and hip-hop genres.
The 3D-animated anthropomorphic blue frog known as Crazy Frog originally hails from Gothenburg. The eurodance act marketed to children gained some brief success on several international music charts in the mid-2000s.
Sports.
As in all of Sweden, a variety of sports are followed, including football, ice hockey, basketball, handball, baseball, and figure skating. A varied amateur and professional sports clubs scene exists.
Gothenburg is the birthplace of football in Sweden as the first football match in Sweden was played there in 1892. The city's three major football clubs, IFK Göteborg, Örgryte IS, and GAIS share a total of 34 Swedish championships between them. IFK has also won the UEFA Cup twice. Other notable clubs include BK Häcken (football), Pixbo Wallenstam IBK (floorball), multiple national handball champion Redbergslids IK, and three-time national ice hockey champion Frölunda HC, Gothenburg had a professional basketball team, Gothia Basket, until 2010 when it ceased. The bandy department of GAIS, GAIS Bandy, played the first season in the highest division Elitserien last season. The group stage match between the main rivals Sweden and Russia in the 2013 Bandy World Championship was played at Arena Heden in central Gothenburg.
The city's most notable sports venues are Scandinavium, and Ullevi (multisport) and the newly built Gamla Ullevi (football).
The 2003 World Allround Speed Skating Championships were held in Rudhallen, Sweden's only indoor speed-skating arena. It is a part of Ruddalens IP, which also has a bandy field and several football fields.
The only Swedish heavyweight champion of the world in boxing, Ingemar Johansson, who took the title from Floyd Paterson in 1959, was from Gothenburg.
Gothenburg has hosted a number of international sporting events including the 1958 FIFA World Cup, the 1983 European Cup Winners' Cup Final, an NFL preseason game on 14August 1988 between the Chicago Bears and the Minnesota Vikings, the 1992 European Football Championship, the 1993 and the 2002 World Men's Handball Championship, the 1995 World Championships in Athletics, the 1997 World Championships in Swimming (short track), the 2002 Ice Hockey World Championships, the 2004 UEFA Cup final, the 2006 European Championships in Athletics, and the 2008 World Figure Skating Championships. Annual events held in the city are the Gothia Cup and the Göteborgsvarvet.
Gothenburg hosted the XIII FINA World Masters Championships in 2010. Diving, swimming, synchronized swimming and open-water competitions were held on 28July to 7August. The water polo events were played on the neighboring city of Borås.
Gothenburg is also home to the Gothenburg Sharks, a professional baseball team in the Elitserien division of baseball in Sweden.
With around 25,000 sailboats and yachts scattered about the city, sailing is a popular sports activity in the region, particularly because of the nearby Gothenburg Archipelago. In June 2015, the Volvo Ocean Race, professional sailing's leading crewed offshore race, concluded in Gothenburg, as well as an event in the 2015–2016 America's Cup World Series in August 2015.
Economy.
Due to Gothenburg's advantageous location in the centre of Scandinavia, trade and shipping have always played a major role in the city's economic history, and they continue to do so. Gothenburg port has come to be the largest harbour in Scandinavia.
Apart from trade, the second pillar of Gothenburg has traditionally been manufacturing and industry, which significantly contributes to the city's wealth. Major companies operating plants in the area include SKF, Volvo, and Ericsson. Volvo Cars is the largest employer in Gothenburg, not including jobs in supply companies. The blue-collar industries which have dominated the city for long are still important factors in the city's economy, but they are being gradually replaced by high-tech industries.
Banking and finance are also important, as well as the event and tourist industry.
Gothenburg is the terminus of the Valdemar-Göteborg gas pipeline, which brings natural gas from the North Sea fields to Sweden, through Denmark.
Historically, Gothenburg was home base from the 18th century of the Swedish East India Company. From its founding until the late 1970s, the city was a world leader in shipbuilding, with such shipyards as Eriksbergs Mekaniska Verkstad, Götaverken, Arendalsvarvet, and Lindholmens varv. Gothenburg is classified as a global city by GaWC, with a ranking of Gamma−. The city has been ranked as the 12th-most inventive city in the world by "Forbes".
Government.
Gothenburg became a city municipality with an elected city council when the first Swedish local government acts were implemented in 1863. The municipality has an assembly consisting of 81 members, elected every fourth year.
Demographics.
Gothenburg has a population of people born in Sweden of around 78%. Like most Swedish metropolitan areas, the city has a sizeable immigrant population. According to Statistics Sweden in 2014, 174,540 immigrants resided in Gothenburg, which was about 18% of the population.
Education.
Gothenburg has two universities, both of which started as colleges founded by private donations in the 19th century. The University of Gothenburg has about 25,000 students and is one of the largest universities in Scandinavia, and one of the most versatile in Sweden. Chalmers University of Technology is a well-known university located in Johanneberg south of the inner city, lately also established at Lindholmen in Norra Älvstranden, Hisingen.
In 2015, there were ten folk high schools in Gothenburg: "Agnesbergs folkhögskola", "Arbetarrörelsens folkhögskola i Göteborg", "Finska folkhögskolan", "Folkhögskolan i Angered", "Göteborgs folkhögskola", "Kvinnofolkhögskolan", "Mo Gård folkhögskola", "S:ta Birgittas folkhögskola", "Västra Götalands folkhögskolor" and "Wendelsbergs folkhögskola".
In 2015, there were 49 high schools Gothenburg. Some of the more notable schools are Sigrid Rudebecks gymnasium, Hvitfeldtska gymnasiet, Göteborgs Högre Samskola, Mikael Elias Teoretiska Gymnasium, and Donnergymnasiet. Some high-schools are also connected to big Swedish companies. One is SKF Technical high-school (belonging to SKF) and Gothenburg's technical high-school (belonging to Volvo). An international school with campuses in Guldheden and central Gothenburg is called the International School of the Gothenburg Region.
Transport.
Public transport.
With over of double track, the Gothenburg tram network covers most of the city and it is the largest tram/light rail network in Scandinavia. The bus network, however, is almost as important. There are also some boat and ferry services. The lack of a subway is due to the soft ground on which Gothenburg is situated. Tunneling is very expensive in such conditions. A commuter rail in Gothenburg services some nearby cities and towns.
Rail and intercity bus.
Other major transportation hubs are "Centralstationen" (Gothenburg Central Station) and the Nils Ericson Terminal with trains and buses to various destinations in Sweden, as well as connections to Oslo and Copenhagen (via Malmö).
Air.
There is one operational international airport in Gothenburg: Göteborg Landvetter Airport is located east of Gothenburg, and is the largest international airport serving the Gothenburg region in Sweden. With 4.9 million passengers in 2011, it is Sweden's second-largest airport.
It is operated by the Swedish Civil Aviation Administration. It has connections with about 40 scheduled destinations.
Göteborg City Airport is closed. On 13January 2015, Swedish airport operator Swedavia announced that Göteborg City Airport will not reopen for commercial services following an extensive rebuild of the airport started in November 2014, citing that the cost of making the airport viable for commercial operations again was too high, at 250 million kronor ($31 million). Commercial operations will be gradually wound down. The airport was located northwest of the city centre. It was formerly known as "Säve Flygplats." It is located within the borders of Gothenburg Municipality. In addition to commercial airlines, the airport was also operated by a number of rescue services, including the Swedish Coast Guard, and was used for other general aviation. Most civil air traffic to Göteborg City Airport was via low-cost airlines such as Ryanair and Wizz Air. Those companies have now been relocated to Landvetter Airport.
Sea.
The Swedish company Stena Line operates between Gothenburg/Frederikshavn in Denmark and Gothenburg/Kiel in Germany.
The "England ferry" ("Englandsfärjan") to Newcastle over Kristiansand (run by the Danish company DFDS Seaways) ceased at the end of October 2006, after being a Gothenburg institution since the 19th century. DFDS Seaways' sister company, DFDS Tor Line, continues to run scheduled cargo ships between Gothenburg and several English ports, and these have limited capacity for passengers and their private vehicles. Also freight ships to North America and East Asia leave from the port.
Freight.
Gothenburg is an intermodal logistics hub and Gothenburg harbour has access to Sweden and Norway via rail and trucks. Gothenburg harbour is the largest port in Scandinavia with a cargo turnover of 36.9 million tonnes per year in 2004.
Notable people.
Two of the noted people from Gothenburg are fictional, but have become synonymous with "people from Gothenburg". They are a working class couple called Kal and Ada, featured in "Gothenburg jokes" ("göteborgsvitsar"), songs, plays and names of events. Each year two persons who have significantly contributed to culture in the city are given the honorary titles of "Kal and Ada". A bronze statue of the couple made by Svenrobert Lundquist, was place outside the entrance to Liseberg in 1995.
Some of the noted people from Gothenburg are Academy Award Winning actress Alicia Vikander, footballer Gunnar Gren, artist Evert Taube, golfer Helen Alfredsson, industrialist Victor Hasselblad, singer-songwriter Björn Ulvaeus, diplomat Jan Eliasson, and YouTuber Pewdiepie.
International relations.
The Gothenburg Award is the city's international prize that recognises and supports work to achieve sustainable development – in the Gothenburg region and from a global perspective. The award, which is one million Swedish crowns, is administrated and funded by a coalition of the City of Gothenburg and 12 companies. Past winners of the award have included Kofi Annan, Al Gore, and Michael Biddle.
Twin towns and sister cities.
Gothenburg is twinned with:
With Lyon (France) there is no formal partnership, but "a joint willingness to cooperate".

</doc>
<doc id="11863" url="https://en.wikipedia.org/wiki?curid=11863" title="Gotland County">
Gotland County

Gotland County ("Gotlands län") is a county or "län" of Sweden. Gotland is located in the Baltic Sea to the east of Öland, and is the largest of Sweden's islands. Counties are usually sub-divided into municipalities, but Gotland County only consists of one municipality: Gotland Municipality. Gotland County is the only county in Sweden that is not governed by a county council. The municipality handles the tasks that are otherwise handled by the county council, mainly health care and public transport. Like other counties, Gotland has a County Administrative Board that oversees implementation of the Swedish state government. Both the County Administrative Board and the municipality have their seat in the largest city Visby, with over 22,000 inhabitants.
Province.
The counties of Sweden are no longer officially administrative units, but are used when reporting population size, politics, etc. In this case the province, the county and the municipality all have identical borders and cover an area of 3151 km² (3151 km² when excluding the lakes and rivers).
Administration.
Gotland is the only Swedish county that is not administered by a county council. Instead, the municipality is tasked with the responsibilities of a county, including public health care and public transport.
The main aim of the County Administrative Board is to fulfil the goals set in national politics by the Riksdag and the Government, to coordinate the interests and promote the development of the county, to establish regional goals and safeguard the due process of law in the handling of each case. The County Administrative Board is a Government agency headed by a Governor. See List of Gotland Governors.
Politics.
During a trial period the County Council provisions for Gotland has been evolved to provisions for a Regional Council, meaning that it has assumed certain tasks from the County Administrative Board. Similar provisions are applicable to the counties of Västra Götaland and Skåne during the trial period.
Localities in order of size.
The five most populous localities of Gotland County in 2010:
Heraldry.
Gotland County inherited its coat of arms from the province of Gotland. When it is shown with a royal crown it represents the County Administrative Board.

</doc>
<doc id="11866" url="https://en.wikipedia.org/wiki?curid=11866" title="Global Positioning System">
Global Positioning System

The Global Positioning System (GPS) is a space-based navigation system that provides location and time information in all weather conditions, anywhere on or near the Earth where there is an unobstructed line of sight to four or more GPS satellites. The system provides critical capabilities to military, civil, and commercial users around the world. The United States government created the system, maintains it, and makes it freely accessible to anyone with a GPS receiver.
The US began the GPS project in 1973 to overcome the limitations of previous navigation systems, integrating ideas from several predecessors, including a number of classified engineering design studies from the 1960s. The U.S. Department of Defense (DoD) developed the system, which originally used 24 satellites. It became fully operational in 1995. Roger L. Easton, Ivan A. Getting and Bradford Parkinson are credited with inventing it.
Advances in technology and new demands on the existing system have now led to efforts to modernize the GPS and implement the next generation of GPS Block IIIA satellites and Next Generation Operational Control System (OCX). Announcements from Vice President Al Gore and the White House in 1998 initiated these changes. In 2000, the U.S. Congress authorized the modernization effort, GPS III.
In addition to GPS, other systems are in use or under development. The Russian Global Navigation Satellite System (GLONASS) was developed contemporaneously with GPS, but suffered from incomplete coverage of the globe until the mid-2000s. There are also the planned European Union Galileo positioning system, India's Indian Regional Navigation Satellite System, China's BeiDou Navigation Satellite System, and the Japanese Quasi-Zenith Satellite System.
History.
The design of GPS is based partly on similar ground-based radio-navigation systems, such as LORAN and the Decca Navigator, developed in the early 1940s and used by the British Royal Navy during World War II.
In 1956, the German-American physicist Friedwardt Winterberg proposed a test of general relativity — detecting time slowing in a strong gravitational field using accurate atomic clocks placed in orbit inside artificial satellites. 
Special and general relativity predict that the clocks on the GPS satellites would be seen by the Earth's observers to run 38 microseconds faster per day than the clocks on the Earth. The GPS calculated positions would quickly drift into error, accumulating to 10 kilometers per day. The relativistic time effect of the GPS clocks running faster than the clocks on earth was corrected for in the design of GPS.
Predecessors.
The Soviet Union launched the first man-made satellite, Sputnik 1, in 1957. Two American physicists, William Guier and George Weiffenbach, at Johns Hopkins's Applied Physics Laboratory (APL), decided to monitor Sputnik's radio transmissions. Within hours they realized that, because of the Doppler effect, they could pinpoint where the satellite was along its orbit. The Director of the APL gave them access to their UNIVAC to do the heavy calculations required. 
The next spring, Frank McClure, the deputy director of the APL, asked Guier and Weiffenbach to investigate the inverse problem — pinpointing the user's location, given that of the satellite. (At the time, the Navy was developing the submarine-launched Polaris missile, which required them to know the submarine's location.) This led them and APL to develop the TRANSIT system. In 1959, ARPA (renamed DARPA in 1972) also played a role in TRANSIT.
The first satellite navigation system, TRANSIT, used by the United States Navy, was first successfully tested in 1960. It used a constellation of five satellites and could provide a navigational fix approximately once per hour. 
In 1967, the U.S. Navy developed the Timation satellite that proved the ability to place accurate clocks in space, a technology required by GPS.
In the 1970s, the ground-based OMEGA navigation system, based on phase comparison of signal transmission from pairs of stations, became the first worldwide radio navigation system. Limitations of these systems drove the need for a more universal navigation solution with greater accuracy.
While there were wide needs for accurate navigation in military and civilian sectors, almost none of those was seen as justification for the billions of dollars it would cost in research, development, deployment, and operation for a constellation of navigation satellites. During the Cold War arms race, the nuclear threat to the existence of the United States was the one need that did justify this cost in the view of the United States Congress. This deterrent effect is why GPS was funded. It is also the reason for the ultra secrecy at that time. The nuclear triad consisted of the United States Navy's submarine-launched ballistic missiles (SLBMs) along with United States Air Force (USAF) strategic bombers and intercontinental ballistic missiles (ICBMs). Considered vital to the nuclear deterrence posture, accurate determination of the SLBM launch position was a force multiplier.
Precise navigation would enable United States ballistic missile submarines to get an accurate fix of their positions before they launched their SLBMs. The USAF, with two thirds of the nuclear triad, also had requirements for a more accurate and reliable navigation system. The Navy and Air Force were developing their own technologies in parallel to solve what was essentially the same problem. 
To increase the survivability of ICBMs, there was a proposal to use mobile launch platforms (such as Russian SS-24 and SS-25) and so the need to fix the launch position had similarity to the SLBM situation.
In 1960, the Air Force proposed a radio-navigation system called MOSAIC (MObile System for Accurate ICBM Control) that was essentially a 3-D LORAN. A follow-on study, Project 57, was worked in 1963 and it was "in this study that the GPS concept was born." That same year, the concept was pursued as Project 621B, which had "many of the attributes that you now see in GPS" and promised increased accuracy for Air Force bombers as well as ICBMs. 
Updates from the Navy TRANSIT system were too slow for the high speeds of Air Force operation. The Naval Research Laboratory continued advancements with their Timation (Time Navigation) satellites, first launched in 1967, and with the third one in 1974 carrying the first atomic clock into orbit.
Another important predecessor to GPS came from a different branch of the United States military. In 1964, the United States Army orbited its first Sequential Collation of Range (SECOR) satellite used for geodetic surveying. The SECOR system included three ground-based transmitters from known locations that would send signals to the satellite transponder in orbit. A fourth ground-based station, at an undetermined position, could then use those signals to fix its location precisely. The last SECOR satellite was launched in 1969. 
Decades later, during the early years of GPS, civilian surveying became one of the first fields to make use of the new technology, because surveyors could reap benefits of signals from the less-than-complete GPS constellation years before it was declared operational. GPS can be thought of as an evolution of the SECOR system where the ground-based transmitters have been migrated into orbit.
Development.
With these parallel developments in the 1960s, it was realized that a superior system could be developed by synthesizing the best technologies from 621B, Transit, Timation, and SECOR in a multi-service program.
During Labor Day weekend in 1973, a meeting of about twelve military officers at the Pentagon discussed the creation of a "Defense Navigation Satellite System (DNSS)". It was at this meeting that "the real synthesis that became GPS was created." Later that year, the DNSS program was named "Navstar", or Navigation System Using Timing and Ranging. With the individual satellites being associated with the name Navstar (as with the predecessors Transit and Timation), a more fully encompassing name was used to identify the constellation of Navstar satellites, "Navstar-GPS". Ten "Block I" prototype satellites were launched between 1978 and 1985 (with one prototype being destroyed in a launch failure).
After Korean Air Lines Flight 007, a Boeing 747 carrying 269 people, was shot down in 1983 after straying into the USSR's prohibited airspace, in the vicinity of Sakhalin and Moneron Islands, President Ronald Reagan issued a directive making GPS freely available for civilian use, once it was sufficiently developed, as a common good. The first Block II satellite was launched on February 14, 1989, and the 24th satellite was launched in 1994. The GPS program cost at this point, not including the cost of the user equipment, but including the costs of the satellite launches, has been estimated at about USD$5 billion (then-year dollars). Roger L. Easton is widely credited as the primary inventor of GPS.
Initially, the highest quality signal was reserved for military use, and the signal available for civilian use was intentionally degraded (Selective Availability). This changed with President Bill Clinton signing a policy directive in 1996 to turn off Selective Availability in May 2000 to provide the same precision to civilians that was afforded to the military. The directive was proposed by the U.S. Secretary of Defense, William Perry, because of the widespread growth of differential GPS services to improve civilian accuracy and eliminate the U.S. military advantage. Moreover, the U.S. military was actively developing technologies to deny GPS service to potential adversaries on a regional basis.
Since its deployment, the U.S. has implemented several improvements to the GPS service including new signals for civil use and increased accuracy and integrity for all users, all the while maintaining compatibility with existing GPS equipment. Modernization of the satellite system has been an ongoing initiative by the U.S. Department of Defense through a series of satellite acquisitions to meet the growing needs of the military, civilians, and the commercial market.
As of early 2015, high-quality, FAA grade, Standard Positioning Service (SPS) GPS receivers provide horizontal accuracy of better than 3.5 meters, although many factors such as receiver quality and atmospheric issues can affect this accuracy.
GPS is owned and operated by the United States Government as a national resource. The Department of Defense is the steward of GPS. "Interagency GPS Executive Board (IGEB)" oversaw GPS policy matters from 1996 to 2004. After that the National Space-Based Positioning, Navigation and Timing Executive Committee was established by presidential directive in 2004 to advise and coordinate federal departments and agencies on matters concerning the GPS and related systems. The executive committee is chaired jointly by the deputy secretaries of defense and transportation. Its membership includes equivalent-level officials from the departments of state, commerce, and homeland security, the joint chiefs of staff, and NASA. Components of the executive office of the president participate as observers to the executive committee, and the FCC chairman participates as a liaison.
The U.S. Department of Defense is required by law to "maintain a Standard Positioning Service (as defined in the federal radio navigation plan and the standard positioning service signal specification) that will be available on a continuous, worldwide basis," and "develop measures to prevent hostile use of GPS and its augmentations without unduly disrupting or degrading civilian uses."
Awards.
On February 10, 1993, the National Aeronautic Association selected the GPS Team as winners of the 1992 Robert J. Collier Trophy, the nation's most prestigious aviation award. This team combines researchers from the Naval Research Laboratory, the USAF, the Aerospace Corporation, Rockwell International Corporation, and IBM Federal Systems Company. The citation honors them "for the most significant development for safe and efficient navigation and surveillance of air and spacecraft since the introduction of radio navigation 50 years ago."
Two GPS developers received the National Academy of Engineering Charles Stark Draper Prize for 2003:
GPS developer Roger L. Easton received the National Medal of Technology on February 13, 2006.
Francis X. Kane (Col. USAF, ret.) was inducted into the U.S. Air Force Space and Missile Pioneers Hall of Fame at Lackland A.F.B., San Antonio, Texas, March 2, 2010 for his role in space technology development and the engineering design concept of GPS conducted as part of Project 621B.
In 1998, GPS technology was inducted into the Space Foundation Space Technology Hall of Fame.
On October 4, 2011, the International Astronautical Federation (IAF) awarded the Global Positioning System (GPS) its 60th Anniversary Award, nominated by IAF member, the American Institute for Aeronautics and Astronautics (AIAA). The IAF Honors and Awards Committee recognized the uniqueness of the GPS program and the exemplary role it has played in building international collaboration for the benefit of humanity.
Basic concept of GPS.
Fundamentals.
The GPS concept is based on time and the known position of specialized satellites. The satellites carry very stable atomic clocks that are synchronized to each other and to ground clocks. Any drift from true time maintained on the ground is corrected daily. Likewise, the satellite locations are known with great precision. GPS receivers have clocks as well; however, they are not synchronized with true time, and are less stable. GPS satellites continuously transmit their current time and position. A GPS receiver monitors multiple satellites and solves equations to determine the exact position of the receiver and its deviation from true time. At a minimum, four satellites must be in view of the receiver for it to compute four unknown quantities (three position coordinates and clock deviation from satellite time).
More detailed description.
Each GPS satellite continually broadcasts a signal (carrier wave with modulation) that includes:
"Conceptually", the receiver measures the TOAs (according to its own clock) of four satellite signals. From the TOAs and the TOTs, the receiver forms four time of flight (TOF) values, which are (given the speed of light) approximately equivalent to receiver-satellite range differences. The receiver then computes its three-dimensional position and clock deviation from the four TOFs.
In practice the receiver position (in three dimensional Cartesian coordinates with origin at the Earth's center) and the offset of the receiver clock relative to the GPS time are computed simultaneously, using the navigation equations to process the TOFs.
The receiver's Earth-centered solution location is usually converted to latitude, longitude and height relative to an ellipsoidal Earth model. The height may then be further converted to height relative the geoid (e.g., EGM96) (essentially, mean sea level). These coordinates may be displayed, e.g. on a moving map display and/or recorded and/or used by some other system (e.g., a vehicle guidance system).
User-satellite geometry.
Although usually not formed explicitly in the receiver processing, the conceptual time differences of arrival (TDOAs) define the measurement geometry. Each TDOA corresponds to a hyperboloid of revolution (see Multilateration). The line connecting the two satellites involved (and its extensions) forms the axis of the hyperboloid. The receiver is located at the point where three hyperboloids intersect.
It is sometimes incorrectly said that the user location is at the intersection of three spheres. While simpler to visualize, this is only the case if the receiver has a clock synchronized with the satellite clocks (i.e., the receiver measures true ranges to the satellites rather than range differences). There are significant performance benefits to the user carrying a clock synchronized with the satellites. Foremost is that only three satellites are needed to compute a position solution. If this were part of the GPS system concept so that all users needed to carry a synchronized clock, then a smaller number of satellites could be deployed. However, the cost and complexity of the user equipment would increase significantly.
Receiver in continuous operation.
The description above is representative of a receiver start-up situation. Most receivers have a track algorithm, sometimes called a "tracker", that combines sets of satellite measurements collected at different times—in effect, taking advantage of the fact that successive receiver positions are usually close to each other. After a set of measurements are processed, the tracker predicts the receiver location corresponding to the next set of satellite measurements. When the new measurements are collected, the receiver uses a weighting scheme to combine the new measurements with the tracker prediction. In general, a tracker can (a) improve receiver position and time accuracy, (b) reject bad measurements, and (c) estimate receiver speed and direction.
The disadvantage of a tracker is that changes in speed or direction can only be computed with a delay, and that derived direction becomes inaccurate when the distance traveled between two position measurements drops below or near the random error of position measurement. GPS units can use measurements of the Doppler shift of the signals received to compute velocity accurately. More advanced navigation systems use additional sensors like a compass or an inertial navigation system to complement GPS.
Non-navigation applications.
In typical GPS operation as a navigator, four or more satellites must be visible to obtain an accurate result. The solution of the navigation equations gives the position of the receiver along with the difference between the time kept by the receiver's on-board clock and the true time-of-day, thereby eliminating the need for a more precise and possibly impractical receiver based clock. Applications for GPS such as time transfer, traffic signal timing, and synchronization of cell phone base stations, make use of this cheap and highly accurate timing. Some GPS applications use this time for display, or, other than for the basic position calculations, do not use it at all.
Although four satellites are required for normal operation, fewer apply in special cases. If one variable is already known, a receiver can determine its position using only three satellites. For example, a ship or aircraft may have known elevation. Some GPS receivers may use additional clues or assumptions such as reusing the last known altitude, dead reckoning, inertial navigation, or including information from the vehicle computer, to give a (possibly degraded) position when fewer than four satellites are visible.
Structure.
The current GPS consists of three major segments. These are the space segment (SS), a control segment (CS), and a user segment (US). The U.S. Air Force develops, maintains, and operates the space and control segments. GPS satellites broadcast signals from space, and each GPS receiver uses these signals to calculate its three-dimensional location (latitude, longitude, and altitude) and the current time.
The space segment is composed of 24 to 32 satellites in medium Earth orbit and also includes the payload adapters to the boosters required to launch them into orbit. The control segment is composed of a master control station (MCS), an alternate master control station, and a host of dedicated and shared ground antennas and monitor stations. The user segment is composed of hundreds of thousands of U.S. and allied military users of the secure GPS Precise Positioning Service, and hundreds of millions of civil, commercial, and scientific users of the Standard Positioning Service (see GPS navigation devices).
Space segment.
The space segment (SS) is composed of the orbiting GPS satellites, or Space Vehicles (SV) in GPS parlance. The GPS design originally called for 24 SVs, eight each in three approximately circular orbits, but this was modified to six orbital planes with four satellites each. The six orbit planes have approximately 55° inclination (tilt relative to the Earth's equator) and are separated by 60° right ascension of the ascending node (angle along the equator from a reference point to the orbit's intersection). The orbital period is one-half a sidereal day, i.e., 11 hours and 58 minutes so that the satellites pass over the same locations or almost the same locations every day. The orbits are arranged so that at least six satellites are always within line of sight from almost everywhere on the Earth's surface. The result of this objective is that the four satellites are not evenly spaced (90 degrees) apart within each orbit. In general terms, the angular difference between satellites in each orbit is 30, 105, 120, and 105 degrees apart, which sum to 360 degrees.
Orbiting at an altitude of approximately ; orbital radius of approximately , each SV makes two complete orbits each sidereal day, repeating the same ground track each day. This was very helpful during development because even with only four satellites, correct alignment means all four are visible from one spot for a few hours each day. For military operations, the ground track repeat can be used to ensure good coverage in combat zones.
, there are 32 satellites in the GPS constellation. The additional satellites improve the precision of GPS receiver calculations by providing redundant measurements. With the increased number of satellites, the constellation was changed to a nonuniform arrangement. Such an arrangement was shown to improve reliability and availability of the system, relative to a uniform system, when multiple satellites fail. About nine satellites are visible from any point on the ground at any one time (see animation at right), ensuring considerable redundancy over the minimum four satellites needed for a position.
Control segment.
The control segment is composed of:
The MCS can also access U.S. Air Force Satellite Control Network (AFSCN) ground antennas (for additional command and control capability) and NGA (National Geospatial-Intelligence Agency) monitor stations. The flight paths of the satellites are tracked by dedicated U.S. Air Force monitoring stations in Hawaii, Kwajalein Atoll, Ascension Island, Diego Garcia, Colorado Springs, Colorado and Cape Canaveral, along with shared NGA monitor stations operated in England, Argentina, Ecuador, Bahrain, Australia and Washington DC. The tracking information is sent to the Air Force Space Command MCS at Schriever Air Force Base ESE of Colorado Springs, which is operated by the 2nd Space Operations Squadron (2 SOPS) of the U.S. Air Force. Then 2 SOPS contacts each GPS satellite regularly with a navigational update using dedicated or shared (AFSCN) ground antennas (GPS dedicated ground antennas are located at Kwajalein, Ascension Island, Diego Garcia, and Cape Canaveral). These updates synchronize the atomic clocks on board the satellites to within a few nanoseconds of each other, and adjust the ephemeris of each satellite's internal orbital model. The updates are created by a Kalman filter that uses inputs from the ground monitoring stations, space weather information, and various other inputs.
Satellite maneuvers are not precise by GPS standards—so to change a satellite's orbit, the satellite must be marked "unhealthy", so receivers don't use it. After the satellite maneuver, engineers track the new orbit from the ground, upload the new ephemeris, and mark the satellite healthy again.
The Operation Control Segment (OCS) currently serves as the control segment of record. It provides the operational capability that supports GPS users and keeps the GPS system operational and performing within specification.
OCS successfully replaced the legacy 1970s-era mainframe computer at Schriever Air Force Base in September 2007. After installation, the system helped enable upgrades and provide a foundation for a new security architecture that supported U.S. armed forces. OCS will continue to be the ground control system of record until the new segment, Next Generation GPS Operation Control System (OCX), is fully developed and functional.
The new capabilities provided by OCX will be the cornerstone for revolutionizing GPS's mission capabilities, and enabling Air Force Space Command to greatly enhance GPS operational services to U.S. combat forces, civil partners and myriad domestic and international users.
The GPS OCX program also will reduce cost, schedule and technical risk. It is designed to provide 50% sustainment cost savings through efficient software architecture and Performance-Based Logistics. In addition, GPS OCX is expected to cost millions less than the cost to upgrade OCS while providing four times the capability.
The GPS OCX program represents a critical part of GPS modernization and provides significant information assurance improvements over the current GPS OCS program.
On September 14, 2011, the U.S. Air Force announced the completion of GPS OCX Preliminary Design Review and confirmed that the OCX program is ready for the next phase of development.
The GPS OCX program has missed major milestones and is pushing the GPS IIIA launch beyond April 2016.
User segment.
The user segment is composed of hundreds of thousands of U.S. and allied military users of the secure GPS Precise Positioning Service, and tens of millions of civil, commercial and scientific users of the Standard Positioning Service. In general, GPS receivers are composed of an antenna, tuned to the frequencies transmitted by the satellites, receiver-processors, and a highly stable clock (often a crystal oscillator). They may also include a display for providing location and speed information to the user. A receiver is often described by its number of channels: this signifies how many satellites it can monitor simultaneously. Originally limited to four or five, this has progressively increased over the years so that, , receivers typically have between 12 and 20 channels.
GPS receivers may include an input for differential corrections, using the RTCM SC-104 format. This is typically in the form of an RS-232 port at 4,800 bit/s speed. Data is actually sent at a much lower rate, which limits the accuracy of the signal sent using RTCM. Receivers with internal DGPS receivers can outperform those using external RTCM data. , even low-cost units commonly include Wide Area Augmentation System (WAAS) receivers.
Many GPS receivers can relay position data to a PC or other device using the NMEA 0183 protocol. Although this protocol is officially defined by the National Marine Electronics Association (NMEA), references to this protocol have been compiled from public records, allowing open source tools like gpsd to read the protocol without violating intellectual property laws. Other proprietary protocols exist as well, such as the SiRF and MTK protocols. Receivers can interface with other devices using methods including a serial connection, USB, or Bluetooth.
Applications.
While originally a military project, GPS is considered a "dual-use" technology, meaning it has significant military and civilian applications.
GPS has become a widely deployed and useful tool for commerce, scientific uses, tracking, and surveillance. GPS's accurate time facilitates everyday activities such as banking, mobile phone operations, and even the control of power grids by allowing well synchronized hand-off switching.
Civilian.
Many civilian applications use one or more of GPS's three basic components: absolute location, relative movement, and time transfer.
Restrictions on civilian use.
The U.S. government controls the export of some civilian receivers. All GPS receivers capable of functioning above altitude and , or designed or modified for use with unmanned air vehicles like, e.g., ballistic or cruise missile systems, are classified as munitions (weapons)—which means they require State Department export licenses.
This rule applies even to otherwise purely civilian units that only receive the L1 frequency and the C/A (Coarse/Acquisition) code.
Disabling operation above these limits exempts the receiver from classification as a munition. Vendor interpretations differ. The rule refers to operation at both the target altitude and speed, but some receivers stop operating even when stationary. This has caused problems with some amateur radio balloon launches that regularly reach .
These limits only apply to units or components exported from the USA. There is a growing trade in various components, including GPS units from other countries. These are expressly sold as ITAR-free.
Military.
As of 2009, military GPS applications include:
GPS type navigation was first used in war in the 1991 Persian Gulf War, before GPS was fully developed in 1995, to assist Coalition Forces to navigate and perform maneuvers in the war. The war also demonstrated the vulnerability of GPS to being jammed, when Iraqi forces added noise to the weak GPS signal transmission to protect Iraqi targets.
Communication.
The navigational signals transmitted by GPS satellites encode a variety of information including satellite positions, the state of the internal clocks, and the health of the network. These signals are transmitted on two separate carrier frequencies that are common to all satellites in the network. Two different encodings are used: a public encoding that enables lower resolution navigation, and an encrypted encoding used by the U.S. military.
Message format.
Each GPS satellite continuously broadcasts a "navigation message" on L1 C/A and L2 P/Y frequencies at a rate of 50 bits per second (see bitrate). Each complete message takes 750 seconds (12 1/2 minutes) to complete. The message structure has a basic format of a 1500-bit-long frame made up of five subframes, each subframe being 300 bits (6 seconds) long. Subframes 4 and 5 are subcommutated 25 times each, so that a complete data message requires the transmission of 25 full frames. Each subframe consists of ten words, each 30 bits long. Thus, with 300 bits in a subframe times 5 subframes in a frame times 25 frames in a message, each message is 37,500 bits long. At a transmission rate of 50-bit/s, this gives 750 seconds to transmit an entire almanac message (GPS). Each 30-second frame begins precisely on the minute or half-minute as indicated by the atomic clock on each satellite.
The first subframe of each frame encodes the week number and the time within the week, as well as the data about the health of the satellite. The second and the third subframes contain the "ephemeris" – the precise orbit for the satellite. The fourth and fifth subframes contain the "almanac", which contains coarse orbit and status information for up to 32 satellites in the constellation as well as data related to error correction. Thus, to obtain an accurate satellite location from this transmitted message, the receiver must demodulate the message from each satellite it includes in its solution for 18 to 30 seconds. To collect all transmitted almanacs, the receiver must demodulate the message for 732 to 750 seconds or 12 1/2 minutes.
All satellites broadcast at the same frequencies, encoding signals using unique code division multiple access (CDMA) so receivers can distinguish individual satellites from each other. The system uses two distinct CDMA encoding types: the coarse/acquisition (C/A) code, which is accessible by the general public, and the precise (P(Y)) code, which is encrypted so that only the U.S. military and other NATO nations who have been given access to the encryption code can access it.
The ephemeris is updated every 2 hours and is generally valid for 4 hours, with provisions for updates every 6 hours or longer in non-nominal conditions. The almanac is updated typically every 24 hours. Additionally, data for a few weeks following is uploaded in case of transmission updates that delay data upload.
Satellite frequencies.
All satellites broadcast at the same two frequencies, 1.57542 GHz (L1 signal) and 1.2276 GHz (L2 signal). The satellite network uses a CDMA spread-spectrum technique where the low-bitrate message data is encoded with a high-rate pseudo-random (PRN) sequence that is different for each satellite. The receiver must be aware of the PRN codes for each satellite to reconstruct the actual message data. The C/A code, for civilian use, transmits data at 1.023 million chips per second, whereas the P code, for U.S. military use, transmits at 10.23 million chips per second. The actual internal reference of the satellites is 10.22999999543 MHz to compensate for relativistic effects that make observers on the Earth perceive a different time reference with respect to the transmitters in orbit. The L1 carrier is modulated by both the C/A and P codes, while the L2 carrier is only modulated by the P code. The P code can be encrypted as a so-called P(Y) code that is only available to military equipment with a proper decryption key. Both the C/A and P(Y) codes impart the precise time-of-day to the user.
The L3 signal at a frequency of 1.38105 GHz is used to transmit data from the satellites to ground stations. This data is used by the United States Nuclear Detonation (NUDET) Detection System (USNDS) to detect, locate, and report nuclear detonations (NUDETs) in the Earth's atmosphere and near space. One usage is the enforcement of nuclear test ban treaties.
The L4 band at 1.379913 GHz is being studied for additional ionospheric correction.
The L5 frequency band at 1.17645 GHz was added in the process of GPS modernization. This frequency falls into an internationally protected range for aeronautical navigation, promising little or no interference under all circumstances. The first Block IIF satellite that provides this signal was launched in 2010. The L5 consists of two carrier components that are in phase quadrature with each other. Each carrier component is bi-phase shift key (BPSK) modulated by a separate bit train. "L5, the third civil GPS signal, will eventually support safety-of-life applications for aviation and provide improved availability and accuracy."
A conditional waiver has recently been granted to LightSquared to operate a terrestrial broadband service near the L1 band. Although LightSquared had applied for a license to operate in the 1525 to 1559 band as early as 2003 and it was put out for public comment, the FCC asked LightSquared to form a study group with the GPS community to test GPS receivers and identify issue that might arise due to the larger signal power from the LightSquared terrestrial network. The GPS community had not objected to the LightSquared (formerly MSV and SkyTerra) applications until November 2010, when LightSquared applied for a modification to its Ancillary Terrestrial Component (ATC) authorization. This filing (SAT-MOD-20101118-00239) amounted to a request to run several orders of magnitude more power in the same frequency band for terrestrial base stations, essentially repurposing what was supposed to be a "quiet neighborhood" for signals from space as the equivalent of a cellular network. Testing in the first half of 2011 has demonstrated that the impact of the lower 10 MHz of spectrum is minimal to GPS devices (less than 1% of the total GPS devices are affected). The upper 10 MHz intended for use by LightSquared may have some impact on GPS devices. There is some concern that this may seriously degrade the GPS signal for many consumer uses. Aviation Week magazine reports that the latest testing (June 2011) confirms "significant jamming" of GPS by LightSquared's system.
Demodulation and decoding.
Because all of the satellite signals are modulated onto the same L1 carrier frequency, the signals must be separated after demodulation. This is done by assigning each satellite a unique binary sequence known as a Gold code. The signals are decoded after demodulation using addition of the Gold codes corresponding to the satellites monitored by the receiver.
If the almanac information has previously been acquired, the receiver picks the satellites to listen for by their PRNs, unique numbers in the range 1 through 32. If the almanac information is not in memory, the receiver enters a search mode until a lock is obtained on one of the satellites. To obtain a lock, it is necessary that there be an unobstructed line of sight from the receiver to the satellite. The receiver can then acquire the almanac and determine the satellites it should listen for. As it detects each satellite's signal, it identifies it by its distinct C/A code pattern. There can be a delay of up to 30 seconds before the first estimate of position because of the need to read the ephemeris data.
Processing of the navigation message enables the determination of the time of transmission and the satellite position at this time. For more information see Demodulation and Decoding, Advanced.
Navigation equations.
Problem description.
The receiver uses messages received from satellites to determine the satellite positions and time sent. The "x, y," and "z" components of satellite position and the time sent are designated as 'x, y, z, s' where the subscript "i" denotes the satellite and has the value 1, 2, ..., "n", where "n" ≥ 4. When the time of message reception indicated by the on-board receiver clock is "t̃", the true reception time is , where "b" is the receiver's clock bias from the much more accurate GPS system clocks employed by the satellites. The receiver clock bias is the same for all received satellite signals (assuming the satellite clocks are all perfectly synchronized). The message's transit time is , where "s" is the satellite time. Assuming the message traveled at the speed of light, "c", the distance traveled is .
For n satellites, the equations to satisfy are:
or in terms of "pseudoranges", formula_2, as
Since the equations have four unknowns 'x, y, z, b'—the three components of GPS receiver position and the clock bias—signals from at least four satellites are necessary to attempt solving these equations. They can be solved by algebraic or numerical methods. Existence and uniqueness of GPS solutions are discussed by Abell and Chaffee. When "n" is greater than 4 this system is overdetermined and a fitting method must be used.
With each combination of satellites, GDOP quantities can be calculated based on the relative sky directions of the satellites used. The receiver location is expressed in a specific coordinate system, such as latitude and longitude using the WGS 84 geodetic datum or a country-specific system.
Geometric interpretation.
The GPS equations can be solved by numerical and analytical methods. Geometrical interpretations can enhance the understanding of these solution methods.
Spheres.
The measured ranges, called pseudoranges, contain clock errors. In a simplified idealization in which the ranges are synchronized, these true ranges represent the radii of spheres, each centered on one of the transmitting satellites. The solution for the position of the receiver is then at the intersection of the surfaces of three of these spheres. If more than the minimum number of ranges is available, a near intersection of more than three sphere surfaces could be found via, e.g. least squares.
Hyperboloids.
If the distance traveled between the receiver and satellite "i" and the distance traveled between the receiver and satellite "j" are subtracted, the result is , which only involves known or measured quantities. The locus of points having a constant difference in distance to two points (here, two satellites) is a hyperboloid (see Multilateration). Thus, from four or more measured reception times, the receiver can be placed at the intersection of the surfaces of three or more hyperboloids.
Spherical cones.
The solution space 'x, y, z, b' can be seen as a four-dimensional geometric space. In that case each of the equations describes a spherical cone, with the cusp located at the satellite, and the base a sphere around the satellite. The receiver is at the intersection of four or more of such cones.
Solution methods.
Least squares.
When more than four satellites are available, the calculation can use the four best, or more than four simultaneously (up to all visible satellites), depending on the number of receiver channels, processing capability, and geometric dilution of precision (GDOP).
Using more than four involves an over-determined system of equations with no unique solution; such a system can be solved by a least-squares or weighted least squares method.
Iterative.
Both the equations for four satellites, or the least squares equations for more than four, are non-linear and need special solution methods. A common approach is by iteration on a linearized form of the equations, (e.g., Gauss–Newton algorithm).
The GPS system was initially developed assuming use of a numerical least-squares solution method—i.e., before closed-form solutions were found.
Closed-form.
One closed-form solution to the above set of equations was developed by S. Bancroft. Its properties are well known; in particular, proponents claim it is superior in low-GDOP situations, compared to iterative least squares methods.
Bancroft's method is algebraic, as opposed to numerical, and can be used for four or more satellites. When four satellites are used, the key steps are inversion of a 4x4 matrix and solution of a single-variable quadratic equation. Bancroft's method provides one or two solutions for the unknown quantities. When there are two (usually the case), only one is a near-Earth sensible solution.
When a receiver uses more than four satellites for a solution, Bancroft uses the generalized inverse (i.e., the pseudoinverse) to find a solution. However, a case has been made that iterative methods (e.g., Gauss–Newton algorithm) for solving over-determined non-linear least squares (NLLS) problems generally provide more accurate solutions.
Leick et al. (2015) states that "Bancroft's (1985) solution is a very early, if not the first, closed-form solution."
Other closed-form solutions were published afterwards, although their adoption in practice is unclear.
Error sources and analysis.
GPS error analysis examines error sources in GPS results and the expected size of those errors. GPS makes corrections for receiver clock errors and other effects, but some residual errors remain uncorrected. Error sources include signal arrival time measurements, numerical calculations, atmospheric effects (ionospheric/tropospheric delays), ephemeris and clock data, multipath signals, and natural and artificial interference. Magnitude of residual errors from these sources depends on geometric dilution of precision. Artificial errors may result from jamming devices and threaten ships and aircraft or from intentional signal degradation through selective availability, which limited accuracy to ~6–12 m, but has been switched off since May 1, 2000.
Accuracy enhancement and surveying.
Augmentation.
Integrating external information into the calculation process can materially improve accuracy. Such augmentation systems are generally named or described based on how the information arrives. Some systems transmit additional error information (such as clock drift, ephemera, or ionospheric delay), others characterize prior errors, while a third group provides additional navigational or vehicle information.
Examples of augmentation systems include the Wide Area Augmentation System (WAAS), European Geostationary Navigation Overlay Service (EGNOS), Differential GPS (DGPS), inertial navigation systems (INS) and Assisted GPS. The standard accuracy of about can be augmented to with DGPS, and to about with WAAS.
Precise monitoring.
Accuracy can be improved through precise monitoring and measurement of existing GPS signals in additional or alternate ways.
The largest remaining error is usually the unpredictable delay through the ionosphere. The spacecraft broadcast ionospheric model parameters, but some errors remain. This is one reason GPS spacecraft transmit on at least two frequencies, L1 and L2. Ionospheric delay is a well-defined function of frequency and the total electron content (TEC) along the path, so measuring the arrival time difference between the frequencies determines TEC and thus the precise ionospheric delay at each frequency.
Military receivers can decode the P(Y) code transmitted on both L1 and L2. Without decryption keys, it is still possible to use a "codeless" technique to compare the P(Y) codes on L1 and L2 to gain much of the same error information. However, this technique is slow, so it is currently available only on specialized surveying equipment. In the future, additional civilian codes are expected to be transmitted on the L2 and L5 frequencies (see GPS modernization). All users will then be able to perform dual-frequency measurements and directly compute ionospheric delay errors.
A second form of precise monitoring is called "Carrier-Phase Enhancement" (CPGPS). This corrects the error that arises because the pulse transition of the PRN is not instantaneous, and thus the correlation (satellite–receiver sequence matching) operation is imperfect. CPGPS uses the L1 carrier wave, which has a period of formula_5, which is about one-thousandth of the C/A Gold code bit period of formula_6, to act as an additional clock signal and resolve the uncertainty. The phase difference error in the normal GPS amounts to of ambiguity. CPGPS working to within 1% of perfect transition reduces this error to of ambiguity. By eliminating this error source, CPGPS coupled with DGPS normally realizes between of absolute accuracy.
"Relative Kinematic Positioning" (RKP) is a third alternative for a precise GPS-based positioning system. In this approach, determination of range signal can be resolved to a precision of less than . This is done by resolving the number of cycles that the signal is transmitted and received by the receiver by using a combination of differential GPS (DGPS) correction data, transmitting GPS signal phase information and ambiguity resolution techniques via statistical tests—possibly with processing in real-time (real-time kinematic positioning, RTK).
Timekeeping.
Leap seconds.
While most clocks derive their time from Coordinated Universal Time (UTC), the atomic clocks on the satellites are set to GPS time (GPST; see the page of United States Naval Observatory). The difference is that GPS time is not corrected to match the rotation of the Earth, so it does not contain leap seconds or other corrections that are periodically added to UTC. GPS time was set to match UTC in 1980, but has since diverged. The lack of corrections means that GPS time remains at a constant offset with International Atomic Time (TAI) (TAI − GPS = 19 seconds). Periodic corrections are performed to the on-board clocks to keep them synchronized with ground clocks.
The GPS navigation message includes the difference between GPS time and UTC. As of July 2015, GPS time is 17 seconds ahead of UTC because of the leap second added to UTC on June 30, 2015. Receivers subtract this offset from GPS time to calculate UTC and specific timezone values. New GPS units may not show the correct UTC time until after receiving the UTC offset message. The GPS-UTC offset field can accommodate 255 leap seconds (eight bits).
Accuracy.
GPS time is theoretically accurate to about 14 nanoseconds. However, most receivers lose accuracy in the interpretation of the signals and are only accurate to 100 nanoseconds.
Format.
As opposed to the year, month, and day format of the Gregorian calendar, the GPS date is expressed as a week number and a seconds-into-week number. The week number is transmitted as a ten-bit field in the C/A and P(Y) navigation messages, and so it becomes zero again every 1,024 weeks (19.6 years). GPS week zero started at 00:00:00 UTC (00:00:19 TAI) on January 6, 1980, and the week number became zero again for the first time at 23:59:47 UTC on August 21, 1999 (00:00:19 TAI on August 22, 1999). To determine the current Gregorian date, a GPS receiver must be provided with the approximate date (to within 3,584 days) to correctly translate the GPS date signal. To address this concern the modernized GPS navigation message uses a 13-bit field that only repeats every 8,192 weeks (157 years), thus lasting until the year 2137 (157 years after GPS week zero).
Carrier phase tracking (surveying).
Another method that is used in surveying applications is carrier phase tracking. The period of the carrier frequency multiplied by the speed of light gives the wavelength, which is about 0.19 meters for the L1 carrier. Accuracy within 1% of wavelength in detecting the leading edge reduces this component of pseudorange error to as little as 2 millimeters. This compares to 3 meters for the C/A code and 0.3 meters for the P code.
However, 2 millimeter accuracy requires measuring the total phase—the number of waves multiplied by the wavelength plus the fractional wavelength, which requires specially equipped receivers. This method has many surveying applications. It is accurate enough for real-time tracking of the very slow motions of tectonic plates, typically per year.
Triple differencing followed by numerical root finding, and a mathematical technique called least squares can estimate the position of one receiver given the position of another. First, compute the difference between satellites, then between receivers, and finally between epochs. Other orders of taking differences are equally valid. Detailed discussion of the errors is omitted.
The satellite carrier total phase can be measured with ambiguity as to the number of cycles. Let formula_7 denote the phase of the carrier of satellite "j" measured by receiver "i" at time formula_8. This notation shows the meaning of the subscripts "i, j," and "k." The receiver ("r"), satellite ("s"), and time ("t") come in alphabetical order as arguments of formula_9 and to balance readability and conciseness, let formula_10 be a concise abbreviation. Also we define three functions, :formula_11, which return differences between receivers, satellites, and time points, respectively. Each function has variables with three subscripts as its arguments. These three functions are defined below. If formula_12 is a function of the three integer arguments, "i, j," and "k" then it is a valid argument for the functions, :formula_11, with the values defined as
Also if formula_17 are valid arguments for the three functions and "a" and "b" are constants then
formula_18 is a valid argument with values defined as
Receiver clock errors can be approximately eliminated by differencing the phases measured from satellite 1 with that from satellite 2 at the same epoch. This difference is designated as formula_22
Double differencing computes the difference of receiver 1's satellite difference from that of receiver 2. This approximately eliminates satellite clock errors. This double difference is:
Triple differencing subtracts the receiver difference from time 1 from that of time 2. This eliminates the ambiguity associated with the integral number of wavelengths in carrier phase provided this ambiguity does not change with time. Thus the triple difference result eliminates practically all clock bias errors and the integer ambiguity. Atmospheric delay and satellite ephemeris errors have been significantly reduced. This triple difference is:
Triple difference results can be used to estimate unknown variables. For example, if the position of receiver 1 is known but the position of receiver 2 unknown, it may be possible to estimate the position of receiver 2 using numerical root finding and least squares. Triple difference results for three independent time pairs may be sufficient to solve for receiver 2's three position components. This may require a numerical procedure. An approximation of receiver 2's position is required to use such a numerical method. This initial value can probably be provided from the navigation message and the intersection of sphere surfaces. Such a reasonable estimate can be key to successful multidimensional root finding. Iterating from three time pairs and a fairly good initial value produces one observed triple difference result for receiver 2's position. Processing additional time pairs can improve accuracy, overdetermining the answer with multiple solutions. Least squares can estimate an overdetermined system. Least squares determines the position of receiver 2 that best fits the observed triple difference results for receiver 2 positions under the criterion of minimizing the sum of the squares.
Regulatory spectrum issues concerning GPS receivers.
In the United States, GPS receivers are regulated under the Federal Communications Commission's (FCC) Part 15 rules. As indicated in the manuals of GPS-enabled devices sold in the United States, as a Part 15 device, it "must accept any interference received, including interference that may cause undesired operation." With respect to GPS devices in particular, the FCC states that GPS receiver manufacturers, "must use receivers that reasonably discriminate against reception of signals outside their allocated spectrum." For the last 30 years, GPS receivers have operated next to the Mobile Satellite Service band, and have discriminated against reception of mobile satellite services, such as Inmarsat, without any issue.
The spectrum allocated for GPS L1 use by the FCC is 1559 to 1610 MHz, while the spectrum allocated for satellite-to-ground use owned by Lightsquared is the Mobile Satellite Service band. Since 1996, the FCC has authorized licensed use of the spectrum neighboring the GPS band of 1525 to 1559 MHz to the Virginia company LightSquared. On March 1, 2001, the FCC received an application from LightSquared's predecessor, Motient Services to use their allocated frequencies for an integrated satellite-terrestrial service. In 2002, the U.S. GPS Industry Council came to an out-of-band-emissions (OOBE) agreement with LightSquared to prevent transmissions from LightSquared's ground-based stations from emitting transmissions into the neighboring GPS band of 1559 to 1610 MHz. In 2004, the FCC adopted the OOBE agreement in its authorization for LightSquared to deploy a ground-based network ancillary to their satellite system – known as the Ancillary Tower Components (ATCs) – "We will authorize MSS ATC subject to conditions that ensure that the added terrestrial component remains ancillary to the principal MSS offering. We do not intend, nor will we permit, the terrestrial component to become a stand-alone service."  This authorization was reviewed and approved by the U.S. Interdepartment Radio Advisory Committee, which includes the U.S. Department of Agriculture, U.S. Air Force, U.S. Army, U.S. Coast Guard, Federal Aviation Administration, National Aeronautics and Space Administration, Interior, and U.S. Department of Transportation.
In January 2011, the FCC conditionally authorized LightSquared's wholesale customers—such as Best Buy, Sharp, and C Spire—to only purchase an integrated satellite-ground-based service from LightSquared and re-sell that integrated service on devices that are equipped to only use the ground-based signal using LightSquared's allocated frequencies of 1525 to 1559 MHz. In December 2010, GPS receiver manufacturers expressed concerns to the FCC that LightSquared's signal would interfere with GPS receiver devices although the FCC's policy considerations leading up to the January 2011 order did not pertain to any proposed changes to the maximum number of ground-based LightSquared stations or the maximum power at which these stations could operate. The January 2011 order makes final authorization contingent upon studies of GPS interference issues carried out by a LightSquared led working group along with GPS industry and Federal agency participation. On February 14, 2012, the FCC initiated proceedings to vacate LightSquared's Conditional Waiver Order based on the NTIA's conclusion that there was currently no practical way to mitigate potential GPS interference.
GPS receiver manufacturers design GPS receivers to use spectrum beyond the GPS-allocated band. In some cases, GPS receivers are designed to use up to 400 MHz of spectrum in either direction of the L1 frequency of 1575.42 MHz, because mobile satellite services in those regions are broadcasting from space to ground, and at power levels commensurate with mobile satellite services. However, as regulated under the FCC's Part 15 rules, GPS receivers are not warranted protection from signals outside GPS-allocated spectrum. This is why GPS operates next to the Mobile Satellite Service band, and also why the Mobile Satellite Service band operates next to GPS. The symbiotic relationship of spectrum allocation ensures that users of both bands are able to operate cooperatively and freely.
The FCC adopted rules in February 2003 that allowed Mobile Satellite Service (MSS) licensees such as LightSquared to construct a small number of ancillary ground-based towers in their licensed spectrum to "promote more efficient use of terrestrial wireless spectrum." In those 2003 rules, the FCC stated "As a preliminary matter, terrestrial ommercial Mobile Radio Service (“CMRS” and MSS ATC are expected to have different prices, coverage, product acceptance and distribution; therefore, the two services appear, at best, to be imperfect substitutes for one another that would be operating in predominately different market segments... MSS ATC is unlikely to compete directly with terrestrial CMRS for the same customer base...". In 2004, the FCC clarified that the ground-based towers would be ancillary, noting that "We will authorize MSS ATC subject to conditions that ensure that the added terrestrial component remains ancillary to the principal MSS offering. We do not intend, nor will we permit, the terrestrial component to become a stand-alone service." In July 2010, the FCC stated that it expected LightSquared to use its authority to offer an integrated satellite-terrestrial service to "provide mobile broadband services similar to those provided by terrestrial mobile providers and enhance competition in the mobile broadband sector." However, GPS receiver manufacturers have argued that LightSquared's licensed spectrum of 1525 to 1559 MHz was never envisioned as being used for high-speed wireless broadband based on the 2003 and 2004 FCC ATC rulings making clear that the Ancillary Tower Component (ATC) would be, in fact, ancillary to the primary satellite component. To build public support of efforts to continue the 2004 FCC authorization of LightSquared's ancillary terrestrial component vs. a simple ground-based LTE service in the Mobile Satellite Service band, GPS receiver manufacturer Trimble Navigation Ltd. formed the "Coalition To Save Our GPS."
The FCC and LightSquared have each made public commitments to solve the GPS interference issue before the network is allowed to operate. However, according to Chris Dancy of the Aircraft Owners and Pilots Association, airline pilots with the type of systems that would be affected "may go off course and not even realize it." The problems could also affect the Federal Aviation Administration upgrade to the air traffic control system, United States Defense Department guidance, and local emergency services including 911.
On February 14, 2012, the U.S. Federal Communications Commission (FCC) moved to bar LightSquared's planned national broadband network after being informed by the National Telecommunications and Information Administration (NTIA), the federal agency that coordinates spectrum uses for the military and other federal government entities, that "there is no practical way to mitigate potential interference at this time". LightSquared is challenging the FCC's action.
Other systems.
Other satellite navigation systems in use or various states of development include:

</doc>

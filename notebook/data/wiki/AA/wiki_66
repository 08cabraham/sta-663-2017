<doc id="9223" url="https://en.wikipedia.org/wiki?curid=9223" title="Economics">
Economics

Economics is the social science that describes the factors that determine the production, distribution and consumption of goods and services.
The term "economics" comes from the Ancient Greek from (', "house") and (', "custom" or "law"), hence "rules of the house (hold for good management)". 'Political economy' was the earlier name for the subject, but economists in the late 19th century suggested "economics" as a shorter term for "economic science" to establish itself as a separate discipline outside of political science and other social sciences.
Economics focuses on the behavior and interactions of economic agents and how economies work. Consistent with this focus, primary textbooks often distinguish between microeconomics and macroeconomics. Microeconomics examines the behavior of basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the entire economy (meaning aggregated production, consumption, savings, and investment) and issues affecting it, including unemployment of resources (labor, capital, and land), inflation, economic growth, and the public policies that address these issues (monetary, fiscal, and other policies).
Other broad distinctions within economics include those between positive economics, describing "what is," and normative economics, advocating "what ought to be"; between economic theory and applied economics; between rational and behavioral economics; and between mainstream economics (more "orthodox" and dealing with the "rationality-individualism-equilibrium nexus") and heterodox economics (more "radical" and dealing with the "institutions-history-social structure nexus").
Besides the traditional concern in production, distribution, and consumption in an economy, economic analysis may be applied throughout society, as "in" business, finance, health care, and government. Economic analyses may also be applied "to" such diverse subjects as crime, education, the family, law, politics, religion, social institutions, war, science, and the environment. Education, for example, requires time, effort, and expenses, plus the foregone income and experience, yet these losses can be weighted against future benefits education may bring to the agent or the economy. At the turn of the 21st century, the expanding domain of economics in the social sciences has been described as economic imperialism.
The ultimate goal of economics is to improve the living conditions of people in their everyday life.
Definitions.
There are a variety of modern definitions of economics. Some of the differences may reflect evolving views of the subject or different views among economists. Scottish philosopher Adam Smith (1776) defined what was then called political economy as "an inquiry into the nature and causes of the wealth of nations", in particular as:
J.-B. Say (1803), distinguishing the subject from its public-policy uses, defines it as the science "of" production, distribution, and consumption of wealth. On the satirical side, Thomas Carlyle (1849) coined "the dismal science" as an epithet for classical economics, in this context, commonly linked to the pessimistic analysis of Malthus (1798). John Stuart Mill (1844) defines the subject in a social context as:
Alfred Marshall provides a still widely cited definition in his textbook "Principles of Economics" (1890) that extends analysis beyond wealth and from the societal to the microeconomic level:
Lionel Robbins (1932) developed implications of what has been termed "erhaps the most commonly accepted current definition of the subject":
Robbins describes the definition as not "classificatory" in "pick[ing] out certain "kinds" of behaviour" but rather "analytical" in "focus[ing] attention on a particular "aspect" of behaviour, the form imposed by the influence of [[scarcity]]." He affirmed that previous economist have usually centered their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow. But he said that economics can be used to study other things, such as war, that are outside its usual focus. This is because war has as the goal winning it (as a sought after end), generates both cost and benefits; and, resources (human life and other costs) are used to attain the goal. If the war is not winnable or if the expected costs outweigh the benefits, the deciding actors (assuming they are rational) may never go to war (a decision) but rather explore other alternatives. We cannot define economics as the science that studies wealth, war, crime, education, and any other field economic analysis can be applied to; but, as the science that studies a particular common aspect of each of those subjects (they all use scarce resources to attain a sought after end).
Some subsequent comments criticized the definition as overly broad in failing to limit its subject matter to analysis of markets. From the 1960s, however, such comments abated as the economic theory of maximizing behavior and [[rational choice|rational-choice]] modeling [[Economic imperialism (economics)|expanded the domain]] of the subject to areas previously treated in other fields. There are other criticisms as well, such as in scarcity not accounting for the [[macroeconomics]] of high unemployment.
[[Gary Becker]], a contributor to the expansion of economics into new areas, describes the approach he favors as "combin[ing the] assumptions of maximizing behavior, stable [[preference (economics)|preferences]], and [[economic equilibrium|market equilibrium]], used relentlessly and unflinchingly." One commentary characterizes the remark as making economics an approach rather than a subject matter but with great specificity as to the "choice process and the type of [[social interaction]] that [such] analysis involves." The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat. Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.
Microeconomics.
Markets.
[[File:Ballard Farmers' Market - vegetables.jpg|thumb|250px|Economists study trade, production and consumption decisions, such as those that occur in a traditional [[marketplace]].|alt=A vegetable vendor in a marketplace.]]
[[File:Sao Paulo Stock Exchange.jpg|thumb|250px|In [[Virtual Markets]], buyer and seller are not present and trade via intermediates and electronic information. Pictured: [[SÃ£o Paulo Stock Exchange]], Brazil.|alt=Two men sit at computer monitors with financial information.]]
Microeconomics examines how entities, forming a [[market structure]], interact within a [[Market (economics)|market]] to create a [[market system]]. These entities include private and public players with various classifications, typically operating under scarcity of tradeable units and [[government regulation]]. The item traded may be a tangible [[product (business)|product]] such as apples or a [[Service (economics)|service]] such as repair services, legal counsel, or entertainment.
In theory, in a [[free market]] the [[Aggregation problem|aggregates]] (sum of) of "quantity demanded" by buyers and "quantity supplied" by sellers will be equal and reach [[economic equilibrium]] over time in reaction to price changes; in practice, various issues may prevent equilibrium, and any equilibrium reached may not necessarily be [[Equity (economics)|morally equitable]]. For example, if the supply of healthcare services is limited by [[exogenous|external factors]], the equilibrium price may be unaffordable for many who desire it but cannot pay for it.
Various market structures exist. In [[perfect competition|perfectly competitive markets]], no participants are large enough to have the [[market power]] to set the price of a homogeneous product. In other words, every participant is a "price taker" as no participant influences the price of a product. In the real world, markets often experience [[imperfect competition]].
Forms include [[monopoly]] (in which there is only one seller of a good), [[duopoly]] (in which there are only two sellers of a good), [[oligopoly]] (in which there are few sellers of a good), [[monopolistic competition]] (in which there are many sellers producing highly differentiated goods), [[monopsony]] (in which there is only one buyer of a good), and [[oligopsony]] (in which there are few buyers of a good). Unlike perfect competition, imperfect competition invariably means market power is unequally distributed. Firms under imperfect competition have the potential to be "price makers", which means that, by holding a disproportionately high share of market power, they can influence the prices of their products.
Microeconomics studies individual markets by simplifying the economic system by assuming that activity in the market being analysed does not affect other markets. This method of analysis is known as [[supply and demand|partial-equilibrium]] analysis (supply and demand). This method aggregates (the sum of all activity) in only one market. [[General equilibrium|General-equilibrium]] theory studies various markets and their behaviour. It aggregates (the sum of all activity) across "all" markets. This method studies both changes in markets and their interactions leading towards equilibrium.
Production, cost, and efficiency.
In microeconomics, [[Production (economics)|production]] is the conversion of [[factor of production|inputs]] into [[Output (economics)|outputs]]. It is an economic process that uses inputs to create a [[good (economics)|commodity]] or a service for [[trade|exchange]] or direct use. Production is a [[Stock and flow|flow]] and thus a rate of output per period of time. Distinctions include such production alternatives as for [[Consumption (economics)|consumption]] (food, haircuts, etc.) vs. [[Investment#In economics or macroeconomics|investment goods]] (new tractors, buildings, roads, etc.), [[public good]]s (national defense, smallpox vaccinations, etc.) or [[private good]]s (new computers, bananas, etc.), and [[Guns versus butter model|"guns" vs. "butter"]].
[[Opportunity cost]] refers to the [[economic cost]] of production: the value of the next best opportunity foregone. Choices must be made between desirable yet [[mutually exclusive]] actions. It has been described as expressing "the basic relationship between [[scarcity]] and [[choice]]". For example, if a baker uses a sack of flour to make pretzels one morning, then the baker cannot use either the flour or the morning to make bagels instead. Part of the cost of making pretzels is that neither the flour nor the morning are available any longer, for use in some other way. The opportunity cost of an activity is an element in ensuring that scarce resources are used efficiently, such that the cost is weighed against the value of that activity in deciding on more or less of it. Opportunity costs are not restricted to monetary or financial costs but could be measured by the [[Real versus nominal value (economics)|real cost]] of [[Production-possibility frontier#Opportunity cost|output forgone]], [[leisure]], or anything else that provides the alternative benefit ([[utility]]).
Inputs used in the production process include such primary [[factors of production]] as [[Labour (economics)|labour services]], [[Capital (economics)|capital]] (durable produced goods used in production, such as an existing factory), and [[Land (economics)|land]] (including natural resources). Other inputs may include [[intermediate good]]s used in production of final goods, such as the steel in a new car.
[[Economic efficiency]] describes how well a system generates desired output with a given set of inputs and available [[technology]]. Efficiency is improved if more output is generated without changing inputs, or in other words, the amount of "waste" is reduced. A widely accepted general standard is [[Pareto efficiency]], which is reached when no further change can make someone better off without making someone else worse off.
[[File:Production Possibilities Frontier Curve.svg|thumb|350px|An example [[productionâpossibility frontier]] with illustrative points marked.]]
The [[productionâpossibility frontier]] (PPF) is an expository figure for representing scarcity, cost, and efficiency. In the simplest case an [[economy]] can produce just two goods (say "guns" and "butter"). The PPF is a table or graph (as at the right) showing the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows [[Potential output|potential total output]] for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good.
[[Scarcity]] is represented in the figure by people being willing but unable in the aggregate to consume "beyond the PPF" (such as at "X") and by the negative slope of the curve. If production of one good "increases" along the curve, production of the other good "decreases", an [[inverse relationship]]. This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter.
The [[slope]] of the curve at a point on it gives the [[trade-off#Examples from common life|trade-off]] between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a "real opportunity cost". Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. "Along the PPF", scarcity implies that choosing "more" of one good in the aggregate entails doing with "less" of the other good. Still, in a [[market economy]], movement along the curve may indicate that the [[utility|choice]] of the increased output is anticipated to be worth the cost to the agents.
By construction, each point on the curve shows "[[productive efficiency]]" in maximizing output for given total inputs. A point "inside" the curve (as at "A"), is feasible but represents "production inefficiency" (wasteful use of inputs), in that output of "one or both goods" could increase by moving in a northeast direction to a point on the curve. Examples cited of such inefficiency include high [[unemployment]] during a [[business cycle|business-cycle]] [[recession]] or economic organization of a country that discourages full use of resources. Being on the curve might still not fully satisfy [[allocative efficiency]] (also called [[Pareto efficiency]]) if it does not produce a mix of goods that consumers prefer over other points.
Much [[applied economics]] in [[public policy]] is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organize society for the most efficient use of resources has been described as the "essence of economics", where the subject "makes its unique contribution."
Specialization.
[[File:Late Medieval Trade Routes.jpg|thumb|450px|A map showing the main [[trade route]]s for goods within [[Late Middle Ages|late medieval Europe]].]]
Specialization is considered key to economic efficiency based on theoretical and [[empirical]] considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in [[stock and flow|stocks]] of [[human capital]] per worker or [[capital (economics)|capital]]/[[labor force|labour]] ratios. According to theory, this may give a [[comparative advantage]] in production of goods that make more intensive use of the relatively more abundant, thus "relatively" cheaper, input.
Even if one region has an [[absolute advantage]] as to the ratio of its outputs to inputs in every type of output, it may still specialize in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else.
It has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of [[Returns to scale|scale]] and [[economies of agglomeration|agglomeration]] to explain specialization in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.
The general theory of specialization applies to trade among individuals, farms, manufacturers, [[Service (economics)|service]] providers, and [[economy|economies]]. Among each of these production systems, there may be a corresponding "[[division of labour]]" with different work groups specializing, or correspondingly different types of [[Capital (economics)|capital equipment]] and differentiated [[Land (economics)|land]] uses.
An example that combines features above is a country that specializes in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products.
Theory and observation set out the conditions such that market [[price]]s of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) [[Production-possibility frontier#Opportunity cost|low-cost]] inputs go to producing low-cost outputs. In the process, aggregate output may increase as a [[invisible hand|by-product]] or by [[mechanism design|design]]. Such specialization of production creates opportunities for "[[gains from trade]]" whereby resource owners benefit from [[trade]] in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the "increased income levels" that trade may facilitate.
Supply and demand.
[[File:Supply-demand-right-shift-demand.svg|thumb|350px|The [[supply and demand]] model describes how prices vary as a result of a balance between product availability and demand. The graph depicts an increase (that is, right-shift) in demand from D to D along with the consequent increase in price and quantity required to reach a new equilibrium point on the supply curve (S).|alt=A graph depicting Quantity on the X-axis and Price on the Y-axis]]
[[Prices and quantities]] have been described as the most directly observable attributes of goods produced and exchanged in a [[market economy]]. The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In [[microeconomics]], it applies to price and output determination for a market with [[perfect competition]], which includes the condition of no buyers or sellers large enough to have price-setting [[market power|power]].
For a given market of a [[Good (economics and accounting)|commodity]], "demand" is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). [[consumer theory|Demand theory]] describes individual consumers as [[rational choice theory|rationally]] choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is "constrained utility maximization" (with income and [[Wealth (economics)|wealth]] as the [[budget constraint|constraints]] on demand). Here, [[utility]] refers to the hypothesized relation of each individual consumer for ranking different commodity bundles as more or less preferred.
The [[law of demand]] states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things [[ceteris paribus|unchanged]]). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the [[substitution effect]]). In addition, [[purchasing power]] from the price decline increases ability to buy (the [[income effect]]). Other factors can change demand; for example an increase in income will shift the demand curve for a [[normal good]] outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.
"Supply" is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesized to be "profit-maximizers", meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.
That is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The "Law of Supply" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.
[[Market equilibrium]] occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The [[Model (economics)|model]] of supply and demand predicts that for given supply and demand curves, price and quantity will stabilize at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply.
For a given quantity of a consumer good, the point on the demand curve indicates the value, or [[marginal utility]], to consumers for that unit. It measures what the consumer would be prepared to pay for that unit. The corresponding point on the supply curve measures [[marginal cost]], the increase in total cost to the supplier for the corresponding unit of the good. The price in equilibrium is determined by supply and demand. In a [[perfect competition|perfectly competitive market]], supply and demand equate marginal cost and marginal utility at equilibrium.
On the supply side of the market, some factors of production are described as (relatively) "variable" in the [[short run]], which affects the cost of changing output levels. Their usage rates can be changed easily, such as electrical power, raw-material inputs, and over-time and temp work. Other inputs are relatively "fixed", such as plant and equipment and key personnel. In the [[long run]], all inputs may be adjusted by [[management]]. These distinctions translate to differences in the [[Price elasticity of supply|elasticity]] (responsiveness) of the supply curve in the short and long runs and corresponding differences in the price-quantity change from a shift on the supply or demand side of the market.
[[marginalism|Marginalist theory]], such as above, describes the consumers as attempting to reach most-preferred positions, subject to [[Income#Meaning in economics and use in economic theory|income]] and [[Wealth (economics)|wealth]] constraints while producers attempt to maximize profits subject to their own constraints, including demand for goods produced, technology, and the price of inputs. For the consumer, that point comes where marginal utility of a good, net of price, reaches zero, leaving no net gain from further consumption increases. Analogously, the producer compares [[marginal revenue]] (identical to price for the perfect competitor) against the [[marginal cost]] of a good, with "marginal profit" the difference. At the point where marginal profit reaches zero, further increases in production of the good stop. For movement to market equilibrium and for changes in equilibrium, price and quantity also change "at the margin": more-or-less of something, rather than necessarily all-or-nothing.
Other applications of demand and supply include the [[Distribution (economics)|distribution of income]] among the [[factors of production]], including labour and capital, through factor markets. In a competitive [[labour market]] for example the quantity of labour employed and the price of labour (the wage rate) depends on the [[Labour economics#Neoclassical microeconomic modelÂ â Demand|demand for labour]] (from employers for production) and supply of labour (from potential workers). [[Labour economics]] examines the interaction of workers and employers through such markets to explain patterns and changes of wages and other labour income, [[labour mobility]], and (un)employment, productivity through [[human capital]], and related public-policy issues.
Demand-and-supply analysis is used to explain the behavior of perfectly competitive markets, but as a standard of comparison it can be extended to any type of market. It can also be generalized to explain variables across the [[economy]], for example, total output (estimated as [[real GDP]]) and the general [[price level]], as studied in [[macroeconomics]]. Tracing the [[qualitative economics|qualitative]] and quantitative effects of variables that change supply and demand, whether in the short or long run, is a standard exercise in [[applied economics]]. Economic theory may also specify conditions such that supply and demand through the market is an efficient mechanism for allocating resources.
Firms.
People frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through "firms". The most obvious kinds of firms are [[corporation]]s, [[partnerships]] and [[trusts]]. According to [[Ronald Coase]] people begin to organise their production in firms when the costs of doing business becomes lower than doing it on the market. Firms combine labour and capital, and can achieve far greater [[economies of scale]] (when the average cost per unit declines as more units are produced) than individual market trading.
In [[perfect competition|perfectly competitive]] markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. [[Industrial organization]] generalizes from that special case to study the strategic behavior of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include [[monopolistic competition]], various forms of [[oligopoly]], and [[monopoly]].
[[Managerial economics]] applies [[microeconomic]] analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as [[operations research]] and programming and from statistical methods such as [[regression analysis]] in the absence of certainty and perfect knowledge. A unifying theme is the attempt to [[Optimization (mathematics)|optimize]] business decisions, including unit-cost minimization and profit maximization, given the firm's objectives and constraints imposed by technology and market conditions.
Uncertainty and game theory.
[[Uncertainty]] in economics is an unknown prospect of gain or loss, whether quantifiable as [[Risk#Risk versus uncertainty|risk]] or not. Without it, household behavior would be unaffected by uncertain employment and income prospects, [[financial market|financial]] and [[capital market]]s would reduce to exchange of a single [[financial instrument|instrument]] in each market period, and there would be no [[communication]]s industry. Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.
[[Game theory]] is a branch of [[applied mathematics]] that considers [[Strategy#Strategies in game theory|strategic interactions]] between agents, one kind of uncertainty. It provides a mathematical [[microfoundation|foundation]] of [[industrial organization]], discussed above, to model different types of firm behavior, for example in an [[oligopolist]]ic industry (few sellers), but equally applicable to wage negotiations, [[Bargaining#Game theory|bargaining]], [[Contract theory|contract design]], and any situation where individual agents are few enough to have perceptible effects on each other. As a method heavily used in [[behavioral economics]], it postulates that [[Agent (economics)|agents]] choose strategies to maximize their payoffs, given the strategies of other agents with at least partially conflicting interests.
In this, it generalizes maximization approaches developed to analyze market actors such as in the [[supply and demand]] model and allows for incomplete information of actors. The field dates from the 1944 classic "[[Theory of Games and Economic Behavior]]" by [[John von Neumann]] and [[Oskar Morgenstern]]. It has significant applications seemingly outside of economics in such diverse subjects as formulation of [[nuclear strategies]], [[Game theory#Philosophy|ethics]], [[Game theory#Political science|political science]], and [[evolutionary biology]].
[[Risk aversion]] may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for [[insurance]], commodity [[futures market|futures contracts]], and [[financial instruments]]. [[Financial economics]] or simply [[finance]] describes the allocation of financial resources. It also analyzes the pricing of financial instruments, the [[capital structure|financial structure]] of companies, the efficiency and fragility of [[financial market]]s, [[Financial crisis|financial crises]], and related government policy or [[Financial regulation|regulation]].
Some market organizations may give rise to inefficiencies associated with uncertainty. Based on [[George Akerlof]]'s "[[Market for Lemons]]" article, the [[paradigm]] example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a "lemon" depress its price below what a quality second-hand car would be. [[Information asymmetry]] arises here, if the seller has more relevant information than the buyer but no incentive to disclose it. Related problems in insurance are [[adverse selection]], such that those at most risk are most likely to insure (say reckless drivers), and [[moral hazard]], such that insurance results in riskier behavior (say more reckless driving).
Both problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market ("[[incomplete markets]]"). Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. [[Information economics]], which studies such problems, has relevance in subjects such as insurance, [[contract theory|contract law]], [[mechanism design]], [[monetary economics]], and [[health economics|health care]]. Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, [[restructuring]] or [[bankruptcy law]], inspection, and [[Regulatory economics|regulation]] for quality and information disclosure.
Market failure.
[[File:Smokestack in Detroit.jpg|thumb|250px|[[Pollution]] can be a simple example of market failure. If [[costs of production]] are not borne by producers but are by the environment, accident victims or others, then prices are distorted.|alt=A smokestack releasing smoke]]
The term "[[market failure]]" encompasses several problems which may undermine standard economic assumptions. Although economists categorise market failures differently, the following categories emerge in the main texts.
[[Information asymmetries]] and [[incomplete markets]] may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.
[[Natural monopoly]], or the overlapping concepts of "practical" and "technical" monopoly, is an extreme case of "failure of competition" as a restraint on producers. Extreme [[economies of scale]] are one possible cause.
[[Public goods]] are goods which are undersupplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time.
[[Externalities]] occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.). Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidize or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price [[distortions (economics)|distortions]] caused by these externalities. Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.
In many areas, some form of [[price stickiness]] is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the [[business cycle]] in [[macroeconomics]]. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesized long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets [[Imperfect competition|deviating]] from [[perfect competition]].
[[File:Field Trip- water sampling.jpg|thumb|250px|[[Environmental scientist]] sampling water|alt=A woman takes samples of water from a river.]]
Some specialised fields of economics deal in market failure more than others. The [[economics of the public sector]] is one example. Much [[environmental economics]] concerns externalities or "[[public bad]]s".
[[Policy]] options include regulations that reflect [[cost-benefit analysis]] or market solutions that change incentives, such as [[Emissions trading|emission fees]] or redefinition of property rights.
Public sector.
Public finance is the field of economics that deals with budgeting the revenues and expenditures of a [[public sector]] entity, usually government. The subject addresses such matters as [[tax incidence]] (who really pays a particular tax), cost-benefit analysis of government programs, effects on [[economic efficiency]] and [[income distribution]] of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of [[public choice theory]], models public-sector behavior analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.
Much of economics is [[positive economics|positive]], seeking to describe and predict economic phenomena. [[Normative economics]] seeks to identify what economies "ought" to be like.
Welfare economics is a normative branch of economics that uses [[microeconomics|microeconomic]] techniques to simultaneously determine the [[allocative efficiency]] within an economy and the income [[Distribution (economics)|distribution]] associated with it. It attempts to measure [[social welfare]] by examining the economic activities of the individuals that comprise society.
Macroeconomics.
[[File:DiagFuncMacroSyst.pdf|thumb|450px|The circulation of money in an economy in a macroeconomic model.]]
Macroeconomics examines the economy as a whole to explain broad aggregates and their interactions "top down", that is, using a simplified form of [[General equilibrium|general-equilibrium]] theory. Such aggregates include [[measures of national income and output|national income and output]], the [[unemployment rate]], and price [[inflation]] and subaggregates like total consumption and investment spending and their components. It also studies effects of [[monetary policy]] and [[fiscal policy]].
Since at least the 1960s, macroeconomics has been characterized by further integration as to [[microfoundations|micro-based]] modeling of sectors, including [[rational expectations|rationality]] of players, [[Efficient market hypothesis|efficient use]] of market information, and [[imperfect competition]]. This has addressed a long-standing concern about inconsistent developments of the same subject.
Macroeconomic analysis also considers factors affecting the long-term level and [[economic growth|growth]] of national income. Such factors include capital accumulation, [[Technological progress|technological change]] and [[labour force]] growth.
Growth.
"Growth economics" studies factors that explain [[economic growth]]Â â the increase in output [[per capita]] of a country over a long period of time. The same factors are used to explain differences in the "level" of output per capita "between" countries, in particular why some countries grow faster than others, and whether countries [[catch-up effect|converge]] at the same rates of growth.
Much-studied factors include the rate of [[Investment (macroeconomics)|investment]], [[population growth]], and [[Technological progress|technological change]]. These are represented in theoretical and [[empirical]] forms (as in the [[neoclassical growth model|neoclassical]] and [[endogenous growth model|endogenous]] growth models) and in [[growth accounting]].
Business cycle.
[[File:Economic cycle.svg|thumb|450px|A basic illustration of [[Business cycle|economic/business cycles]].]]
The economics of a depression were the spur for the creation of "macroeconomics" as a separate discipline field of study. During the [[Great Depression]] of the 1930s, [[John Maynard Keynes]] authored a book entitled "[[The General Theory of Employment, Interest and Money]]" outlining the key theories of [[Keynesian economics]]. Keynes contended that [[aggregate demand]] for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.
He therefore advocated active policy responses by the [[public sector]], including [[monetary policy]] actions by the [[central bank]] and [[fiscal policy]] actions by the government to stabilize output over the [[business cycle]].
Thus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards [[full employment]] levels. [[John Hicks]]' [[IS/LM]] model has been the most influential interpretation of "The General Theory".
Over the years, understanding of the [[business cycle]] has branched into various [[research program]]s, mostly related to or distinct from Keynesianism. The [[neoclassical synthesis]] refers to the reconciliation of Keynesian economics with [[neoclassical economics]], stating that Keynesianism is correct in the [[short run]] but qualified by neoclassical-like considerations in the intermediate and [[long run]].
[[New classical macroeconomics]], as distinct from the Keynesian view of the business cycle, posits [[market clearing]] with [[imperfect information]]. It includes Friedman's [[permanent income hypothesis]] on consumption and "[[rational expectations]]" theory, led by [[Robert Lucas, Jr.|Robert Lucas]], and [[real business cycle theory]].
In contrast, the [[New Keynesian economics|new Keynesian]] approach retains the rational expectations assumption, however it assumes a variety of [[market failures]]. In particular, New Keynesians assume prices and wages are "[[Sticky (economics)|sticky]]", which means they do not adjust instantaneously to changes in economic conditions.
Thus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the "long run" may be very long.
Unemployment.
[[File:US employment 1995-2012.png|thumb|450px|The percentage of the [[Unemployment in the United States|US population employed]], 1995â2012.]]
The amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or [[discouraged worker|discouraged from seeking work]] by a lack of job prospects are excluded from the labor force. Unemployment can be generally broken down into several types that are related to different causes.
Classical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Wages may be too high because of minimum wage laws or union activity. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.
[[Structural unemployment]] covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs. Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand. Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.
While some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. [[Okun's law]] represents the empirical relationship between unemployment and economic growth. The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.
Inflation and monetary policy.
[[Money]] is a "means of final payment" for goods in most [[price system]] economies and the [[unit of account]] in which prices are typically stated. An apt statement by [[Francis Amasa Walker]], a well-known economist is, "Money is what money does." Money has a general acceptability, a relative consistency in value, divisibility, durability, portability, elastic in supply and survives with mass public confidence. It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others.
As a [[medium of exchange]], money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with [[barter]] (non-monetary exchange). Given a diverse array of produced goods and specialized producers, barter may entail a hard-to-locate [[double coincidence of wants]] as to what is exchanged, say apples and a book. Money can reduce the [[transaction cost]] of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.
At the level of an [[economy]], [[quantity theory of money|theory]] and evidence are consistent with a [[positive relationship]] running from the total [[money supply]] to the [[nominal value]] of total output and to the general [[price level]]. For this reason, management of the [[money supply]] is a key aspect of [[monetary policy]].
Fiscal policy.
Governments implement fiscal policy that influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an [[output gap]] where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government.
For example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have [[Fiscal multiplier|multiplier effects]] where the initial increase in demand from the policy percolates through the economy and generates additional economic activity.
The effects of fiscal policy can be limited by [[Crowding out (economics)|crowding out]]. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government use resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.
Skeptics of fiscal policy also make the argument of [[Ricardian equivalence]]. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from fiscal policy will be offset by the increased savings rate intended to pay for future higher taxes.
International economics.
[[File:Countries by GDP (PPP) Per Capita in 2014.svg|thumb||400px|upright=2|List of countries by GDP (PPP) per capita in 2014.]]
International trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of [[gains from trade]]. Policy applications include estimating the effects of changing [[tariff]] rates and trade quotas. [[International finance]] is a macroeconomic field which examines the flow of [[Capital (economics)|capital]] across international borders, and the effects of these movements on [[exchange rate]]s. Increased trade in goods, services and capital between countries is a major effect of contemporary [[globalization]].
The distinct field of "[[development economics]]" examines economic aspects of the [[economic development]] process in relatively [[developing countries|low-income countries]] focusing on [[structural change]], [[poverty]], and [[economic growth]]. Approaches in development economics frequently incorporate social and political factors.
Economic systems is the [[JEL classification codes#Economic systems JEL: P Subcategories|branch]] of economics that studies the methods and [[institutions]] by which societies determine the ownership, direction, and allocation of economic resources. An "economic system" of a society is the unit of analysis.
Among contemporary systems at different ends of the organizational spectrum are [[Planned economy|socialist systems]] and [[Capitalism|capitalist systems]], in which most production occurs in respectively state-run and private enterprises. In between are [[mixed economies]]. A common element is the interaction of economic and political influences, broadly described as [[Political economy#Current approaches|political economy]]. "[[Comparative economic systems]]" studies the relative performance and behavior of different economies or systems.
The U.S. Export-Import Bank defines a Marxist-Lenninist state as having a centrally [[planned economy]]. They are now rare, examples can still be seen in [[Economy of Cuba|Cuba]], [[Economy of North Korea|North Korea]] and [[Economy of Laos|Laos]].
Practice.
Contemporary economics uses mathematics. Economists draw on the tools of [[calculus]], [[linear algebra]], [[statistics]], [[game theory]], and [[computer science]]. Professional economists are expected to be familiar with these tools, while a minority specialize in econometrics and mathematical methods.
Theory.
Mainstream economic theory relies upon [[wikt:a priori|a priori]] quantitative [[model (economics)|economic models]], which employ a variety of concepts. Theory typically proceeds with an assumption of "[[ceteris paribus]]", which means holding constant explanatory variables other than the one under consideration. When creating theories, the objective is to find ones which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories.
In [[microeconomics]], principal concepts include [[supply and demand]], [[marginalism]], [[rational choice theory]], [[opportunity cost]], [[budget constraint]]s, [[utility]], and the [[theory of the firm]]. Early [[macroeconomic]] models focused on modeling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including [[new Keynesian]]s, reformulated their models in [[microfoundations]].
The aforementioned microeconomic concepts play a major part in macroeconomic modelsÂ â for instance, in [[monetary theory]], the [[quantity theory of money]] predicts that increases in the [[money supply]] increase [[inflation]], and inflation is assumed to be influenced by [[rational expectations]]. In [[development economics]], slower growth in developed nations has been sometimes predicted because of the declining marginal returns of investment and capital, and this has been observed in the [[Four Asian Tigers]]. Sometimes an economic hypothesis is only "[[qualitative economics|qualitative]]", not "quantitative".
Expositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, [[Paul Samuelson]]'s treatise "[[Foundations of Economic Analysis]]" (1947) used mathematical methods to represent the theory, particularly as to maximizing behavioral relations of agents reaching equilibrium. The book focused on examining the class of statements called "operationally meaningful theorems" in economics, which are [[theorem]]s that can conceivably be refuted by empirical data.
Empirical investigation.
Economic theories are frequently tested [[empirical]]ly, largely through the use of [[econometrics]] using [[economic data]]. The controlled experiments common to the [[physical science]]s are difficult and uncommon in economics, and instead broad data is [[observational study|observationally studied]]; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of [[experimental economics]] is growing, and increasing use is being made of [[natural experiments]].
[[Statistics|Statistical methods]] such as [[regression analysis]] are common. Practitioners use such methods to estimate the size, economic significance, and [[statistical significance]] ("signal strength") of the hypothesized relation(s) and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the [[falsifiability|falsifiable]] hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, [[data set]]s, and prior beliefs.
Criticism based on professional standards and non-[[Replication (statistics)|replicability]] of results serve as further checks against bias, errors, and over-generalization, although much economic research has been accused of being non-replicable, and prestigious journals have been accused of not facilitating replication through the provision of the code and data. Like theories, uses of test statistics are themselves open to critical analysis, although critical commentary on papers in economics in prestigious journals such as the "[[American Economic Review]]" has declined precipitously in the past 40 years. This has been attributed to journals' incentives to maximize citations in order to rank higher on the Social Science Citation Index (SSCI).
In applied economics, [[input-output model]]s employing [[linear programming]] methods are quite common. Large amounts of data are run through computer programs to analyze the impact of certain policies; [[Minnesota IMPLAN Group|IMPLAN]] is one well-known example.
[[Experimental economics]] has promoted the use of [[Scientific control|scientifically controlled]] [[experiment]]s. This has reduced long-noted distinction of economics from [[natural science]]s allowed direct tests of what were previously taken as axioms. In some cases these have found that the axioms are not entirely correct; for example, the [[ultimatum game]] has revealed that people reject unequal offers.
In [[behavioral economics]], psychologist [[Daniel Kahneman]] won the [[Nobel Memorial Prize in Economic Sciences|Nobel Prize in economics]] in 2002 for his and [[Amos Tversky]]'s empirical discovery of several [[cognitive bias]]es and [[heuristics in judgment and decision making|heuristics]]. Similar empirical testing occurs in [[neuroeconomics]]. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences. These techniques have led some to argue that economics is a "genuine science."
Profession.
The professionalization of economics, reflected in the growth of graduate programs on the subject, has been described as "the main change in economics since around 1900". Most major [[universities]] and many colleges have a major, school, or department in which [[academic degrees]] are awarded in the subject, whether in the [[liberal arts]], business, or for professional study.
In the private sector, professional economists are employed as consultants and in industry, including [[banking]] and [[finance]]. Economists also work for various government departments and agencies, for example, the national [[Treasury]], [[Central Bank]] or [[Bureau of Statistics]].
The [[Nobel Memorial Prize in Economic Sciences]] (commonly known as the Nobel Prize in Economics) is a prize awarded to economists each year for outstanding intellectual contributions in the field.
Related subjects.
Economics is one [[social science]] among several and has fields bordering on other areas, including [[economic geography]], [[economic history]], [[public choice]], [[energy economics]], [[JEL classification codes#Other special topics (economics) JEL: Z Subcategories|cultural economics]], [[family economics]] and [[institutional economics]].
Law and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are [[economic efficiency|economically efficient]], and to predict what the legal rules will be. A seminal article by [[Ronald Coase]] published in 1961 suggested that well-defined property rights could overcome the problems of [[externalities]].
[[Political economy]] is the interdisciplinary study that combines economics, law, and [[political science]] in explaining how political institutions, the political environment, and the economic system ([[capitalism|capitalist]], [[socialist]], mixed) influence each other. It studies questions such as how [[monopoly]], [[rent-seeking]] behavior, and [[externalities]] should impact government policy. [[Historian]]s have employed "political economy" to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.
[[Energy economics]] is a broad [[science|scientific]] subject area which includes topics related to [[energy supply]] and [[energy demand]]. [[Georgescu-Roegen]] reintroduced the concept of [[entropy]] in relation to economics and energy from [[thermodynamics]], as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to [[thermoeconomics]] and to [[ecological economics]]. He also did foundational work which later developed into [[evolutionary economics]].
The [[sociological]] subfield of [[economic sociology]] arose, primarily through the work of [[Ãmile Durkheim]], [[Max Weber]] and [[Georg Simmel]], as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm (i.e. [[modernity]]). Classic works include [[Max Weber]]'s "[[The Protestant Ethic and the Spirit of Capitalism]]" (1905) and [[Georg Simmel]]'s "[[The Philosophy of Money]]" (1900). More recently, the works of [[Mark Granovetter]], [[Peter Hedstrom]] and [[Richard Swedberg]] have been influential in this field.
History.
Economic writings date from earlier [[Mesopotamia]]n, [[ancient Greece|Greek]], [[Ancient Rome|Roman]], [[History of India|Indian subcontinent]], [[China|Chinese]], [[Achaemenid Empire|Persian]], and [[Arab world|Arab]] civilizations. Notable writers from antiquity through to the 14th century include [[Aristotle]], [[Oeconomicus|Xenophon]], [[Chanakya]] (also known as Kautilya), [[Qin Shi Huang]], [[Thomas Aquinas]], and [[Ibn Khaldun]]. [[Joseph Schumpeter]] described Aquinas as "coming nearer than any other group to being the 'founders' of scientific economics" as to [[Monetary economics|monetary]], interest, and [[microeconomics|value]] theory within a [[natural law|natural-law]] perspective.
[[File:Lorrain.seaport.jpg|thumb|250px|A 1638 painting of a French seaport during the heyday of [[mercantilism]].|alt=A seaport with a ship arriving]]
Two groups, later called "mercantilists" and "physiocrats", more directly influenced the subsequent development of the subject. Both groups were associated with the rise of [[economic nationalism]] and [[History of capitalism#Merchant capitalism and mercantilism|modern capitalism]] in Europe. [[Mercantilism]] was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing cheap raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.
[[Physiocrats]], a group of 18th-century French thinkers and writers, developed the idea of the economy as a [[circular flow]] of income and output. Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth. Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of [[laissez-faire]], which called for minimal government intervention in the economy.
[[Adam Smith]] (1723â1790) was an early economic theorist. Smith was harshly critical of the mercantilists but described the physiocratic system "with all its imperfections" as "perhaps the purest approximation to the truth that has yet been published" on the subject.
Classical political economy.
[[File:AdamSmith.jpg|thumb|upright|The publication of [[Adam Smith]]'s "[[The Wealth of Nations]]" in 1776 is considered to be the first formalisation of economic thought.|alt=A man facing the right]]
The publication of [[Adam Smith]]'s "[[The Wealth of Nations]]" in 1776, has been described as "the effective birth of economics as a separate discipline." The book identified land, labor, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the Physiocratic idea that only agriculture was productive.
Smith discusses potential benefits of specialization by [[division of labour]], including increased [[labour productivity]] and [[gains from trade]], whether between town and country or across countries. His "theorem" that "the division of labor is limited by the extent of the market" has been described as the "core of a [[Theory of the firm|theory of the functions of firm]] and [[industrial organization|industry]]" and a "fundamental principle of economic organization." To Smith has also been ascribed "the most important substantive proposition in all of economics" and foundation of [[Allocation of resources|resource-allocation]] theory â that, under [[Competition (economics)|competition]], resource owners (of labour, land, and capital) seek their most profitable uses, resulting in an equal rate of return for all uses in [[Economic equilibrium|equilibrium]] (adjusted for apparent differences arising from such factors as training and unemployment).
In an argument that includes "one of the most famous passages in all economics," Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society, and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce. In this:
Economists have linked Smith's invisible-hand concept to his concern for the common man and woman through [[economic growth]] and [[economic development|development]], enabling higher levels of consumption, which Smith describes as "the sole end and purpose of all production."
He embeds the "invisible hand" in a framework that includes limiting restrictions on competition and foreign trade by government and industry in the same chapter and elsewhere regulation of banking and the interest rate, provision of a "natural system of liberty" â national defence, an [[egalitarian]] justice and legal system, and certain institutions and public works with general benefits to the whole society that might otherwise be unprofitable to produce, such as education and roads, canals, and the like. An influential introductory textbook includes parallel discussion and this assessment: "Above all, it is Adam Smith's vision of a self-regulating [[invisible hand]] that is his enduring contribution to modern economics."
The [[Reverend|Rev.]] [[Thomas Robert Malthus]] (1798) used the idea of diminishing returns to explain low living standards. [[Human population]], he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level. Economist [[Julian Lincoln Simon]] has criticised Malthus's conclusions.
While Adam Smith emphasized the production of income, [[David Ricardo]] (1817) focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was the first to state and prove the principle of [[comparative advantage]], according to which each country should specialize in producing and exporting goods in that it has a lower "relative" cost of production, rather relying only on its own production. It has been termed a "fundamental analytical explanation" for [[gains from trade]].
Coming at the end of the Classical tradition, [[John Stuart Mill]] (1848) parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.
Value theory was important in classical theory. Smith wrote that the "real price of every thingÂ ... is the toil and trouble of acquiring it" as influenced by its scarcity. Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity. Other classical economists presented variations on Smith, termed the '[[labour theory of value#The theory's development|labour theory of value]]'. Classical economics focused on the tendency of markets to move to long-run equilibrium.
Marxism.
[[File:Karl Marx 001.jpg|upright|right|thumb|The Marxist school of economic thought comes from the work of German economist [[Karl Marx]].|alt=A man facing the viewer]]
Marxist (later, Marxian) economics descends from classical economics. It derives from the work of [[Karl Marx]]. The first volume of Marx's major work, "[[Das Kapital]]", was published in German in 1867. In it, Marx focused on the [[labour theory of value]] and the [[theory of surplus value]] which, he believed, explained the exploitation of labour by capital. The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production and the theory of surplus value demonstrated how the workers only got paid a proportion of the value their work had created.
Neoclassical economics.
At the dawn as a social science, economics was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his "Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth" (1803). These three items are considered by the science only in relation to the increase or diminution of wealth, and not in reference to their processes of execution. Say's definition has prevailed up to our time, saved by substituting the word "wealth" for "goods and services" meaning that wealth may include non material objects as well. One hundred and thirty years later, [[Lionel Robbins, Baron Robbins|Lionel Robbins]] noticed that this definition no longer sufficed, because many economists were making theoretical and philosophical inroads in other areas of human activity. In his "[[An Essay on the Nature and Significance of Economic Science|Essay on the Nature and Significance of Economic Science]], he proposed a definition of economics as a study of a particular aspect of human behavior, the one that falls under the influence of scarcity, which forces people to choose, allocate scarce resources to competing ends, and economize (seeking the greatest welfare while avoiding the wasting of scarce resources). For Robbins, the insufficiency was solved, and his definition allows us to proclaim, with an easy conscience, education economics, safety and security economics, health economics, war economics, and of course, production, distribution and consumption economics as valid subjects of the economic science.
Citing Robbins: "Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses". After discussing it for decades, Robbins' definition became widely accepted by mainstream economists, and it has opened way into current textbooks. Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition. Due to the lack of strong consensus, and that production, distribution and consumption of goods and services is the prime area of study of economics, the old definition still stands in many quarters.
A body of theory later termed "neoclassical economics" or "[[Marginalist Revolution|marginalism]]" formed from about 1870 to 1910. The term "economics" was popularized by such neoclassical economists as [[Alfred Marshall]] as a concise synonym for 'economic science' and a substitute for the earlier "[[political economy]]". This corresponded to the influence on the subject of mathematical methods used in the [[natural science]]s.
Neoclassical economics systematized [[supply and demand]] as joint determinants of price and quantity in market equilibrium, affecting both the allocation of output and the distribution of income. It dispensed with the [[labour theory of value]] inherited from classical economics in favor of a [[marginal utility]] theory of value on the demand side and a more general theory of costs on the supply side. In the 20th century, neoclassical theorists moved away from an earlier notion suggesting that total utility for a society could be measured in favor of [[ordinal utility]], which hypothesizes merely behavior-based relations across persons.
In [[microeconomics]], neoclassical economics represents incentives and costs as playing a pervasive role in shaping [[decision making]]. An immediate example of this is the [[consumer theory]] of individual demand, which isolates how prices (as costs) and income affect quantity demanded. In [[macroeconomics]] it is reflected in an early and lasting [[neoclassical synthesis]] with Keynesian macroeconomics.
Neoclassical economics is occasionally referred as "orthodox economics" whether by its critics or sympathizers. Modern [[mainstream economics]] builds on neoclassical economics but with many refinements that either supplement or generalize earlier analysis, such as [[econometrics]], [[game theory]], analysis of [[market failure]] and [[imperfect competition]], and the [[neoclassical model]] of [[economic growth]] for analyzing long-run variables affecting [[national income]].
Neoclassical economics studies the behavior of [[individual]]s, [[household]]s, and [[organization]]s (called economic actors, players, or agents), when they manage or use [[Scarcity|scarce]] resources, which have alternative uses, to achieve desired ends. Agents are assumed to act rationally, have multiple desirable ends in sight, limited resources to obtain these ends, a set of stable preferences, a definite overall guiding objective, and the capability of making a choice. There exists an economic problem, subject to study by economic science, when a [[Decision theory|decision]] (choice) is made by one or more resource-controlling players to attain the best possible outcome under bounded rational conditions. In other words, resource-controlling agents maximize value subject to the constraints imposed by the information the agents have, their cognitive limitations, and the finite amount of time they have to make and execute a decision. Economic science centers on the activities of the economic agents that comprise society. They are the focus of economic analysis.
An approach to understanding these processes, through the study of agent behavior under scarcity, may go as follows:
The continuous interplay (exchange or trade) done by economic actors in all markets sets the prices for all goods and services which, in turn, make the rational managing of scarce resources possible. At the same time, the decisions (choices) made by the same actors, while they are pursuing their own interest, determine the level of output (production), consumption, savings, and investment, in an economy, as well as the remuneration (distribution) paid to the owners of labor (in the form of wages), capital (in the form of profits) and land (in the form of rent). Each period, as if they were in a giant feedback system, economic players influence the pricing processes and the economy, and are in turn influenced by them until a steady state (equilibrium) of all variables involved is reached or until an external shock throws the system toward a new equilibrium point. Because of the autonomous actions of rational interacting agents, the economy is a complex adaptive system.
Keynesian economics.
[[File:WhiteandKeynes.jpg|right|thumb|upright|[[John Maynard Keynes]] (right), was a key theorist in economics.]]
Keynesian economics derives from [[John Maynard Keynes]], in particular his book "[[The General Theory of Employment, Interest and Money]]" (1936), which ushered in contemporary [[macroeconomics]] as a distinct field. The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low "[[effective demand]]" and why even price flexibility and monetary policy might be unavailing. The term "revolutionary" has been applied to the book in its impact on economic analysis.
Keynesian economics has two successors. [[Post-Keynesian economics]] also concentrates on macroeconomic rigidities and adjustment processes. Research on micro foundations for their models is represented as based on real-life practices rather than simple optimizing models. It is generally associated with the [[University of Cambridge]] and the work of [[Joan Robinson]].
[[New-Keynesian economics]] is also associated with developments in the Keynesian fashion. Within this group researchers tend to share with other economists the emphasis on models employing micro foundations and optimizing behavior but with a narrower focus on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones.
Chicago school of economics.
The Chicago School of economics is best known for its free market advocacy and [[monetarist]] ideas. According to [[Milton Friedman]] and monetarists, market economies are inherently stable if the money supply does not greatly expand or contract. [[Ben Bernanke]], former Chairman of the Federal Reserve, is among the economists today generally accepting Friedman's analysis of the causes of the Great Depression.
Milton Friedman effectively took many of the basic principles set forth by [[Adam Smith]] and the classical economists and modernized them. One example of this is his article in the September 1970 issue of The New York Times Magazine, where he claims that the social responsibility of business should be "to use its resources and engage in activities designed to increase its profitsÂ ... (through) open and free competition without deception or fraud."
Other schools and approaches.
Other well-known schools or trends of thought referring to a particular style of economics practiced at and disseminated from well-defined groups of academicians that have become known worldwide, include the [[Austrian School]], the [[Freiburg School]], the [[School of Lausanne]], [[post-Keynesian economics]] and the [[Stockholm school (economics)|Stockholm school]]. Contemporary [[mainstream economics]] is sometimes separated into the Saltwater approach of those universities along the [[East Coast of the United States|Eastern]] and [[West coast of the United States|Western]] coasts of the US, and the Freshwater, or Chicago-school approach.
Within macroeconomics there is, in general order of their appearance in the literature; [[classical economics]], [[Keynesian economics]], the neoclassical synthesis, [[post-Keynesian economics]], [[monetarism]], [[new classical economics]], and [[supply-side economics]]. Alternative developments include [[ecological economics]], [[constitutional economics]], [[institutional economics]], [[evolutionary economics]], [[dependency theory]], [[structuralist economics]], [[world systems theory]], [[econophysics]], [[feminist economics]] and [[biophysical economics]].
Agreements.
According to various polls cited in "Principles of Economics" by Harvard Chairman and Economics Professor [[Gregory Mankiw]], economists have the following agreements by percentage.
Criticisms.
General criticisms.
"[[The dismal science]]" is a derogatory alternative name for economics devised by the [[Victorian era|Victorian]] historian [[Thomas Carlyle]] in the 19th century. It is often stated that Carlyle gave economics the nickname "the dismal science" as a response to the late 18th century writings of The Reverend [[Thomas Malthus|Thomas Robert Malthus]], who grimly predicted that starvation would result, as projected population growth exceeded the rate of increase in the food supply. However, the actual phrase was coined by Carlyle in the context of a debate with [[John Stuart Mill]] on [[slavery]], in which Carlyle argued for slavery, while Mill opposed it.
Some economists, like [[John Stuart Mill]] or [[LÃ©on Walras]], have maintained that the production of wealth should not be tied to its distribution.
In "The Wealth of Nations", [[Adam Smith]] addressed many issues that are currently also the subject of debate and dispute. Smith repeatedly attacks groups of politically aligned individuals who attempt to use their collective influence to manipulate a government into doing their bidding. In Smith's day, these were referred to as [[Political faction|factions]], but are now more commonly called [[special interests]], a term which can comprise international bankers, corporate conglomerations, outright [[oligopolies]], [[monopolies]], [[trade unions]] and other groups.
Economics per se, as a social science, is independent of the political acts of any government or other decision-making organization, however, many [[policymaker]]s or individuals holding highly ranked positions that can influence other people's lives are known for arbitrarily using a plethora of economic concepts and [[rhetoric]] as vehicles to legitimize [[Political agenda|agendas]] and [[value systems]], and do not limit their remarks to matters relevant to their responsibilities. The close relation of economic theory and practice with [[politics]] is a focus of contention that may shade or distort the most unpretentious original tenets of economics, and is often confused with specific social agendas and value systems.
Notwithstanding, economics legitimately has a role in informing government policy. It is, indeed, in some ways an outgrowth of the older field of political economy. Some academic economic journals are currently focusing increased efforts on gauging the consensus of economists regarding certain policy issues in hopes of effecting a more informed political environment. Currently, there exists a low approval rate from professional economists regarding many public policies. Policy issues featured in a recent survey of [[American Economic Association]] economists include trade restrictions, social insurance for those put out of work by international competition, genetically modified foods, curbside recycling, health insurance (several questions), medical malpractice, barriers to entering the medical profession, organ donations, unhealthy foods, mortgage deductions, taxing internet sales, Wal-Mart, casinos, ethanol subsidies, and inflation targeting.
In "Steady State Economics" 1977, [[Herman Daly]] argues that there exist logical inconsistencies between the emphasis placed on economic growth and the limited availability of natural resources.
Issues like [[central bank]] independence, central bank policies and rhetoric in central bank governors discourse or the premises of [[Macroeconomic policy|macroeconomic policies]] ([[monetary policy|monetary]] and [[fiscal policy]]) of the [[State (polity)|state]], are focus of contention and criticism.
[[Deirdre McCloskey]] has argued that many empirical economic studies are poorly reported, and she and Stephen Ziliak argue that although [[McCloskey critique|her critique]] has been well-received, practice has not improved. This latter contention is controversial.
A 2002 [[International Monetary Fund]] study looked at "consensus forecasts" (the forecasts of large groups of economists) that were made in advance of 60 different national recessions in the 1990s: in 97% of the cases the economists did not predict the contraction a year in advance. On those rare occasions when economists did successfully predict recessions, they significantly underestimated their severity.
Criticisms of assumptions.
Economics has been subject to criticism that it relies on unrealistic, unverifiable, or highly simplified assumptions, in some cases because these assumptions simplify the proofs of desired conclusions. Examples of such assumptions include [[perfect information]], [[profit maximization]] and [[rational choice theory|rational choices]]. The field of [[information economics]] includes both mathematical-economical research and also [[behavioral economics]], akin to studies in [[behavioral psychology]].
Nevertheless, prominent mainstream economists such as Keynes and Joskow have observed that much of economics is conceptual rather than quantitative, and difficult to model and formalize quantitatively. In a discussion on [[oligopoly]] research, [[Paul Joskow]] pointed out in 1975 that in practice, serious students of actual economies tended to use "informal models" based upon qualitative factors specific to particular industries. Joskow had a strong feeling that the important work in oligopoly was done through informal observations while formal models were "trotted out "[[ex post]]"". He argued that formal models were largely not important in the empirical work, either, and that the fundamental factor behind the theory of the firm, behavior, was neglected.
In recent years, feminist critiques of neoclassical economic models gained prominence, leading to the formation of [[feminist economics]]. Contrary to common conceptions of economics as a [[positive economics|positive]] and [[objectivity (philosophy)|objective]] science, feminist economists call attention to the social construction of economics and highlight the ways in which its models and methods reflect masculine preferences. Primary criticisms focus on failures to account for: the selfish nature of actors ([[homo economicus]]); exogenous tastes; the impossibility of utility comparisons; the exclusion of unpaid work; and the exclusion of class and gender considerations. [[Feminist economics]] developed to address these concerns, and the field now includes critical examinations of many areas of economics including paid and unpaid work, economic epistemology and history, globalization, household economics and the care economy. In 1988, [[Marilyn Waring]] published the book "[[If Women Counted]]", in which she argues that the discipline of economics ignores [[women's work|women's unpaid work]] and the value of [[nature]]; according to [[Julie A. Nelson]], "If Women Counted" "showed exactly how the unpaid work traditionally done by women has been made invisible within [[national accounts|national accounting systems]]" and "issued a wake-up call to issues of ecological [[sustainability]]." BjÃ¸rnholt and McKay argue that the [[financial crisis of 2007â08]] and the response to it revealed a crisis of ideas in mainstream economics and within the economics profession, and call for a reshaping of both the economy, economic theory and the economics profession. They argue that such a reshaping should include new advances within feminist economics that take as their starting point the socially responsible, sensible and accountable subject in creating an economy and economic theories that fully acknowledge care for each other as well as the planet.
[[Philip Mirowski]] observes that
In a series of peer-reviewed journal and conference papers and books published over a period of several decades, [[John McMurtry]] has provided extensive criticism of what he terms the "unexamined assumptions and implications [of economics], and their consequent cost to people's lives."
[[Nassim Nicholas Taleb]] and [[Michael Perelman]] are two additional scholars who criticized conventional or mainstream economics. Taleb opposes most economic theorizing, which in his view suffers acutely from the problem of overuse of Plato's Theory of Forms, and calls for cancellation of the [[Nobel Memorial Prize in Economics]], saying that the damage from economic theories can be devastating. Michael Perelman provides extensive criticism of economics and its assumptions in all his [[Michael Perelman#Books|books]] (and especially his [[Michael Perelman#Books|books]] published from 2000 to date), papers and interviews.
Despite these concerns, mainstream graduate programs have become increasingly technical and mathematical.
General:
[[Category:Economics| ]]
External links.
[[Category:Economic theories]]
[[Category:General economics]]
[[Category:Social sciences]]
[[Category:Economics terminology| ]]
[[as:à¦à§°à§à¦¥à¦¨à§à¦¤à¦¿]]

</doc>
<doc id="9225" url="https://en.wikipedia.org/wiki?curid=9225" title="Electronic paper">
Electronic paper

Electronic paper and e-paper are display technologies that mimic the appearance of ordinary ink on paper. Unlike conventional backlit flat panel displays that emit light, electronic paper displays reflect light like paper. This may make them more comfortable to read, and provide a wider viewing angle than most light-emitting displays. The contrast ratio in electronic displays available as of 2008 approaches newspaper, and newly developed displays are slightly better. An ideal e-paper display can be read in direct sunlight without the image appearing to fade.
Many electronic paper technologies hold static text and images indefinitely without electricity. Flexible electronic paper uses plastic substrates and plastic electronics for the display backplane. There is ongoing competition among manufacturers to provide full-color ability.
Applications of electronic visual displays include electronic pricing labels in retail shops, and digital signage, time tables at bus stations, electronic billboards, mobile phone displays, and e-readers able to display digital versions of books and e-paper magazines.
Technologies.
Gyricon.
Electronic paper was first developed in the 1970s by Nick Sheridon at Xerox's Palo Alto Research Center. The first electronic paper, called Gyricon, consisted of polyethylene spheres between 75 and 106 micrometers across. Each sphere is a janus particle composed of negatively charged black plastic on one side and positively charged white plastic on the other (each bead is thus a dipole). The spheres are embedded in a transparent silicone sheet, with each sphere suspended in a bubble of oil so that they can rotate freely. The polarity of the voltage applied to each pair of electrodes then determines whether the white or black side is face-up, thus giving the pixel a white or black appearance.
At the FPD 2008 exhibition, Japanese company Soken demonstrated a wall with electronic wall-paper using this technology. From 2007 the Estonian company Visitret Displays is developing this kind of displays using polyvinylidene fluoride (PVDF) as the material for spheres, dramatically improving the video speed and decreasing the control voltage.
Electrophoretic.
In the simplest implementation of an electrophoretic display, titanium dioxide (titania) particles approximately one micrometer in diameter are dispersed in a hydrocarbon oil. A dark-colored dye is also added to the oil, along with surfactants and charging agents that cause the particles to take on an electric charge. This mixture is placed between two parallel, conductive plates separated by a gap of 10 to 100 micrometres. When a voltage is applied across the two plates, the particles migrate electrophoretically to the plate that bears the opposite charge from that on the particles. When the particles are located at the front (viewing) side of the display, it appears white, because light is scattered back to the viewer by the high-index titania particles. When the particles are located at the rear side of the display, it appears dark, because the incident light is absorbed by the colored dye. If the rear electrode is divided into a number of small picture elements (pixels), then an image can be formed by applying the appropriate voltage to each region of the display to create a pattern of reflecting and absorbing regions.
Electrophoretic displays are considered prime examples of the electronic paper category, because of their paper-like appearance and low power consumption.
Examples of commercial electrophoretic displays include the high-resolution active matrix displays used in the Amazon Kindle, Barnes & Noble Nook, Sony Librie, Sony Reader, Kobo eReader and iRex iLiad e-readers. These displays are constructed from an electrophoretic imaging film manufactured by E Ink Corporation. A mobile phone that used the technology is the Motorola Fone.
Electrophoretic Display technology has also been developed by Sipix and Bridgestone/Delta.
SiPix is now part of E Ink. The Sipix design uses a flexible 0.15mm Microcup architecture, instead of E Ink's 0.04mm diameter microcapsules.
Bridgestone Corp.'s Advanced Materials Division cooperated with Delta Optoelectronics Inc. in developing the Quick Response Liquid Powder Display (QR-LPD) technology.
Electrophoretic displays can be manufactured using the Electronics on Plastic by Laser Release (EPLaR) process developed by Philips Research to enable existing AM-LCD manufacturing plants to create flexible plastic displays.
Microencapsulated Electrophoretic Display.
An electrophoretic display forms images by rearranging charged pigment particles with an applied electric field.
In the 1990s another type of electronic ink based on a microencapsulated electrophoretic display was conceived and prototyped by a team of undergraduates at MIT as described in their Nature paper. J.D. Albert, Barrett Comiskey, Joseph Jacobson, Jeremy Rubin and Russ Wilcox co-founded E Ink Corporation in 1997 to commercialize the technology. E ink subsequently formed a partnership with Philips Components two years later to develop and market the technology. In 2005, Philips sold the electronic paper business as well as its related patents to Prime View International. âIt has for many years been an ambition of researchers in display media to create a flexible low-cost system that is the electronic analogue of paper. In this context, microparticle-based displays have long intrigued researchers. Switchable contrast in such displays is achieved by the electromigration of highly scattering or absorbing microparticles (in the size range 0.1â5mm), quite distinct from the molecular-scale properties that govern the behaviour of the more familiar liquid-crystal displays. Micro-particle-based displays possess intrinsic bistability, exhibit extremely low power d.c. field addressing and have demonstrated high contrast and reflectivity. These features, combined with a near-lambertian viewing characteristic, result in an âink on paperâ look. But such displays have to date suffered from short lifetimes and difficulty in manufacture. Here we report the synthesis of an electrophoretic ink based on the microencapsulation of an electrophoretic dispersion. The use of a microencapsulated electrophoretic medium solves the lifetime issues and permits the fabrication of a bistable electronic display solely by means of printing. This system may satisfy the practical requirements of electronic paper.â
This used tiny microcapsules filled with electrically charged white particles suspended in a colored oil. In early versions, the underlying circuitry controlled whether the white particles were at the top of the capsule (so it looked white to the viewer) or at the bottom of the capsule (so the viewer saw the color of the oil). This was essentially a reintroduction of the well-known electrophoretic display technology, but microcapsules meant the display could be made on flexible plastic sheets instead of glass.
One early version of electronic paper consists of a sheet of very small transparent capsules, each about 40 micrometers across. Each capsule contains an oily solution containing black dye (the electronic ink), with numerous white titanium dioxide particles suspended within. The particles are slightly negatively charged, and each one is naturally white.
The screen holds microcapsules in a layer of liquid polymer, sandwiched between two arrays of electrodes, the upper of which is transparent. The two arrays are aligned to divide the sheet into pixels, and each pixel corresponds to a pair of electrodes situated on either side of the sheet. The sheet is laminated with transparent plastic for protection, resulting in an overall thickness of 80 micrometers, or twice that of ordinary paper.
The network of electrodes connects to display circuitry, which turns the electronic ink 'on' and 'off' at specific pixels by applying a voltage to specific electrode pairs. A negative charge to the surface electrode repels the particles to the bottom of local capsules, forcing the black dye to the surface and turning the pixel black. Reversing the voltage has the opposite effect. It forces the particles to the surface, turning the pixel white. A more recent implementation of this concept requires only one layer of electrodes beneath the microcapsules.
Electrowetting.
Electro-wetting display (EWD) is based on controlling the shape of a confined water/oil interface by an applied voltage. With no voltage applied, the (colored) oil forms a flat film between the water and a hydrophobic (water-repellent) insulating coating of an electrode, resulting in a colored pixel.
When a voltage is applied between the electrode and the water, the interfacial tension between the water and the coating changes. As a result, the stacked state is no longer stable, causing the water to move the oil aside.
This makes a partly transparent pixel, or, if a reflective white surface is under the switchable element, a white pixel. Because of the small pixel size, the user only experiences the average reflection, which provides a high-brightness, high-contrast switchable element.
Displays based on electro-wetting provide several attractive features. The switching between white and colored reflection is fast enough to display video content.
It's a low-power and low-voltage technology, and displays based on the effect can be made flat and thin. The reflectivity and contrast are better than or equal to other reflective display types and approach the visual qualities of paper.
In addition, the technology offers a unique path toward high-brightness full-color displays, leading to displays that are four times brighter than reflective LCDs and twice as bright as other emerging technologies.
Instead of using red, green and blue (RGB) filters or alternating segments of the three primary colors, which effectively result in only one third of the display reflecting light in the desired color, electro-wetting allows for a system in which one sub-pixel can switch two different colors independently.
This results in the availability of two thirds of the display area to reflect light in any desired color. This is achieved by building up a pixel with a stack of two independently controllable colored oil films plus a color filter.
The colors are cyan, magenta and yellow, which is a subtractive system, comparable to the principle used in inkjet printing for example. Compared to LCD another factor two in brightness is gained because no polarisers are required.
Examples of commercial electrowetting displays include Liquavista, ITRI, PVI and ADT.
Miortechâs 2nd generation electrowetting display technology solves a number of issues of 1st generation electrowetting display technology and large-area devices are easy to manufacture since the pixel walls act as spacers. Miortech has established Etulipa as a subsidiary to bring its electrowetting display technology (EWD) into the digital signage space. Etulipa has been working on color displays that reflect sunlight, just like paper, with environmental benefits such as low power consumption and reduced light pollution that would overcome the disadvantages of LED billboards.
Electrofluidic.
Electrofluidic displays are a variation of an electrowetting display. Electrofluidic displays place an aqueous pigment dispersion inside a tiny reservoir. The reservoir comprises <5-10% of the viewable pixel area and therefore the pigment is substantially hidden from view. Voltage is used to electromechanically pull the pigment out of the reservoir and spread it as a film directly behind the viewing substrate. As a result, the display takes on color and brightness similar to that of conventional pigments printed on paper. When voltage is removed liquid surface tension causes the pigment dispersion to rapidly recoil into the reservoir. As reported in the May 2009 Issue of Nature Photonics, the technology can potentially provide >85% white state reflectance for electronic paper.
The core technology was invented at the Novel Devices Laboratory at the University of Cincinnati. The technology is currently being commercialized by Gamma Dynamics.
Interferometric modulator (Mirasol).
Technology used in electronic visual displays that can create various colors via interference of reflected light. The color is selected with an electrically switched light modulator comprising a microscopic cavity that is switched on and off using driver integrated circuits similar to those used to address liquid crystal displays (LCD).
Other technologies.
Other research efforts into e-paper have involved using organic transistors embedded into flexible substrates, including attempts to build them into conventional paper.
Simple color e-paper consists of a thin colored optical filter added to the monochrome technology described above. The array of pixels is divided into triads, typically consisting of the standard cyan, magenta and yellow, in the same way as CRT monitors (although using subtractive primary colors as opposed to additive primary colors). The display is then controlled like any other electronic color display.
Examples of electrochromic displays include Acreo, Ajjer, Aveso and Ntera.
Disadvantages.
Electronic paper technologies have a very low refresh rate compared to other low-power display technologies, such as LCD. This prevents producers from implementing sophisticated interactive applications (using fast moving menus, mouse pointers or scrolling) like those common on standard mobile devices. An example of this limit is that a document cannot be smoothly zoomed without either extreme blurring during the transition or a very slow zoom.
Another limit is that a shadow of an image may be visible after refreshing parts of the screen. Such shadows are termed "ghost images", and the effect is termed "ghosting". This effect is reminiscent of screen burn-in but, unlike screen burn-in, is solved after the screen is refreshed several times. Turning every pixel white, then black, then white, helps normalize the contrast of the pixels. This is why several devices with this technology "flash" the entire screen white and black when loading a new image.
E Ink Corporation of E Ink Holdings released the first colored e-ink displays to be used in a marketed product. The ECTACO JetBook Colorâ¢ was released in 2012 as the first colored e-ink e-reader, which used the Tritonâ¢ display technology of the E Ink Corporation. E Ink Corporation in early 2015 also released a newer e-ink technology called Prismâ¢. This new technology is a color changing film that can be used for e-reader, but Prismâ¢ is also marketed as a film that can be integrated into architectural design such as "wall, ceiling panel, or entire room instantly." The disadvantages present within these technologies are that they are considerably more expensive than standard e-ink, at least in the case of the JetBook Colorâ¢. The JetBook Colorâ¢ costs roughly nine times more than other popular e-readers such as the Amazon Kindleâ¢ as of 27 Nov 2015. Also, as of 6 Jan 2015, Prismâ¢ had not been announced in to used in the plans for any e-reader devices. This may change in the future. These disadvantages are as referenced from the consumer end.
Applications.
Several companies are simultaneously developing electronic paper and ink. While the technologies used by each company provide many of the same features, each has its own distinct technological advantages. All electronic paper technologies face the following general challenges:
Electronic ink can be applied to flexible or rigid materials. For flexible displays, the base requires a thin, flexible material tough enough to withstand considerable wear, such as extremely thin plastic. The method of how the inks are encapsulated and then applied to the substrate is what distinguishes each company from others. These processes are complex and are carefully guarded industry secrets. Nevertheless, making electronic paper is less complex and costly than LCDs.
There are many approaches to electronic paper, with many companies developing technology in this area. Other technologies being applied to electronic paper include modifications of liquid crystal displays, electrochromic displays, and the electronic equivalent of an Etch A Sketch at Kyushu University. Advantages of electronic paper includes low power usage (power is only drawn when the display is updated), flexibility and better readability than most displays. Electronic ink can be printed on any surface, including walls, billboards, product labels and T-shirts. The ink's flexibility would also make it possible to develop rollable displays for electronic devices.
Wristwatches.
In December 2005 Seiko released the first electronic ink based watch called the Spectrum SVRD001 wristwatch, which has a flexible electrophoretic display and in March 2010 Seiko released a second generation of this famous e-ink watch with an active matrix display. The Pebble smart watch (2013) uses a low-power memory LCD manufactured by Sharp for its e-paper display.
e-Books.
In 2004 Sony released LibriÃ© EBR-1000EP in Japan, the first e-book reader with an electronic paper display. In September 2006 Sony released the PRS-500 Sony Reader e-book reader in the USA. On October 2, 2007, Sony announced the PRS-505, an updated version of the Reader. In November 2008, Sony released the PRS-700BC, which incorporated a backlight and a touchscreen.
In late 2007, Amazon began producing and marketing the Amazon Kindle, an e-book reader with an e-paper display. In February 2009, Amazon released the Kindle 2 and in May 2009 the larger Kindle DX was announced. In July 2010 the third generation Kindle was announced, with notable design changes. The fourth generation of Kindles were announced in September 2011. This generation was unique as it marked the Kindle's first departure from keyboards in favor of touchscreens. In September 2012, Amazon announced the fifth generation of the Kindle, which incorporates a LED frontlight and a higher contrast display.
In November 2009 Barnes and Noble launched the Barnes & Noble Nook, running an Android operating system. It differs from other big name readers in having a replaceable battery, and a separate touch-screen color LCD below the main electronic paper reading screen.
Newspapers.
In February 2006, the Flemish daily "De Tijd" distributed an electronic version of the paper to select subscribers in a limited marketing study, using a pre-release version of the iRex iLiad. This was the first recorded application of electronic ink to newspaper publishing.
The French daily "Les Ãchos" announced the official launch of an electronic version of the paper on a subscription basis, in September 2007. Two offers were available, combining a one-year subscription and a reading device. The offer included either a light (176g) reading device (adapted for Les Echos by Ganaxa) or the iRex iLiad. Two different processing platforms were used to deliver readable information of the daily, one based on the newly developed GPP electronic ink platform from "Ganaxa", and the other one developed internally by Les Echos.
Displays embedded in smart cards.
Flexible display cards enable financial payment cardholders to generate a one-time password to reduce online banking and transaction fraud. Electronic paper offers a flat and thin alternative to existing key fob tokens for data security. The worldâs first ISO compliant smart card with an embedded display was developed by Innovative Card Technologies and nCryptone in 2005. The cards were manufactured by Nagra ID.
Status displays.
Some devices, like USB flash drives, have used electronic paper to display status information, such as available storage space. Once the image on the electronic paper has been set, it requires no power to maintain, so the readout can be seen even when the flash drive is not plugged in.
Mobile phones.
Motorola's low-cost mobile phone, the Motorola F3, uses an alphanumeric black-and-white electrophoretic display.
The Samsung Alias 2 mobile phone incorporates electronic ink from E Ink into the keypad, which allows the keypad to change character sets and orientation while in different display modes.
On December 12, 2012, Yota Devices announced the first "YotaPhone" prototype and was later released on December 2013, a unique double-display smartphone. It has an 4.3-inch, HD LCD display on the front and an e-ink display on the back with smart battery usage.
Electronic shelf labels.
E-Paper based electronic shelf labels (ESL) are used to digitally display the prices of goods at retail stores. Electronic paper based labels are updated via two-way infrared or radio technology.
Other.
Other proposed applications include clothes, digital photo frames, information boards and keyboards. Keyboards with dynamically changeable keys are useful for less represented languages, non-standard keyboard layouts such as Dvorak, or for special non-alphabetical applications such as video editing or games.

</doc>
<doc id="9228" url="https://en.wikipedia.org/wiki?curid=9228" title="Earth">
Earth

Earth (otherwise known as The World, in "Gaia", or in Latin: Terra) is the third planet from the Sun, the densest planet in the Solar System, the largest of the Solar System's four terrestrial planets, and the only astronomical object known to harbor life.
According to evidence from radiometric dating and other sources, Earth was formed about 4.54 billion years ago. Earth gravitationally interacts with other objects in space, especially the Sun and the Moon. During one orbit around the Sun, Earth rotates about its own axis 366.26 times, creating 365.26 solar days or one sidereal year. Earth's axis of rotation is tilted 23.4Â° away from the perpendicular of its orbital plane, producing seasonal variations on the planet's surface with a period of one tropical year (365.24 solar days). The Moon is Earth's only permanent natural satellite. Its gravitational interaction with Earth causes ocean tides, stabilizes the orientation of Earth's rotational axis, and gradually slows Earth's rotational rate.
Earth's lithosphere is divided into several rigid tectonic plates that migrate across the surface over periods of many millions of years. 71% of Earth's surface is covered with water, with the remainder consisting of continents and islands that together have many lakes and other sources of water that contribute to the hydrosphere. Earth's polar regions are mostly covered with ice, including the Antarctic ice sheet and the sea ice of the Arctic ice pack. Earth's interior remains active with a solid iron inner core, a liquid outer core that generates the magnetic field, and a convecting mantle that drives plate tectonics.
Within its first billion years, life appeared in Earth's oceans and began to affect its atmosphere and surface, promoting the proliferation of aerobic as well as anaerobic organisms. Since then, the combination of Earth's distance from the Sun, its physical properties and its geological history have allowed life to thrive and evolve. The earliest undisputed life on Earth arose at least 3.5 billion years ago. Earlier physical evidence of life includes biogenic graphite in 3.7 billion-year-old metasedimentary rocks discovered in southwestern Greenland, as well as "remains of biotic life" found in 4.1 billion-year-old rocks in Western Australia. Earth's biodiversity has expanded continually except when interrupted by mass extinctions. Although scholars estimate that over 99% of all species of life (over five billion) that ever lived on Earth are extinct, there are still an estimated 10â14 million extant species, of which about 1.2 million have been documented and over 86% have not yet been described. Over 7.3 billion humans live on Earth and depend on its biosphere and minerals for their survival. Earth's human population is divided among about two hundred sovereign states which interact through diplomacy, conflict, travel, trade and communication media.
Chronology.
Formation.
The earliest material found in the Solar System is dated to (Gya). By the primordial Earth had formed. The formation and evolution of the Solar System bodies occurred along with those of the Sun. In theory, a solar nebula partitions a volume out of a molecular cloud by gravitational collapse, which begins to spin and flatten into a circumstellar disk, and then the planets grow out of that along with the Sun. A nebula contains gas, ice grains, and dust (including primordial nuclides). In nebular theory, planetesimals form by accretion. The assembly of the primordial Earth proceeded for 10â.
The process that led to the formation of the Moon approximately 4.53 billion years ago is the subject of ongoing research. The working hypothesis is that it formed by accretion from material loosed from Earth after a Mars-sized object, named Theia, impacted with Earth. In this scenario, the mass of Theia was 10% of that of Earth, it impacted Earth with a glancing blow, and some of its mass merged with Earth. Between approximately 4.1 and , numerous asteroid impacts during the Late Heavy Bombardment caused significant changes to the greater surface environment of the Moon, and by inference, to Earth.
Geological history.
Earth's atmosphere and oceans formed by volcanic activity and outgassing that included water vapor. The origin of the world's oceans was condensation augmented by water and ice delivered by asteroids, protoplanets, and comets. In this model, atmospheric "greenhouse gases" kept the oceans from freezing when the newly forming Sun had only 70% of its current luminosity. By , Earth's magnetic field was established, which helped prevent the atmosphere from being stripped away by the solar wind.
A crust formed when the molten outer layer of Earth cooled to form a solid as the accumulated water vapor began to act in the atmosphere. The two models that explain land mass propose either a steady growth to the present-day forms or, more likely, a rapid growth early in Earth history followed by a long-term steady continental area. Continents formed by plate tectonics, a process ultimately driven by the continuous loss of heat from Earth's interior. On time scales lasting hundreds of millions of years, the supercontinents have formed and broken up three times. Roughly (million years ago), one of the earliest known supercontinents, Rodinia, began to break apart. The continents later recombined to form Pannotia, 600â, then finally Pangaea, which also broke apart .
The present pattern of ice ages began about and then intensified during the Pleistocene about . High-latitude regions have since undergone repeated cycles of glaciation and thaw, repeating every 40â. The last continental glaciation ended 10,000Â years ago.
Evolution of life.
Highly energetic chemical reactions are thought to have produced selfâreplicating molecules around four billion years ago. This was followed a half billion years later by the last common ancestor of all life. The development of photosynthesis allowed the Sun's energy to be harvested directly by life forms; the resultant molecular oxygen (O) accumulated in the atmosphere and due to interaction with ultraviolet solar radiation, formed a layer of protective ozone (O) in the upper atmosphere. The incorporation of smaller cells within larger ones resulted in the development of complex cells called eukaryotes. True multicellular organisms formed as cells within colonies became increasingly specialized. Aided by the absorption of harmful ultraviolet radiation by the ozone layer, life colonized Earth's surface. The earliest fossil evidence for life is microbial mat fossils found in 3.48 billion-year-old sandstone in Western Australia, biogenic graphite found in 3.7 billion-year-old metasedimentary rocks in Western Greenland, as well as, "remains of biotic life" found in 4.1 billion-year-old rocks in Western Australia.
Since the 1960s, it has been hypothesized that severe glacial action between 750 and , during the Neoproterozoic, covered much of Earth in ice. This hypothesis has been termed "Snowball Earth", and it is of particular interest because it preceded the Cambrian explosion, when multicellular life forms began to proliferate.
Following the Cambrian explosion, about , there have been five major mass extinctions. The most recent such event was , when an asteroid impact triggered the extinction of the non-avian dinosaurs and other large reptiles, but spared some small animals such as mammals, which then resembled shrews. Over the past , mammalian life has diversified, and several million years ago an African ape-like animal such as "Orrorin tugenensis" gained the ability to stand upright. This facilitated tool use and encouraged communication that provided the nutrition and stimulation needed for a larger brain, which allowed the evolution of the human race. The development of agriculture, and then civilization, led to humans having an influence on Earth and the nature and quantity of other life forms as no other species ever has.
Predicted future.
Estimates on how much longer Earth will be able to continue to support life range from , to as long as . Earth's long-term future is closely tied to that of the Sun. As a result of the steady accumulation of helium at the Sun's core, the Sun's total luminosity will slowly increase. The luminosity of the Sun will grow by 10% over the next and by 40% over the next . Climate models indicate that the rise in radiation reaching Earth is likely to have dire consequences, including the loss of the oceans.
Earth's increasing surface temperature will accelerate the inorganic CO cycle, reducing its concentration to levels lethally low for plants ( for C4 photosynthesis) in approximately 500â. The lack of vegetation will result in the loss of oxygen in the atmosphere, so animal life will become extinct within several million more years. After another billion years all surface water will have disappeared and the mean global temperature will reach (). Earth is expected to be effectively habitable for about another from that point, although this may be extended up to if the nitrogen is removed from the atmosphere. Even if the Sun were eternal and stable, 27% of the water in the modern oceans will descend to the mantle in one billion years, due to reduced steam venting from mid-ocean ridges.
The Sun will evolve to become a red giant in about . Models predict that the Sun will expand to roughly , which is about 250 times its present radius. Earth's fate is less clear. As a red giant, the Sun will lose roughly 30% of its mass, so, without tidal effects, Earth will move to an orbit from the Sun when it reaches its maximum radius. Earth was, therefore, once expected to escape envelopment by the expanded Sun's outer atmosphere, though most, if not all, remaining life would have been destroyed by the Sun's increased luminosity (peaking at about 5,000 times its present level). A 2008 simulation indicates that Earth's orbit will decay due to tidal effects and drag, causing it to enter the red giant Sun's atmosphere and be vaporized.
Name and etymology.
The modern English word "Earth" developed from a wide variety of Middle English forms, which derived from an Old English noun most often spelled '. It has cognates in every Germanic language, and their proto-Germanic root has been reconstructed as *"erÃ¾Å". In its earliest appearances, "eorÃ°e" was already being used to translate the many senses of Latin ' and Greek ("gÄ"): the ground, its soil, dry land, the human world, the surface of the world (including the sea), and the globe itself. As with Terra and Gaia, Earth was a personified goddess in Germanic paganism: the Angles were listed by Tacitus as among the devotees of Nerthus, and later Norse mythology included JÃ¶rÃ°, a giantess often given as the mother of Thor.
Originally, "earth" was written in lowercase, and from early Middle English, its definite sense as "the globe" was expressed as "the earth". By early Modern English, many nouns were capitalized, and "the earth" became (and often remained) "the Earth", particularly when referenced along with other heavenly bodies. More recently, the name is sometimes simply given as "Earth", by analogy with the names of the other planets. House styles now vary: Oxford spelling recognizes the lowercase form as the most common, with the capitalized form an acceptable variant. Another convention capitalizes "Earth" when appearing as a name (e.g. "Earth's atmosphere") but writes it in lowercase when preceded by "the" (e.g. "the atmosphere of the earth"). It almost always appears in lowercase in colloquial expressions such as "what on earth are you doing?"
Composition and structure.
Shape.
The shape of Earth approximates an oblate spheroid, a sphere flattened along the axis from pole to pole such that there is a bulge around the equator. This bulge results from the rotation of Earth, and causes the diameter at the equator to be larger than the pole-to-pole diameter. Thus the point on the surface farthest from Earth's center of mass is the summit of the equatorial Chimborazo volcano in Ecuador. The average diameter of the reference spheroid is about , which is approximately (40,000Â km)/Ï, because the meter was originally defined as 1/10,000,000 of the distance from the equator to the North Pole through Paris, France.
Local topography deviates from this idealized spheroid, although on a global scale these deviations are small compared to Earth's radius: The maximum deviation of only 0.17% is at the Mariana Trench ( below local sea level), whereas Mount Everest ( above local sea level) represents a deviation of 0.14%. If Earth were shrunk to the size of a billiard ball, some areas of Earth such as large mountain ranges and oceanic trenches would feel like tiny imperfections, whereas much of the planet, including the Great Plains and the abyssal plains, would feel smoother.
Chemical composition.
Earth's mass is approximately (5,970 Yg). It is composed mostly of iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur (2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%), with the remaining 1.2% consisting of trace amounts of other elements. Due to mass segregation, the core region is estimated to be primarily composed of iron (88.8%), with smaller amounts of nickel (5.8%), sulfur (4.5%), and less than 1% trace elements.
The geochemist F. W. Clarke calculated that a little more than 47% of Earth's crust consists of oxygen. The more common rock constituents of the crust are nearly all oxides: chlorine, sulfur and fluorine are the important exceptions to this and their total amount in any rock is usually much less than 1%. The principal oxides are silica, alumina, iron oxides, lime, magnesia, potash and soda. The silica functions principally as an acid, forming silicates, and all the most common minerals of igneous rocks are of this nature. From a computation based on 1,672 analyses of all kinds of rocks, Clarke deduced that 99.22% was composed of 11 oxides (see the table at right), with the other constituents occurring in minute quantities.
Internal structure.
Earth's interior, like that of the other terrestrial planets, is divided into layers by their chemical or physical (rheological) properties, but unlike the other terrestrial planets, it has a distinct outer and inner core. The outer layer is a chemically distinct silicate solid crust, which is underlain by a highly viscous solid mantle. The crust is separated from the mantle by the MohoroviÄiÄ discontinuity, and the thickness of the crust varies: averaging (kilometers) under the oceans and 30â50Â km on the continents. The crust and the cold, rigid, top of the upper mantle are collectively known as the lithosphere, and it is of the lithosphere that the tectonic plates are composed. Beneath the lithosphere is the asthenosphere, a relatively low-viscosity layer on which the lithosphere rides. Important changes in crystal structure within the mantle occur at 410 and below the surface, spanning a transition zone that separates the upper and lower mantle. Beneath the mantle, an extremely low viscosity liquid outer core lies above a solid inner core. The inner core may rotate at a slightly higher angular velocity than the remainder of the planet, advancing by 0.1â0.5Â° per year. The radius of the inner core is about one fifth of Earth's.
Heat.
Earth's internal heat comes from a combination of residual heat from planetary accretion (about 20%) and heat produced through radioactive decay (80%). The major heat-producing isotopes within Earth are potassium-40, uranium-238, uranium-235, and thorium-232. At the center, the temperature may be up to , and the pressure could reach 360Â GPa. Because much of the heat is provided by radioactive decay, scientists postulate that early in Earth's history, before isotopes with short half-lives had been depleted, Earth's heat production would have been much higher. This extra heat production, twice present-day at approximately , would have increased temperature gradients with radius, increasing the rates of mantle convection and plate tectonics, and allowing the production of uncommon igneous rocks such as komatiites that are rarely formed today.
The mean heat loss from Earth is , for a global heat loss of . A portion of the core's thermal energy is transported toward the crust by mantle plumes; a form of convection consisting of upwellings of higher-temperature rock. These plumes can produce hotspots and flood basalts. More of the heat in Earth is lost through plate tectonics, by mantle upwelling associated with mid-ocean ridges. The final major mode of heat loss is through conduction through the lithosphere, the majority of which occurs under the oceans because the crust there is much thinner than that of the continents.
Tectonic plates.
The mechanically rigid outer layer of Earth, the lithosphere, is broken into pieces called tectonic plates. These plates are rigid segments that move in relation to one another at one of three types of plate boundaries: convergent boundaries, at which two plates come together, divergent boundaries, at which two plates are pulled apart, and transform boundaries, in which two plates slide past one another laterally. Earthquakes, volcanic activity, mountain-building, and oceanic trench formation can occur along these plate boundaries. The tectonic plates ride on top of the asthenosphere, the solid but less-viscous part of the upper mantle that can flow and move along with the plates.
As the tectonic plates migrate across the planet, the ocean floor is subducted under the leading edges of the plates at convergent boundaries. At the same time, the upwelling of mantle material at divergent boundaries creates mid-ocean ridges. The combination of these processes continually recycles the oceanic crust back into the mantle. Due to this recycling, most of the ocean floor is less than old in age. The oldest oceanic crust is located in the Western Pacific, and has an estimated age of about . By comparison, the oldest dated continental crust is .
The seven major plates are the Pacific, North American, Eurasian, African, Antarctic, Indo-Australian, and South American. Other notable plates include the Arabian Plate, the Caribbean Plate, the Nazca Plate off the west coast of South America and the Scotia Plate in the southern Atlantic Ocean. The Australian Plate fused with the Indian Plate between 50 and . The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of 75Â mm/year and the Pacific Plate moving 52â69Â mm/year. At the other extreme, the slowest-moving plate is the Eurasian Plate, progressing at a typical rate of about 21Â mm/year.
Surface.
Earth's terrain varies greatly from place to place. About 70.8% of the surface is covered by water, with much of the continental shelf below sea level. This equates to (139.43 million sq mi). The submerged surface has mountainous features, including a globe-spanning mid-ocean ridge system, as well as undersea volcanoes, oceanic trenches, submarine canyons, oceanic plateaus and abyssal plains. The remaining 29.2% (, or 57.51 million sq mi) not covered by water consists of mountains, deserts, plains, plateaus, and other landforms.
The planetary surface undergoes reshaping over geological time periods due to tectonics and erosion. The surface features built up or deformed through plate tectonics are subject to steady weathering and erosion from precipitation, thermal cycles, and chemical effects. Glaciation, coastal erosion, the build-up of coral reefs, and large meteorite impacts also act to reshape the landscape.
The continental crust consists of lower density material such as the igneous rocks granite and andesite. Less common is basalt, a denser volcanic rock that is the primary constituent of the ocean floors. Sedimentary rock is formed from the accumulation of sediment that becomes buried and compacted together. Nearly 75% of the continental surfaces are covered by sedimentary rocks, although they form about 5% of the crust. The third form of rock material found on Earth is metamorphic rock, which is created from the transformation of pre-existing rock types through high pressures, high temperatures, or both. The most abundant silicate minerals on Earth's surface include quartz, feldspars, amphibole, mica, pyroxene and olivine. Common carbonate minerals include calcite (found in limestone) and dolomite.
The pedosphere is the outermost layer of Earth's continental surface and is composed of soil and subject to soil formation processes. The total arable land is 10.9% of the land surface, with 1.3% being permanent cropland. Close to 40% of Earth's land surface is used for cropland and pasture, or an estimated 1.3Â km of cropland and 3.4Â km of pastureland.
The elevation of the land surface varies from the low point of â418Â m at the Dead Sea, to a 2005-estimated maximum altitude of 8,848Â m at the top of Mount Everest. The mean height of land above sea level is 840Â m.
Besides being divided logically into Northern and Southern hemispheres centered on the poles, Earth has been divided arbitrarily into Eastern and Western hemispheres. Earth's surface is traditionally divided into seven continents and various seas.
Hydrosphere.
The abundance of water on Earth's surface is a unique feature that distinguishes the "Blue Planet" from other planets in the Solar System. Earth's hydrosphere consists chiefly of the oceans, but technically includes all water surfaces in the world, including inland seas, lakes, rivers, and underground waters down to a depth of 2,000Â m. The deepest underwater location is Challenger Deep of the Mariana Trench in the Pacific Ocean with a depth of 10,911.4Â m.
The mass of the oceans is approximately 1.35Â metric tons, or about 1/4400 of Earth's total mass. The oceans cover an area of with a mean depth of , resulting in an estimated volume of . If all of Earth's crustal surface was at the same elevation as a smooth sphere, the depth of the resulting world ocean would be 2.7 to 2.8Â km.
About 97.5% of the water is saline; the remaining 2.5% is fresh water. Most fresh water, about 68.7%, is present as ice in ice caps and glaciers.
The average salinity of Earth's oceans is about 35Â grams of salt per kilogram of sea water (3.5% salt). Most of this salt was released from volcanic activity or extracted from cool igneous rocks. The oceans are also a reservoir of dissolved atmospheric gases, which are essential for the survival of many aquatic life forms. Sea water has an important influence on the world's climate, with the oceans acting as a large heat reservoir. Shifts in the oceanic temperature distribution can cause significant weather shifts, such as the El NiÃ±o-Southern Oscillation.
Atmosphere.
The atmospheric pressure on Earth's surface averages 101.325Â kPa, with a scale height of about 8.5Â km. It has a composition of 78% nitrogen and 21% oxygen, with trace amounts of water vapor, carbon dioxide and other gaseous molecules. The height of the troposphere varies with latitude, ranging between 8Â km at the poles to 17Â km at the equator, with some variation resulting from weather and seasonal factors.
Earth's biosphere has significantly altered its atmosphere. Oxygenic photosynthesis evolved , forming the primarily nitrogenâoxygen atmosphere of today. This change enabled the proliferation of aerobic organisms and, indirectly, the formation of the ozone layer due to the subsequent conversion of atmospheric O into O. The ozone layer blocks ultraviolet solar radiation, permitting life on land. Other atmospheric functions important to life include transporting water vapor, providing useful gases, causing small meteors to burn up before they strike the surface, and moderating temperature. This last phenomenon is known as the greenhouse effect: trace molecules within the atmosphere serve to capture thermal energy emitted from the ground, thereby raising the average temperature. Water vapor, carbon dioxide, methane and ozone are the primary greenhouse gases in the atmosphere. Without this heat-retention effect, the average surface temperature would be â18Â Â°C, in contrast to the current +15Â Â°C, and life would likely not exist.
Weather and climate.
Earth's atmosphere has no definite boundary, slowly becoming thinner and fading into outer space. Three-quarters of the atmosphere's mass is contained within the first 11Â km of the surface. This lowest layer is called the troposphere. Energy from the Sun heats this layer, and the surface below, causing expansion of the air. This lower-density air then rises, and is replaced by cooler, higher-density air. The result is atmospheric circulation that drives the weather and climate through redistribution of thermal energy.
The primary atmospheric circulation bands consist of the trade winds in the equatorial region below 30Â° latitude and the westerlies in the mid-latitudes between 30Â° and 60Â°. Ocean currents are also important factors in determining climate, particularly the thermohaline circulation that distributes thermal energy from the equatorial oceans to the polar regions.
Water vapor generated through surface evaporation is transported by circulatory patterns in the atmosphere. When atmospheric conditions permit an uplift of warm, humid air, this water condenses and falls to the surface as precipitation. Most of the water is then transported to lower elevations by river systems and usually returned to the oceans or deposited into lakes. This water cycle is a vital mechanism for supporting life on land, and is a primary factor in the erosion of surface features over geological periods. Precipitation patterns vary widely, ranging from several meters of water per year to less than a millimeter. Atmospheric circulation, topographic features and temperature differences determine the average precipitation that falls in each region.
The amount of solar energy reaching Earth's surface decreases with increasing latitude. At higher latitudes the sunlight reaches the surface at lower angles and it must pass through thicker columns of the atmosphere. As a result, the mean annual air temperature at sea level decreases by about per degree of latitude from the equator. Earth's surface can be subdivided into specific latitudinal belts of approximately homogeneous climate. Ranging from the equator to the polar regions, these are the tropical (or equatorial), subtropical, temperate and polar climates. Climate can also be classified based on the temperature and precipitation, with the climate regions characterized by fairly uniform air masses. The commonly used KÃ¶ppen climate classification system (as modified by Wladimir KÃ¶ppen's student Rudolph Geiger) has five broad groups (humid tropics, arid, humid middle latitudes, continental and cold polar), which are further divided into more specific subtypes.
Climate on Earth has latitudinal anomalies, namely the habitability of the Scandinavian peninsula very far north in sharp contrast to the polar climates of northern Canada as well as the cool summers expected at low latitudes in the Southern Hemisphere (for example on the west coast of South America). Another anomaly is the impact of landmass on temperature, manifested by the fact that Earth is much warmer at aphelion, where the planet is at a more distant position from the Sun. When the Northern hemisphere is turned towards the sunlight even the increased distance to it does not hinder temperatures to be warmer than at perihelionâwhen the marine southern hemisphere is turned towards the Sun.
At high latitudes, the western sides of continents tend to be milder than the eastern sidesâfor example seen in North America and Western Europe where rough continental climates appear on the east coast on parallels with mild climates on the other side of the ocean.
The highest air temperature ever measured on Earth was in Furnace Creek, California, in Death Valley, in 1913. The lowest air temperature ever directly measured on Earth was at Vostok Station in 1983, but satellites have used remote sensing to measure temperatures as low as in East Antarctica. These temperature records are only measurements made with modern instruments from the 20th century onwards and likely do not reflect the full range of temperature on Earth.
Upper atmosphere.
Above the troposphere, the atmosphere is usually divided into the stratosphere, mesosphere, and thermosphere. Each layer has a different lapse rate, defining the rate of change in temperature with height. Beyond these, the exosphere thins out into the magnetosphere, where the geomagnetic fields interact with the solar wind. Within the stratosphere is the ozone layer, a component that partially shields the surface from ultraviolet light and thus is important for life on Earth. The KÃ¡rmÃ¡n line, defined as 100Â km above Earth's surface, is a working definition for the boundary between the atmosphere and outer space.
Thermal energy causes some of the molecules at the outer edge of the atmosphere to increase their velocity to the point where they can escape from Earth's gravity. This causes a slow but steady leakage of the atmosphere into space. Because unfixed hydrogen has a low molecular mass, it can achieve escape velocity more readily and it leaks into outer space at a greater rate than other gases. The leakage of hydrogen into space contributes to the shifting of Earth's atmosphere and surface from an initially reducing state to its current oxidizing one. Photosynthesis provided a source of free oxygen, but the loss of reducing agents such as hydrogen is thought to have been a necessary precondition for the widespread accumulation of oxygen in the atmosphere. Hence the ability of hydrogen to escape from the atmosphere may have influenced the nature of life that developed on Earth. In the current, oxygen-rich atmosphere most hydrogen is converted into water before it has an opportunity to escape. Instead, most of the hydrogen loss comes from the destruction of methane in the upper atmosphere.
Magnetic field.
The main part of Earth's magnetic field is generated in the core, the site of a dynamo process that converts kinetic energy of fluid convective motion into electrical and magnetic field energy. The field extends outwards from the core, through the mantle, and up to Earth's surface, where it is, to rough approximation, a dipole. The poles of the dipole are located close to Earth's geographic poles. At the equator of the magnetic field, the magnetic-field strength at the surface is , with global magnetic dipole moment of . The convection movements in the core are chaotic; the magnetic poles drift and periodically change alignment. This causes field reversals at irregular intervals averaging a few times every million years. The most recent reversal occurred approximately 700,000 years ago.
Magnetosphere.
The extent of Earth's magnetic field in space defines the magnetosphere. Ions and electrons of the solar wind are deflected by the magnetosphere; solar wind pressure compresses the dayside of the magnetosphere, to about 10 Earth radii, and extends the nightside magnetosphere into a long tail. Because the velocity of the solar wind is greater than the speed at which wave propagate through the solar wind, a supersonic bowshock precedes the dayside magnetosphere within the solar wind. Charged particles are contained within the magnetosphere; the plasmasphere is defined by low-energy particles that essentially follow magnetic field lines as Earth rotates; the ring current is defined by medium-energy particles that drift relative to the geomagnetic field, but with paths that are still dominated by the magnetic field, and the Van Allen radiation belt are formed by high-energy particles whose motion is essentially random, but otherwise contained by the magnetosphere.
During a magnetic storm, charged particles can be deflected from the outer magnetosphere, directed along field lines into Earth's ionosphere, where atmospheric atoms can be excited and ionized, causing the aurora.
Orbit and rotation.
Rotation.
Earth's rotation period relative to the Sunâits mean solar dayâis 86,400Â seconds of mean solar time (86,400.0025Â SIÂ seconds). Because Earth's solar day is now slightly longer than it was during the 19th century due to tidal deceleration, each day varies between 0 and 2 SI ms longer.
Earth's rotation period relative to the fixed stars, called its "stellar day" by the International Earth Rotation and Reference Systems Service (IERS), is of mean solar time (UT1), or Earth's rotation period relative to the precessing or moving mean vernal equinox, misnamed its "sidereal day", is of mean solar time (UT1) . Thus the sidereal day is shorter than the stellar day by about 8.4Â ms. The length of the mean solar day in SI seconds is available from the IERS for the periods 1623â2005 and 1962â2005.
Apart from meteors within the atmosphere and low-orbiting satellites, the main apparent motion of celestial bodies in Earth's sky is to the west at a rate of 15Â°/h = 15'/min. For bodies near the celestial equator, this is equivalent to an apparent diameter of the Sun or the Moon every two minutes; from Earth's surface, the apparent sizes of the Sun and the Moon are approximately the same.
Orbit.
Earth orbits the Sun at an average distance of about every 365.2564 mean solar days, or one sidereal year. This gives an apparent movement of the Sun eastward with respect to the stars at a rate of about 1Â°/day, which is one apparent Sun or Moon diameter every 12Â hours. Due to this motion, on average it takes 24Â hoursâa solar dayâfor Earth to complete a full rotation about its axis so that the Sun returns to the meridian. The orbital speed of Earth averages about , which is fast enough to travel a distance equal to Earth's diameter, about , in seven minutes, and the distance to the Moon, , in about 3.5 hours.
The Moon and Earth orbit a common barycenter every 27.32Â days relative to the background stars. When combined with the EarthâMoon system's common orbit around the Sun, the period of the synodic month, from new moon to new moon, is 29.53Â days. Viewed from the celestial north pole, the motion of Earth, the Moon, and their axial rotations are all counterclockwise. Viewed from a vantage point above the north poles of both the Sun and Earth, Earth orbits in a counterclockwise direction about the Sun. The orbital and axial planes are not precisely aligned: Earth's axis is tilted some 23.4Â degrees from the perpendicular to the EarthâSun plane (the ecliptic), and the EarthâMoon plane is tilted up to Â±5.1Â degrees against the EarthâSun plane. Without this tilt, there would be an eclipse every two weeks, alternating between lunar eclipses and solar eclipses.
The Hill sphere, or gravitational sphere of influence, of Earth is about in radius. This is the maximum distance at which the Earth's gravitational influence is stronger than the more distant Sun and planets. Objects must orbit Earth within this radius, or they can become unbound by the gravitational perturbation of the Sun.
Earth, along with the Solar System, is situated in the Milky Way and orbits about 28,000Â light-years from its center. It is about 20Â light-years above the galactic plane in the Orion Arm.
Axial tilt and seasons.
The axial tilt of the Earth is approximately 23.439281Â°. Due to Earth's axial tilt, the amount of sunlight reaching any given point on the surface varies over the course of the year. This causes seasonal change in climate, with summer in the northern hemisphere occurring when the North Pole is pointing toward the Sun, and winter taking place when the pole is pointed away. During the summer, the day lasts longer and the Sun climbs higher in the sky. In winter, the climate becomes generally cooler and the days shorter. In northern temperate latitudes, the Sun rises north of true east during the summer solstice, and sets north of true west, reversing in the winter. The Sun rises south of true east in the summer for the southern temperate zone, and sets south of true west.
Above the Arctic Circle, an extreme case is reached where there is no daylight at all for part of the year, up to six months at the North Pole itself, a polar night. In the southern hemisphere the situation is exactly reversed, with the South Pole oriented opposite the direction of the North Pole. Six months later, this pole will experience a midnight sun, a day of 24 hours, again reversing with the South Pole.
By astronomical convention, the four seasons can be determined by the solstices â the points in the orbit of maximum axial tilt toward or away from the Sun â and the equinoxes, when the direction of the tilt and the direction to the Sun are perpendicular. In the northern hemisphere, winter solstice currently occurs around 21 December, summer solstice is near 21 June, spring equinox is around 20 March and autumnal equinox is about 22 or 23 September. In the southern hemisphere, the situation is reversed, with the summer and winter solstices exchanged and the spring and autumnal equinox dates swapped.
The angle of Earth's axial tilt is relatively stable over long periods of time. Its axial tilt does undergo nutation; a slight, irregular motion with a main period of 18.6Â years. The orientation (rather than the angle) of Earth's axis also changes over time, precessing around in a complete circle over each 25,800Â year cycle; this precession is the reason for the difference between a sidereal year and a tropical year. Both of these motions are caused by the varying attraction of the Sun and the Moon on Earth's equatorial bulge. The poles also migrate a few meters across Earth's surface. This polar motion has multiple, cyclical components, which collectively are termed quasiperiodic motion. In addition to an annual component to this motion, there is a 14-month cycle called the Chandler wobble. Earth's rotational velocity also varies in a phenomenon known as length-of-day variation.
In modern times, Earth's perihelion occurs around 3 January, and its aphelion around 4 July. These dates change over time due to precession and other orbital factors, which follow cyclical patterns known as Milankovitch cycles. The changing EarthâSun distance causes an increase of about 6.9% in solar energy reaching Earth at perihelion relative to aphelion. Because the southern hemisphere is tilted toward the Sun at about the same time that Earth reaches the closest approach to the Sun, the southern hemisphere receives slightly more energy from the Sun than does the northern over the course of a year. This effect is much less significant than the total energy change due to the axial tilt, and most of the excess energy is absorbed by the higher proportion of water in the southern hemisphere.
Habitability.
A planet that can sustain life is termed habitable, even if life did not originate there. Earth provides liquid waterâan environment where complex organic molecules can assemble and interact, and sufficient energy to sustain metabolism. The distance of Earth from the Sun, as well as its orbital eccentricity, rate of rotation, axial tilt, geological history, sustaining atmosphere and protective magnetic field all contribute to the current climatic conditions at the surface.
Biosphere.
A planet's life forms inhabit ecosystems, whose total is sometimes said to form a "biosphere". Earth's biosphere is thought to have begun evolving about . The biosphere is divided into a number of biomes, inhabited by broadly similar plants and animals. On land, biomes are separated primarily by differences in latitude, height above sea level and humidity. Terrestrial biomes lying within the Arctic or Antarctic Circles, at high altitudes or in extremely arid areas are relatively barren of plant and animal life; species diversity reaches a peak in humid lowlands at equatorial latitudes.
Natural resources and land use.
Earth has resources that have been exploited by humans. Those termed non-renewable resources, such as fossil fuels, only renew over geological timescales.
Large deposits of fossil fuels are obtained from Earth's crust, consisting of coal, petroleum, and natural gas. These deposits are used by humans both for energy production and as feedstock for chemical production. Mineral ore bodies have also been formed within the crust through a process of ore genesis, resulting from actions of magmatism, erosion and plate tectonics. These bodies form concentrated sources for many metals and other useful elements.
Earth's biosphere produces many useful biological products for humans, including food, wood, pharmaceuticals, oxygen, and the recycling of many organic wastes. The land-based ecosystem depends upon topsoil and fresh water, and the oceanic ecosystem depends upon dissolved nutrients washed down from the land. In 1980, 5,053Â Mha (50.53 million km) of Earth's land surface consisted of forest and woodlands, 6,788Â Mha (67.88 million km) was grasslands and pasture, and 1,501Â Mha (15.01 million km) was cultivated as croplands. The estimated amount of irrigated land in 1993 was . Humans also live on the land by using building materials to construct shelters.
Natural and environmental hazards.
Large areas of Earth's surface are subject to extreme weather such as tropical cyclones, hurricanes, or typhoons that dominate life in those areas. From 1980 to 2000, these events caused an average of 11,800 human deaths per year. Many places are subject to earthquakes, landslides, tsunamis, volcanic eruptions, tornadoes, sinkholes, blizzards, floods, droughts, wildfires, and other calamities and disasters.
Many localized areas are subject to human-made pollution of the air and water, acid rain and toxic substances, loss of vegetation (overgrazing, deforestation, desertification), loss of wildlife, species extinction, soil degradation, soil depletion and erosion.
According to the United Nations, a scientific consensus exists linking human activities to global warming due to industrial carbon dioxide emissions. This is predicted to produce changes such as the melting of glaciers and ice sheets, more extreme temperature ranges, significant changes in weather and a global rise in average sea levels.
Human geography.
Cartography, the study and practice of map-making, and geography, the study of the lands, features, inhabitants and phenomena on Earth, have historically been the disciplines devoted to depicting Earth. Surveying, the determination of locations and distances, and to a lesser extent navigation, the determination of position and direction, have developed alongside cartography and geography, providing and suitably quantifying the requisite information.
Earth's human population reached approximately seven billion on 31 October 2011. Projections indicate that the world's human population will reach 9.2Â billion in 2050. Most of the growth is expected to take place in developing nations. Human population density varies widely around the world, but a majority live in Asia. By 2020, 60% of the world's population is expected to be living in urban, rather than rural, areas.
It is estimated that one-eighth of Earth's surface is suitable for humans to live onÂ â three-quarters of Earth's surface is covered by oceans, leaving one quarter as land. Half of that land area is desert (14%), high mountains (27%), or other unsuitable terrain. The northernmost permanent settlement in the world is Alert, on Ellesmere Island in Nunavut, Canada. (82Â°28â²N) The southernmost is the AmundsenâScott South Pole Station, in Antarctica, almost exactly at the South Pole. (90Â°S)
Independent sovereign nations claim the planet's entire land surface, except for some parts of Antarctica, a few land parcels along the Danube river's western bank, and the odd unclaimed area of Bir Tawil between Egypt and Sudan. , there are 193 sovereign states that are member states of the United Nations, plus two observer states and 72 dependent territories and states with limited recognition. Historically, Earth has never had a sovereign government with authority over the entire globe although a number of nation-states have striven for world domination and failed.
The United Nations is a worldwide intergovernmental organization that was created with the goal of intervening in the disputes between nations, thereby avoiding armed conflict. The U.N. serves primarily as a forum for international diplomacy and international law. When the consensus of the membership permits, it provides a mechanism for armed intervention.
The first human to orbit Earth was Yuri Gagarin on 12 April 1961. In total, about 487 people have visited outer space and reached orbit , and, of these, twelve have walked on the Moon. Normally, the only humans in space are those on the International Space Station. The station's crew, made up of six people, is usually replaced every six months. The farthest that humans have travelled from Earth is 400,171Â km, achieved during the Apollo 13 mission in 1970.
Moon.
The Moon is a relatively large, terrestrial, planet-like natural satellite, with a diameter about one-quarter of Earth's. It is the largest moon in the Solar System relative to the size of its planet, although Charon is larger relative to the dwarf planet Pluto. The natural satellites of other planets are also referred to as "moons", after Earth's.
The gravitational attraction between Earth and the Moon causes tides on Earth. The same effect on the Moon has led to its tidal locking: its rotation period is the same as the time it takes to orbit Earth. As a result, it always presents the same face to the planet. As the Moon orbits Earth, different parts of its face are illuminated by the Sun, leading to the lunar phases; the dark part of the face is separated from the light part by the solar terminator.
Due to their tidal interaction, the Moon recedes from Earth at the rate of approximately 38Â mm/yr. Over millions of years, these tiny modificationsâand the lengthening of Earth's day by about 23Â Âµs/yrâadd up to significant changes. During the Devonian period, for example, (approximately ) there were 400 days in a year, with each day lasting 21.8 hours.
The Moon may have dramatically affected the development of life by moderating the planet's climate. Paleontological evidence and computer simulations show that Earth's axial tilt is stabilized by tidal interactions with the Moon. Some theorists think that without this stabilization against the torques applied by the Sun and planets to Earth's equatorial bulge, the rotational axis might be chaotically unstable, exhibiting chaotic changes over millions of years, as appears to be the case for Mars.
Viewed from Earth, the Moon is just far enough away to have almost the same apparent-sized disk as the Sun. The angular size (or solid angle) of these two bodies match because, although the Sun's diameter is about 400 times as large as the Moon's, it is also 400 times more distant. This allows total and annular solar eclipses to occur on Earth.
The most widely accepted theory of the Moon's origin, the giant impact theory, states that it formed from the collision of a Mars-size protoplanet called Theia with the early Earth. This hypothesis explains (among other things) the Moon's relative lack of iron and volatile elements, and the fact that its composition is nearly identical to that of Earth's crust.
Asteroids and artificial satellites.
Earth has at least five co-orbital asteroids, including 3753 Cruithne and . A trojan asteroid companion, , is librating around the leading Lagrange triangular point, L4, in the Earth's orbit around the Sun.
The tiny near-Earth asteroid makes close approaches to the EarthâMoon system roughly every twenty years. During these approaches, it can orbit Earth for brief periods of time.
, there were 1,305 operational, human-made satellites orbiting Earth. There are also inoperative satellites, including Vanguard 1 the oldest satellite currently in orbit, and over 300,000 pieces of space debris. Earth's largest artificial satellite is the International Space Station.
Cultural and historical viewpoint.
The standard astronomical symbol of Earth consists of a cross circumscribed by a circle, , representing the four quadrants of the world.
Human cultures have developed many views of the planet. Earth is sometimes personified as a deity. In many cultures it is a mother goddess that is also the primary fertility deity, and by the mid-20th century the Gaia Principle compared Earth's environments and life as a single self-regulating organism leading to broad stabilization of the conditions of habitability. Creation myths in many religions involve the creation of Earth by a supernatural deity or deities.
Scientific investigation has resulted in several culturally transformative shifts in our view of the planet. In the West, belief in a flat Earth was displaced by the idea of spherical Earth, credited to Pythagoras in the 6th century BC. Earth was further believed to be the center of the universe until the 16th century, when scientists first theorized that it was a moving object, comparable to the other planets in the Solar System. Due to the efforts of influential Christian scholars and clerics such as James Ussher, who sought to determine the age of Earth through analysis of genealogies in Scripture, Westerners prior to the 19th century generally believed Earth to be a few thousand years old at most. It was only during the 19th century that geologists realized Earth's age was at least many millions of years. Lord Kelvin used thermodynamics to estimate the age of Earth to be between 20 million and 400 million years in 1864, sparking a vigorous debate on the subject; it was only when radioactivity and radioactive dating were discovered in the late 19th and early 20th centuries that a reliable mechanism for determining Earth's age was established, proving the planet to be billions of years old. The perception of Earth shifted again in the 20th century when humans first viewed it from orbit, and especially with photographs of Earth returned by the Apollo program.
Notes.
</math>, where "m" is the mass of Earth, "a" is an astronomical unit, and "M" is the mass of the Sun. So the radius in AU is about formula_1.</ref>

</doc>
<doc id="9230" url="https://en.wikipedia.org/wiki?curid=9230" title="English Channel">
English Channel

The English Channel (, "the Sleeve"; , "Sea of Brittany"; , "British Sea"), also called simply the Channel, is the body of water that separates southern England from northern France, and joins the southern part of the North Sea to the rest of the Atlantic Ocean. The name "English Channel" is mostly used in English.
It is about long and varies in width from at its widest to in the Strait of Dover. It is the smallest of the shallow seas around the continental shelf of Europe, covering an area of some .
Geography.
The International Hydrographic Organization defines the limits of the English Channel as follows:
The IHO defines the southwestern limit of the North Sea as "a line joining the Walde Lighthouse (France, 1Â°55'E) and Leathercoat Point (England, 51Â°10'N)". The Walde Lighthouse is 6Â km east of Calais (), and Leathercoat Point is at the north end of St Margaret's Bay, Kent ().
The Strait of Dover (French: "Pas de Calais"), at the Channel's eastern end is its narrowest point, while its widest point lies between Lyme Bay and the Gulf of Saint Malo near its midpoint. It is relatively shallow, with an average depth of about at its widest part, reducing to a depth of about between Dover and Calais. Eastwards from there the adjoining North Sea reduces to about in the Broad Fourteens where it lies over the watershed of the former land bridge between East Anglia and the Low Countries. It reaches a maximum depth of in the submerged valley of Hurd's Deep, west-northwest of Guernsey.
The eastern region along the French coast between Cherbourg and the mouth of the Seine river at Le Havre is frequently referred to as the "Bay of the Seine ()".
There are several major islands in the Channel, the most notable being the Isle of Wight off the English coast, and the Channel Islands, British Crown Dependencies off the coast of France. The coastline, particularly on the French shore, is deeply indented; several small islands close to the coastline, including Chausey and Mont Saint-Michel, are within French jurisdiction. The Cotentin Peninsula in France juts out into the Channel, whilst on the English side there is a small parallel channel known as the Solent between the Isle of Wight and the mainland. The Celtic Sea is to the west of the Channel.
The Channel is of geologically recent origins, having been dry land for most of the Pleistocene period. It is thought to have been created between 450,000 and 180,000Â years ago by two catastrophic glacial lake outburst floods caused by the breaching of the WealdâArtois anticline, a ridge that held back a large proglacial lake in the Doggerland region, now submerged under the North Sea. The flood would have lasted for several months, releasing as much as one million cubic metres of water per second. The cause of the breach is not known but may have been an earthquake or the build-up of water pressure in the lake. The flood carved a large bedrock-floored valley down the length of the Channel, leaving behind streamlined islands and longitudinal erosional grooves characteristic of catastrophic megaflood events. It destroyed the isthmus that connected Britain to continental Europe, although a land bridge across the southern North Sea would have existed intermittently at later times after periods of glaciation resulted in lowering of sea levels.
The Channel acts as a funnel that amplifies the tidal range from less than a metre as observed at sea to more than 6 metres as observed in the Channel Islands, the west coast of the Cotentin Peninsula and the north cost of Britanny. The time difference of about 6 hours between high water at the eastern and western limits of the Channel are indicative of the tidal range being amplified further by resonance.
For the UK Shipping Forecast the Channel is divided into the following areas, from the west:
Name.
The name "English Channel" has been widely used since the early 18th century, possibly originating from the designation in Dutch sea maps from the 16th century onwards. In modern Dutch, however, it is known as (with no reference to the word "English"). Later, it has also been known as the "British Channel" or the "British Sea" having been called the by the 2nd-century geographer Ptolemy. The same name is used on an Italian map of about 1450, which gives the alternative name of âpossibly the first recorded use of the "Channel" designation. The Anglo-Saxon texts often call it "SÅ«Ã°-sÇ£" ("South Sea") as opposed to "NorÃ°-sÇ£" ("North Sea" = Bristol Channel). The word "channel" was first recorded in Middle English in the 13th century and was borowed from Old French "chanel", variant form of "chenel" "canal".
The French name has been in use since at least the 17th century. The name is usually said to refer to the Channel's sleeve () shape. However, it is sometimes claimed to derive from a Celtic word meaning "channel" that is also the source of the name for the Minch in Scotland.
In Spain and most Spanish-speaking countries the Channel is referred to as . In Portuguese it is known as . This is not a translation from French: in Portuguese and Spanish, means "stain", while the word for sleeve is â which suggests either a phonetic borrowing from French or a common source. Other languages also use this name, such as Greek () and Italian (). The German name is , literally "sleeve-channel", or more generally .
The name in Breton ("Mor Breizh") means "Breton Sea", and its Cornish name ("Mor Bretannek") means "British Sea".
History.
Before the Devensian glaciation (the most recent ice age that ended around 10,000 years ago), Britain and Ireland were part of continental Europe, linked by an unbroken Weald-Artois Anticline, which acted as a natural dam that held back a large freshwater pro-glacial lake in the Doggerland region, now submerged under the North Sea. During this period the North Sea and almost all of the British Isles were covered with ice. The lake was fed by meltwater from the Baltic and from the Caledonian and Scandinavian ice sheets that joined to the north, blocking its exit. The sea level was about lower than it is today. Then, more than 200,000 years ago a single catastrophic glacial lake outburst flood overtopped the Weald-Artois Anticline and scoured a channel through an expanse of low-lying tundra, right down to the underlying chalk bedrock. In a study published in 2007 high-resolution sonar revealed the unexpectedly well-preserved scourmarks and the telltale lenticular island forms characteristic of torrential flood. Through the scoured channel passed a river which now drained the combined Rhine and Thames towards the Atlantic to the west. As the ice sheet melted, a large freshwater lake formed in the southern part of what is now the North Sea. As the meltwater could still not escape to the north (as the northern North Sea was still frozen) the outflow channel from the lake entered the Atlantic Ocean in the region of Dover and Calais.
The Channel, which delayed human reoccupation of Great Britain for more than 100,000 years, has in historic times been both an easy entry for seafaring people and a key natural defence, halting invading armies while in conjunction with control of the North Sea allowing Britain to blockade the continent. The most significant failed invasion threats came when the Dutch and Belgian ports were held by a major continental power, e.g. from the Spanish Armada in 1588, Napoleon during the Napoleonic Wars, and Nazi Germany during World War II. Successful invasions include the Roman conquest of Britain, the Norman Conquest in 1066 and the invasion by the Dutch in 1688, while the concentration of excellent harbours in the Western Channel on Britain's south coast made possible the largest invasion of all time, the Normandy Landings in 1944. Channel naval battles include the Battle of the Downs (1639), Battle of Goodwin Sands (1652), the Battle of Portland (1653), the Battle of La Hougue (1692) and the engagement between USS "Kearsarge" and CSS "Alabama" (1864).
In more peaceful times the Channel served as a link joining shared cultures and political structures, particularly the huge Angevin Empire from 1135 to 1217. For nearly a thousand years, the Channel also provided a link between the Modern Celtic regions and languages of Cornwall and Brittany. Brittany was founded by Britons who fled Cornwall and Devon after Anglo-Saxon encroachment. In Brittany, there is a region known as "Cornouaille" (Cornwall) in French and "Kernev" in Breton In ancient times there was also a "Domnonia" (Devon) in Brittany as well.
In February 1684, ice formed on the sea in a belt wide off the coast of Kent and wide on the French side.
Route to the British Isles.
Remnants of a mesolithic boatyard have been found on the Isle of Wight. Wheat was traded across the Channel about 8,000 years ago. "... Sophisticated social networks linked the Neolithic front in southern Europe to the Mesolithic peoples of northern Europe." The Ferriby Boats, Hanson Log Boats and the later Dover Bronze Age Boat could carry a substantial cross-Channel cargo.
Diodorus Siculus and Pliny both suggest trade between the rebel Celtic tribes of Armorica and Iron Age Britain flourished. In 55 BC Julius Caesar invaded, claiming that the Britons had aided the Veneti against him the previous year. He was more successful in 54 BC, but Britain was not fully established as part of the Roman Empire until completion of the invasion by Aulus Plautius in 43 AD. A brisk and regular trade began between ports in Roman Gaul and those in Britain. This traffic continued until the end of Roman rule in Britain in 410 AD, after which the early Anglo-Saxons left less clear historical records.
In the power vacuum left by the retreating Romans, the Germanic Angles, Saxons, and Jutes began the next great migration across the North Sea. Having already been used as mercenaries in Britain by the Romans, many people from these tribes crossed during the Migration Period, conquering and perhaps displacing the native Celtic populations.
Norsemen and Normans.
The attack on Lindisfarne in 793 is generally considered the beginning of the Viking Age. For the next 250Â years the Scandinavian raiders of Norway, Sweden, and Denmark dominated the North Sea, raiding monasteries, homes, and towns along the coast and along the rivers that ran inland. According to the "Anglo-Saxon Chronicle" they began to settle in Britain in 851. They continued to settle in the British Isles and the continent until around 1050.
The fiefdom of Normandy was created for the Viking leader Rollo (also known as Robert of Normandy). Rollo had besieged Paris but in 911 entered vassalage to the king of the West Franks Charles the Simple through the Treaty of St.-Claire-sur-Epte. In exchange for his homage and fealty, Rollo legally gained the territory he and his Viking allies had previously conquered. The name "Normandy" reflects Rollo's Viking (i.e. "Northman") origins.
The descendants of Rollo and his followers adopted the local Gallo-Romance language and intermarried with the area's inhabitants and became the Normans â a Norman French-speaking mixture of Scandinavians, Hiberno-Norse, Orcadians, Anglo-Danish, and indigenous Franks and Gauls.
Rollo's descendant William, Duke of Normandy became king of England in 1066 in the Norman Conquest beginning with the Battle of Hastings, while retaining the fiefdom of Normandy for himself and his descendants. In 1204, during the reign of King John, mainland Normandy was taken from England by France under Philip II, while insular Normandy (the Channel Islands) remained under English control. In 1259, Henry III of England recognised the legality of French possession of mainland Normandy under the Treaty of Paris. His successors, however, often fought to regain control of mainland Normandy.
With the rise of William the Conqueror the North Sea and Channel began to lose some of their importance. The new order oriented most of England and Scandinavia's trade south, toward the Mediterranean and the Orient.
Although the British surrendered claims to mainland Normandy and other French possessions in 1801, the monarch of the United Kingdom retains the title Duke of Normandy in respect to the Channel Islands. The Channel Islands (except for Chausey) are Crown dependencies of the British Crown. Thus the Loyal toast in the Channel Islands is "La Reine, notre Duc" ("The Queen, our Duke"). The British monarch is understood to "not" be the Duke of Normandy in regards of the French region of Normandy described herein, by virtue of the Treaty of Paris of 1259, the surrender of French possessions in 1801, and the belief that the rights of succession to that title are subject to Salic Law which excludes inheritance through female heirs.
French Normandy was occupied by English forces during the Hundred Years' War in 1346â1360 and again in 1415â1450.
England and Britain: Naval superpower.
From the reign of Elizabeth I, English foreign policy concentrated on preventing invasion across the Channel by ensuring no major European power controlled the potential Dutch and Flemish invasion ports. Her climb to the pre-eminent sea power of the world began in 1588 as the attempted invasion of the Spanish Armada was defeated by the combination of outstanding naval tactics by the English and the Dutch under command of Charles Howard, 1st Earl of Nottingham with Sir Francis Drake second in command, and the following stormy weather. Over the centuries the Royal Navy slowly grew to be the most powerful in the world.
The building of the British Empire was possible only because the Royal Navy eventually managed to exercise unquestioned control over the seas around Europe, especially the Channel and the North Sea. During the Seven Years' War, France attempted to launch an invasion of Britain. To achieve this France needed to gain control of the Channel for several weeks, but was thwarted following the British naval victory at the Battle of Quiberon Bay in 1759.
Another significant challenge to British domination of the seas came during the Napoleonic Wars. The Battle of Trafalgar took place off the coast of Spain against a combined French and Spanish fleet and was won by Admiral Horatio Nelson, ending Napoleon's plans for a cross-Channel invasion and securing British dominance of the seas for over a century.
First World War.
The exceptional strategic importance of the Channel as a tool for blockade was recognised by the First Sea Lord Admiral Fisher in the years before World War I. "Five keys lock up the world! Singapore, the Cape, Alexandria, Gibraltar, Dover." However, on 25 July 1909 Louis BlÃ©riot successfully made the first Channel crossing from Calais to Dover in an aeroplane. BlÃ©riot's crossing signalled the end of the Channel as a barrier-moat for England against foreign enemies.
Because the Kaiserliche Marine surface fleet could not match the British Grand Fleet, the Germans developed submarine warfare, which was to become a far greater threat to Britain. The Dover Patrol was set up just before war started to escort cross-Channel troopships and to prevent submarines from accessing the Channel, thereby obliging them to travel to the Atlantic via the much longer route around Scotland.
On land, the German army attempted to capture Channel ports (see "Race to the Sea"), but although the trenches are often said to have stretched "from the frontier of Switzerland to the English Channel", they reached the coast at the North Sea. Much of the British war effort in Flanders was a bloody but successful strategy to prevent the Germans reaching the Channel coast.
At the outset of the war, an attempt was made to block the path of U-boats through the Dover Strait with naval minefields. By February 1915, this had been augmented by a 25 kilometre stretch of light steel netting called the Dover Barrage, which it was hoped would ensnare submerged submarines. After initial success, the Germans learned how to pass through the barrage, aided by the unreliability of British mines. 31 January 1917, the Germans restarted unrestricted submarine warfare leading to dire Admiralty predictions that submarines would defeat Britain by November, the most dangerous situation Britain faced in either World War.
The Battle of Passchendaele in 1917 was fought to reduce the threat by capturing the submarine bases on the Belgian coast, though it was the introduction of convoys and not capture of the bases that averted defeat. In April 1918 the Dover Patrol carried out the famous Zeebrugge Raid against the U-boat bases. During 1917, the Dover Barrage was re-sited with improved mines and more effective nets, aided by regular patrols by small warships equipped with powerful searchlights. A German attack on these vessels resulted in the Battle of Dover Strait in 1917. A much more ambitious attempt to improve the barrage by installing eight massive concrete towers across the strait was called the Admiralty MâN Scheme, but only two towers were nearing completion at the end of the war and the project was abandoned.
The naval blockade in the Channel and North Sea was one of the decisive factors in the German defeat in 1918.
Second World War.
During the Second World War, naval activity in the European theatre was primarily limited to the Atlantic. During the Battle of France in May 1940, the Germans succeeded in capturing both Boulogne and Calais, thereby threatening the line of retreat for the British Expeditionary Force. By a combination of hard fighting and German indecision, the port of Dunkirk was kept open allowing 338,000 Allied troops to be evacuated in Operation Dynamo. More than 11,000 were evacuated from Le Havre during Operation Cycle and a further 192,000 were evacuated from ports further down the coast in Operation Ariel in June 1940. The early stages of the Battle of Britain featured air attacks on Channel shipping and ports, and until the Normandy Landings (with the exception of the Channel Dash) the narrow waters were too dangerous for major warships. Despite these early successes against shipping, the Germans did not win the air supremacy necessary for Operation Sealion, the projected cross-Channel invasion.
The Channel subsequently became the stage for an intensive coastal war, featuring submarines, minesweepers, and Fast Attack Craft.
Dieppe was the site of an ill-fated raid by Canadian and British armed forces. More successful was the later Operation Overlord (D-Day), a massive invasion of German-occupied France by Allied troops. Caen, Cherbourg, Carentan, Falaise and other Norman towns endured many casualties in the fight for the province, which continued until the closing of the so-called Falaise gap between Chambois and Montormel, then liberation of Le Havre.
The Channel Islands were the only part of the British Commonwealth occupied by Germany (excepting the part of Egypt occupied by the Afrika Korps at the time of the Second Battle of El Alamein, which was a protectorate and not part of the Commonwealth). The German occupation of 1940â1945 was harsh, with some island residents being taken for slave labour on the Continent; native Jews sent to concentration camps; partisan resistance and retribution; accusations of collaboration; and slave labour (primarily Russians and eastern Europeans) being brought to the islands to build fortifications. The Royal Navy blockaded the islands from time to time, particularly following the liberation of mainland Normandy in 1944. Intense negotiations resulted in some Red Cross humanitarian aid, but there was considerable hunger and privation during the occupation, particularly in the final months, when the population was close to starvation. The German troops on the islands surrendered on 9 May 1945, a few days after the final surrender in mainland Europe.
Population.
The English Channel is far more densely populated on the English shore. The most significant towns and cities along both the English and French sides of the Channel (each with more than 20,000 inhabitants, ranked in descending order; populations are the urban area populations from the 1999 French census, 2001 UK census, and 2001 Jersey census) are as follows:
Shipping.
The Channel has traffic on both the UK-Europe and North Sea-Atlantic routes, and is the world's busiest seaway, with over 500 ships per day. Following an accident in January 1971 and a series of disastrous collisions with wreckage in February, the Dover TSS the world's first radar-controlled Traffic Separation Scheme was set up by the International Maritime Organization. The scheme mandates that vessels travelling north must use the French side, travelling south the English side. There is a separation zone between the two lanes.
In December 2002 the MV "Tricolor", carrying Â£30m of luxury cars sank northwest of Dunkirk after collision in fog with the container ship "Kariba". The cargo ship "Nicola" ran into the wreckage the next day. There was no loss of life.
The shore-based long range traffic control system was updated in 2003 and there is a series of Traffic Separation Systems in operation. Though the system is inherently incapable of reaching the levels of safety obtained from aviation systems such as the Traffic Collision Avoidance System, it has reduced accidents to one or two per year.
Marine GPS systems allow ships to be preprogrammed to follow navigational channels accurately and automatically, further avoiding risk of running aground, but following the fatal collision between Dutch Aquamarine and Ash in October 2001, Britain's Marine Accident Investigation Branch (MAIB) issued a safety bulletin saying it believed that in these most unusual circumstances GPS use had actually contributed to the collision. The ships were maintaining a very precise automated course, one directly behind the other, rather than making use of the full width of the traffic lanes as a human navigator would.
A combination of radar difficulties in monitoring areas near cliffs, a failure of a CCTV system, incorrect operation of the anchor, the inability of the crew to follow standard procedures of using a GPS to provide early warning of the ship dragging the anchor and reluctance to admit the mistake and start the engine led to the MV "Willy" running aground in Cawsand bay, Cornwall in January 2002. The MAIB report makes it clear that the harbour controllers were informed of impending disaster by shore observers before the crew were themselves aware. The village of Kingsand was evacuated for three days because of the risk of explosion, and the ship was stranded for 11 days.
Ecology.
As a busy shipping lane, the Channel experiences environmental problems following accidents involving ships with toxic cargo and oil spills. Indeed, over 40% of the UK incidents threatening pollution occur in or very near the Channel. One of the recent occurrences was the MSC "Napoli", which on 18 January 2007 was beached with nearly 1700Â tonnes of dangerous cargo in Lyme Bay, a protected World Heritage Site coastline. The ship had been damaged and was en route to Portland Harbour.
Transport.
Ferry.
The number of ferry routes crossing the Strait of Dover has reduced since the Channel Tunnel opened. Current cross-channel ferry routes are:
Channel Tunnel.
Many travellers cross beneath the Channel using the Channel Tunnel, first proposed in the early 19th century and finally opened in 1994, connecting the UK and France by rail. It is now routine to travel between Paris or Brussels and London on the Eurostar train. Cars can also be carried on special trains between Folkestone and Calais.
Economy.
Tourism.
The coastal resorts of the Channel, such as Brighton and Deauville, inaugurated an era of aristocratic tourism in the early 19th century, which developed into the seaside tourism that has shaped resorts around the world. Short trips across the Channel for leisure purposes are often referred to as Channel Hopping.
Culture and languages.
The two dominant cultures are English on the north shore of the Channel, French on the south. However, there are also a number of minority languages that are or were found on the shores and islands of the English Channel, which are listed here, with the Channel's name following them.
Dutch previously had a larger range, and extended into parts of modern-day France. For more information, please see French Flemish.
Most other languages tend towards variants of the French and English forms, but notably Welsh has "MÃ´r Udd".
Channel crossings.
As one of the narrowest and most well-known international waterways lacking dangerous currents, the Channel has been the first objective of numerous innovative sea, air, and human powered crossing technologies.
Pre-historic people sailed from the mainland to England for millennia. At the end of the last Ice Age, lower sea levels even permitted walking across.
By boat.
Pierre Andriel crossed the English Channel aboard the "Ãlise", ex the Scottish p.s. "Margery" in March 1816, one of the earliest seagoing voyages by steam ship.
The paddle steamer "Defiance", Captain William Wager, was the first steamer to cross the Channel to Holland, arriving there on 9 May 1816.
On 10 June 1821, English-built paddle steamer "Rob Roy" was the first passenger ferry to cross channel. The steamer was purchased subsequently by the French postal administration and renamed "Henri IV" and put into regular passenger service a year later. It was able to make the journey across the Straits of Dover in around three hours.
In June 1843, because of difficulties with Dover harbour, the South Eastern Railway company developed the Boulogne-sur-Mer-Folkestone route as an alternative to Calais-Dover. The first ferry crossed under the command of Captain Hayward.
In 1974 a Welsh coracle piloted by Bernard Thomas of Llechryd crossed the English Channel to France in 13Â½ hours. The journey was undertaken to demonstrate how the Bull Boats of the Mandan Indians of North Dakota could have been copied from coracles introduced by Prince Madog in the 12th century.
The Mountbatten class hovercraft (MCH) entered commercial service in August 1968, initially between Dover and Boulogne but later also Ramsgate (Pegwell Bay) to Calais. The journey time Dover to Boulogne was roughly 35Â minutes, with six trips per day at peak times. The fastest crossing of the English Channel by a commercial car-carrying hovercraft was 22Â minutes, recorded by the "Princess Anne" MCH SR-N4 Mk3 on 14 September 1995,
By air.
The first aircraft to cross the Channel was a balloon in 1785, piloted by Jean Pierre FranÃ§ois Blanchard (France) and John Jeffries (US).
Louis BlÃ©riot (France) piloted the first airplane to cross in 1909.
By swimming.
The sport of Channel swimming traces its origins to the latter part of the 19th century when Captain Matthew Webb made the first observed and unassisted swim across the Strait of Dover, swimming from England to France on 24â25 August 1875 in 21Â hours 45Â minutes.
In 1927, at a time when fewer than ten swimmers (including the first woman, Gertrude Ederle in 1926) had managed to emulate the feat and many dubious claims were being made, the Channel Swimming Association (CSA) was founded to authenticate and ratify swimmers' claims to have swum the Channel and to verify crossing times. The CSA was dissolved in 1999 and was succeeded by two separate organisations: CSA (Ltd) and the Channel Swimming and Piloting Federation (CSPF). Both observe and authenticate cross-Channel swims in the Strait of Dover. The Channel Crossing Association was set up at about this time to cater for unorthodox crossings.
The team with the most number of Channel swims to its credit is the Serpentine Swimming Club in London, followed by the International Sri Chinmoy Marathon Team.
By the end of 2005, 811 people had completed 1,185 verified crossings under the rules of the CSA, the CSA (Ltd), the CSPF and Butlins.
The number of swims conducted under and ratified by the Channel Swimming Association to 2005 was 982 by 665 people. This includes 24 two-way crossings and three three-way crossings.
The number of ratified swims to 2004 was 948 by 675 people (456 men, 214 women). There have been 16 two-way crossings (9 by men and 7 by women). There have been three three-way crossings (2 by men and 1 by a woman). (It is unclear whether this last set of data is comprehensive or CSA only.)
The Strait of Dover is the busiest stretch of water in the world. It is governed by International Law as described in "Unorthodox Crossing of the Dover Strait Traffic Separation Scheme". It states: " exceptional cases the French Maritime Authorities may grant authority for unorthodox craft to cross French territorial waters within the Traffic Separation Scheme when these craft set off from the British coast, on condition that the request for authorisation is sent to them with the opinion of the British Maritime Authorities."
The CCA, CSA, and CS&PF are the organisations escorting channel swims, because their pilots have the experience, qualifications, and equipment to guarantee the safety of the swimmers they escort.
The fastest verified swim of the Channel was by the Australian Trent Grimsey on 8 September 2012, in 6 hours 55 minutes, beating the previous record set in 2007 by Bulgarian swimmer Petar Stoychev.
There may have been some unreported swims of the Channel, by people intent on entering Britain in circumvention of immigration controls. A failed attempt to cross the Channel by two Syrian refugees in October 2014 only came to light when their bodies were later discovered on the shores of the North Sea in Norway and the Netherlands.
By car.
On 16 September 1965, two Amphicars crossed from Dover to Calais. One was crewed by two British Army officers, Captain Mike Bailey REME and Captain Peter Tappenden RAOC, the other by Tim Dill-Russell and Sgt Joe Minto RASC. The crossing took 7 hours 20 minutes, with mid-Channel wind conditions reaching force 5 on the Beaufort scale. The cars went on to the Frankfurt Motor Show that year, where they were put on display.
In 2007, the presenters of the BBC programme "Top Gear" (Jeremy Clarkson, Richard Hammond and James May) "drove" across the Channel from England to France. They did it by designing "amphibious cars" that could be driven on land and also operate in water.
After four attempts â twice failing to leave Dover Harbour â they reached the coast of France in a Nissan pick-up with an outboard motor and oil drums attached to the back to aid stability in open water. The other two vehicles that attempted the crossing (a Triumph Herald with a sail and a Volkswagen Campervan with a propeller attached to the flywheel) both sank. Clarkson believed it might be possible to break the world record for crossing the Channel in this manner, but the team was unsuccessful. The "Daily Mail" claimed that the BBC received criticism from a coastguard who claimed that they had not been told that the stunt was going to take place, and allegedly branded it "completely irresponsible"; however this was not reported by any other media sources and the aired episode showed the full co-operation of the coastguard.

</doc>
<doc id="9232" url="https://en.wikipedia.org/wiki?curid=9232" title="Eiffel Tower">
Eiffel Tower

The Eiffel Tower ( ; ) is a wrought iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower. Constructed in 1889 as the entrance to the 1889 World's Fair, it was initially criticized by some of France's leading artists and intellectuals for its design, but has become a global cultural icon of France and one of the most recognisable structures in the world. The tower is the tallest structure in Paris and the most-visited paid monument in the world: 6.98 million people ascended it in 2011. The tower received its 250 millionth visitor in 2010.
The tower is tall, about the same height as an 81- building. Its base is square, on a side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was built in 1930. Due to the addition of the aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by . Not including broadcast aerials, it is the second-tallest structure in France, after the Millau Viaduct.
The tower has three levels for visitors, with restaurants on the first and second. The top level's upper platform is above the ground, the highest accessible to the public in the European Union. Tickets can be purchased to ascend by stairs or lift (elevator) to the first and second levels. The climb from ground level to the first level is over 300 steps, as is the climb from the first level to the second. Although there is a staircase to the top level, it is usually only accessible by lift.
History.
Origin.
The design of the Eiffel Tower was the product of Maurice Koechlin and Ãmile Nouguier, two senior engineers working for the Compagnie des Ãtablissements Eiffel, after discussion about a suitable centrepiece for the proposed 1889 Exposition Universelle, a world's fair to celebrate the centennial of the French Revolution. Eiffel openly acknowledged that inspiration for a tower came from the Latting Observatory built in New York City in 1853. In May 1884, working at home, Koechlin made a sketch of their idea, described by him as "a great pylon, consisting of four lattice girders standing apart at the base and coming together at the top, joined together by metal trusses at regular intervals". Eiffel initially showed little enthusiasm, but he did approve further study, and the two engineers then asked Stephen Sauvestre, the head of company's architectural department, to contribute to the design. Sauvestre added decorative arches to the base of the tower, a glass pavilion to the first level, and other embellishments.
The new version gained Eiffel's support: he bought the rights to the patent on the design which Koechlin, Nougier, and Sauvestre had taken out, and the design was exhibited at the Exhibition of Decorative Arts in the autumn of 1884 under the company name. On 30 March 1885, Eiffel presented his plans to the ; after discussing the technical problems and emphasising the practical uses of the tower, he finished his talk by saying the tower would symbolise, 
Little progress was made until 1886, when Jules GrÃ©vy was re-elected as president of France and Ãdouard Lockroy was appointed as minister for trade. A budget for the exposition was passed and, on 1 May, Lockroy announced an alteration to the terms of the open competition being held for a centerpiece to the exposition, which effectively made the selection of Eiffel's design a foregone conclusion, as entries had to include a study for a 300Â m (980Â ft) four-sided metal tower on the Champ de Mars. On 12 May, a commission was set up to examine Eiffel's scheme and its rivals, which, a month later, decided that all the proposals except Eiffel's were either impractical or lacking in details.
After some debate about the exact location of the tower, a contract was signed on 8 January 1887. This was signed by Eiffel acting in his own capacity rather than as the representative of his company, and granted him 1.5 million francs toward the construction costs: less than a quarter of the estimated 6.5 million francs. Eiffel was to receive all income from the commercial exploitation of the tower during the exhibition and for the next 20 years. He later established a separate company to manage the tower, putting up half the necessary capital himself.
The artists' protest.
The proposed tower had been a subject of controversy, drawing criticism from those who did not believe it was feasible and those who objected on artistic grounds. These objections were an expression of a long-standing debate in France about the relationship between architecture and engineering. It came to a head as work began at the Champ de Mars: a "Committee of Three Hundred" (one member for each metre of the tower's height) was formed, led by the prominent architect Charles Garnier and including some of the most important figures of the arts, such as Adolphe Bouguereau, Guy de Maupassant, Charles Gounod and Jules Massenet. A petition called "Artists against the Eiffel Tower" was sent to the Minister of Works and Commissioner for the Exposition, Charles Alphand, and it was published by "Le Temps" on 14 February 1887.
Gustave Eiffel responded to these criticisms by comparing his tower to the Egyptian pyramids: "My tower will be the tallest edifice ever erected by man. Will it not also be grandiose in its way? And why would something admirable in Egypt become hideous and ridiculous in Paris?" These criticisms were also dealt with by Ãdouard Lockroy in a letter of support written to Alphand, ironically saying, "Judging by the stately swell of the rhythms, the beauty of the metaphors, the elegance of its delicate and precise style, one can tell this protest is the result of collaboration of the most famous writers and poets of our time", and he explained that the protest was irrelevant since the project had been decided upon months before, and construction on the tower was already under way.
Indeed, Garnier was a member of the Tower Commission that had examined the various proposals, and had raised no objection. Eiffel was similarly unworried, pointing out to a journalist that it was premature to judge the effect of the tower solely on the basis of the drawings, that the Champ de Mars was distant enough from the monuments mentioned in the protest for there to be little risk of the tower overwhelming them, and putting the aesthetic argument for the tower: "Do not the laws of natural forces always conform to the secret laws of harmony?"
Some of the protesters changed their minds when the tower was built; others remained unconvinced. Guy de Maupassant supposedly ate lunch in the tower's restaurant every day because it was the one place in Paris where the tower was not visible.
By 1918, it had become a symbol of Paris and of France after Guillaume Apollinaire wrote a nationalist poem in the shape of the tower (a calligram) to express his feelings about the war against Germany. Today, it is widely considered to be a remarkable piece of structural art, and is often featured in films and literature.
Construction.
Work on the foundations started on 28 January 1887. Those for the east and south legs were straightforward, with each leg resting on four concrete slabs, one for each of the principal girders of each leg. The west and north legs, being closer to the river Seine, were more complicated: each slab needed two piles installed by using compressed-air caissons long and in diameter driven to a depth of to support the concrete slabs, which were thick. Each of these slabs supported a block of limestone with an inclined top to bear a supporting shoe for the ironwork.
Each shoe was anchored to the stonework by a pair of bolts 10Â cm (4Â in) in diameter and long. The foundations were completed on 30 June, and the erection of the ironwork began. The visible work on-site was complemented by the enormous amount of exacting preparatory work that took place behind the scenes: the drawing office produced 1,700 general drawings and 3,629 detailed drawings of the 18,038 different parts needed. The task of drawing the components was complicated by the complex angles involved in the design and the degree of precision required: the position of rivet holes was specified to within 0.1Â mm (0.004Â in) and angles worked out to one second of arc. The finished components, some already riveted together into sub-assemblies, arrived on horse-drawn carts from a factory in the nearby Parisian suburb of Levallois-Perret and were first bolted together, with the bolts being replaced with rivets as construction progressed. No drilling or shaping was done on site: if any part did not fit, it was sent back to the factory for alteration. In all, 18,038 pieces were joined together using 2.5Â million rivets.
At first the legs were constructed as cantilevers, but about halfway to the first level, construction was paused in order to create a substantial timber scaffold. This renewed concerns about the structural integrity of the tower, and sensational headlines such as "Eiffel Suicide!" and "Gustave Eiffel Has Gone Mad: He Has Been Confined in an Asylum" appeared in the tabloid press. At this stage, a small "creeper" crane designed to move up the tower was installed in each leg. They made use of the guides for the lifts which were to be fitted in the four legs. The critical stage of joining the legs at the first level was completed by the end of March 1888. Although the metalwork had been prepared with the utmost attention to detail, provision had been made to carry out small adjustments in order to precisely align the legs; hydraulic jacks were fitted to the shoes at the base of each leg, capable of exerting a force of 800 tonnes, and the legs were intentionally constructed at a slightly steeper angle than necessary, being supported by sandboxes on the scaffold. Although construction involved 300 on-site employees, only one person died thanks to Eiffel's stringent safety precautions and the use of movable gangways, guardrails and screens.
Lifts.
Equipping the tower with adequate and safe passenger lifts was a major concern of the government commission overseeing the Exposition. Although some visitors could be expected to climb to the first level, or even the second, lifts clearly had to be the main means of ascent.
Constructing lifts to reach the first level was relatively straightforward: the legs were wide enough at the bottom and so nearly straight that they could contain a straight track, and a contract was given to the French company Roux, Combaluzier & Lepape for two lifts to be fitted in the east and west legs. Roux, Combaluzier & Lepape used a pair of endless chains with rigid, articulated links to which the car was attached. Lead weights on some links of the upper or return sections of the chains counterbalanced most of the car's weight. The car was pushed up from below, not pulled up from above: to prevent the chain buckling, it was enclosed in a conduit. At the bottom of the run, the chains passed around 3.9Â m (12Â ft 10Â in) diameter sprockets. Smaller sprockets at the top guided the chains.
Installing lifts to the second level was more of a challenge because a straight track was impossible. No French company wanted to undertake the work. The European branch of Otis Brothers & Company submitted a proposal but this was rejected: the fair's charter ruled out the use of any foreign material in the construction of the tower. The deadline for bids was extended but still no French companies put themselves forward, and eventually the contract was given to Otis in July 1887. Otis were confident they would eventually be given the contract and had already started creating designs.
The car was divided into two superimposed compartments, each holding 25 passengers, with the lift operator occupying an exterior platform on the first level. Motive power was provided by an inclined hydraulic ram 12.67Â m (41Â ft 7Â in) long and 96.5Â cm (38Â in) in diameter in the tower leg with a stroke of 10.83Â m (35Â ft 6Â in): this moved a carriage carrying six sheaves. Five fixed sheaves were mounted higher up the leg, producing an arrangement similar to a block and tackle but acting in reverse, multiplying the stroke of the piston rather than the force generated. The hydraulic pressure in the driving cylinder was produced by a large open reservoir on the second level. After being exhausted from the cylinder, the water was pumped back up to the reservoir by two pumps in the machinery room at the base of the south leg. This reservoir also provided power to the lifts to the first level.
The original lifts for the journey between the second and third levels were supplied by LÃ©on Edoux. A pair of hydraulic rams were mounted on the second level, reaching nearly halfway up to the third level. One lift car was mounted on top of these rams: cables ran from the top of this car up to sheaves on the third level and back down to a second car. Each car only travelled half the distance between the second and third levels and passengers were required to change lifts halfway by means of a short gangway. The 10-ton cars each held 65 passengers.
Inauguration and the 1889 exposition.
The main structural work was completed at the end of March 1889 and, on the 31st of March, Eiffel celebrated by leading a group of government officials, accompanied by representatives of the press, to the top of the tower. Because the lifts were not yet in operation, the ascent was made by foot, and took over an hour, with Eiffel stopping frequently to explain various features. Most of the party chose to stop at the lower levels, but a few, including the structural engineer, Ãmile Nouguier, the head of construction, Jean Compagnon, the President of the City Council, and reporters from "Le Figaro" and "Le Monde IllustrÃ©", completed the ascent. At 2:35Â pm, Eiffel hoisted a large Tricolour to the accompaniment of a 25-gun salute fired at the first level.
There was still work to be done, particularly on the lifts and facilities, and the tower was not opened to the public until nine days after the opening of the exposition on 6 May; even then, the lifts had not been completed. The tower was an instant success with the public, and nearly 30,000 visitors made the 1,710-step climb to the top before the lifts entered service on 26 May.
Tickets cost 2 francs for the first level, 3 for the second, and 5 for the top, with half-price admission on Sundays, and by the end of the exhibition there had been 1,896,987 visitors.
After dark, the tower was lit by hundreds of gas lamps, and a beacon sent out three beams of red, white and blue light. Two searchlights mounted on a circular rail were used to illuminate various buildings of the exposition. The daily opening and closing of the exposition were announced by a cannon at the top.
On the second level, the French newspaper "Le Figaro" had an office and a printing press, where a special souvenir edition, "Le Figaro de la Tour", was made. There was also a pÃ¢tisserie.
At the top, there was a post office where visitors could send letters and postcards as a memento of their visit. Graffitists were also catered for: sheets of paper were mounted on the walls each day for visitors to record their impressions of the tower. Gustave Eiffel described some of the responses as "vraiment curieuse" ("truly curious").
Famous visitors to the tower included the Prince of Wales, Sarah Bernhardt, "Buffalo Bill" Cody (his Wild West show was an attraction at the exposition) and Thomas Edison. Eiffel invited Edison to his private apartment at the top of the tower, where Edison presented him with one of his phonographs, a new invention and one of the many highlights of the exposition. Edison signed the guestbook with this message: 
Eiffel had a permit for the tower to stand for 20 years. It was to be dismantled in 1909, when its ownership would revert to the City of Paris. The City had planned to tear it down (part of the original contest rules for designing a tower was that it should be easy to dismantle) but as the tower proved to be valuable for communication purposes, it was allowed to remain after the expiry of the permit.
Eiffel made use of his apartment at the top of the tower to carry out meteorological observations, and also used the tower to perform experiments on the action of air resistance on falling bodies.
Subsequent events.
For the 1900 "Exposition Universelle", the lifts in the east and west legs were replaced by lifts running as far as the second level constructed by the French firm Fives-Lille. These had a compensating mechanism to keep the floor level as the angle of ascent changed at the first level, and were driven by a similar hydraulic mechanism to the Otis lifts, although this was situated at the base of the tower. Hydraulic pressure was provided by pressurised accumulators located near this mechanism. At the same time the lift in the north pillar was removed and replaced by a staircase to the first level. The layout of both first and second levels was modified, with the space available for visitors on the second level. The original lift in the south pillar was removed 13 years later.
On 19 October 1901, Alberto Santos-Dumont, flying his No.6 airship, won a 100,000-franc prize offered by Henri Deutsch de la Meurthe for the first person to make a flight from St. Cloud to the Eiffel Tower and back in less than half an hour.
Many innovations took place at the Eiffel Tower in the early 20th century. In 1910, Father Theodor Wulf measured radiant energy at the top and bottom of the tower. He found more at the top than expected, incidentally discovering what are known today as cosmic rays. Just two years later, on 4 February 1912, Austrian tailor Franz Reichelt died after jumping from the first level of the tower (a height of 57 metres) to demonstrate his parachute design. In 1914, at the outbreak of World WarÂ I, a radio transmitter located in the tower jammed German radio communications, seriously hindering their advance on Paris and contributing to the Allied victory at the First Battle of the Marne. From 1925 to 1934, illuminated signs for CitroÃ«n adorned three of the tower's sides, making it the tallest advertising space in the world at the time. In April 1935, the tower was used to make experimental low-resolution television transmissions, using a shortwave transmitter of 200 watts power. On 17 November, an improved 180-line transmitter was installed.
On two separate but related occasions in 1925, the con artist Victor Lustig "sold" the tower for scrap metal. A year later, in February 1926, pilot Leon Collet was killed trying to fly under the tower. His aircraft became entangled in an aerial belonging to a wireless station. On 2 May 1929, a bust of Gustave Eiffel by Antoine Bourdelle was unveiled at the base of the north leg. In 1930, the tower lost the title of the world's tallest structure when the Chrysler Building in New York City was completed. In 1938, the decorative arcade around the first level was removed.
Upon the German occupation of Paris in 1940, the lift cables were cut by the French. The tower was closed to the public during the occupation and the lifts were not repaired until 1946. In 1940, German soldiers had to climb the tower to hoist the swastika, but the flag was so large it blew away just a few hours later, and was replaced by a smaller one. When visiting Paris, Hitler chose to stay on the ground. In August 1944, when the Allies were nearing Paris, Hitler ordered General Dietrich von Choltitz, the military governor of Paris, to demolish the tower along with the rest of the city. Von Choltitz disobeyed the order. On 25 June, before the Germans had been driven out of Paris, the Nazi flag was replaced with a Tricolour by two men from the French Naval Museum, who narrowly beat three men led by Lucien Sarniguet, who had lowered the Tricolour on 13 June 1940 when Paris fell to the Germans.
On 3 January 1956, a fire started in the television transmitter, damaging the top of the tower. Repairs took a year, and in 1957, the present radio aerial was added to the top. In 1964, the Eiffel Tower was officially declared to be a historical monument by the Minister of Cultural Affairs, AndrÃ© Malraux. A year later, due to increasing visitor numbers, an additional lift system was installed in the north pillar.
According to interviews, in 1967, Montreal Mayor Jean Drapeau negotiated a secret agreement with Charles de Gaulle for the tower to be dismantled and temporarily relocated to Montreal to serve as a landmark and tourist attraction during Expo 67. The plan was allegedly vetoed by the company operating the tower out of fear that the French government could refuse permission for the tower to be restored in its original location.
In 1982, the original lifts between the second and third levels were replaced after 97 years in service. These had been closed to the public between November and March because the water in the hydraulic drive tended to freeze. The new cars operate in pairs, with one counterbalancing the other, and perform the journey in one stage, reducing the journey time from eight minutes to less than two minutes. At the same time, two new emergency staircases were installed, replacing the original spiral staircases. In 1983, the south pillar was fitted with an electrically driven Otis lift to serve the Jules Verne restaurant. The Fives-Lille lifts in the east and west legs, fitted in 1899, were extensively refurbished in 1986. The cars were replaced, and a computer system was installed to completely automate the lifts. The motive power was moved from the water hydraulic system to a new electrically driven oil-filled hydraulic system, and the original water hydraulics were retained solely as a counterbalance system. A service lift was added to the south pillar for moving small loads and maintenance personnel three years later.
On 31 March 1984, Robert Moriarty flew a Beechcraft Bonanza under the tower. In 1987, A.J. Hackett made one of his first bungee jumps from the top of the Eiffel Tower, using a special cord he had helped develop. Hackett was arrested by the police. On 27 October 1991, Thierry Devaux, along with mountain guide HervÃ© Calvayrac, performed a series of acrobatic figures while bungee jumping from the second floor of the tower. Facing the Champ de Mars, Devaux used an electric winch between figures to go back up to the second floor. When firemen arrived, he stopped after the sixth jump.
On 31 December 1999, for its "Countdown to the Year 2000" celebration, flashing lights and high-powered searchlights were installed on the tower. Fireworks were set off all over it. An exhibition above a cafeteria on the first floor commemorates this event. The searchlights on top of the tower made it a beacon in Paris's night sky, and 20,000 flashing bulbs gave the tower a sparkly appearance for five minutes every hour on the hour. On 31 December 2000, the lights sparkled blue for several nights to herald the new millennium. The sparkly lighting continued for 18 months until July 2001. The sparkling lights were turned on again on 21 June 2003, and the display was planned to continue for 10 years.
The tower received its th guest on 28 November 2002. In 2004, the Eiffel Tower began hosting a seasonal ice rink on the first level. A glass floor was installed on the first level during the 2014 refurbishment.
Design.
Material.
The puddled iron (wrought iron) of the Eiffel Tower weighs tonnes, and the entire structure, including non-metal components, is approximately Â tonnes. As a demonstration of the economy of design, if the 7,300 tonnes of metal in the structure were melted down, it would fill the 125Â m base to a depth of only 6.25Â cm (2.5Â in), assuming the density of the metal to be 7.8 tonnes per cubic metre. Additionally, a cubic box surrounding the tower (324Â m x 125Â m x 125Â m) would contain Â tonnes of air, weighing almost as much as the iron itself. Depending on the ambient temperature, the top of the tower may shift away from the sun by up to 18Â cm (7.1Â in) due to thermal expansion of the metal on the side facing the sun.
Wind considerations.
When the tower was built, many people were shocked by its daring form. Eiffel was accused of trying to create something artistic with no regard to the principles of engineering. However, Eiffel and his engineers, as experienced bridge builders, understood the importance of wind forces, and knew that if they were going to build the tallest structure in the world, they had to be sure it could withstand them. In an interview with the newspaper "Le Temps" published on 14 February 1887, Eiffel said,
Eiffel used empirical and graphical methods to account for the effects of wind rather than a specific mathematical formula. Careful examination of the tower reveals a basically exponential shape (actually two different exponentials, the lower section being over-designed to ensure resistance to wind forces). Several mathematical explanations have been proposed over the years for the success of the design; the most recent is described as a non-linear integral equation based on counteracting the wind pressure on any point on the tower with the tension between the construction elements at that point. The tower sways by only 6â7Â cm (2â3Â in) in the wind.
Accommodation.
When originally built, the first level contained three restaurantsâone French, one Russian and one Flemishâand an "Anglo-American Bar". After the exposition closed, the Flemish restaurant was converted to a 250-seat theatre. A promenade wide ran around the outside of the first level. At the top, there were laboratories for various experiments, and a small apartment reserved for Gustave Eiffel to entertain guests, which is now open to the public, complete with period decorations and lifelike mannequins of Eiffel and some of his notable guests.
Passenger lifts.
The arrangement of the lifts has been changed several times during the tower's history. Given the elasticity of the cables and the time taken to align the cars with the landings, each lift, in normal service, takes an average of 8 minutes and 50 seconds to do the round trip, spending an average of 1 minute and 15 seconds at each level. The average journey time between levels is 1 minute. The original hydraulic mechanism is on public display in a small museum at the base of the east and west legs. Because the mechanism requires frequent lubrication and maintenance, public access is often restricted. The rope mechanism of the north tower can be seen as visitors exit the lift.
Engraved names.
Gustave Eiffel engraved on the tower the names of 72 French scientists, engineers and mathematicians in recognition of their contributions to the building of the tower. Eiffel chose this "invocation of science" because of his concern over the artists' protest. At the beginning of the 20th century, the engravings were painted over, but they were restored in 1986â87 by the , a company operating the tower.
Aesthetics.
The tower was originally painted in three shades: lighter at the top, getting progressively darker towards the bottom to perfectly complement the Parisian sky. The colour is periodically changed; as of 2013 the tower is bronze coloured. On the first level are interactive consoles hosting a poll for the colour to use for the next repaint.
The only non-structural elements are the four decorative grill-work arches, added in Sauvestre's sketches, which served to make the tower look more substantial and to make a more impressive entrance to the exposition.
One of the great Hollywood movie clichÃ©s is that the view from a Parisian window always includes the tower. In reality, since zoning restrictions limit the height of most buildings in Paris to seven storeys, only a small number of tall buildings have a clear view of the tower.
Maintenance.
Maintenance of the tower includes applying of paint every seven years to prevent it from rusting. The height of the Eiffel Tower varies by up to due to thermal expansion.
Tourism.
Transport.
The nearest Paris MÃ©tro station is Bir-Hakeim and the nearest RER station is Champ de Mars-Tour Eiffel. The tower itself is located at the intersection of the quai Branly and the Pont d'IÃ©na.
Popularity.
More than 250Â million people have visited the tower since it was completed in 1889: in 2012 there were 6,180,000 visitors. The tower is the most-visited paid monument in the world. An average of 25,000 people ascend the tower every day which can result in long queues. Tickets can be purchased online to avoid the long queues.
Restaurants.
The tower has two restaurants: on the first level, and , a gourmet restaurant with its own lift on the second level. This restaurant has one star in the Michelin Red Guide. It is run by the multi-Michelin star chef Alain Ducasse and owes its name to the famous science-fiction writer Jules Verne.
Replicas.
As one of the most iconic landmarks in the world, the Eiffel Tower has been the inspiration for the creation of at least 12 replicas of a quarter scale or larger, and there are more than 40 duplicates and similar towers of various scales around the world. An early example is the Blackpool Tower in England. The mayor of Blackpool, Sir John Bickerstaffe, was so impressed on seeing the Eiffel Tower at the 1889 exposition that he commissioned a similar tower to be built in his town. Two full size replicas exist: Tokyo Tower in Japan and the Long Ta communications tower in northern China.
In 2011, the American TV show "Pricing the Priceless" speculated that the Eiffel Tower would cost $480Â million to build, that the land on which the tower stands is worth $350Â million, and that the scrap value of the tower is $3.5Â million. The show estimated that the tower makes a profit of $29Â million per year, but it is unlikely the Eiffel Tower is managed so as to maximize profit.
Communications.
The tower has been used for making radio transmissions since the beginning of the 20th century. Until the 1950s, sets of aerial wires ran from the cupola to anchors on the Avenue de Suffren and Champ de Mars. These were connected to longwave transmitters in small bunkers. In 1909, a permanent underground radio centre was built near the south pillar, which still exists today. On 20 November 1913, the Paris Observatory, using the Eiffel Tower as an aerial, exchanged wireless signals with the United States Naval Observatory, which used an aerial in Arlington, Virginia. The object of the transmissions was to measure the difference in longitude between Paris and Washington, D.C. Today, radio and television signals are transmitted from the Eiffel Tower.
Television.
Analogue.
Analogue television signals ceased from the Eiffel Tower on 8 March 2011.
Image copyright claims.
The tower and its representations have long been in the public domain. In June 1990, however, a French court ruled that a special lighting display on the tower in 1989 to mark the tower's 100th anniversary was an "original visual creation" protected by copyright. The Court of Cassation, France's judicial court of last resort, upheld the ruling in March 1992. The (SETE) now considers any illumination of the tower to be under copyright. As a result, it is illegal to publish contemporary photographs of the tower at night without permission in France and some other countries.
The imposition of copyright has been controversial. The Director of Documentation for what was then called the (SNTE), StÃ©phane Dieu, commented in January 2005, "It is really just a way to manage commercial use of the image, so that it isn't used in ways we don't approve." However, it could also be used to prohibit the publication of tourist photographs of the tower at night, as well as hindering non-profit and semi-commercial publication of images of the tower. French doctrine and jurisprudence traditionally allows pictures incorporating a copyrighted work as long as their presence is incidental or accessory to the subject being represented, a reasoning akin to the "de minimis" rule. Therefore, SETE could not claim copyright on photographs of Paris which happen to include the lit tower.
In popular culture.
As a global landmark, the Eiffel Tower is featured in films, video games and TV shows.
In a commitment ceremony in 2007, Erika Eiffel, an American woman, "married" the Eiffel Tower. Her relationship with the tower has been the subject of extensive global publicity.
Taller structures.
Although it was the world's tallest structure when completed in 1889, the Eiffel Tower has since lost its standing both as the tallest lattice tower and as the tallest structure in France.

</doc>
<doc id="9235" url="https://en.wikipedia.org/wiki?curid=9235" title="Ethical egoism">
Ethical egoism

Ethical egoism is the normative ethical position that moral agents ought to do what is in their own self-interest. It differs from psychological egoism, which claims that people can only act in their self-interest. Ethical egoism also differs from rational egoism, which holds that it is rational to act in one's self-interest.
Ethical egoism holds that actions whose consequences will benefit the doer can be considered ethical.
Ethical egoism contrasts with ethical altruism, which holds that moral agents have an obligation to help others. Egoism and altruism both contrast with ethical utilitarianism, which holds that a moral agent should treat one's self (also known as the subject) with no higher regard than one has for others (as egoism does, by elevating self-interests and "the self" to a status not granted to others). But it also holds that one should not (as altruism does) sacrifice one's own interests to help others' interests, so long as one's own interests (i.e. one's own desires or well-being) are substantially equivalent to the others' interests and well-being. Egoism, utilitarianism, and altruism are all forms of consequentialism, but egoism and altruism contrast with utilitarianism, in that egoism and altruism are both agent-focused forms of consequentialism (i.e. subject-focused or subjective). However, utilitarianism is held to be agent-neutral (i.e. objective and impartial): it does not treat the subject's (i.e. the self's, i.e. the moral "agent's") own interests as being more or less important than the interests, desires, or well-being of others.
Ethical egoism does not, however, require moral agents to harm the interests and well-being of others when making moral deliberation; e.g. what is in an agent's self-interest may be incidentally detrimental, beneficial, or neutral in its effect on others. Individualism allows for others' interest and well-being to be disregarded or not, as long as what is chosen is efficacious in satisfying the self-interest of the agent. Nor does ethical egoism necessarily entail that, in pursuing self-interest, one ought always to do what one wants to do; e.g. in the long term, the fulfillment of short-term desires may prove detrimental to the self. Fleeting pleasure, then, takes a back seat to protracted eudaimonia. In the words of James Rachels, "Ethical egoism . endorses selfishness, but it doesn't endorse foolishness."
Ethical egoism is often used as the philosophical basis for support of right-libertarianism and individualist anarchism. These are political positions based partly on a belief that individuals should not coercively prevent others from exercising freedom of action.
Forms of ethical egoism.
Ethical egoism can be broadly divided into three categories: individual, personal, and universal. An "individual ethical egoist" would hold that all people should do whatever benefits "my" ("the individual")" "self-interest; a "personal ethical egoist" would hold that he or she should act in "his or her" self-interest, but would make no claims about what anyone else ought to do; a "universal ethical egoist" would argue that everyone should act in ways that are in their self-interest.
History.
Ethical egoism was introduced by the philosopher Henry Sidgwick in his book "The Methods of Ethics", written in 1874. Sidgwick compared egoism to the philosophy of utilitarianism, writing that whereas utilitarianism sought to maximize overall pleasure, egoism focused only on maximizing individual pleasure.
Philosophers before Sidgwick have also retroactively been identified as ethical egoists. One ancient example is the philosophy of Yang Zhu (4th century B.C.), Yangism, who views "wei wo", or "everything for myself", as the only virtue necessary for self-cultivation. Ancient Greek philosophers like Plato, Aristotle and the Stoics were exponents of virtue ethics, and "did not accept the formal principle that whatever the good is, we should seek only our own good, or prefer it to the good of others." However, the beliefs of the Cyrenaics have been referred to as a "form of egoistic hedonism", and while some refer to Epicurus' hedonism as a form of virtue ethics, others argue his ethics are more properly described as ethical egoism.
Justifications.
Philosopher James Rachels, in an essay that takes as its title the theory's name, outlines the three arguments most commonly touted in its favor:
Notable proponents.
The term "ethical egoism" has been applied retroactively to philosophers such as Bernard de Mandeville and to many other materialists of his generation, although none of them declared themselves to be egoists. Note that materialism does not necessarily imply egoism, as indicated by Karl Marx, and the many other materialists who espoused forms of collectivism. It has been argued that ethical egoism can lend itself to individualist anarchism such as that of Benjamin Tucker, or the combined anarcho-communism and egoism of Emma Goldman, both of whom were proponents of many egoist ideas put forward by Max Stirner. In this context, egoism is another way of describing the sense that the common good should be enjoyed by all. However, most notable anarchists in history have been less radical, retaining altruism and a sense of the importance of the individual that is appreciable but does not go as far as egoism. Recent trends to greater appreciation of egoism within anarchism tend to come from less classical directions such as post-left anarchy or Situationism (e.g. Raoul Vaneigem). Egoism has also been referenced by anarcho-capitalists, such as Murray Rothbard.
Philosopher Max Stirner, in his book "The Ego and Its Own", was the first philosopher to call himself an egoist, though his writing makes clear that he desired not a new idea of morality (ethical egoism), but rather a rejection of morality (amoralism), as a nonexistent and limiting âspookâ; for this, Stirner has been described as the first individualist anarchist. Other philosophers, such as Thomas Hobbes and David Gauthier, have argued that the conflicts which arise when people each pursue their own ends can be resolved for the best of each individual only if they all voluntarily forgo some of their aims â that is, one's self-interest is often best pursued by allowing others to pursue their self-interest as well so that liberty is equal among individuals. Sacrificing one's short-term self-interest to maximize one's long-term self-interest is one form of "rational self-interest" which is the idea behind most philosophers' advocacy of ethical egoism. Egoists have also argued that one's actual interests are not immediately obvious, and that the pursuit of self-interest involves more than merely the acquisition of some good, but the "maximizing" of one's chances of survival and/or happiness.
Philosopher Friedrich Nietzsche suggested that egoistic or "life-affirming" behavior stimulates jealousy or "ressentiment" in others, and that this is the psychological motive for the altruism in Christianity. Sociologist Helmut Schoeck similarly considered envy the motive of collective efforts by society to reduce the disproportionate gains of successful individuals through moral or legal constraints, with altruism being primary among these. In addition, Nietzsche (in "Beyond Good and Evil") and Alasdair MacIntyre (in "After Virtue") have pointed out that the ancient Greeks did not associate morality with altruism in the way that post-Christian Western civilization has done.
Aristotle's view is that we have duties to ourselves as well as to other people (e.g. friends) and to the "polis" as a whole. The same is true for Thomas Aquinas, Christian Wolff and Immanuel Kant, who claim that there are duties to ourselves as Aristotle did, although it has been argued that, for Aristotle, the duty to one's self is primary.
Ayn Rand argued that there is a positive harmony of interests among free, rational humans, such that no moral agent can rationally coerce another person consistently with his own long-term self-interest. Rand argued that other people are an enormous value to an individual's well-being (through education, trade and affection), but also that this value could be fully realized only under conditions of political and economic freedom. According to Rand, voluntary trade alone can assure that human interaction is "mutually" beneficial. Rand's student, Leonard Peikoff has argued that the identification of one's interests itself is impossible absent the use of principles, and that self-interest cannot be consistently pursued absent a consistent adherence to certain ethical principles. Recently, Rand's position has also been defended by such writers as Tara Smith, Tibor Machan, Allan Gotthelf, David Kelley, Douglas Rasmussen, Nathaniel Branden, Harry Binswanger, Andrew Bernstein, and Craig Biddle.
Philosopher David L. Norton identified himself an "ethical individualist," and, like Rand, saw a harmony between an individual's fidelity to his own self-actualization, or "personal destiny," and the achievement of society's well being.
Criticisms.
According to amoralism, there is nothing wrong with egoism, but there is also nothing ethical about it; one can adopt rational egoism and drop morality as a superfluous attribute of the egoism.
Ethical egoism has been alleged as the basis for immorality. Egoism has also been alleged as being outside the scope of moral philosophy. Thomas Jefferson writes in an 1814 letter to Thomas Law:
In contrast, Rand saw ethics as a necessity for human survival and well-being, and argued that the "social" implications of morality, including natural rights, were simply a subset of the wider field of ethics. Thus, for Rand, "virtue" included productiveness, honesty with oneself, and scrupulousness of thought. Although she greatly admired Jefferson, she also wrote:
In "The Moral Point of View", Kurt Baier objects that ethical egoism provides no moral basis for the resolution of conflicts of interest, which, in his opinion, form the only vindication for a moral code. Were this an ideal world, one in which interests and purposes never jarred, its inhabitants would have no need of a specified set of ethics, according to Baier. This, however, is not an "ideal world." Baier believes that ethical egoism fails to provide the moral guidance and arbitration that it necessitates. Far from resolving conflicts of interest, claimed Baier, ethical egoism all too often spawns them. To this, as Rachels has shown, the ethical egoist may object that he cannot admit a construct of morality whose aim is merely to forestall conflicts of interest. "On his view," he writes, "the moralist is not like a courtroom judge, who resolves disputes. Instead, he is like the Commissioner of Boxing, who urges each fighter to do his best."
Baiers is also part of a team of philosophers who hold that ethical egoism is paradoxical, implying that to do what is in one's best interests can be both wrong and right in ethical terms. Although a successful pursuit of self-interest may be viewed as a moral victory, it could also be dubbed immoral if it prevents another person from executing what is in "his" best interests. Again, however, the ethical egoists have responded by assuming the guise of the Commissioner of Boxing. His philosophy precludes empathy for the interests of others, so forestalling them is perfectly acceptable. "Regardless of whether we think this is a correct view," adds Rachels, "it is, at the very least, a "consistent" view, and so this attempt to convict the egoist of self-contradiction fails."
Finally, it has been averred that ethical egoism is no better than bigotry in that, like racism, it divides people into two types â themselves and others â and discriminates against one type on the basis of some arbitrary disparity. This, to Rachels's mind, is probably the best objection to ethical egoism, for it provides the soundest reason why the interests of others ought to concern the interests of the self. "What," he asks, "is the difference between myself and others that justifies placing myself in this special category? Am I more intelligent? Do I enjoy my life more? Are my accomplishments greater? Do I have needs or abilities that are so different from the needs and abilities of others? "What is it that makes me so special"? Failing an answer, it turns out that Ethical Egoism is an arbitrary doctrine, in the same way that racism is arbitrary. . We should care about the interests of other people "for the very same reason we care about our own interests"; for their needs and desires are comparable to our own."

</doc>
<doc id="9236" url="https://en.wikipedia.org/wiki?curid=9236" title="Evolution">
Evolution

Evolution is change in the heritable traits of biological populations over successive generations. Evolutionary processes give rise to diversity at every level of biological organisation, including the levels of species, individual organisms, and molecules.
All life on Earth shares a common ancestor known as the last universal ancestor, which lived approximately 3.5â3.8 billion years ago, although a study in 2015 found "remains of biotic life" from 4.1 billion years ago in ancient rocks in Western Australia. According to one of the researchers, "If life arose relatively quickly on Earth ... then it could be common in the universe."
Repeated formation of new species (speciation), change within species (anagenesis), and loss of species (extinction) throughout the evolutionary history of life on Earth are demonstrated by shared sets of morphological and biochemical traits, including shared DNA sequences. These shared traits are more similar among species that share a more recent common ancestor, and can be used to reconstruct a biological "tree of life" based on evolutionary relationships (phylogenetics), using both existing species and fossils. The fossil record includes a progression from early biogenic graphite, to microbial mat fossils, to fossilized multicellular organisms. Existing patterns of biodiversity have been shaped both by speciation and by extinction. More than 99 percent of all species that ever lived on Earth are estimated to be extinct. Estimates of Earth's current species range from 10 to 14 million, of which about 1.2 million have been documented.
In the mid-19th century, Charles Darwin formulated the scientific theory of evolution by natural selection, published in his book "On the Origin of Species" (1859). Evolution by natural selection is a process demonstrated by the observation that more offspring are produced than can possibly survive, along with three facts about populations: 1) traits vary among individuals with respect to morphology, physiology, and behaviour (phenotypic variation), 2) different traits confer different rates of survival and reproduction (differential fitness), and 3) traits can be passed from generation to generation (heritability of fitness). Thus, in successive generations members of a population are replaced by progeny of parents better adapted to survive and reproduce in the biophysical environment in which natural selection takes place. This teleonomy is the quality whereby the process of natural selection creates and preserves traits that are seemingly fitted for the functional roles they perform. Natural selection is the only known cause of adaptation but not the only known cause of evolution. Other, nonadaptive causes of microevolution include mutation and genetic drift.
In the early 20th century the modern evolutionary synthesis integrated classical genetics with Darwin's theory of evolution by natural selection through the discipline of population genetics. The importance of natural selection as a cause of evolution was accepted into other branches of biology. Moreover, previously held notions about evolution, such as orthogenesis, evolutionism, and other beliefs about innate "progress" within the largest-scale trends in evolution, became obsolete scientific theories. Scientists continue to study various aspects of evolutionary biology by forming and testing hypotheses, constructing mathematical models of theoretical biology and biological theories, using observational data, and performing experiments in both the field and the laboratory.
Evolution is a cornerstone of modern science, accepted as one of the most reliably established of all facts and theories of science, based on evidence not just from the biological sciences but also from anthropology, psychology, astrophysics, chemistry, geology, physics, mathematics, and other scientific disciplines, as well as behavioral and social sciences. Understanding of evolution has made significant contributions to humanity, including the prevention and treatment of human disease, new agricultural products, industrial innovations, a subfield of computer science, and rapid advances in life sciences. Discoveries in evolutionary biology have made a significant impact not just in the traditional branches of biology but also in other academic disciplines (e.g., biological anthropology and evolutionary psychology) and in society at large.
History of evolutionary thought.
The proposal that one type of organism could descend from another type goes back to some of the first pre-Socratic Greek philosophers, such as Anaximander and Empedocles. Such proposals survived into Roman times. The poet and philosopher Lucretius followed Empedocles in his masterwork "De rerum natura" ("On the Nature of Things"). In contrast to these materialistic views, Aristotle understood all natural things, not only living things, as being imperfect actualisations of different fixed natural possibilities, known as "forms," "ideas," or (in Latin translations) ""species"." This was part of his teleological understanding of nature in which all things have an intended role to play in a divine cosmic order. Variations of this idea became the standard understanding of the Middle Ages and were integrated into Christian learning, but Aristotle did not demand that real types of organisms always correspond one-for-one with exact metaphysical forms and specifically gave examples of how new types of living things could come to be.
In the 17th century, the new method of modern science rejected Aristotle's approach. It sought explanations of natural phenomena in terms of physical laws that were the same for all visible things and that did not require the existence of any fixed natural categories or divine cosmic order. However, this new approach was slow to take root in the biological sciences, the last bastion of the concept of fixed natural types. John Ray applied one of the previously more general terms for fixed natural types, "species," to plant and animal types, but he strictly identified each type of living thing as a species and proposed that each species could be defined by the features that perpetuated themselves generation after generation. These species were designed by God, but showed differences caused by local conditions. The biological classification introduced by Carl Linnaeus in 1735 explicitly recognized the hierarchical nature of species relationships, but still viewed species as fixed according to a divine plan.
Other naturalists of this time speculated on the evolutionary change of species over time according to natural laws. In 1751, Pierre Louis Maupertuis wrote of natural modifications occurring during reproduction and accumulating over many generations to produce new species. Georges-Louis Leclerc, Comte de Buffon suggested that species could degenerate into different organisms, and Erasmus Darwin proposed that all warm-blooded animals could have descended from a single microorganism (or "filament"). The first full-fledged evolutionary scheme was Jean-Baptiste Lamarck's "transmutation" theory of 1809, which envisaged spontaneous generation continually producing simple forms of life that developed greater complexity in parallel lineages with an inherent progressive tendency, and postulated that on a local level these lineages adapted to the environment by inheriting changes caused by their use or disuse in parents. (The latter process was later called Lamarckism.) These ideas were condemned by established naturalists as speculation lacking empirical support. In particular, Georges Cuvier insisted that species were unrelated and fixed, their similarities reflecting divine design for functional needs. In the meantime, Ray's ideas of benevolent design had been developed by William Paley into the "Natural Theology or Evidences of the Existence and Attributes of the Deity" (1802), which proposed complex adaptations as evidence of divine design and which was admired by Charles Darwin.
The crucial break from the concept of constant typological classes or types in biology came with the theory of evolution through natural selection, which was formulated by Charles Darwin in terms of variable populations. Partly influenced by "An Essay on the Principle of Population" (1798) by Thomas Robert Malthus, Darwin noted that population growth would lead to a "struggle for existence" in which favorable variations prevailed as others perished. In each generation, many offspring fail to survive to an age of reproduction because of limited resources. This could explain the diversity of plants and animals from a common ancestry through the working of natural laws in the same way for all types of organism. Darwin developed his theory of "natural selection" from 1838 onwards and was writing up his "big book" on the subject when Alfred Russel Wallace sent him a version of virtually the same theory in 1858. Their separate papers were presented together at a 1858 meeting of the Linnean Society of London. At the end of 1859, Darwin's publication of his "abstract" as "On the Origin of Species" explained natural selection in detail and in a way that led to an increasingly wide acceptance of concepts of evolution. Thomas Henry Huxley applied Darwin's ideas to humans, using paleontology and comparative anatomy to provide strong evidence that humans and apes shared a common ancestry. Some were disturbed by this since it implied that humans did not have a special place in the universe.
Precise mechanisms of reproductive heritability and the origin of new traits remained a mystery. Towards this end, Darwin developed his provisional theory of pangenesis. In 1865, Gregor Mendel reported that traits were inherited in a predictable manner through the independent assortment and segregation of elements (later known as genes). Mendel's laws of inheritance eventually supplanted most of Darwin's pangenesis theory. August Weismann made the important distinction between germ cells that give rise to gametes (such as sperm and egg cells) and the somatic cells of the body, demonstrating that heredity passes through the germ line only. Hugo de Vries connected Darwin's pangenesis theory to Weismann's germ/soma cell distinction and proposed that Darwin's pangenes were concentrated in the cell nucleus and when expressed they could move into the cytoplasm to change the cells structure. De Vries was also one of the researchers who made Mendel's work well-known, believing that Mendelian traits corresponded to the transfer of heritable variations along the germline. To explain how new variants originate, de Vries developed a mutation theory that led to a temporary rift between those who accepted Darwinian evolution and biometricians who allied with de Vries. In the 1930s, pioneers in the field of population genetics, such as Ronald Fisher, Sewall Wright and J. B. S. Haldane set the foundations of evolution onto a robust statistical philosophy. The false contradiction between Darwin's theory, genetic mutations, and Mendelian inheritance was thus reconciled.
In the 1920s and 1930s a modern evolutionary synthesis connected natural selection, mutation theory, and Mendelian inheritance into a unified theory that applied generally to any branch of biology. The modern synthesis was able to explain patterns observed across species in populations, through fossil transitions in palaeontology, and even complex cellular mechanisms in developmental biology. The publication of the structure of DNA by James Watson and Francis Crick in 1953 demonstrated a physical basis for inheritance. Molecular biology improved our understanding of the relationship between genotype and phenotype. Advancements were also made in phylogenetic systematics, mapping the transition of traits into a comparative and testable framework through the publication and use of evolutionary trees. In 1973, evolutionary biologist Theodosius Dobzhansky penned that "nothing in biology makes sense except in the light of evolution," because it has brought to light the relations of what first seemed disjointed facts in natural history into a coherent explanatory body of knowledge that describes and predicts many observable facts about life on this planet.
Since then, the modern synthesis has been further extended to explain biological phenomena across the full and integrative scale of the biological hierarchy, from genes to species. This extension, known as evolutionary developmental biology and informally called "evo-devo," emphasises how changes between generations (evolution) acts on patterns of change within individual organisms (development).
Heredity.
Evolution in organisms occurs through changes in heritable traitsâthe inherited characteristics of an organism. In humans, for example, eye colour is an inherited characteristic and an individual might inherit the "brown-eye trait" from one of their parents. Inherited traits are controlled by genes and the complete set of genes within an organism's genome (genetic material) is called its genotype.
The complete set of observable traits that make up the structure and behaviour of an organism is called its phenotype. These traits come from the interaction of its genotype with the environment. As a result, many aspects of an organism's phenotype are not inherited. For example, suntanned skin comes from the interaction between a person's genotype and sunlight; thus, suntans are not passed on to people's children. However, some people tan more easily than others, due to differences in genotypic variation; a striking example are people with the inherited trait of albinism, who do not tan at all and are very sensitive to sunburn.
Heritable traits are passed from one generation to the next via DNA, a molecule that encodes genetic information. DNA is a long biopolymer composed of four types of bases. The sequence of bases along a particular DNA molecule specify the genetic information, in a manner similar to a sequence of letters spelling out a sentence. Before a cell divides, the DNA is copied, so that each of the resulting two cells will inherit the DNA sequence. Portions of a DNA molecule that specify a single functional unit are called genes; different genes have different sequences of bases. Within cells, the long strands of DNA form condensed structures called chromosomes. The specific location of a DNA sequence within a chromosome is known as a locus. If the DNA sequence at a locus varies between individuals, the different forms of this sequence are called alleles. DNA sequences can change through mutations, producing new alleles. If a mutation occurs within a gene, the new allele may affect the trait that the gene controls, altering the phenotype of the organism. However, while this simple correspondence between an allele and a trait works in some cases, most traits are more complex and are controlled by quantitative trait loci (multiple interacting genes).
Recent findings have confirmed important examples of heritable changes that cannot be explained by changes to the sequence of nucleotides in the DNA. These phenomena are classed as epigenetic inheritance systems. DNA methylation marking chromatin, self-sustaining metabolic loops, gene silencing by RNA interference and the three-dimensional conformation of proteins (such as prions) are areas where epigenetic inheritance systems have been discovered at the organismic level. Developmental biologists suggest that complex interactions in genetic networks and communication among cells can lead to heritable variations that may underlay some of the mechanics in developmental plasticity and canalisation. Heritability may also occur at even larger scales. For example, ecological inheritance through the process of niche construction is defined by the regular and repeated activities of organisms in their environment. This generates a legacy of effects that modify and feed back into the selection regime of subsequent generations. Descendants inherit genes plus environmental characteristics generated by the ecological actions of ancestors. Other examples of heritability in evolution that are not under the direct control of genes include the inheritance of cultural traits and symbiogenesis.
Variation.
An individual organism's phenotype results from both its genotype and the influence from the environment it has lived in. A substantial part of the phenotypic variation in a population is caused by genotypic variation. The modern evolutionary synthesis defines evolution as the change over time in this genetic variation. The frequency of one particular allele will become more or less prevalent relative to other forms of that gene. Variation disappears when a new allele reaches the point of fixationâwhen it either disappears from the population or replaces the ancestral allele entirely.
Natural selection will only cause evolution if there is enough genetic variation in a population. Before the discovery of Mendelian genetics, one common hypothesis was blending inheritance. But with blending inheritance, genetic variance would be rapidly lost, making evolution by natural selection implausible. The HardyâWeinberg principle provides the solution to how variation is maintained in a population with Mendelian inheritance. The frequencies of alleles (variations in a gene) will remain constant in the absence of selection, mutation, migration and genetic drift.
Variation comes from mutations in the genome, reshuffling of genes through sexual reproduction and migration between populations (gene flow). Despite the constant introduction of new variation through mutation and gene flow, most of the genome of a species is identical in all individuals of that species. However, even relatively small differences in genotype can lead to dramatic differences in phenotype: for example, chimpanzees and humans differ in only about 5% of their genomes.
Mutation.
Mutations are changes in the DNA sequence of a cell's genome. When mutations occur, they may alter the product of a gene, or prevent the gene from functioning, or have no effect. Based on studies in the fly "Drosophila melanogaster", it has been suggested that if a mutation changes a protein produced by a gene, this will probably be harmful, with about 70% of these mutations having damaging effects, and the remainder being either neutral or weakly beneficial.
Mutations can involve large sections of a chromosome becoming duplicated (usually by genetic recombination), which can introduce extra copies of a gene into a genome. Extra copies of genes are a major source of the raw material needed for new genes to evolve. This is important because most new genes evolve within gene families from pre-existing genes that share common ancestors. For example, the human eye uses four genes to make structures that sense light: three for colour vision and one for night vision; all four are descended from a single ancestral gene.
New genes can be generated from an ancestral gene when a duplicate copy mutates and acquires a new function. This process is easier once a gene has been duplicated because it increases the redundancy of the system; one gene in the pair can acquire a new function while the other copy continues to perform its original function. Other types of mutations can even generate entirely new genes from previously noncoding DNA.
The generation of new genes can also involve small parts of several genes being duplicated, with these fragments then recombining to form new combinations with new functions. When new genes are assembled from shuffling pre-existing parts, domains act as modules with simple independent functions, which can be mixed together to produce new combinations with new and complex functions. For example, polyketide synthases are large enzymes that make antibiotics; they contain up to one hundred independent domains that each catalyse one step in the overall process, like a step in an assembly line.
Sex and recombination.
In asexual organisms, genes are inherited together, or "linked", as they cannot mix with genes of other organisms during reproduction. In contrast, the offspring of sexual organisms contain random mixtures of their parents' chromosomes that are produced through independent assortment. In a related process called homologous recombination, sexual organisms exchange DNA between two matching chromosomes. Recombination and reassortment do not alter allele frequencies, but instead change which alleles are associated with each other, producing offspring with new combinations of alleles. Sex usually increases genetic variation and may increase the rate of evolution.
The two-fold cost of sex was first described by John Maynard Smith. The first cost is that only one of the two sexes can bear young. (This cost does not apply to hermaphroditic species, like most plants and many inverebrates.) The second cost is that any individual who reproduces sexually can only pass on 50% of its genes to any individual offspring, with even less passed on as each new generation passes. (Again, this applies mostly to the evolution of sexual dimorphism, which occurred long after the evolution of sex itself.) Yet sexual reproduction is the more common means of reproduction among eukaryotes and multicellular organisms (although more common than sexual dimorphism). The Red Queen hypothesis has been used to explain the significance of sexual reproduction as a means to enable continual evolution and adaptation in response to coevolution with other species in an ever-changing environment.
Gene flow.
Gene flow is the exchange of genes between populations and between species. It can therefore be a source of variation that is new to a population or to a species. Gene flow can be caused by the movement of individuals between separate populations of organisms, as might be caused by the movement of mice between inland and coastal populations, or the movement of pollen between heavy metal tolerant and heavy metal sensitive populations of grasses.
Gene transfer between species includes the formation of hybrid organisms and horizontal gene transfer. Horizontal gene transfer is the transfer of genetic material from one organism to another organism that is not its offspring; this is most common among bacteria. In medicine, this contributes to the spread of antibiotic resistance, as when one bacteria acquires resistance genes it can rapidly transfer them to other species. Horizontal transfer of genes from bacteria to eukaryotes such as the yeast "Saccharomyces cerevisiae" and the adzuki bean weevil "Callosobruchus chinensis" has occurred. An example of larger-scale transfers are the eukaryotic bdelloid rotifers, which have received a range of genes from bacteria, fungi and plants. Viruses can also carry DNA between organisms, allowing transfer of genes even across biological domains.
Large-scale gene transfer has also occurred between the ancestors of eukaryotic cells and bacteria, during the acquisition of chloroplasts and mitochondria. It is possible that eukaryotes themselves originated from horizontal gene transfers between bacteria and archaea.
Mechanisms.
From a Neo-Darwinian perspective, evolution occurs when there are changes in the frequencies of alleles within a population of interbreeding organisms. For example, the allele for black colour in a population of moths becoming more common. Mechanisms that can lead to changes in allele frequencies include natural selection, genetic drift, genetic hitchhiking, mutation and gene flow.
Natural selection.
Evolution by means of natural selection is the process by which traits that enhance survival and reproduction become more common in successive generations of a population. It has often been called a "self-evident" mechanism because it necessarily follows from three simple facts:
More offspring are produced than can possibly survive, and these conditions produce competition between organisms for survival and reproduction. Consequently, organisms with traits that give them an advantage over their competitors are more likely to pass on their traits to the next generation than those with traits that do not confer an advantage.
The central concept of natural selection is the evolutionary fitness of an organism. Fitness is measured by an organism's ability to survive and reproduce, which determines the size of its genetic contribution to the next generation. However, fitness is not the same as the total number of offspring: instead fitness is indicated by the proportion of subsequent generations that carry an organism's genes. For example, if an organism could survive well and reproduce rapidly, but its offspring were all too small and weak to survive, this organism would make little genetic contribution to future generations and would thus have low fitness.
If an allele increases fitness more than the other alleles of that gene, then with each generation this allele will become more common within the population. These traits are said to be "selected "for"." Examples of traits that can increase fitness are enhanced survival and increased fecundity. Conversely, the lower fitness caused by having a less beneficial or deleterious allele results in this allele becoming rarerâthey are "selected "against"." Importantly, the fitness of an allele is not a fixed characteristic; if the environment changes, previously neutral or harmful traits may become beneficial and previously beneficial traits become harmful. However, even if the direction of selection does reverse in this way, traits that were lost in the past may not re-evolve in an identical form (see Dollo's law).
Natural selection within a population for a trait that can vary across a range of values, such as height, can be categorised into three different types. The first is directional selection, which is a shift in the average value of a trait over timeâfor example, organisms slowly getting taller. Secondly, disruptive selection is selection for extreme trait values and often results in two different values becoming most common, with selection against the average value. This would be when either short or tall organisms had an advantage, but not those of medium height. Finally, in stabilising selection there is selection against extreme trait values on both ends, which causes a decrease in variance around the average value and less diversity. This would, for example, cause organisms to slowly become all the same height.
A special case of natural selection is sexual selection, which is selection for any trait that increases mating success by increasing the attractiveness of an organism to potential mates. Traits that evolved through sexual selection are particularly prominent among males of several animal species. Although sexually favoured, traits such as cumbersome antlers, mating calls, large body size and bright colours often attract predation, which compromises the survival of individual males. This survival disadvantage is balanced by higher reproductive success in males that show these hard-to-fake, sexually selected traits.
Natural selection most generally makes nature the measure against which individuals and individual traits, are more or less likely to survive. "Nature" in this sense refers to an ecosystem, that is, a system in which organisms interact with every other element, physical as well as biological, in their local environment. Eugene Odum, a founder of ecology, defined an ecosystem as: "Any unit that includes all of the organisms...in a given area interacting with the physical environment so that a flow of energy leads to clearly defined trophic structure, biotic diversity and material cycles (ie: exchange of materials between living and nonliving parts) within the system." Each population within an ecosystem occupies a distinct niche, or position, with distinct relationships to other parts of the system. These relationships involve the life history of the organism, its position in the food chain and its geographic range. This broad understanding of nature enables scientists to delineate specific forces which, together, comprise natural selection.
Natural selection can act at different levels of organisation, such as genes, cells, individual organisms, groups of organisms and species. Selection can act at multiple levels simultaneously. An example of selection occurring below the level of the individual organism are genes called transposons, which can replicate and spread throughout a genome. Selection at a level above the individual, such as group selection, may allow the evolution of cooperation, as discussed below.
Biased mutation.
In addition to being a major source of variation, mutation may also function as a mechanism of evolution when there are different probabilities at the molecular level for different mutations to occur, a process known as mutation bias. If two genotypes, for example one with the nucleotide G and another with the nucleotide A in the same position, have the same fitness, but mutation from G to A happens more often than mutation from A to G, then genotypes with A will tend to evolve. Different insertion vs. deletion mutation biases in different taxa can lead to the evolution of different genome sizes. Developmental or mutational biases have also been observed in morphological evolution. For example, according to the phenotype-first theory of evolution, mutations can eventually cause the genetic assimilation of traits that were previously induced by the environment.
Mutation bias effects are superimposed on other processes. If selection would favor either one out of two mutations, but there is no extra advantage to having both, then the mutation that occurs the most frequently is the one that is most likely to become fixed in a population. Mutations leading to the loss of function of a gene are much more common than mutations that produce a new, fully functional gene. Most loss of function mutations are selected against. But when selection is weak, mutation bias towards loss of function can affect evolution. For example, pigments are no longer useful when animals live in the darkness of caves, and tend to be lost. This kind of loss of function can occur because of mutation bias, and/or because the function had a cost, and once the benefit of the function disappeared, natural selection leads to the loss. Loss of sporulation ability in "Bacillus subtilis" during laboratory evolution appears to have been caused by mutation bias, rather than natural selection against the cost of maintaining sporulation ability. When there is no selection for loss of function, the speed at which loss evolves depends more on the mutation rate than it does on the effective population size, indicating that it is driven more by mutation bias than by genetic drift. In parasatic organisms, mutation bias leads to selection pressures as seen in Ehrlichia. Mutations are biased towards antigenic variants in outer-membrane proteins.
Genetic drift.
Genetic drift is the change in allele frequency from one generation to the next that occurs because alleles are subject to sampling error. As a result, when selective forces are absent or relatively weak, allele frequencies tend to "drift" upward or downward randomly (in a random walk). This drift halts when an allele eventually becomes fixed, either by disappearing from the population, or replacing the other alleles entirely. Genetic drift may therefore eliminate some alleles from a population due to chance alone. Even in the absence of selective forces, genetic drift can cause two separate populations that began with the same genetic structure to drift apart into two divergent populations with different sets of alleles.
It is usually difficult to measure the relative importance of selection and neutral processes, including drift. The comparative importance of adaptive and non-adaptive forces in driving evolutionary change is an area of current research.
The neutral theory of molecular evolution proposed that most evolutionary changes are the result of the fixation of neutral mutations by genetic drift. Hence, in this model, most genetic changes in a population are the result of constant mutation pressure and genetic drift. This form of the neutral theory is now largely abandoned, since it does not seem to fit the genetic variation seen in nature. However, a more recent and better-supported version of this model is the nearly neutral theory, where a mutation that would be effectively neutral in a small population is not necessarily neutral in a large population. Other alternative theories propose that genetic drift is dwarfed by other stochastic forces in evolution, such as genetic hitchhiking, also known as genetic draft.
The time for a neutral allele to become fixed by genetic drift depends on population size, with fixation occurring more rapidly in smaller populations. The number of individuals in a population is not critical, but instead a measure known as the effective population size. The effective population is usually smaller than the total population since it takes into account factors such as the level of inbreeding and the stage of the lifecycle in which the population is the smallest. The effective population size may not be the same for every gene in the same population.
Genetic hitchhiking.
Recombination allows alleles on the same strand of DNA to become separated. However, the rate of recombination is low (approximately two events per chromosome per generation). As a result, genes close together on a chromosome may not always be shuffled away from each other and genes that are close together tend to be inherited together, a phenomenon known as linkage. This tendency is measured by finding how often two alleles occur together on a single chromosome compared to expectations, which is called their linkage disequilibrium. A set of alleles that is usually inherited in a group is called a haplotype. This can be important when one allele in a particular haplotype is strongly beneficial: natural selection can drive a selective sweep that will also cause the other alleles in the haplotype to become more common in the population; this effect is called genetic hitchhiking or genetic draft. Genetic draft caused by the fact that some neutral genes are genetically linked to others that are under selection can be partially captured by an appropriate effective population size.
Gene flow.
Gene flow involves the exchange of genes between populations and between species. The presence or absence of gene flow fundamentally changes the course of evolution. Due to the complexity of organisms, any two completely isolated populations will eventually evolve genetic incompatibilities through neutral processes, as in the Bateson-Dobzhansky-Muller model, even if both populations remain essentially identical in terms of their adaptation to the environment.
If genetic differentiation between populations develops, gene flow between populations can introduce traits or alleles which are disadvantageous in the local population and this may lead to organisms within these populations evolving mechanisms that prevent mating with genetically distant populations, eventually resulting in the appearance of new species. Thus, exchange of genetic information between individuals is fundamentally important for the development of the biological species concept.
During the development of the modern synthesis, Sewall Wright developed his shifting balance theory, which regarded gene flow between partially isolated populations as an important aspect of adaptive evolution. However, recently there has been substantial criticism of the importance of the shifting balance theory.
Outcomes.
Evolution influences every aspect of the form and behaviour of organisms. Most prominent are the specific behavioural and physical adaptations that are the outcome of natural selection. These adaptations increase fitness by aiding activities such as finding food, avoiding predators or attracting mates. Organisms can also respond to selection by cooperating with each other, usually by aiding their relatives or engaging in mutually beneficial symbiosis. In the longer term, evolution produces new species through splitting ancestral populations of organisms into new groups that cannot or will not interbreed.
These outcomes of evolution are distinguished based on time scale as macroevolution versus microevolution. Macroevolution refers to evolution that occurs at or above the level of species, in particular speciation and extinction; whereas microevolution refers to smaller evolutionary changes within a species or population, in particular shifts in gene frequency and adaptation. In general, macroevolution is regarded as the outcome of long periods of microevolution. Thus, the distinction between micro- and macroevolution is not a fundamental oneâthe difference is simply the time involved. However, in macroevolution, the traits of the entire species may be important. For instance, a large amount of variation among individuals allows a species to rapidly adapt to new habitats, lessening the chance of it going extinct, while a wide geographic range increases the chance of speciation, by making it more likely that part of the population will become isolated. In this sense, microevolution and macroevolution might involve selection at different levelsâwith microevolution acting on genes and organisms, versus macroevolutionary processes such as species selection acting on entire species and affecting their rates of speciation and extinction.
A common misconception is that evolution has goals, long-term plans, or an innate tendency for "progress," as expressed in beliefs such as orthogenesis and evolutionism; realistically however, evolution has no long-term goal and does not necessarily produce greater complexity. Although complex species have evolved, they occur as a side effect of the overall number of organisms increasing and simple forms of life still remain more common in the biosphere. For example, the overwhelming majority of species are microscopic prokaryotes, which form about half the world's biomass despite their small size, and constitute the vast majority of Earth's biodiversity. Simple organisms have therefore been the dominant form of life on Earth throughout its history and continue to be the main form of life up to the present day, with complex life only appearing more diverse because it is more noticeable. Indeed, the evolution of microorganisms is particularly important to modern evolutionary research, since their rapid reproduction allows the study of experimental evolution and the observation of evolution and adaptation in real time.
Adaptation.
Adaptation is the process that makes organisms better suited to their habitat. Also, the term adaptation may refer to a trait that is important for an organism's survival. For example, the adaptation of horses' teeth to the grinding of grass. By using the term "adaptation" for the evolutionary process and "adaptive trait" for the product (the bodily part or function), the two senses of the word may be distinguished. Adaptations are produced by natural selection. The following definitions are due to Theodosius Dobzhansky:
Adaptation may cause either the gain of a new feature, or the loss of an ancestral feature. An example that shows both types of change is bacterial adaptation to antibiotic selection, with genetic changes causing antibiotic resistance by both modifying the target of the drug, or increasing the activity of transporters that pump the drug out of the cell. Other striking examples are the bacteria "Escherichia coli" evolving the ability to use citric acid as a nutrient in a long-term laboratory experiment, "Flavobacterium" evolving a novel enzyme that allows these bacteria to grow on the by-products of nylon manufacturing, and the soil bacterium "Sphingobium" evolving an entirely new metabolic pathway that degrades the synthetic pesticide pentachlorophenol. An interesting but still controversial idea is that some adaptations might increase the ability of organisms to generate genetic diversity and adapt by natural selection (increasing organisms' evolvability).
Adaptation occurs through the gradual modification of existing structures. Consequently, structures with similar internal organisation may have different functions in related organisms. This is the result of a single ancestral structure being adapted to function in different ways. The bones within bat wings, for example, are very similar to those in mice feet and primate hands, due to the descent of all these structures from a common mammalian ancestor. However, since all living organisms are related to some extent, even organs that appear to have little or no structural similarity, such as arthropod, squid and vertebrate eyes, or the limbs and wings of arthropods and vertebrates, can depend on a common set of homologous genes that control their assembly and function; this is called deep homology.
During evolution, some structures may lose their original function and become vestigial structures. Such structures may have little or no function in a current species, yet have a clear function in ancestral species, or other closely related species. Examples include pseudogenes, the non-functional remains of eyes in blind cave-dwelling fish, wings in flightless birds, the presence of hip bones in whales and snakes, and sexual traits in organisms that reproduce via asexual reproduction. Examples of vestigial structures in humans include wisdom teeth, the coccyx, the vermiform appendix, and other behavioural vestiges such as goose bumps and primitive reflexes.
However, many traits that appear to be simple adaptations are in fact exaptations: structures originally adapted for one function, but which coincidentally became somewhat useful for some other function in the process. One example is the African lizard "Holaspis guentheri", which developed an extremely flat head for hiding in crevices, as can be seen by looking at its near relatives. However, in this species, the head has become so flattened that it assists in gliding from tree to treeâan exaptation. Within cells, molecular machines such as the bacterial flagella and protein sorting machinery evolved by the recruitment of several pre-existing proteins that previously had different functions. Another example is the recruitment of enzymes from glycolysis and xenobiotic metabolism to serve as structural proteins called crystallins within the lenses of organisms' eyes.
An area of current investigation in evolutionary developmental biology is the developmental basis of adaptations and exaptations. This research addresses the origin and evolution of embryonic development and how modifications of development and developmental processes produce novel features. These studies have shown that evolution can alter development to produce new structures, such as embryonic bone structures that develop into the jaw in other animals instead forming part of the middle ear in mammals. It is also possible for structures that have been lost in evolution to reappear due to changes in developmental genes, such as a mutation in chickens causing embryos to grow teeth similar to those of crocodiles. It is now becoming clear that most alterations in the form of organisms are due to changes in a small set of conserved genes.
Coevolution.
Interactions between organisms can produce both conflict and cooperation. When the interaction is between pairs of species, such as a pathogen and a host, or a predator and its prey, these species can develop matched sets of adaptations. Here, the evolution of one species causes adaptations in a second species. These changes in the second species then, in turn, cause new adaptations in the first species. This cycle of selection and response is called coevolution. An example is the production of tetrodotoxin in the rough-skinned newt and the evolution of tetrodotoxin resistance in its predator, the common garter snake. In this predator-prey pair, an evolutionary arms race has produced high levels of toxin in the newt and correspondingly high levels of toxin resistance in the snake.
Cooperation.
Not all co-evolved interactions between species involve conflict. Many cases of mutually beneficial interactions have evolved. For instance, an extreme cooperation exists between plants and the mycorrhizal fungi that grow on their roots and aid the plant in absorbing nutrients from the soil. This is a reciprocal relationship as the plants provide the fungi with sugars from photosynthesis. Here, the fungi actually grow inside plant cells, allowing them to exchange nutrients with their hosts, while sending signals that suppress the plant immune system.
Coalitions between organisms of the same species have also evolved. An extreme case is the eusociality found in social insects, such as bees, termites and ants, where sterile insects feed and guard the small number of organisms in a colony that are able to reproduce. On an even smaller scale, the somatic cells that make up the body of an animal limit their reproduction so they can maintain a stable organism, which then supports a small number of the animal's germ cells to produce offspring. Here, somatic cells respond to specific signals that instruct them whether to grow, remain as they are, or die. If cells ignore these signals and multiply inappropriately, their uncontrolled growth causes cancer.
Such cooperation within species may have evolved through the process of kin selection, which is where one organism acts to help raise a relative's offspring. This activity is selected for because if the "helping" individual contains alleles which promote the helping activity, it is likely that its kin will "also" contain these alleles and thus those alleles will be passed on. Other processes that may promote cooperation include group selection, where cooperation provides benefits to a group of organisms.
Speciation.
Speciation is the process where a species diverges into two or more descendant species.
There are multiple ways to define the concept of "species." The choice of definition is dependent on the particularities of the species concerned. For example, some species concepts apply more readily toward sexually reproducing organisms while others lend themselves better toward asexual organisms. Despite the diversity of various species concepts, these various concepts can be placed into one of three broad philosophical approaches: interbreeding, ecological and phylogenetic. The Biological Species Concept (BSC) is a classic example of the interbreeding approach. Defined by Ernst Mayr in 1942, the BSC states that "species are groups of actually or potentially interbreeding natural populations, which are reproductively isolated from other such groups." Despite its wide and long-term use, the BSC like others is not without controversy, for example because these concepts cannot be applied to prokaryotes, and this is called the species problem. Some researchers have attempted a unifying monistic definition of species, while others adopt a pluralistic approach and suggest that there may be different ways to logically interpret the definition of a species.
Barriers to reproduction between two diverging sexual populations are required for the populations to become new species. Gene flow may slow this process by spreading the new genetic variants also to the other populations. Depending on how far two species have diverged since their most recent common ancestor, it may still be possible for them to produce offspring, as with horses and donkeys mating to produce mules. Such hybrids are generally infertile. In this case, closely related species may regularly interbreed, but hybrids will be selected against and the species will remain distinct. However, viable hybrids are occasionally formed and these new species can either have properties intermediate between their parent species, or possess a totally new phenotype. The importance of hybridisation in producing new species of animals is unclear, although cases have been seen in many types of animals, with the gray tree frog being a particularly well-studied example.
Speciation has been observed multiple times under both controlled laboratory conditions and in nature. In sexually reproducing organisms, speciation results from reproductive isolation followed by genealogical divergence. There are four mechanisms for speciation. The most common in animals is allopatric speciation, which occurs in populations initially isolated geographically, such as by habitat fragmentation or migration. Selection under these conditions can produce very rapid changes in the appearance and behaviour of organisms. As selection and drift act independently on populations isolated from the rest of their species, separation may eventually produce organisms that cannot interbreed.
The second mechanism of speciation is peripatric speciation, which occurs when small populations of organisms become isolated in a new environment. This differs from allopatric speciation in that the isolated populations are numerically much smaller than the parental population. Here, the founder effect causes rapid speciation after an increase in inbreeding increases selection on homozygotes, leading to rapid genetic change.
The third mechanism of speciation is parapatric speciation. This is similar to peripatric speciation in that a small population enters a new habitat, but differs in that there is no physical separation between these two populations. Instead, speciation results from the evolution of mechanisms that reduce gene flow between the two populations. Generally this occurs when there has been a drastic change in the environment within the parental species' habitat. One example is the grass "Anthoxanthum odoratum", which can undergo parapatric speciation in response to localised metal pollution from mines. Here, plants evolve that have resistance to high levels of metals in the soil. Selection against interbreeding with the metal-sensitive parental population produced a gradual change in the flowering time of the metal-resistant plants, which eventually produced complete reproductive isolation. Selection against hybrids between the two populations may cause "reinforcement", which is the evolution of traits that promote mating within a species, as well as character displacement, which is when two species become more distinct in appearance.
Finally, in sympatric speciation species diverge without geographic isolation or changes in habitat. This form is rare since even a small amount of gene flow may remove genetic differences between parts of a population. Generally, sympatric speciation in animals requires the evolution of both genetic differences and non-random mating, to allow reproductive isolation to evolve.
One type of sympatric speciation involves crossbreeding of two related species to produce a new hybrid species. This is not common in animals as animal hybrids are usually sterile. This is because during meiosis the homologous chromosomes from each parent are from different species and cannot successfully pair. However, it is more common in plants because plants often double their number of chromosomes, to form polyploids. This allows the chromosomes from each parental species to form matching pairs during meiosis, since each parent's chromosomes are represented by a pair already. An example of such a speciation event is when the plant species "Arabidopsis thaliana" and "Arabidopsis arenosa" crossbred to give the new species "Arabidopsis suecica". This happened about 20,000 years ago, and the speciation process has been repeated in the laboratory, which allows the study of the genetic mechanisms involved in this process. Indeed, chromosome doubling within a species may be a common cause of reproductive isolation, as half the doubled chromosomes will be unmatched when breeding with undoubled organisms.
Speciation events are important in the theory of punctuated equilibrium, which accounts for the pattern in the fossil record of short "bursts" of evolution interspersed with relatively long periods of stasis, where species remain relatively unchanged. In this theory, speciation and rapid evolution are linked, with natural selection and genetic drift acting most strongly on organisms undergoing speciation in novel habitats or small populations. As a result, the periods of stasis in the fossil record correspond to the parental population and the organisms undergoing speciation and rapid evolution are found in small populations or geographically restricted habitats and therefore rarely being preserved as fossils.
Extinction.
Extinction is the disappearance of an entire species. Extinction is not an unusual event, as species regularly appear through speciation and disappear through extinction. Nearly all animal and plant species that have lived on Earth are now extinct, and extinction appears to be the ultimate fate of all species. These extinctions have happened continuously throughout the history of life, although the rate of extinction spikes in occasional mass extinction events. The CretaceousâPaleogene extinction event, during which the non-avian dinosaurs went extinct, is the most well-known, but the earlier PermianâTriassic extinction event was even more severe, with approximately 96% of all marine species driven to extinction. The Holocene extinction event is an ongoing mass extinction associated with humanity's expansion across the globe over the past few thousand years. Present-day extinction rates are 100â1000 times greater than the background rate and up to 30% of current species may be extinct by the mid 21st century. Human activities are now the primary cause of the ongoing extinction event; global warming may further accelerate it in the future.
The role of extinction in evolution is not very well understood and may depend on which type of extinction is considered. The causes of the continuous "low-level" extinction events, which form the majority of extinctions, may be the result of competition between species for limited resources (the competitive exclusion principle). If one species can out-compete another, this could produce species selection, with the fitter species surviving and the other species being driven to extinction. The intermittent mass extinctions are also important, but instead of acting as a selective force, they drastically reduce diversity in a nonspecific manner and promote bursts of rapid evolution and speciation in survivors.
Evolutionary history of life.
Origin of life.
The Earth is about 4.54 billion years old. The earliest undisputed evidence of life on Earth dates from at least 3.5 billion years ago, during the Eoarchean Era after a geological crust started to solidify following the earlier molten Hadean Eon. Microbial mat fossils have been found in 3.48 billion-year-old sandstone in Western Australia. Other early physical evidence of a biogenic substance is graphite in 3.7 billion-year-old metasedimentary rocks discovered in Western Greenland as well as "remains of biotic life" found in 4.1 billion-year-old rocks in Western Australia. According to one of the researchers, "If life arose relatively quickly on Earth â¦ then it could be common in the universe." 
More than 99 percent of all species, amounting to over five billion species, that ever lived on Earth are estimated to be extinct. Estimates on the number of Earth's current species range from 10 million to 14 million, of which about 1.2 million have been documented and over 86 percent have not yet been described.
Highly energetic chemistry is thought to have produced a self-replicating molecule around 4 billion years ago, and half a billion years later the last common ancestor of all life existed. The current scientific consensus is that the complex biochemistry that makes up life came from simpler chemical reactions. The beginning of life may have included self-replicating molecules such as RNA and the assembly of simple cells.
Common descent.
All organisms on Earth are descended from a common ancestor or ancestral gene pool. Current species are a stage in the process of evolution, with their diversity the product of a long series of speciation and extinction events. The common descent of organisms was first deduced from four simple facts about organisms: First, they have geographic distributions that cannot be explained by local adaptation. Second, the diversity of life is not a set of completely unique organisms, but organisms that share morphological similarities. Third, vestigial traits with no clear purpose resemble functional ancestral traits and finally, that organisms can be classified using these similarities into a hierarchy of nested groupsâsimilar to a family tree. However, modern research has suggested that, due to horizontal gene transfer, this "tree of life" may be more complicated than a simple branching tree since some genes have spread independently between distantly related species.
Past species have also left records of their evolutionary history. Fossils, along with the comparative anatomy of present-day organisms, constitute the morphological, or anatomical, record. By comparing the anatomies of both modern and extinct species, paleontologists can infer the lineages of those species. However, this approach is most successful for organisms that had hard body parts, such as shells, bones or teeth. Further, as prokaryotes such as bacteria and archaea share a limited set of common morphologies, their fossils do not provide information on their ancestry.
More recently, evidence for common descent has come from the study of biochemical similarities between organisms. For example, all living cells use the same basic set of nucleotides and amino acids. The development of molecular genetics has revealed the record of evolution left in organisms' genomes: dating when species diverged through the molecular clock produced by mutations. For example, these DNA sequence comparisons have revealed that humans and chimpanzees share 98% of their genomes and analysing the few areas where they differ helps shed light on when the common ancestor of these species existed.
Evolution of life.
Prokaryotes inhabited the Earth from approximately 3â4 billion years ago. No obvious changes in morphology or cellular organisation occurred in these organisms over the next few billion years. The eukaryotic cells emerged between 1.6â2.7 billion years ago. The next major change in cell structure came when bacteria were engulfed by eukaryotic cells, in a cooperative association called endosymbiosis. The engulfed bacteria and the host cell then underwent coevolution, with the bacteria evolving into either mitochondria or hydrogenosomes. Another engulfment of cyanobacterial-like organisms led to the formation of chloroplasts in algae and plants.
The history of life was that of the unicellular eukaryotes, prokaryotes and archaea until about 610 million years ago when multicellular organisms began to appear in the oceans in the Ediacaran period. The evolution of multicellularity occurred in multiple independent events, in organisms as diverse as sponges, brown algae, cyanobacteria, slime moulds and myxobacteria. In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule called GK-PID may have allowed organisms to go from a single cell organism to one of many cells.
Soon after the emergence of these first multicellular organisms, a remarkable amount of biological diversity appeared over approximately 10 million years, in an event called the Cambrian explosion. Here, the majority of types of modern animals appeared in the fossil record, as well as unique lineages that subsequently became extinct. Various triggers for the Cambrian explosion have been proposed, including the accumulation of oxygen in the atmosphere from photosynthesis. 
About 500 million years ago, plants and fungi colonised the land and were soon followed by arthropods and other animals. Insects were particularly successful and even today make up the majority of animal species. Amphibians first appeared around 364 million years ago, followed by early amniotes and birds around 155 million years ago (both from "reptile"-like lineages), mammals around 129 million years ago, homininae around 10 million years ago and modern humans around 250,000 years ago. However, despite the evolution of these large animals, smaller organisms similar to the types that evolved early in this process continue to be highly successful and dominate the Earth, with the majority of both biomass and species being prokaryotes.
Applications.
Concepts and models used in evolutionary biology, such as natural selection, have many applications.
Artificial selection is the intentional selection of traits in a population of organisms. This has been used for thousands of years in the domestication of plants and animals. More recently, such selection has become a vital part of genetic engineering, with selectable markers such as antibiotic resistance genes being used to manipulate DNA. Proteins with valuable properties have evolved by repeated rounds of mutation and selection (for example modified enzymes and new antibodies) in a process called directed evolution.
Understanding the changes that have occurred during an organism's evolution can reveal the genes needed to construct parts of the body, genes which may be involved in human genetic disorders. For example, the Mexican tetra is an albino cavefish that lost its eyesight during evolution. Breeding together different populations of this blind fish produced some offspring with functional eyes, since different mutations had occurred in the isolated populations that had evolved in different caves. This helped identify genes required for vision and pigmentation.
Many human diseases are not static phenomena, but capable of evolution. Viruses, bacteria, fungi and cancers evolve to be resistant to host immune defences, as well as pharmaceutical drugs. These same problems occur in agriculture with pesticide and herbicide resistance. It is possible that we are facing the end of the effective life of most of available antibiotics and predicting the evolution and evolvability of our pathogens and devising strategies to slow or circumvent it is requiring deeper knowledge of the complex forces driving evolution at the molecular level.
In computer science, simulations of evolution using evolutionary algorithms and artificial life started in the 1960s and were extended with simulation of artificial selection. Artificial evolution became a widely recognised optimisation method as a result of the work of Ingo Rechenberg in the 1960s. He used evolution strategies to solve complex engineering problems. Genetic algorithms in particular became popular through the writing of John Henry Holland. Practical applications also include automatic evolution of computer programmes. Evolutionary algorithms are now used to solve multi-dimensional problems more efficiently than software produced by human designers and also to optimise the design of systems.
Social and cultural responses.
In the 19th century, particularly after the publication of "On the Origin of Species" in 1859, the idea that life had evolved was an active source of academic debate centred on the philosophical, social and religious implications of evolution. Today, the modern evolutionary synthesis is accepted by a vast majority of scientists. However, evolution remains a contentious concept for some theists.
While various religions and denominations have reconciled their beliefs with evolution through concepts such as theistic evolution, there are creationists who believe that evolution is contradicted by the creation myths found in their religions and who raise various objections to evolution. As had been demonstrated by responses to the publication of "Vestiges of the Natural History of Creation" in 1844, the most controversial aspect of evolutionary biology is the implication of human evolution that humans share common ancestry with apes and that the mental and moral faculties of humanity have the same types of natural causes as other inherited traits in animals. In some countries, notably the United States, these tensions between science and religion have fuelled the current creationâevolution controversy, a religious conflict focusing on politics and public education. While other scientific fields such as cosmology and Earth science also conflict with literal interpretations of many religious texts, evolutionary biology experiences significantly more opposition from religious literalists.
The teaching of evolution in American secondary school biology classes was uncommon in most of the first half of the 20th century. The Scopes Trial decision of 1925 caused the subject to become very rare in American secondary biology textbooks for a generation, but it was gradually re-introduced later and became legally protected with the 1968 "Epperson v. Arkansas" decision. Since then, the competing religious belief of creationism was legally disallowed in secondary school curricula in various decisions in the 1970s and 1980s, but it returned in pseudoscientific form as intelligent design (ID), to be excluded once again in the 2005 "Kitzmiller v. Dover Area School District" case.
Further reading.
Introductory reading
Advanced reading

</doc>
<doc id="9238" url="https://en.wikipedia.org/wiki?curid=9238" title="Ernst Mayr">
Ernst Mayr

Ernst Walter Mayr (; 5 July 1904 â 3 February 2005) was one of the 20th century's leading evolutionary biologists. He was also a renowned taxonomist, tropical explorer, ornithologist, philospher of biology, and historian of science. His work contributed to the conceptual revolution that led to the modern evolutionary synthesis of Mendelian genetics, systematics, and Darwinian evolution, and to the development of the biological species concept.
Although Charles Darwin and others posited that multiple species could evolve from a single common ancestor, the mechanism by which this occurred was not understood, creating the "species problem". Ernst Mayr approached the problem with a new definition for species. In his book "Systematics and the Origin of Species" (1942) he wrote that a species is not just a group of morphologically similar individuals, but a group that can breed only among themselves, excluding all others. When populations within a species become isolated by geography, feeding strategy, mate choice, or other means, they may start to differ from other populations through genetic drift and natural selection, and over time may evolve into new species. The most significant and rapid genetic reorganization occurs in extremely small populations that have been isolated (as on islands).
His theory of peripatric speciation (a more precise form of allopatric speciation which he advanced), based on his work on birds, is still considered a leading mode of speciation, and was the theoretical underpinning for the theory of punctuated equilibrium, proposed by Niles Eldredge and Stephen Jay Gould. Mayr is sometimes credited with inventing modern philosophy of biology, particularly the part related to evolutionary biology, which he distinguished from physics due to its introduction of (natural) history into science.
Biography.
Mayr was the second son of Helene Pusinelli and Dr. Otto Mayr. His father was a jurist (District Prosecuting
Attorney at WÃ¼rzburg) but took an interest in natural history and took the children out on field trips. He learnt all the local birds in WÃ¼rzburg from his elder brother Otto. He also had access to a natural history magazine for amateurs, "Kosmos". His father died just before he was thirteen. The family then moved to Dresden and he studied at the Staatsgymnasium (âRoyal Gymnasiumâ until 1918) in Dresden-Neustadt and completed his high school education there. In April 1922, while still in high school, he joined the newly founded Saxony Ornithologistsâ Association. Here he met Rudolf Zimmermann, who became his ornithological mentor. In February 1923, Mayr passed his high school examination (Abitur) and his mother rewarded him with a pair of binoculars.
On 23 March 1923 on the lakes of Moritzburg, the Frauenteich, he spotted what he identified as a red-crested pochard. The species had not been seen in Saxony since 1845 and the local club argued about the identity. Raimund Schelcher (1891â1979) of the club then suggested that Mayr visit his classmate Erwin Stresemann on his way to Greifswald, where Mayr was to begin his medical studies. After a tough interrogation, Stresemann accepted and published the sighting as authentic. Stresemann was very impressed and suggested that, between semesters, Mayr could work as a volunteer in the ornithological section of the museum. Mayr wrote about this event, "It was as if someone had given me the key to heaven." He entered the University of Greifswald in 1923 and, according to Mayr himself, "took the medical curriculum (to satisfy a family tradition) but after only a year, he decided to leave medicine and enrolled at the Faculty of Biological Sciences." Mayr was endlessly interested in ornithology and "chose Greifswald at the Baltic for my studies for no other reason than that ... it was situated in the ornithologically most interesting area." Although he ostensibly planned to become a physician, he was "first and foremost an ornithologist." During the first semester break Stresemann gave him a test to identify treecreepers and Mayr was able to identify most of the specimens correctly. Stresemann declared that Mayr "was a born systematist". In 1925, Stresemann suggested that he give up his medical studies, in fact he should leave the faculty of medicine and enrole into the faculty of Biology and then join the Berlin Museum with the prospect of bird-collecting trips to the tropics, on the condition that he completed his doctoral studies in 16 months. Mayr completed his doctorate in ornithology at the University of Berlin under Dr. Carl Zimmer, who was a full professor (Ordentlicher Professor), on 24 June 1926 at the age of 21. On 1 July he accepted the position offered to him at the museum for a monthly salary of 330.54 Reichsmark.
At the International Zoological Congress at Budapest in 1927, Mayr was introduced by Stresemann to banker and naturalist Walter Rothschild, who asked him to undertake an expedition to New Guinea on behalf of himself and the American Museum of Natural History in New York. In New Guinea, Mayr collected several thousand bird skins (he named 26 new bird species during his lifetime) and, in the process also named 38 new orchid species. During his stay in New Guinea, he was invited to accompany the Whitney South Seas Expedition to the Solomon Islands. Also, while in New Guinea, he visited the Lutheran missionaries Otto Thiele and Christian Keyser, in the Finschhafen district; there, while in conversation with his hosts, he uncovered the discrepancies in Hermann Detzner's popular book "Four Years Among the Cannibals in German Guinea from 1914 to the Truce", in which Detzner claimed to have seen the interior, discovered several species of flora and fauna, while remaining only steps ahead of the Australian patrols sent to capture him.
He returned to Germany in 1930, and in 1931 he accepted a curatorial position at the American Museum of Natural History, where he played the important role of brokering and acquiring the Walter Rothschild collection of bird skins, which was being sold in order to pay off a blackmailer. During his time at the museum he produced numerous publications on bird taxonomy, and in 1942 his first book "Systematics and the Origin of Species", which completed the evolutionary synthesis started by Darwin.
After Mayr was appointed at the American Museum of Natural History, he influenced American ornithological research by mentoring young birdwatchers. Mayr was surprised at the differences between American and German birding societies. He noted that the German society was "far more scientific, far more interested in life histories and breeding bird species, as well as in reports on recent literature."
Mayr organized a monthly seminar under the auspices of the Linnean Society of New York. Under the influence of J.A. Allen, Frank Chapman, and Jonathan Dwight, the society concentrated on taxonomy and later became a clearing house for bird banding and sight records.
Mayr encouraged his Linnaean Society seminar participants to take up a specific research project of their own. Under Mayr's influence one of them, Joseph Hickey, went on to write "A Guide to Birdwatching" (1943). Hickey remembered later, "Mayr was our age and invited on all our field trips. The heckling of this German foreigner was tremendous, but he gave tit for tat, and any modern picture of Dr E. Mayr as a very formal person does not square with my memory of the 1930s. He held his own." A group of eight young birdwatchers from The Bronx later became the Bronx County Bird Club, led by Ludlow Griscom. "Everyone should have a problem" was the way one Bronx County Bird Club member recalled Mayr's refrain.
Mayr said of his own involvement with the local birdwatchers: "In those early years in New York when I was a stranger in a big city, it was the companionship and later friendship which I was offered in the Linnean Society that was the most important thing in my life."
Mayr also greatly influenced the American ornithologist Margaret Morse Nice. Mayr encouraged her to correspond with European ornithologists and helped her in her landmark study on song sparrows. Nice wrote to Joseph Grinnell in 1932, trying to get foreign literature reviewed in the "Condor": "Too many American ornithologists have despised the study of the living bird; the magazines and books that deal with the subject abound in careless statements, anthropomorphic interpretations, repetition of ancient errors, and sweeping conclusions from a pitiful array of facts.Â  ... in Europe the study of the living bird is taken seriously. We could learn a great deal from their writing." Mayr ensured that Nice could publish her two-volume "Studies in the Life History of the Song Sparrow". He found her a publisher, and her book was reviewed by Aldo Leopold, Joseph Grinnell, and Jean Delacour. Nice dedicated her book to "My Friend Ernst Mayr."
Mayr joined the faculty of Harvard University in 1953, where he also served as director of the Museum of Comparative Zoology from 1961 to 1970. He retired in 1975 as emeritus professor of zoology, showered with honors. Following his retirement, he went on to publish more than 200 articles, in a variety of journalsâmore than some reputable scientists publish in their entire careers; 14 of his 25 books were published after he was 65. Even as a centenarian, he continued to write books. On his 100th birthday, he was interviewed by "Scientific American" magazine. Mayr died on 3 February 2005 in his retirement home in Bedford, Massachusetts after a short illness. His wife, Margarete, died in 1990. He was survived by two daughters, five grandchildren and 10 great-grandchildren.
The awards that Mayr received include the National Medal of Science, the Balzan Prize, the Sarton Medal of the History of Science Society, the International Prize for Biology, the Loye and Alden Miller Research Award, and the Lewis Thomas Prize for Writing about Science. In 1939 he was elected a Corresponding Member of the Royal Australasian Ornithologists Union. He was awarded the 1946 Leidy Award from the Academy of Natural Sciences of Philadelphia. He was awarded the Linnean Society of London's prestigious Darwin-Wallace Medal in 1958 and the Linnaean Society of New York's inaugural Eisenmann Medal in 1983. For his work, "Animal Species and Evolution", he was awarded the Daniel Giraud Elliot Medal from the National Academy of Sciences in 1967. Mayr was elected a Foreign Member of the Royal Society (ForMemRS) in 1988. In 1995 he received the Benjamin Franklin Medal for Distinguished Achievement in the Sciences of the American Philosophical Society.
Mayr never won a Nobel Prize, but he noted that there is no prize for evolutionary biology and that Darwin would not have received one, either. (In fact, there is no Nobel Prize for biology.) Mayr did win a 1999 Crafoord Prize. It honors basic research in fields that do not qualify for Nobel Prizes and is administered by the same organization as the Nobel Prize.
Mayr was co-author of six global reviews of bird species new to science (listed below).
Mayr said he was an atheist towards "the idea of a personal God" because "there is nothing that supports "
Mayr's ideas.
As a traditionally trained biologist, Mayr was often highly critical of early mathematical approaches to evolution such as those of J.B.S. Haldane, famously calling such approaches "beanbag genetics" in 1959. He maintained that factors such as reproductive isolation had to be taken into account. In a similar fashion, Mayr was also quite critical of molecular evolutionary studies such as those of Carl Woese. Current molecular studies in evolution and speciation indicate that although allopatric speciation is the norm, there are numerous cases of sympatric speciation in groups with greater mobility (such as birds). The precise mechanisms of sympatric speciation, however, are usually a form of microallopatry enabled by variations in niche occupancy among individuals within a population.
In many of his writings, Mayr rejected reductionism in evolutionary biology, arguing that evolutionary pressures act on the whole organism, not on single genes, and that genes can have different effects depending on the other genes present. He advocated a study of the whole genome rather than of isolated genes only. After articulating the biological species concept in 1942, Mayr played a central role in the species problem debate over what was the best species concept. He staunchly defended the biological species concept against the many definitions of "species" that others proposed.
Mayr was an outspoken defender of the scientific method, and one known to sharply critique science on the edge. As a notable example, in 1995, he criticized the Search for Extra-Terrestrial Intelligence (SETI) as conducted by fellow Harvard professor Paul Horowitz as being a waste of university and student resources, for its inability to address and answer a scientific question. Over 60 eminent scientists led by Carl Sagan rebutted the criticism.
Mayr rejected the idea of a gene-centered view of evolution and starkly but politely criticized Richard Dawkins' ideas:
Mayr insisted that it is the entire genome, rather than individual genes that should be considered as the target of selection:

</doc>
<doc id="9239" url="https://en.wikipedia.org/wiki?curid=9239" title="Europe">
Europe

Europe ( or ) is a continent that comprises the westernmost part of Eurasia. Europe is bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean Sea to the south. To the east and southeast, Europe is generally considered as separated from Asia by the watershed divides of the Ural and Caucasus Mountains, the Ural River, the Caspian and Black Seas, and the waterways of the Turkish Straits. Yet the borders of Europeâa concept dating back to classical antiquityâare arbitrary, as the primarily physiographic term "continent" also incorporates cultural and political elements.
Europe is the world's second-smallest continent by surface area, covering about or 2% of the Earth's surface and about 6.8% of its land area. Of Europe's approximately 50 countries, Russia is by far the largest by both area and population, taking up 40% of the continent (although the country has territory in both Europe and Asia), while the Vatican City is the smallest. Europe is the third-most populous continent after Asia and Africa, with a population of 739â743Â million or about 11% of the world's population. Europe has a climate heavily affected by warm Atlantic currents, tempering winters and enabling warm summers on most of the continent, even on latitudes that have severe climates in North America and Asia. Further from the Atlantic, seasonal differences increase, but the mildness of the climate remains.
Europe, in particular ancient Greece, is the birthplace of Western civilization. The fall of the Western Roman Empire, during the migration period, marked the end of ancient history and the beginning of an era known as the "Middle Ages". The Renaissance humanism, exploration, art, and science led the "old continent", and eventually the rest of the world, to the modern era. From this period onwards, Europe played a predominant role in global affairs. Between the 16th and 20th centuries, European nations controlled at various times the Americas, most of Africa, Oceania, and the majority of Asia.
The Industrial Revolution, which began in the United Kingdom at the end of the 18th century, gave rise to radical economic, cultural, and social change in Western Europe, and eventually the wider world. Both world wars were largely focused upon Europe, contributing to a decline in Western European dominance in world affairs by the mid-20th century as the United States and Soviet Union took prominence. During the Cold War, Europe was divided along the Iron Curtain between NATO in the west and the Warsaw Pact in the east, until the revolutions of 1989 and fall of the Berlin Wall.
European integration led to the formation of the European Union, a political entity that lies between a confederation and a federation. The EU originated in Western Europe but has been expanding eastward since the fall of the Soviet Union in 1991. The currency of the European Union, the Euro, is the most commonly used among Europeans and the EU's Schengen Area abolishes border and immigration controls among most of its member states.
Definition.
The use of the term "Europe" has developed gradually throughout history. In antiquity, the Greek historian Herodotus mentioned that the world had been divided by unknown persons into three parts, Europe, Asia, and Libya (Africa), with the Nile and the River Phasis forming their boundariesâthough he also states that some considered the River Don, rather than the Phasis, as the boundary between Europe and Asia. Europe's eastern frontier was defined in the 1st century by geographer Strabo at the River Don. The "Book of Jubilees" described the continents as the lands given by Noah to his three sons; Europe was defined as stretching from the Pillars of Hercules at the Strait of Gibraltar, separating it from North Africa, to the Don, separating it from Asia.
A cultural definition of Europe as the lands of Latin Christendom coalesced in the 8th century, signifying the new cultural condominium created through the confluence of Germanic traditions and Christian-Latin culture, defined partly in contrast with Byzantium and Islam, and limited to northern Iberia, the British Isles, France, Christianised western Germany, the Alpine regions and northern and central Italy. The concept is one of the lasting legacies of the Carolingian Renaissance: "Europa" often figures in the letters of Charlemagne's court scholar, Alcuin. This divisionâas much cultural as geographicalâwas used until the Late Middle Ages, when it was challenged by the Age of Discovery. The problem of redefining Europe was finally resolved in 1730 when, instead of waterways, the Swedish geographer and cartographer von Strahlenberg proposed the Ural Mountains as the most significant eastern boundary, a suggestion that found favour in Russia and throughout Europe.
Europe is now generally defined by geographers as the western part of Eurasia, with its boundaries marked by large bodies of water to the north, west and south; Europe's limits to the far east are usually taken to be the Urals, the Ural River, and the Caspian Sea; to the southeast, including the Caucasus Mountains, the Black Sea and the waterways connecting the Black Sea to the Mediterranean Sea.
Islands are generally grouped with the nearest continental landmass, hence Iceland is generally considered to be part of Europe, while the nearby island of Greenland is usually assigned to North America. Nevertheless, there are some exceptions based on sociopolitical and cultural differences. Cyprus is closest to Anatolia (or Asia Minor), but is usually considered part of Europe both culturally and politically and currently is a member state of the EU. Malta was considered an island of North Africa for centuries.
The geographic boundary drawn between Europe and Asia in 1730 follows no international boundaries. As a result, attempts to organise Europe along political or economic lines have resulted in uses of the name in a geopolitically limiting way to refer only to the 28 member states of the European Union. Conversely, Europe has also been used in a very expansive way by the Council of Europe which has 47 member countries, some of which territorially over-reach the Ural and Bosphorus lines to include all of Russia and Turkey. In addition, people in the British Isles may refer to "continental" or "mainland" Europe as Europe.
Etymology.
In classical Greek mythology, Europa was a Phoenician princess whom Zeus abducted after assuming the form of a dazzling white bull. He took her to the island of Crete where she gave birth to Minos, Rhadamanthus, and Sarpedon. For Homer, Europe (, ""; see also List of Greek place names) was a mythological queen of Crete, not a geographical designation.
The etymology of "Europe" is uncertain. One theory suggests that it is derived from the Greek Îµá½ÏÏÏ ("eurus"), meaning "wide, broad" and á½¤Ï/á½ Ï-/á½ÏÏ- ("Åps"/"Åp"-/"opt-"), meaning "eye, face, countenance", hence ', "wide-gazing", "broad of aspect" (compare with "glaukÅpis" (Î³Î»Î±ÏÎºá¿¶ÏÎ¹Ï 'grey-eyed') Athena or "boÅp"'is" (Î²Î¿á½ ÏÎ¹Ï 'ox-eyed') Hera). "Broad" has been an epithet of Earth herself in the reconstructed Proto-Indo-European religion. Another theory suggests that it is based on a Semitic word such as the Akkadian "erebu" meaning "to go down, set" (in reference to the sun), cognate to Phoenician " 'ereb" "evening; west" and Arabic Maghreb, Hebrew "ma'arav" (see also "Erebus", PIE "*hregÊ·os", "darkness"). Martin Litchfield West states that "phonologically, the match between Europa's name and any form of the Semitic word is very poor". However, Michael A. Barry, professor in Princeton University's Near Eastern Studies Department, finds the mention of the word "Ereb" on an Assyrian stele with the meaning of "night", "he country o sunset", in opposition to "Asu" "he country o sunrise", i.e. Asia (Anatolia coming equally from á¼Î½Î±ÏÎ¿Î»Î®, "(sun)rise", "east"). In the "Homeric Hymns" written in the seventh century BC, "EurÃ´pÃ¨" still represents, the western shore of the Aegean Sea.
Whatever the origin of the name of the mythological figure, Îá½ÏÏÏÎ· is first used as a geographical term in the 6th century BC, by Greek geographers such as Anaximander and Hecataeus. Anaximander placed the boundary between Asia and Europe along the Phasis River (the modern Rioni) in the Caucasus, a convention still followed by Herodotus in the 5th century BC. But the convention received by the Middle Ages and surviving into modern usage is that of the Roman era used by Roman era authors such as Posidonius, Strabo and Ptolemy,
who took the Tanais (the modern Don River) as the boundary.
The term "Europe" is first used for a cultural sphere in the Carolingian Renaissance of the 9th century. From that time, the term designated the sphere of influence of the Western Church, as opposed to both the Eastern Orthodox churches and to the Islamic world. The modern convention, enlarging the area of "Europe" somewhat to the east and the southeast, develops in the 19th century.
Most major world languages use words derived from "Europa" to refer to the continent. Chinese, for example, uses the word (æ­æ´²/æ¬§æ´²); a similar Chinese-derived term is also sometimes used in Japanese such as in the Japanese name of the European Union, , despite the katakana being more commonly used. However, in some Turkic languages the originally Persian name "Frangistan" (land of the Franks) is used casually in referring to much of Europe, besides official names such as "Avrupa" or "Evropa".
History.
Prehistory.
"Homo erectus georgicus", which lived roughly 1.8Â million years ago in Georgia, is the earliest hominid to have been discovered in Europe. Other hominid remains, dating back roughly 1Â million years, have been discovered in Atapuerca, Spain. Neanderthal man (named after the Neandertal valley in Germany) appeared in Europe 150,000 years ago and disappeared from the fossil record about 28,000 BC, with this extinction probably due to climate change, and their final refuge being present-day Portugal. The Neanderthals were supplanted by modern humans (Cro-Magnons), who appeared in Europe around 43 to 40 thousand years ago.
The European Neolithic periodâmarked by the cultivation of crops and the raising of livestock, increased numbers of settlements and the widespread use of potteryâbegan around 7000 BC in Greece and the Balkans, probably influenced by earlier farming practices in Anatolia and the Near East. It spread from the Balkans along the valleys of the Danube and the Rhine (Linear Pottery culture) and along the Mediterranean coast (Cardial culture). Between 4500 and 3000 BC, these central European neolithic cultures developed further to the west and the north, transmitting newly acquired skills in producing copper artefacts. In Western Europe the Neolithic period was characterised not by large agricultural settlements but by field monuments, such as causewayed enclosures, burial mounds and megalithic tombs. The Corded Ware cultural horizon flourished at the transition from the Neolithic to the Chalcolithic. During this period giant megalithic monuments, such as the Megalithic Temples of Malta and Stonehenge, were constructed throughout Western and Southern Europe.
The European Bronze Age began c. 3200 BC in Greece with the Minoan civilization on Crete, the first advanced civilization in Europe. The Minoans were followed by the Myceneans, who collapsed suddenly around 1200 BC, ushering the European Iron Age. Iron Age colonisation by the Greeks and Phoenicians gave rise to early Mediterranean cities. Early Iron Age Italy and Greece from around the 8th century BC gradually gave rise to historical Classical antiquity, whose beginning is sometimes dated to 776 BC, the year the first Olympic Games.
Classical antiquity.
Ancient Greece was the founding culture of Western civilisation. Western democratic and individualistic culture are often attributed to Ancient Greece. The Greeks city-state, the polis, was the fundamental political unit of classical Greece. In 508 BC, Cleisthenes instituted the world's first democratic system of government in Athens. The Greek political ideals were rediscovered in the late 18th century by European philosophers and idealists. Greece also generated many cultural contributions: in philosophy, humanism and rationalism under Aristotle, Socrates and Plato; in history with Herodotus and Thucydides; in dramatic and narrative verse, starting with the epic poems of Homer; in drama with Sophocles and Euripides, in medicine with Hippocrates and Galen; and in science with Pythagoras, Euclid and Archimedes. In the course of the 5th century BC, several of the Greek city states would ultimately check the Achaemenid Persian advance in Europe through the Greco-Persian Wars, considered a pivotal moment in world history, as the 50 years of peace that followed are known as Golden Age of Athens, the seminal period of ancient Greece that laid many of the foundations of Western civilization.
Greece was followed by Rome, which left its mark on law, politics, language, engineering, architecture, government and many more key aspects in western civilisation. Expanding from their base in Italy beginning in the 3rd century BC, the Romans gradually expanded to eventually rule the entire Mediterranean basin and western Europe by the turn of the millennium. The Roman Republic ended in 27 BC, when Augustus proclaimed the Roman Empire. The two centuries that followed are known as the "pax romana", a period of unprecedented peace, prosperity, and political stability in most of Europe.
The empire continued to expand under emperors such as Hadrian, Antoninus Pius, and Marcus Aurelius, who all spent time on the Empire's northern border fighting Germanic, Pictish and Scottish tribes. The Empire began to decline in the 3rd century, particularly in the west. Christianity was legalised by Constantine I in 313 AD after three centuries of imperial persecution. Constantine also permanently moved the capital of the empire from Rome to the city of Byzantium, which was renamed Constantinople in his honour (modern-day Istanbul) in 330 AD. Christianity became the sole official religion of the empire in 380 AD, and in 391-392 AD, the emperor Theodosius outlawed pagan religions. This is sometimes considered to mark the end of antiquity; alternatively antiquity is considered to end with the fall of the Western Roman Empire in 476 AD; the closure of the pagan Platonic Academy of Athens in 529 AD; or the rise of Islam in the early 7th century AD.
Early Middle Ages.
During the decline of the Roman Empire, Europe entered a long period of change arising from what historians call the "Age of Migrations". There were numerous invasions and migrations amongst the Ostrogoths, Visigoths, Goths, Vandals, Huns, Franks, Angles, Saxons, Slavs, Avars, Bulgars and, later on, the Vikings, Pechenegs, Cumans and Magyars. Renaissance thinkers such as Petrarch would later refer to this as the "Dark Ages". Isolated monastic communities were the only places to safeguard and compile written knowledge accumulated previously; apart from this very few written records survive and much literature, philosophy, mathematics, and other thinking from the classical period disappeared from Western Europe though they were preserved in the east, in the Byzantine Empire.
While the Roman empire in the west continued to decline, Roman traditions and the Roman state remained strong in the predominantly Greek-speaking Eastern Roman Empire, also known as the Byzantine Empire. During most of its existence, the Byzantine Empire was the most powerful economic, cultural, and military force in Europe. Emperor Justinian I presided over Constantinople's first golden age: he established a legal code that forms the basis of many modern legal systems, funded the construction of the Hagia Sophia, and brought the Christian church under state control.
From the 7th century onwards, Muslim Arabs started to encroach on historically Roman territory. As the Byzantines and neighbouring Sasanid Persians were severely weakened by the time due the protracted, centuries-lasting and frequent ByzantineâSasanian wars, the Muslims entirely toppled the Sasanids, and made inroads into Byzantine Asia Minor. In the mid 7th century AD, following the Muslim conquest of Persia, Islam penetrated into the Caucasus region. Over the next centuries Muslim forces took Cyprus, Malta, Crete, Sicily and parts of southern Italy. In the East, Volga Bulgaria became an Islamic state in the 10th century. Between 711 and 720, most of the Iberian Peninsula was brought under Muslim ruleÂ â save for small areas in the northwest (Asturias) and largely Basque regions in the Pyrenees. This territory, under the Arabic name Al-Andalus, became part of the expanding Umayyad Caliphate. The unsuccessful second siege of Constantinople (717) weakened the Umayyad dynasty and reduced their prestige. The Umayyads were then defeated by the Frankish leader Charles Martel at the Battle of Poitiers in 732, which ended their northward advance.
During the Dark Ages, the Western Roman Empire fell under the control of various tribes. The Germanic and Slav tribes established their domains over Western and Eastern Europe respectively. Eventually the Frankish tribes were united under ClovisÂ I. Charlemagne, a Frankish king of the Carolingian dynasty who had conquered most of Western Europe, was anointed "Holy Roman Emperor" by the Pope in 800. This led in 962 to the founding of the Holy Roman Empire, which eventually became centred in the German principalities of central Europe.
East Central Europe saw the creation of the first Slavic states and the adoption of Christianity (circa 1000 AD). The powerful West Slavic state of Great Moravia spread its territory all the way south to the Balkans, reaching its largest territorial extent under Svatopluk I and causing a series of armed conflicts with East Francia. Further south, the first South Slavic states emerged in the late 7th and 8th century and adopted Christianity: the First Bulgarian Empire, the Serbian Principality (later Kingdom and Empire), and the Duchy of Croatia (later Kingdom of Croatia). To the East, the Kievan Rus expanded from its capital in Kiev to become the largest state in Europe by the 10th century. In 988, Vladimir the Great adopted Orthodox Christianity as the religion of state.
High and Late Middle Ages.
The period between the year 1000 and 1300 is known as the High Middle Ages, during which the population of Europe experienced significant growth, culminating in the Renaissance of the 12th century. Economic growth, together with the lack of safety on the mainland trading routes, made possible the development of major commercial routes along the coast of the Mediterranean and Baltic Seas. The growing wealth and independence acquired by some coastal cities gave the Maritime Republics a leading role in the European scene.
The Middle Ages on the mainland were dominated by the two upper echelons of the social structure: the nobility and the clergy. Feudalism developed in France in the Early Middle Ages and soon spread throughout Europe. A struggle for influence between the nobility and the monarchy in England led to the writing of the Magna Carta and the establishment of a parliament. The primary source of culture in this period came from the Roman Catholic Church. Through monasteries and cathedral schools, the Church was responsible for education in much of Europe.
The Papacy reached the height of its power during the High Middle Ages. An East-West Schism in 1054 split the former Roman Empire religiously, with the Eastern Orthodox Church in the Byzantine Empire and the Roman Catholic Church in the former Western Roman Empire. In 1095 Pope Urban II called for a crusade against Muslims occupying Jerusalem and the Holy Land. In Europe itself, the Church organised the Inquisition against heretics. In Spain, the Reconquista concluded with the fall of Granada in 1492, ending over seven centuries of Islamic rule in the Iberian Peninsula.
In the east a resurgent Byzantine Empire recaptured Crete and Cyprus from the Muslims and reconquered the Balkans. Constantinople was the largest and wealthiest city in Europe from the 9th to the 12th centuries, with a population of approximately 400,000. The Empire was weakened following the defeat at Manzikert and was weakened considerably by the sack of Constantinople in 1204, during the Fourth Crusade. Although it would recover Constantinople in 1261, Byzantium fell in 1453 when Constantinople was taken by the Ottoman Empire.
In the 11th and 12th centuries, constant incursions by nomadic Turkic tribes, such as the Pechenegs and the Cuman-Kipchaks, caused a massive migration of Slavic populations to the safer, heavily forested regions of the north and temporarily halted the expansion of the Rus' state to the south and east. Like many other parts of Eurasia, these territories were overrun by the Mongols. The invaders, who became known as Tatars, were mostly Turkic-speaking peoples under Mongol suzerainty. They established the state of the Golden Horde with headquarters in Crimea, which later adopted Islam as a religion and ruled over modern-day southern and central Russia for more than three centuries. After the collapse of Mongol dominions, the first Romanian states (principalities) emerged in the 14th century: Moldova and Walachia. Previously, these territories were under the successive control of Pechenegs and Cumans. From the 12th to the 15th centuries, the Grand Duchy of Moscow grew from a small principality under Mongol rule to the largest state in Europe, overthrowing the Mongols in 1480 and eventually becoming the Tsardom of Russia. The state was consolidated under Ivan III the Great and Ivan the Terrible, steadily expanding to the east and south over the next centuries.
The Great Famine of 1315â1317 was the first crisis that would strike Europe in the late Middle Ages. The period between 1348 and 1420 witnessed the heaviest loss. The population of France was reduced by half. Medieval Britain was afflicted by 95 famines, and France suffered the effects of 75 or more in the same period. Europe was devastated in the mid-14th century by the Black Death, one of the most deadly pandemics in human history which killed an estimated 25Â million people in Europe aloneâa third of the European population at the time.
The plague had a devastating effect on Europe's social structure; it induced people to live for the moment as illustrated by Giovanni Boccaccio in "The Decameron" (1353). It was a serious blow to the Roman Catholic Church and led to increased persecution of Jews, foreigners, beggars and lepers. The plague is thought to have returned every generation with varying virulence and mortalities until the 18th century. During this period, more than 100 plague epidemics swept across Europe.
Early modern period.
The Renaissance was a period of cultural change originating in Florence and later spreading to the rest of Europe. The rise of a new humanism was accompanied by the recovery of forgotten classical Greek and Arabic knowledge from monastic libraries, often translated from Arabic into Latin. The Renaissance spread across Europe between the 14th and 16th centuries: it saw the flowering of art, philosophy, music, and the sciences, under the joint patronage of royalty, the nobility, the Roman Catholic Church, and an emerging merchant class. Patrons in Italy, including the Medici family of Florentine bankers and the Popes in Rome, funded prolific quattrocento and cinquecento artists such as Raphael, Michelangelo, and Leonardo da Vinci.
Political intrigue within the Church in the mid-14th century caused the Western Schism. During this forty-year period, two popesâone in Avignon and one in Romeâclaimed rulership over the Church. Although the schism was eventually healed in 1417, the papacy's spiritual authority had suffered greatly.
The Church's power was further weakened by the Protestant Reformation (1517â1648), initially sparked by the works of German theologian Martin Luther, an attempt to start a reform within the Church. The Reformation also damaged the Holy Roman Emperor's influence, as German princes became divided between Protestant and Roman Catholic faiths. This eventually led to the Thirty Years War (1618â1648), which crippled the Holy Roman Empire and devastated much of Germany, killing between 25 and 40 percent of its population. In the aftermath of the Peace of Westphalia, France rose to predominance within Europe.
The 17th century in southern, central and eastern Europe was a period of general decline. Central and Eastern Europe experienced more than 150 famines in a 200-year period between 1501 to 1700. From the 15th to 18th centuries, when the disintegrating khanates of the Golden Horde were conquered by Russia, Tatars from the Crimean Khanate frequently raided Eastern Slavic lands to capture slaves. Further east, the Nogai Horde and Kazakh Khanate frequently raided the Slavic-speaking areas of Russia, Ukraine and Poland for hundreds of years, until the Russian expansion and conquest of most of northern Eurasia (i.e. Eastern Europe, Central Asia and Siberia). Meanwhile, in the south, the Ottomans had conquered the Balkans by the 15th century, laying siege to Vienna in 1529. In the Battle of Lepanto in 1571, the Holy League checked Ottoman power in the Mediterranean. The Ottomans again laid siege to Vienna in 1683, but the Battle of Vienna permanently ended their advance into Europe, and marked the political hegemony of the Habsburg dynasty in central Europe.
The Renaissance and the New Monarchs marked the start of an Age of Discovery, a period of exploration, invention, and scientific development. Among the great figures of the Western scientific revolution of the 16th and 17th centuries were Copernicus, Kepler, Galileo, and Isaac Newton. According to Peter Barrett, "It is widely accepted that 'modern science' arose in the Europe of the 17th century (towards the end of the Renaissance), introducing a new understanding of the natural world." In the 15th century, Portugal and Spain, two of the greatest naval powers of the time, took the lead in exploring the world. Christopher Columbus reached the New World in 1492 and Vasco da Gama opened the ocean route to the East in 1498, and soon after the Spanish and Portuguese began establishing colonial empires in the Americas and Asia. France, the Netherlands and England soon followed in building large colonial empires with vast holdings in Africa, the Americas, and Asia.
18th and 19th centuries.
The Age of Enlightenment was a powerful intellectual movement during the 18th century promoting scientific and reason-based thoughts. Discontent with the aristocracy and clergy's monopoly on political power in France resulted in the French Revolution and the establishment of the First Republic as a result of which the monarchy and many of the nobility perished during the initial reign of terror. Napoleon Bonaparte rose to power in the aftermath of the French Revolution and established the First French Empire that, during the Napoleonic Wars, grew to encompass large parts of Europe before collapsing in 1815 with the Battle of Waterloo. Napoleonic rule resulted in the further dissemination of the ideals of the French Revolution, including that of the nation-state, as well as the widespread adoption of the French models of administration, law, and education. The Congress of Vienna, convened after Napoleon's downfall, established a new balance of power in Europe centred on the five "Great Powers": the UK, France, Prussia, Austria, and Russia. This balance would remain in place until the Revolutions of 1848, during which liberal uprisings affected all of Europe except for Russia and the UK. These revolutions were eventually put down by conservative elements and few reforms resulted. The year 1859 saw the unification of Romania, as a nation-state, from smaller principalities. In 1867, the Austro-Hungarian empire was formed; and 1871 saw the unifications of both Italy and Germany as nation-states from smaller principalities.
In parallel, the Eastern Question grew more complex ever since the Ottoman defeat in the Russo-Turkish War (1768â1774). As the dissolution of the Ottoman Empire seemed imminent, the Great Powers struggled to safeguard their strategic and commercial interests in the Ottoman domains. The Russian Empire stood to benefit from the decline, whereas the Habsburg Empire and Britain perceived the preservation of the Ottoman Empire to be in their best interests. Meanwhile, the Serbian revolution (1804) and Greek War of Independence (1821) marked the beginning of the end of Ottoman rule in the Balkans, which ended with the Balkan Wars in 1912-1913. Formal recognition of the "de facto" independent principalities of Montenegro, Serbia and Romania ensued at the Congress of Berlin in 1878.
The Industrial Revolution started in Great Britain in the last part of the 18th century and spread throughout Europe. The invention and implementation of new technologies resulted in rapid urban growth, mass employment, and the rise of a new working class. Reforms in social and economic spheres followed, including the first laws on child labour, the legalisation of trade unions, and the abolition of slavery. In Britain, the Public Health Act of 1875 was passed, which significantly improved living conditions in many British cities. Europe's population increased from about 100 million in 1700 to 400 million by 1900. The last major famine recorded in Western Europe, the Irish Potato Famine, caused death and mass emigration of millions of Irish people. In the 19th century, 70Â million people left Europe in migrations to various European colonies abroad and to the United States. Demographic growth meant that, by 1900, Europe's share of the world's population was 25%.
20th century to the present.
Two World Wars and an economic depression dominated the first half of the 20th century. World War I was fought between 1914 and 1918. It started when Archduke Franz Ferdinand of Austria was assassinated by the Yugoslav nationalist Gavrilo Princip. Most European nations were drawn into the war, which was fought between the Entente Powers (France, Belgium, Serbia, Portugal, Russia, the United Kingdom, and later Italy, Greece, Romania, and the United States) and the Central Powers (Austria-Hungary, Germany, Bulgaria, and the Ottoman Empire). The War left more than 16Â million civilians and military dead. Over 60Â million European soldiers were mobilised from 1914 to 1918.
Russia was plunged into the Russian Revolution, which threw down the Tsarist monarchy and replaced it with the communist Soviet Union. Austria-Hungary and the Ottoman Empire collapsed and broke up into separate nations, and many other nations had their borders redrawn. The Treaty of Versailles, which officially ended World War I in 1919, was harsh towards Germany, upon whom it placed full responsibility for the war and imposed heavy sanctions.
Excess deaths in Russia over the course of World War I and the Russian Civil War (including the postwar famine) amounted to a combined total of 18 million. In 1932â1933, under Stalin's leadership, confiscations of grain by the Soviet authorities contributed to the second Soviet famine which caused millions of deaths; surviving kulaks were persecuted and many sent to Gulags to do forced labour. Stalin was also responsible for the Great Purge of 1937â38 in which the NKVD executed 681,692 people; millions of people were deported and exiled to remote areas of the Soviet Union.
Economic instability, caused in part by debts incurred in the First World War and 'loans' to Germany played havoc in Europe in the late 1920s and 1930s. This and the Wall Street Crash of 1929 brought about the worldwide Great Depression. Helped by the economic crisis, social instability and the threat of communism, fascist movements developed throughout Europe placing Adolf Hitler of Nazi Germany, Francisco Franco of Spain and Benito Mussolini of Italy in power.
In 1933, Hitler became the leader of Germany and began to work towards his goal of building Greater Germany. Germany re-expanded and took back the Saarland and Rhineland in 1935 and 1936. In 1938, Austria became a part of Germany following the Anschluss. Later that year, following the Munich Agreement signed by Germany, France, the United Kingdom and Italy, Germany annexed the Sudetenland, which was a part of Czechoslovakia inhabited by ethnic Germans, and in early 1939, the remainder of Czechoslovakia was split into the Protectorate of Bohemia and Moravia, controlled by Germany, and the Slovak Republic. At the time, Britain and France preferred a policy of appeasement.
With tensions mounting between Germany and Poland over the future of Danzig, the Germans turned to the Soviets, and signed the MolotovâRibbentrop Pact, which allowed the Soviets to invade the Baltic states and parts of Poland and Romania. Germany invaded Poland on 1 September 1939, prompting France and the United Kingdom to declare war on Germany on 3 September, opening the European Theatre of World War II. The Soviet invasion of Poland started on 17 September and Poland fell soon thereafter. On 24 September, the Soviet Union attacked the Baltic countries and later, Finland. The British hoped to land at Narvik and send troops to aid Finland, but their primary objective in the landing was to encircle Germany and cut the Germans off from Scandinavian resources. Around the same time, Germany moved troops into Denmark. The Phoney War continued.
In May 1940, Germany attacked France through the Low Countries. France capitulated in June 1940. By August Germany began a bombing offensive on Britain, but failed to convince the Britons to give up. In 1941, Germany invaded the Soviet Union in the Operation Barbarossa. On 7 December 1941 Japan's attack on Pearl Harbor drew the United States into the conflict as allies of the British Empire and other allied forces.
After the staggering Battle of Stalingrad in 1943, the German offensive in the Soviet Union turned into a continual fallback. The Battle of Kursk, which involved the largest tank battle in history, was the last major German offensive on the Eastern Front. In 1944, British and American forces invaded France in the D-Day landings, opening a new front against Germany. Berlin finally fell in 1945, ending World War II in Europe. The war was the largest and most destructive in human history, with 60Â million dead across the world. More than 40Â million people in Europe had died as a result of World War II, including between 11 and 17Â million people who perished during the Holocaust. The Soviet Union lost around 27Â million people (mostly civilians) during the war, about half of all World War II casualties. By the end of World War II, Europe had more than 40Â million refugees. Several post-war expulsions in Central and Eastern Europe displaced a total of about 20Â million people.
World War I and especially World War II diminished the eminence of Western Europe in world affairs. After World War II the map of Europe was redrawn at the Yalta Conference and divided into two blocs, the Western countries and the communist Eastern bloc, separated by what was later called by Winston Churchill an "Iron Curtain". The United States and Western Europe
established the NATO alliance and later the Soviet Union and Central Europe established the Warsaw Pact.
The two new superpowers, the United States and the Soviet Union, became locked in a fifty-year-long Cold War, centred on nuclear proliferation. At the same time decolonisation, which had already started after World War I, gradually resulted in the independence of most of the European colonies in Asia and Africa.
In the 1980s the reforms of Mikhail Gorbachev and the Solidarity movement in Poland accelerated the collapse of the Eastern bloc and the end of the Cold War. Germany was reunited, after the symbolic fall of the Berlin Wall in 1989, and the maps of Central and Eastern Europe were redrawn once more.
European integration also grew after World War II. The Treaty of Rome in 1957 established the European Economic Community between six Western European states with the goal of a unified economic policy and common market. In 1967 the EEC, European Coal and Steel Community and Euratom formed the European Community, which in 1993 became the European Union. The EU established a parliament, court and central bank and introduced the euro as a unified currency. In 2004 and 2007, more Central and Eastern European countries began joining, expanding the EU to its current size of 28 European countries, and once more making Europe a major economical and political centre of power.
Geography.
Europe makes up the western fifth of the Eurasian landmass. It has a higher ratio of coast to landmass than any other continent or subcontinent. Its maritime borders consist of the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean, Black, and Caspian Seas to the south.
Land relief in Europe shows great variation within relatively small areas. The southern regions are more mountainous, while moving north the terrain descends from the high Alps, Pyrenees, and Carpathians, through hilly uplands, into broad, low northern plains, which are vast in the east. This extended lowland is known as the Great European Plain, and at its heart lies the North German Plain. An arc of uplands also exists along the north-western seaboard, which begins in the western parts of the islands of Britain and Ireland, and then continues along the mountainous, fjord-cut spine of Norway.
This description is simplified. Sub-regions such as the Iberian Peninsula and the Italian Peninsula contain their own complex features, as does mainland Central Europe itself, where the relief contains many plateaus, river valleys and basins that complicate the general trend. Sub-regions like Iceland, Britain, and Ireland are special cases. The former is a land unto itself in the northern ocean which is counted as part of Europe, while the latter are upland areas that were once joined to the mainland until rising sea levels cut them off.
Climate.
Europe lies mainly in the temperate climate zones, being subjected to prevailing westerlies. The climate is milder in comparison to other areas of the same latitude around the globe due to the influence of the Gulf Stream. The Gulf Stream is nicknamed "Europe's central heating", because it makes Europe's climate warmer and wetter than it would otherwise be. The Gulf Stream not only carries warm water to Europe's coast but also warms up the prevailing westerly winds that blow across the continent from the Atlantic Ocean.
Therefore, the average temperature throughout the year of Naples is 16Â Â°C (60.8Â Â°F), while it is only 12Â Â°C (53.6Â Â°F) in New York City which is almost on the same latitude. Berlin, Germany; Calgary, Canada; and Irkutsk, in the Asian part of Russia, lie on around the same latitude; January temperatures in Berlin average around 8Â Â°C (15Â Â°F) higher than those in Calgary, and they are almost 22Â Â°C (40Â Â°F) higher than average temperatures in Irkutsk. Similarly, northern parts of Scotland have a tempertate marine climate. The yearly average temperature in city of Inverness is 9.05 degrees Celsius (48.3 degrees Fahrenheit). However, Churchill, Manitoba, Canada, is on roughly the same latitude and has an average temperature of -6.5 degrees Celsius (20.3 degrees Fahrenheit), giving it a nearly subarctic climate.
Geology.
The geological history of Europe traces back to the formation of the Baltic Shield (Fennoscandia) and the Sarmatian craton, both around 2.25Â billion years ago, followed by the VolgoâUralia shield, the three together leading to the East European craton (â Baltica) which became a part of the supercontinent Columbia. Around 1.1Â billion years ago, Baltica and Arctica (as part of the Laurentia block) became joined to Rodinia, later resplitting around 550Â million years ago to reform as Baltica. Around 440Â million years ago Euramerica was formed from Baltica and Laurentia; a further joining with Gondwana then leading to the formation of Pangea. Around 190Â million years ago, Gondwana and Laurasia split apart due to the widening of the Atlantic Ocean. Finally, and very soon afterwards, Laurasia itself split up again, into Laurentia (North America) and the Eurasian continent. The land connection between the two persisted for a considerable time, via Greenland, leading to interchange of animal species. From around 50Â million years ago, rising and falling sea levels have determined the actual shape of Europe, and its connections with continents such as Asia. Europe's present shape dates to the late Tertiary period about five million years ago.
The geology of Europe is hugely varied and complex, and gives rise to the wide variety of landscapes found across the continent, from the Scottish Highlands to the rolling plains of Hungary. Europe's most significant feature is the dichotomy between highland and mountainous Southern Europe and a vast, partially underwater, northern plain ranging from Ireland in the west to the Ural Mountains in the east. These two halves are separated by the mountain chains of the Pyrenees and Alps/Carpathians. The northern plains are delimited in the west by the Scandinavian Mountains and the mountainous parts of the British Isles. Major shallow water bodies submerging parts of the northern plains are the Celtic Sea, the North Sea, the Baltic Sea complex and Barents Sea.
The northern plain contains the old geological continent of Baltica, and so may be regarded geologically as the "main continent", while peripheral highlands and mountainous regions in the south and west constitute fragments from various other geological continents. Most of the older geology of western Europe existed as part of the ancient microcontinent Avalonia.
Flora.
Having lived side-by-side with agricultural peoples for millennia, Europe's animals and plants have been profoundly affected by the presence and activities of man. With the exception of Fennoscandia and northern Russia, few areas of untouched wilderness are currently found in Europe, except for various national parks.
The main natural vegetation cover in Europe is mixed forest. The conditions for growth are very favourable. In the north, the Gulf Stream and North Atlantic Drift warm the continent. Southern Europe could be described as having a warm, but mild climate. There are frequent summer droughts in this region. Mountain ridges also affect the conditions. Some of these (Alps, Pyrenees) are oriented east-west and allow the wind to carry large masses of water from the ocean in the interior. Others are oriented south-north (Scandinavian Mountains, Dinarides, Carpathians, Apennines) and because the rain falls primarily on the side of mountains that is oriented towards the sea, forests grow well on this side, while on the other side, the conditions are much less favourable. Few corners of mainland Europe have not been grazed by livestock at some point in time, and the cutting down of the pre-agricultural forest habitat caused disruption to the original plant and animal ecosystems.
Probably 80 to 90 percent of Europe was once covered by forest. It stretched from the Mediterranean Sea to the Arctic Ocean. Though over half of Europe's original forests disappeared through the centuries of deforestation, Europe still has over one quarter of its land area as forest, such as the taiga of Scandinavia and Russia, mixed rainforests of the Caucasus and the Cork oak forests in the western Mediterranean. During recent times, deforestation has been slowed and many trees have been planted. However, in many cases monoculture plantations of conifers have replaced the original mixed natural forest, because these grow quicker. The plantations now cover vast areas of land, but offer poorer habitats for many European forest dwelling species which require a mixture of tree species and diverse forest structure. The amount of natural forest in Western Europe is just 2â3% or less, in European Russia 5â10%. The country with the smallest percentage of forested area is Iceland (1%), while the most forested country is Finland (77%).
In temperate Europe, mixed forest with both broadleaf and coniferous trees dominate. The most important species in central and western Europe are beech and oak. In the north, the taiga is a mixed spruceâpineâbirch forest; further north within Russia and extreme northern Scandinavia, the taiga gives way to tundra as the Arctic is approached. In the Mediterranean, many olive trees have been planted, which are very well adapted to its arid climate; Mediterranean Cypress is also widely planted in southern Europe. The semi-arid Mediterranean region hosts much scrub forest. A narrow east-west tongue of Eurasian grassland (the steppe) extends eastwards from Ukraine and southern Russia and ends in Hungary and traverses into taiga to the north.
Fauna.
Glaciation during the most recent ice age and the presence of man affected the distribution of European fauna. As for the animals, in many parts of Europe most large animals and top predator species have been hunted to extinction. The woolly mammoth was extinct before the end of the Neolithic period. Today wolves (carnivores) and bears (omnivores) are endangered. Once they were found in most parts of Europe. However, deforestation and hunting caused these animals to withdraw further and further. By the Middle Ages the bears' habitats were limited to more or less inaccessible mountains with sufficient forest cover. Today, the brown bear lives primarily in the Balkan peninsula, Scandinavia, and Russia; a small number also persist in other countries across Europe (Austria, Pyrenees etc.), but in these areas brown bear populations are fragmented and marginalised because of the destruction of their habitat. In addition, polar bears may be found on Svalbard, a Norwegian archipelago far north of Scandinavia. The wolf, the second largest predator in Europe after the brown bear, can be found primarily in Central and Eastern Europe and in the Balkans, with a handful of packs in pockets of Western Europe (Scandinavia, Spain, etc.).
European wild cat, foxes (especially the red fox), jackal and different species of martens, hedgehogs, different species of reptiles (like snakes such as vipers and grass snakes) and amphibians, different birds (owls, hawks and other birds of prey).
Important European herbivores are snails, larvae, fish, different birds, and mammals, like rodents, deer and roe deer, boars, and living in the mountains, marmots, steinbocks, chamois among others. A number of insects, such as the small tortoiseshell butterfly, add to the biodiversity.
The extinction of the dwarf hippos and dwarf elephants has been linked to the earliest arrival of humans on the islands of the Mediterranean.
Sea creatures are also an important part of European flora and fauna. The sea flora is mainly phytoplankton. Important animals that live in European seas are zooplankton, molluscs, echinoderms, different crustaceans, squids and octopuses, fish, dolphins, and whales.
Biodiversity is protected in Europe through the Council of Europe's Bern Convention, which has also been signed by the European Community as well as non-European states.
Politics.
The list below includes all entities falling even partially under any of the various common definitions of Europe, geographic or political. The data displayed are per sources in cross-referenced articles.
Within the above-mentioned states are several de facto independent countries with limited to no international recognition. None of them are members of the UN:
Several dependencies and similar territories with broad autonomy are also found in Europe. Note that the list does not include the constituent countries of the United Kingdom, federal states of Germany and Austria, and autonomous territories of Spain and the post-Soviet republics as well as the republic of Serbia.
Integration.
European integration is the process of political, legal, economic (and in some cases social and cultural) integration of states wholly or partially in Europe. While the Council of Europeâwhich includes almost all European statesâhas promoted pan-Europe cooperation, the European Union has been the focus of economic integration on the continent. More recently, the Eurasian Economic Union has been established as a counterpart comprising former Soviet states.
28 European states are members of the politico-economic European Union, 26 of the border-free Schengen Area and 19 of the monetary union Eurozone. Among the smaller European organizations are the Nordic Council, the Benelux, the Baltic Assembly and the VisegrÃ¡d Group.
Economy.
As a continent, the economy of Europe is currently the largest on Earth and it is the richest region as measured by assets under management with over $32.7Â trillion compared to North America's $27.1Â trillion in 2008. In 2009 Europe remained the wealthiest region. Its $37.1 trillion in assets under management represented one-third of the world's wealth. It was one of several regions where wealth surpassed its precrisis year-end peak. As with other continents, Europe has a large variation of wealth among its countries. The richer states tend to be in the West; some of the Central and Eastern European economies are still emerging from the collapse of the Soviet Union and Yugoslavia.
The European Union, a political entity composed of 28 European states, comprises the largest single economic area in the world. 18 EU countries share the euro as a common currency.
Five European countries rank in the top ten of the world's largest national economies in GDP (PPP). This includes (ranks according to the CIA): Germany (5), the UK (6), Russia (7), France (8), and Italy (10).
There is huge disparity between many European countries in terms of their income. The richest in terms of GDP per capita is Monaco with its US$172,676 per capita (2009) and the poorest is Moldova with its GDP per capita of US$1,631 (2010). Monaco is the richest country in terms of GDP per capita in the world according to the World Bank report.
Capitalism has been dominant in the Western world since the end of feudalism. From Britain, it gradually spread throughout Europe. The Industrial Revolution started in Europe, specifically the United Kingdom in the late 18th century, and the 19th century saw Western Europe industrialise. Economies were disrupted by World War I but by the beginning of World War II they had recovered and were having to compete with the growing economic strength of the United States. World War II, again, damaged much of Europe's industries.
After World War II the economy of the UK was in a state of ruin, and continued to suffer relative economic decline in the following decades. Italy was also in a poor economic condition but regained a high level of growth by the 1950s. West Germany recovered quickly and had doubled production from pre-war levels by the 1950s. France also staged a remarkable comeback enjoying rapid growth and modernisation; later on Spain, under the leadership of Franco, also recovered, and the nation recorded huge unprecedented economic growth beginning in the 1960s in what is called the Spanish miracle. The majority of Central and Eastern European states came under the control of the Soviet Union and thus were members of the Council for Mutual Economic Assistance (COMECON).
History.
The states which retained a free-market system were given a large amount of aid by the United States under the Marshall Plan.
With the fall of communism in Central and Eastern Europe in 1991, the post-socialist states began free market reforms: Poland, Hungary, and Slovenia adopted them reasonably quickly, while Ukraine and Russia are still in the process of doing so.
After East and West Germany were reunited in 1990, the economy of West Germany struggled as it had to support and largely rebuild the infrastructure of East Germany.
By the millennium change, the EU dominated the economy of Europe comprising the five largest European economies of the time namely Germany, the United Kingdom, France, Italy, and Spain. In 1999, 12 of the 15 members of the EU joined the Eurozone replacing their former national currencies by the common euro. The three who chose to remain outside the Eurozone were: the United Kingdom, Denmark, and Sweden.
The European Union is now the largest economy in the world.
Figures released by Eurostat in 2009 confirmed that the Eurozone had gone into recession in 2008. It impacted much of the region. In 2010, fears of a sovereign debt crisis developed concerning some countries in Europe, especially Greece, Ireland, Spain, and Portugal. As a result, measures were taken, especially for Greece, by the leading countries of the Eurozone. The EU-27 unemployment rate was 10.3% in 2012. For those aged 15â24 it was 22.4%.
Demographics.
Since the Renaissance, Europe has had a major influence in culture, economics and social movements in the world. The most significant inventions had their origins in the Western world, primarily Europe and the United States. Approximately 70 million Europeans died through war, violence and famine between 1914 and 1945. Some current and past issues in European demographics have included religious emigration, race relations, economic immigration, a declining birth rate and an ageing population.
In some countries, such as Ireland and Poland, access to abortion is limited. It remains illegal on the island of Malta. Furthermore, three European countries (the Netherlands, Belgium, and Switzerland) and the Autonomous Community of Andalusia (Spain) have allowed a limited form of voluntary euthanasia for some terminally ill people.
In 2005, the population of Europe was estimated to be 731Â million according to the United Nations, which is slightly more than one-ninth of the world's population. A century ago, Europe had nearly a quarter of the world's population. The population of Europe has grown in the past century, but in other areas of the world (in particular Africa and Asia) the population has grown far more quickly. Among the continents, Europe has a relatively high population density, second only to Asia. The most densely populated country in Europe (and in the world) is Monaco. Pan and Pfeil (2004) count 87 distinct "peoples of Europe", of which 33 form the majority population in at least one sovereign state, while the remaining 54 constitute ethnic minorities.
According to UN population projection, Europe's population may fall to about 7% of world population by 2050, or 653Â million people (medium variant, 556 to 777Â million in low and high variants, respectively). Within this context, significant disparities exist between regions in relation to fertility rates. The average number of children per female of child bearing age is 1.52. According to some sources, this rate is higher among Muslims in Europe. The UN predicts a steady population decline in Central and Eastern Europe as a result of emigration and low birth rates.
Europe is home to the highest number of migrants of all global regions at 70.6 million people, the IOM's report said. In 2005, the EU had an overall net gain from immigration of 1.8Â million people. This accounted for almost 85% of Europe's total population growth. The European Union plans to open the job centres for legal migrant workers from Africa. In 2008, 696,000 persons were given citizenship of an EU27 member state, a decrease from 707,000 the previous year.
Emigration from Europe began with Spanish and Portuguese settlers in the 16th century, and French and English settlers in the 17th century. But numbers remained relatively small until waves of mass emigration in the 19th century, when millions of poor families left Europe.
Today, large populations of European descent are found on every continent. European ancestry predominates in North America, and to a lesser degree in South America (particularly in Uruguay, Argentina, Chile and Brazil, while most of the other Latin American countries also have a considerable population of European origins). Australia and New Zealand have large European derived populations. Africa has no countries with European-derived majorities (or with the exception of Cape Verde and probably SÃ£o TomÃ© and PrÃ­ncipe, depending on context), but there are significant minorities, such as the White South Africans. In Asia, European-derived populations predominate in Northern Asia (specifically Russians), some parts of Northern Kazakhstan and Israel. Additionally, transcontinental or geographically Asian countries such as Georgia, Armenia, Azerbaijan, Cyprus and Turkey have populations historically closely related to Europeans, with considerable genetic and cultural affinity.
Languages.
European languages mostly fall within three Indo-European language groups: the Romance languages, derived from the Latin of the Roman Empire; the Germanic languages, whose ancestor language came from southern Scandinavia; and the Slavic languages.
Slavic languages are most spoken by the number of native speakers in Europe, they are spoken in Central, Eastern, and Southeastern Europe. Romance languages are spoken primarily in south-western Europe as well as in Romania and Moldova, in Central or Eastern Europe. Germanic languages are spoken in Northern Europe, the British Isles and some parts of Central Europe.
Many other languages outside the three main groups exist in Europe. Other Indo-European languages include the Baltic group (that is, Latvian and Lithuanian), the Celtic group (that is, Irish, Scottish Gaelic, Manx, Welsh, Cornish, and Breton), Greek, Armenian, and Albanian. In addition, a distinct group of Uralic languages (Estonian, Finnish, and Hungarian) is spoken mainly in Estonia, Finland, and Hungary, while Kartvelian languages (Georgian, Mingrelian, and Svan), are spoken primarily in Georgia, and two other language families reside in the North Caucasus (termed Northeast Caucasian, most notably including Chechen, Avar and Lezgin and Northwest Caucasian, notably including Adyghe). Maltese is the only Semitic language that is official within the EU, while Basque is the only European language isolate. Turkic languages include Azerbaijani and Turkish, in addition to the languages of minority nations in Russia.
Multilingualism and the protection of regional and minority languages are recognised political goals in Europe today. The Council of Europe Framework Convention for the Protection of National Minorities and the Council of Europe's European Charter for Regional or Minority Languages set up a legal framework for language rights in Europe.
Religion.
Historically, religion in Europe has been a major influence on European art, culture, philosophy and law. The largest religion in Europe is Christianity, with 76.2% of Europeans considering themselves Christians, including Catholic, Eastern Orthodox and various Protestant denominations (especially historically state-supported European ones such as Lutheranism, Anglicanism and the Reformed faith). The notion of "Europe" and the "Western World" has been intimately connected with the concept of "Christianity and Christendom" many even attribute Christianity for being the link that created a unified European identity.
The second most popular religion is Islam (6%) concentrated mainly in the Balkans and eastern Europe (Bosnia and Herzegovina, Albania, Kosovo, Kazakhstan, North Cyprus, Turkey, Azerbaijan, North Caucasus, and the Volga-Ural region). Other religions, including Judaism, Hinduism, and Buddhism are minority religions (though Tibetan Buddhism is the majority religion of Russia's Republic of Kalmykia). The 20th century saw the revival of Neopaganism through movements such as Wicca and Druidry.
Europe has become a relatively secular continent, with an increasing number and proportion of irreligious, atheist and agnostic people which make up about 18.2% of Europeans population, actually the largest secular in the Western world. There are a particularly high number of self-described non-religious people in the Czech Republic, Estonia, Sweden, former East Germany, and France.
Culture.
The culture of Europe can be described as a series of overlapping cultures; cultural mixes exist across the continent. Scholar Andreas Kaplan describes Europe as "embracing maximum cultural diversity at minimal geographical distances". There are cultural innovations and movements, sometimes at odds with each other. Thus, the question of "common culture" or "common values" is complex.
According to historian Hilaire Belloc, for several centuries the peoples of Europe based their self-identification on the remaining traces of the Roman culture and on the concept of Christendom, because many European-wide military alliances were of religious nature: the Crusades (1095â1291), the Reconquista (711â1492), the Battle of Lepanto (1571).
Historical Maps

</doc>
<doc id="9240" url="https://en.wikipedia.org/wiki?curid=9240" title="Europa">
Europa

Europa may refer to:

</doc>
<doc id="9241" url="https://en.wikipedia.org/wiki?curid=9241" title="Euglenozoa">
Euglenozoa

The Euglenozoa are a large group of flagellate protozoa. They include a variety of common free-living species, as well as a few important parasites, some of which infect humans. There are two main subgroups, the euglenids and kinetoplastids. Euglenozoa are unicellular, mostly around 15-40 Âµm in size, although some euglenids get up to 500Â Âµm long. 
Structure.
Most euglenozoa have two flagella, which are inserted parallel to one another in an apical or subapical pocket. In some these are associated with a cytostome or mouth, used to ingest bacteria or other small organisms. This is supported by one of three sets of microtubules that arise from the flagellar bases; the other two support the dorsal and ventral surfaces of the cell.
Some other euglenozoa feed through absorption, and many euglenids possess chloroplasts and so obtain energy through photosynthesis. These chloroplasts are surrounded by three membranes and contain chlorophylls "A" and "B", along with other pigments, so are probably derived from a captured green alga. Reproduction occurs exclusively through cell division. During mitosis, the nuclear membrane remains intact, and the spindle microtubules form inside of it.
The group is characterized by the ultrastructure of the flagella. In addition to the normal supporting microtubules or axoneme, each contains a rod (called "paraxonemal"), which has a tubular structure in one flagellum and a latticed structure in the other. Based on this, two smaller groups have been included here: the diplonemids and "Postgaardi".
Classification.
The euglenozoa are generally accepted as monophyletic. They are related to Percolozoa; the two share mitochondria with disk-shaped cristae, which only occurs in a few other groups.
Both probably belong to a larger group of eukaryotes called the excavates. This grouping, though, has been challenged.

</doc>
<doc id="9247" url="https://en.wikipedia.org/wiki?curid=9247" title="Epistemology">
Epistemology

Epistemology (; ) is a term first used by the Scottish philosopher James Frederick Ferrier to describe the branch of philosophy concerned with the nature and scope of knowledge; it is also referred to as "theory of knowledge". Put concisely, it is the study of knowledge and justified belief. It questions what knowledge is and how it can be acquired, and the extent to which knowledge pertinent to any given subject or entity can be acquired. Much of the debate in this field has focused on the philosophical analysis of the nature of knowledge and how it relates to connected notions such as truth, belief, and justification. The term was probably first introduced in Ferrier's "Institutes of Metaphysic: The Theory of Knowing and Being" (1854), p.Â 46.
Background and meaning.
The word "epistemology" is derived from the ancient Greek "epistÄmÄ" meaning "scientific knowledge" and "logos" meaning "speech" or "word", in this context denoting "codified knowledge of". J.F. Ferrier coined "epistemology" on the model of 'ontology', to designate that branch of philosophy which aims to discover the meaning of knowledge, and called it the 'true beginning' of philosophy. The word is equivalent to the German concept "Wissenschaftslehre", which was used by Fichte and Bolzano for different projects before it was taken up again by Husserl. French philosophers then gave the term "Ã©pistÃ©mologie" a narrower meaning as 'theory of knowledge "hÃ©orie de la connaissanc".' E.g., Ãmile Meyerson opened his "Identity and Reality", written in 1908, with the remark that the word 'is becoming current' as equivalent to 'the philosophy of the sciences.'
Knowledge.
Knowledge that, knowledge how, and knowledge by acquaintance.
In epistemology in general, the kind of knowledge usually discussed is propositional knowledge, also known as "knowledge that." This is distinguished from "knowledge how" and "acquaintance-knowledge". For example: in mathematics, it is known "that" 2 + 2 = 4, but there is also knowing "how" to add two numbers and knowing a "person" (e.g., oneself), "place" (e.g., one's hometown), "thing" (e.g., cars), or "activity" (e.g., addition). Some philosophers think there is an important distinction between "knowing that," "knowing how," and "acquaintance-knowledge," with epistemology being primarily concerned with the first of these. It is sometimes suggested that these distinctions are defined linguistically in some languages, even if not in modern Standard English (N.B. some languages related to English have been said to retain these verbs, e.g. Scots: "wit" and "ken"). In French, Portuguese and Spanish, "to know (a person)" is translated using "connaÃ®tre," "conhecer," and "conocer," respectively, whereas "to know (how to do something)" is translated using "savoir", "saber", and "saber". Modern Greek has the verbs "Î³Î½ÏÏÎ¯Î¶Ï" (gnorÃ­zo) and "Î¾Î­ÏÏ" (ksÃ©ro). Italian has the verbs "conoscere" and "sapere" and the nouns for "knowledge" are "conoscenza" and "sapienza." German has the verbs "kennen" and "wissen." "Wissen" implies knowing a fact, "kennen" implies knowing in the sense of being acquainted with and having a working knowledge of; there is also a noun derived from "kennen," namely "Erkennen," which has been said to imply knowledge in the form of recognition or acknowledgment. The verb itself implies a process: you have to go from one state to another, from a state of "not-"erkennen"" to a state of true "erkennen." This verb seems to be the most appropriate in terms of describing the "episteme" in one of the modern European languages, hence the German name "." The theoretical interpretation and significance of these linguistic issues remains controversial.
In his paper "On Denoting" and his later book "Problems of Philosophy" Bertrand Russell stressed the distinction between "knowledge by description" and "knowledge by acquaintance". Gilbert Ryle is also credited with stressing the distinction between knowing how and knowing that in "The Concept of Mind." In "Personal Knowledge," Michael Polanyi argues for the epistemological relevance of knowledge how and knowledge that; using the example of the act of balance involved in riding a bicycle, he suggests that the theoretical knowledge of the physics involved in maintaining a state of balance cannot substitute for the practical knowledge of how to ride, and that it is important to understand how both are established and grounded. This position is essentially Ryle's, who argued that a failure to acknowledge the distinction between knowledge that and knowledge how leads to infinite regress.
In recent times, some epistemologists (Sosa, Greco, Kvanvig, Zagzebski) and Duncan Pritchard have argued that epistemology should evaluate people's "properties" (i.e., intellectual virtues) and not just the properties of propositions or of propositional mental attitudes.
Belief.
In common speech, a "statement of belief" is typically an expression of faith and/or trust in a person, power or other entity â while it includes such traditional views, epistemology is also concerned with what we believe. This includes 'the' truth, and everything else we accept as true for ourselves from a cognitive point of view.
Truth.
Whether someone's belief is true is not a prerequisite for (its) belief. On the other hand, if something is actually "known", then it categorically cannot be false. For example, if a person believes that a bridge is safe enough to support him, and attempts to cross it, but the bridge then collapses under his weight, it could be said that he "believed" that the bridge was safe but that his belief was mistaken. It would "not" be accurate to say that he "knew" that the bridge was safe, because plainly it was not. By contrast, if the bridge actually supported his weight, then he might say that he had believed that the bridge was safe, whereas now, after proving it to himself (by crossing it), he "knows" it was safe.
Epistemologists argue over whether belief is the proper truth-bearer. Some would rather describe knowledge as a system of justified true propositions, and others as a system of justified true sentences. Plato, in his Gorgias, argues that belief is the most commonly invoked truth-bearer.
Justification.
In many of Plato's dialogues, such as the "Meno" and, in particular, the "Theaetetus", Socrates considers a number of theories as to what knowledge is, the last being that knowledge is true belief that has been "given an account of" (meaning explained or defined in some way). According to the theory that knowledge is justified true belief, in order to know that a given proposition is true, one must not only believe the relevant true proposition, but one must also have a good reason for doing so. One implication of this would be that no one would gain knowledge just by believing something that happened to be true. For example, an ill person with no medical training, but with a generally optimistic attitude, might believe that he will recover from his illness quickly. Nevertheless, even if this belief turned out to be true, the patient would not have "known" that he would get well since his belief lacked justification.
The definition of knowledge as justified true belief was widely accepted until the 1960s. At this time, a paper written by the American philosopher Edmund Gettier provoked major widespread discussion. (See theories of justification for other views on the idea.)
Gettier problem.
Edmund Gettier is best known for a short paper entitled 'Is Justified True Belief Knowledge?' published in 1963, which called into question the theory of knowledge that had been dominant among philosophers for thousands of years. In a few pages, Gettier argued that there are situations in which one's belief may be justified and true, yet fail to count as knowledge. That is, Gettier contended that while justified belief in a true proposition is necessary for that proposition to be known, it is not sufficient. As in the diagram, a true proposition can be believed by an individual (purple region) but still not fall within the "knowledge" category (yellow region).
According to Gettier, there are certain circumstances in which one does not have knowledge, even when all of the above conditions are met. Gettier proposed two thought experiments, which have come to be known as "Gettier cases," as counterexamples to the classical account of knowledge. One of the cases involves two men, Smith and Jones, who are awaiting the results of their applications for the same job. Each man has ten coins in his pocket. Smith has excellent reasons to believe that Jones will get the job and, furthermore, knows that Jones has ten coins in his pocket (he recently counted them). From this Smith infers, "the man who will get the job has ten coins in his pocket." However, Smith is unaware that he also has ten coins in his own pocket. Furthermore, Smith, not Jones, is going to get the job. While Smith has strong evidence to believe that Jones will get the job, he is wrong. Smith has a justified true belief that a man with ten coins in his pocket will get the job; however, according to Gettier, Smith does not "know" that a man with ten coins in his pocket will get the job, because Smith's belief is "...true by virtue of the number of coins in "Jones's" pocket, while Smith does not know how many coins are in Smith's pocket, and bases his belief...on a count of the coins in Jones's pocket, whom he falsely believes to be the man who will get the job." (see p.Â 122.) These cases fail to be knowledge because the subject's belief is justified, but only happens to be true by virtue of luck. In other words, he made the correct choice (in this case predicting an outcome) for the wrong reasons. This example is similar to those often given when discussing belief and truth, wherein a person's belief of what will happen can coincidentally be correct without his or her having the actual knowledge to base it on.
Responses to Gettier.
The responses to Gettier have been varied. Usually, they have involved substantial attempts to provide a definition of knowledge different from the classical one, either by recasting knowledge as justified true belief with some additional fourth condition, or as something else altogether.
Yet a good counter-argument to Gettier's cases, is that unless they pulled out the coins and recounted them, they could not have "known", because the knowledge was based on past events. As time passes, so too does circumstances; for one could have dropped a coin after the other counted them, also without his knowledge, and he would be aware of this variable; thus couldn't truly believe this; ergo, the counter case is null.
Infallibilism, indefeasibility.
In one response to Gettier, the American philosopher Richard Kirkham has argued that the only definition of knowledge that could ever be immune to all counterexamples is the infallibilist one. To qualify as an item of knowledge, goes the theory, a belief must not only be true and justified, the justification of the belief must "necessitate" its truth. In other words, the justification for the belief must be infallible.
Yet another possible candidate for the fourth condition of knowledge is "indefeasibility." Defeasibility theory maintains that there should be no overriding or defeating truths for the reasons that justify one's belief. For example, suppose that person "S" believes he saw Tom Grabit steal a book from the library and uses this to justify the claim that Tom Grabit stole a book from the library. A possible defeater or overriding proposition for such a claim could be a true proposition like, "Tom Grabit's identical twin Sam is currently in the same town as Tom." When no defeaters of one's justification exist, a subject would be epistemelogically justified.
The Indian philosopher B K Matilal has drawn on the Navya-NyÄya fallibilism tradition to respond to the Gettier problem. Nyaya theory distinguishes between "know p" and "know that one knows p" â these are different events, with different causal conditions. The second level is a sort of implicit inference that usually follows immediately the episode of knowing p (knowledge "simpliciter"). The Gettier case is examined by referring to a view of Gangesha Upadhyaya (late 12th century), who takes any true belief to be knowledge; thus a true belief acquired through a wrong route may just be regarded as knowledge simpliciter on this view. The question of justification arises only at the second level, when one considers the knowledgehood of the acquired belief. Initially, there is lack of uncertainty, so it becomes a true belief. But at the very next moment, when the hearer is about to embark upon the venture of "knowing whether he knows p", doubts may arise. "If, in
some Gettier-like cases, I am wrong in my inference about the knowledgehood of the given occurrent belief (for the evidence may be pseudo-evidence), then I am mistaken about the truth of my belief â and this is in accordance with Nyaya fallibilism: not all knowledge-claims can be sustained."
Reliabilism.
Reliabilism has been a significant line of response to the Gettier problem among philosophers, originating with work by Alvin Goldman in the 1960s. According to reliabilism, a belief is justified (or otherwise supported in such a way as to count towards knowledge) only if it is produced by processes that typically yield a sufficiently high ratio of true to false beliefs. In other words, this theory states that a true belief counts as knowledge only if it is produced by a reliable belief-forming process.
Reliabilism has been challenged by Gettier cases. Another argument that challenges reliabilism, like the Gettier cases (although it was not presented in the same short article as the Gettier cases), is the case of Henry and the barn faÃ§ades. In the thought experiment, a man, Henry, is driving along and sees a number of buildings that resemble barns. Based on his perception of one of these, he concludes that he has just seen barns. While he has seen one, and the perception he based his belief that the one he saw was of a real barn, all the other barn-like buildings he saw were faÃ§ades. Theoretically, Henry does not know that he has seen a barn, despite both his belief that he has seen one being true and his belief being formed on the basis of a reliable process (i.e. his vision), since he only acquired his true belief by accident.
Other responses.
Robert Nozick has offered the following definition of knowledge:
"S" knows that "P" if and only if:
Nozick argues that the third of these conditions serves to address cases of the sort described by Gettier. Nozick further claims this condition addresses a case of the sort described by D. M. Armstrong: A father believes his daughter innocent of committing a particular crime, both because of faith in his baby girl and (now) because he has seen presented in the courtroom a conclusive demonstration of his daughter's innocence. His belief via the method of the courtroom satisfies the four subjunctive conditions, but his faith-based belief does not. If his daughter were guilty, he would still believe her innocent, on the basis of faith in his daughter; this would violate the third condition.
The British philosopher Simon Blackburn has criticized this formulation by suggesting that we do not want to accept as knowledge beliefs, which, while they "track the truth" (as Nozick's account requires), are not held for appropriate reasons. He says that "we do not want to award the title of knowing something to someone who is only meeting the conditions through a defect, flaw, or failure, compared with someone else who is not meeting the conditions." In addition to this, externalist accounts of knowledge, such as Nozick's, are often forced to reject closure in cases where it is intuitively valid.
Timothy Williamson has advanced a theory of knowledge according to which knowledge is not justified true belief plus some extra condition(s). In his book "Knowledge and its Limits," Williamson argues that the concept of knowledge cannot be broken down into a set of other concepts through analysisâinstead, it is "sui generis." Thus, though knowledge requires justification, truth, and belief, the word "knowledge" can't be, according to Williamson's theory, accurately regarded as simply shorthand for "justified true belief."
Alvin Goldman writes in his Causal Theory of Knowing that in order for knowledge to truly exist there must be a causal chain between the proposition and the belief of that proposition.
Externalism and internalism.
Part of the debate over the nature of knowledge is a debate between epistemological externalists on the one hand, and epistemological internalists on the other.
Externalists hold that factors deemed "external", meaning outside of the psychological states of those who gain knowledge, can be conditions of knowledge. For example, an externalist response to the Gettier problem is to say that, in order for a justified true belief to count as knowledge, there must be a link or dependency between the belief and the state of the external world. Usually this is understood to be a causal link. Such causation, to the extent that it is "outside" the mind, would count as an external, knowledge-yielding condition. Internalists, on the other hand, assert that all knowledge-yielding conditions are within the psychological states of those who gain knowledge.
Though unfamiliar with the internalist/externalist debate himself, many point to RenÃ© Descartes as an early example of the internalist path to justification. He wrote that, because the only method by which we perceive the external world is through our senses, and that, because the senses are not infallible, we should not consider our concept of knowledge to be infallible. The only way to find anything that could be described as "indubitably true," he advocates, would be to see things "clearly and distinctly". He argued that if there is an omnipotent, good being who made the world, then it's reasonable to believe that people are made with the ability to know. However, this does not mean that man's ability to know is perfect. God gave man the ability to know, but not omniscience. Descartes said that man must use his capacities for knowledge correctly and carefully through methodological doubt. The dictum "Cogito ergo sum" (I think, therefore I am) is also commonly associated with Descartes' theory, because in his own methodological doubt, doubting everything he previously knew in order to start from a blank slate, the first thing that he could not logically bring himself to doubt was his own existence: "I do not exist" would be a contradiction in terms; the act of saying that one does not exist assumes that someone must be making the statement in the first place. Though Descartes could doubt his senses, his body and the world around him, he could not deny his own existence, because he was able to doubt and must exist in order to do so. Even if some "evil genius" were to be deceiving him, he would have to exist in order to be deceived. This one sure point provided him with what he would call his Archimedean point, in order to further develop his foundation for knowledge. Simply put, Descartes' epistemological justification depended upon his indubitable belief in his own existence and his clear and distinct knowledge of God.
Value problem.
A formulation of the value problem in epistemology first occurs in Plato's Meno. The problem is to identify what is it about knowledge (if anything) that makes it more valuable than mere true belief, or that makes knowledge more valuable than a more minimal conjunction of its components on a particular analysis of knowledge. The value problem re-emerged in the philosophical literature on epistemology in the twenty-first century following the rise of virtue epistemology in the 1980s, partly because of the obvious link with the concept of value in ethics.
The value problem has been presented as an argument against epistemic reliabilism by philosophers including Linda Zagzebski, Wayne Riggs and Richard Swinburne. Zagzebski gives a thought experiment to illustrate the unimportance of the belief being produced by a reliable process: imagine you go to a coffee machine and attempt to have it produce you a cup of coffee. The machine you use might reliably produce coffee, or it might not. Imagine one machine had a 90% chance of producing you coffee while another only had a 40% chance. If you happen to choose the 40% chance machine and it produces you a cup of coffee, the fact that it does not "reliably" produce coffee does not change the value that the coffee has to you. Similarly, if you have a true belief achieved through an unreliable process, Zagzebski argues that there's no particular reason that has "less" value than one produced through a reliable process. Advocates of virtue epistemology have argued that the value of knowledge comes from an internal relationship between the knower and the mental state of believing.
One of the more influential responses to the problem is that knowledge is not particularly valuable and is not what ought to be the main focus of epistemology. Instead, epistemologists ought to focus on other mental states, such as understanding.
Acquiring knowledge.
"A priori" and "a posteriori" knowledge.
The nature of this distinction has been disputed by various philosophers; however, the terms may be roughly defined as follows:
A priori knowledge is a way of gaining knowledge without the need of experience. In Bruce Russell's article "A Priori Justification and Knowledge" he says that it is "knowledge based on a priori justification," (1) which relies on intuition and the nature of these intuitions. A priori knowledge is often contrasted with posteriori knowledge, which is knowledge gained by experience. A way to look at the difference between the two is through an example. Bruce Russell gives two propositions in which the reader decides which one he believes more. Option A: All crows are birds. Option B: All crows are black. If you believe option A, then you are a priori justified in believing it because you don't have to see a crow to know it's a bird. If you believe in option B, then you are posteriori justified to believe it because you have seen many crows therefore knowing they are black. He goes on to say that it doesn't matter if the statement is true or not, only that if you believe in one or the other that matters.
The idea of a priori knowledge is that it is based on intuition or rational insights. Laurence BonJour says in his article "The Structure of Empirical Knowledge", that a "rational insight is an immediate, non-inferential grasp, apprehension or 'seeing' that some proposition is necessarily true." (3) Going back to the crow example, by Laurence BonJour's definition the reason you would believe in option A is because you have an immediate knowledge that a crow is a bird, without ever experiencing one.
Evolutionary psychology takes a novel approach to the problem. It says that there is an innate predisposition for certain types of learning. "Only small parts of the brain resemble a tabula rasa; this is true even for human beings. The remainder is more like an exposed negative waiting to be dipped into a developer fluid"
Analyticâsynthetic distinction.
Immanuel Kant, in his "Critique of Pure Reason", drew a distinction between "analytic" and "synthetic" propositions. He contended that some propositions are such that we can know them to be true just by understanding their meaning. For example, consider, "My father's brother is my uncle." We can know it to be true solely by virtue of our understanding what its terms mean. Philosophers call such propositions "analytic." Synthetic propositions, on the other hand, have distinct subjects and predicates. An example would be, "My father's brother has black hair." Kant stated that all mathematical and scientific statements are synthetic a priori propositions because they are necessarily true but our knowledge about the attributes of the mathematical or physical subjects we can only get by logical inference.
The American philosopher W. V. O. Quine, in his "Two Dogmas of Empiricism", famously challenged the distinction, arguing that the two have a blurry boundary. Some contemporary philosophers have offered more sustainable accounts of the distinction.
Branches or 'tendencies' within epistemology.
Historical.
The historical study of philosophical epistemology is the historical study of efforts to gain philosophical understanding or knowledge of the nature and scope of human knowledge. Since efforts to get that kind of understanding have a history, the questions philosophical epistemology asks today about human knowledge are not necessarily the same as they once were. But that does not mean that philosophical epistemology is itself a historical subject, or that it pursues only or even primarily historical understanding.
Empiricism.
In philosophy, empiricism is generally a theory of knowledge focusing on the role of experience, especially experience based on perceptual observations by the senses. Certain forms treat all knowledge as empirical, while some regard disciplines such as mathematics and logic as exceptions.
There are many variants of empiricism, positivism, realism and common sense being among the most commonly expounded. But central to all empiricist epistemologies is the notion of the epistemologically privileged status of sense data.
Idealism.
Many idealists believe that knowledge is primarily (at least in some areas) acquired by "a priori" processes or is innateâfor example, in the form of concepts not derived from experience. The relevant theoretical processes often go by the name "intuition". The relevant theoretical concepts may purportedly be part of the structure of the human mind (as in Kant's theory of transcendental idealism), or they may be said to exist independently of the mind (as in Plato's theory of Forms).
Rationalism.
By contrast with empiricism and idealism, which centres around the epistemologically privileged status of sense data (empirical) and the primacy of Reason (theoretical) respectively, modern rationalism adds a third 'system of thinking', (as Gaston Bachelard has termed these areas) and holds that all three are of equal importance: The empirical, the theoretical and the "abstract". For Bachelard, rationalism makes equal reference to all three systems of thinking.
Constructivism.
Constructivism is a view in philosophy according to which all "knowledge is a compilation of human-made constructions", "not the neutral discovery of an objective truth". Whereas objectivism is concerned with the "object of our knowledge", constructivism emphasises "how we construct knowledge". Constructivism proposes new definitions for knowledge and truth that form a new paradigm, based on inter-subjectivity instead of the classical objectivity, and on viability instead of truth. Piagetian constructivism, however, believes in objectivityâconstructs can be validated through experimentation. The constructivist point of view is pragmatic; as Vico said: "The norm of the truth is to have made it."
Regress problem.
The regress problem is the problem of providing a complete logical foundation for human knowledge. The traditional way of supporting a rational argument is to appeal to other rational arguments, typically using chains of reason and rules of logic. A classic example that goes back to Aristotle is deducing that "Socrates is mortal." We have a logical rule that says "All humans are mortal" and an assertion that "Socrates is human" and we deduce that "Socrates is mortal". In this example how do we know that Socrates is human? Presumably we apply other rules such as: "All born from human females are human." Which then leaves open the question how do we know that all born from humans are human? This is the regress problem: how can we eventually terminate a logical argument with some statement(s) that do not require further justification but can still be considered rational and justified?
As John Pollock stated: ... to justify a belief one must appeal to a further justified belief. This means that one of two things can be the case. Either there are some beliefs that we can be justified for holding, without being able to justify them on the basis of any other belief, or else for each justified belief there is an infinite regress of (potential) justification he nebula theor. On this theory there is no rock bottom of justification. Justification just meanders in and out through our network of beliefs, stopping nowhere.
The apparent impossibility of completing an infinite chain of reasoning is thought by some to support skepticism. It is also the impetus for Descartes' famous dictum: "I think therefore I am". Descartes was looking for some logical statement that could be true without appeal to other statements.
Response to the regress problem.
Many epistemologists studying justification have attempted to argue for various types of chains of reasoning that can escape the regress problem.
Foundationalism.
Foundationalists respond to the regress problem by asserting that certain "foundations" or "basic beliefs" support other beliefs but do not themselves require justification from other beliefs. These beliefs might be justified because they are self-evident, infallible, or derive from reliable cognitive mechanisms. Perception, memory, and a priori intuition are often considered to be possible examples of basic beliefs.
The chief criticism of foundationalism is that if a belief is not supported by other beliefs, accepting it may be arbitrary or unjustified.
Coherentism.
Another response to the regress problem is coherentism, which is the rejection of the assumption that the regress proceeds according to a pattern of linear justification. To avoid the charge of circularity, coherentists hold that an individual belief is justified circularly by the way it fits together (coheres) with the rest of the belief system of which it is a part. This theory has the advantage of avoiding the infinite regress without claiming special, possibly arbitrary status for some particular class of beliefs. Yet, since a system can be coherent while also being wrong, coherentists face the difficulty of ensuring that the whole system corresponds to reality. Additionally, most logicians agree that any argument that is circular is trivially valid. That is, to be illuminating, arguments must be linear with conclusions that follow from stated premises.
However, Warburton writes in 'Thinking from A to Z,' "Circular arguments are not invalid; in other words, from a logical point of view there is nothing intrinsically wrong with them. However, they are, when viciously circular, spectacularly uninformative. (Warburton 1996)."
Foundherentism.
A position known as "foundherentism", advanced by Susan Haack, is meant to be a unification of foundationalism and coherentism. One component of this theory is what is called the "analogy of the crossword puzzle." Whereas, for example, infinitists regard the regress of reasons as "shaped" like a single line, Susan Haack has argued that it is more like a crossword puzzle, with multiple lines mutually supporting each other.
Infinitism.
An alternative resolution to the regress problem is known as "infinitism". Infinitists take the infinite series to be merely potential, in the sense that an individual may have indefinitely many reasons available to them, without having consciously thought through all of these reasons when the need arises. This position is motivated in part by the desire to avoid what is seen as the arbitrariness and circularity of its chief competitors, foundationalism and coherentism.
Skepticism.
Skepticism is a position that questions the validity of some or all of human knowledge. Skepticism does not refer to any one specific school of philosophy, rather it is a thread that runs through many philosophical discussions of epistemology. The first well known sceptic was Socrates who claimed that his only knowledge was that he knew nothing with certainty. Descartes' most famous inquiry into mind and body also began as an exercise in skepticism. Descartes began by questioning the validity of all knowledge and looking for some fact that was irrefutable. In so doing, he came to his famous dictum: I think therefore I am.
Foundationalism and the other responses to the regress problem are essentially defenses against skepticism. Similarly, the pragmatism of William James can be viewed as a coherentist defense against skepticism. James discarded conventional philosophical views of truth and defined truth to be based on how well a concept works in a specific context rather than objective rational criteria. The philosophy of Logical Positivism and the work of philosophers such as Kuhn and Popper can be viewed as skepticism applied to what can truly be considered scientific knowledge.
External links.
"Stanford Encyclopedia of Philosophy" articles:
Other links:

</doc>
<doc id="9248" url="https://en.wikipedia.org/wiki?curid=9248" title="Esperanto">
Esperanto

Esperanto ( or ; ) is a constructed international auxiliary language. It is the most widely spoken constructed language in the world. Its name derives from " (" translates as "one who hopes"), the pseudonym under which physician L. L. Zamenhof published the first book detailing Esperanto, the "," on 26 July 1887. Zamenhof's goal was to create an easy-to-learn, politically neutral language that would transcend nationality and foster peace and international understanding between people with different languages.
Up to 2,000,000 people worldwide, to varying degrees, speak Esperanto, including perhaps 2,000 native speakers who learned Esperanto from birth. The World Esperanto Association has members in 120 countries. Its usage is highest in Europe, East Asia, and South America. , the most popular online learning platform for Esperanto, reported 150,000 registered users in 2013, and sees between 150,000 and 200,000 visitors each month. With about articles, Esperanto Wikipedia is the 31st-largest Wikipedia as measured by the number of articles, and the largest Wikipedia in a constructed language. On 22 February 2012, Google Translate added Esperanto as its 64th language. On 28 May 2015, the language learning platform Duolingo launched an Esperanto course for English speakers. , over 300,000 users had signed up.
The first World Congress of Esperanto was organized in France in 1905. Since then, congresses have been held in various countries every year, with the exceptions of years during the world wars. Although no country has adopted Esperanto officially, Esperanto was recommended by the French Academy of Sciences in 1921 and recognized by UNESCO in 1954, which recommended in 1985 that international non-governmental organizations use Esperanto. Esperanto was the 32nd language accepted as adhering to the "Common European Framework of Reference for Languages" in 2007.
Esperanto is currently the language of instruction of the International Academy of Sciences in San Marino.
Esperanto is seen by many of its speakers as an alternative or addition to the growing use of English throughout the world, offering a language that is easier to learn than English.
History.
Creation.
Esperanto was created in the late 1870s and early 1880s by L. L. Zamenhof, a Polish-Jewish ophthalmologist from BiaÅystok, then part of the Russian Empire. According to Zamenhof, he created the language to foster harmony between people from different countries. His feelings and the situation in BiaÅystok may be gleaned from an extract from his letter to Nikolai Borovko:
After some ten years of development, which Zamenhof spent translating literature into Esperanto as well as writing original prose and verse, the first book of Esperanto grammar was published in Warsaw on the 26th of July 1887. The number of speakers grew rapidly over the next few decades, at first primarily in the Russian Empire and Central Europe, then in other parts of Europe, the Americas, China, and Japan. In the early years, speakers of Esperanto kept in contact primarily through correspondence and periodicals, but in 1905 the first world congress of Esperanto speakers was held in Boulogne-sur-Mer, France. Since then world congresses have been held in different countries every year, except during the two World Wars. Since the Second World War, they have been attended by an average of more than 2,000 people and up to 6,000 people.
Zamenhof's name for the language was simply "" ("International Language").
Early proposals.
The autonomous territory of Neutral Moresnet, between what is today Belgium and Germany, had a sizable proportion of Esperanto-speakers among its small and multiethnic population. There was a proposal to make Esperanto its official language.
However, neither Belgium nor Prussia (now within Germany) had ever surrendered its original claim to it. Around 1900, Germany in particular was taking a more aggressive stance towards the territory and was accused of sabotage and of obstructing the administrative process in order to force the issue. It was the First World War, however, that was the catalyst that brought about the end of neutrality. On 4 August 1914, Germany invaded Belgium, leaving Moresnet at first "an oasis in a desert of destruction". In 1915, the territory was annexed by the Kingdom of Prussia, without international recognition.
After the Great War, there was a proposal for the League of Nations to accept Esperanto as their working language, following a report by Nitobe InazÅ, an official delegate of League of Nations during the 13th World Congress of Esperanto in Prague. Ten delegates accepted the proposal with only one voice against, the French delegate, Gabriel Hanotaux. Hanotaux did not like how the French language was losing its position as the international language and saw Esperanto as a threat, effectively wielding his veto power to block the decision. However, two years later, the League recommended that its member states include Esperanto in their educational curricula. For this reason, many people see the 1920s as the heyday of the Esperanto movement. Anarchism as a political movement was very supportive during this time of anationalism as well as of the Esperanto language.
Totalitarian responses.
Esperanto attracted the suspicion of many totalitarian states. The situation was especially pronounced in Nazi Germany, Francoist Spain up until the 1950s, and in the Soviet Union from 1937 to 1956.
In Nazi Germany, there was a motivation to persecute Esperanto because Zamenhof was Jewish, and due to the internationalist nature of Esperanto, which was perceived as "Bolshevist". In his work, "Mein Kampf", Adolf Hitler specifically mentioned Esperanto as an example of a language that could be used by an international Jewish conspiracy once they achieved world domination. Esperantists were killed during the Holocaust, with Zamenhof's family in particular singled out for being killed. The efforts of a minority of Esperantists to expel Jewish colleagues and align themselves with the Reich were futile and Esperanto was legally forbidden in 1935. Esperantists in German concentration camps taught the language to fellow prisoners, telling guards they were teaching Italian, the language of one of Germany's Axis allies.
In Imperial Japan, the left-wing of the Japanese Esperanto movement was persecuted, but its leaders were careful enough not to give the impression to the government that the Esperantists were socialist revolutionaries, which proved a successful strategy.
After the October Revolution of 1917, Esperanto was given a measure of government support by the new workers' states in the former Russian Empire and later by the Soviet Union government, with the Soviet Esperanto Association being established as an officially recognized organization. In his biography on Joseph Stalin, Leon Trotsky mentions that Stalin had studied Esperanto. However, in 1937, at the height of the Great Purge, Stalin completely reversed the Soviet government's policies on Esperanto, denouncing it as "the language of spies" and had Esperantists exiled or executed. The use of Esperanto was then banned in the Soviet Union until 1956.
Fascist Italy allowed the use of Esperanto, finding its phonology similar to that of Italian and publishing some tourist material in the language.
During and after the Spanish Civil War, Francoist Spain persecuted anarchists, socialists and Catalan nationalists for many years, among whom the use of Esperanto was extensive, but in the 1950s the Esperanto movement was tolerated again.
Increasing use of Esperanto.
There are several numbers indicating an increasing use of Esperanto during the last decades.
The Hungarian census calculated 942 Esperanto speakers in 1941, 2,083 in 1990, 4,575 in 2001 and 8,397 in 2011. For 985 of these Esperanto was a family or native language.
In the 1960s the "Jarlibro" (yearbook) of the Universal Esperanto Association listed 58 (1961), 67 (1962) and 83 (1965) names of native speakers of Esperanto. , there were approximately 350 attested cases of families with native Esperanto speakers.
There are now Esperanto associations in some twenty African countries; nearly all of them were founded after 1960. The number of African addresses in the "Pasporta Servo" hospitality service went from 18 in 1988/89 to 59 in 2005.
There were four new music albums in Esperanto in the sixties, 17 in the seventies, 58 in the eighties, 75 in the nineties and over one hundred in the first decade of the new millennium. There are now more than 3000 songs in Esperanto.
The number of participants in Esperanto meetings of one week or longer in Germany went from around 100 in the early seventies to around 800 in 2008.
The Esperanto Wikipedia has over ,000articles as of 2016, and about 1,000 new articles are created every month. These numbers are similar to the Basque Wikipedia (articles) and the Danishâlanguage Wikipedia (). Before the foundation of the Esperanto Wikipedia in 2001, there was no generalâknowledge encyclopedia in Esperanto; the "Enciklopedio de Esperanto" (documenting the Esperanto movement) was published in 1934 and only reprinted, but never edited.
Between 1906 and 1971 there were about 28 dissertations about Esperanto and interlinguistics; about one in two or three years. This number increased significantly: Between 1975 and 1987 there were about 95 dissertationsâan average of seven per year after 1975.
Official use.
Esperanto has not been a secondary official language of any recognized country. However, there were plans at the beginning of the 20th century to establish Neutral Moresnet as the world's first Esperanto state. In addition, the self-proclaimed artificial island micronation of Rose Island used Esperanto as its official language in 1968.
The Chinese government has used Esperanto since 2001 for daily news on china.org.cn. China also uses Esperanto in China Radio International and for the internet magazine "El Popola Äinio".
The Vatican Radio has an Esperanto version of its website.
The US Army has published military phrase books in Esperanto, to be used from the 1950s through the 1970s in war games by mock enemy forces.
Esperanto is the working language of several non-profit international organizations such as the "", a left-wing cultural association, or Education@Internet, which has developed from an Esperanto organization; most others are specifically Esperanto organizations. The largest of these, the World Esperanto Association, has an official consultative relationship with the United Nations and UNESCO, which recognized Esperanto as a medium for international understanding in 1954. Esperanto is also the first language of teaching and administration of one university, the International Academy of Sciences San Marino.
In the summer of 1924, the American Radio Relay League adopted Esperanto as its official international auxiliary language, and hoped that the language would be used by radio amateurs in international communications, but its actual use for radio communications was negligible.
All the personal documents issued by the World Service Authority, including the World Passport, are written in Esperanto, together with English, French, Spanish, Russian, Arabic, and Chinese.
Linguistic properties.
Classification.
As a constructed language, most scholars would say Esperanto is not genealogically related to any natural language. The phonology, grammar, vocabulary, and semantics are based on the Indo-European languages spoken in Europe. The sound inventory is essentially Slavic, as is much of the semantics, whereas the vocabulary derives primarily from the Romance languages, with a lesser contribution from Germanic languages and minor contributions from Slavic languages and Greek. Pragmatics and other aspects of the language not specified by Zamenhof's original documents were influenced by the native languages of early authors, primarily Russian, Polish, German, and French. However, Paul Wexler proposes that Esperanto is relexified Yiddish, which in turn he claims is a relexified Slavic language.
Esperanto has been described as "a language lexically predominantly Romanic, morphologically intensively agglutinative, and to a certain degree isolating in character". Typologically, Esperanto has prepositions and a pragmatic word order that by default is "subjectâverbâobject." Adjectives can be freely placed before or after the nouns they modify, though placing them before the noun is more common. New words are formed through extensive prefixing and suffixing.
Phonology.
Esperanto has 23 consonants, five vowels, and two semivowels that combine with the vowels to form six diphthongs. (The consonant and semivowel are both written "j", and the uncommon consonant is written with the digraph "dz", which is the only consonant that doesn't have its own letter.) Tone is not used to distinguish meanings of words. Stress is always on the second-last vowel in fully Esperanto words unless a final vowel ' is elided, which occurs mostly in poetry. For example, ' "family" is , with the stress on the second "i", but when the word is used without the final " ()," the stress remains on the second ': .
Consonants.
The 23 consonants are:
The sound is usually trilled , but may be tapped . The is normally pronounced like English "v," but may be pronounced (between English "v" and "w") or , depending on the language background of the speaker. A semivowel normally occurs only in diphthongs after the vowels and , not as a consonant . Common, if debated, assimilation includes the pronunciation of ' as and ' as .
A large number of consonant clusters can occur, up to three in initial position (as in ', "strange") and four in medial position (as in ', "teach"). Final clusters are uncommon except in foreign names, poetic elision of final "," and a very few basic words such as ' "hundred" and ' "after".
Vowels.
Esperanto has the five vowels found in such languages as Spanish, Swahili, Modern Hebrew, and Modern Greek.
There are also two semivowels, and , which combine with the monophthongs to form six falling diphthongs: ", , , , ," and "".
Since there are only five vowels, a good deal of variation in pronunciation is tolerated. For instance, "e" commonly ranges from (French ') to (French '). These details often depend on the speaker's native language. A glottal stop may occur between adjacent vowels in some people's speech, especially when the two vowels are the same, as in ' "hero" ( or ) and ' "great-grandfather" ( or ).
Alphabet.
The Esperanto alphabet is based on the Latin script, using a one-sound-one-letter principle, except for Í¡. It includes six letters with diacritics: Ä, Ä, Ä¥, Äµ, Å (with circumflex), and Å­ (with breve). The alphabet does not include the letters "q, w, x," or "y", which are only used when writing unassimilated foreign terms or proper names.
The 28-letter alphabet is:
All unaccented letters are pronounced approximately as in the IPA, with the exception of "c". Esperanto "j" and "c" are used in a way familiar to speakers of many European languages, but which is largely unfamiliar to English speakers: "j" has a "y" sound, as in yellow" and "boy," and "c" has a "ts" sound, as in "hits or the "zz" in "pizza". The accented letters are a bit like "h"-digraphs in English: "Ä" is pronounced like English "ch", and "Å" like "sh". "Ä" is the "g" in gem", "Äµ" a "zh" sound, as in "fusion" or French Jacques", and the rare "Ä¥" is like the German , older Scottish English "loch, or how Scouse people sometimes pronounce the 'k' in "book" and 'ck' in "chicken".
Writing diacritics.
Until the widespread adoption of Unicode, the letters with diacritics (found in the "Latin-Extended A" section of the Unicode Standard) caused problems with printing and computing. This was particularly true of the five letters with circumflexes, as they do not occur in any other language. These problems have abated, and are now normally seen only with computing applications that are limited to ASCII characters (typically internet chat systems and databases).
There are two principal workarounds to this problem, which substitute digraphs for the accented letters. Zamenhof, the inventor of Esperanto, created an "h-convention", which replaces "Ä, Ä, Ä¥, Äµ, Å," and "Å­" with "ch, gh, hh, jh, sh," and "u," respectively. If used in a database, a program in principle could not determine whether to render, for example, "ch" as "c" followed by "h" or as "Ä", and would fail to render, for example, the word "" properly. A more recent "x-convention" has gained ground since the advent of computing. This system replaces each diacritic with an "x" (not part of the Esperanto alphabet) after the letter, producing the six digraphs "cx, gx, hx, jx, sx," and "ux."
There are computer keyboard layouts that support the Esperanto alphabet, and some systems use software that automatically replaces x- or h-convention digraphs with the corresponding diacritic letters ( for Microsoft Windows and for Windows Phone are examples). Another example is the Esperanto Wikipedia, which accepts the x-convention for input: when a contributor types "cx" when editing an article, it will appear as the correct ' in the article text. (The input pane also accepts '; when the page is saved, it will be changed to "cx", so that the x-convention applies uniformly in the wikitext.)
Grammar.
Esperanto words are derived by stringing together prefixes, roots, and suffixes. This process is regular, so that people can create new words as they speak and be understood. Compound words are formed with a modifier-first, head-final order, as in English (compare "birdsong" and "songbird," and likewise, ' and ').
The different parts of speech are marked by their own suffixes: all common nouns end in ', all adjectives in ', all derived adverbs in ', and all verbs in one of six tense and mood suffixes, such as the present tense '. Nouns and adjectives have two cases: nominative for grammatical subjects and in general, and accusative for direct objects and (after a preposition) to indicate direction of movement.
Singular nouns used as grammatical subjects end in ', plural subject nouns in ' (pronounced like English "oy"). Singular direct object forms end in ', and plural direct objects with the combination ' (rhymes with "coin"): ' indicates that the word is a noun, ' indicates the plural, and ' indicates the accusative (direct object) case. Adjectives agree with their nouns; their endings are singular subject ' (rhymes with "ha!"), plural subject ' (pronounced "eye"), singular object ', and plural object "" (rhymes with "fine").
The suffix "", besides indicating the direct object, is used to indicate movement and a few other things as well.
The six verb inflections consist of three tenses and three moods. They are present tense ', future tense ', past tense ', infinitive mood ', conditional mood ' and jussive mood ' (used for wishes and commands). Verbs are not marked for person or number. Thus, ' means "to sing", ' means "I sing", ' means "you sing", and ' means "they sing".
Word order is comparatively free. Adjectives may precede or follow nouns; subjects, verbs and objects may occur in any order. However, the article ' "the", demonstratives such as ' "that" and prepositions (such as ' "at") must come before their related nouns. Similarly, the negative ' "not" and conjunctions such as ' "and" and ' "that" must precede the phrase or clause that they introduce. In copular (A = B) clauses, word order is just as important as in English: "people are animals" is distinguished from "animals are people".
Vocabulary.
The core vocabulary of Esperanto was defined by ', published by Zamenhof in 1887. This book listed 900 roots; these could be expanded into tens of thousands of words using prefixes, suffixes, and compounding. In 1894, Zamenhof published the first Esperanto dictionary, ', which had a larger set of roots. The rules of the language allowed speakers to borrow new roots as needed; it was recommended, however, that speakers use most international forms and then derive related meanings from these.
Since then, many words have been borrowed, primarily (but not solely) from the European languages. Not all proposed borrowings become widespread, but many do, especially technical and scientific terms. Terms for everyday use, on the other hand, are more likely to be derived from existing roots; ' "computer", for instance, is formed from the verb ' "compute" and the suffix ' "tool". Words are also calqued; that is, words acquire new meanings based on usage in other languages. For example, the word ' "mouse" has acquired the meaning of a computer mouse from its usage in English. Esperanto speakers often debate about whether a particular borrowing is justified or whether meaning can be expressed by deriving from or extending the meaning of existing words.
Some compounds and formed words in Esperanto are not entirely straightforward; for example, ', literally "give out", means "publish", paralleling the usage of certain European languages (such as German). In addition, the suffix "-um-" has no defined meaning; words using the suffix must be learned separately (such as ' "to the right" and "" "clockwise").
There are not many idiomatic or slang words in Esperanto, as these forms of speech tend to make international communication difficultâworking against Esperanto's main goal.
Simple phrases.
Below are listed some useful Esperanto words and phrases along with transcriptions:
Sample text.
The following short extract gives an idea of the character of Esperanto. (Pronunciation is covered above; the Esperanto letter "j" is pronounced like English "y".)
Education.
The majority of Esperanto speakers learn the language through self-directed study, online tutorials, and correspondence courses taught by volunteers. More recently, free teaching websites, like "", have become popular.
Esperanto instruction is occasionally available at schools, including four primary schools in a pilot project under the supervision of the University of Manchester, and by one count at 69 universities. However, outside China and Hungary, these mostly involve informal arrangements rather than dedicated departments or state sponsorship. EÃ¶tvÃ¶s LorÃ¡nd University in Budapest had a department of Interlinguistics and Esperanto from 1966 to 2004, after which time instruction moved to vocational colleges; there are state examinations for Esperanto instructors. Additionally, Adam Mickiewicz University in Poland offers a diploma in Interlinguistics. The Senate of Brazil passed a bill in 2009 that would make Esperanto an optional part of the curriculum in public schools, although mandatory if there is demand for it. the bill is still under consideration by the Chamber of Deputies.
Various educators have estimated that Esperanto can be learned in anywhere from one quarter to one twentieth the amount of time required for other languages. Claude Piron, a psychologist formerly at the University of Geneva and ChineseâEnglishâRussianâSpanish translator for the United Nations, argued that Esperanto is far more intuitive than many ethnic languages. "Esperanto relies entirely on innate reflexes n differs from all other languages in that you can always trust your natural tendency to generalize patterns... The same neuropsychological law called b Jean Piaget "generalizing assimilation"âapplies to word formation as well as to grammar."
The Institute of Cybernetic Pedagogy at Paderborn (Germany) has compared the length of study time it takes natively French-speaking high-school students to obtain comparable 'standard' levels in Esperanto, English, German, and Italian. The results were:
Third-language acquisition.
Four primary schools in Britain, with some 230 pupils, are currently following a course in "propaedeutic Esperanto"âthat is, instruction in Esperanto to raise language awareness and accelerate subsequent learning of foreign languagesâunder the supervision of the University of Manchester. As they put it,
Studies have been conducted in New Zealand, United States, Germany, Italy and Australia. The results of these studies were favorable and demonstrated that studying Esperanto before another foreign language expedites the acquisition of the other, natural, language. This appears to be because learning subsequent foreign languages is easier than learning one's first foreign language, whereas the use of a grammatically simple and culturally flexible auxiliary language like Esperanto lessens the first-language learning hurdle. In one study, a group of European secondary school students studied Esperanto for one year, then French for three years, and ended up with a significantly better command of French than a control group, who studied French for all four years. 
Community.
Geography and demography.
Esperanto is by far the most widely spoken constructed language in the world. Speakers are most numerous in Europe and East Asia, especially in urban areas, where they often form Esperanto clubs. Esperanto is particularly prevalent in the northern and central countries of Europe; in China, Korea, Japan, and Iran within Asia; in Brazil, Argentina, and Mexico in the Americas; and in Togo in Africa.
Number of speakers.
An estimate of the number of Esperanto speakers was made by Sidney S. Culbert, a retired psychology professor at the University of Washington and a longtime Esperantist, who tracked down and tested Esperanto speakers in sample areas in dozens of countries over a period of twenty years. Culbert concluded that between one and two million people speak Esperanto at Foreign Service Level 3, "professionally proficient" (able to communicate moderately complex ideas without hesitation, and to follow speeches, radio broadcasts, etc.). Culbert's estimate was not made for Esperanto alone, but formed part of his listing of estimates for all languages of more than one million speakers, published annually in the World Almanac and Book of Facts. Culbert's most detailed account of his methodology is found in a 1989 letter to David Wolff. Since Culbert never published detailed intermediate results for particular countries and regions, it is difficult to independently gauge the accuracy of his results.
In the Almanac, his estimates for numbers of language speakers were rounded to the nearest million, thus the number for Esperanto speakers is shown as two million. This latter figure appears in "Ethnologue". Assuming that this figure is accurate, that means that about 0.03% of the world's population speak the language. Although it is not Zamenhof's goal of a universal language, it still represents a level of popularity unmatched by any other constructed language.
Marcus Sikosek (now Ziko van Dijk) has challenged this figure of 1.6 million as exaggerated. He estimated that even if Esperanto speakers were evenly distributed, assuming one million Esperanto speakers worldwide would lead one to expect about 180 in the city of Cologne. Van Dijk finds only 30 fluent speakers in that city, and similarly smaller-than-expected figures in several other places thought to have a larger-than-average concentration of Esperanto speakers. He also notes that there are a total of about 20,000 members of the various Esperanto organizations (other estimates are higher). Though there are undoubtedly many Esperanto speakers who are not members of any Esperanto organization, he thinks it unlikely that there are fifty times more speakers than organization members.
Finnish linguist Jouko Lindstedt, an expert on native-born Esperanto speakers, presented the following scheme to show the overall proportions of language capabilities within the Esperanto community:
In the absence of Dr. Culbert's detailed sampling data, or any other census data, it is impossible to state the number of speakers with certainty. According to the website of the World Esperanto Association:
In 2009 Lu Wunsch-Rolshoven used 2001 year census data from Hungary and Lithuania as a base for an estimate, resulting in approximately 160,000 to 300,000 to speak the language actively or fluently throughout the world, with about 80,000 to 150,000 of these being in the European Union.
Native speakers.
Native Esperanto speakers, "," have learned the language from birth from Esperanto-speaking parents. This usually happens when Esperanto is the chief or only common language in an international family, but sometimes occurs in a family of devoted Esperantists. The 15th edition of "Ethnologue" cited estimates that there were 200 to 2,000 native speakers in 1996, but these figures were removed from the 16th and 17th editions.
Esperanto speaking users of Facebook.
Facebook has about 350,000 users who indicated Esperanto as one of their languages.
Culture.
Esperantists can access an international culture, including a large body of original as well as translated literature. There are more than 25,000 Esperanto books, both originals and translations, as well as several regularly distributed Esperanto magazines. In 2013 a museum about Esperanto opened in China. Esperantists use the language for free accommodations with Esperantists in 92 countries using the or to develop pen pals through "".
Every year, Esperantists meet for the World Congress of Esperanto "()".
Historically, much Esperanto music, such as ', has been in various folk traditions. There is also a variety of classical and semi-classical choral music, both original and translated, as well as large ensemble music that includes voices singing Esperanto texts. Lou Harrison, who incorporated styles and instruments from many world cultures in his music, used Esperanto titles and/or texts in several of his works, most notably ' (1973). David Gaines used Esperanto poems as well as an excerpt from a speech by Dr. Zamenhof for his "Symphony No. 1 (Esperanto)" for mezzo-soprano and orchestra (1994â98). He wrote original Esperanto text for his "" ("I Can Cry No Longer") for unaccompanied SATB choir (1994).
There are also shared traditions, such as Zamenhof Day, and shared behaviour patterns. Esperantists speak primarily in Esperanto at international Esperanto meetings.
Detractors of Esperanto occasionally criticize it as "having no culture". Proponents, such as Prof. Humphrey Tonkin of the University of Hartford, observe that Esperanto is "culturally neutral by design, as it was intended to be a facilitator between cultures, not to be the carrier of any one national culture". The late Scottish Esperanto author William Auld wrote extensively on the subject, arguing that Esperanto is "the expression of a common human culture, unencumbered by national frontiers. Thus it is considered a culture on its own."
Noted authors in Esperanto.
Some authors of works in Esperanto are:
Popular culture.
Esperanto has been used in a number of films and novels. Typically, this is done either to add the exotic flavour of a foreign language without representing any particular ethnicity, or to avoid going to the trouble of inventing a new language. The Charlie Chaplin film "The Great Dictator" (1940) showed Jewish ghetto shop signs in Esperanto. Two full-length feature films have been produced with dialogue entirely in Esperanto: "," in 1964, and "Incubus," a 1965 B-movie horror film. A language school teaching Esperanto is featured in Graham Greene's novel "The Confidential Agent", which was made into a film starring Charles Boyer and Lauren Bacall (1945). Other amateur productions have been made, such as a dramatization of the novel "" (Gerda Has Disappeared). In "Stamboul Train", Greene used Esperanto as the language on signs at the main train station in Budapest. A number of mainstream films in national languages have used Esperanto in some way.
Esperanto is used as the universal language in the far future of Harry Harrison's "Stainless Steel Rat" and "Deathworld" stories. Poul Anderson's story "High Treason" takes place in a future where Earth became united politically but was still divided into many languages and cultures, and Esperanto became the language of its space armed forces, fighting wars with various extraterrestrial races.
The opening song to the popular video game "Final Fantasy XI", "", was written in Esperanto. It was the first game in the series that was played online, and would have players from both Japan and North America (official European support was added after the North American launch) playing together on the same servers, using an auto-translate tool to communicate. The composer, Nobuo Uematsu, felt that Esperanto was a good language to symbolize worldwide unity.
In the geek fiction novel "Off to Be the Wizard", Esperanto is programmed as the language that triggers all of the wizard's spells. Philip, Martin's teacher, explains that this is because "no one really speaks Esperanto and it's easy to learn".
Esperanto is also found in the comic book series "Saga" as the language Blue, spoken by the inhabitants of Wreath. It is rendered in blue-colored text. Blue is generally only spoken by inhabitants of Wreath, while most other cultures use a universal language that appears to be simply named "Language." Some Wreath inhabitants use translator rings to communicate with those who don't speak Blue. Magic seems to be activated via the linguistic medium of blue.
In the television show "Red Dwarf", the bulk of which takes place more than three million years in the future, crewman Arnold Rimmer constantly spends his time trying to learn Esperanto and failing, even compared to his bunkmate Dave Lister who only maintains a casual interest. Additionally many of the signs around the ship "Red Dwarf" are written in both English and Esperanto. The novel "Infinity Welcomes Careful Drivers" states that, although not required, it is widely expected that officers in the Space Corps be fluent in the language, hence Rimmer's interest.
Science.
In 1921 the French Academy of Sciences recommended using Esperanto for international scientific communication. A few scientists and mathematicians, such as Maurice FrÃ©chet (mathematics), John C. Wells (linguistics), Helmar Frank (pedagogy and cybernetics), and Nobel laureate Reinhard Selten (economics) have published part of their work in Esperanto. Frank and Selten were among the founders of the International Academy of Sciences in San Marino, sometimes called the "Esperanto University", where Esperanto is the primary language of teaching and administration.
A message in Esperanto was recorded and included in "Voyager 1"s Golden Record.
Commerce and trade.
Esperanto business groups have been active for many years. The French Chamber of Commerce did research in the 1920s and reported in "The New York Times" in 1921 that Esperanto seemed to be the best business language.
Goals of the movement.
Zamenhof's intention was to create an easy-to-learn language to foster international understanding. It was to serve as an international auxiliary language, that is, as a universal second language, not to replace ethnic languages. This goal was widely shared among Esperanto speakers in the early decades of the movement. Later, Esperanto speakers began to see the language and the culture that had grown up around it as ends in themselves, even if Esperanto is never adopted by the United Nations or other international organizations.
Esperanto speakers who want to see Esperanto adopted officially or on a large scale worldwide are commonly called ', from ', meaning "final victory", Those who focus on the intrinsic value of the language are commonly called ", from Rauma, Finland, where a declaration on the near-term unlikelihood of the " and the value of Esperanto culture was made at the International Youth Congress in 1980.
Symbols and flags.
The earliest flag, and the one most commonly used today, features a green five-pointed star against a white canton, upon a field of green. It was proposed to Zamenhof by Irishman Richard Geoghegan, author of the first Esperanto textbook for English speakers, in 1887. The flag was approved in 1905 by delegates to the first conference of Esperantists at Boulogne-sur-Mer. A version with an "" superimposed over the green star is sometimes seen. Other variants include that for Christian Esperantists, with a white Christian cross superimposed upon the green star, and that for Leftists, with the color of the field changed from green to red.
In 1987, a second flag design was chosen in a contest organized by the UEA celebrating the first centennial of the language. It featured a white background with two stylised curved "E"s facing each other. Dubbed the " (jubilee symbol), it attracted criticism from some Esperantists, who dubbed it the " (melon) because of the design's elliptical shape. It is still in use, though to a lesser degree than the traditional symbol, known as the "" (green star).
Politics.
Esperanto has been placed in many proposed political situations. The most popular of these is the EuropeâDemocracyâEsperanto, which aims to establish Esperanto as the official language of the European Union. Grin's Report, published in 2005 by FranÃ§ois Grin found that the use of English as the lingua franca within the European Union costs billions annually and significantly benefits English-speaking countries financially. The report considered a scenario where Esperanto would be the lingua franca and found that it would have many advantages, particularly economically speaking, as well as ideologically.
Religion.
Esperanto has served an important role in several religions, such as Oomoto from Japan and the BahÃ¡'Ã­ Faith from Iran, and has been encouraged by others, like some Spiritist movements.
Oomoto.
The Oomoto religion encourages the use of Esperanto among its followers and includes Zamenhof as one of its deified spirits.
BahÃ¡'Ã­ Faith.
The BahÃ¡'Ã­ Faith encourages the use of an auxiliary international language. The Baha'i's believe that it will not be the language of the future, although it has great potential in this role, as it has not been chosen by the people. L. L. Zamenhof's daughter Lidja became a BahÃ¡'Ã­, and various volumes of the BahÃ¡'Ã­ literatures and other Baha'i books have been translated into Esperanto. In 1973, the BahÃ¡'Ã­ Esperanto-League for active BahÃ¡'Ã­ supporters of Esperanto was founded.
Spiritism.
In 1908, spiritist Camilo Chaigneau wrote an article named "Spiritism and Esperanto" in the periodic "La Vie d'Outre-Tombe" recommending the use of Esperanto in a "central magazine" for all spiritists and esperantists. Esperanto then became actively promoted by spiritists, at least in Brazil, initially by Ismael Gomes Braga and FrantiÅ¡ek Lorenz; the latter is known in Brazil as Francisco Valdomiro Lorenz, and was a pioneer of both spiritist and Esperantist movements in this country.
The Brazilian Spiritist Federation publishes Esperanto coursebooks, translations of Spiritism's basic books, and encourages Spiritists to become Esperantists.
Bible translations.
The first translation of the Bible into Esperanto was a translation of the Tanakh or Old Testament done by L. L. Zamenhof. The translation was reviewed and compared with other languages' translations by a group of British clergy and scholars before its publication at the British and Foreign Bible Society in 1910. In 1926 this was published along with a New Testament translation, in an edition commonly called the ". In the 1960s, the ' tried to organize a new, ecumenical Esperanto Bible version. Since then, the Dutch Remonstrant pastor Gerrit Berveling has translated the Deuterocanonical or apocryphal books in addition to new translations of the Gospels, some of the New Testament epistles, and some books of the Tanakh or Old Testament. These have been published in various separate booklets, or serialized in ', but the Deuterocanonical books have appeared in recent editions of the Londona Biblio.
Christianity.
Christian Esperanto organizations include two that were formed early in the history of Esperanto:
Individual churches using Esperanto include:
Chick Publications, publisher of Protestant fundamentalist themed evangelistic tracts, has published a number of comic book style tracts by Jack T. Chick translated into Esperanto, including "This Was Your Life!" ("")
Islam.
Ayatollah Khomeini of Iran called on Muslims to learn Esperanto and praised its use as a medium for better understanding among peoples of different religious backgrounds. After he suggested that Esperanto replace English as an international lingua franca, it began to be used in the seminaries of Qom. An Esperanto translation of the Qur'an was published by the state shortly thereafter. In 1981, its usage became less popular when it became apparent that followers of the BahÃ¡'Ã­ Faith were interested in it. However, during the recent decades, specially after the establishment of the Sabzandishan (Green-Thinkers) Institute in 1996, the first official Esperanto institute in Iran ever, and publication of its 56-page organ, called Payame Sabzandishan (Message of Green-Thinkers), a seasonal (quarterly) magazine in Esperanto and Persian from the autumn of 2002 till now, and recognition of the Iranian Esperanto-Association by the Universal Esperanto-Association (which enjoys official relations with UN and UNESCO) as its Iranian official branch in 2005, a new era started in Iran for spreading of Esperanto Movement as vastly as possible. During this new era, i.a. there have been speeches, lectures, seminars and courses in different cultural centers, universities and schools; publication of original and translated books and articles on Esperanto and specially its neutrality (politically, religiously, nationally, racially, etc.) by diverse publishers and in varied Persian newspapers and magazines; ... E.g. in the Persian translation of William Auld's book, called The Phenomenon Esperanto, 14 annexes were added to show more the history and neutrality of Esperanto language: as example, in the first annex, called The Views of World Celebrities on Esperanto, the Persian readers can read the positive views and opinions of 15 acclaimed and famous leaders and writers on Esperanto from different countries, religions, political backgrounds, languages and races, like Mahatma Gandhi, Leo Tolstoy, Romain Rolland, Umberto Eco, Rudolf Diesel, Rabindranath Tagore, Helen Keller, Lu Xun, J. R. R. Tolkien, ... (William Auld was nominated for the Nobel Prize in Literature in 1999, 2004, and 2006 making him the first person to be nominated for works in Esperanto.)
Criticism.
Esperanto was conceived as a language of international communication, more precisely as a universal second language. Since publication, there has been debate over whether it is possible for Esperanto to attain this position, and whether it would be an improvement for international communication were it to do so; Esperanto proponents have also been criticized for diverting public funds to encourage its study over more-useful living world languages.
Since Esperanto is a planned language, there have been many criticisms of minor points. An example is Zamenhof's choice of the word ' over something like ' for "husband, spouse", or his choice of the Classic Greek and Old Latin singular and plural endings "-, -, -, -" over their Medieval contractions "-, -, -, -." (Both these changes were adopted by the reform, though dispensed with adjectival agreement altogether.) Some more common examples of general criticism include the following:
Modifications.
Though Esperanto itself has changed little since the publication of the "" (Foundation of Esperanto), a number of reform projects have been proposed over the years, starting with Zamenhof's proposals in 1894 and in 1907. Several later constructed languages, such as Universal, were based on Esperanto.
In modern times, attempts have been made to eliminate perceived sexism in the language, such as Riism.
Eponymous entities.
There are some geographical and astronomical features named after Esperanto, or after its creator L. L. Zamenhof. These include Esperanto Island in Zed Islands off Livingston Island, and the asteroids 1421 Esperanto and 1462 Zamenhof discovered by Finnish astronomer and Esperantist YrjÃ¶ VÃ¤isÃ¤lÃ¤.

</doc>
<doc id="9251" url="https://en.wikipedia.org/wiki?curid=9251" title="Engineering">
Engineering

Engineering is the application of mathematics, empirical evidence and scientific, economic, social, and practical knowledge in order to invent, innovate, design, build, maintain, research, and improve structures, machines, tools, systems, components, materials, and processes.
The discipline of engineering is extremely broad, and encompasses a range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied science, technology and types of application.
The term "Engineering" is derived from the Latin "ingenium", meaning "cleverness" and "ingeniare", meaning "to contrive, devise".
Definition.
The American Engineers' Council for Professional Development (ECPD, the predecessor of ABET) has defined "engineering" as:
The creative application of scientific principles to design or develop structures, machines, apparatus, or manufacturing processes, or works utilizing them singly or in combination; or to construct or operate the same with full cognizance of their design; or to forecast their behavior under specific operating conditions; all as respects an intended function, economics of operation or safety to life and property.
History.
Engineering has existed since ancient times as humans devised fundamental inventions such as the wedge, lever, wheel, and pulley. Each of these inventions is essentially consistent with the modern definition of engineering.
The term "engineering" deriving from the word "engineer", which itself dates back to 1300, when an "engine'er" (literally, one who operates an "engine") originally referred to "a constructor of military engines." In this context, now obsolete, an "engine" referred to a military machine, "i.e.", a mechanical contraption used in war (for example, a catapult). Notable examples of the obsolete usage which have survived to the present day are military engineering corps, "e.g.", the U.S. Army Corps of Engineers.
The word "engine" itself is of even older origin, ultimately deriving from the Latin "ingenium" (c. 1250), meaning "innate quality, especially mental power, hence a clever invention."
Later, as the design of civilian structures such as bridges and buildings matured as a technical discipline, the term civil engineering entered the lexicon as a way to distinguish between those specializing in the construction of such non-military projects and those involved in the older discipline of military engineering.
Ancient era.
The Pharos of Alexandria, the pyramids in Egypt, the Hanging Gardens of Babylon, the Acropolis and the Parthenon in Greece, the Roman aqueducts, Via Appia and the Colosseum, TeotihuacÃ¡n and the cities and pyramids of the Mayan, Inca and Aztec Empires, the Great Wall of China, the Brihadeeswarar Temple of Thanjavur and Indian Temples, among many others, stand as a testament to the ingenuity and skill of the ancient civil and military engineers.
The earliest civil engineer known by name is Imhotep. As one of the officials of the Pharaoh, DjosÃ¨r, he probably designed and supervised the construction of the Pyramid of Djoser (the Step Pyramid) at Saqqara in Egypt around 2630-2611 BC.
Ancient Greece developed machines in both civilian and military domains. The Antikythera mechanism, the first known mechanical computer, and the mechanical inventions of Archimedes are examples of early mechanical engineering. Some of Archimedes' inventions as well as the Antikythera mechanism required sophisticated knowledge of differential gearing or epicyclic gearing, two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are still widely used today in diverse fields such as robotics and automotive engineering.
Chinese, Greek and Roman armies employed complex military machines and inventions such as artillery which was developed by the Greeks around the 4th century B.C., the trireme, the ballista and the catapult. In the Middle Ages, the trebuchet was developed.
Renaissance era.
William Gilbert is considered to be the first electrical engineer with his 1600 publication of De Magnete. He coined the term "electricity".
The first steam engine was built in 1698 by Thomas Savery. The development of this device gave rise to the Industrial Revolution in the coming decades, allowing for the beginnings of mass production.
With the rise of engineering as a profession in the 18th century, the term became more narrowly applied to fields in which mathematics and science were applied to these ends. Similarly, in addition to military and civil engineering the fields then known as the mechanic arts became incorporated into engineering.
Modern era.
The inventions of Thomas Newcomen and the Scottish engineer James Watt gave rise to modern mechanical engineering. The development of specialized machines and machine tools during the industrial revolution led to the rapid growth of mechanical engineering both in its birthplace Britain and abroad.
John Smeaton was the first self-proclaimed civil engineer, and is often regarded as the "father" of civil engineering. He was an English civil engineer responsible for the design of bridges, canals, harbours and lighthouses. He was also a capable mechanical engineer and an eminent physicist. Smeaton designed the third Eddystone Lighthouse (1755â59) where he pioneered the use of 'hydraulic lime' (a form of mortar which will set under water) and developed a technique involving dovetailed blocks of granite in the building of the lighthouse. His lighthouse remained in use until 1877 and was dismantled and partially rebuilt at Plymouth Hoe where it is known as Smeaton's Tower. He is important in the history, rediscovery of, and development of modern cement, because he identified the compositional requirements needed to obtain "hydraulicity" in lime; work which led ultimately to the invention of Portland cement.
The United States census of 1850 listed the occupation of "engineer" for the first time with a count of 2,000. There were fewer than 50 engineering graduates in the U.S. before 1865. In 1870 there were a dozen U.S. mechanical engineering graduates, with that number increasing to 43 per year in 1875. In 1890 there were 6,000 engineers in civil, mining, mechanical and electrical.
There was no chair of applied mechanism and applied mechanics established at Cambridge until 1875, and no chair of engineering at Oxford until 1907. Germany established technical universities earlier.
The early stages of electrical engineering included the experiments of Alessandro Volta in the 1800s, the experiments of Michael Faraday, Georg Ohm and others and the invention of the electric motor in 1872. The theoretical work of James Maxwell (see: Maxwell's equations) and Heinrich Hertz in the late 19th century gave rise to the field of electronics. The later inventions of the vacuum tube and the transistor further accelerated the development of electronics to such an extent that electrical and electronics engineers currently outnumber their colleagues of any other engineering specialty.
Chemical engineering developed in the late nineteenth century. Industrial scale manufacturing demanded new materials and new processes and by 1880 the need for large scale production of chemicals was such that a new industry was created, dedicated to the development and large scale manufacturing of chemicals in new industrial plants. The role of the chemical engineer was the design of these chemical plants and processes.
Aeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design. Its origins can be traced back to the aviation pioneers around the start of the 20th century although the work of Sir George Cayley has recently been dated as being from the last decade of the 18th century. Early knowledge of aeronautical engineering was largely empirical with some concepts and skills imported from other branches of engineering.
The first PhD in engineering (technically, "applied science and engineering") awarded in the United States went to Josiah Willard Gibbs at Yale University in 1863; it was also the second PhD awarded in science in the U.S.
Only a decade after the successful flights by the Wright brothers, there was extensive development of aeronautical engineering through development of military aircraft that were used in World War I . Meanwhile, research to provide fundamental background science continued by combining theoretical physics with experiments.
In 1990, with the rise of computer technology, the first search engine was built by computer engineer Alan Emtage.
Main branches of engineering.
Engineering is a broad discipline which is often broken down into several sub-disciplines. These disciplines concern themselves with differing areas of engineering work. Although initially an engineer will usually be trained in a specific discipline, throughout an engineer's career the engineer may become multi-disciplined, having worked in several of the outlined areas. Engineering is often characterized as having four main branches:
Beyond these four, a number of other branches are recognized. Historically, naval engineering and mining engineering were major branches. Modern fields sometimes included as major branches are manufacturing engineering, acoustical engineering, corrosion engineering, Instrumentation and control, aerospace, automotive, computer, electronic, petroleum, systems, audio, software, architectural, agricultural, biosystems, biomedical, geological, textile, industrial, materials, and nuclear engineering. These and other branches of engineering are represented in the 36 institutions forming the membership of the UK Engineering Council.
New specialties sometimes combine with the traditional fields and form new branches - for example Earth Systems Engineering and Management involves a wide range of subject areas including anthropology, engineering studies, environmental science, ethics and philosophy. A new or emerging area of application will commonly be defined temporarily as a permutation or subset of existing disciplines; there is often gray area as to when a given sub-field warrants classification as a new "branch." One key indicator of such emergence is when major universities start establishing departments and programs in the new field.
For each of these fields there exists considerable overlap, especially in the areas of the application of fundamental sciences to their disciplines such as physics, chemistry, and mathematics.
Practice.
One who practices engineering is called an engineer, and those licensed to do so may have more formal designations such as Professional Engineer, Designated Engineering Representative, Chartered Engineer, Incorporated Engineer, Ingenieur or European Engineer.
Methodology.
Engineers apply mathematics and sciences such as physics to find suitable solutions to problems or to make improvements to the status quo. More than ever, engineers are now required to have knowledge of relevant sciences for their design projects. As a result, they may keep on learning new material throughout their career.
If multiple options exist, engineers weigh different design choices on their merits and choose the solution that best matches the requirements. The crucial and unique task of the engineer is to identify, understand, and interpret the constraints on a design in order to produce a successful result. It is usually not enough to build a technically successful product; it must also meet further requirements.
Constraints may include available resources, physical, imaginative or technical limitations, flexibility for future modifications and additions, and other factors, such as requirements for cost, safety, marketability, productivity, and serviceability. By understanding the constraints, engineers derive specifications for the limits within which a viable object or system may be produced and operated.
A general methodology and epistemology of engineering can be inferred from the historical case studies and comments provided by Walter Vincenti. Though Vincenti's case studies are from the domain of aeronautical engineering, his conclusions can be transferred into many other branches of engineering, too.
According to Billy Vaughn Koen, the ""engineering method" is the use of heuristics to cause the best change in a poorly understood situation within the available resources." Koen argues that the definition of what makes one an engineer should not be based on what he produces, but rather how he goes about it.
Problem solving.
Engineers use their knowledge of science, mathematics, logic, economics, and appropriate experience or tacit knowledge to find suitable solutions to a problem. Creating an appropriate mathematical model of a problem allows them to analyze it (sometimes definitively), and to test potential solutions.
Usually multiple reasonable solutions exist, so engineers must evaluate the different design choices on their merits and choose the solution that best meets their requirements. Genrich Altshuller, after gathering statistics on a large number of patents, suggested that compromises are at the heart of "low-level" engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.
Engineers typically attempt to predict how well their designs will perform to their specifications prior to full-scale production. They use, among other things: prototypes, scale models, simulations, destructive tests, nondestructive tests, and stress tests. Testing ensures that products will perform as expected.
Engineers take on the responsibility of producing designs that will perform as well as expected and will not cause unintended harm to the public at large. Engineers typically include a factor of safety in their designs to reduce the risk of unexpected failure. However, the greater the safety factor, the less efficient the design may be.
The study of failed products is known as forensic engineering, and can help the product designer in evaluating his or her design in the light of real conditions. The discipline is of greatest value after disasters, such as bridge collapses, when careful analysis is needed to establish the cause or causes of the failure.
Computer use.
As with all modern scientific and technological endeavors, computers and software play an increasingly important role. As well as the typical business application software there are a number of computer aided applications (computer-aided technologies) specifically for engineering. Computers can be used to generate models of fundamental physical processes, which can be solved using numerical methods.
One of the most widely used design tools in the profession is computer-aided design (CAD) software like CATIA, Autodesk Inventor, DSS SolidWorks or Pro Engineer which enables engineers to create 3D models, 2D drawings, and schematics of their designs. CAD together with digital mockup (DMU) and CAE software such as finite element method analysis or analytic element method allows engineers to create models of designs that can be analyzed without having to make expensive and time-consuming physical prototypes.
These allow products and components to be checked for flaws; assess fit and assembly; study ergonomics; and to analyze static and dynamic characteristics of systems such as stresses, temperatures, electromagnetic emissions, electrical currents and voltages, digital logic levels, fluid flows, and kinematics. Access and distribution of all this information is generally organized with the use of product data management software.
There are also many tools to support specific engineering tasks such as computer-aided manufacturing (CAM) software to generate CNC machining instructions; manufacturing process management software for production engineering; EDA for printed circuit board (PCB) and circuit schematics for electronic engineers; MRO applications for maintenance management; and AEC software for civil engineering.
In recent years the use of computer software to aid the development of goods has collectively come to be known as product lifecycle management (PLM).
Social context.
Engineering as a subject ranges from large collaborations to small individual projects. Almost all engineering projects are beholden to some sort of financing agency: a company, a set of investors, or a government. The few types of engineering that are minimally constrained by such issues are "pro bono" engineering and open-design engineering.
By its very nature engineering has interconnections with society and human behavior. Every product or construction used by modern society will have been influenced by engineering. Engineering is a very powerful tool to make changes to environment, society and economies, and its application brings with it a great responsibility. Many engineering societies have established codes of practice and codes of ethics to guide members and inform the public at large.
Engineering projects can be subject to controversy. Examples from different engineering disciplines include the development of nuclear weapons, the Three Gorges Dam, the design and use of sport utility vehicles and the extraction of oil. In response, some western engineering companies have enacted serious corporate and social responsibility policies.
Engineering is a key driver of human development. Sub-Saharan Africa in particular has a very small engineering capacity which results in many African nations being unable to develop crucial infrastructure without outside aid. The attainment of many of the Millennium Development Goals requires the achievement of sufficient engineering capacity to develop infrastructure and sustainable technological development.
All overseas development and relief NGOs make considerable use of engineers to apply solutions in disaster and development scenarios. A number of charitable organizations aim to use engineering directly for the good of mankind:
Engineering companies in many established economies are facing significant challenges ahead with regard to the number of skilled engineers being trained, compared with the number retiring. This problem is very prominent in the UK. There are many economic and political issues that this can cause, as well as ethical issues It is widely agreed that engineering faces an "image crisis", rather than it being fundamentally an unattractive career. Much work is needed to avoid huge problems in the UK and well as the USA and other western economies.
Relationships with other disciplines.
Science.
There exists an overlap between the sciences and engineering practice; in engineering, one applies science. Both areas of endeavor rely on accurate observation of materials and phenomena. Both use mathematics and classification criteria to analyze and communicate observations.
Scientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes. Conversely, in the process of developing technology engineers sometimes find themselves exploring new phenomena, thus becoming, for the moment, scientists.
In the book "What Engineers Know and How They Know It", Walter Vincenti asserts that engineering research has a character different from that of scientific research. First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.
Examples are the use of numerical approximations to the NavierâStokes equations to describe aerodynamic flow over an aircraft, or the use of Miner's rule to calculate fatigue damage. Second, engineering research employs many semi-empirical methods that are foreign to pure scientific research, one example being the method of parameter variation.
As stated by Fung "et al." in the revision to the classic engineering text "Foundations of Solid Mechanics":
Engineering is quite different from science. Scientists try to understand nature. Engineers try to make things that do not exist in nature. Engineers stress invention. To embody an invention the engineer must put his idea in concrete terms, and design something that people can use. That something can be a device, a gadget, a material, a method, a computing program, an innovative experiment, a new solution to a problem, or an improvement on what is existing. Since a design has to be concrete, it must have its geometry, dimensions, and characteristic numbers. Almost all engineers working on new designs find that they do not have all the needed information. Most often, they are limited by insufficient scientific knowledge. Thus they study mathematics, physics, chemistry, biology and mechanics. Often they have to add to the sciences relevant to their profession. Thus engineering sciences are born.
Although engineering solutions make use of scientific principles, engineers must also take into account safety, efficiency, economy, reliability and constructability or ease of fabrication as well as the environment, ethical and legal considerations such as patent infringement or liability in the case of failure of the solution.
Medicine and biology.
The study of the human body, albeit from different directions and for different purposes, is an important common link between medicine and some engineering disciplines. Medicine aims to sustain, repair, enhance and even replace functions of the human body, if necessary, through the use of technology.
Modern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers. The fields of bionics and medical bionics are dedicated to the study of synthetic implants pertaining to natural systems.
Conversely, some engineering disciplines view the human body as a biological machine worth studying, and are dedicated to emulating many of its functions by replacing biology with technology. This has led to fields such as artificial intelligence, neural networks, fuzzy logic, and robotics. There are also substantial interdisciplinary interactions between engineering and medicine.
Both fields provide solutions to real world problems. This often requires moving forward before phenomena are completely understood in a more rigorous scientific sense and therefore experimentation and empirical knowledge is an integral part of both.
Medicine, in part, studies the function of the human body. The human body, as a biological machine, has many functions that can be modeled using engineering methods.
The heart for example functions much like a pump, the skeleton is like a linked structure with levers, the brain produces electrical signals etc. These similarities as well as the increasing importance and application of engineering principles in medicine, led to the development of the field of biomedical engineering that uses concepts developed in both disciplines.
Newly emerging branches of science, such as systems biology, are adapting analytical tools traditionally used for engineering, such as systems modeling and computational analysis, to the description of biological systems.
Art.
There are connections between engineering and art;
they are direct in some fields, for example, architecture, landscape architecture and industrial design (even to the extent that these disciplines may sometimes be included in a university's Faculty of Engineering); and indirect in others.
The Art Institute of Chicago, for instance, held an exhibition about the art of NASA's aerospace design. Robert Maillart's bridge design is perceived by some to have been deliberately artistic. At the University of South Florida, an engineering professor, through a grant with the National Science Foundation, has developed a course that connects art and engineering.
Among famous historical figures Leonardo da Vinci is a well-known Renaissance artist and engineer, and a prime example of the nexus between art and engineering.
Other fields.
In political science the term "engineering" has been borrowed for the study of the subjects of social engineering and political engineering, which deal with forming political and social structures using engineering methodology coupled with political science principles. Financial engineering has similarly borrowed the term.

</doc>
<doc id="9252" url="https://en.wikipedia.org/wiki?curid=9252" title="Education">
Education

Education is the process of facilitating learning, or the acquisition of knowledge, skills, values, beliefs, and habits. Educational methods include storytelling, discussion, teaching, training, and directed research. Education frequently takes place under the guidance of educators, but learners may also educate themselves. Education can take place in formal or informal settings and any experience that has a formative effect on the way one thinks, feels, or acts may be considered educational. The methodology of teaching is called pedagogy.
Education is commonly and formally divided into stages such as preschool or kindergarten, primary school, secondary school and then college, university or apprenticeship.
A right to education has been recognized by some governments, including at the global level: Article 13 of the United Nations' 1966 International Covenant on Economic, Social and Cultural Rights recognizes a universal right to education. In most regions education is compulsory up to a certain age.
Etymology.
Etymologically, the word "education" is derived from the Latin "ÄducÄtiÅ" ("A breeding, a bringing up, a rearing") from "ÄdÅ«cÅ" ("I educate, I train") which is related to the homonym "ÄdÅ«cÅ" ("I lead forth, I take out; I raise up, I erect") from "Ä-" ("from, out of") and "dÅ«cÅ" ("I lead, I conduct").
History.
Education began in prehistory, as adults trained the young in the knowledge and skills deemed necessary in their society. In pre-literate societies this was achieved orally and through imitation. Story-telling passed knowledge, values, and skills from one generation to the next. As cultures began to extend their knowledge beyond skills that could be readily learned through imitation, formal education developed. Schools existed in Egypt at the time of the Middle Kingdom.
Plato founded the Academy in Athens, the first institution of higher learning in Europe. The city of Alexandria in Egypt, established in 330 BCE, became the successor to Athens as the intellectual cradle of Ancient Greece. There, the great Library of Alexandria was built in the 3rd century BCE. European civilizations suffered a collapse of literacy and organization following the fall of Rome in AD 476.
In China, Confucius (551-479 BCE), of the State of Lu, was the country's most influential ancient philosopher, whose educational outlook continues to influence the societies of China and neighbors like Korea, Japan and Vietnam. Confucius gathered disciples and searched in vain for a ruler who would adopt his ideals for good governance, but his Analects were written down by followers and have continued to influence education in East Asia into the modern era.
After the Fall of Rome, the Catholic Church became the sole preserver of literate scholarship in Western Europe. The church established cathedral schools in the Early Middle Ages as centers of advanced education. Some of these establishments ultimately evolved into medieval universities and forebears of many of Europe's modern universities. During the High Middle Ages, Chartres Cathedral operated the famous and influential Chartres Cathedral School. The medieval universities of Western Christendom were well-integrated across all of Western Europe, encouraged freedom of inquiry, and produced a great variety of fine scholars and natural philosophers, including Thomas Aquinas of the University of Naples, Robert Grosseteste of the University of Oxford, an early expositor of a systematic method of scientific experimentation, and Saint Albert the Great, a pioneer of biological field research. Founded in 1088, the University of Bologne is considered the first, and the oldest continually operating university.
Elsewhere during the Middle Ages, Islamic science and mathematics flourished under the Islamic caliphate which was established across the Middle East, extending from the Iberian Peninsula in the west to the Indus in the east and to the Almoravid Dynasty and Mali Empire in the south.
The Renaissance in Europe ushered in a new age of scientific and intellectual inquiry and appreciation of ancient Greek and Roman civilizations. Around 1450, Johannes Gutenberg developed a printing press, which allowed works of literature to spread more quickly. The European Age of Empires saw European ideas of education in philosophy, religion, arts and sciences spread out across the globe. Missionaries and scholars also brought back new ideas from other civilisationsÂ â as with the Jesuit China missions who played a significant role in the transmission of knowledge, science, and culture between China and Europe, translating works from Europe like Euclid's Elements for Chinese scholars and the thoughts of Confucius for European audiences. The Enlightenment saw the emergence of a more secular educational outlook in Europe.
In most countries today, full-time education, whether at school or otherwise, is compulsory for all children up to a certain age. Due to this the proliferation of compulsory education, combined with population growth, UNESCO has calculated that in the next 30Â years more people will receive formal education than in all of human history thus far.
Formal education.
Formal education occurs in a structured environment whose explicit purpose is teaching students. Usually, formal education takes place in a school environment with classrooms of multiple students learning together with a trained, certified teacher of the subject. Most school systems are designed around a set of values or ideals that govern all educational choices in that system. Such choices include curriculum, physical classroom design, student-teacher interactions, methods of assessment, class size, educational activities, and more.
Preschool.
Preschools provide education from ages approximately three to seven, depending on the country, when children enter primary education. These are also known as nursery schools and as kindergarten, except in the US, where kindergarten is a term used for primary education. Kindergarten "provide a child-centered, preschool curriculum for three- to seven-year-old children that aim at unfolding the child's physical, intellectual, and moral nature with balanced emphasis on each of them."
Primary.
Primary (or elementary) education consists of the first five to seven years of formal, structured education. In general, primary education consists of six to eight years of schooling starting at the age of five or six, although this varies between, and sometimes within, countries. Globally, around 89% of children aged six to twelve are enrolled in primary education, and this proportion is rising. Under the Education For All programs driven by UNESCO, most countries have committed to achieving universal enrollment in primary education by 2015, and in many countries, it is compulsory. The division between primary and secondary education is somewhat arbitrary, but it generally occurs at about eleven or twelve years of age. Some education systems have separate middle schools, with the transition to the final stage of secondary education taking place at around the age of fourteen. Schools that provide primary education, are mostly referred to as "primary schools "or "elementary schools". Primary schools are often subdivided into infant schools and junior school.
In India, for example, compulsory education spans over twelve years, with eight years of elementary education, five years of primary schooling and three years of upper primary schooling. Various states in the republic of India provide 12 years of compulsory school education based on a national curriculum framework designed by the National Council of Educational Research and Training.
Secondary.
In most contemporary educational systems of the world, secondary education comprises the formal education that occurs during adolescence. It is characterized by transition from the typically compulsory, comprehensive primary education for minors, to the optional, selective tertiary, "postsecondary", or "higher" education (e.g. university, vocational school) for adults. Depending on the system, schools for this period, or a part of it, may be called secondary or high schools, gymnasiums, lyceums, middle schools, colleges, or vocational schools. The exact meaning of any of these terms varies from one system to another. The exact boundary between primary and secondary education also varies from country to country and even within them, but is generally around the seventh to the tenth year of schooling. Secondary education occurs mainly during the teenage years. In the United States, Canada and Australia, primary and secondary education together are sometimes referred to as K-12 education, and in New Zealand Year 1â13 is used. The purpose of secondary education can be to give common knowledge, to prepare for higher education, or to train directly in a profession.
Secondary education in the United States did not emerge until 1910, with the rise of large corporations and advancing technology in factories, which required skilled workers. In order to meet this new job demand, high schools were created, with a curriculum focused on practical job skills that would better prepare students for white collar or skilled blue collar work. This proved beneficial for both employers and employees, since the improved human capital lowered costs for the employer, while skilled employees received a higher wages.
Secondary education has a longer history in Europe, where grammar schools or academies date from as early as the 16th century, in the form of public schools, fee-paying schools, or charitable educational foundations, which themselves date even further back.
Community colleges offer another option at this transitional stage of education. They provide nonresidential junior college courses to people living in a particular area.
Tertiary (higher).
Higher education, also called tertiary, third stage, or postsecondary education, is the non-compulsory educational level that follows the completion of a school such as a high school or secondary school. Tertiary education is normally taken to include undergraduate and postgraduate education, as well as vocational education and training. Colleges and universities mainly provide tertiary education. Collectively, these are sometimes known as tertiary institutions. Individuals who complete tertiary education generally receive certificates, diplomas, or academic degrees.
Higher education typically involves work towards a degree-level or foundation degree qualification. In most developed countries a high proportion of the population (up to 50%) now enter higher education at some time in their lives. Higher education is therefore very important to national economies, both as a significant industry in its own right, and as a source of trained and educated personnel for the rest of the economy.
University education includes teaching, research, and social services activities, and it includes both the undergraduate level (sometimes referred to as tertiary education) and the graduate (or postgraduate) level (sometimes referred to as graduate school). Universities are generally composed of several colleges. In the United States, universities can be private and independent like Yale University; public and state-governed like the Pennsylvania State System of Higher Education; or independent but state-funded like the University of Virginia. A number of career specific courses are now available to students through the Internet.
One type of university education is a liberal arts education, which can be defined as a "college or university curriculum aimed at imparting broad general knowledge and developing general intellectual capacities, in contrast to a professional, vocational, or technical curriculum." Although what is known today as liberal arts education began in Europe, the term "liberal arts college" is more commonly associated with institutions in the United States.
Vocational.
Vocational education is a form of education focused on direct and practical training for a specific trade or craft. Vocational education may come in the form of an apprenticeship or internship as well as institutions teaching courses such as carpentry, agriculture, engineering, medicine, architecture and the arts.
Special.
In the past, those who were disabled were often not eligible for public education. Children with disabilities were repeatedly denied an education by physicians or special tutors. These early physicians (people like Itard, Seguin, Howe, Gallaudet) set the foundation for special education today. They focused on individualized instruction and functional skills. In its early years, special education was only provided to people with severe disabilities, but more recently it has been opened to anyone who has experienced difficulty learning.
Other educational forms.
Alternative.
While considered "alternative" today, most alternative systems have existed since ancient times. After the public school system was widely developed beginning in the 19th century, some parents found reasons to be discontented with the new system. Alternative education developed in part as a reaction to perceived limitations and failings of traditional education. A broad range of educational approaches emerged, including alternative schools, self learning, homeschooling and unschooling. Example alternative schools include Montessori schools, Waldorf schools (or Steiner schools), Friends schools, Sands School, Summerhill School, The Peepal Grove School, Sudbury Valley School, Krishnamurti schools, and open classroom schools. Charter schools are another example of alternative education, which have in the recent years grown in numbers in the US and gained greater importance in its public education system.
In time, some ideas from these experiments and paradigm challenges may be adopted as the norm in education, just as Friedrich FrÃ¶bel's approach to early childhood education in 19th-century Germany has been incorporated into contemporary kindergarten classrooms. Other influential writers and thinkers have included the Swiss humanitarian Johann Heinrich Pestalozzi; the American transcendentalists Amos Bronson Alcott, Ralph Waldo Emerson, and Henry David Thoreau; the founders of progressive education, John Dewey and Francis Parker; and educational pioneers such as Maria Montessori and Rudolf Steiner, and more recently John Caldwell Holt, Paul Goodman, Frederick Mayer, George Dennison and Ivan Illich.
Indigenous.
Indigenous education refers to the inclusion of indigenous knowledge, models, methods, and content within formal and non-formal educational systems. Often in a post-colonial context, the growing recognition and use of indigenous education methods can be a response to the erosion and loss of indigenous knowledge and language through the processes of colonialism. Furthermore, it can enable indigenous communities to "reclaim and revalue their languages and cultures, and in so doing, improve the educational success of indigenous students."
Informal learning.
Informal learning is one of three forms of learning defined by the Organisation for Economic Co-operation and Development (OECD). Informal learning occurs in a variety of places, such as at home, work, and through daily interactions and shared relationships among members of society. For many learners this includes language acquisition, cultural norms and manners. Informal learning for young people is an ongoing process that also occurs in a variety of places, such as out of school time, in youth programs at community centers and media labs.
Informal learning usually takes place outside educational establishments, does not follow a specified curriculum and may originate accidentally, sporadically, in association with certain occasions, from changing practical requirements. It is not necessarily planned to be pedagogically conscious, systematic and according to subjects, but rather unconsciously incidental, holistically problem-related, and related to situation management and fitness for life. It is experienced directly in its "natural" function of everyday life and is often spontaneous.
The concept of 'education through recreation' was applied to childhood development in the 19th century. In the early 20th century, the concept was broadened to include young adults but the emphasis was on physical activities. L.P. Jacks, also an early proponent of lifelong learning, described education through recreation: "A master in the art of living draws no sharp distinction between his work and his play, his labour and his leisure, his mind and his body, his education and his recreation. He hardly knows which is which. He simply pursues his vision of excellence through whatever he is doing and leaves others to determine whether he is working or playing. To himself he always seems to be doing both. Enough for him that he does it well." Education through recreation is the opportunity to learn in a seamless fashion through all of life's activities. The concept has been revived by the University of Western Ontario to teach anatomy to medical students.
Self-directed learning.
Autodidacticism (also autodidactism) is a contemplative, absorbing process, of "learning on your own" or "by yourself", or as a self-teacher. Some autodidacts spend a great deal of time reviewing the resources of libraries and educational websites. One may become an autodidact at nearly any point in one's life. While some may have been informed in a conventional manner in a particular field, they may choose to inform themselves in other, often unrelated areas. Notable autodidacts include Abraham Lincoln (U.S. president), Srinivasa Ramanujan (mathematician), Michael Faraday (chemist and physicist), Charles Darwin (naturalist), Thomas Alva Edison (inventor), Tadao Ando (architect), George Bernard Shaw (playwright), Frank Zappa (composer, recording engineer, film director), and Leonardo da Vinci (engineer, scientist, mathematician).
Open education and electronic technology.
"Main articles: Open education" and "Educational technology"
In 2012, the modern use of electronic educational technology (also called e-learning) had grown at 14 times the rate of traditional learning. Open education is fast growing to become the dominant form of education, for many reasons such as its efficiency and results compared to traditional methods. Cost of education has been an issue throughout history, and a major political issue in most countries today. Online courses often can be more expensive than face-to-face classes. Out of 182 colleges surveyed in 2009 nearly half said tuition for online courses was higher than for campus based ones. Many large university institutions are now starting to offer free or almost free full courses such as Harvard, MIT and Berkeley teaming up to form edX. Other universities offering open education are Stanford, Princeton, Duke, Johns Hopkins, Edinburgh, U. Penn, U. Michigan, U. Virginia, U. Washington, and Caltech. It has been called the biggest change in the way we learn since the printing press. Despite favorable studies on effectiveness, many people may still desire to choose traditional campus education for social and cultural reasons.
The conventional merit-system degree is currently not as common in open education as it is in campus universities, although some open universities do already offer conventional degrees such as the Open University in the United Kingdom. Presently, many of the major open education sources offer their own form of certificate. Due to the popularity of open education, these new kind of academic certificates are gaining more respect and equal "academic value" to traditional degrees. Many open universities are working to have the ability to offer students standardized testing and traditional degrees and credentials.
A culture is beginning to form around distance learning for people who are looking to social connections enjoyed on traditional campuses. For example, students may create study groups, meetups and movements such as UnCollege.
Development goals.
Since 1909, the ratio of children in the developing world attending school has increased. Before then, a small minority of boys attended school. By the start of the 21st century, the majority of all children in most regions of the world attended school.
Universal Primary Education is one of the eight international Millennium Development Goals, towards which progress has been made in the past decade, though barriers still remain. Securing charitable funding from prospective donors is one particularly persistent problem. Researchers at the Overseas Development Institute have indicated that the main obstacles to funding for education include conflicting donor priorities, an immature aid architecture, and a lack of evidence and advocacy for the issue. Additionally, Transparency International has identified corruption in the education sector as a major stumbling block to achieving Universal Primary Education in Africa. Furthermore, demand in the developing world for improved educational access is not as high as foreigners have expected. Indigenous governments are reluctant to take on the ongoing costs involved. There is also economic pressure from some parents, who prefer their children to earn money in the short term rather than work towards the long-term benefits of education.
A study conducted by the UNESCO International Institute for Educational Planning indicates that stronger capacities in educational planning and management may have an important spill-over effect on the system as a whole. Sustainable capacity development requires complex interventions at the institutional, organizational and individual levels that could be based on some foundational principles:
Internationalization.
Nearly every country now has Universal Primary Education.
SimilaritiesÂ â in systems or even in ideasÂ â that schools share internationally have led to an increase in international student exchanges. The European Socrates-Erasmus Program facilitates exchanges across European universities. The Soros Foundation provides many opportunities for students from central Asia and eastern Europe. Programs such as the International Baccalaureate have contributed to the internationalization of education. The global campus online, led by American universities, allows free access to class materials and lecture files recorded during the actual classes.
Education and technology in developing countries.
Technology plays an increasingly significant role in improving access to education for people living in impoverished areas and developing countries. Charities like One Laptop per Child are dedicated to providing infrastructures through which the disadvantaged may access educational materials.
The OLPC foundation, a group out of MIT Media Lab and supported by several major corporations, has a stated mission to develop a $100 laptop for delivering educational software. The laptops were widely available as of 2008. They are sold at cost or given away based on donations.
In Africa, the New Partnership for Africa's Development (NEPAD) has launched an "e-school program" to provide all 600,000 primary and high schools with computer equipment, learning materials and internet access within 10 years. An International Development Agency project called nabuur.com, started with the support of former American President Bill Clinton, uses the Internet to allow co-operation by individuals on issues of social development.
India is developing technologies that will bypass land-based telephone and Internet infrastructure to deliver distance learning directly to its students. In 2004, the Indian Space Research Organisation launched EDUSAT, a communications satellite providing access to educational materials that can reach more of the country's population at a greatly reduced cost.
Private vs public funding in developing countries.
Research into LCPS (low cost private schools) found that over 5 years to July 2013, debate around LCPSs to achieving Education for All (EFA) objectives was polarised and finding growing coverage in international policy. The polarisation was due to disputes around whether the schools are affordable for the poor, reach disadvantaged groups, provide quality education, support or undermine equality, and are financially sustainable.
The report examined the main challenges encountered by development organisations which support LCPSs. Surveys suggest these types of schools are expanding across Africa and Asia. This success is attributed to excess demand. These surveys found concern for:
The report showed some cases of successful voucher and subsidy programmes; evaluations of international support to the sector are not widespread. Addressing regulatory ineffectiveness is a key challenge. Emerging approaches stress the importance of understanding the political economy of the market for LCPS, specifically how relationships of power and accountability between users, government, and private providers can produce better education outcomes for the poor.
Educational theory.
Purpose of schools.
Individual purposes for pursuing education can vary. Understanding the goals and means of educational socialization processes may also differ according to the sociological paradigm used.
The early years of schooling generally focus around developing basic interpersonal communication and literacy skills. This lays a foundation for more complex skills and subjects. Later, education usually turns toward gaining the knowledge and skills needed to create value and establish a livelihood.
People also pursue education for its own sake to satisfy innate curiosity, out of interest in a specific subject or skill, or for overall personal development.
Education is often understood as a means of overcoming handicaps, achieving greater equality, and acquiring wealth and status for all (Sargent 1994). Education is also often perceived as a place where children can develop according to their unique needs and potentials, with the purpose of developing every individual to their full potential.
Some claim that there is education inequality because children did not exceed the education of their parents. This education inequality is then associated with income inequality. Although critical thinking is a goal of education, criticism and blame are often the unintended by products of our current educational process. Students often blame their teachers and their textbooks, despite the availability of libraries and the internet. When someone tries to improve education, the educational establishment itself occasionally showers the person with criticism rather than gratitude. Better by products of an educational system would be gratitude and determination.
Developed countries have people with more resources (housing, food, transportation, water and sewage treatment, hospitals, health care, libraries, books, media, schools, the internet, education, etc.) than most of the world's population. One merely needs to see through travel or the media how many people in the undeveloped countries live to sense this. However, one can also use economic data to gain some insight into this. Yet criticism and blame are common among people in the developed countries.
Gratitude for all these resources and the determination to develop oneself would be more productive than criticism and blame because the resources are readily available and because, if you blame others, there is no need for you to do something different tomorrow or for you to change and improve. Where there is a will, there is a way. People in developed countries have the will and the way to do many things that they want to do. They sometimes need more determination and will to improve and to educate themselves with the resources that are abundantly available. They occasionally need more gratitude for the resources they have, including their teachers and their textbooks. The entire internet is also available to supplement these teachers and textbooks.
Educational psychology.
Educational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. Although the terms "educational psychology" and "school psychology" are often used interchangeably, researchers and theorists are likely to be identified as , whereas practitioners in schools or school-related settings are identified as school psychologists. Educational psychology is concerned with the processes of educational attainment in the general population and in sub-populations such as gifted children and those with specific disabilities.
Educational psychology can in part be understood through its relationship with other disciplines. It is informed primarily by psychology, bearing a relationship to that discipline analogous to the relationship between medicine and biology. Educational psychology in turn informs a wide range of specialties within educational studies, including instructional design, educational technology, curriculum development, organizational learning, special education and classroom management. Educational psychology both draws from and contributes to cognitive science and the learning sciences. In universities, departments of educational psychology are usually housed within faculties of education, possibly accounting for the lack of representation of educational psychology content in introductory psychology textbooks (Lucas, Blazek, & Raley, 2006).
The intelligenceâeducation relationship.
Intelligence is an important factor in how the individual responds to education. Those who have higher intelligence tend to perform better at school and go on to higher levels of education. This effect is also observable in the opposite direction, in that education increases measurable intelligence. Studies have shown that while educational attainment is important in predicting intelligence in later life, intelligence at 53 is more closely correlated to intelligence at 8 years old than to educational attainment.
Learning modalities.
There has been much interest in learning modalities and styles over the last two decades. The most commonly employed learning modalities are:
Other commonly employed modalities include musical, interpersonal, verbal, logical, and intrapersonal.
Dunn and Dunn focused on identifying relevant stimuli that may influence learning and manipulating the school environment, at about the same time as Joseph Renzulli recommended varying teaching strategies. Howard Gardner identified a wide range of modalities in his Multiple Intelligences theories. The Myers-Briggs Type Indicator and Keirsey Temperament Sorter, based on the works of Jung, focus on understanding how people's personality affects the way they interact personally, and how this affects the way individuals respond to each other within the learning environment. The work of David Kolb and Anthony Gregorc's Type Delineator follows a similar but more simplified approach.
Some theories propose that all individuals benefit from a variety of learning modalities, while others suggest that individuals may have preferred learning styles, learning more easily through visual or kinesthetic experiences. A consequence of the latter theory is that effective teaching should present a variety of teaching methods which cover all three learning modalities so that different students have equal opportunities to learn in a way that is effective for them. Guy Claxton has questioned the extent that learning styles such as Visual, Auditory and Kinesthetic(VAK) are helpful, particularly as they can have a tendency to label children and therefore restrict learning. Recent research has argued "there is no adequate evidence base to justify incorporating learning styles assessments into general educational practice."
Philosophy.
As an academic field, philosophy of education is "the philosophical study of education and its problemsÂ (...) its central subject matter is education, and its methods are those of philosophy". "The philosophy of education may be either the philosophy of the process of education or the philosophy of the discipline of education. That is, it may be part of the discipline in the sense of being concerned with the aims, forms, methods, or results of the process of educating or being educated; or it may be metadisciplinary in the sense of being concerned with the concepts, aims, and methods of the discipline." As such, it is both part of the field of education and a field of applied philosophy, drawing from fields of metaphysics, epistemology, axiology and the philosophical approaches (speculative, prescriptive, and/or analytic) to address questions in and about pedagogy, education policy, and curriculum, as well as the process of learning, to name a few. For example, it might study what constitutes upbringing and education, the values and norms revealed through upbringing and educational practices, the limits and legitimization of education as an academic discipline, and the relation between education theory and practice.
Curriculum.
In formal education, a curriculum is the set of courses and their content offered at a school or university. As an idea, curriculum stems from the Latin word for "race course", referring to the course of deeds and experiences through which children grow to become mature adults. A curriculum is prescriptive, and is based on a more general syllabus which merely specifies what topics must be understood and to what level to achieve a particular grade or standard.
An academic discipline is a branch of knowledge which is formally taught, either at the universityâor via some other such method. Each discipline usually has several sub-disciplines or branches, and distinguishing lines are often both arbitrary and ambiguous. Examples of broad areas of academic disciplines include the natural sciences, mathematics, computer science, social sciences, humanities and applied sciences.
Educational institutions may incorporate fine arts as part of K-12 grade curricula or within majors at colleges and universities as electives. The various types of fine arts are music, dance, and theater.
Instruction.
Instruction is the facilitation of another's learning. Instructors in primary and secondary institutions are often called teachers, and they direct the education of students and might draw on many subjects like reading, writing, mathematics, science and history. Instructors in post-secondary institutions might be called teachers, instructors, or professors, depending on the type of institution; and they primarily teach only their specific discipline. Studies from the United States suggest that the quality of teachers is the single most important factor affecting student performance, and that countries which score highly on international tests have multiple policies in place to ensure that the teachers they employ are as effective as possible. With the passing of NCLB in the United States (No Child Left Behind), teachers must be highly qualified. A popular way to gauge teaching performance is to use student evaluations of teachers (SETS), but these evaluations have been criticized for being counterproductive to learning and inaccurate due to student bias.
Economics of education.
It has been argued that high rates of education are essential for countries to be able to achieve high levels of economic growth. Empirical analyses tend to support the theoretical prediction that poor countries should grow faster than rich countries because they can adopt cutting edge technologies already tried and tested by rich countries. However, technology transfer requires knowledgeable managers and engineers who are able to operate new machines or production practices borrowed from the leader in order to close the gap through imitation. Therefore, a country's ability to learn from the leader is a function of its stock of "human capital". Recent study of the determinants of aggregate economic growth have stressed the importance of fundamental economic institutions and the role of cognitive skills.
At the level of the individual, there is a large literature, generally related to the work of Jacob Mincer, on how earnings are related to the schooling and other human capital. This work has motivated a large number of studies, but is also controversial. The chief controversies revolve around how to interpret the impact of schooling. Some students who have indicated a high potential for learning, by testing with a high intelligence quotient, may not achieve their full academic potential, due to financial difficulties.
Economists Samuel Bowles and Herbert Gintis argued in 1976 that there was a fundamental conflict in American schooling between the egalitarian goal of democratic participation and the inequalities implied by the continued profitability of capitalist production.

</doc>
<doc id="9253" url="https://en.wikipedia.org/wiki?curid=9253" title="Encyclopedia">
Encyclopedia

An encyclopedia or encyclopaedia (also spelled encyclopÃ¦dia, see spelling differences) is a type of reference work or compendium holding a comprehensive summary of information from either all branches of knowledge or a particular branch of knowledge.
Encyclopedias are divided into articles or entries, which are usually accessed alphabetically by article name. Encyclopedia entries are longer and more detailed than those in most dictionaries. Generally speaking, unlike dictionary entries, which focus on linguistic information about words, encyclopedia articles focus on factual information concerning the subject for which the article is named.
Encyclopedias have existed for around 2,000 years; the oldest still in existence, "Naturalis Historia", was written starting in ca. AD 77 by Pliny the Elder and was not fully revised at the time of his death in AD 79. The modern encyclopedia evolved out of dictionaries around the 17th century. Historically, some encyclopedias were contained in one volume, whereas others, such as the "EncyclopÃ¦dia Britannica", the "Enciclopedia Italiana" (62 volumes, 56,000 pages) or the world's largest, "Enciclopedia universal ilustrada europeo-americana" (118 volumes, 105,000 pages), became huge multi-volume works. Some modern encyclopedias, such as Wikipedia, are electronic and often freely available.
Etymology.
The word "encyclopedia" comes from the Koine Greek , transliterated "enkyklios paideia", meaning "general education" from "enkyklios" (á¼Î³ÎºÏÎºÎ»Î¹Î¿Ï), meaning "circular, recurrent, required regularly, general" and "paideia" (ÏÎ±Î¹Î´ÎµÎ¯Î±), meaning "education, rearing of a child"; it was reduced to a single word due to an error by copyists of Latin manuscripts. Together, the phrase literally translates as "complete instruction" or "complete knowledge".
Copyists of Latin manuscripts took this phrase to be a single Greek word, "enkyklopaidia", with the same meaning, and this spurious Greek word became the New Latin word "encyclopaedia", which in turn came into English. Though the notion of a compendium of knowledge dates back thousands of years, the term was first used in the title of a book in 1517 by Johannes Aventinus: "Encyclopedia orbisque doctrinarum, hoc est omnium artium, scientiarum, ipsius philosophiae index ac divisio", and in 1538 by Joachimus Fortius Ringelbergius, "Lucubrationes vel potius absolutissima kyklopaideia" (Basel, 1538).
The word "encyclopaedia" was first used as a noun in the title of his book by the Croatian encyclopedist Pavao SkaliÄ in his "Encyclopaedia seu orbis disciplinarum tam sacrarum quam prophanarum epistemon" (Encyclopaedia, or Knowledge of the World of Disciplines, Basel, 1559). One of the oldest vernacular uses was by FranÃ§ois Rabelais in his "Pantagruel" in 1532. Several encyclopedias have names that include the suffix "-p(a)edia", e.g., Banglapedia (on matters relevant for Bengal).
In British usage, the spellings "encyclopedia" and "encyclopaedia" are both current.
In American usage, only the former is commonly used. The spelling "encyclopÃ¦dia"âwith the "Ã¦" ligatureâwas frequently used in the 19th century and is increasingly rare, although it is retained in product titles such as "EncyclopÃ¦dia Britannica" and others. The "Oxford English Dictionary" (1989) records "encyclopÃ¦dia" and "encyclopaedia" as equal alternatives (in that order), and notes the "Ã¦" would be obsolete except that it is preserved in works that have Latin titles. "Webster's Third New International Dictionary" (1997â2002) features "encyclopedia" as the main headword and "encyclopaedia" as a minor variant. In addition, "cyclopedia" and "cyclopaedia" are now rarely used shortened forms of the word originating in the 17th century.
Characteristics.
The modern encyclopedia was developed from the dictionary in the 18th century. Historically, both encyclopedias and dictionaries have been researched and written by well-educated, well-informed content experts, but they are significantly different in structure. A dictionary is a linguistic work which primarily focuses on alphabetical listing of words and their definitions. Synonymous words and those related by the subject matter are to be found scattered around the dictionary, giving no obvious place for in-depth treatment. Thus, a dictionary typically provides limited information, analysis or background for the word defined. While it may offer a definition, it may leave the reader lacking in understanding the meaning, significance or limitations of a term, and how the term relates to a broader field of knowledge. An encyclopedia is, allegedly, not written in order to convince, although one of its goals is indeed to convince its reader about its own veracity. In the terms of Aristotle's Modes of persuasion, a dictionary should persuade the reader through "logos" (conveying only appropriate emotions); it will be expected to have a lack of pathos (it should not stir up irrelevant emotions), and to have little ethos except that of the dictionary itself.
To address those needs, an encyclopedia article is typically not limited to simple definitions, and is not limited to defining an individual word, but provides a more extensive meaning for a "subject or discipline". In addition to defining and listing synonymous terms for the topic, the article is able to treat the topic's more extensive meaning in more depth and convey the most relevant accumulated knowledge on that subject. An encyclopedia article also often includes many maps and illustrations, as well as bibliography and statistics.
Four major elements define an encyclopedia: its subject matter, its scope, its method of organization, and its method of production:
Some works entitled "dictionaries" are actually similar to encyclopedias, especially those concerned with a particular field (such as the "Dictionary of the Middle Ages", the "Dictionary of American Naval Fighting Ships", and "Black's Law Dictionary"). The "Macquarie Dictionary," Australia's national dictionary, became an encyclopedic dictionary after its first edition in recognition of the use of proper nouns in common communication, and the words derived from such proper nouns.
There are some broad differences between encyclopedias and dictionaries. Most noticeably, encyclopedia articles are longer, fuller and more thorough than entries in most general-purpose dictionaries. There are differences in content as well. Generally speaking, dictionaries provide linguistic information about words themselves, while encyclopedias focus more on the thing for which those words stand. Thus, while dictionary entries are inextricably fixed to the word described, encyclopedia articles can be given a different entry name. As such, dictionary entries are not fully translatable into other languages, but encyclopedia articles can be.
In practice, however, the distinction is not concrete, as there is no clear-cut difference between factual, "encyclopedic" information and linguistic information such as appears in dictionaries. Thus encyclopedias may contain material that is also found in dictionaries, and vice versa. In particular, dictionary entries often contain factual information about the thing named by the word.
History.
Encyclopedias have progressed from the beginning of history in written form, through medieval and modern times in print, and most recently, displayed on computer and distributed via computer networks.
Ancient times.
One of the earliest encyclopedic works to have survived to modern times is the "Naturalis Historia" of Pliny the Elder, a Roman statesman living in the 1st century AD. He compiled a work of 37 chapters covering natural history, architecture, medicine, geography, geology, and all aspects of the world around him. He stated in the preface that he had compiled 20,000 facts from 2000 works by over 200 authors, and added many others from his own experience. The work was published around AD 77-79, although he probably never finished proofing the work before his death in the eruption of Vesuvius in AD 79.
Middle Ages.
Isidore of Seville, one of the greatest scholars of the early Middle Ages, is widely recognized for writing the first encyclopedia of the Middle Ages, the "Etymologiae" ("The Etymologies") or "Origines" (around 630), in which he compiled a sizable portion of the learning available at his time, both ancient and contemporary. The work has 448 chapters in 20 volumes, and is valuable because of the quotes and fragments of texts by other authors that would have been lost had he not collected them.
The most popular encyclopedia of the Carolingian Age was the "De universo" or "De rerum naturis" by Rabanus Maurus, written about 830; it was based on "Etymologiae".
The encyclopedia of Suda, a massive 10th-century Byzantine encyclopedia, had 30 000 entries, many drawing from ancient sources that have since been lost, and often derived from medieval Christian compilers. The text was arranged alphabetically with some slight deviations from common vowel order and place in the Greek alphabet.
The early Muslim compilations of knowledge in the Middle Ages included many comprehensive works. Around year 960, the Brethren of Purity of Basra were engaged in their Encyclopedia of the Brethren of Purity. Notable works include Abu Bakr al-Razi's encyclopedia of science, the Mutazilite Al-Kindi's prolific output of 270 books, and Ibn Sina's medical encyclopedia, which was a standard reference work for centuries. Also notable are works of universal history (or sociology) from Asharites, al-Tabri, al-Masudi, Tabari's "History of the Prophets and Kings", Ibn Rustah, al-Athir, and Ibn Khaldun, whose Muqadimmah contains cautions regarding trust in written records that remain wholly applicable today.
The enormous encyclopedic work in China of the "Four Great Books of Song", compiled by the 11th century AD during the early Song dynasty (960â1279), was a massive literary undertaking for the time. The last encyclopedia of the four, the "Prime Tortoise of the Record Bureau", amounted to 9.4 million Chinese characters in 1000 written volumes.
In the late Middle Ages, several authors had the ambition of compiling the sum of human knowledge in a certain field or overall, for example Bartholomew of England, Vincent of Beauvais, Radulfus Ardens, Sydrac, Brunetto Latini, Giovanni da Sangiminiano, Pierre Bersuire. Some were women, like Hildegard of Bingen and Herrad of Landsberg. The most successful of those publications were the "Speculum maius (Great Mirror)" of Vincent of Beauvais and the "De proprietatibus rerum (On the Properties of Things)" by Bartholomew of England. The latter was translated (or adapted) into French, ProvenÃ§al, Italian, English, Flemish, Anglo-Norman, Spanish and German during the Middle Ages. Both were written in the middle of the 13th century. No medieval encyclopedia bore the title "Encyclopaedia" â they were often called "On nature (De natura, De naturis rerum)", "Mirror (Speculum maius, Speculum universale)", "Treasure (TrÃ©sor)".
Renaissance.
These works were all hand copied and thus rarely available, beyond wealthy patrons or monastic men of learning: they were expensive, and usually written for those extending knowledge rather than those using it.
During Renaissance the creation of printing allowed a wider diffusion of encyclopedias and every scholar could have his or her own copy. The "De expetendis et fugiendis rebus" by Giorgio Valla was posthumously printed in 1501 by Aldo Manuzio in Venice. This work followed the traditional scheme of liberal arts. However, Valla added the translation of ancient Greek works on mathematics (firstly by Archimedes), newly discovered and translated. The "Margarita Philosophica" by Gregor Reisch, printed in 1503, was a complete encyclopedia explaining the seven liberal arts.
The term encyclopaedia was coined by 16th century humanists who misread copies of their texts of Pliny and Quintilian, and combined the two Greek words "enkyklios paideia" into one word, Î­Î³ÎºÏÎºÎ»Î¿ÏÎ±Î¹Î´ÎµÎ¯Î±. The phrase "enkyklios paideia" (á¼Î³ÎºÏÎºÎ»Î¹Î¿Ï ÏÎ±Î¹Î´ÎµÎ¯Î±) was used by Plutarch and the Latin word Encyclopedia came from him.
The first work titled in this way was the "Encyclopedia orbisque doctrinarum, hoc est omnium artium, scientiarum, ipsius philosophiae index ac divisio" written by Johannes Aventinus in 1517.
The English physician and philosopher, Sir Thomas Browne used the word 'encyclopaedia' in 1646 in the preface to the reader to define his "Pseudodoxia Epidemica", a major work of the 17th-century scientific revolution. Browne structured his encyclopaedia upon the time-honoured schemata of the Renaissance, the so-called 'scale of creation' which ascends through the mineral, vegetable, animal, human, planetary and cosmological worlds. "Pseudodoxia Epidemica" was a European best-seller, translated into French, Dutch and German as well as Latin it went through no less than five editions, each revised and augmented, the last edition appearing in 1672.
18thâ19th centuries.
The beginnings of the modern idea of the general-purpose, widely distributed printed encyclopedia precede the 18th century encyclopedists. However, Chambers' "Cyclopaedia, or Universal Dictionary of Arts and Sciences" (1728), and the "EncyclopÃ©die" of Denis Diderot and Jean le Rond d'Alembert (1751 onwards), as well as "EncyclopÃ¦dia Britannica" and the "Conversations-Lexikon", were the first to realize the form we would recognize today, with a comprehensive scope of topics, discussed in depth and organized in an accessible, systematic method. Chambers, in 1728, followed the earlier lead of John Harris's "Lexicon Technicum" of 1704 and later editions (see also below); this work was by its title and content "A Universal English Dictionary of Arts and Sciences: Explaining not only the Terms of Art, but the Arts Themselves".
During the 19th and early 20th century, many smaller or less developed languages saw their first encyclopedias, using French, German, and English role models. While encyclopedias in larger languages, having large markets that could support a large editorial staff, churned out new 20-volume works in a few years and new editions with brief intervals, such publication plans often spanned a decade or more in smaller languages.
20th century.
Popular and affordable encyclopedias such as Harmsworth's Universal Encyclopaedia and the Children's Encyclopaedia appeared in the early 1920s.
In the United States, the 1950s and 1960s saw the introduction of several large popular encyclopedias, often sold on installment plans. The best known of these were "World Book" and "Funk and Wagnalls".
The second half of the 20th century also saw the proliferation of specialized encyclopedias that compiled topics in specific fields. This trend has continued. Encyclopedias of at least one volume in size now exist for most if not all academic disciplines, including such narrow topics such as bioethics.
By the late 20th century, encyclopedias were being published on CD-ROMs for use with personal computers. Microsoft's "Encarta", launched in 1993, was a landmark example as it had no printed equivalent. Articles were supplemented with both video and audio files as well as numerous high-quality images. After sixteen years, Microsoft discontinued the Encarta line of products in 2009.
21st century.
In 2001, Jimmy Wales and Larry Sanger launched Wikipedia, a collaboratively edited, multilingual, open-source, free Internet encyclopedia supported by the non-profit Wikimedia Foundation. As of 16 2016, there are articles in the English Wikipedia. There are 287 different editions of Wikipedia. As of February 2014, it had 18 billion page views and nearly 500 million unique visitors each month. Wikipedia has more than 25 million accounts, out of which there were over 118,000 active editors globally, as of August 2015. Wikipedia's accuracy was found by a "Nature" study to be close to that of EncyclopÃ¦dia Britannica, with Wikipedia being much larger. However, critics argue Wikipedia exhibits systemic bias, and its group dynamics hinder its goals. Many academics, historians, teachers, and journalists reject Wikipedia as a reliable source of information, primarily for being a mixture of truths, half truths, and some falsehoods, and that as a resource about many controversial topics, is notoriously subject to manipulation and spin.
While Wikipedia is by far the largest web-based encyclopedia, it is not the only one in existence. There are several much smaller, usually more specialized, encyclopedias on various themes, sometimes dedicated to a specific geographic region or time period.

</doc>
<doc id="9256" url="https://en.wikipedia.org/wiki?curid=9256" title="Enigma machine">
Enigma machine

The Enigma machines were a series of electro-mechanical rotor cipher machines developed and used in the early- to mid-twentieth century to protect commercial, diplomatic and military communication. Enigma was invented by the German engineer Arthur Scherbius at the end of World War I. Early models were used commercially from the early 1920s, and adopted by military and government services of several countries, most notably Nazi Germany before and during World War II. Several different Enigma models were produced, but the German military models are the most commonly recognised.
German military messages enciphered on the Enigma machine were first broken by the Polish Cipher Bureau, beginning in December 1932. This success was a result of efforts by three Polish cryptologists, Marian Rejewski, Jerzy RÃ³Å¼ycki and Henryk Zygalski, working for Polish military intelligence. Rejewski reverse-engineered the device, using theoretical mathematics and material supplied by French military intelligence. Subsequently the three mathematicians designed mechanical devices for breaking Enigma ciphers, including the cryptologic bomb. From 1938 onwards, additional complexity was repeatedly added to the Enigma machines, making decryption more difficult and requiring further equipment and personnelâmore than the Poles could readily produce.
On 25 July 1939, in Warsaw, the Poles initiated French and British military intelligence representatives into their Enigma-decryption techniques and equipment, including Zygalski sheets and the cryptologic bomb, and promised each delegation a Polish-reconstructed Enigma. The demonstration represented a vital basis for the later British continuation and effort. During the war, British cryptologists decrypted a vast number of messages enciphered on Enigma. The intelligence gleaned from this source, codenamed "Ultra" by the British, was a substantial aid to the Allied war effort.
Though Enigma had some cryptographic weaknesses, in practice it was German procedural flaws, operator mistakes, failure to systematically introduce changes in encipherment procedures, and Allied capture of key tables and hardware that, during the war, enabled Allied cryptologists to succeed.
Design.
Like other rotor machines, the Enigma machine is a combination of mechanical and electrical subsystems. The mechanical subsystem consists of a keyboard; a set of rotating disks called "rotors" arranged adjacently along a spindle; and one of various stepping components to turn at least one rotor with each key press.
Electrical pathway.
The mechanical parts act in such a way as to form a varying electrical circuit. When a key is pressed, one or more rotors move to form a new rotor configuration, and a circuit is completed. Current flows through various components in the new configuration, ultimately lighting one display lamp, which shows the output letter. For example, when encrypting a message starting "ANX...", the operator would first press the "A" key, and the "Z" lamp might light, so "Z" would be the first letter of the ciphertext. The operator would next press "N", and then "X" in the same fashion, and so on.
The detailed operation of Enigma is shown in the wiring diagram to the left. To simplify the example, only four components of a complete Enigma machine are shown. In reality, there are 26 lamps and keys, rotor wirings inside the rotors (of which there are either three or four) and between six and ten plug leads.
Current flowed from the battery (1) through a depressed bi-directional keyboard switch (2) to the plugboard (3). Next, it passed through the (unused in this instance, so shown closed) plug "A" (3) via the entry wheel (4), through the wiring of the three (Wehrmacht Enigma) or four ("Kriegsmarine" M4 and "Abwehr" variants) installed rotors (5), and entered the reflector (6). The reflector returned the current, via an entirely different path, back through the rotors (5) and entry wheel (4), proceeding through plug "S" (7) connected with a cable (8) to plug "D", and another bi-directional switch (9) to light the appropriate lamp.
The repeated changes of electrical path through an Enigma scrambler implemented a polyalphabetic substitution cipher that provided Enigma's security. The diagram on the right shows how the electrical pathway changed with each key depression, which caused rotation of at least the right-hand rotor. Current passed into the set of rotors, into and back out of the reflector, and out through the rotors again. The greyed-out lines are other possible paths within each rotor; these are hard-wired from one side of each rotor to the other. The letter "A" encrypts differently with consecutive key presses, first to "G", and then to "C". This is because the right-hand rotor has stepped, sending the signal on a completely different route. Eventually other rotors step with a key press.
Rotors.
The rotors (alternatively "wheels" or "drums", "Walzen" in German) formed the heart of an Enigma machine. Each rotor was a disc approximately in diameter made from hard rubber or bakelite with 26 brass, spring-loaded, electrical contact pins arranged in a circle on one face; the other side housing the corresponding number of circular plate electrical contacts. The pins and contacts represent the alphabetâtypically the 26 letters AâZ (this will be assumed for the rest of this description). When the rotors were mounted side-by-side on the spindle, the pins of one rotor rested against the plate contacts of the neighbouring rotor, forming an electrical connection. Inside the body of the rotor, 26 wires connected each pin on one side to a contact on the other in a complex pattern. Most of the rotors were identified by Roman numerals, and each issued copy of rotor I was wired identically to all others. The same was true for the special thin beta and gamma rotors used in the M4 naval variant.
By itself, a rotor performs only a very simple type of encryptionâa simple substitution cipher. For example, the pin corresponding to the letter "E" might be wired to the contact for letter "T" on the opposite face, and so on. Enigma's security came from using several rotors in series (usually three or four) and the regular stepping movement of the rotors, thus implementing a polyalphabetic substitution cipher.
When placed in an Enigma, each rotor can be set to one of 26 possible positions. When inserted, it can be turned by hand using the grooved finger-wheel, which protrudes from the internal Enigma cover when closed. So that the operator can know the rotor's position, each had an "alphabet tyre" (or letter ring) attached to the outside of the rotor disk, with 26 characters (typically letters); one of these could be seen through the window, thus indicating the rotational position of the rotor. In early models, the alphabet ring was fixed to the rotor disk. A later improvement was the ability to adjust the alphabet ring relative to the rotor disk. The position of the ring was known as the "Ringstellung" ("ring setting"), and was a part of the initial setting prior to an operating session. In modern terms it was a part of the initialization vector.
Each rotor contained a notch (or more than one) that controlled rotor stepping. In the military variants, the notches are located on the alphabet ring.
The Army and Air Force Enigmas were used with several rotors, initially three. On 15 December 1938, this changed to five, from which three were chosen for a given session. Rotors were marked with Roman numerals to distinguish them: I, II, III, IV and V, all with single notches located at different points on the alphabet ring. This variation was probably intended as a security measure, but ultimately allowed the Polish Clock Method and British Banburismus attacks.
The Naval version of the "Wehrmacht" Enigma had always been issued with more rotors than the other services: at first six, then seven, and finally eight. The additional rotors were marked VI, VII and VIII, all with different wiring, and had two notches, resulting in more frequent turnover. The four-rotor Naval Enigma (M4) machine accommodated an extra rotor in the same space as the three-rotor version. This was accomplished by replacing the original reflector with a thinner one and by adding a thin fourth rotor. That fourth rotor was one of two types, "Beta" or "Gamma", and never stepped, but could be manually set to any of 26 positions. One of the 26 made the machine perform identically to the three-rotor machine.
Stepping.
To avoid merely implementing a simple (and easily breakable) substitution cipher, every key press caused one or more rotors to step by one twenty-sixth of a full rotation, before the electrical connections were made. This changed the substitution alphabet used for encryption, ensuring that the cryptographic substitution was different at each new rotor position, producing a more formidable polyalphabetic substitution cipher. The stepping mechanism varied slightly from model to model. The right-hand rotor stepped once with each keystroke, and other rotors stepped less frequently.
Turnover.
The advancement of a rotor other than the left-hand one was called a "turnover" by the British. This was achieved by a ratchet and pawl mechanism. Each rotor had a ratchet with 26 teeth and every time a key was pressed, the set of spring-loaded pawls moved forward in unison, trying to engage with a ratchet. The alphabet ring of the rotor to the right normally prevented this. As this ring rotated with its rotor, a notch machined into it would eventually align itself with the pawl, allowing it to engage with the ratchet, and advance the rotor on its left. The right-hand pawl, having no rotor and ring to its right, stepped its rotor with every key depression. For a single-notch rotor in the right-hand position, the middle rotor stepped once for every 26 steps of the right-hand rotor. Similarly for rotors two and three. For a two-notch rotor, the rotor to its left would turn over twice for each rotation.
The first five rotors to be introduced (IâV) contained one notch each, while the additional naval rotors VI, VII and VIII each had two notches. The position of the notch on each rotor was determined by the letter ring which could be adjusted in relation to the core containing the interconnections. The points on the rings at which they caused the next wheel to move were as follows.
The design also included a feature known as "double-stepping". This occurred when each pawl aligned with both the ratchet of its rotor and the rotating notched ring of the neighbouring rotor. If a pawl engaged with a ratchet through alignment with a notch, as it moved forward it pushed against both the ratchet and the notch, advancing both rotors. In a three-rotor machine, double-stepping affected rotor two only. If in moving forward the ratchet of rotor three was engaged, rotor two would move again on the subsequent keystroke, resulting in two consecutive steps. Rotor two also pushes rotor one forward after 26 steps, but since rotor one moves forward with every keystroke anyway, there is no double-stepping. This double-stepping caused the rotors to deviate from odometer-style regular motion.
With three wheels and only single notches in the first and second wheels, the machine had a period of 26 Ã 25 Ã 26 = 16,900 (not 26 Ã 26 Ã 26, because of double-stepping). Historically, messages were limited to a few hundred letters, and so there was no chance of repeating any combined rotor position during a single session, denying cryptanalysts valuable clues.
To make room for the Naval fourth rotors, the reflector was made much thinner. The fourth rotor fitted into the space made available. No other changes were made, which eased the changeover. Since there were only three pawls, the fourth rotor never stepped, but could be manually set into one of 26 possible positions.
A device that was designed, but not implemented before the war's end, was the "LÃ¼ckenfÃ¼llerwalze" (gap-fill wheel) that implemented irregular stepping. It allowed field configuration of notches in all 26 positions. If the number of notches was a relative prime of 26 and the number of notches were different for each wheel, the stepping would be more unpredictable. Like the Umkehrwalze-D it also allowed the internal wiring to be reconfigured.
Entry wheel.
The current entry wheel ("Eintrittswalze" in German), or entry stator, connects the plugboard to the rotor assembly. If the plugboard is not present, the entry wheel instead connects the keyboard and lampboard to the rotor assembly. While the exact wiring used is of comparatively little importance to security, it proved an obstacle to Rejewski's progress during his study of the rotor wirings. The commercial Enigma connects the keys in the order of their sequence on a QWERTZ keyboard: "Q"formula_1"A", "W"formula_1"B", "E"formula_1"C" and so on. However, the military Enigma connects them in straight alphabetical order: "A"formula_1"A", "B"formula_1"B", "C"formula_1"C", and so on. It took inspired guesswork for Rejewski to penetrate the modification.
Reflector.
With the exception of models "A" and "B", the last rotor came before a 'reflector' (German: "Umkehrwalze", meaning 'reversal rotor'), a patented feature unique to Enigma among the period's various rotor machines. The reflector connected outputs of the last rotor in pairs, redirecting current back through the rotors by a different route. The reflector ensured that Enigma is self-reciprocal: conveniently, encryption was the same as decryption. However, the reflector also gave Enigma the property that no letter ever encrypted to itself. This was a severe conceptual flaw and a cryptological mistake subsequently exploited by codebreakers.
In Model 'C', the reflector could be inserted in one of two different positions. In Model 'D', the reflector could be set in 26 possible positions, although it did not move during encryption. In the "Abwehr" Enigma, the reflector stepped during encryption in a manner similar to the other wheels.
In the German Army and Air Force Enigma, the reflector was fixed and did not rotate; there were four versions. The original version was marked 'A', and was replaced by "Umkehrwalze B" on 1 November 1937. A third version, "Umkehrwalze C" was used briefly in 1940, possibly by mistake, and was solved by Hut 6. The fourth version, first observed on 2 January 1944, had a rewireable reflector, called "Umkehrwalze D", allowing the Enigma operator to alter the connections as part of the key settings.
Plugboard.
The plugboard ("Steckerbrett" in German) permitted variable wiring that could be reconfigured by the operator (visible on the front panel of Figure 1; some of the patch cords can be seen in the lid). It was introduced on German Army versions in 1930, and was soon adopted by the "Reichsmarine" (German Navy). The plugboard contributed more cryptographic strength than an extra rotor. Enigma without a plugboard (known as "unsteckered Enigma") can be solved relatively straightforwardly using hand methods; these techniques are generally defeated by the plugboard, driving Allied cryptanalysts to develop special machines to solve it.
A cable placed onto the plugboard connected letters in pairs; for example, "E" and "Q" might be a steckered pair. The effect was to swap those letters before and after the main rotor scrambling unit. For example, when an operator presses "E", the signal was diverted to "Q" before entering the rotors. Up to 13 steckered pairs might be used at one time, although only 10 were normally used.
Current flowed from the keyboard through the plugboard, and proceeded to the entry-rotor or "Eintrittswalze". Each letter on the plugboard had two jacks. Inserting a plug disconnected the upper jack (from the keyboard) and the lower jack (to the entry-rotor) of that letter. The plug at the other end of the crosswired cable was inserted into another letter's jacks, thus switching the connections of the two letters.
Accessories.
Other features made various Enigma machines more secure or more convenient.
"Schreibmax".
Some M4 Enigmas used the "Schreibmax", a small printer that could print the 26 letters on a narrow paper ribbon. This eliminated the need for a second operator to read the lamps and transcribe the letters. The "Schreibmax" was placed on top of the Enigma machine and was connected to the lamp panel. To install the printer, the lamp cover and light bulbs had to be removed. It improved both convenience and operational security; the printer could be installed remotely such that the signal officer operating the machine no longer had to see the decrypted plaintext.
"FernlesegerÃ¤t".
Another accessory was the remote lamp panel "FernlesegerÃ¤t". For machines equipped with the extra panel, the wooden case of the Enigma was wider and could store the extra panel. A lamp panel version could be connected afterwards, but that required, as with the "Schreibmax", that the lamp panel and lightbulbs be removed. The remote panel made it possible for a person to read the decrypted plaintext without the operator seeing it.
"Uhr".
In 1944, the "Luftwaffe" introduced a plugboard switch, called the "Uhr" (clock), a small box containing a switch with 40 positions. It replaced the standard plugs. After connecting the plugs, as determined in the daily key sheet, the operator turned the switch into one of the 40 positions, each producing a different combination of plug wiring. Most of these plug connections were, unlike the default plugs, not pair-wise. In one switch position, the "Uhr" did not swap letters, but simply emulated the 13 stecker wires with plugs.
Mathematical analysis.
The Enigma transformation for each letter can be specified mathematically as a product of permutations. Assuming a three-rotor German Army/Air Force Enigma, let formula_7 denote the plugboard transformation, formula_8 denote that of the reflector, and formula_9 denote those of the left, middle and right rotors respectively. Then the encryption formula_10 can be expressed as
After each key press, the rotors turn, changing the transformation. For example, if the right-hand rotor formula_12 is rotated formula_13 positions, the transformation becomes formula_14, where formula_15 is the cyclic permutation mapping "A" to "B", "B" to "C", and so forth. Similarly, the middle and left-hand rotors can be represented as formula_16 and formula_17 rotations of formula_18 and formula_19. The encryption transformation can then be described as
Combining three rotors from a set of five, the rotor settings with 26 positions, and the plugboard with ten pairs of letters connected, the military Enigma has 158,962,555,217,826,360,000 (nearly 159 quintillion) different settings.
Operation.
Basic operation.
A German Enigma operator would be given a plaintext message to encrypt. For each letter typed in, a lamp indicated a different letter according to a pseudo-random substitution, based upon the wiring of the machine. The letter indicated by the lamp would be recorded as the enciphered substitution. The action of pressing a key also moved the rotor so that the next key press used a different electrical pathway, and thus a different substitution would occur. For each key press there was rotation of at least the right hand rotor, giving a different substitution alphabet. This continued for each letter in the message until the message was completed and a series of substitutions, each different from the others, had occurred to create a cyphertext from the plaintext. The cyphertext would then be transmitted as normal to an operator of another Enigma machine. This operator would key in the cyphertext andâas long as all the settings of the deciphering machine were identical to those of the enciphering machineâfor every key press the reverse substitution would occur and the plaintext message would emerge.
Details.
In use, the Enigma required a list of daily key settings and auxiliary documents. The procedures for German Naval Enigma were more elaborate and more secure than those in other services. Navy codebooks were printed in red, water-soluble ink on pink paper so that they could easily be destroyed if they were endangered.
In German military practice, communications were divided into separate networks, each using different settings. These communication nets were termed "keys" at Bletchley Park, and were assigned code names, such as "Red", "Chaffinch", and "Shark". Each unit operating in a network was assigned a settings list for its Enigma for a period of time. For a message to be correctly encrypted and decrypted, both sender and receiver had to configure their Enigma in the same way; rotor selection and order, starting position and plugboard connections must be identical. All these settings (together the key in modern terms) were established beforehand, distributed in codebooks.
An Enigma machine's initial state, the cryptographic key, has several aspects:
For example, the settings for the 18th day of the month in the German Luftwaffe Enigma key list number 649 (see image) were as follows:
Enigma was designed to be secure even if the rotor wiring was known to an opponent, although in practice considerable effort protected the wiring configuration. If the wiring is secret, the total number of possible configurations has been calculated to be around 10 (approximately 380 bits); with known wiring and other operational constraints, this is reduced to around 10 (76 bits). Users of Enigma were confident of its security because of the large number of possibilities; it was not then feasible for an adversary to even begin to try a brute force attack.
Indicator.
Most of the key was kept constant for a set time period, typically a day. However, a different initial rotor position was used for each message, a concept similar to an initialisation vector in modern cryptography. The reason is that encrypting many messages with identical or near-identical settings (termed in cryptanalysis as being "in depth"), would enable an attack using a statistical procedure such as Friedman's Index of coincidence. The starting position for the rotors was transmitted just before the ciphertext, usually after having been enciphered. The exact method used was termed the "indicator procedure". Design weakness and operator sloppiness in these indicator procedures were two of the main weaknesses that made cracking Enigma possible.
One of the earliest "indicator procedures" was used by Polish cryptanalysts to make the initial breaks into the Enigma. The procedure was for the operator to set up his machine in accordance with his settings list, which included a global initial position for the rotors (the "Grundstellung", meaning "ground setting"), say, "AOH". The operator turned his rotors until "AOH" was visible through the rotor windows. At that point, the operator chose his own arbitrary starting position for that particular message. An operator might select "EIN", and these became the "message settings" for that encryption session. The operator then typed "EIN" into the machine, twice, to allow for detection of transmission errors. The results were an encrypted indicatorâthe "EIN" typed twice might turn into "XHTLOA", which would be transmitted along with the message. Finally, the operator then spun the rotors to his message settings, "EIN" in this example, and typed the plaintext of the message.
At the receiving end, the operation was reversed. The operator set the machine to the initial settings and typed in the first six letters of the message ("XHTLOA"). In this example, "EINEIN" emerged on the lamps. After moving his rotors to "EIN", the receiving operator then typed in the rest of the ciphertext, deciphering the message.
The weakness in this indicator scheme came from two factors. First, use of a global ground settingâthis was later changed so the operator selected his initial position to encrypt the indicator, and sent the initial position in the clear. The second problem was the repetition of the indicator, which was a serious security flaw. The message setting was encoded twice, resulting in a relation between first and fourth, second and fifth, and third and sixth character. This security problem enabled the Polish Cipher Bureau to break into the pre-war Enigma system as early as 1932. However, from 1940 on, the Germans changed procedure.
During World War II, codebooks were only used each day to set up the rotors, their ring settings and the plugboard. For each message, the operator selected a random start position, let's say "WZA", and a random message key, perhaps "SXT". He moved the rotors to the "WZA" start position and encoded the message key "SXT". Assume the result was "UHL". He then set up the message key, "SXT", as the start position and encrypted the message. Next, he transmitted the start position, "WZA", the encoded message key, "UHL", and then the ciphertext. The receiver set up the start position according to the first trigram, "WZA", and decoded the second trigram, "UHL", to obtain the "SXT" message setting. Next, he used this "SXT" message setting as the start position to decrypt the message. This way, each ground setting was different and the new procedure avoided the security flaw of double encoded message settings.
This procedure was used by "Wehrmacht" and "Luftwaffe" only. The "Kriegsmarine" procedures on sending messages with the Enigma were far more complex and elaborate. Prior to encryption the message was encoded using the "Kurzsignalheft" code book. The "Kurzsignalheft" contained tables to convert sentences into four-letter groups. A great many choices were included, for example, logistic matters such as refuelling and rendezvous with supply ships, positions and grid lists, harbour names, countries, weapons, weather conditions, enemy positions and ships, date and time tables. Another codebook contained the "Kenngruppen" and "SpruchschlÃ¼ssel": the key identification and message key.
Additional details.
The Army Enigma machine used only the 26 alphabet characters. Punctuation was replaced with rare character combinations. A space was omitted or replaced with an X. The X was generally used as period or full-stop.
Some punctuation marks were different in other parts of the armed forces. The "Wehrmacht" replaced a comma with ZZ and the question mark with FRAGE or FRAQ.
The "Kriegsmarine" replaced the comma with Y and the question mark with UD. The combination CH, as in ""Acht" (eight) or "Richtung"" (direction), was replaced with Q (AQT, RIQTUNG). Two, three and four zeros were replaced with CENTA, MILLE and MYRIA.
The "Wehrmacht" and the "Luftwaffe" transmitted messages in groups of five characters.
The "Kriegsmarine", using the four rotor Enigma, had four-character groups. Frequently used names or words were varied as much as possible. Words like "Minensuchboot" (minesweeper) could be written as MINENSUCHBOOT, MINBOOT, MMMBOOT or MMM354. To make cryptanalysis harder, messages were limited to 250 characters. Longer messages were divided into several parts, each using a different message key.
History.
The Enigma family included multiple designs. The earliest were commercial models dating from the early 1920s. Starting in the mid-1920s, the German military began to use Enigma, making a number of security-related changes. Various nations either adopted or adapted the design for their own cipher machines.
An estimated 100,000 Enigma machines were constructed. After the end of World War II, the Allies sold captured Enigma machines, still widely considered secure, to developing countries.
Commercial Enigma.
On 23 February 1918, German engineer Arthur Scherbius applied for a patent for a cipher machine using rotors and, with E. Richard Ritter, founded the firm of Scherbius & Ritter. They approached the "Kaiserliche Marine", (German Navy) and Foreign Office with their design, but neither was interested. Scherbius & Ritter then assigned the patent rights to Gewerkschaft Securitas, who founded the "Chiffriermaschinen Aktien-Gesellschaft" (Cipher Machines Stock Corporation) on 9 July 1923; Scherbius and Ritter were on the board of directors.
Enigma model A (1923).
Chiffriermaschinen AG began advertising a rotor machineâ"Enigma model A"âwhich was exhibited at the Congress of the International Postal Union in 1924. The machine was heavy and bulky, incorporating a typewriter. It measured 65Ã45Ã35Â cm and weighed about .
In 1925 Enigma "model B" was introduced, and was of a similar construction. While bearing the Enigma name, both models "A" and "B" were quite unlike later versions: they differed in physical size and shape, but also cryptographically, in that they lacked the reflector.
Enigma C (1926).
The reflectorâsuggested by Scherbius's colleague Willi Kornâwas introduced in "Enigma C" (1926).
"Model C" was smaller and more portable than its predecessors. It lacked a typewriter, relying on the operator; hence the informal name of "glowlamp Enigma" to distinguish it from models "A" and "B".
Enigma D (1927).
The "Enigma C" quickly gave way to "Enigma D" (1927). This version was widely used, with shipments to Sweden, the Netherlands, United Kingdom, Japan, Italy, Spain, United States and Poland. In 1927 Hugh Foss at the British Government Code and Cypher School was able to show that commercial Enigma machines could be broken provided that suitable cribs were available.
"Navy Cipher D" â Italian Navy.
Other countries used Enigma machines. The Italian Navy adopted the commercial Enigma as "Navy Cipher D". The Spanish also used commercial Enigma during their Civil War. British codebreakers succeeded in breaking these machines, which lacked a plugboard. Enigma were also used by diplomatic services.
Swiss K.
The Swiss used a version of Enigma called "model K" or "Swiss K" for military and diplomatic use, which was very similar to commercial Enigma D. The machine was cracked by Poland, France, the United Kingdom and the United States (the latter codenamed it INDIGO). An "Enigma T" model (codenamed "Tirpitz") was used by Japan.
Military Enigma.
FunkschlÃ¼ssel C.
The Reichsmarine was the first military branch to adopt Enigma. This version, named "FunkschlÃ¼ssel C" ("Radio cipher C"), had been put into production by 1925 and was introduced into service in 1926.
The keyboard and lampboard contained 29 lettersâA-Z, Ã, Ã and Ãâwhich were arranged alphabetically, as opposed to the QWERTZUI ordering. The rotors had 28 contacts, with the letter "X" wired to bypass the rotors unencrypted.
Three rotors were chosen from a set of five and the reflector could be inserted in one of four different positions, denoted Î±, Î², Î³ and Î´. The machine was revised slightly in July 1933.
Enigma G (1928â1930).
By 15 July 1928, the German Army ("Reichswehr") had introduced their own exclusive version of the Enigma machine; the "Enigma G".
The "Abwehr" used the "Enigma G" (the "Abwehr" Enigma). This Enigma variant was a four-wheel unsteckered machine with multiple notches on the rotors. This model was equipped with a counter which incremented upon each key press, and so is also known as the "counter machine" or the "ZÃ¤hlwerk" Enigma.
Wehrmacht Enigma I (1930â1938).
Enigma machine G was modified to the "Enigma I" by June 1930. Enigma I is also known as the "Wehrmacht", or "Services" Enigma, and was used extensively by German military services and other government organisations (such as the railways) before and during World War II.
The major difference between "Enigma I", (German Army version from 1930), and commercial Enigma models was the addition of a plugboard to swap pairs of letters, greatly increasing cryptographic strength.
Other differences included the use of a fixed reflector and the relocation of the stepping notches from the rotor body to the movable letter rings. The machine measured 28Ã34Ã15Â cm (11Â inÃ13.5Â inÃ6Â in) and weighed around .
In August 1935, the Air Force introduced the Wehrmacht Enigma for their communications.
M3, (1934).
By 1930, the Reichswehr had suggested that the Navy adopt their machine, citing the benefits of increased security (with the plugboard) and easier interservice communications. The Reichsmarine eventually agreed and in 1934 brought into service the Navy version of the Army Enigma, designated "FunkschlÃ¼ssel" ' or "M3". While the Army used only three rotors at that time, the Navy specified a choice of three from a possible five.
Two extra rotors (1938).
In December 1938, the Army issued two extra rotors so that the three rotors were chosen from a set of five. In 1938, the Navy added two more rotors, and then another in 1939 to allow a choice of three rotors from a set of eight.
M4 (1942).
A four-rotor Enigma was introduced by the Navy for U-boat traffic on 1 February 1942, called "M4" (the network was known as "Triton", or "Shark" to the Allies). The extra rotor was fitted in the same space by splitting the reflector into a combination of a thin reflector and a thin fourth rotor.
Enigma II.
There was also a large, eight-rotor printing model, the "Enigma II". In 1933 the Polish Cipher Bureau detected that it was in use for high-level military communications, but that it was soon withdrawn, as it was unreliable and jammed frequently.
Surviving machines.
The effort to break the Enigma was not disclosed until the 1970s. Since then, interest in the Enigma machine has grown. Enigmas are on public display in museums around the world, and several are in the hands of private collectors and computer history enthusiasts.
The "Deutsches Museum" in Munich has both the three- and four-rotor German military variants, as well as several civilian versions. Enigma machines are exhibited at the National Codes Centre in Bletchley Park, the Government Communications Headquarters, the Science Museum in London, the Polish Institute and Sikorski Museum in London, the Polish Army Museum in Warsaw, the Swedish Army Museum ("ArmÃ©museum") in Stockholm, the Nordland Red Cross War Memorial Museum in Narvik, Norway, the National Signals Museum in Finland, the Technical University of Denmark in Lyngby, Denmark, and at the Australian War Memorial and in the foyer of the Defence Signals Directorate, both in Canberra, Australia.
In the United States, Enigma machines can be seen at the Computer History Museum in Mountain View, California, and at the National Security Agency's National Cryptologic Museum in Fort Meade, Maryland, where visitors can try their hand at enciphering and deciphering messages. Two machines that were acquired after the capture of during World War II are on display at the Museum of Science and Industry in Chicago, Illinois. A four rotor device is on display in the ANZUS Corridor of the Pentagon on the second floor, A ring, between corridors 9 and 10. This machine is on loan from Australia. The United States Air Force Academy in Colorado Springs has a machine on display in the Computer Science Department. There's also a machine located at the National World War II Museum in New Orleans. The Museum of World War II in Boston has seven Enigma machines on display, including a U-Boat four-rotor model, one of three surviving examples of an Enigma machine with a printer, one of fewer than ten surviving ten-rotor code machines, an example blown up by a retreating German Army unit, and two three-rotor Enigmas that visitors can operate to encode and decode messages themselves.
In Canada, a Swiss Army issue Enigma-K, is in Calgary, Alberta. It is on permanent display at the Naval Museum of Alberta inside the Military Museums of Calgary. A 3-rotor Enigma machine is on display at the Military Communications and Electronics Museum at Canadian Forces Base (CFB) Kingston in Kingston, Ontario.
Occasionally, Enigma machines are sold at auction; prices have in recent years ranged from US$40,000 to US$203,000 in 2011. Replicas are available in various forms, including an exact reconstructed copy of the Naval M4 model, an Enigma implemented in electronics (Enigma-E), various simulators and paper-and-scissors analogues.
A rare "Abwehr" Enigma machine, designated G312, was stolen from the Bletchley Park museum on 1 April 2000. In September, a man identifying himself as "The Master" sent a note demanding Â£25,000 and threatening to destroy the machine if the ransom was not paid. In early October 2000, Bletchley Park officials announced that they would pay the ransom, but the stated deadline passed with no word from the blackmailer. Shortly afterward, the machine was sent anonymously to BBC journalist Jeremy Paxman, missing three rotors.
In November 2000, an antiques dealer named Dennis Yates was arrested after telephoning "The Sunday Times" to arrange the return of the missing parts. The Enigma machine was returned to Bletchley Park after the incident. In October 2001, Yates was sentenced to 10 months in prison and served three months.
In October 2008, the Spanish daily newspaper "El PaÃ­s" reported that 28 Enigma machines had been discovered by chance in an attic of Army headquarters in Madrid. These 4-rotor commercial machines had helped Franco's Nationalists win the Spanish Civil War because, though the British cryptologist Alfred Dilwyn Knox in 1937 broke the cipher generated by Franco's Enigma machines, this was not disclosed to the Republicans, who failed to break the cipher. The Nationalist government continued using its 50 Enigmas into the 1950s. Some machines have gone on display in Spanish military museums, including one at the National Museum of Science and Technology (MUNCYT) in La CoruÃ±a. Two have been given to Britain's GCHQ.
The Bulgarian military used Enigma machines with a Cyrillic keyboard; one is on display in the National Museum of Military History in Sofia.
Derivatives.
The Enigma was influential in the field of cipher machine design, spinning off other rotor machines. The British Typex was originally derived from the Enigma patents; Typex even includes features from the patent descriptions that were omitted from the actual Enigma machine. The British paid no royalties for the use of the patents, to protect secrecy. The Typex implementation is not the same as that found in German or other Axis versions.
A Japanese Enigma clone was codenamed GREEN by American cryptographers. Little used, it contained four rotors mounted vertically. In the U.S., cryptologist William Friedman designed the M-325, a machine logically similar, although not in construction.
A unique rotor machine was constructed in 2002 by Netherlands-based Tatjana van Vark. This device makes use of 40-point rotors, allowing letters, numbers and some punctuation to be used; each rotor contains 509 parts.
Machines like the SIGABA, NEMA, Typex and so forth, are deliberately not considered to be Enigma derivatives as their internal ciphering functions are not mathematically identical to the Enigma transform.
Several software implementations exist, but not all exactly match Enigma behaviour. The most commonly used software derivative (that is not compliant with any hardware implementation of the Enigma) is at EnigmaCo.de. Many Java applet Enigmas only accept single letter entry, complicating use even if the applet is Enigma compliant. Technically, Enigma@home is the largest scale deployment of a software Enigma, but the decoding software does not implement encipherment making it a derivative (as all original machines could cipher and decipher).
A user-friendly 3-rotor simulator, where users can select rotors, use the plugboard and define new settings for the rotors and reflectors is available. The output appears in separate windows which can be independently made "invisible" to hide decryption. Another includes an "autotyping" function which takes plaintext from a clipboard and converts it to cyphertext (or vice versa) at one of four speeds. The "very fast" option produces 26 characters in less than one second.

</doc>
<doc id="9257" url="https://en.wikipedia.org/wiki?curid=9257" title="Enzyme">
Enzyme

Enzymes are macromolecular biological catalysts. Enzymes accelerate, or catalyze, chemical reactions. The molecules at the beginning of the process are called substrates and the enzyme converts these into different molecules, called products. Almost all metabolic processes in the cell need enzymes in order to occur at rates fast enough to sustain life. The set of enzymes made in a cell determines which metabolic pathways occur in that cell. The study of enzymes is called "enzymology".
Enzymes are known to catalyze more than 5,000 biochemical reaction types. Most enzymes are proteins, although a few are catalytic RNA molecules. Enzymes' specificity comes from their unique three-dimensional structures.
Like all catalysts, enzymes increase the rate of a reaction by lowering its activation energy. Some enzymes can make their conversion of substrate to product occur many millions of times faster. An extreme example is orotidine 5'-phosphate decarboxylase, which allows a reaction that would otherwise take millions of years to occur in milliseconds. Chemically, enzymes are like any catalyst and are not consumed in chemical reactions, nor do they alter the equilibrium of a reaction. Enzymes differ from most other catalysts by being much more specific. Enzyme activity can be affected by other molecules: inhibitors are molecules that decrease enzyme activity, and activators are molecules that increase activity. Many drugs and poisons are enzyme inhibitors. An enzyme's activity decreases markedly outside its optimal temperature and pH.
Some enzymes are used commercially, for example, in the synthesis of antibiotics. Some household products use enzymes to speed up chemical reactions: enzymes in biological washing powders break down protein, starch or fat stains on clothes, and enzymes in meat tenderizer break down proteins into smaller molecules, making the meat easier to chew.
Etymology and history.
By the late 17th and early 18th centuries, the digestion of meat by stomach secretions and the conversion of starch to sugars by plant extracts and saliva were known but the mechanisms by which these occurred had not been identified.
French chemist Anselme Payen was the first to discover an enzyme, diastase, in 1833. A few decades later, when studying the fermentation of sugar to alcohol by yeast, Louis Pasteur concluded that this fermentation was caused by a vital force contained within the yeast cells called "ferments", which were thought to function only within living organisms. He wrote that "alcoholic fermentation is an act correlated with the life and organization of the yeast cells, not with the death or putrefaction of the cells."
In 1877, German physiologist Wilhelm KÃ¼hne (1837â1900) first used the term "enzyme", which comes from Greek á¼Î½Î¶ÏÎ¼Î¿Î½, "leavened", to describe this process. The word "enzyme" was used later to refer to nonliving substances such as pepsin, and the word "ferment" was used to refer to chemical activity produced by living organisms.
Eduard Buchner submitted his first paper on the study of yeast extracts in 1897. In a series of experiments at the University of Berlin, he found that sugar was fermented by yeast extracts even when there were no living yeast cells in the mixture. He named the enzyme that brought about the fermentation of sucrose "zymase". In 1907, he received the Nobel Prize in Chemistry for "his discovery of cell-free fermentation". Following Buchner's example, enzymes are usually named according to the reaction they carry out: the suffix "-ase" is combined with the name of the substrate (e.g., lactase is the enzyme that cleaves lactose) or to the type of reaction (e.g., DNA polymerase forms DNA polymers).
The biochemical identity of enzymes was still unknown in the early 1900s. Many scientists observed that enzymatic activity was associated with proteins, but others (such as Nobel laureate Richard WillstÃ¤tter) argued that proteins were merely carriers for the true enzymes and that proteins "per se" were incapable of catalysis. In 1926, James B. Sumner showed that the enzyme urease was a pure protein and crystallized it; he did likewise for the enzyme catalase in 1937. The conclusion that pure proteins can be enzymes was definitively demonstrated by John Howard Northrop and Wendell Meredith Stanley, who worked on the digestive enzymes pepsin (1930), trypsin and chymotrypsin. These three scientists were awarded the 1946 Nobel Prize in Chemistry.
The discovery that enzymes could be crystallized eventually allowed their structures to be solved by x-ray crystallography. This was first done for lysozyme, an enzyme found in tears, saliva and egg whites that digests the coating of some bacteria; the structure was solved by a group led by David Chilton Phillips and published in 1965. This high-resolution structure of lysozyme marked the beginning of the field of structural biology and the effort to understand how enzymes work at an atomic level of detail.
Structure.
Enzymes are generally globular proteins, acting alone or in larger complexes. Like all proteins, enzymes are linear chains of amino acids that fold to produce a three-dimensional structure. The sequence of the amino acids specifies the structure which in turn determines the catalytic activity of the enzyme. Although structure determines function, a novel enzyme's activity cannot yet be predicted from its structure alone. Enzyme structures unfold (denature) when heated or exposed to chemical denaturants and this disruption to the structure typically causes a loss of activity. Enzyme denaturation is normally linked to temperatures above a species' normal level; as a result, enzymes from bacteria living in volcanic environments such as hot springs are prized by industrial users for their ability to function at high temperatures, allowing enzyme-catalysed reactions to be operated at a very high rate.
Enzymes are usually much larger than their substrates. Sizes range from just 62 amino acid residues, for the monomer of 4-oxalocrotonate tautomerase, to over 2,500 residues in the animal fatty acid synthase. Only a small portion of their structure (around 2â4 amino acids) is directly involved in catalysis: the catalytic site. This catalytic site is located next to one or more binding sites where residues orient the substrates. The catalytic site and binding site together comprise the enzyme's active site. The remaining majority of the enzyme structure serves to maintain the precise orientation and dynamics of the active site.
In some enzymes, no amino acids are directly involved in catalysis; instead, the enzyme contains sites to bind and orient catalytic cofactors. Enzyme structures may also contain allosteric sites where the binding of a small molecule causes a conformational change that increases or decreases activity.
A small number of RNA-based biological catalysts called ribozymes exist, which again can act alone or in complex with proteins. The most common of these is the ribosome which is a complex of protein and catalytic RNA components.
Mechanism.
Substrate binding.
Enzymes must bind their substrates before they can catalyse any chemical reaction. Enzymes are usually very specific as to what substrates they bind and then the chemical reaction catalysed. Specificity is achieved by binding pockets with complementary shape, charge and hydrophilic/hydrophobic characteristics to the substrates. Enzymes can therefore distinguish between very similar substrate molecules to be chemoselective, regioselective and stereospecific.
Some of the enzymes showing the highest specificity and accuracy are involved in the copying and expression of the genome. Some of these enzymes have "proof-reading" mechanisms. Here, an enzyme such as DNA polymerase catalyzes a reaction in a first step and then checks that the product is correct in a second step. This two-step process results in average error rates of less than 1 error in 100 million reactions in high-fidelity mammalian polymerases. Similar proofreading mechanisms are also found in RNA polymerase, aminoacyl tRNA synthetases and ribosomes.
Conversely, some enzymes display enzyme promiscuity, having broad specificity and acting on a range of different physiologically relevant substrates. Many enzymes possess small side activities which arose fortuitously (i.e. neutrally), which may be the starting point for the evolutionary selection of a new function.
"Lock and key" model.
To explain the observed specificity of enzymes, in 1894 Emil Fischer proposed that both the enzyme and the substrate possess specific complementary geometric shapes that fit exactly into one another. This is often referred to as "the lock and key" model. This early model explains enzyme specificity, but fails to explain the stabilization of the transition state that enzymes achieve.
Induced fit model.
In 1958, Daniel Koshland suggested a modification to the lock and key model: since enzymes are rather flexible structures, the active site is continuously reshaped by interactions with the substrate as the substrate interacts with the enzyme. As a result, the substrate does not simply bind to a rigid active site; the amino acid side-chains that make up the active site are molded into the precise positions that enable the enzyme to perform its catalytic function. In some cases, such as glycosidases, the substrate molecule also changes shape slightly as it enters the active site. The active site continues to change until the substrate is completely bound, at which point the final shape and charge distribution is determined.
Induced fit may enhance the fidelity of molecular recognition in the presence of competition and noise via the conformational proofreading mechanism.
Catalysis.
Enzymes can accelerate reactions in several ways, all of which lower the activation energy (ÎG, Gibbs free energy)
Enzymes may use several of these mechanisms simultaneously. For example, proteases such as trypsin perform covalent catalysis using a catalytic triad, stabilise charge build-up on the transition states using an oxyanion hole, complete hydrolysis using an oriented water substrate.
Dynamics.
Enzymes are not rigid, static structures; instead they have complex internal dynamic motions â that is, movements of parts of the enzyme's structure such as individual amino acid residues, groups of residues forming a protein loop or unit of secondary structure, or even an entire protein domain. These motions give rise to a conformational ensemble of slightly different structures that interconvert with one another at equilibrium. Different states within this ensemble may be associated with different aspects of an enzyme's function. For example, different conformations of the enzyme dihydrofolate reductase are associated with the substrate binding, catalysis, cofactor release, and product release steps of the catalytic cycle.
Allosteric modulation.
Allosteric sites are pockets on the enzyme, distinct from the active site, that bind to molecules in the cellular environment. These molecules then cause a change in the conformation or dynamics of the enzyme that is transduced to the active site and thus affects the reaction rate of the enzyme. In this way, allosteric interactions can either inhibit or activate enzymes. Allosteric interactions with metabolites upstream or downstream in an enzyme's metabolic pathway cause feedback regulation, altering the activity of the enzyme according to the flux through the rest of the pathway.
Cofactors.
Some enzymes do not need additional components to show full activity. Others require non-protein molecules called cofactors to be bound for activity. Cofactors can be either inorganic (e.g., metal ions and iron-sulfur clusters) or organic compounds (e.g., flavin and heme). Organic cofactors can be either coenzymes, which are released from the enzyme's active site during the reaction, or prosthetic groups, which are tightly bound to an enzyme. Organic prosthetic groups can be covalently bound (e.g., biotin in enzymes such as pyruvate carboxylase).
An example of an enzyme that contains a cofactor is carbonic anhydrase, which is shown in the ribbon diagram above with a zinc cofactor bound as part of its active site. These tightly bound ions or molecules are usually found in the active site and are involved in catalysis. For example, flavin and heme cofactors are often involved in redox reactions.
Enzymes that require a cofactor but do not have one bound are called "apoenzymes" or "apoproteins". An enzyme together with the cofactor(s) required for activity is called a "holoenzyme" (or haloenzyme). The term "holoenzyme" can also be applied to enzymes that contain multiple protein subunits, such as the DNA polymerases; here the holoenzyme is the complete complex containing all the subunits needed for activity.
Coenzymes.
Coenzymes are small organic molecules that can be loosely or tightly bound to an enzyme. Coenzymes transport chemical groups from one enzyme to another. Examples include NADH, NADPH and adenosine triphosphate (ATP). Some coenzymes, such as riboflavin, thiamine and folic acid, are vitamins, or compounds that cannot be synthesized by the body and must be acquired from the diet. The chemical groups carried include the hydride ion (H) carried by NAD or NADP, the phosphate group carried by adenosine triphosphate, the acetyl group carried by coenzyme A, formyl, methenyl or methyl groups carried by folic acid and the methyl group carried by S-adenosylmethionine.
Since coenzymes are chemically changed as a consequence of enzyme action, it is useful to consider coenzymes to be a special class of substrates, or second substrates, which are common to many different enzymes. For example, about 1000 enzymes are known to use the coenzyme NADH.
Coenzymes are usually continuously regenerated and their concentrations maintained at a steady level inside the cell. For example, NADPH is regenerated through the pentose phosphate pathway and "S"-adenosylmethionine by methionine adenosyltransferase. This continuous regeneration means that small amounts of coenzymes can be used very intensively. For example, the human body turns over its own weight in ATP each day.
Thermodynamics.
As with all catalysts, enzymes do not alter the position of the chemical equilibrium of the reaction. In the presence of an enzyme, the reaction runs in the same direction as it would without the enzyme, just more quickly. For example, carbonic anhydrase catalyzes its reaction in either direction depending on the concentration of its reactants:
The rate of a reaction is dependent on the activation energy needed to form the transition state which then decays into products. Enzymes increase reaction rates by lowering the energy of the transition state. First, binding forms a low energy enzyme-substrate complex (ES). Secondly the enzyme stabilises the transition state such that it requires less energy to achieve compared to the uncatalyzed reaction (ES). Finally the enzyme-product complex (EP) dissociates to release the products.
Enzymes can couple two or more reactions, so that a thermodynamically favorable reaction can be used to "drive" a thermodynamically unfavourable one so that the combined energy of the products is lower than the substrates. For example, the hydrolysis of ATP is often used to drive other chemical reactions.
Kinetics.
Enzyme kinetics is the investigation of how enzymes bind substrates and turn them into products. The rate data used in kinetic analyses are commonly obtained from enzyme assays. In 1913 Leonor Michaelis and Maud Leonora Menten proposed a quantitative theory of enzyme kinetics, which is referred to as MichaelisâMenten kinetics. The major contribution of Michaelis and Menten was to think of enzyme reactions in two stages. In the first, the substrate binds reversibly to the enzyme, forming the enzyme-substrate complex. This is sometimes called the Michaelis-Menten complex in their honor. The enzyme then catalyzes the chemical step in the reaction and releases the product. This work was further developed by G. E. Briggs and J. B. S. Haldane, who derived kinetic equations that are still widely used today.
Enzyme rates depend on solution conditions and substrate concentration. To find the maximum speed of an enzymatic reaction, the substrate concentration is increased until a constant rate of product formation is seen. This is shown in the saturation curve on the right. Saturation happens because, as substrate concentration increases, more and more of the free enzyme is converted into the substrate-bound ES complex. At the maximum reaction rate ("V") of the enzyme, all the enzyme active sites are bound to substrate, and the amount of ES complex is the same as the total amount of enzyme.
"V" is only one of several important kinetic parameters. The amount of substrate needed to achieve a given rate of reaction is also important. This is given by the Michaelis-Menten constant ("K"), which is the substrate concentration required for an enzyme to reach one-half its maximum reaction rate; generally, each enzyme has a characteristic "K" for a given substrate. Another useful constant is "k", also called the "turnover number", which is the number of substrate molecules handled by one active site per second.
The efficiency of an enzyme can be expressed in terms of "k"/"K". This is also called the specificity constant and incorporates the rate constants for all steps in the reaction up to and including the first irreversible step. Because the specificity constant reflects both affinity and catalytic ability, it is useful for comparing different enzymes against each other, or the same enzyme with different substrates. The theoretical maximum for the specificity constant is called the diffusion limit and is about 10 to 10 (M s). At this point every collision of the enzyme with its substrate will result in catalysis, and the rate of product formation is not limited by the reaction rate but by the diffusion rate. Enzymes with this property are called "catalytically perfect" or "kinetically perfect". Example of such enzymes are triose-phosphate isomerase, carbonic anhydrase, acetylcholinesterase, catalase, fumarase, Î²-lactamase, and superoxide dismutase. The turnover of such enzymes can reach several million reactions per second.
MichaelisâMenten kinetics relies on the law of mass action, which is derived from the assumptions of free diffusion and thermodynamically driven random collision. Many biochemical or cellular processes deviate significantly from these conditions, because of macromolecular crowding and constrained molecular movement. More recent, complex extensions of the model attempt to correct for these effects.
Inhibition.
Enzyme reaction rates can be decreased by various types of enzyme inhibitors.
Functions of inhibitors.
In many organisms, inhibitors may act as part of a feedback mechanism. If an enzyme produces too much of one substance in the organism, that substance may act as an inhibitor for the enzyme at the beginning of the pathway that produces it, causing production of the substance to slow down or stop when there is sufficient amount. This is a form of negative feedback. Major metabolic pathways such as the citric acid cycle make use of this mechanism.
Since inhibitors modulate the function of enzymes they are often used as drugs. Many such drugs are reversible competitive inhibitors that resemble the enzyme's native substrate, similar to methotrexate above; other well-known examples include statins used to treat high cholesterol, and protease inhibitors used to treat retroviral infections such as HIV. A common example of an irreversible inhibitor that is used as a drug is aspirin, which inhibits the COX-1 and COX-2 enzymes that produce the inflammation messenger prostaglandin. Other enzyme inhibitors are poisons. For example, the poison cyanide is an irreversible enzyme inhibitor that combines with the copper and iron in the active site of the enzyme cytochrome c oxidase and blocks cellular respiration.
Biological function.
Enzymes serve a wide variety of functions inside living organisms. They are indispensable for signal transduction and cell regulation, often via kinases and phosphatases. They also generate movement, with myosin hydrolyzing ATP to generate muscle contraction, and also transport cargo around the cell as part of the cytoskeleton. Other ATPases in the cell membrane are ion pumps involved in active transport. Enzymes are also involved in more exotic functions, such as luciferase generating light in fireflies. Viruses can also contain enzymes for infecting cells, such as the HIV integrase and reverse transcriptase, or for viral release from cells, like the influenza virus neuraminidase.
An important function of enzymes is in the digestive systems of animals. Enzymes such as amylases and proteases break down large molecules (starch or proteins, respectively) into smaller ones, so they can be absorbed by the intestines. Starch molecules, for example, are too large to be absorbed from the intestine, but enzymes hydrolyze the starch chains into smaller molecules such as maltose and eventually glucose, which can then be absorbed. Different enzymes digest different food substances. In ruminants, which have herbivorous diets, microorganisms in the gut produce another enzyme, cellulase, to break down the cellulose cell walls of plant fiber.
Metabolism.
Several enzymes can work together in a specific order, creating metabolic pathways. In a metabolic pathway, one enzyme takes the product of another enzyme as a substrate. After the catalytic reaction, the product is then passed on to another enzyme. Sometimes more than one enzyme can catalyze the same reaction in parallel; this can allow more complex regulation: with, for example, a low constant activity provided by one enzyme but an inducible high activity from a second enzyme.
Enzymes determine what steps occur in these pathways. Without enzymes, metabolism would neither progress through the same steps and could not be regulated to serve the needs of the cell. Most central metabolic pathways are regulated at a few key steps, typically through enzymes whose activity involves the hydrolysis of ATP. Because this reaction releases so much energy, other reactions that are thermodynamically unfavorable can be coupled to ATP hydrolysis, driving the overall series of linked metabolic reactions.
Control of activity.
There are five main ways that enzyme activity is controlled in the cell.
Involvement in disease.
Since the tight control of enzyme activity is essential for homeostasis, any malfunction (mutation, overproduction, underproduction or deletion) of a single critical enzyme can lead to a genetic disease. The malfunction of just one type of enzyme out of the thousands of types present in the human body can be fatal. An example of a fatal genetic disease due to enzyme insufficiency is Tay-Sachs disease, in which patients lack the enzyme hexosaminidase.
One example of enzyme deficiency is the most common type of phenylketonuria. Many different single amino acid mutations in the enzyme phenylalanine hydroxylase, which catalyzes the first step in the degradation of phenylalanine, result in build-up of phenylalanine and related products. Some mutations are in the active site, directly disrupting binding and catalysis, but many are far from the active site and reduce activity by destabilising the protein structure, or affecting correct oligomerisation. This can lead to intellectual disability if the disease is untreated. Another example is pseudocholinesterase deficiency, in which the body's ability to break down choline ester drugs is impaired. 
Oral administration of enzymes can be used to treat some functional enzyme deficiencies, such as pancreatic insufficiency and lactose intolerance.
Another way enzyme malfunctions can cause disease comes from germline mutations in genes coding for DNA repair enzymes. Defects in these enzymes cause cancer because cells are less able to repair mutations in their genomes. This causes a slow accumulation of mutations and results in the development of cancers. An example of such a hereditary cancer syndrome is xeroderma pigmentosum, which causes the development of skin cancers in response to even minimal exposure to ultraviolet light.
Naming conventions.
An enzyme's name is often derived from its substrate or the chemical reaction it catalyzes, with the word ending in "-ase". Examples are lactase, alcohol dehydrogenase and DNA polymerase. Different enzymes that catalyze the same chemical reaction are called isozymes.
The International Union of Biochemistry and Molecular Biology have developed a nomenclature for enzymes, the EC numbers; each enzyme is described by a sequence of four numbers preceded by "EC". The first number broadly classifies the enzyme based on its mechanism.
The top-level classification is:
These sections are subdivided by other features such as the substrate, products, and chemical mechanism. An enzyme is fully specified by four numerical designations. For example, hexokinase (EC 2.7.1.1) is a transferase (EC 2) that adds a phosphate group (EC 2.7) to a hexose sugar, a molecule containing an alcohol group (EC 2.7.1).
Industrial applications.
Enzymes are used in the chemical industry and other industrial applications when extremely specific catalysts are required. Enzymes in general are limited in the number of reactions they have evolved to catalyze and also by their lack of stability in organic solvents and at high temperatures. As a consequence, protein engineering is an active area of research and involves attempts to create new enzymes with novel properties, either through rational design or "in vitro" evolution. These efforts have begun to be successful, and a few enzymes have now been designed "from scratch" to catalyze reactions that do not occur in nature.
Further reading.
General
Etymology and history
Enzyme structure and mechanism
Kinetics and inhibition

</doc>
<doc id="9258" url="https://en.wikipedia.org/wiki?curid=9258" title="Ethics">
Ethics

Ethics or moral philosophy is the branch of philosophy that involves systematizing, defending, and recommending concepts of right and wrong conduct. The term "ethics" derives from the Ancient Greek word á¼ Î¸Î¹ÎºÏÏ "ethikos", which is derived from the word á¼¦Î¸Î¿Ï "ethos" (habit, "custom"). The branch of philosophy axiology comprises the sub-branches of ethics and aesthetics, each concerned with values.
As a branch of philosophy, ethics investigates the questions "What is the best way for people to live?" and "What actions are right or wrong in particular circumstances?" In practice, ethics seeks to resolve questions of human morality, by defining concepts such as good and evil, right and wrong, virtue and vice, justice and crime. As a field of intellectual enquiry, moral philosophy also is related to the fields of moral psychology, descriptive ethics, and value theory.
Three major areas of study within ethics recognised today are:
Defining ethics.
Rushworth Kidder states that "standard definitions of "ethics" have typically included such phrases as 'the science of the ideal human character' or 'the science of moral duty'â". Richard William Paul and Linda Elder define ethics as "a set of concepts and principles that guide us in determining what behavior helps or harms sentient creatures". The "Cambridge Dictionary of Philosophy" states that the word ethics is "commonly used interchangeably with 'morality'Â ... and sometimes it is used more narrowly to mean the moral principles of a particular tradition, group or individual." Paul and Elder state that most people confuse ethics with behaving in accordance with social conventions, religious beliefs and the law and don't treat ethics as a stand-alone concept.
The word "ethics" in English refers to several things. It can refer to philosophical ethics or moral philosophyâa project that attempts to use reason in order to answer various kinds of ethical questions. As the English philosopher Bernard Williams writes, attempting to explain moral philosophy: "What makes an inquiry a philosophical one is reflective generality and a style of argument that claims to be rationally persuasive." And Williams describes the content of this area of inquiry as addressing the very broad question, "how one should live" Ethics can also refer to a common human ability to think about ethical problems that is not particular to philosophy. As bioethicist Larry Churchill has written: "Ethics, understood as the capacity to think critically about moral values and direct our actions in terms of such values, is a generic human capacity." Ethics can also be used to describe a particular person's own, idiosyncratic principles or habits. For example: "Joe has strange ethics."
The English word ethics is derived from an Ancient Greek word "Ãªthikos", which means "relating to one's character." The Ancient Greek adjective "Ãªthikos" is itself derived from another Greek word, the noun "Ãªthos" meaning "character, disposition."
Meta-ethics.
Meta-ethics asks how we understand, know about, and what we mean when we talk about what is right and what is wrong. An ethical question fixed on some particular practical questionâsuch as, "Should I eat this particular piece of chocolate cake?"âcannot be a meta-ethical question. A meta-ethical question is abstract and relates to a wide range of more specific practical questions. For example, "Is it ever possible to have secure knowledge of what is right and wrong?" would be a meta-ethical question.
Meta-ethics has always accompanied philosophical ethics. For example, Aristotle implies that less precise knowledge is possible in ethics than in other spheres of inquiry, and he regards ethical knowledge as depending upon habit and acculturation in a way that makes it distinctive from other kinds of knowledge. Meta-ethics is also important in G.E. Moore's "Principia Ethica" from 1903. In it he first wrote about what he called "the naturalistic fallacy". Moore was seen to reject naturalism in ethics, in his Open Question Argument. This made thinkers look again at second order questions about ethics. Earlier, the Scottish philosopher David Hume had put forward a similar view on the difference between facts and values.
Studies of how we know in ethics divide into cognitivism and non-cognitivism; this is similar to the contrast between descriptivists and non-descriptivists. Non-cognitivism is the claim that when we judge something as right or wrong, this is neither true nor false. We may for example be only expressing our emotional feelings about these things. Cognitivism can then be seen as the claim that when we talk about right and wrong, we are talking about matters of fact.
The ontology of ethics is about value-bearing things or properties, i.e. the kind of things or stuff referred to by ethical propositions. Non-descriptivists and non-cognitivists believe that ethics does not need a specific ontology, since ethical propositions do not refer. This is known as an anti-realist position. Realists on the other hand must explain what kind of entities, properties or states are relevant for ethics, how they have value, and why they guide and motivate our actions.
Normative ethics.
Normative ethics is the study of ethical action. It is the branch of ethics that investigates the set of questions that arise when considering how one ought to act, morally speaking. Normative ethics is distinct from meta-ethics because it examines standards for the rightness and wrongness of actions, while meta-ethics studies the meaning of moral language and the metaphysics of moral facts. Normative ethics is also distinct from descriptive ethics, as the latter is an empirical investigation of people's moral beliefs. To put it another way, descriptive ethics would be concerned with determining what proportion of people believe that killing is always wrong, while normative ethics is concerned with whether it is correct to hold such a belief. Hence, normative ethics is sometimes called prescriptive, rather than descriptive. However, on certain versions of the meta-ethical view called moral realism, moral facts are both descriptive and prescriptive at the same time.
Traditionally, normative ethics (also known as moral theory) was the study of what makes actions right and wrong. These theories offered an overarching moral principle one could appeal to in resolving difficult moral decisions.
At the turn of the 20th century, moral theories became more complex and are no longer concerned solely with rightness and wrongness, but are interested in many different kinds of moral status. During the middle of the century, the study of normative ethics declined as meta-ethics grew in prominence. This focus on meta-ethics was in part caused by an intense linguistic focus in analytic philosophy and by the popularity of logical positivism.
In 1971 John Rawls published "A Theory of Justice", noteworthy in its pursuit of moral arguments and eschewing of meta-ethics. This publication set the trend for renewed interest in normative ethics.
Virtue ethics.
Virtue ethics describes the character of a moral agent as a driving force for ethical behavior, and is used to describe the ethics of Socrates, Aristotle, and other early Greek philosophers. Socrates (469â399Â BC) was one of the first Greek philosophers to encourage both scholars and the common citizen to turn their attention from the outside world to the condition of humankind. In this view, knowledge bearing on human life was placed highest, while all other knowledge were secondary. Self-knowledge was considered necessary for success and inherently an essential good. A self-aware person will act completely within his capabilities to his pinnacle, while an ignorant person will flounder and encounter difficulty. To Socrates, a person must become aware of every fact (and its context) relevant to his existence, if he wishes to attain self-knowledge. He posited that people will naturally do what is good, if they know what is right. Evil or bad actions are the result of ignorance. If a criminal was truly aware of the intellectual and spiritual consequences of his actions, he would neither commit nor even consider committing those actions. Any person who knows what is truly right will automatically do it, according to Socrates. While he correlated knowledge with virtue, he similarly equated virtue with joy. The truly wise man will know what is right, do what is good, and therefore be happy.
Aristotle (384â323Â BC) posited an ethical system that may be termed "self-realizationism." In Aristotle's view, when a person acts in accordance with his nature and realizes his full potential, he will do good and be content. At birth, a baby is not a person, but a potential person. To become a "real" person, the child's inherent potential must be realized. Unhappiness and frustration are caused by the unrealized potential of a person, leading to failed goals and a poor life. Aristotle said, "Nature does nothing in vain." Therefore, it is imperative for people to act in accordance with their nature and develop their latent talents in order to be content and complete. Happiness was held to be the ultimate goal. All other things, such as civic life or wealth, are merely means to the end. Self-realization, the awareness of one's nature and the development of one's talents, is the surest path to happiness.
Aristotle asserted that man had three natures: vegetable (physical/metabolism), animal (emotional/appetite) and rational (mental/conceptual). Physical nature can be assuaged through exercise and care, emotional nature through indulgence of instinct and urges, and mental through human reason and developed potential. Rational development was considered the most important, as essential to philosophical self-awareness and as uniquely human. Moderation was encouraged, with the extremes seen as degraded and immoral. For example, courage is the moderate virtue between the extremes of cowardice and recklessness. Man should not simply live, but live well with conduct governed by moderate virtue. This is regarded as difficult, as virtue denotes doing the right thing, to the right person, at the right time, to the proper extent, in the correct fashion, for the right reason.
Stoicism.
The Stoic philosopher Epictetus posited that the greatest good was contentment and serenity. Peace of mind, or Apatheia, was of the highest value; self-mastery over one's desires and emotions leads to spiritual peace. The "unconquerable will" is central to this philosophy. The individual's will should be independent and inviolate. Allowing a person to disturb the mental equilibrium is in essence offering yourself in slavery. If a person is free to anger you at will, you have no control over your internal world, and therefore no freedom. Freedom from material attachments is also necessary. If a thing breaks, the person should not be upset, but realize it was a thing that could break. Similarly, if someone should die, those close to them should hold to their serenity because the loved one was made of flesh and blood destined to death. Stoic philosophy says to accept things that cannot be changed, resigning oneself to existence and enduring in a rational fashion. Death is not feared. People do not "lose" their life, but instead "return", for they are returning to God (who initially gave what the person is as a person). Epictetus said difficult problems in life should not be avoided, but rather embraced. They are spiritual exercises needed for the health of the spirit, just as physical exercise is required for the health of the body. He also stated that sex and sexual desire are to be avoided as the greatest threat to the integrity and equilibrium of a man's mind. Abstinence is highly desirable. Epictetus said remaining abstinent in the face of temptation was a victory for which a man could be proud.
Contemporary virtue ethics.
Modern virtue ethics was popularized during the late 20th century in large part as a response to G. E. M. Anscombe's "Modern Moral Philosophy". Anscombe argues that consequentialist and deontological ethics are only feasible as universal theories if the two schools ground themselves in divine law. As a deeply devoted Christian herself, Anscombe proposed that either those who do not give ethical credence to notions of divine law take up virtue ethics, which does not necessitate universal laws as agents themselves are investigated for virtue or vice and held up to "universal standards," or that those who wish to be utilitarian or consequentialist ground their theories in religious conviction. Alasdair MacIntyre, who wrote the book "After Virtue", was a key contributor and proponent of modern virtue ethics, although MacIntyre supports a relativistic account of virtue based on cultural norms, not objective standards. Martha Nussbaum, a contemporary virtue ethicist, objects to MacIntyre's relativism, among that of others, and responds to relativist objections to form an objective account in her work "Non-Relative Virtues: An Aristotelian Approach."
"Complete Conduct Principles for the 21st Century" blended the Eastern virtue ethics and the Western virtue ethics, with some modifications to suit the 21st Century, and formed a part of contemporary virtue ethics.
Hedonism.
Hedonism posits that the principal ethic is maximizing pleasure and minimizing pain. There are several schools of Hedonist thought ranging from those advocating the indulgence of even momentary desires to those teaching a pursuit of spiritual bliss. In their consideration of consequences, they range from those advocating self-gratification regardless of the pain and expense to others, to those stating that the most ethical pursuit maximizes pleasure and happiness for the most people.
Cyrenaic hedonism.
Founded by Aristippus of Cyrene, Cyrenaics supported immediate gratification or pleasure. "Eat, drink and be merry, for tomorrow we die." Even fleeting desires should be indulged, for fear the opportunity should be forever lost. There was little to no concern with the future, the present dominating in the pursuit for immediate pleasure. Cyrenaic hedonism encouraged the pursuit of enjoyment and indulgence without hesitation, believing pleasure to be the only good.
Epicureanism.
Epicurean ethics is a hedonist form of virtue ethics. Epicurus "presented a sustained argument that pleasure, correctly understood, will coincide with virtue". He rejected the extremism of the Cyrenaics, believing some pleasures and indulgences to be detrimental to human beings. Epicureans observed that indiscriminate indulgence sometimes resulted in negative consequences. Some experiences were therefore rejected out of hand, and some unpleasant experiences endured in the present to ensure a better life in the future. To Epicurus the "summum bonum", or greatest good, was prudence, exercised through moderation and caution. Excessive indulgence can be destructive to pleasure and can even lead to pain. For example, eating one food too often will cause a person to lose taste for it. Eating too much food at once will lead to discomfort and ill-health. Pain and fear were to be avoided. Living was essentially good, barring pain and illness. Death was not to be feared. Fear was considered the source of most unhappiness. Conquering the fear of death would naturally lead to a happier life. Epicurus reasoned if there was an afterlife and immortality, the fear of death was irrational. If there was no life after death, then the person would not be alive to suffer, fear or worry; he would be non-existent in death. It is irrational to fret over circumstances that do not exist, such as one's state in death in the absence of an afterlife.
State consequentialism.
State consequentialism, also known as Mohist consequentialism, is an ethical theory that evaluates the moral worth of an action based on how much it contributes to the basic goods of a state. The "Stanford Encyclopedia of Philosophy" describes Mohist consequentialism, dating back to the 5th century BC, as "a remarkably sophisticated version based on a plurality of intrinsic goods taken as constitutive of human welfare." Unlike utilitarianism, which views pleasure as a moral good, "the basic goods in Mohist consequentialist thinking areÂ ... order, material wealth, and increase in population". During Mozi's era, war and famines were common, and population growth was seen as a moral necessity for a harmonious society. The "material wealth" of Mohist consequentialism refers to basic needs like shelter and clothing, and the "order" of Mohist consequentialism refers to Mozi's stance against warfare and violence, which he viewed as pointless and a threat to social stability.
Stanford sinologist David Shepherd Nivison, in "The Cambridge History of Ancient China", writes that the moral goods of Mohism "are interrelated: more basic wealth, then more reproduction; more people, then more production and wealthÂ ... if people have plenty, they would be good, filial, kind, and so on unproblematically." The Mohists believed that morality is based on "promoting the benefit of all under heaven and eliminating harm to all under heaven." In contrast to Bentham's views, state consequentialism is not utilitarian because it is not hedonistic or individualistic. The importance of outcomes that are good for the community outweigh the importance of individual pleasure and pain.
Consequentialism/Teleology.
Consequentialism refers to moral theories that hold that the consequences of a particular action form the basis for any valid moral judgment about that action (or create a structure for judgment, see rule consequentialism). Thus, from a consequentialist standpoint, a morally right action is one that produces a good outcome, or consequence. This view is often expressed as the aphorism "The ends justify the means".
The term "consequentialism" was coined by G. E. M. Anscombe in her essay "Modern Moral Philosophy" in 1958, to describe what she saw as the central error of certain moral theories, such as those propounded by Mill and Sidgwick. Since then, the term has become common in English-language ethical theory.
The defining feature of consequentialist moral theories is the weight given to the consequences in evaluating the rightness and wrongness of actions. In consequentialist theories, the consequences of an action or rule generally outweigh other considerations. Apart from this basic outline, there is little else that can be unequivocally said about consequentialism as such. However, there are some questions that many consequentialist theories address:
One way to divide various consequentialisms is by the types of consequences that are taken to matter most, that is, which consequences count as good states of affairs. According to utilitarianism, a good action is one that results in an increase in a positive effect, and the best action is one that results in that effect for the greatest number. Closely related is eudaimonic consequentialism, according to which a full, flourishing life, which may or may not be the same as enjoying a great deal of pleasure, is the ultimate aim. Similarly, one might adopt an aesthetic consequentialism, in which the ultimate aim is to produce beauty. However, one might fix on non-psychological goods as the relevant effect. Thus, one might pursue an increase in material equality or political liberty instead of something like the more ephemeral "pleasure". Other theories adopt a package of several goods, all to be promoted equally. Whether a particular consequentialist theory focuses on a single good or many, conflicts and tensions between different good states of affairs are to be expected and must be adjudicated.
Utilitarianism.
Utilitarianism is an ethical theory that argues the proper course of action is one that maximizes a positive effect, such as "happiness", "welfare", or the ability to live according to personal preferences. Jeremy Bentham and John Stuart Mill are influential proponents of this school of thought. In "A Fragment on Government" Bentham says 'it is the greatest happiness of the greatest number that is the measure of right and wrong' and describes this as a fundamental axiom. In "An Introduction to the Principles of Morals and Legislation" he talks of 'the principle of utility' but later prefers "the greatest happiness principle".
Utilitarianism is the paradigmatic example of a consequentialist moral theory. This form of utilitarianism holds that what matters is the aggregate positive effect of everyone and not only of any one person. John Stuart Mill, in his exposition of utilitarianism, proposed a hierarchy of pleasures, meaning that the pursuit of certain kinds of pleasure is more highly valued than the pursuit of other pleasures. Other noteworthy proponents of utilitarianism are neuroscientist Sam Harris, author of The Moral Landscape, and moral philosopher Peter Singer, author of, amongst other works, Practical Ethics.
There are two types of utilitarianism, act utilitarianism and rule utilitarianism. In act utilitarianism the principle of utility is applied directly to each alternative act in a situation of choice. The right act is then defined as the one which brings about the best results (or the least amount of bad results). In rule utilitarianism the principle of utility is used to determine the validity of rules of conduct (moral principles). A rule like promise-keeping is established by looking at the consequences of a world in which people broke promises at will and a world in which promises were binding. Right and wrong are then defined as following or breaking those rules.
Deontology.
Deontological ethics or deontology (from Greek , "deon", "obligation, duty"; and , "-logia") is an approach to ethics that determines goodness or rightness from examining acts, or the rules and duties that the person doing the act strove to fulfill. This is in contrast to consequentialism, in which rightness is based on the consequences of an act, and not the act by itself. In deontology, an act may be considered right even if the act produces a bad consequence, if it follows the "rule" that "one should do unto others as they would have done unto them", and even if the person who does the act lacks virtue and had a bad intention in doing the act. According to deontology, we have a "duty" to act in a way that does those things that are inherently good as acts ("truth-telling" for example), or follow an objectively obligatory rule (as in rule utilitarianism). For deontologists, the ends or consequences of our actions are not important in and of themselves, and our intentions are not important in and of themselves.
Immanuel Kant's theory of ethics is considered deontological for several different reasons. First, Kant argues that to act in the morally right way, people must act from duty ("deon"). Second, Kant argued that it was not the consequences of actions that make them right or wrong but the motives (maxime) of the person who carries out the action.
Kant's argument that to act in the morally right way, one must act from duty, begins with an argument that the highest good must be both good in itself, and good without qualification. Something is 'good in itself' when it is intrinsically good, and 'good without qualification' when the addition of that thing never makes a situation ethically worse. Kant then argues that those things that are usually thought to be good, such as intelligence, perseverance and pleasure, fail to be either intrinsically good or good without qualification. Pleasure, for example, appears to not be good without qualification, because when people take pleasure in watching someone suffer, they make the situation ethically worse. He concludes that there is only one thing that is truly good: Nothing in the worldâindeed nothing even beyond the worldâcan possibly be conceived which could be called good without qualification except a "good will". 
Pragmatic ethics.
Associated with the pragmatists, Charles Sanders Peirce, William James, and especially John Dewey, pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, provided social reform is provided for).
Role ethics.
Role ethics is an ethical theory based on family roles. Unlike virtue ethics, role ethics is not individualistic. Morality is derived from a person's relationship with their community. Confucian ethics is an example of role ethics. Confucian roles center around the concept of filial piety or "xiao", a respect for family members. According to Roger Ames and Henry Rosemont, "Confucian normativity is defined by living one's family roles to maximum effect." Morality is determined through a person's fulfillment of a role, such as that of a parent or a child. Confucian roles are not rational, and originate through the "xin", or human emotions.
Anarchist ethics.
Anarchist ethics is an ethical theory based on the studies of anarchist thinkers. The biggest contributor to the anarchist ethics is the Russian zoologist, geographer, economist and political activist Peter Kropotkin. The anarchist ethics is a big and vague field which can depend upon different historical situations and different anarchist thinkers, but as Peter Kropotkin explains, "any âbourgeoisâ or âproletarianâ ethics rests, after all, on the common basis, on the common ethnological foundation, which at times exerts a very strong inï¬uence on the principles of the class or group morality." Still, most of the anarchist ethics schools are based on three fundamental ideas, which are: "solidarity, equality and justice". Kropotkin argues that Ethics is evolutionary and is inherited as a sort of a social instinct through History, and by so, he rejects any religious and transcendental explanation of ethics. Kropotkin suggests that the principle of equality which lies at the basis of anarchism is the same as the Golden rule: This principle of treating others as one wishes to be treated oneself, what is it but the very same principle as equality, the fundamental principle of anarchism? And how can any one manage to believe himself an anarchist unless he practices it? We do not wish to be ruled. And by this very fact, do we not declare that we ourselves wish to rule nobody? We do not wish to be deceived, we wish always to be told nothing but the truth. And by this very fact, do we not de- clare that we ourselves do not wish to deceive anybody, that we promise to always tell the truth, nothing but the truth, the whole truth? We do not wish to have the fruits of our labor stolen from us. And by that very fact, do we not declare that we respect the fruits of others' labor? By what right indeed can we demand that we should be treated in one fashion, reserving it to ourselves to treat others in a fashion entirely different? Our sense of equality revolts at such an idea.
Postmodern ethics.
The 20th century saw a remarkable expansion and evolution of critical theory, following on earlier Marxist Theory efforts to locate individuals within larger structural frameworks of ideology and action.
Antihumanists such as Louis Althusser and Michel Foucault and structuralists such as Roland Barthes challenged the possibilities of individual agency and the coherence of the notion of the 'individual' itself. As critical theory developed in the later 20th century, post-structuralism sought to problematize human relationships to knowledge and 'objective' reality. Jacques Derrida argued that access to meaning and the 'real' was always deferred, and sought to demonstrate via recourse to the linguistic realm that "there is nothing outside context" ("il n'y a pas de hors-texte" is often mistranslated as "there is nothing outside the text"); at the same time, Jean Baudrillard theorised that signs and symbols or simulacra mask reality (and eventually the absence of reality itself), particularly in the consumer world.
Post-structuralism and postmodernism argue that ethics must study the complex and relational conditions of actions. A simple alignment of ideas of right and particular acts is not possible. There will always be an ethical remainder that cannot be taken into account or often even recognized. Such theorists find narrative (or, following Nietzsche and Foucault, genealogy) to be a helpful tool for understanding ethics because narrative is always about particular lived experiences in all their complexity rather than the assignment of an idea or norm to separate and individuated actions.
Zygmunt Bauman says Postmodernity is best described as Modernity without illusion, the illusion being the belief that humanity can be repaired by some ethic principle. Postmodernity can be seen in this light as accepting the messy nature of humanity as unchangeable.
David Couzens Hoy states that Emmanuel Levinas's writings on the face of the Other and Derrida's meditations on the relevance of death to ethics are signs of the "ethical turn" in Continental philosophy that occurred in the 1980s and 1990s. Hoy describes post-critique ethics as the "obligations that present themselves as necessarily to be fulfilled but are neither forced on one or are enforceable" (2004, p.Â 103).
Hoy's post-critique model uses the term "ethical resistance". Examples of this would be an individual's resistance to consumerism in a retreat to a simpler but perhaps harder lifestyle, or an individual's resistance to a terminal illness. Hoy describes Levinas's account as "not the attempt to use power against itself, or to mobilize sectors of the population to exert their political power; the ethical resistance is instead the resistance of the powerless"(2004, p.Â 8).
Hoy concludes that
In present-day terms the powerless may include the unborn, the terminally sick, the aged, the insane, and non-human animals. It is in these areas that ethical action in Hoy's sense will apply. Until legislation or the state apparatus enforces a moral order that addresses the causes of resistance these issues will remain in the ethical realm. For example, should animal experimentation become illegal in a society, it will no longer be an ethical issue on Hoy's definition. Likewise one hundred and fifty years ago, not having a black slave in America would have been an ethical choice. This later issue has been absorbed into the fabric of an enforceable social order and is therefore no longer an ethical issue in Hoy's sense.
Applied ethics.
Applied ethics is a discipline of philosophy that attempts to apply ethical theory to real-life situations. The discipline has many specialized fields, such as engineering ethics, bioethics, geoethics, public service ethics and business ethics.
Specific questions.
Applied ethics is used in some aspects of determining public policy, as well as by individuals facing difficult decisions. The sort of questions addressed by applied ethics include: "Is getting an abortion immoral?" "Is euthanasia immoral?" "Is affirmative action right or wrong?" "What are human rights, and how do we determine them?" "Do animals have rights as well?" and "Do individuals have the right of self determination?"
A more specific question could be: "If someone else can make better out of his/her life than I can, is it then moral to sacrifice myself for them if needed?" Without these questions there is no clear fulcrum on which to balance law, politics, and the practice of arbitration â in fact, no common assumptions of all participantsâso the ability to formulate the questions are prior to rights balancing. But not all questions studied in applied ethics concern public policy. For example, making ethical judgments regarding questions such as, "Is lying always wrong?" and, "If not, when is it permissible?" is prior to any etiquette.
People in-general are more comfortable with dichotomies (two opposites). However, in ethics the issues are most often multifaceted and the best proposed actions address many different areas concurrently. In ethical decisions the answer is almost never a "yes or no", "right or wrong" statement. Many buttons are pushed so that the overall condition is improved and not to the benefit of any particular faction.
Particular fields of application.
Bioethics.
Bioethics is the study of controversial ethics brought about by advances in biology and medicine. Bioethicists are concerned with the ethical questions that arise in the relationships among life sciences, biotechnology, medicine, politics, law, and philosophy. It also includes the study of the more commonplace questions of values ("the ethics of the ordinary") that arise in primary care and other branches of medicine.
Bioethics also needs to address emerging biotechnologies that affect basic biology and future humans. These developments include cloning, gene therapy, human genetic engineering, astroethics and life in space, and manipulation of basic biology through altered DNA, RNA and proteins,e.g.- "three parent baby,where baby is born from genetically modified embryos, would have DNA from a mother, a father and from a female donor. Correspondingly, new bioethics also need to address life at its core. For example, biotic ethics value organic gene/protein life itself and seek to propagate it. With such life-centered principles, ethics may secure a cosmological future for life.
Business ethics.
Business ethics (also corporate ethics) is a form of applied ethics or professional ethics that examines ethical principles and moral or ethical problems that arise in a business environment, including fields like Medical ethics. It applies to all aspects of business conduct and is relevant to the conduct of individuals and entire organizations.
Business ethics has both normative and descriptive dimensions. As a corporate practice and a career specialization, the field is primarily normative. Academics attempting to understand business behavior employ descriptive methods. The range and quantity of business ethical issues reflects the interaction of profit-maximizing behavior with non-economic concerns.
Interest in business ethics accelerated dramatically during the 1980s and 1990s, both within major corporations and within academia. For example, today most major corporations promote their commitment to non-economic values under headings such as ethics codes and social responsibility charters.
Adam Smith said, "People of the same trade seldom meet together, even for merriment and diversion, but the conversation ends in a conspiracy against the public, or in some contrivance to raise prices." Governments use laws and regulations to point business behavior in what they perceive to be beneficial directions. Ethics implicitly regulates areas and details of behavior that lie beyond governmental control. The emergence of large corporations with limited relationships and sensitivity to the communities in which they operate accelerated the development of formal ethics regimes.
Relational ethics.
Relational ethics are related to an ethics of care. They are used in qualitative research, especially ethnography and autoethnography. Researchers who employ relational ethics value and respect the connection between themselves and the people they study, and "between researchers and the communities in which they live and work" (Ellis, 2007, p.Â 4). Relational ethics also help researchers understand difficult issues such as conducting research on intimate others that have died and developing friendships with their participants. Relational ethics in close personal relationships form a central concept of contextual therapy.
Machine ethics.
In "Moral Machines: Teaching Robots Right from Wrong", Wendell Wallach and Colin Allen conclude that issues in machine ethics will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation. The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of learning algorithms, and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.
Military ethics.
Military ethics are concerned with questions regarding the application of force and the ethos of the soldier and are often understood as applied professional ethics. Just war theory is generally seen to set the background terms of military ethics. However individual countries and traditions have different fields of attention.
Military ethics involves multiple subareas, including the following among others:
Political ethics.
Political ethics (also known as political morality or public ethics) is the practice of making moral judgements about political action and political agents.
Public sector ethics.
Public sector ethics is a set of principles that guide public officials in their service to their constituents, including their decision-making on behalf of their constituents. Fundamental to the concept of public sector ethics is the notion that decisions and actions are based on what best serves the public's interests, as opposed to the official's personal interests (including financial interests) or self-serving political interests.
Publication ethics.
Publication ethics is the set of principles that guide the writing and publishing process for all professional publications. In order to follow the set of principles, authors should verify that the publication does not contain plagiarism or publication bias. As a way to avoid misconduct in research these principles can also be applied to experiments which are referenced or analyzed in publications by ensuring the data is recorded, honestly and accurately.
Plagiarism is the failure to give credit to another authorâs work or ideas, when it is used in the publication. It is the obligation of the editor of the journal to ensure the article does not contain any plagiarism before it is published. If a publication which has already been published is proven to contain plagiarism, then the editor of the journal can proceed to have the article retracted.
Publication bias occurs when the publication is one-sided or "prejudiced against results". In best practice, an author should try to include information from all parties involved, or affected by the topic. If an author is prejudiced against certain results, than it can "lead to erroneous conclusions being drawn.â
Misconduct in research can occur when information from an experiment is falsely recorded or altered. Falsely recorded information occurs when the researcher "fakes" information or data, which was not used when conducting the actual experiment. By faking the data, the researcher can alter the results from the experiment to better fit the hypothesis they originally predicted. When conducting medical research, it is important to honor the healthcare rights of a patient by protecting their anonymity in the publication.
Moral psychology.
Moral psychology is a field of study that began as an issue in philosophy and that is now properly considered part of the discipline of psychology. Some use the term "moral psychology" relatively narrowly to refer to the study of moral development. However, others tend to use the term more broadly to include any topics at the intersection of ethics and psychology (and philosophy of mind). Such topics are ones that involve the mind and are relevant to moral issues. Some of the main topics of the field are moral responsibility, moral development, moral character (especially as related to virtue ethics), altruism, psychological egoism, moral luck, and moral disagreement.
Evolutionary ethics.
Evolutionary ethics concerns approaches to ethics (morality) based on the role of evolution in shaping human psychology and behavior. Such approaches may be based in scientific fields such as evolutionary psychology or sociobiology, with a focus on understanding and explaining observed ethical preferences and choices.
Descriptive ethics.
Descriptive ethics is on the less philosophical end of the spectrum, since it seeks to gather particular information about how people live and draw general conclusions based on observed patterns. Abstract and theoretical questions that are more clearly philosophicalâsuch as, "Is ethical knowledge possible?"âare not central to descriptive ethics. Descriptive ethics offers a value-free approach to ethics, which defines it as a social science rather than a humanity. Its examination of ethics doesn't start with a preconceived theory, but rather investigates observations of actual choices made by moral agents in practice. Some philosophers rely on descriptive ethics and choices made and unchallenged by a society or culture to derive categories, which typically vary by context. This can lead to situational ethics and situated ethics. These philosophers often view aesthetics, etiquette, and arbitration as more fundamental, percolating "bottom up" to imply the existence of, rather than explicitly prescribe, theories of value or of conduct. The study of descriptive ethics may include examinations of the following:

</doc>
<doc id="9259" url="https://en.wikipedia.org/wiki?curid=9259" title="Equivalence relation">
Equivalence relation

In mathematics, an equivalence relation is a binary relation that is at the same time a reflexive relation, a symmetric relation and a transitive relation. As a consequence of these properties an equivalence relation provides a partition of a set into equivalence classes.
Notation.
Although various notations are used throughout the literature to denote that two elements "a" and "b" of a set are equivalent with respect to an equivalence relation "R", the most common are ""a" ~ "b" and "a" â¡ "b", which are used when "R" is the obvious relation being referenced, and variations of "a" ~ "b", "a" â¡ "b", or "aRb"" otherwise.
Definition.
A given binary relation ~ on a set "X" is said to be an equivalence relation if and only if it is reflexive, symmetric and transitive. That is, for all "a", "b" and "c" in "X":
"X" together with the relation ~ is called a setoid. The equivalence class of formula_1 under ~, denoted formula_2, is defined as formula_3.
Examples.
Simple example.
Let the set formula_4 have the equivalence relation formula_5. The following sets are equivalence classes of this relation:
formula_6.
The set of all equivalence classes for this relation is formula_7.
Equivalence relations.
The following are all equivalence relations:
Well-definedness under an equivalence relation.
If ~ is an equivalence relation on "X", and "P"("x") is a property of elements of "X", such that whenever "x" ~ "y", "P"("x") is true if "P"("y") is true, then the property "P" is said to be well-defined or a "class invariant" under the relation ~.
A frequent particular case occurs when "f" is a function from "X" to another set "Y"; if "x" ~ "x" implies "f"("x") = "f"("x") then "f" is said to be a "morphism" for ~, a "class invariant under" ~, or simply "invariant under" ~. This occurs, e.g. in the character theory of finite groups. The latter case with the function "f" can be expressed by a commutative triangle. See also invariant. Some authors use "compatible with ~" or just "respects ~" instead of "invariant under ~".
More generally, a function may map equivalent arguments (under an equivalence relation ~) to equivalent values (under an equivalence relation ~). Such a function is known as a morphism from ~ to ~.
Equivalence class, quotient set, partition.
Let formula_8. Some definitions:
Equivalence class.
A subset "Y" of "X" such that "a" ~ "b" holds for all "a" and "b" in "Y", and never for "a" in "Y" and "b" outside "Y", is called an equivalence class of "X" by ~. Let formula_9 denote the equivalence class to which "a" belongs. All elements of "X" equivalent to each other are also elements of the same equivalence class.
Quotient set.
The set of all possible equivalence classes of "X" by ~, denoted formula_10, is the quotient set of "X" by ~. If "X" is a topological space, there is a natural way of transforming "X"/~ into a topological space; see quotient space for the details.
Projection.
The projection of ~ is the function formula_11 defined by formula_12 which maps elements of "X" into their respective equivalence classes by ~.
Equivalence kernel.
The equivalence kernel of a function "f" is the equivalence relation ~ defined by formula_13. The equivalence kernel of an injection is the identity relation.
Partition.
A partition of "X" is a set "P" of nonempty subsets of "X", such that every element of "X" is an element of a single element of "P". Each element of "P" is a "cell" of the partition. Moreover, the elements of "P" are pairwise disjoint and their union is "X".
Counting possible partitions.
Let "X" be a finite set with "n" elements. Since every equivalence relation over "X" corresponds to a partition of "X", and vice versa, the number of possible equivalence relations on "X" equals the number of distinct partitions of "X", which is the "nth" Bell number "B:
where the above is one of the ways to write the nth Bell number.
Fundamental theorem of equivalence relations.
A key result links equivalence relations and partitions:
In both cases, the cells of the partition of "X" are the equivalence classes of "X" by ~. Since each element of "X" belongs to a unique cell of any partition of "X", and since each cell of the partition is identical to an equivalence class of "X" by ~, each element of "X" belongs to a unique equivalence class of "X" by ~. Thus there is a natural bijection between the set of all possible equivalence relations on "X" and the set of all partitions of "X".
Comparing equivalence relations.
If ~ and â are two equivalence relations on the same set "S", and "a"~"b" implies "a"â"b" for all "a","b" â "S", then â is said to be a coarser relation than ~, and ~ is a finer relation than â. Equivalently,
The equality equivalence relation is the finest equivalence relation on any set, while the trivial relation that makes all pairs of elements related is the coarsest.
The relation "~ is finer than â" on the collection of all equivalence relations on a fixed set is itself a partial order relation, which makes the collection a geometric lattice.
Algebraic structure.
Much of mathematics is grounded in the study of equivalences, and order relations. Lattice theory captures the mathematical structure of order relations. Even though equivalence relations are as ubiquitous in mathematics as order relations, the algebraic structure of equivalences is not as well known as that of orders. The former structure draws primarily on group theory and, to a lesser extent, on the theory of lattices, categories, and groupoids.
Group theory.
Just as order relations are grounded in ordered sets, sets closed under pairwise supremum and infimum, equivalence relations are grounded in partitioned sets, which are sets closed under bijections and preserve partition structure. Since all such bijections map an equivalence class onto itself, such bijections are also known as permutations. Hence permutation groups (also known as transformation groups) and the related notion of orbit shed light on the mathematical structure of equivalence relations.
Let '~' denote an equivalence relation over some nonempty set "A", called the universe or underlying set. Let "G" denote the set of bijective functions over "A" that preserve the partition structure of "A": â"x" â "A" â"g" â "G" ("g"("x") â 'x'). Then the following three connected theorems hold:
In sum, given an equivalence relation ~ over "A", there exists a transformation group "G" over "A" whose orbits are the equivalence classes of "A" under ~.
This transformation group characterisation of equivalence relations differs fundamentally from the way lattices characterize order relations. The arguments of the lattice theory operations meet and join are elements of some universe "A". Meanwhile, the arguments of the transformation group operations composition and inverse are elements of a set of bijections, "A" â "A".
Moving to groups in general, let "H" be a subgroup of some group "G". Let ~ be an equivalence relation on "G", such that "a" ~ "b" â ("ab" â "H"). The equivalence classes of ~âalso called the orbits of the action of "H" on "G"âare the right cosets of "H" in "G". Interchanging "a" and "b" yields the left cosets.
â¡"Proof". Let function composition interpret group multiplication, and function inverse interpret group inverse. Then "G" is a group under composition, meaning that â"x" â "A" â"g" â "G" ('g"("x" = 'x'), because "G" satisfies the following four conditions:
Let "f" and "g" be any two elements of "G". By virtue of the definition of "G", 'g"("f"("x") = 'f"("x" and 'f"("x" = 'x', so that 'g"("f"("x") = 'x'. Hence "G" is also a transformation group (and an automorphism group) because function composition preserves the partitioning of "A". formula_15
Related thinking can be found in Rosen (2008: chpt. 10).
Categories and groupoids.
Let "G" be a set and let "~" denote an equivalence relation over "G". Then we can form a groupoid representing this equivalence relation as follows. The objects are the elements of "G", and for any two elements "x" and "y" of "G", there exists a unique morphism from "x" to "y" if and only if "x"~"y".
The advantages of regarding an equivalence relation as a special case of a groupoid include:
Lattices.
The possible equivalence relations on any set "X", when ordered by set inclusion, form a complete lattice, called Con "X" by convention. The canonical map ker: "X"^"X" â Con "X", relates the monoid "X"^"X" of all functions on "X" and Con "X". ker is surjective but not injective. Less formally, the equivalence relation ker on "X", takes each function "f": "X"â"X" to its kernel ker "f". Likewise, ker(ker) is an equivalence relation on "X"^"X".
Equivalence relations and mathematical logic.
Equivalence relations are a ready source of examples or counterexamples. For example, an equivalence relation with exactly two infinite equivalence classes is an easy example of a theory which is Ï-categorical, but not categorical for any larger cardinal number.
An implication of model theory is that the properties defining a relation can be proved independent of each other (and hence necessary parts of the definition) if and only if, for each property, examples can be found of relations not satisfying the given property while satisfying all the other properties. Hence the three defining properties of equivalence relations can be proved mutually independent by the following three examples:
Properties definable in first-order logic that an equivalence relation may or may not possess include:
Euclidean relations.
Euclid's "The Elements" includes the following "Common Notion 1":
Nowadays, the property described by Common Notion 1 is called Euclidean (replacing "equal" by "are in relation with"). By "relation" is meant a binary relation, in which "aRb" is generally distinct from "bRa". A Euclidean relation thus comes in two forms:
The following theorem connects Euclidean relations and equivalence relations:
with an analogous proof for a right-Euclidean relation. Hence an equivalence relation is a relation that is "Euclidean" and "reflexive". "The Elements" mentions neither symmetry nor reflexivity, and Euclid probably would have deemed the reflexivity of equality too obvious to warrant explicit mention.

</doc>
<doc id="9260" url="https://en.wikipedia.org/wiki?curid=9260" title="Equivalence class">
Equivalence class

In mathematics, when a set has an equivalence relation defined on its elements, there is a natural grouping of elements that are related to one another, forming what are called equivalence classes. Notationally, given a set and an equivalence relation on , the "equivalence class" of an element in is the subset of all elements in which are equivalent to . It follows from the definition of the equivalence relations that the equivalence classes form a partition of. The set of equivalence classes is sometimes called the quotient set or the quotient space of by and is denoted by .
When has some structure, and the equivalence relation is defined with some connection to this structure, the quotient set often inherits some related structure. Examples include quotient spaces in linear algebra, quotient spaces in topology, quotient groups, homogeneous spaces, quotient rings, quotient monoids, and quotient categories.
Notation and formal definition.
An equivalence relation is a binary relation satisfying three properties:
The equivalence class of an element is denoted and is defined as the set
of elements that are related to byÂ . An alternative notation can be used to denote the equivalence class of the element , specifically with respect to the equivalence relation . This is said to be the -equivalence class of .
The set of all equivalence classes in with respect to an equivalence relation is denoted as and called modulo (or the quotient set of by ). The surjective map formula_2 from onto , which maps each element to its equivalence class, is called the canonical surjection or the canonical projection map.
When an element is chosen (often implicitly) in each equivalence class, this defines an injective map called a "section". If this section is denoted by , one has for every equivalence class . The element is called a representative of . Any element of a class may be chosen as a representative of the class, by choosing the section appropriately.
Sometimes, there is a section that is more "natural" than the other ones. In this case, the representatives are called "canonical representatives". For example, in modular arithmetic, consider the equivalence relation on the integers defined by if is a multiple of a given integer , called the "modulus". Each class contains a unique non-negative integer smaller than , and these integers are the canonical representatives. The class and its representative are more or less identified, as is witnessed by the fact that the notation may denote either the class or its canonical representative (which is the remainder of the division of by ).
Properties.
Every element of is a member of the equivalence class . Every two equivalence classes and are either equal or disjoint. Therefore, the set of all equivalence classes of forms a partition of : every element of belongs to one and only one equivalence class. Conversely every partition of comes from an equivalence relation in this way, according to which if and only if and belong to the same set of the partition.
It follows from the properties of an equivalence relation that
In other words, if is an equivalence relation on a set , and and are two elements of , then these statements are equivalent:
Graphical representation.
Any binary relation can be represented by a directed graph and symmetric ones, such as equivalence relations, by undirected graphs. If is an equivalence relation on a set , let the vertices of the graph be the elements of and join vertices and if and only if . The equivalence classes are represented in this graph by the maximal cliques forming the connected components of the graph.
Invariants.
If is an equivalence relation on , and is a property of elements of such that whenever , is true if is true, then the property is said to be an invariant of , or well-defined under the relation .
A frequent particular case occurs when is a function from to another set ; if whenever , then is said to be a "morphism" for , a "class invariant under" , or simply "invariant under" . This occurs, e.g. in the character theory of finite groups. Some authors use "compatible with " or just "respects " instead of "invariant under ".
Any function itself defines an equivalence relation on according to which if and only if . The equivalence class of is the set of all elements in which get mapped to , i.e. the class is the inverse image of . This equivalence relation is known as the kernel of .
More generally, a function may map equivalent arguments (under an equivalence relation on ) to equivalent values (under an equivalence relation on ). Such a function is known as a morphism from to .
Quotient space in topology.
In topology, a quotient space is a topological space formed on the set of equivalence classes of an equivalence relation on a topological space using the original space's topology to create the topology on the set of equivalence classes.
In abstract algebra, congruence relations on the underlying set of an algebra allow the algebra to induce an algebra on the equivalence classes of the relation, called a quotient algebra. In linear algebra, a quotient space is a vector space formed by taking a quotient group where the quotient homomorphism is a linear map. By extension, in abstract algebra, the term quotient space may be used for quotient modules, quotient rings, quotient groups, or any quotient algebra. However, the use of the term for the more general cases can as often be by analogy with the orbits of a group action.
The orbits of a group action on a set may be called the quotient space of the action on the set, particularly when the orbits of the group action are the right cosets of a subgroup of a group, which arise from the action of the subgroup on the group by left translations, or respectively the left cosets as orbits under right translation.
A normal subgroup of a topological group, acting on the group by translation action, is a quotient space in the senses of topology, abstract algebra, and group actions simultaneously.
Although the term can be used for any equivalence relation's set of equivalence classes, possibly with further structure, the intent of using the term is generally to compare that type of equivalence relation on a set "X" either to an equivalence relation that induces some structure on the set of equivalence classes from a structure of the same kind on "X", or to the orbits of a group action. Both the sense of a structure preserved by an equivalence relation and the study of invariants under group actions lead to the definition of invariants of equivalence relations given above.
Further reading.
This material is basic and can be found in any text dealing with the fundamentals of proof technique, such as any of the following:

</doc>
<doc id="9262" url="https://en.wikipedia.org/wiki?curid=9262" title="Entertainment">
Entertainment

Entertainment is a form of activity that holds the attention and interest of an audience, or gives pleasure and delight. It can be an idea or a task, but is more likely to be one of the activities or events that have developed over thousands of years specifically for the purpose of keeping an audience's attention. Although people's attention is held by different things, because individuals have different preferences in entertainment, most forms are recognisable and familiar. Storytelling, music, drama, dance, and different kinds of performance exist in all cultures, were supported in royal courts, developed into sophisticated forms and over time became available to all citizens. The process has been accelerated in modern times by an entertainment industry which records and sells entertainment products. Entertainment evolves and can be adapted to suit any scale, ranging from an individual who chooses a private entertainment from a now enormous array of pre-recorded products; to a banquet adapted for two; to any size or type of party, with appropriate music and dance; to performances intended for thousands; and even for a global audience.
The experience of being entertained has come to be strongly associated with amusement, so that one common understanding of the idea is fun and laughter, although many entertainments have a serious purpose. This may be the case in the various forms of ceremony, celebration, religious festival, or satire for example. Hence, there is the possibility that what appears as entertainment may also be a means of achieving insight or intellectual growth.
An important aspect of entertainment is the audience, which turns a private recreation or leisure activity into entertainment. The audience may have a passive role, as in the case of persons watching a play, opera, television show, or film; or the audience role may be active, as in the case of games, where the participant/audience roles may be routinely reversed. Entertainment can be public or private, involving formal, scripted performance, as in the case of theatre or concerts; or unscripted and spontaneous, as in the case of children's games. Most forms of entertainment have persisted over many centuries, evolving due to changes in culture, technology, and fashion. Films and video games, for example, although they use newer media, continue to tell stories, present drama, and play music. Festivals devoted to music, film, or dance allow audiences to be entertained over a number of consecutive days.
Some activities that once were considered entertaining, particularly public punishments, have been removed from the public arena. Others, such as fencing or archery, once necessary skills for some, have become serious sports and even professions for the participants, at the same time developing into entertainment with wider appeal for bigger audiences. In the same way, other necessary skills, such as cooking, have developed into performances among professionals, staged as global competitions and then broadcast for entertainment. What is entertainment for one group or individual may be regarded as work by another.
The familiar forms of entertainment have the capacity to cross over different media and have demonstrated a seemingly unlimited potential for creative remix. This has ensured the continuity and longevity of many themes, images, and structures.
Psychology and philosophy.
Entertainment can be distinguished from other activities such as education and marketing even though they have learned how to use the appeal of entertainment to achieve their different goals. The importance and impact of entertainment is recognised by scholars and its increasing sophistication has influenced practices in other fields such as museology.
Psychologists say the function of media entertainment is "the attainment of gratification". No other results or measurable benefit are usually expected from it (except perhaps the final score in a sporting entertainment). This is in contrast to education (which is designed with the purpose of developing understanding or helping people to learn) and marketing (which aims to encourage people to purchase commercial products). However, the distinctions become blurred when education seeks to be more "entertaining" and entertainment or marketing seek to be more "educational". Such mixtures are often known by the neologisms "edutainment" or "infotainment". The psychology of entertainment as well as of learning has been applied to all these fields. Some education-entertainment is a serious attempt to combine the best features of the two. Some people are entertained by others' pain or the idea of their unhappiness (schadenfreude).
An entertainment might go beyond gratification and produce some insight in its audience when it skilfully considers universal philosophical questions such as: "What is the meaning of life?"; "What does it mean to be human?"; "What is the right thing to do?"; or "How do I know what I know?". Questions such as these drive many narratives and dramas, whether they are presented in the form of a story, film, play, poem, book, dance, comic, or game. Dramatic examples include Shakespeare's influential play "Hamlet", whose hero articulates these concerns in poetry; and films, such as "The Matrix", which explores the nature of knowledge and was released world-wide. Novels give great scope for investigating these themes while they entertain their readers. An example of a creative work that considers philosophical questions so entertainingly that it has been presented in a very wide range of forms is "The Hitchhiker's Guide to the Galaxy". Originally a radio comedy, this story became so popular that it has also appeared as a novel, film, television series, stage show, comic, audiobook, LP record, adventure game and online game, its ideas became popular references (see Phrases from The Hitchhiker's Guide to the Galaxy) and has been translated into many languages. Its themes encompass the meaning of life, as well as "the ethics of entertainment, artificial intelligence, multiple worlds, God, and philosophical method".
History.
The "ancient craft of communicating events and experiences, using words, images, sounds and gestures" by telling a story is not only the means by which people passed on their cultural values and traditions and history from one generation to another, it has been an important part of most forms of entertainment ever since the earliest times. Stories are still told in the early forms, for example, around a fire while camping, or when listening to the stories of another culture as a tourist. "The earliest storytelling sequences we possess, now of course, committed to writing, were undoubtedly originally a speaking from mouth to ear and their force as entertainment derived from the very same elements we today enjoy in films and novels." Storytelling is an activity that has evolved and developed "toward variety". Many entertainments, including storytelling but especially music and drama, remain familiar but have developed into a wide variety of form to suit a very wide range of personal preferences and cultural expression. Many types are blended or supported by other forms. For example, drama, stories and banqueting (or dining) are commonly enhanced by music; sport and games are incorporated into other activities to increase appeal. Some may have evolved from serious or necessary activities (such as running and jumping) into competition and then become entertainment. It is said, for example, that pole vaulting "may have originated in the Netherlands, where people used long poles to vault over wide canals rather than wear out their clogs walking miles to the nearest bridge. Others maintain that pole vaulting was used in warfare to vault over fortress walls during battle." The equipment for such sports has become increasingly sophisticated. Vaulting poles, for example, were originally made from woods such as ash, hickory or hazel; in the 19th century bamboo was used and in the 21st century poles can be made of carbon fibre. Other activities, such as walking on stilts, are still seen in circus performances in the 21st century. Gladiatorial combats, also known as "gladiatorial games", popular during Roman times, provide a good example of an activity that is a combination of sport, punishment, and entertainment.
Changes to what is regarded as entertainment can occur in response to cultural or historical shifts. Hunting wild animals, for example, was introduced into the Roman Empire from Carthage and became a popular public entertainment and spectacle, supporting an international trade in wild animals.
Entertainment also evolved into different forms and expressions as a result of social upheavals such as wars and revolutions. During the Chinese Cultural Revolution, for example, Revolutionary opera was sanctioned by the Communist party and World War I, the Great Depression and the Russian revolution all had an impact on entertainment.
Relatively minor changes to the form and venue of an entertainment continue to come and go as they are affected by the period, fashion, culture, technology, and economics. For example, a story told in dramatic form can be presented in an open-air theatre, a music hall, a movie theatre, a multiplex, or as technological possibilities advanced, via a personal electronic device such as a tablet computer. Entertainment is provided for mass audiences in purpose-built structures such as a theatre, auditorium, or stadium. One of the most famous venues in the Western world, the Colosseum, "dedicated AD 80 with a hundred days of games, held fifty thousand spectators," and in it audiences "enjoyed "blood sport with the trappings of stage shows". Spectacles, competitions, races, and sports were once presented in this purpose-built arena as public entertainment. New stadia continue to be built to suit the ever more sophisticated requirements of global audiences.
Court entertainment.
Imperial and royal courts have provided training grounds and support for professional entertainers, with different cultures using palaces, castles and forts in different ways. In the Maya city states, for example, "spectacles often took place in large plazas in front of palaces; the crowds gathered either there or in designated places from which they could watch at a distance." Court entertainments also crossed cultures. For example, the durbar was introduced to India by the Mughals, and passed onto the British Empire, which then followed Indian tradition: "institutions, titles, customs, ceremonies by which a Maharaja or Nawab were installedÂ ... the exchange of official presentsÂ ... the order of precedence", for example, were "all inherited fromÂ ... the Emperors of Delhi". In Korea, the "court entertainment dance" was "originally performed in the palace for entertainment at court banquets."
Court entertainment often moved from being associated with the court to more general use among commoners. This was the case with "masked dance-dramas" in Korea, which "originated in conjunction with village shaman rituals and eventually became largely an entertainment form for commoners". Nautch dancers in the Mughal Empire performed in Indian courts and palaces. Another evolution, similar to that from courtly entertainment to common practice, was the transition from religious ritual to secular entertainment, such as happened during the Goryeo dynasty with the Narye festival. Originally "solely religious or ritualistic, a secular component was added at the conclusion". Former courtly entertainments, such as jousting, often also survived in children's games.
In some courts, such as those during the Byzantine Empire, the genders were segregated among the upper classes, so that "at least before the period of the Komnenoi" (1081â1185) men were separated from women at ceremonies where there was entertainment such as receptions and banquets.
Court ceremonies, palace banquets and the spectacles associated with them, have been used not only to entertain but also to demonstrate wealth and power. Such events reinforce the relationship between ruler and ruled; between those with power and those without, serving to "dramatise the differences between ordinary families and that of the ruler". This is the case as much as for traditional courts as it is for contemporary ceremonials, such as the Hong Kong handover ceremony in 1997, at which an array of entertainments (including a banquet, a parade, fireworks, a festival performance and an art spectacle) were put to the service of highlighting a change in political power. Court entertainments were typically performed for royalty and courtiers as well as "for the pleasure of local and visiting dignitaries". Royal courts, such as the Korean one, also supported traditional dances. In Sudan, musical instruments such as the so-called "slit" or "talking" drums, once "part of the court orchestra of a powerful chief", had multiple purposes: they were used to make music; "speak" at ceremonies; mark community events; send long-distance messages; and call men to hunt or war.
Courtly entertainments also demonstrate the complex relationship between entertainer and spectator: individuals may be either an entertainer or part of the audience, or they may swap roles even during the course of one entertainment. In the court at the Palace of Versailles, "thousands of courtiers, including men and women who inhabited its apartments, acted as both performers and spectators in daily rituals that reinforced the status hierarchy".
Like court entertainment, royal occasions such as coronations and weddings provided opportunities to entertain both the aristocracy and the people. For example, the splendid 1595 Accession Day celebrations of Queen Elizabeth I offered tournaments and jousting and other events performed "not only before the assembled court, in all their finery, but also before thousands of Londoners eager for a good day's entertainment. Entry for the day's events at the Tiltyard in Whitehall was set at 12d".
Public punishment.
Although most forms of entertainment have evolved and continued over time, some once-popular forms are no longer as acceptable. For example, during earlier centuries in Europe, watching or participating in the punishment of criminals or social outcasts was an accepted and popular form of entertainment. Many forms of public humiliation also offered local entertainment in the past. Even capital punishment such as hanging and beheading, offered to the public as a warning, were also regarded partly as entertainment. Capital punishments that lasted longer, such as stoning and drawing and quartering, afforded a greater public spectacle. "A hanging was a carnival that diverted not merely the unemployed but the unemployable. Good bourgeois or curious aristocrats who could afford it watched it from a carriage or rented a room." Public punishment as entertainment lasted until the 19th century by which time "the awesome event of a public hanging aroused the loathing of writers and philosophers". Both Dickens and Thackeray wrote about a hanging in Newgate Prison in 1840, and "taught an even wider public that executions are obscene entertainments".
Children.
Children's entertainment is centred on play and is significant for their growth and learning. Entertainment is also provided to children or taught to them by adults and many activities that appeal to them such as puppets, clowns, pantomimes and cartoons are also enjoyed by adults.
Children have always played games. It is accepted that as well as being entertaining, playing games helps children's development. One of the most famous visual accounts of children's games is a painting by Pieter Bruegel the Elder called "Children's Games", painted in 1560. It depicts children playing a range of games which were presumably typical of the time. Many of these games, such as marbles, hide-and-seek, blowing soap bubbles and piggyback riding continue to be played.
Most forms of entertainment can be or are modified to suit children's needs and interests. During the 20th century, starting with the often criticised but nonetheless important work of G. Stanley Hall, who "promoted the link between the study of development and the 'new' laboratory psychology", and especially with the work of Jean Piaget, who "saw cognitive development as being analogous to biological development", it became understood that the psychological development of children occurs in stages and that their capacities differ from adults. Hence, stories and activities, whether in books, film, or video games were developed specifically for child audiences. Countries have responded to the special needs of children and the rise of digital entertainment by developing systems such as television content rating systems, to guide the public and the entertainment industry.
In the 21st century, as with adult products, much entertainment is available for children on the internet for private use. This constitutes a significant change from earlier times. The amount of time expended by children indoors on screen-based entertainment and the "remarkable collapse of children's engagement with nature" has drawn criticism for its negative effects on imagination, adult cognition and psychological well-being.<ref name=http://www.guardian.co.uk/commentisfree/2012/nov/19/children-lose-contact-with-nature></ref>
Forms.
Banquets.
Banquets have been a venue for entertainment since ancient times, continuing until the 21st century, when they are still being used for many of their original purposes â to impress visitors, especially important ones (4, 6, 9); to show hospitality (2, 4, 8); as an occasion to showcase supporting entertainments such as music or dancing, or both (2, 3). They were an integral part of court entertainments (3, 4) and helped entertainers develop their skills (2, 3). They are also important components of celebrations such as coronations (9), weddings (7), birthdays (10) civic or political achievements (5), military engagements or victories (6) as well as religious obligations (1). In modern times, banquets are commercially available, for example, in restaurants (10) and combined with a performance in dinner theatres. Cooking by professional chefs has also become a form of entertainment as part of global competitions such as the Bocuse d'Or.
Music.
Music is a supporting component of many kinds of entertainment and most kinds of performance. For example, it is used to enhance storytelling, it is indispensable in dance (1, 4) and opera, and is usually incorporated into dramatic film or theatre productions.
Music is also a universal and popular type of entertainment on its own, constituting an entire performance such as when concerts are given (2, 4, 5, 6, 7, 8, 9 ). Depending on the rhythm, instrument, performance and style, music is divided into many genres, such as classical, jazz, folk, (4, 5, 8), rock, pop music (6, 9) or traditional (1, 3). Since the 20th century, performed music, once available only to those who could pay for the performers, has been available cheaply to individuals by the entertainment industry which broadcasts it or pre-records it for sale.
The wide variety of musical performances, whether or not they are artificially amplified (6, 7, 9, 10), all provide entertainment irrespective of whether the performance is from soloists (6), choral (2) or orchestral groups (5, 8), or ensemble (3). Live performances use specialised venues, which might be small or large; indoors or outdoors; free or expensive. The audiences have different expectations of the performers as well as of their own role in the performance. For example, some audiences expect to listen silently and are entertained by the excellence of the music, its rendition or its interpretation (5, 8). Other audiences of live performances are entertained by the ambience and the chance to participate (7, 9). Even more listeners are entertained by pre-recorded music and listen privately (10).
The instruments used in musical entertainment are either solely the human voice (2, 6) or solely instrumental (1, 3) or some combination of the two (4, 5, 7, 8). Whether the performance is given by vocalists or instrumentalists, the performers may be soloists or part of a small or large group, in turn entertaining an audience that might be individual (10), passing by (3), small (1, 2) or large (6, 7, 8, 9). Singing is generally accompanied by instruments although some forms, notably a cappella and overtone singing, are unaccompanied. Modern concerts often use various special effects and other theatrics to accompany performances of singing and dancing (7).
Games.
Games are played for entertainmentâsometimes purely for entertainment, sometimes for achievement or reward as well. They can be played alone, in teams, or online; by amateurs or by professionals. The players may have an audience of non-players, such as when people are entertained by watching a chess championship. On the other hand, players in a game may constitute their own audience as they take their turn to play. Often, part of the entertainment for children playing a game is deciding who will be part of their audience and who will be a player.
Equipment varies with the game. Board games, such as Go, "Monopoly" or backgammon need a board and markers. One of the oldest known board games is Senet, a game played in Ancient Egypt, enjoyed by the pharaoh Tutankhamun. Card games, such as whist, poker and Bridge have long been played as evening entertainment among friends. For these games, all that is needed is a deck of playing cards. Other games, such as bingo, played with numerous strangers, have been organised to involve the participation of non-players via gambling. Many are geared for children, and can be played outdoors, including hopscotch, hide and seek, or Blind man's bluff. The list of ball games is quite extensive. It includes, for example, croquet, lawn bowling and paintball as well as many sports using various forms of balls. The options cater to a wide range of skill and fitness levels. Physical games can develop agility and competence in motor skills. Number games such as Sudoku and puzzle games like the Rubik's cube can develop mental prowess.
Video games are played using a controller to create results on a screen. They can also be played online with participants joining in remotely. In the second half of the 20th century and in the 21st century the number of such games increased enormously, providing a wide variety of entertainment to players around the world. Video games are popular in East Asian countries such as South Korea.
Reading.
Reading has been a source of entertainment for a very long time, especially when other forms, such as performance entertainments, were (or are) either unavailable or too costly. Even when the primary purpose of the writing is to inform or instruct, reading is well known for its capacity to distract from everyday worries. Both stories and information have been passed on through the tradition of orality and oral traditions survive in the form of performance poetry for example. However, they have drastically declined. "Once literacy had arrived in strength, there was no return to the oral prerogative." The advent of printing, the reduction in costs of books and an increasing literacy all served to enhance the mass appeal of reading. Furthermore, as fonts were standardised and texts became clearer, "reading ceased being a painful process of decipherment and became an act of pure pleasure". By the 16th century in Europe, the appeal of reading for entertainment was well established.
Among literature's many genres are some designed, in whole or in part, purely for entertainment. Limericks, for example, use verse in a strict, predictable rhyme and rhythm to create humour and to amuse an audience of listeners or readers. Interactive books such as "choose your own adventure" can make literary entertainment more participatory.
Comics and cartoons are literary genres that use drawings or graphics, usually in combination with text, to convey an entertaining narrative. Many contemporary comics have elements of fantasy and are produced by companies that are part of the entertainment industry. Others have unique authors who offer a more personal, philosophical view of the world and the problems people face. Comics about superheroes such as Superman are of the first type. Examples of the second sort include the individual work over 50 years of Charles M. Schulz who produced a popular comic called "Peanuts" about the relationships among a cast of child characters; and Michael Leunig who entertains by producing whimsical cartoons that also incorporate social criticism. The Japanese Manga style differs from the western approach in that it encompasses a wide range of genres and themes for a readership of all ages. Caricature uses a kind of graphic entertainment for purposes ranging from merely putting a smile on the viewer's face, to raising social awareness, to highlighting the moral characteristics of a person being caricatured.
Comedy.
Comedy is both a genre of entertainment and a component of it, providing laughter and amusement, whether the comedy is the sole purpose or used as a form of contrast in an otherwise serious piece. It is a valued contributor to many forms of entertainment, including in literature, theatre, opera, film and games. In royal courts, such as for example, in the Byzantine court, and presumably, also in its wealthy households, "mimes were the focus of orchestrated humour, expected or obliged to make fun of all at court, not even excepting the emperor and members of the imperial family. This highly structured role of jester consisted of verbal humour, including teasing, jests, insult, ridicule, and obscenity and non-verbal humour such as slapstick and horseplay in the presence of an audience." In medieval times, all comic types â the buffoon, jester, hunchback, dwarf, jokester, were all "considered to be essentially of one comic type: the fool", who while not necessarily funny, represented "the shortcomings of the individual".
Shakespeare wrote seventeen comedies which use many of the techniques still called upon by performers and writers of comedy, such as jokes, puns, parody, wit, observational humor or the unexpected effect of irony. One-liner jokes and satire are also used to comedic effect in literature. In farce, the comedy is a primary purpose.
The meaning of the word "comedy" and the audience's expectations of it have changed over time and vary according to culture. Simple physical comedy such as slapstick is entertaining to a broad range of people of all ages. However, as cultures become more sophisticated, national nuances appear in the style and references so that what is amusing in one culture may be unintelligible in another.
Performance.
Live performances before an audience constitute a major form of entertainment, especially before the invention of audio and video recording. Performance takes a wide range of forms, including theatre, music and drama. In the 16th and 17th centuries, European royal courts presented masques that were complex theatrical entertainments involving dancing, singing and acting. Opera is a similarly demanding performance style that remains popular. It also encompass all three forms, demanding a high level of musical and dramatic skill, collaboration and like the masque, production expertise as well.
Audiences generally show their appreciation of an entertaining performance with applause. However, all performers run the risk of failing to hold their audience's attention and thus, failing to entertain. Audience dissatisfaction is often brutally honest and direct.
Storytelling.
Storytelling is an ancient form of entertainment that has influenced almost all other forms. It is "not only entertainment, it is also thinking through human conflicts and contradictions". Hence, although stories may be delivered directly to a small listening audience, they are also presented as entertainment and used as a component of any piece that relies on a narrative, such as film, drama, ballet, and opera. Written stories have been enhanced by illustrations, often to a very high artistic standard, for example, on illuminated manuscripts and on ancient scrolls such as Japanese ones. Stories remain a common way of entertaining a group that is on a journey. Showing how stories are used to pass the time and entertain an audience of travellers, Chaucer used pilgrims in his literary work "The Canterbury Tales" in the 14th century, as did Wu Cheng'en in the 16th century in "Journey to the West". Even though journeys can now be completed much faster, stories are still told to passengers en route in cars and aeroplanes either orally or delivered by some form of technology.
The power of stories to entertain is evident in one of the most famous onesâScheherazadeâa story in the Persian professional storytelling tradition, of a woman who saves her own life by telling stories. The connections between the different types of entertainment are shown by the way that stories like this inspire a retelling in another medium, such as music, film or games. For example, composers Rimsky-Korsakov, Ravel and Szymanowski have each been inspired by the Scheherazade story and turned it into an orchestral work; director Pasolini made a film adaptation; and there is an innovative video game based on the tale. Stories may be told wordlessly, in music, dance or puppetry for example, such as in the Javanese tradition of wayang, in which the performance is accompanied by a gamelan orchestra or the similarly traditional Punch and Judy show.
Epic narratives, poems, sagas and allegories from all cultures tell such gripping tales that they have inspired countless other stories in all forms of entertainment. Examples include the Hindu "Ramayana" and "Mahabharata"; Homer's "Odyssey" and "Iliad"; the first Arabic novel "Hayy ibn Yaqdhan"; the Persian epic "Shahnameh"; the Sagas of Icelanders and the celebrated "Tale of the Genji". Collections of stories, such as "Grimms' Fairy Tales" or those by Hans Christian Andersen, have been similarly influential. Originally published in the early 19th century, this collection of folk stories had significant influence in modern popular culture which subsequently used its themes, images, symbols and structural elements to create new forms of entertainment.
Some of the most powerful and long-lasting stories are the foundation stories, also called origin or creation myths such as the Dreamtime myths of the Australian aborigines, the Mesopotamian "Epic of Gilgamesh", or the Hawaiian stories of the origin of the world. These too are developed into books, films, music and games in a way that increases their longevity and enhances their entertainment value.
Theatre.
Theatre performances, typically dramatic or musical, are presented on a stage for an audience and have a history that goes back to Hellenistic times when "leading musicians and actors" performed widely at "poetical competitions", for example at "Delphi, Delos, Ephesus". Aristotle and his teacher Plato both wrote on the theory and purpose of theatre. Aristotle posed questions such as "What is the function of the arts in shaping character? Should a member of the ruling class merely watch performances or be a participant and perform? What kind of entertainment should be provided for those who do not belong to the elite?" The "Ptolemys in Egypt, the Seleucids in Pergamum" also had a strong theatrical tradition and later, wealthy patrons in Rome staged "far more lavish productions".
Expectations about the performance and their engagement with it have changed over time (1). For example, in England during the 18th century, "the prejudice against actresses had faded" and in Europe generally, going to the theatre, once a socially dubious activity, became "a more respectable middle-class pastime" in the late 19th and early 20th centuries, when the variety of popular entertainments increased. Operetta and music halls became available, and new drama theatres such as the Moscow Art Theatre and the Suvorin Theatre in Russia opened. At the same time, commercial newspapers "began to carry theatre columns and reviews" which helped to make theatre "a legitimate subject of intellectual debate" in general discussions about art and culture. Audiences began to gather to "appreciate creative achievement, to marvel at, and be entertained by, the prominent 'stars'." Vaudeville and music halls, popular at this time in the United States, England, Canada, Australia and New Zealand, were themselves eventually superseded.
Plays, musicals, monologues, pantomimes, and performance poetry are part of the very long history of theatre which is also the venue for the type of performance known as stand-up comedy. In the 20th century, radio and television, often broadcast live, extended the theatrical tradition that continued to exist alongside the new forms.
The stage and the spaces set out in front of it for an audience create a theatre. All types of stage are used with all types of seating for the audience, including the impromptu or improvised (2, 3, 6); the temporary (2); the elaborate (9); or the traditional and permanent (5, 7). They are erected indoors (3, 5, 9) or outdoors (2, 4, 6). The skill of managing, organising and preparing the stage for a performance is known as stagecraft (10). The audience's experience of the entertainment is affected by their expectations, the stagecraft, the type of stage, and the type and standard of seating provided.
Cinema and film.
Films are a major form of entertainment, although not all films have entertainment as their primary purpose: documentary film, for example, aims to create a record or inform, although the two purposes often work together. The medium was a global business from the beginning: "The LumiÃ¨re brothers were the first to send cameramen throughout the world, instructing them to film everything which could be of interest for the public." In 1908, PathÃ© launched and distributed newsreels and by World War I, films were meeting an enormous need for mass entertainment. "In the first decade of the 0t century cinematic programmes combined, at random, fictions and newsfilms." The Americans first "contrived a way of producing an illusion of motion through successive images," but "the French were able to transform a scientific principle into a commercially lucrative spectacle". Film therefore became a part of the entertainment industry from its early days. Increasingly sophisticated techniques have been used in the film medium to delight and entertain audiences. Animation, for example, which involves the display of rapid movement in an art work, is one of these techniques that particularly appeals to younger audiences. The advent of computer-generated imagery (CGI) in the 21st century made it "possible to do spectacle" more cheaply and "on a scale never dreamed of" by Cecil B. DeMille. From the 1930s to 1950s, movies and radio were the "only mass entertainment" but by the second decade of the 21st century, technological changes, economic decisions, risk aversion and globalisation reduced both the quality and range of films being produced. Sophisticated visual effects and CGI techniques, for example, rather than humans, were used not only to create realistic images of people, landscapes and events (both real and fantastic) but also to animate non-living items such as Lego normally used as entertainment as a game in physical form. Creators of "The Lego Movie" "wanted the audience to believe they were looking at actual Lego bricks on a tabletop that were shot with a real camera, not what we actually did, which was create vast environments with digital bricks inside the computer." The convergence of computers and film has allowed entertainment to be presented in a new way and the technology has also allowed for those with the personal resources to screen films in a home theatre, recreating in a private venue the quality and experience of a public theatre. This is similar to the way that the nobility in earlier times could stage private musical performances or the use of domestic theatres in large homes to perform private plays in earlier centuries.
Films also re-imagine entertainment from other forms, turning stories, books and plays, for example, into new entertainments. "", a documentary about the history of film, gives a survey of global achievements and innovations in the medium, as well as changes in the conception of film-making. It demonstrates that while some films, particularly those in the Hollywood tradition that combines "realism and melodramatic romanticism", are intended as a form of escapism, others require a deeper engagement or more thoughtful response from their audiences. For example, the award winning Senegalese film "Xala" takes government corruption as its theme. Charlie Chaplin's film "The Great Dictator" was a brave and innovative parody, also on a political theme. Stories that are thousands of years old, such as "Noah", have been re-interpreted in film, applying familiar literary devices such as allegory and personification with new techniques such as CGI to explore big themes such as "human folly", good and evil, courage and despair, love, faith, and death â themes which have been a main-stay of entertainment across all its forms.
As in other media, excellence and achievement in films is recognised through a range of awards, including ones from the American Academy of Motion Picture Arts and Sciences, the British Academy of Film and Television Arts, the Cannes International Film Festival in France and the Asia Pacific Screen Awards.
Dance.
The many forms of dance provide entertainment for all age groups and cultures. Dance can be serious in tone, such as when it is used to express a culture's history or important stories; it may be provocative; or it may put in the service of comedy. Since it combines many forms of entertainment â music, movement, storytelling, theatre â it provides a good example of the various ways that these forms can be combined to create entertainment for different purposes and audiences.
Dance is "a form of cultural representation" that involves not just dancers, but "choreographers, audience members, patrons and impresariosÂ ... coming from all over the globe and from vastly varied time periods." Whether from Africa, Asia or Europe, dance is constantly negotiating the realms of political, social, spiritual and artistic influence." Even though dance traditions may be limited to one cultural group, they all develop. For example, in Africa, there are "Dahomean dances, Hausa dances, Masai dances and so forth." Ballet is an example of a highly developed Western form of dance that moved to the theatres from the French court during the time of Louis XIV, the dancers becoming professional theatrical performers. Some dances, such as the quadrille, a square dance that "emerged during the Napoleonic years in France" and other country dances were once popular at social gatherings like balls, but are now rarely performed. On the other hand, many folk dances (such as Scottish Highland dancing and Irish dancing), have evolved into competitions, which by adding to their audiences, has increased their entertainment value. "Irish dance theatre, which sometimes features traditional Irish steps and music, has developed into a major dance form with an international reputation."
Since dance is often "associated with the female body and women's experiences", female dancers, who dance to entertain, have in some cases been regarded as distinct from "decent" women because they "use their bodies to make a living instead of hiding them as much as possible". Society's attitudes to female dancers depend on the culture, its history and the entertainment industry itself. For example, while some cultures regard any dancing by women as "the most shameful form of entertainment", other cultures have established venues such as strip clubs where deliberately erotic or sexually provocative dances such as striptease are performed in public by professional women dancers for mostly male audiences.
Various political regimes have sought to control or ban dancing or specific types of dancing, sometimes because of disapproval of the music or clothes associated with it. Nationalism, authoritarianism and racism have played a part in banning dances or dancing. For example, during the Nazi regime, American dances such as swing, regarded as "completely un-German", had "become a public offense and needed to be banned". Similarly, in Shanghai, China, in the 1930s, "dancing and nightclubs had come to symbolise the excess that plagued Chinese society" and officials wondered if "other forms of entertainment such as brothels" should also be banned. Banning had the effect of making "the dance craze" even greater. In Ireland, the Public Dance Hall Act of 1935 "banned â but did not stop â dancing at the crossroads and other popular dance forms such as house and barn dances." In the US, various dances have been banned, either because like burlesque, they were suggestive, or because, like the Twist, they were associated with African Americans. "African American dancers were typically banned from performing in minstrel shows until after the Civil War."
Dances can be performed solo (1, 4); in pairs, (2, 3); in groups, (5, 6, 7); or by massed performers (10). They might be improvised (4, 8) or highly choreographed (1, 2, 5, 10); spontaneous for personal entertainment, (such as when children begin dancing for themselves); a private audience, (4); a paying audience (2); a world audience (10); or an audience interested in a particular dance genre (3, 5). They might be a part of a celebration, such as a wedding or New Year (6, 8); or a cultural ritual with a specific purpose, such as a dance by warriors like a haka (7). Some dances, such as traditional dance in 1 and ballet in 2, need a very high level of skill and training; others, such as the can-can, require a very high level of energy and physical fitness. Entertaining the audience is a normal part of dance but its physicality often also produces joy for the dancers themselves (9).
Animals.
Animals have been used for the purposes of entertainment for millennia. They have been hunted for entertainment (as opposed to hunted for food); displayed while they hunt for prey; watched when they compete with each other; and watched while they perform a trained routine for human amusement. The Romans, for example, were entertained both by competitions involving wild animals and acts performed by trained animals. They watched as "lions and bears danced to the music of pipes and cymbals; horses were trained to kneel, bow, dance and pranceÂ ... acrobats turning handsprings over wild lions and vaulting over wild leopards." There were "violent confrontations with wild beasts" and "performances over time became more brutal and bloodier".
Animals that perform trained routines or "acts" for human entertainment include fleas in flea circuses, dolphins in dolphinaria, and monkeys doing tricks for an audience on behalf of the player of a street organ. Animals kept in zoos in ancient times were often kept there for later use in the arena as entertainment or for their entertainment value as exotica.
Many contests between animals are now regarded as sports â for example, horse racing is regarded as both a sport and an important source of entertainment. Its economic impact means that it is also considered a global industry, one in which horses are carefully transported around the world to compete in races. In Australia, the horse race run on Melbourne Cup Day is a public holiday and the public regards the race as an important annual event. Like horse racing, camel racing requires human riders, while greyhound racing does not. People find it entertaining to watch animals race competitively, whether they are trained, like horses, camels or dogs, or untrained, like cockroaches.
The use of animals for entertainment is often controversial, especially the hunting of wild animals. Some contests between animals, once popular entertainment for the public, have become illegal because of the cruelty involved. Among these are blood sports such as bear-baiting, dog fighting and cockfighting. Other contests involving animals remain controversial and have both supporters and detractors. For example, the conflict between opponents of pigeon shooting who view it as "a cruel and moronic exercise in marksmanship, and proponents, who view it as entertainment" has been tested in a court of law. Fox hunting, which involves the use of horses as well as hounds, and bullfighting, which has a strong theatrical component, are two entertainments that have a long and significant cultural history. They both involve animals and are variously regarded as sport, entertainment or cultural tradition. Among the organisations set up to advocate for the rights of animals are some whose concerns include the use of animals for entertainment. However, "in many cases of animal advocacy groups versus organisations accused of animal abuse, both sides have cultural claims."
Circus.
A circus, described as "one of the most brazen of entertainment forms", is a special type of theatrical performance, involving acrobatics and often performing animals, usually thought of as a travelling show, although permanent venues have also been used. Philip Astley is regarded as the founder of the modern circus in the second half of the 18th century and Jules LÃ©otard is the French performer credited with developing the art of the trapeze, considered synonymous with circuses. Astley brought together performances that were generally familiar in traditional British fairs "at least since the beginning of the 17th century": "tumbling, rope-dancing, juggling, animal tricks and so on". It has been claimed that "there is no direct link between the Roman circus and the circus of modern times.Â ... Between the demise of the Roman 'circus' and the foundation of Astley's Amphitheatre in London some 1300 years later, the nearest thing to a circus ring was the rough circle formed by the curious onlookers who gathered around the itinerant tumbler or juggler on a village green."
Magic.
The form of entertainment known as stage magic or conjuring and recognisable as performance, is based on traditions and texts of magical rites and dogmas that have been a part of most cultural traditions since ancient times. (References to magic, for example, can be found in the Bible, in Hermeticism, in Zoroastrianism, in the Kabbalistic tradition, in mysticism and in the sources of Freemasonry.)
Stage magic is performed for an audience in a variety of media and locations: on stage, on television, in the street, and live at parties or events. It is often combined with other forms of entertainment, such as comedy or music and showmanship is often an essential part of magic performances. Performance magic relies on deception, psychological manipulation, sleight of hand and other forms of trickery to give an audience the illusion that a performer can achieve the impossible. Audiences amazed at the stunt performances and escape acts of Harry Houdini, for example, regarded him as a magician.
Fantasy magicians have held an important place in literature for centuries, offering entertainment to millions of readers. Famous wizards such as Merlin in the Arthurian legends have been written about since the 5th and 6th centuries, while in the 21st century, the young wizard Harry Potter became a global entertainment phenomenon when the book series about him sold about 450 million copies (as at June 2011), making it the best-selling book series in history.
Street performance.
Street entertainment, street performance or "busking" are forms of performance that have been meeting the public's need for entertainment for centuries. It was "an integral aspect of London's life", for example, when the city in the early 19th century was "filled with spectacle and diversion". Minstrels or troubadours are part of the tradition. The art and practice of busking is still celebrated at annual busking festivals.
There are three basic forms of contemporary street performance. The first form is the "circle show". It tends to gather a crowd, usually has a distinct beginning and end, and is done in conjunction with street theatre, puppeteering, magicians, comedians, acrobats, jugglers and sometimes musicians. This type has the potential to be the most lucrative for the performer because there are likely to be more donations from larger audiences if they are entertained by the act. Good buskers control the crowd so patrons do not obstruct foot traffic. The second form, the "walk-by act", has no distinct beginning or end. Typically, the busker provides an entertaining ambience, often with an unusual instrument, and the audience may not stop to watch or form a crowd. Sometimes a walk-by act will spontaneously turn into a circle show. The third form, "cafÃ© busking", is performed mostly in restaurants, pubs, bars and cafÃ©s. This type of act occasionally uses public transport as a venue.
Parades.
Parades are held for a range of purposes, often more than one. Whether their mood is sombre or festive, being public events that are designed to attract attention and activities that necessarily divert normal traffic, parades have a clear entertainment value to their audiences. Cavalcades and the modern variant, the motorcade, are examples of public processions. Some people watching the parade or procession may have made a special effort to attend, while others become part of the audience by happenstance. Whatever their mood or primary purpose, parades attract and entertain people who watch them pass by. Occasionally, a parade takes place in an improvised theatre space (such as the Trooping the Colour in 5) and tickets are sold to the physical audience while the global audience participates via broadcast.
One of the earliest forms of parade were "triumphs" â grand and sensational displays of foreign treasures and spoils, given by triumphant Roman generals to celebrate their victories. They presented conquered peoples and nations that exalted the prestige of the victor. "In the summer of 46 B.C.E. Julius Caesar chose to celebrate four triumphs held on different days extending for about one month." In Europe from the Middle Ages to the Baroque the Royal Entry celebrated the formal visit of the monarch to the city with a parade through elaborately decorated streets, passing various shows and displays. The annual Lord Mayor's Show in London is an example of a civic parade that has survived since medieval times.
Many religious festivals (especially those which incorporate processions, such as Holy Week processions or the Indian festival of Holi) have some entertainment appeal in addition to their serious purpose. Sometimes, religious rituals have been adapted or evolved into secular entertainments, or like the Festa del Redentore in Venice, have managed to grow in popularity while holding both secular and sacred purposes in balance. However, pilgrimages, such as the Christian pilgrimage of the Way of St. James, the Muslim Hajj and the Hindu Kumbh Mela, which may appear to the outsider as an entertaining parade or procession, are not intended as entertainment: they are instead about an individual's spiritual journey. Hence, the relationship between spectator and participant, unlike entertainments proper, is different. The manner in which the Kumbh Mela, for example, "is divorced from its cultural context and repackaged for Western consumption â renders the presence of voyeurs deeply problematic."
Parades generally impress and delight (5, 6, 7, 8), often by including unusual, colourful costumes (6, 7). Sometimes they also commemorate (5, 8) or celebrate (1, 4, 8, 9, 10). Sometimes they have a serious purpose, such as when the context is military (1, 2, 5), when the intention is sometimes to intimidate; or religious, when the audience might participate or have a role to play (6, 7, 9). Even if a parade uses new technology and is some distance away (10), it is likely to have a strong appeal, draw the attention of onlookers and entertain them.
Fireworks.
Fireworks are a part of many public entertainments and have retained an enduring popularity since they became a "crowning feature of elaborate celebrations" in the 17th century. First used in China, classical antiquity and Europe for military purposes, fireworks were most popular in the 18th century and high prices were paid for pyrotechnists, especially the skilled Italian ones, who were summoned to other countries to organise displays. Fire and water were important aspects of court spectacles because the displays "inspired by means of fire, sudden noise, smoke and general magnificence the sentiments thought fitting for the subject to entertain of his sovereign: awe fear and a vicarious sense of glory in his might. Birthdays, name-days, weddings and anniversaries provided the occasion for celebration." One of the most famous courtly uses of fireworks was one used to celebrate the end of the War of the Austrian Succession and while the fireworks themselves caused a fire, the accompanying Music for the Royal Fireworks written by Handel has been popular ever since. Aside from their contribution to entertainments related to military successes, courtly displays and personal celebrations, fireworks are also used as part of religious ceremony. For example, during the Indian Dashavatara Kala of Gomantaka "the temple deity is taken around in a procession with a lot of singing, dancing and display of fireworks".
The "fire, sudden noise and smoke" of fireworks is still a significant part of public celebration and entertainment. For example, fireworks were one of the primary forms of display chosen to celebrate the turn of the millennium around the world. As the clock struck midnight and 1999 became 2000, firework displays and open-air parties greeted the New Year as the time zones changed over to the next century. Fireworks, carefully planned and choreographed, were let off against the backdrop of many of the world's most famous buildings, including the Sydney Harbour Bridge, the Pyramids of Giza in Egypt, the Acropolis in Athens, Red Square in Moscow, Vatican City in Rome, the Brandenburg Gate in Berlin, the Eiffel Tower in Paris, and Elizabeth Tower in London.
Sport.
Sporting competitions have always provided entertainment for crowds. To distinguish the players from the audience, the latter are often known as spectators. Developments in stadium and auditorium design, as well as in recording and broadcast technology, have allowed off-site spectators to watch sport, with the result that the size of the audience has grown ever larger and spectator sport has become increasingly popular. Two of the most popular sports with global appeal are association football and cricket. Their ultimate international competitions, the World Cup and test cricket, are broadcast around the world. Beyond the very large numbers involved in playing these sports, they are notable for being a major source of entertainment for many millions of non-players worldwide. A comparable multi-stage, long-form sport with global appeal is the Tour de France, unusual in that it takes place outside of special stadia, being run instead in the countryside.
Aside from sports that have world-wide appeal and competitions, such as the Olympic Games, the entertainment value of a sport depends on the culture and country in which it is played. For example, in the United States, baseball and basketball games are popular forms of entertainment; in Bhutan, the national sport is archery; in New Zealand, it is rugby union; in Iran, it is freestyle wrestling. Japan's unique sumo wrestling contains ritual elements that derive from its long history. In some cases, such as the international running group Hash House Harriers, participants create a blend of sport and entertainment for themselves, largely independent of spectator involvement, where the social component is more important than the competitive.
The evolution of an activity into a sport and then an entertainment is also affected by the local climate and conditions. For example, the modern sport of surfing is associated with Hawaii and that of snow skiing probably evolved in Scandinavia. While these sports and the entertainment they offer to spectators have spread around the world, people in the two originating countries remain well known for their prowess. Sometimes the climate offers a chance to adapt another sport such as in the case of ice hockey which is an important entertainment in Canada.
Fairs, expositions, shopping.
Fairs and exhibitions have existed since ancient and medieval times, displaying wealth, innovations and objects for trade and offering specific entertainments as well as being places of entertainment in themselves. Whether in a medieval market or a small shop, "shopping always offered forms of exhilaration that took one away from the everyday". However, in the modern world, "merchandising has become entertainment: spinning signs, flashing signs, thumping musicÂ ... video screens, interactive computer kiosks, day care .. cafÃ©s".
By the 19th century, "expos" which encourage arts, manufactures and commerce had become truly international and were not only hugely popular but were having an enormous impact on international ideas. For example, the 1878 Paris Exposition facilitated international cooperation about ideas, innovations and standards. From London 1851 to Paris 1900, "in excess of 200 million visitors had entered the turnstiles in London, Paris, Vienna, Philadelphia, Chicago and a myriad of smaller shows around the world." Since World War II "well over 500 million visits have been recorded through world expo turnstiles". As a form of spectacle and entertainment, expositions influenced "everything from architecture, to patterns of globalisation, to fundamental matters of human identity" and in the process established the close relationship between "fairs, the rise of department stores and art museums", the modern world of mass consumption and the entertainment industry.
Safety.
Some entertainments, such as at large festivals (whether religious or secular), concerts, clubs, parties and celebrations, involve big crowds. From earliest times, crowds at an entertainment have associated hazards and dangers, especially when combined with the recreational consumption of intoxicants such as alcohol. The Ancient Greeks had Dionysian Mysteries, for example, and the Romans had Saturnalia. The consequence of excess and crowds can produce breaches of social norms of behaviour, sometimes causing injury or even death, such as for example, at the Altamont Free Concert, an outdoor rock festival. The list of serious incidents at nightclubs includes those caused by stampede; overcrowding; terrorism, such as the 2002 Bali bombings that targeted a nightclub; and especially fire. Investigations, such as that carried out in the US after The Station nightclub fire often demonstrate that lessons learned "regarding fire safety in nightclubs" from earlier events such as the Cocoanut Grove fire do "not necessarily result in lasting effective change". Efforts to prevent such incidents include appointing special officers, such as the medieval Lord of Misrule or, in modern times, security officers who control access; and also ongoing improvement of relevant standards such as those for building safety. The tourism industry now regards safety and security at entertainment venues as an important management task.
Industry.
Although kings, rulers and powerful people have always been able to pay for entertainment to be provided for them and in many cases have paid for public entertainment, people generally have made their own entertainment or when possible, attended a live performance. Technological developments in the 20th century meant that entertainment could be produced independently of the audience, packaged and sold on a commercial basis by an entertainment industry. Sometimes referred to as show business, the industry relies on business models to produce, market, broadcast or otherwise distribute many of its traditional forms, including performances of all types. The industry became so sophisticated that its economics became a separate area of academic study.
The film industry is a part of the entertainment industry. Components of it include the Hollywood and Bollywood film industries, as well as the cinema of the United Kingdom and all the cinemas of Europe, including France, Germany, Spain, Italy and others. The sex industry is another component of the entertainment industry, applying the same forms and media (for example, film, books, dance and other performances) to the development, marketing and sale of sex products on a commercial basis.
Amusement parks entertain paying guests with rides, such as roller coasters, train rides, water rides, and dark rides, as well as other events and associated attractions. The parks are built on a large area subdivided into themed areas named "lands". Sometimes the whole amusement park is based on one theme, such as the various SeaWorld parks that focus on the theme of sea life.
One of the consequences of the development of the entertainment industry has been the creation of new types of employment. While jobs such as writer, musician and composer exist as they always have, people doing this work are likely to be employed by a company rather than a patron as they once would have been. New jobs have appeared, such as gaffer or special effects supervisor in the film industry, and attendants in an amusement park.
Prestigious awards are given by the industry for excellence in the various types of entertainment. For example, there are awards for Music, Games (including video games), Comics, Comedy, Theatre, Television, Film, Dance and Magic. Sporting awards are made for the results and skill, rather than for the entertainment value.
Architecture.
Architecture for entertainment.
Purpose-built structures as venues for entertainment that accommodate audiences have produced many famous and innovative buildings, among the most recognisable of which are theatre structures. For the ancient Greeks, "the architectural importance of the theatre is a reflection of their importance to the community, made apparent in their monumentality, in the effort put into their design, and in the care put into their detail." The Romans subsequently developed the stadium in an oval form known as a circus. In modern times, some of the grandest buildings for entertainment have brought fame to their cities as well as their designers. The Sydney Opera House, for example, is a World Heritage Site and The Oâ in London is an entertainment precinct that contains an indoor arena, a music club, a cinema and exhibition space. The Bayreuth Festspielhaus in Germany is a theatre designed and built for performances of one specific musical composition.
Two of the chief architectural concerns for the design of venues for mass audiences are speed of egress and safety. The speed at which the venue can be emptied is important both for amenity and safety because large crowds take a very long time to disperse from a badly designed venue and this in turn creates a safety risk. The Hillsborough disaster is an example of how poor aspects of building design can contribute to audience deaths. Sightlines and acoustics are also important design considerations in most theatrical venues.
In the 21st century, entertainment venues, especially stadia, are "likely to figure among the leading architectural genres". However, they require "a whole new approach" to design, because they need to be "sophisticated entertainment centres, multi-experience venues, capable of being enjoyed in many diverse ways". Hence, architects now have to design "with two distinct functions in mind, as sports and entertainment centres playing host to live audiences, and as sports and entertainment studios serving the viewing and listening requirements of the remote audience".
Architecture as entertainment.
Architects who push the boundaries of design or construction sometimes create buildings that are entertaining because they exceed the expectations of the public and the client and are aesthetically outstanding. Buildings such as Guggenheim Museum Bilbao, designed by Frank Gehry, are of this type, becoming a tourist attraction as well as a significant international museum. Other apparently usable buildings are really follies, deliberately constructed for a decorative purpose and never intended to be practical.
On the other hand, sometimes architecture is entertainment, while pretending to be functional. The tourism industry, for example, creates or renovates buildings as "attractions" that have either never been used or can never be used for their ostensible purpose. They are instead re-purposed to entertain visitors often by simulating cultural experiences. Buildings, history and sacred spaces are thus made into commodities for purchase. Such intentional tourist attractions divorce buildings from the past so that "the difference between historical authenticity and contemporary entertainment venues/theme parks becomes hard to define". Examples include "the preservation of the AlcÃ¡zar of Toledo, with its grim Civil War History, the conversion of slave dungeons into tourist attractions in Ghana, uch as, for example, [[Cape Coast Castle] and the presentation of indigenous culture in Libya". The specially constructed buildings in amusement parks represent the park's theme and are usually neither authentic nor completely functional.
Effects of developments in electronic media.
Globalisation.
By the second half of the 20th century, developments in electronic media made possible the delivery of entertainment products to mass audiences across the globe. The technology enabled people to see, hear and participate in all the familiar forms â stories, theatre, music, dance â wherever they live. The rapid development of entertainment technology was assisted by improvements in data storage devices such as cassette tapes or compact discs, along with increasing miniaturisation. Computerisation and the development of barcodes also made ticketing easier, faster and global.
Obsolescence.
In the 1940s, radio was the electronic medium for family entertainment and information. In the 1950s, it was television that was the new medium and it rapidly became global, bringing visual entertainment, first in black and white, then in colour, to the world. By the 1970s, games could be played electronically, then hand-held devices provided mobile entertainment, and by the last decade of the 20th century, via networked play. In combination with products from the entertainment industry, all the traditional forms of entertainment became available personally. People could not only select an entertainment product such as a piece of music, film or game, they could choose the time and place to use it. The "proliferation of portable media players and the emphasis on the computer as a site for film consumption" together have significantly changed how audiences encounter films. One of the most notable consequences of the rise of electronic entertainment has been the rapid obsolescence of the various recording and storage methods. As an example of speed of change driven by electronic media, over the course of one generation, television as a medium for receiving standardised entertainment products went from unknown, to novel, to ubiquitous and finally to superseded. One estimate was that by 2011 over 30 percent of households in the US would own a Wii console, "about the same percentage that owned a television in 1953". It is expected that halfway through the second decade of the 21st century, television will be completely replaced by online entertainment. The so-called "digital revolution" has resulted in an increasingly transnational marketplace that has caused difficulties for governments, business, industries and individuals as they all try to keep up. Even the sports stadium of the future will increasingly become a competitor with television viewing "in terms of comfort, safety and the constant flow of audio-visual information and entertainment available". Other flow on effects of the shift are likely to include those on public architecture such as hospitals and nursing homes, where television, regarded as an essential entertainment service for patients and residents, will need to be replaced by access to the internet. At the same time, the ongoing need for entertainers as "professional engagers" shows the continuity of traditional entertainment.
Convergence.
By the second decade of the 21st century, analogue recording was being replaced by digital recording and all forms of electronic entertainment began to converge. For example, convergence is challenging standard practices in the film industry: whereas "success or failure used to be determined by the first weekend of its run. Today,Â ... a series of exhibition 'windows', such as DVD, pay-per-view, and fibre-optic video-on-demand are used to maximise profits." Part of the industry's adjustment is its release of new commercial product directly via video hosting services. Media convergence is said to be more than technological: the convergence is cultural as well. It is also "the result of a deliberate effort to protect the interests of business entities, policy institutions and other groups". Globalisation and cultural imperialism are two of the cultural consequences of convergence. Others include fandom and interactive storytelling as well as the way that single franchises are distributed through and impact on a range of delivery methods. The "greater diversity in the ways that signals may be received and packaged for the viewer, via terrestrial, satellite or cable television, and of course, via the Internet" also affects entertainment venues, such as sports stadia, which now need to be designed so that both live and remote audiences can interact in increasingly sophisticated ways â for example, audiences can "watch highlights, call up statistics", "order tickets and merchandise" and generally "tap into the stadium's resources at any time of the day or night".
The introduction of television altered the availability, cost, variety and quality of entertainment products for the public and the convergence of online entertainment is having a similar effect. For example, the possibility and popularity of user-generated content, as distinct from commercial product, creates a "networked audience model ha makes programming obsolete". Individuals and corporations use video hosting services to broadcast content that is equally accepted by the public as legitimate entertainment.
While technology increases demand for entertainment products and offers increased speed of delivery, the forms that make up the content are in themselves, relatively stable. Storytelling, music, theatre, dance and games are recognisably the same as in earlier centuries.

</doc>
<doc id="9263" url="https://en.wikipedia.org/wiki?curid=9263" title="Ether">
Ether

Ethers () are a class of organic compounds that contain an ether groupâan oxygen atom connected to two alkyl or aryl groupsâof general formula RâOâR'. These ethers can again be classified into two varieties: if the alkyl groups are the same on both sides of the oxygen atom, then it is a simple or symmetrical ether, whereas if they are different the ethers are called mixed or unsymmetrical ethers A typical example is the solvent and anesthetic diethyl ether, commonly referred to simply as "ether" (CH-CH-O-CH-CH). Ethers are common in organic chemistry and pervasive in biochemistry, as they are common linkages in carbohydrates and lignin.
Structure and bonding.
Ethers feature C-O-C linkage defined by a bond angle of about 110Â° and C-O distances of about 140 pm. The barrier to rotation about the C-O bonds is low. The bonding of oxygen in ethers, alcohols, and water is similar. In the language of valence bond theory, the hybridization at oxygen is sp.
Oxygen is more electronegative than carbon, thus the hydrogens alpha to ethers are more acidic than in simple hydrocarbons. They are far less acidic than hydrogens alpha to carbonyl groups (such as in ketones or aldehydes), however.
Nomenclature.
In the IUPAC nomenclature system, ethers are named using the general formula "alkoxyalkane", for example CH-CH-O-CH is methoxyethane. If the ether is part of a more complex molecule, it is described as an alkoxy substituent, so -OCH would be considered a "methoxy-" group. The simpler alkyl radical is written in front, so CH-O-CHCH would be given as "methoxy"(CHO)"ethane"(CHCH).
Trivial name.
IUPAC rules are often not followed for simple ethers. The trivial names for simple ethers (i.e. those with none or few other functional groups) are a composite of the two substituents followed by "ether." For example, ethyl methyl ether (CHOCH), diphenylether (CHOCH). As for other organic compounds, very common ethers acquired names before rules for nomenclature were formalized. Diethyl ether is simply called "ether," but was once called "sweet oil of vitriol". Methyl phenyl ether is anisole, because it was originally found in aniseed. The aromatic ethers include furans. Acetals (Î±-alkoxy ethers R-CH(-OR)-O-R) are another class of ethers with characteristic properties.
Polyethers.
Polyethers are compounds with more than one ether group.
The crown ethers are examples of small polyethers. Some toxins produced by dinoflagellates such as brevetoxin and ciguatoxin are extremely large and are known as "cyclic" or "ladder" polyethers.
Polyether generally refers to polymers which contain the ether functional group in their main chain. The term glycol is reserved for low to medium range molar mass polymer when the nature of the end-group, which is usually a hydroxyl group, still matters. The term "oxide" or other terms are used for high molar mass polymer when end-groups no longer affect polymer properties.
Aliphatic polyethers
Aromatic polyethers
The phenyl ether polymers are a class of polyethers containing aromatic cycles in their main chain: Polyphenyl ether (PPE) and Poly(p-phenylene oxide) (PPO).
Related compounds.
Many classes of compounds with C-O-C linkages are not considered ethers: Esters (R-C(=O)-O-R), hemiacetals (R-CH(-OH)-O-R), carboxylic acid anhydrides (RC(=O)-O-C(=O)R).
Physical properties.
Ether molecules cannot form hydrogen bonds with each other, resulting in relatively low boiling points compared to those of the analogous alcohols. The difference, however, in the boiling points of the ethers and their isomeric alcohols becomes lower as the carbon chains become longer, as the van der Waals interactions of the extended carbon chain dominates over the presence of hydrogen bonding.
Ethers are slightly polar. The C-O-C bond angle in the functional group is about 110Â°, and the C-O dipoles do not cancel out. Ethers are more polar than alkenes but not as polar as alcohols, esters, or amides of comparable structure. However, the presence of two lone pairs of electrons on the oxygen atoms makes hydrogen bonding with water molecules possible.
Cyclic ethers such as tetrahydrofuran and 1,4-dioxane are miscible in water because of the more exposed oxygen atom for hydrogen bonding as compared to linear aliphatic ethers.
Other properties are:
Reactions.
Ethers are quite stable chemical compounds which do not react with bases, active metals, dilute acids, oxidising agents and reducing agents. Generally, they are of low chemical reactivity, but they are more reactive than alkanes (epoxides, ketals, and acetals are unrepresentative classes of ethers and are discussed in separate articles). Important reactions are listed below.
Ether cleavage.
Although ethers resist hydrolysis, their polar bonds are cloven by mineral acids such as hydrobromic acid and hydroiodic acid. Hydrogen chloride cleaves ethers only slowly. Methyl ethers typically afford methyl halides:
These reactions proceed via onium intermediates, i.e. O(H)CH) is used as a catalyst for the reaction generating an ether with Markovnikov regiochemistry. Using similar reactions, tetrahydropyranyl ethers are used as protective groups for alcohols.
Preparation of epoxides.
Epoxides are typically prepared by oxidation of alkenes. The most important epoxide in terms of industrial scale is ethylene oxide, which is produced by oxidation of ethylene with oxygen. Other epoxides are produced by one of two routes:

</doc>
<doc id="9264" url="https://en.wikipedia.org/wiki?curid=9264" title="Ecliptic">
Ecliptic

The ecliptic is the apparent path of the Sun on the celestial sphere, and is the basis for the ecliptic coordinate system. It also refers to the plane of this path, which is coplanar with the orbit of Earth around the Sun (and hence the apparent orbit of the Sun around Earth).
The path of the Sun is not normally noticeable from Earth's surface because Earth rotates, carrying the observer through the cycles of sunrise and sunset, obscuring the apparent motion of the Sun with respect to the stars.
Sun's apparent motion.
The motions as described above are simplifications. Due to the movement of Earth around the EarthâMoon center of mass, the apparent path of the Sun wobbles slightly, with a period of about one month. Due to further perturbations by the other planets of the Solar System, the EarthâMoon barycenter wobbles slightly around a mean position in a complex fashion. The ecliptic is actually the apparent path of the Sun throughout the course of a year.
Because Earth takes one year to orbit the Sun, the apparent position of the Sun also takes the same length of time to make a complete circuit of the ecliptic. With slightly more than 365 days in one year, the Sun moves a little less than 1Â° eastward every day. This small difference in the Sun's position against the stars causes any particular spot on Earth's surface to catch up with (and stand directly north or south of) the Sun about four minutes later each day than it would if Earth would not orbit; a day on Earth is therefore 24 hours long rather than the approximately 23-hour 56-minute sidereal day. 
Again, this is a simplification, based on a hypothetical Earth that orbits at uniform speed around the Sun. The actual speed with which Earth orbits the Sun varies slightly during the year, so the speed with which the Sun seems to move along the ecliptic also varies. For example, the Sun is north of the celestial equator for about 185 days of each year, and south of it for about 180 days. The variation of orbital speed accounts for part of the equation of time.
Relationship to the celestial equator.
Because Earth's rotational axis is not perpendicular to its orbital plane, Earth's equatorial plane is not coplanar with the ecliptic plane, but is inclined to it by an angle of about 23.4Â°, which is known as the obliquity of the ecliptic. If the equator is projected outward to the celestial sphere, forming the celestial equator, it crosses the ecliptic at two points known as the equinoxes. The Sun, in its apparent motion along the ecliptic, crosses the celestial equator at these points, one from south to north, the other from north to south. The crossing from south to north is known as the vernal equinox, also known as the "first point of Aries" and the "ascending node of the ecliptic" on the celestial equator. The crossing from north to south is the autumnal equinox or descending node.
The orientation of Earth's axis and equator are not fixed in space, but rotate about the poles of the ecliptic with a period of about 26,000 years, a process known as "lunisolar precession", as it is due mostly to the gravitational effect of the Moon and Sun on Earth's equatorial bulge. Likewise, the ecliptic itself is not fixed. The gravitational perturbations of the other bodies of the Solar System cause a much smaller motion of the plane of Earth's orbit, and hence of the ecliptic, known as "planetary precession". The combined action of these two motions is called "general precession", and changes the position of the equinoxes by about 50 arc seconds (about 0Â°.014) per year.
Once again, this is a simplification. Periodic motions of the Moon and apparent periodic motions of the Sun (actually of Earth in its orbit) cause short-term small-amplitude periodic oscillations of Earth's axis, and hence the celestial equator, known as nutation.
This adds a periodic component to the position of the equinoxes; the positions of the celestial equator and (vernal) equinox with fully updated precession and nutation are called the "true equator and equinox"; the positions without nutation are the "mean equator and equinox".
Obliquity of the ecliptic.
Obliquity of the ecliptic is the term used by astronomers for the inclination of Earth's equator with respect to the ecliptic, or of Earth's rotation axis to a perpendicular to the ecliptic. It is about 23.4Â° and is currently decreasing 0.013 degrees (47 arcseconds) per hundred years due to planetary perturbations.
The angular value of the obliquity is found by observation of the motions of Earth and other planets over many years. Astronomers produce new fundamental ephemerides as the accuracy of observation improves and as the understanding of the dynamics increases, and from these ephemerides various astronomical values, including the obliquity, are derived.
Until 1983 the obliquity for any date was calculated from work of Newcomb, who analyzed positions of the planets until about 1895:
where is the obliquity and is tropical centuries from B1900.0 to the date in question.
From 1984, the Jet Propulsion Laboratory's DE series of computer-generated ephemerides took over as the fundamental ephemeris of the "Astronomical Almanac". Obliquity based on DE200, which analyzed observations from 1911 to 1979, was calculated:
where hereafter is Julian centuries from J2000.0.
JPL's fundamental ephemerides have been continually updated. The "Astronomical Almanac" for 2010 specifies:
These expressions for the obliquity are intended for high precision over a relatively short time span, perhaps several centuries. 
J. Laskar computed an expression to order good to /1000 years over 10,000 years.
All of these expressions are for the "mean" obliquity, that is, without the nutation of the equator included. The "true" or instantaneous obliquity includes the nutation.
Plane of the Solar System.
Most of the major bodies of the Solar System orbit the Sun in nearly the same plane. This is likely due to the way in which the Solar System formed from a protoplanetary disk. Probably the closest current representation of the disk is known as the "invariable plane of the Solar System". Earth's orbit, and hence, the ecliptic, is inclined a little more than 1Â° to the invariable plane, and the other major planets are also within about 6Â° of it. Because of this, most Solar System bodies appear very close to the ecliptic in the sky. The ecliptic is well defined by the motion of the Sun. The invariable plane is defined by the angular momentum of the entire Solar System, essentially the summation of all of the orbital motions and rotations of all the bodies of the system, a somewhat uncertain value that requires precise knowledge of every object in the system. For these reasons, the ecliptic is used as the reference plane of the Solar System out of convenience.
Celestial reference plane.
The ecliptic forms one of the two fundamental planes used as reference for positions on the celestial sphere, the other being the celestial equator. Perpendicular to the ecliptic are the ecliptic poles, the north ecliptic pole being the pole north of the equator. Of the two fundamental planes, the ecliptic is closer to unmoving against the background stars, its motion due to planetary precession being roughly 1/100 that of the celestial equator.
Spherical coordinates, known as ecliptic longitude and latitude or celestial longitude and latitude, are used to specify positions of bodies on the celestial sphere with respect to the ecliptic. Longitude is measured positively eastward 0Â° to 360Â° along the ecliptic from the vernal equinox, the same direction in which the Sun appears to move. Latitude is measured perpendicular to the ecliptic, to +90Â° northward or -90Â° southward to the poles of the ecliptic, the ecliptic itself being 0Â° latitude. For a complete spherical position, a distance parameter is also necessary. Different distance units are used for different objects. Within the Solar System, astronomical units are used, and for objects near Earth, Earth radii or kilometers are used. A corresponding right-handed rectangular coordinate system is also used occasionally; the "x"-axis is directed toward the vernal equinox, the "y"-axis 90Â° to the east, and the "z"-axis toward the north ecliptic pole; the astronomical unit is the unit of measure. Symbols for ecliptic coordinates are somewhat standardized; see the table.
Ecliptic coordinates are convenient for specifying positions of Solar System objects, as most of the planets' orbits have small inclinations to the ecliptic, and therefore always appear relatively close to it on the sky. Because Earth's orbit, and hence the ecliptic, moves very little, it is a relatively fixed reference with respect to the stars.
Because of the precessional motion of the equinox, the ecliptic coordinates of objects on the celestial sphere are continuously changing. Specifying a position in ecliptic coordinates requires specifying a particular equinox, that is, the equinox of a particular date, known as an epoch; the coordinates are referred to the direction of the equinox at that date. For instance, the "Astronomical Almanac" lists the heliocentric position of Mars at 0h Terrestrial Time, 4 Jan 2010 as: longitude 118Â° 09' 15".8, latitude +1Â° 43' 16".7, true heliocentric distance 1.6302454 AU, mean equinox and ecliptic of date. This specifies the mean equinox of 4 Jan 2010 0h TT as above, without the addition of nutation.
Eclipses.
Because the orbit of the Moon is inclined only about 5Â° to the ecliptic and the Sun is always very near the ecliptic, eclipses always occur on or near it. Because of the inclination of the Moon's orbit, eclipses do not occur at every conjunction and opposition of the Sun and Moon, but only when the Moon is near an ascending or descending node at the same time it is at conjunction or opposition. The ecliptic is so named because the ancients noted that eclipses only occurred when the Moon crossed it.
Equinoxes and solstices.
The exact instants of equinoxes or solstices are the times when the apparent ecliptic longitude (including the effects of aberration and nutation) of the Sun is 0Â°, 90Â°, 180Â°, or 270Â°. Because of perturbations of Earth's orbit and peculiarities of the calendar, the dates of these are not fixed.
In the constellations.
The ecliptic currently passes through the following constellations:
Astrology.
The ecliptic forms the center of a band about 20Â° wide called the zodiac, on which the Sun, Moon, and planets are seen always to move. 
Traditionally, this region is divided into 12 signs of 30Â° longitude, each of which approximates the Sun's motion through one month.
In ancient times the signs corresponded roughly to 12 of the constellations that straddle the ecliptic.
These signs give us some of the terminology used today. The "first point of Aries" was named when the vernal equinox was actually in the constellation Aries; it has since moved into Pisces.

</doc>
<doc id="9269" url="https://en.wikipedia.org/wiki?curid=9269" title="List of former sovereign states">
List of former sovereign states

This page lists sovereign states, countries, nations, empires or territories that have ceased to exist as political entities, grouped geographically and by constitutional nature.
Criteria for inclusion.
The criteria for inclusion in this list is similar to that of the List of states with limited recognition. To be included here, a polity must have claimed statehood and either:
For purposes of this list, the cutoff between medieval and early modern states is the Fall of Constantinople in 1453.
Modern states and territories by geography.
Asia.
South Asia.
In the Indian subcontinent:
Europe.
Nordic countries.
In the Nordic countries, unions were personal, not unitary
Significant territory changes occurred in the overseas possessions of the UK, referred to as the British Empire at times during the period 1497â1997.
Modern states and territories by type.
Former colonies, possessions, protectorates and territories.
These were all colonies, League of Nations mandates, or United Nations trust territories, most of which were renamed after their independence.
Dismembered countries.
These states are now dissolved into a number of states, none of which retain the old name.
Renamed countries.
These country names have been replaced. Only major and/or famous cases are listed, there are thousands of relatively obscure former names.
Nominally independent homelands of South Africa.
Four of the homelands, or bantustans, for black South Africans, were granted nominal independence from South Africa. Not recognised by other nations, these puppet states were re-incorporated in 1994.
Secessionist states.
These nations declared themselves independent, but failed to achieve it in fact or did not seek permanent independence and were either re-incorporated into the mother country or incorporated into another country.
Annexed countries.
These nations, once separate, are now part of another country. Cases of voluntary accession are included.

</doc>
<doc id="9277" url="https://en.wikipedia.org/wiki?curid=9277" title="Ellipse">
Ellipse

In mathematics, an ellipse is a curve on a plane that surrounds two focal points such that the sum of the distances to the two focal points is constant for every point on the curve. As such, it is a generalization of a circle, which is a special type of an ellipse that has both focal points at the same location. The shape of an ellipse (how 'elongated' it is) is represented by its eccentricity, which for an ellipse can be any number from 0 (the limiting case of a circle) to arbitrarily close to but less than 1.
Ellipses are the closed type of conic section: a plane curve that results from the intersection of a cone by a plane. (See figure to the right.) Ellipses have many similarities with the other two forms of conic sections: the parabolas and the hyperbolas, both of which are open and unbounded. The cross section of a cylinder is an ellipse, unless the section is parallel to the axis of the cylinder.
Analytically, an ellipse can also be defined as the set of points such that the ratio of the distance of each point on the curve from a given point (called a focus or focal point) to the distance from that same point on the curve to a given line (called the directrix) is a constant, called the eccentricity of the ellipse.
Ellipses are common in physics, astronomy and engineering. For example, the orbit of each planet in the solar system is approximately an ellipse with the barycenter of the planet-Sun pair at one of the focal points. The same is true for moons orbiting planets and all other systems having two astronomical bodies. The shape of planets and stars are often well described by ellipsoids. Ellipses also arise as images of a circle under parallel projection and the bounded cases of perspective projection, which are simply intersections of the projective cone with the plane of projection. It is also the simplest Lissajous figure, formed when the horizontal and vertical motions are sinusoids with the same frequency. A similar effect leads to elliptical polarization of light in optics.
The name, á¼Î»Î»ÎµÎ¹ÏÎ¹Ï (Ã©lleipsis, "omission"), was given by Apollonius of Perga in his "Conics", emphasizing the connection of the curve with "application of areas".
Elements of an ellipse.
Ellipses have two perpendicular axes about which the ellipse is symmetric. These axes intersect at the center of the ellipse due to this symmetry. The larger of these two axes, which corresponds to the larger distance between antipodal points on the ellipse, is called the major axis (in the figure to the right it is represented by the line segment between the point labeled âa and the point labeled a). The smaller of these two axes, and the smaller distance between antipodal points on the ellipse, is called the minor axis.
(in the figure to the right it is represented by the line segment between the point labeled âb to the point labeled b).
The semi-major axis (denoted by "a" in the figure) and the semi-minor axis (denoted by "b" in the figure) are one half of the major and minor axes, respectively. These are sometimes called (especially in technical fields) the major and minor semi-axes, the major and minor semiaxes, or major radius and minor radius.
The four points where these axes cross the ellipse are the vertices and are marked as a, âa, b, and âb. In addition to being at the largest and smallest distance from the center, these points are where the curvature of the ellipse is maximum and minimum.
The two foci (the term focal points is also used) of an ellipse are two special points "F" and "F" on the ellipse's major axis that are equidistant from the center point. The sum of the distances from any point P on the ellipse to those two foci is constant and equal to the major axis ("PF"Â +Â "PF"Â =Â 2"a") (in the figure to the right this corresponds to the sum of the two green lines equaling the length of the major axis that goes from âa to a).
The distance to the focal point from the center of the ellipse is sometimes called the linear eccentricity, "f", of the ellipse. Here it is denoted by "f", but it is often denoted by "c". Due to the Pythagorean theorem and the definition of the ellipse explained in the previous paragraph: "f"Â =Â "a"Â â"b".
A second equivalent method of constructing an ellipse using a directrix is shown on the plot as the three blue lines. (See the Directrix section of this article for more information about this method). The dashed blue line is the directrix of the ellipse shown.
The eccentricity of an ellipse, usually denoted by "Îµ" or "e", is the ratio of the distance between the two foci, to the length of the major axis or "e"Â =Â 2"f"/2"a"Â =Â "f"/"a". For an ellipse the eccentricity is between 0 and 1 (0Â <Â "e"Â <Â 1). When the eccentricity is 0 the foci coincide with the center point and the figure is a circle. As the eccentricity tends toward 1, the ellipse gets a more elongated shape. It tends towards a line segment (see below) if the two foci remain a finite distance apart and a parabola if one focus is kept fixed as the other is allowed to move arbitrarily far away. The eccentricity is also equal to the ratio of the distance (such as the (blue) line "PF") from any particular point on an ellipse to one of the foci to the perpendicular distance to the directrix from the same point (line "PD"), "e"Â =Â "PF"/"PD".
Drawing ellipses.
Pins-and-string method.
The characterization of an ellipse as the locus of points so that sum of the distances to the foci is constant leads to a method of drawing one using two drawing pins, a length of string, and a pencil. In this method, pins are pushed into the paper at two points, which become the ellipse's foci. A string tied at each end to the two pins and the tip of a pen pulls the loop taut to form a triangle. The tip of the pen then traces an ellipse if it is moved while keeping the string taut. Using two pegs and a rope, gardeners use this procedure to outline an elliptical flower bedâthus it is called the "gardener's ellipse".
Trammel method.
An ellipse can also be drawn using a ruler, a set square, and a pencil:
The trammel of Archimedes, or ellipsograph, is a mechanical device that implements this principle. The ruler is replaced by a rod with a pencil holder (point "C") at one end, and two adjustable side pins (points "A" and "B") that slide into two perpendicular slots cut into a metal plate. The mechanism can be used with a router to cut ellipses from board material. The mechanism is also used in a toy called the "nothing grinder".
Parallelogram method.
In the parallelogram method, an ellipse is constructed point by point using equally spaced points on two horizontal lines and equally spaced points on two vertical lines. It is based on Steiner's theorem on the generation of conic sections. Similar methods exist for the parabola and hyperbola.
Mathematical definitions and properties.
In Euclidean geometry.
Definition.
In Euclidean geometry, the ellipse is usually defined as the bounded case of a conic section, or as the set of points such that the sum of the distances to two fixed points (the foci) is constant. The ellipse can also be defined as the set of points such that the distance from any point in that set to a given point in the plane (a focus) is a constant positive fraction less than 1 (the eccentricity) of the perpendicular distance of the point in the set to a given line (called the directrix). Yet another equivalent definition of the ellipse is that it is the set of points that are equidistant from one point in the plane (a focus) and a particular circle, the directrix circle (whose center is the other focus).
The equivalence of these definitions can be proved using the Dandelin spheres.
Equations.
The equation of an ellipse whose major and minor axes coincide with the Cartesian axes is
formula_1. This can be explained as follows. If we let an independent parameter formula_2 increase from 0 to 2Ï, and let
and
then plotting "x" and "y" values for all angles of Î¸ results in an ellipse. Note that formula_2 is the eccentric anomaly and is not the angle traced out by a point on the ellipse (see below). For example, at Î¸ = 0, "x" = a, "y" = 0 and at Î¸ = Ï/2, "y" = b, "x" = 0. This can be seen as follows.
Squaring both equations gives:
And
Dividing these two equations by "a" and "b" respectively gives:
And
Adding these two equations together gives:
Applying the Pythagorean identity to the right hand side gives:
This means any noncircular ellipse is a compressed (or stretched) circle. If a circle is treated like an ellipse, then the area of the ellipse would be proportional to the length of either axis (i.e. doubling the length of an axis in a circular ellipse would create an ellipse with double the area of the original circle).
Focus.
The distance from the center "C" to either focus is "f" = "ae", which can be expressed in terms of the major and minor radii:
The sum of the distances from any point "P" = "P"("x,y") on the ellipse to those two foci is constant and equal to the major axis (proof): 
Eccentricity.
The eccentricity of the ellipse (commonly denoted as either "e" or formula_14) is
(where again "a" and "b" are one-half of the ellipse's major and minor axes respectively, and f is the focal distance) or, as expressed in terms using the flattening factor formula_16
Other formulas for the eccentricity of an ellipse are listed in the article on eccentricity of conic sections.
Formulas for the eccentricity of an ellipse that is expressed in the more general quadratic form are described in the article dedicated to conic sections.
Directrix.
Each focus "F" of the ellipse is associated with a line parallel to the minor axis called a directrix. Refer to the illustration on the right, in which the ellipse is centered at the origin. The distance from any point "P" on the ellipse to the focus "F" is a constant fraction of that point's perpendicular distance to the directrix, resulting in the equality "e" = "PF"/"PD". The ratio of these two distances is the eccentricity of the ellipse. This property (which can be proved using the Dandelin spheres) can be taken as another definition of the ellipse.<br>
Besides the well-known ratio "e" = "f"/"a", where "f" is the distance from the center to the focus and "a" is the distance from the center to the farthest vertices (most sharply curved points of the ellipse), it is also true that "e" = "a"/"d", where "d" is the distance from the center to the directrix.
Circular directrix.
The ellipse can also be defined as the set of points that are equidistant from one focus and a circle, the directrix circle, that is centered on the other focus. The radius of the directrix circle equals the ellipse's major axis, so the focus and the entire ellipse are inside the directrix circle.
Ellipse as hypotrochoid.
The ellipse is a special case of the hypotrochoid whenÂ "R"Â =Â 2"r", as shown in the image to the right.
Area.
The area formula_18 enclosed by an ellipse is:
where "a" and "b" are the semi-major and semi-minor axes (half of the ellipse's major and minor axes), respectively.
An ellipse defined implicitly by formula_20 has area formula_21.
The area formula "Ïab" is intuitive: start with a circle of radius "b" (so its area is Ï"b") and stretch it by a factor "a"/"b" to make an ellipse. This intuitively justifies the area by the same factor: Ï"b"("a"/"b") = Ï"ab". However, a more rigorous proof requires integration as follows:
For the ellipse in standard form, formula_22, and hence formula_23, with horizontal intercepts at Â± "a", the area formula_18 can be computed as twice the integral of the positive square root:
The second integral is the area of a circle of radius formula_26, i.e.,
formula_27; thus we have:
The area formula can also be proven in terms of polar coordinates using the coordinate transformation
formula_29
Any point inside the ellipse with "x"-intercept "a" and "y"-intercept "b" can be defined in terms of "r" and formula_2, where formula_31 and formula_32.
To define the area differential in such coordinates we use the Jacobian matrix of the coordinate transformation times formula_33:
We now integrate over the ellipse to find the area:
Circumference.
The circumference formula_36 of an ellipse is:
where again "a" is the length of the semi-major axis, "e" is the eccentricity formula_38, and the function formula_39 is the complete elliptic integral of the second kind,
which calculates the circumference of the ellipse in the first quadrant alone, and the formula for the circumference of an ellipse can thus be written
The arc length of an ellipse, in general, has no closed-form solution in terms of elementary functions. Elliptic integrals were motivated by this problem. Equation () may be evaluated directly using the Carlson symmetric form. This gives a succinct and rapidly converging method for evaluating the circumference.
The exact infinite series is:
or
where formula_43 is the double factorial.
Unfortunately, this series converges rather slowly; however, by expanding in terms of formula_44,
Ivory
and
Bessel
derived an expression that converges much more rapidly,
Ramanujan gives two good approximations for the circumference in Â§16 of "Modular Equations and Approximations to Ï"; they are
and
The errors in these approximations, which were obtained empirically, are of order formula_48 and formula_49, respectively.
More generally, the arc length of a portion of the circumference, as a function of the angle subtended, is given by an incomplete elliptic integral.
The inverse function, the angle subtended as a function of the arc length, is given by the elliptic functions.
Some lower and upper bounds on the circumference of the canonical ellipse formula_50 with "a" â¥"b" are
Here the upper bound formula_54 is the circumference of a circumscribed concentric circle passing through the endpoints of the ellipse's major axis, and the lower bound formula_55 is the perimeter of an inscribed rhombus with vertices at the endpoints of the major and minor axes.
Chords.
The midpoints of a set of parallel chords of an ellipse are collinear.
Latus rectum.
The chords of an ellipse that are perpendicular to the major axis and pass through one of its foci are called the latera recta of the ellipse. The length of each latus rectum is .
Curvature.
The curvature is given by formula_56
Angle bisection property.
A local normal (perpendicular) to the ellipse at any point "P" bisects the angle formula_57 to the foci. This is evident graphically in the parallelogram method of construction, and can be proven analytically, for example by using the parametric form in canonical position, as given below.
Reflexive property.
When a ray of light originating from one focus reflects off the inner surface of an ellipse, it always passes through the other focus.
In projective geometry.
In a projective geometry defined over a field, a conic section can be defined as the set of all points of intersection between corresponding lines of two pencils of lines in a plane that are related by a projective, but not perspective, map (see Steiner's theorem). By projective duality, a conic section can also be defined as the envelope of all lines that connect corresponding points of two lines related by a projective, but not perspective, map.
In a pappian projective plane (one defined over a field), all conic sections are equivalent to each other, and the different types of conic sections are determined by how they intersect the line at infinity, denoted by Î©. An ellipse is a conic section that does not intersect this line. A parabola is a conic section that is tangent to Î©, and a hyperbola is one that crosses Î© twice. Since an ellipse does not intersect the line at infinity, it properly belongs to the affine plane determined by removing the line at infinity and all of its points from the projective plane.
Affine space.
An ellipse is also the result of projecting a circle, sphere, or ellipse in a three dimensional affine space onto a plane (flat), by parallel lines. This is a special case of conical (perspective) projection of any of those geometric objects in the affine space from a point "O" onto a plane "P", when the point "O" lies in the plane at infinity of the affine space. In the setting of pappian projective planes, the image of an ellipse by any affine map (a projective map that leaves the line at infinity invariant) is an ellipse, and, more generally, the image of an ellipse by any projective map "M" such that the line "M"(Î©) does not touch or cross the ellipse is an ellipse.
In analytic geometry.
General ellipse.
In analytic geometry, the ellipse is defined as the set of points formula_58 of the Cartesian plane that, in non-degenerate cases, satisfy the implicit equation
provided formula_60
To distinguish the degenerate cases from the non-degenerate case, let "â" be the determinant
that is,
Then the ellipse is a non-degenerate real ellipse if and only if "Câ" < 0. If "Câ" > 0, we have an imaginary ellipse, and if "â" = 0, we have a point ellipse.
The general equation's coefficients can be obtained from known semi-major axis formula_26, semi-minor axis formula_64, center coordinates formula_65 and rotation angle formula_66 using the following formulae:
These expressions can be derived from the canonical equation (see next section) by substituting the coordinates with expressions for rotation and translation of the coordinate system:
Canonical form.
Let formula_71. Through change of coordinates (a rotation of axes and a translation of axes) the general ellipse can be described by the canonical implicit equation
Here formula_73 are the point coordinates in the canonical system, whose origin is the center formula_74 of the ellipse, whose formula_75-axis is the unit vector formula_76 coinciding with the major axis, and whose formula_77-axis is the perpendicular vector formula_78 coinciding with the minor axis. That is, formula_79 and formula_80.
In this system, the center is the origin formula_81 and the foci are formula_82 and formula_83.
Any ellipse can be obtained by rotation and translation of a canonical ellipse with the proper semi-diameters. The expression of an ellipse centered at formula_74 is
Moreover, any canonical ellipse can be obtained by scaling the unit circle of formula_86, defined by the equation
by factors "a" and "b" along the two axes.
For an ellipse in canonical form, we have
The distances from a point formula_58 on the ellipse to the left and right foci are formula_90 and formula_91, respectively.
Line segment as a type of degenerate ellipse.
A line segment is a degenerate ellipse with semi-minor axis = 0 and eccentricity = 1, and with the focal points at the ends. Although the eccentricity is 1 this is not a parabola. A radial elliptic trajectory is a non-trivial special case of an elliptic orbit, where the ellipse is a line segment.
In trigonometry.
General parametric form.
An ellipse in general position can be expressed parametrically as the path of a point formula_92, where
as the parameter "t" varies from 0 to 2"Ï". Here formula_74 is the center of the ellipse, and formula_96 is the angle between the formula_97-axis and the major axis of the ellipse.
Parametric form in canonical position.
For an ellipse in canonical position (center at origin, major axis along the "X"-axis), the equation simplifies to 
The parameter "t" (called the eccentric anomaly in astronomy) is "not" the angle of formula_92 with the "X"-axis (see diagram at right).
For a given point on an ellipse, formulae connecting the tangential angle formula_101, the polar angle from the ellipse center formula_2, and the parametric angle "t" are:
Polar form relative to center.
In polar coordinates, with the origin at the center of the ellipse and with the angular coordinate formula_2 measured from the major axis, the ellipse's equation is
Polar form relative to focus.
If instead we use polar coordinates with the origin at one focus, with the angular coordinate formula_107 still measured from the major axis, the ellipse's equation is
where the sign in the denominator is negative if the reference direction formula_107 points towards the center (as illustrated on the right), and positive if that direction points away from the center.
In the slightly more general case of an ellipse with one focus at the origin and the other focus at angular coordinate formula_101, the polar form is
The angle formula_2 in these formulas is called the true anomaly of the point. The numerator formula_113 of these formulas is the semi-latus rectum of the ellipse, usually denoted formula_114. It is the distance from a focus of the ellipse to the ellipse itself, measured along a line perpendicular to the major axis.
General polar form.
The following equation on the polar coordinates ("r",Â "Î¸") describes a general ellipse with semidiameters "a" and "b", centered at a point ("r",Â "Î¸"), with the "a" axis rotated by "Ï" relative to the polar axis:
where "r" is the radius or central distance, and
Angular eccentricity.
The angular eccentricity formula_119 is the angle whose sine is the eccentricity "e"; that is,
As a parametric rational polynomial.
An ellipse can be parameterized as a rational quadratic polynomial, in other words described by the equations formula_121 and formula_122 where formula_123 and formula_124 are quadratic polynomials in formula_125 The tangent half-angle identities
imply formula_127 and this implies
Substituting this equation for formula_129 into the first tangent half-angle identity yields
Substituting these values for formula_131 and formula_129 into the trigonometric parameterization above yields
For formula_134 this formula represents the quarter ellipse centered at the origin with radii formula_26 and formula_64 moving counter-clockwise with increasing formula_137 It is easy to test this by computing formula_138 and formula_139
Degrees of freedom.
An ellipse in the plane has five degrees of freedom (the same as a general conic section), defining its vertical and horizontal position, orientation, shape, and scale. In comparison, circles have only three degrees of freedom (horizontal position, vertical position and scale), while parabolae have four. Said another way, the set of all ellipses in the plane, with any natural metric (such as the Hausdorff distance) is a five-dimensional manifold.
The five degrees of freedom can be identified with, for example, the coefficients "A","B","C","D","E" of the implicit equation, or with the coefficients "X", "Y", "Ï", "a", "b" of the general parametric form. Thus an ellipse is uniquely determined by any five points lying on it.
Applications.
Ellipses in physics.
Elliptical reflectors and acoustics.
If the water's surface is disturbed at one focus of an elliptical water tank, the circular waves of that disturbance, after reflecting off the walls, converge simultaneously to a single point: the "second focus". This is a consequence of the total travel length being the same along any wall-bouncing path between the two foci.
Similarly, if a light source is placed at one focus of an elliptic mirror, all light rays on the plane of the ellipse are reflected to the second focus. Since no other smooth curve has such a property, it can be used as an alternative definition of an ellipse. (In the special case of a circle with a source at its center all light would be reflected back to the center.) If the ellipse is rotated along its major axis to produce an ellipsoidal mirror (specifically, a prolate spheroid), this property holds for all rays out of the source. Alternatively, a cylindrical mirror with elliptical cross-section can be used to focus light from a linear fluorescent lamp along a line of the paper; such mirrors are used in some document scanners.
Sound waves are reflected in a similar way, so in a large elliptical room a person standing at one focus can hear a person standing at the other focus remarkably well. The effect is even more evident under a vaulted roof shaped as a section of a prolate spheroid. Such a room is called a "whisper chamber". The same effect can be demonstrated with two reflectors shaped like the end caps of such a spheroid, placed facing each other at the proper distance. Examples are the National Statuary Hall at the United States Capitol (where John Quincy Adams is said to have used this property for eavesdropping on political matters); the Mormon Tabernacle at Temple Square in Salt Lake City, Utah; at an exhibit on sound at the Museum of Science and Industry in Chicago; in front of the University of Illinois at Urbana-Champaign Foellinger Auditorium; and also at a side chamber of the Palace of Charles V, in the Alhambra.
Planetary orbits.
In the 17th century, Johannes Kepler discovered that the orbits along which the planets travel around the Sun are ellipses with the Sun pproximatel at one focus, in his first law of planetary motion. Later, Isaac Newton explained this as a corollary of his law of universal gravitation.
More generally, in the gravitational two-body problem, if the two bodies are bound to each other (i.e., the total energy is negative), their orbits are similar ellipses with the common barycenter being one of the foci of each ellipse. The other focus of either ellipse has no known physical significance. Interestingly, the orbit of either body in the reference frame of the other is also an ellipse, with the other body at the same focus.
Keplerian elliptical orbits are the result of any radially directed attraction force whose strength is inversely proportional to the square of the distance. Thus, in principle, the motion of two oppositely charged particles in empty space would also be an ellipse. (However, this conclusion ignores losses due to electromagnetic radiation and quantum effects, which become significant when the particles are moving at high speed.)
For elliptical orbits, useful relations involving the eccentricity formula_140 are:
where
Also, in terms of formula_142 and formula_143, the semi-major axis formula_26 is their arithmetic mean, the semi-minor axis formula_64 is their geometric mean, and the semi-latus rectum formula_114 is their harmonic mean. In other words,
Harmonic oscillators.
The general solution for a harmonic oscillator in two or more dimensions is also an ellipse. Such is the case, for instance, of a long pendulum that is free to move in two dimensions; of a mass attached to a fixed point by a perfectly elastic spring; or of any object that moves under influence of an attractive force that is directly proportional to its distance from a fixed attractor. Unlike Keplerian orbits, however, these "harmonic orbits" have the center of attraction at the geometric center of the ellipse, and have fairly simple equations of motion.
Phase visualization.
In electronics, the relative phase of two sinusoidal signals can be compared by feeding them to the vertical and horizontal inputs of an oscilloscope. If the display is an ellipse, rather than a straight line, the two signals are out of phase.
Elliptical gears.
Two non-circular gears with the same elliptical outline, each pivoting around one focus and positioned at the proper angle, turn smoothly while maintaining contact at all times. Alternatively, they can be connected by a link chain or timing belt, or in the case of a bicycle the main chainring may be elliptical, or an ovoid similar to an ellipse in form. Such elliptical gears may be used in mechanical equipment to produce variable angular speed or torque from a constant rotation of the driving axle, or in the case of a bicycle to allow a varying crank rotation speed with inversely varying mechanical advantage.
Elliptical bicycle gears make it easier for the chain to slide off the cog when changing gears.
An example gear application would be a device that winds thread onto a conical bobbin on a spinning machine. The bobbin would need to wind faster when the thread is near the apex than when it is near the base.
Ellipses in statistics and finance.
In statistics, a bivariate random vector ("X", "Y") is jointly elliptically distributed if its iso-density contours â loci of equal values of the density function â are ellipses. The concept extends to an arbitrary number of elements of the random vector, in which case in general the iso-density contours are ellipsoids. A special case is the multivariate normal distribution. The elliptical distributions are important in finance because if rates of return on assets are jointly elliptically distributed then all portfolios can be characterized completely by their mean and variance â that is, any two portfolios with identical mean and variance of portfolio return have identical distributions of portfolio return.
Ellipses in computer graphics.
Drawing an ellipse as a graphics primitive is common in standard display libraries, such as the MacIntosh QuickDraw API, and Direct2D on Windows. Jack Bresenham at IBM is most famous for the invention of 2D drawing primitives, including line and circle drawing, using only fast integer operations such as addition and branch on carry bit. M. L. V. Pitteway extended Bresenham's algorithm for lines to conics in 1967. Another efficient generalization to draw ellipses was invented in 1984 by Jerry Van Aken.
In 1970 Danny Cohen presented at the "Computer Graphics 1970" conference in England a linear algorithm for drawing ellipses and circles. In 1971, L. B. Smith published similar algorithms for all conic sections and proved them to have good properties. These algorithms need only a few multiplications and additions to calculate each vector.
It is beneficial to use a parametric formulation in computer graphics because the density of points is greatest where there is the most curvature. Thus, the change in slope between each successive point is small, reducing the apparent "jaggedness" of the approximation.
Drawing with BÃ©zier paths.
Composite BÃ©zier curves may also be used to draw an ellipse to sufficient accuracy, since any ellipse may be construed as an affine transformation of a circle. The spline methods used to draw a circle may be used to draw an ellipse, since the constituent BÃ©zier curves behave appropriately under such transformations.
Drawing with three points of a parallelogram.
Rytzâs construction can be used to find the minor and major axes and their angle of an ellipse from conjugate diameters (which can be seen as three points of a parallelogram). The method uses the conjugate diameters of an ellipse to map the ellipse to an unit circle under affine transformation and calculate the ellipse parameters from that.
Ellipses in optimization theory.
It is sometimes useful to find the minimum bounding ellipse on a set of points. The ellipsoid method is quite useful for attacking this problem.

</doc>
<doc id="9278" url="https://en.wikipedia.org/wiki?curid=9278" title="Extension">
Extension

Extension, extend or extended may refer to:

</doc>
<doc id="9279" url="https://en.wikipedia.org/wiki?curid=9279" title="Elephant">
Elephant

Elephants are large mammals of the family Elephantidae and the order Proboscidea. Two species are traditionally recognised, the African elephant ("Loxodonta africana") and the Asian elephant ("Elephas maximus"), although some evidence suggests that African bush elephants and African forest elephants are separate species ("L.Â africana" and "L.Â cyclotis" respectively). Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia. Elephantidae is the only surviving family of the order Proboscidea; other, now extinct, members of the order include deinotheres, gomphotheres, mammoths, and mastodons. Male African elephants are the largest extant terrestrial animals and can reach a height of and weigh . All elephants have several distinctive features the most notable of which is a long trunk or proboscis, used for many purposes, particularly breathing, lifting water and grasping objects. Their incisors grow into tusks, which can serve as weapons and as tools for moving objects and digging. Elephants' large ear flaps help to control their body temperature. Their pillar-like legs can carry their great weight. African elephants have larger ears and concave backs while Asian elephants have smaller ears and convex or level backs.
Elephants are herbivorous and can be found in different habitats including savannahs, forests, deserts and marshes. They prefer to stay near water. They are considered to be keystone species due to their impact on their environments. Other animals tend to keep their distance where predators such as lions, tigers, hyenas, and wild dogs usually target only the young elephants (or "calves"). Females ("cows") tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups are led by an individual known as the matriarch, often the oldest cow. Elephants have a fissionâfusion society in which multiple family groups come together to socialise. Males ("bulls") leave their family groups when they reach puberty, and may live alone or with other males. Adult bulls mostly interact with family groups when looking for a mate and enter a state of increased testosterone and aggression known as musth, which helps them gain dominance and reproductive success. Calves are the centre of attention in their family groups and rely on their mothers for as long as three years. Elephants can live up to 70 years in the wild. They communicate by touch, sight, smell and sound; elephants use infrasound, and seismic communication over long distances. Elephant intelligence has been compared with that of primates and cetaceans. They appear to have self-awareness and show empathy for dying or dead individuals of their kind.
African elephants are listed as vulnerable by the International Union for Conservation of Nature (IUCN), while the Asian elephant is classed as endangered. One of the biggest threats to elephant populations is the ivory trade, as the animals are poached for their ivory tusks. Other threats to wild elephants include habitat destruction and conflicts with local people. Elephants are used as working animals in Asia. In the past they were used in war; today, they are often controversially put on display in zoos, or exploited for entertainment in circuses. Elephants are highly recognisable and have been featured in art, folklore, religion, literature and popular culture.
Etymology.
The word "elephant" is based on the Latin "elephas" (genitive "elephantis") ("elephant"), which is the Latinised form of the Greek á¼Î»Î­ÏÎ±Ï ("elephas") (genitive á¼Î»Î­ÏÎ±Î½ÏÎ¿Ï ("elephantos")), probably from a non-Indo-European language, likely Phoenician. It is attested in Mycenaean Greek as "e-re-pa" and "e-re-pa-to" in Linear B syllabic script. As in Mycenaean Greek, Homer used the Greek word to mean ivory, but after the time of Herodotus, it also referred to the animal. The word "elephant" appears in Middle English as "olyfaunt" (c.1300) and was borrowed from Old French "oliphant" (12th century). The Tamil word is "aliyan" for elephant. In Swahili elephants are known as "Ndovu" or "Tembo". In Sanskrit the elephant is called "hastin", while in Hindi it is known as "hÄthÄ«" . Babylonians called the animal "pÄ«ru", from which the Middle Persian word for "elephant" "pil" derives. It was Arabicized as "fÄ«l", and was then borrowed from Arabic into Old Norse as "fil" ("fÃ­ll" in Icelandic). "Loxodonta", the generic name for the African elephants, is Greek for "oblique-sided tooth".
Taxonomy.
Classification, species and subspecies.
Elephants belong to the family Elephantidae, the sole remaining family within the order Proboscidea. Their closest extant relatives are the sirenians (dugongs and manatees) and the hyraxes, with which they share the clade Paenungulata within the superorder Afrotheria. Elephants and sirenians are further grouped in the clade Tethytheria. Traditionally, two species of elephants are recognised; the African elephant ("Loxodonta africana") of sub-Saharan Africa, and the Asian elephant ("Elephas maximus") of South and Southeast Asia. African elephants have larger ears, a concave back, more wrinkled skin, a sloping abdomen and two finger-like extensions at the tip of the trunk. Asian elephants have smaller ears, a convex or level back, smoother skin, a horizontal abdomen that occasionally sags in the middle and one extension at the tip of the trunk. The looped ridges on the molars are narrower in the Asian elephant while those of the African are more diamond-shaped. The Asian elephant also has dorsal bumps on its head and some patches of depigmentation on its skin. In general, African elephants are larger than their Asian cousins.
Swedish zoologist Carl Linnaeus first described the genus "Elephas" and an elephant from Sri Lanka (then known as Ceylon) under the binomial "Elephas maximus" in 1758. In 1798, Georges Cuvier classified the Indian elephant under the binomial "Elephas indicus". Dutch zoologist Coenraad Jacob Temminck described the Sumatran elephant in 1847 under the binomial "Elephas sumatranus". English zoologist Frederick Nutter Chasen classified all three as subspecies of the Asian elephant in 1940. Asian elephants vary geographically in their colour and amount of depigmentation. The Sri Lankan elephant ("Elephas maximus maximus") inhabits Sri Lanka, the Indian elephant ("E.Â m.Â indicus") is native to mainland Asia (on the Indian subcontinent and Indochina), and the Sumatran elephant ("E.Â m.Â sumatranus") is found in Sumatra. One disputed subspecies, the Borneo elephant, lives in northern Borneo and is smaller than all the other subspecies. It has larger ears, a longer tail, and straighter tusks than the typical elephant. Sri Lankan zoologist Paules Edward Pieris Deraniyagala described it in 1950 under the trinomial "Elephas maximus borneensis", taking as his type an illustration in "National Geographic". It was subsequently subsumed under either "E.Â m.Â indicus" or "E.Â m.Â sumatranus". Results of a 2003 genetic analysis indicate its ancestors separated from the mainland population about 300,000Â years ago. A 2008 study found that Borneo elephants are not indigenous to the island but were brought there before 1521 by the Sultan of Sulu from Java, where elephants are now extinct.
The African elephant was first named by German naturalist Johann Friedrich Blumenbach in 1797 as "Elephas africana". The genus "Loxodonta" was commonly believed to have been named by Georges Cuvier in 1825. Cuvier spelled it "Loxodonte" and an anonymous author romanised the spelling to "Loxodonta"; the International Code of Zoological Nomenclature recognises this as the proper authority. In 1942, 18 subspecies of African elephant were recognised by Henry Fairfield Osborn, but further morphological data has reduced the number of classified subspecies, and by the 1990s, only two were recognised, the savannah or bush elephant ("L.Â a.Â africana") and the forest elephant ("L.Â a.Â cyclotis"); the latter has smaller and more rounded ears and thinner and straighter tusks, and is limited to the forested areas of western and Central Africa. A 2000 study argued for the elevation of the two forms into separate species ("L.Â africana" and "L.Â cyclotis" respectively) based on differences in skull morphology. DNA studies published in 2001 and 2007 also suggested they were distinct species, while studies in 2002 and 2005 concluded that they were the same species. Further studies (2010, 2011, 2015) have supported African savannah and forest elephants' status as separate species. The two species are believed to have diverged 6 million years ago. The third edition of "Mammal Species of the World" lists the two forms as full species and does not list any subspecies in its entry for "Loxodonta africana". This approach is not taken by the United Nations Environment Programme's World Conservation Monitoring Centre nor by the IUCN, both of which list "L.Â cyclotis" as a synonym of "L.Â africana". Some evidence suggests that elephants of western Africa are a separate species, although this is disputed. The pygmy elephants of the Congo Basin, which have been suggested to be a separate species ("Loxodonta pumilio") are probably forest elephants whose small size and/or early maturity are due to environmental conditions.
Evolution and extinct relatives.
Over 161 extinct members and three major evolutionary radiations of the order Proboscidea have been recorded. The earliest proboscids, the African "Eritherium" and "Phosphatherium" of the late Paleocene, heralded the first radiation. The Eocene included "Numidotherium", "Moeritherium" and "Barytherium" from Africa. These animals were relatively small and aquatic. Later on, genera such as "Phiomia" and "Palaeomastodon" arose; the latter likely inhabited forests and open woodlands. Proboscidean diversity declined during the Oligocene. One notable species of this epoch was "Eritreum melakeghebrekristosi" of the Horn of Africa, which may have been an ancestor to several later species. The beginning of the Miocene saw the second diversification, with the appearance of the deinotheres and the mammutids. The former were related to "Barytherium", lived in Africa and Eurasia, while the latter may have descended from "Eritreum" and spread to North America.
The second radiation was represented by the emergence of the gomphotheres in the Miocene, which likely evolved from "Eritreum" and originated in Africa, spreading to every continent except Australia and Antarctica. Members of this group included "Gomphotherium" and "Platybelodon". The third radiation started in the late Miocene and led to the arrival of the elephantids, which descended from, and slowly replaced, the gomphotheres. The African "Primelephas gomphotheroides" gave rise to "Loxodonta", "Mammuthus" and "Elephas". "Loxodonta" branched off earliest, around the Miocene and Pliocene boundary, while "Mammuthus" and "Elephas" diverged later during the early Pliocene. "Loxodonta" remained in Africa, while "Mammuthus" and "Elephas" spread to Eurasia, and the former reached North America. At the same time, the stegodontids, another proboscidean group descended from gomphotheres, spread throughout Asia, including the Indian subcontinent, China, southeast Asia and Japan. Mammutids continued to evolve into new species, such as the American mastodon.
At the beginning of the Pleistocene, elephantids experienced a high rate of speciation. "Loxodonta atlantica" became the most common species in northern and southern Africa but was replaced by "Elephas iolensis" later in the Pleistocene. Only when "Elephas" disappeared from Africa did "Loxodonta" become dominant once again, this time in the form of the modern species. "Elephas" diversified into new species in Asia, such as "E.Â hysudricus" and "E.Â platycephus"; the latter the likely ancestor of the modern Asian elephant. "Mammuthus" evolved into several species, including the well-known woolly mammoth. In the Late Pleistocene, most proboscidean species vanished during the Quaternary glaciation which killed off 50% of genera weighing over worldwide.
Proboscideans experienced several evolutionary trends, such as an increase in size, which led to many giant species that stood up to tall. As with other megaherbivores, including the extinct sauropod dinosaurs, the large size of elephants likely developed to allow them to survive on vegetation with low nutritional value. Their limbs grew longer and the feet shorter and broader. Early proboscideans developed longer mandibles and smaller craniums, while more advanced ones developed shorter mandibles, which shifted the head's centre of gravity. The skull grew larger, especially the cranium, while the neck shortened to provide better support for the skull. The increase in size led to the development and elongation of the mobile trunk to provide reach. The number of premolars, incisors and canines decreased. The cheek teeth (molars and premolars) became larger and more specialized, especially after elephants started to switch from C3-plants to C4-grasses, which caused their teeth to undergo a three-fold increase in teeth height as well as substantial multiplication of lamellae after about five million years ago. Only in the last million year or so did they return to a diet mainly consisting of C3 trees and shrubs. The upper second incisors grew into tusks, which varied in shape from straight, to curved (either upward or downward), to spiralled, depending on the species. Some proboscideans developed tusks from their lower incisors. Elephants retain certain features from their aquatic ancestry such as their middle ear anatomy and the internal testes of the males.
There has been some debate over the relationship of "Mammuthus" to "Loxodonta" or "Elephas". Some DNA studies suggest "Mammuthus" is more closely related to the former, while others point to the latter. However, analysis of the complete mitochondrial genome profile of the woolly mammoth (sequenced in 2005) supports "Mammuthus" being more closely related to "Elephas". Morphological evidence supports "Mammuthus" and "Elephas" as sister taxa, while comparisons of protein albumin and collagen have concluded that all three genera are equally related to each other. Some scientists believe a cloned mammoth embryo could one day be implanted in an Asian elephant's womb.
Dwarf species.
Several species of proboscideans lived on islands and experienced insular dwarfism. This occurred primarily during the Pleistocene, when some elephant populations became isolated by fluctuating sea levels, although dwarf elephants did exist earlier in the Pliocene. These elephants likely grew smaller on islands due to a lack of large or viable predator populations and limited resources. By contrast, small mammals such as rodents develop gigantism in these conditions. Dwarf proboscideans are known to have lived in Indonesia, the Channel Islands of California, and several islands of the Mediterranean.
"Elephas celebensis" of Sulawesi is believed to have descended from "Elephas planifrons". "Elephas falconeri" of Malta and Sicily was only , and had probably evolved from the straight-tusked elephant. Other descendants of the straight-tusked elephant existed in Cyprus. Dwarf elephants of uncertain descent lived in Crete, Cyclades and Dodecanese, while dwarf mammoths are known to have lived in Sardinia. The Columbian mammoth colonised the Channel Islands and evolved into the pygmy mammoth. This species reached a height of and weighed . A population of small woolly mammoths survived on Wrangel Island, now 87 miles north of the Siberian coast, as recently as 4,000 years ago. After their discovery in 1993, they were considered dwarf mammoths. This classification has been re-evaluated and since the Second International Mammoth Conference in 1999, these animals are no longer considered to be true "dwarf mammoths".
Anatomy and morphology.
Elephants are the largest living terrestrial animals. African elephants stand and weigh while Asian elephants stand and weigh . In both cases, males are larger than females. Among African elephants, the forest form is smaller than the savannah form. The skeleton of the elephant is made up of 326â351 bones. The vertebrae are connected by tight joints, which limit the backbone's flexibility. African elephants have 21 pairs of ribs, while Asian elephants have 19 or 20 pairs.
An elephant's skull is resilient enough to withstand the forces generated by the leverage of the tusks and head-to-head collisions. The back of the skull is flattened and spread out, creating arches that protect the brain in every direction. The skull contains air cavities (sinuses) that reduce the weight of the skull while maintaining overall strength. These cavities give the inside of the skull a honeycomb-like appearance. The cranium is particularly large and provides enough room for the attachment of muscles to support the entire head. The lower jaw is solid and heavy. Because of the size of the head, the neck is relatively short to provide better support. Lacking a lacrimal apparatus, the eye relies on the harderian gland to keep it moist. A durable nictitating membrane protects the eye globe. The animal's field of vision is compromised by the location and limited mobility of the eyes. Elephants are considered dichromats and they can see well in dim light but not in bright light. The core body temperature averages 35.9Â Â°C (97Â Â°F), similar to a human. Like all mammals, an elephant can raise or lower its temperature a few degrees from the average in response to extreme environmental conditions.
Ears.
Elephant ears have thick bases with thin tips. The ear flaps, or pinnae, contain numerous blood vessels called capillaries. Warm blood flows into the capillaries, helping to release excess body heat into the environment. This occurs when the pinnae are still, and the animal can enhance the effect by flapping them. Larger ear surfaces contain more capillaries, and more heat can be released. Of all the elephants, African bush elephants live in the hottest climates, and have the largest ear flaps. Elephants are capable of hearing at low frequencies and are most sensitive at 1 kHz.
Trunk.
The trunk, or proboscis, is a fusion of the nose and upper lip, although in early fetal life, the upper lip and trunk are separated. The trunk is elongated and specialised to become the elephant's most important and versatile appendage. It contains up to 150,000 separate muscle fascicles, with no bone and little fat. These paired muscles consist of two major types: superficial (surface) and internal. The former are divided into dorsals, ventrals and laterals, while the latter are divided into transverse and radiating muscles. The muscles of the trunk connect to a bony opening in the skull. The nasal septum is composed of tiny muscle units that stretch horizontally between the nostrils. Cartilage divides the nostrils at the base. As a muscular hydrostat, the trunk moves by precisely coordinated muscle contractions. The muscles work both with and against each other. A unique proboscis nerve â formed by the maxillary and facial nerves â runs along both sides of the trunk.
Elephant trunks have multiple functions, including breathing, olfaction, touching, grasping, and sound production. The animal's sense of smell may be four times as sensitive as that of a bloodhound. The trunk's ability to make powerful twisting and coiling movements allows it to collect food, wrestle with conspecifics, and lift up to . It can be used for delicate tasks, such as wiping an eye and checking an orifice, and is capable of cracking a peanut shell without breaking the seed. With its trunk, an elephant can reach items at heights of up to and dig for water under mud or sand. Individuals may show lateral preference when grasping with their trunks: some prefer to twist them to the left, others to the right. Elephants can suck up water both to drink and to spray on their bodies. An adult Asian elephant is capable of holding of water in its trunk. They will also spray dust or grass on themselves. When underwater, the elephant uses its trunk as a snorkel.
The African elephant has two finger-like extensions at the tip of the trunk that allow it to grasp and bring food to its mouth. The Asian elephant has only one, and relies more on wrapping around a food item and squeezing it into its mouth. Asian elephants have more muscle coordination and can perform more complex tasks. Losing the trunk would be detrimental to an elephant's survival, although in rare cases individuals have survived with shortened ones. One elephant has been observed to graze by kneeling on its front legs, raising on its hind legs and taking in grass with its lips. Floppy trunk syndrome is a condition of trunk paralysis in African bush elephants caused by the degradation of the peripheral nerves and muscles beginning at the tip.
Teeth.
Elephants usually have 26 teeth: the incisors, known as the tusks, 12 deciduous premolars, and 12 molars. Unlike most mammals, which grow baby teeth and then replace them with a single permanent set of adult teeth, elephants are polyphyodonts that have cycles of tooth rotation throughout their lives. The chewing teeth are replaced six times in a typical elephant's lifetime. Teeth are not replaced by new ones emerging from the jaws vertically as in most mammals. Instead, new teeth grow in at the back of the mouth and move forward to push out the old ones. The first chewing tooth on each side of the jaw falls out when the elephant is two to three years old. The second set of chewing teeth falls out when the elephant is four to six years old. The third set is lost at 9â15 years of age, and set four lasts until 18â28 years of age. The fifth set of teeth lasts until the elephant is in its early 40s. The sixth (and usually final) set must last the elephant the rest of its life. Elephant teeth have loop-shaped dental ridges, which are thicker and more diamond-shaped in African elephants.
Tusks.
The tusks of an elephant are modified incisors in the upper jaw. They replace deciduous milk teeth when the animal reaches 6â12 months of age and grow continuously at about a year. A newly developed tusk has a smooth enamel cap that eventually wears off. The dentine is known as ivory and its cross-section consists of crisscrossing line patterns, known as "engine turning", which create diamond-shaped areas. As a piece of living tissue, a tusk is relatively soft; it is as hard as the mineral calcite. Much of the incisor can be seen externally, while the rest is fastened to a socket in the skull. At least one-third of the tusk contains the pulp and some have nerves stretching to the tip. Thus it would be difficult to remove it without harming the animal. When removed, ivory begins to dry up and crack if not kept cool and moist. Tusks serve multiple purposes. They are used for digging for water, salt, and roots; debarking or marking trees; and for moving trees and branches when clearing a path. When fighting, they are used to attack and defend, and to protect the trunk.
Like humans, who are typically right- or left-handed, elephants are usually right- or left-tusked. The dominant tusk, called the master tusk, is generally more worn down, as it is shorter with a rounder tip. For the African elephants, tusks are present in both males and females, and are around the same length in both sexes, reaching up to , but those of males tend to be thicker. In earlier times elephant tusks weighing over 200 pounds (more than 90Â kg) were not uncommon, though it is rare today to see any over 100 pounds.
In the Asian species, only the males have large tusks. Female Asians have very small ones, or none at all. Tuskless males exist and are particularly common among Sri Lankan elephants. Asian males can have tusks as long as Africans', but they are usually slimmer and lighter; the largest recorded was long and weighed . Hunting for elephant ivory in Africa and Asia has led to natural selection for shorter tusks and tusklessness.
Skin.
An elephant's skin is generally very tough, at thick on the back and parts of the head. The skin around the mouth, anus and inside of the ear is considerably thinner. Elephants typically have grey skin, but African elephants look brown or reddish after wallowing in coloured mud. Asian elephants have some patches of depigmentation, particularly on the forehead and ears and the areas around them. Calves have brownish or reddish hair, especially on the head and back. As elephants mature, their hair darkens and becomes sparser, but dense concentrations of hair and bristles remain on the end of the tail as well as the chin, genitals and the areas around the eyes and ear openings. Normally the skin of an Asian elephant is covered with more hair than its African counterpart.
An elephant uses mud as a sunscreen, protecting its skin from ultraviolet light. Although tough, an elephant's skin is very sensitive. Without regular mud baths to protect it from burning, insect bites, and moisture loss, an elephant's skin suffers serious damage. After bathing, the elephant will usually use its trunk to blow dust onto its body and this dries into a protective crust. Elephants have difficulty releasing heat through the skin because of their low surface-area-to-volume ratio, which is many times smaller than that of a human. They have even been observed lifting up their legs, presumably in an effort to expose their soles to the air.
Legs, locomotion and posture.
To support the animal's weight, an elephant's limbs are positioned more vertically under the body than in most other mammals. The long bones of the limbs have cancellous bone in place of medullary cavities. This strengthens the bones while still allowing haematopoiesis. Both the front and hind limbs can support an elephant's weight, although 60% is borne by the front. Since the limb bones are placed on top of each other and under the body, an elephant can stand still for long periods of time without using much energy. Elephants are incapable of rotating their front legs, as the ulna and radius are fixed in pronation; the "palm" of the manus faces backward. The pronator quadratus and the pronator teres are either reduced or absent. The circular feet of an elephant have soft tissues or "cushion pads" beneath the manus or pes, which distribute the weight of the animal. They appear to have a sesamoid, an extra "toe" similar in placement to a giant panda's extra "thumb", that also helps in weight distribution. As many as five toenails can be found on both the front and hind feet.
Elephants can move both forwards and backwards, but cannot trot, jump, or gallop. They use only two gaits when moving on land, the walk and a faster gait similar to running. In walking, the legs act as pendulums, with the hips and shoulders rising and falling while the foot is planted on the ground. With no "aerial phase", the fast gait does not meet all the criteria of running, although the elephant uses its legs much like other running animals, with the hips and shoulders falling and then rising while the feet are on the ground. Fast-moving elephants appear to 'run' with their front legs, but 'walk' with their hind legs and can reach a top speed of . At this speed, most other quadrupeds are well into a gallop, even accounting for leg length. Spring-like kinetics could explain the difference between the motion of elephants and other animals. During locomotion, the cushion pads expand and contract, and reduce both the pain and noise that would come from a very heavy animal moving. Elephants are capable swimmers. They have been recorded swimming for up to six hours without touching the bottom, and have travelled as far as at a stretch and at speeds of up to .
Internal and sexual organs.
The brain of an elephant weighs compared to for a human brain. While the elephant brain is larger overall, it is proportionally smaller. At birth, an elephant's brain already weighs 30â40% of its adult weight. The cerebrum and cerebellum are well developed, and the temporal lobes are so large that they bulge out laterally. The throat of an elephant appears to contain a pouch where it can store water for later use.
The heart of an elephant weighs . It has a double-pointed apex, an unusual trait among mammals. When standing, the elephant's heart beats approximately 30 times per minute. Unlike many other animals, the heart rate speeds up by 8 to 10 beats per minute when the elephant is lying down. The lungs are attached to the diaphragm, and breathing relies mainly on the diaphragm rather than the expansion of the ribcage. Connective tissue exists in place of the pleural cavity. This may allow the animal to deal with the pressure differences when its body is underwater and its trunk is breaking the surface for air, although this explanation has been questioned. Another possible function for this adaptation is that it helps the animal suck up water through the trunk. Elephants inhale mostly through the trunk, although some air goes through the mouth. They have a hindgut fermentation system, and their large and small intestines together reach in length. The majority of an elephant's food intake goes undigested despite the process lasting up to a day.
A male elephant's testes are located internally near the kidneys. The elephant's penis can reach a length of and a diameter of at the base. It is S-shaped when fully erect and has a Y-shaped orifice. The female has a well-developed clitoris at up to . The vulva is located between the hind legs instead of near the tail as in most mammals. Determining pregnancy status can be difficult due to the animal's large abdominal cavity. The female's mammary glands occupy the space between the front legs, which puts the suckling calf within reach of the female's trunk. Elephants have a unique organ, the temporal gland, located in both sides of the head. This organ is associated with sexual behaviour, and males secrete a fluid from it when in musth. Females have also been observed with secretions from the temporal glands.
Behaviour and life history.
Ecology and activities.
The African bush elephant can be found in habitats as diverse as dry savannahs, deserts, marshes, and lake shores, and in elevations from sea level to mountain areas above the snow line. Forest elephants mainly live in equatorial forests, but will enter gallery forests and ecotones between forests and savannahs. Asian elephants prefer areas with a mix of grasses, low woody plants and trees, primarily inhabiting dry thorn-scrub forests in southern India and Sri Lanka and evergreen forests in Malaya. Elephants are herbivorous and will eat leaves, twigs, fruit, bark, grass and roots. They are born with sterile intestines, and require bacteria obtained from their mothers feces to digest vegetation. African elephants are mostly browsers while Asian elephants are mainly grazers. They can consume as much as of food and of water in a day. Elephants tend to stay near water sources. Major feeding bouts take place in the morning, afternoon and night. At midday, elephants rest under trees and may doze off while standing. Sleeping occurs at night while the animal is lying down. Elephants average 3â4 hours of sleep per day. Both males and family groups typically move a day, but distances as far as have been recorded in the Etosha region of Namibia. Elephants go on seasonal migrations in search of food, water and mates. At Chobe National Park, Botswana, herds travel to visit the river when the local waterholes dry up.
Because of their large size, elephants have a huge impact on their environments and are considered keystone species. Their habit of uprooting trees and undergrowth can transform savannah into grasslands; when they dig for water during drought, they create waterholes that can be used by other animals. They can enlarge waterholes when they bathe and wallow in them. At Mount Elgon, elephants excavate caves that are used by ungulates, hyraxes, bats, birds and insects. Elephants are important seed dispersers; African forest elephants ingest and defecate seeds, with either no effect or a positive effect on germination. The seeds are typically dispersed in large amounts over great distances. In Asian forests, large seeds require giant herbivores like elephants and rhinoceros for transport and dispersal. This ecological niche cannot be filled by the next largest herbivore, the tapir. Because most of the food elephants eat goes undigested, their dung can provide food for other animals, such as dung beetles and monkeys. Elephants can have a negative impact on ecosystems. At Murchison Falls National Park in Uganda, the overabundance of elephants has threatened several species of small birds that depend on woodlands. Their weight can compact the soil, which causes the rain to run off, leading to erosion.
Elephants typically coexist peacefully with other herbivores, which will usually stay out of their way. Some aggressive interactions between elephants and rhinoceros have been recorded. At Aberdare National Park, Kenya, a rhino attacked an elephant calf and was killed by the other elephants in the group. At HluhluweâUmfolozi Game Reserve, South Africa, introduced young orphan elephants went on a killing spree that claimed the lives of 36 rhinos during the 1990s, but ended with the introduction of older males. The size of adult elephants makes them nearly invulnerable to predators, though there are rare reports of adult elephants falling prey to tigers. Calves may be preyed on by lions, spotted hyenas, and wild dogs in Africa and tigers in Asia. The lions of Savuti, Botswana, have adapted to hunting juvenile elephants during the dry season, and a pride of 30 lions has been recorded killing juvenile individuals between the ages of four and eleven years. Elephants appear to distinguish between the growls of larger predators like tigers and smaller ones like leopards (which have not been recorded killing calves); the latter they react less fearfully and more aggressively to. Elephants tend to have high numbers of parasites, particularly nematodes, compared to other herbivores. This is due to lower predation pressures that would otherwise kill off many of the individuals with significant parasite loads.
Social organisation.
Female elephants spend their entire lives in tight-knit matrilineal family groups, some of which are made up of more than ten members, including three pairs of mothers with offspring, and are led by the matriarch which is often the eldest female. She remains leader of the group until death or if she no longer has the energy for the role; a study on zoo elephants showed that when the matriarch died, the levels of faecal corticosterone ('stress hormone') dramatically increased in the surviving elephants. When her tenure is over, the matriarch's eldest daughter takes her place; this occurs even if her sister is present. The older matriarchs tend to be more effective decision-makers.
The social circle of the female elephant does not necessarily end with the small family unit. In the case of elephants in Amboseli National Park, Kenya, a female's life involves interaction with other families, clans, and subpopulations. Families may associate and bond with each other, forming what are known as bond groups. These are typically made of two family groups. During the dry season, elephant families may cluster together and form another level of social organisation known as the clan. Groups within these clans do not form strong bonds, but they defend their dry-season ranges against other clans. There are typically nine groups in a clan. The Amboseli elephant population is further divided into the "central" and "peripheral" subpopulations.
Some elephant populations in India and Sri Lanka have similar basic social organisations. There appear to be cohesive family units and loose aggregations. They have been observed to have "nursing units" and "juvenile-care units". In southern India, elephant populations may contain family groups, bond groups and possibly clans. Family groups tend to be small, consisting of one or two adult females and their offspring. A group containing more than two adult females plus offspring is known as a "joint family". Malay elephant populations have even smaller family units, and do not have any social organisation higher than a family or bond group. Groups of African forest elephants typically consist of one adult female with one to three offspring. These groups appear to interact with each other, especially at forest clearings.
The social life of the adult male is very different. As he matures, a male spends more time at the edge of his group and associates with outside males or even other families. At Amboseli, young males spend over 80% of their time away from their families when they are 14â15. The adult females of the group start to show aggression towards the male, which encourages him to permanently leave. When males do leave, they either live alone or with other males. The former is typical of bulls in dense forests. Asian males are usually solitary, but occasionally form groups of two or more individuals; the largest consisted of seven bulls. Larger bull groups consisting of over 10 members occur only among African bush elephants, the largest of which numbered up to 144 individuals. A dominance hierarchy exists among males, whether they range socially or solitarily. Dominance depends on the age, size and sexual condition. Old bulls appear to control the aggression of younger ones and prevent them from forming "gangs". Adult males and females come together for reproduction. Bulls appear to associate with family groups if an oestrous cow is present.
Sexual behaviour.
Musth.
Adult males enter a state of increased testosterone known as musth. In a population in southern India, males first enter musth at the age of 15, but it is not very intense until they are older than 25. At Amboseli, bulls under 24 do not go into musth, while half of those aged 25â35 and all those over 35 do. Young bulls appear to enter musth during the dry season (JanuaryâMay), while older bulls go through it during the wet season (JuneâDecember). The main characteristic of a bull's musth is a fluid secreted from the temporal gland that runs down the side of his face. He may urinate with his penis still in his sheath, which causes the urine to spray on his hind legs. Behaviours associated with musth include walking with the head held high and swinging, picking at the ground with the tusks, marking, rumbling and waving only one ear at a time. This can last from a day to four months.
Males become extremely aggressive during musth. Among both musth and nonmusth bulls, size is the determining factor in agonistic encounters. In contests between individuals from the two groups, musth bulls win the majority of the time, even when the non-musth bull is larger. A male may stop showing signs of musth when he encounters a musth male of higher rank. Those of equal rank tend to avoid each other. Agonistic encounters typically consist of threat displays, chases and minor sparring with the tusks. Serious fights are rare.
Mating.
Elephants are polygynous breeders, and copulations are most frequent during the peak of the wet season. A cow in oestrus releases chemical signals (pheromones) in her urine and vaginal secretions to signal her readiness to mate. A bull will follow a potential mate and assess her condition with the flehmen response, which requires the male to collect a chemical sample with his trunk and bring it to the vomeronasal organ. The oestrous cycle of a cow lasts 14â16 weeks with a 4â6-week follicular phase and an 8â10-week luteal phase. While most mammals have one surge of luteinizing hormone during the follicular phase, elephants have two. The first (or anovulatory) surge, could signal to males that the female is in oestrus by changing her scent, but ovulation does not occur until the second (or ovulatory) surge. Fertility rates in cows decline around 45â50 years of age.
Bulls engage in a behaviour known as mate-guarding, where they follow oestrous females and defend them from other males. Most mate-guarding is done by musth males, and females actively seek to be guarded by them, particularly older ones. Thus these bulls have more reproductive success. Musth appears to signal to females the condition of the male, as weak or injured males do not have normal musths. For young females, the approach of an older bull can be intimidating, so her relatives stay nearby to provide support and reassurance. During copulation, the male lays his trunk over the female's back. The penis is very mobile, being able to move independently of the pelvis. Prior to mounting, it curves forward and upward. Copulation lasts about 45 seconds and does not involve pelvic thrusting or ejaculatory pause.
Homosexual behaviour is frequent in both sexes. As in heterosexual interactions, this involves mounting. Male elephants sometimes stimulate each other by playfighting and "championships" may form between old bulls and younger males. Female same-sex behaviours have been documented only in captivity where they are known to masturbate one another with their trunks.
Birthing and calves.
Gestation in elephants typically lasts around two years with interbirth intervals usually lasting four to five years. Births tend to take place during the wet season. Calves are born tall and weigh around . Typically, only a single young is born, but twins sometimes occur. The relatively long pregnancy is maintained by five corpus luteums (as opposed to one in most mammals) and gives the foetus more time to develop, particularly the brain and trunk. As such, newborn elephants are precocial and quickly stand and walk to follow their mother and family herd. A new calf is usually the centre of attention for herd members. Adults and most of the other young will gather around the newborn, touching and caressing it with their trunks. For the first few days, the mother is intolerant of other herd members near her young. Alloparenting â where a calf is cared for by someone other than its mother â takes place in some family groups. Allomothers are typically two to twelve years old. When a predator is near, the family group gathers together with the calves in the centre.
For the first few days, the newborn is unsteady on its feet, and needs the support of its mother. It relies on touch, smell and hearing, as its eyesight is poor. It has little precise control over its trunk, which wiggles around and may cause it to trip. By its second week of life, the calf can walk more firmly and has more control over its trunk. After its first month, a calf can pick up, hold and put objects in its mouth, but cannot suck water through the trunk and must drink directly through the mouth. It is still dependent on its mother and keeps close to her.
For its first three months, a calf relies entirely on milk from its mother for nutrition after which it begins to forage for vegetation and can use its trunk to collect water. At the same time, improvements in lip and leg coordination occur. Calves continue to suckle at the same rate as before until their sixth month, after which they become more independent when feeding. By nine months, mouth, trunk and foot coordination is perfected. After a year, a calf's abilities to groom, drink, and feed itself are fully developed. It still needs its mother for nutrition and protection from predators for at least another year. Suckling bouts tend to last 2â4 min/hr for a calf younger than a year and it continues to suckle until it reaches three years of age or older. Suckling after two years may serve to maintain growth rate, body condition and reproductive ability. Play behaviour in calves differs between the sexes; females run or chase each other, while males play-fight. The former are sexually mature by the age of nine years while the latter become mature around 14â15 years. Adulthood starts at about 18 years of age in both sexes. Elephants have long lifespans, reaching 60â70 years of age. Lin Wang, a captive male Asian elephant, lived for 86 years.
Communication.
Touching is an important form of communication among elephants. Individuals greet each other by stroking or wrapping their trunks; the latter also occurs during mild competition. Older elephants use trunk-slaps, kicks and shoves to discipline younger ones. Individuals of any age and sex will touch each other's mouths, temporal glands and genitals, particularly during meetings or when excited. This allows individuals to pick up chemical cues. Touching is especially important for motherâcalf communication. When moving, elephant mothers will touch their calves with their trunks or feet when side-by-side or with their tails if the calf is behind them. If a calf wants to rest, it will press against its mother's front legs and when it wants to suckle, it will touch her breast or leg.
Visual displays mostly occur in agonistic situations. Elephants will try to appear more threatening by raising their heads and spreading their ears. They may add to the display by shaking their heads and snapping their ears, as well as throwing dust and vegetation. They are usually bluffing when performing these actions. Excited elephants may raise their trunks. Submissive ones will lower their heads and trunks, as well as flatten their ears against their necks, while those that accept a challenge will position their ears in a V shape.
Elephants produce several sounds, usually through the larynx, though some may be modified by the trunk. Perhaps the most well known is the trumpet, which is made during excitement, distress or aggression. Fighting elephants may roar or squeal, and wounded ones may bellow. Rumbles are produced during mild arousal and some appear to be infrasonic. Infrasonic calls are important, particularly for long-distance communication, in both Asian and African elephants. For Asian elephants, these calls have a frequency of 14â24Â Hz, with sound pressure levels of 85â90Â dB and last 10â15 seconds. For African elephants, calls range from 15â35Â Hz with sound pressure levels as high as 117Â dB, allowing communication for many kilometres, with a possible maximum range of around .
At Amboseli, several different infrasonic calls have been identified. A greeting rumble is emitted by members of a family group after having been separated for several hours. Contact calls are soft, unmodulated sounds made by individuals that have been separated from their group and may be responded to with a "contact answer" call that starts out loud, but becomes softer. A "let's go" soft rumble is emitted by the matriarch to signal to the other herd members that it is time to move to another spot. Bulls in musth emit a distinctive, low-frequency pulsated rumble nicknamed the "motorcycle". Musth rumbles may be answered by the "female chorus", a low-frequency, modulated chorus produced by several cows. A loud postcopulatory call may be made by an oestrous cow after mating. When a cow has mated, her family may produce calls of excitement known as the "mating pandemonium".
Elephants are known to communicate with seismics, vibrations produced by impacts on the earth's surface or acoustical waves that travel through it. They appear to rely on their leg and shoulder bones to transmit the signals to the middle ear. When detecting seismic signals, the animals lean forward and put more weight on their larger front feet; this is known as the "freezing behaviour". Elephants possess several adaptations suited for seismic communication. The cushion pads of the feet contain cartilaginous nodes and have similarities to the acoustic fat found in marine mammals like toothed whales and sirenians. A unique sphincter-like muscle around the ear canal constricts the passageway, thereby dampening acoustic signals and allowing the animal to hear more seismic signals. Elephants appear to use seismics for a number of purposes. An individual running or mock charging can create seismic signals that can be heard at great distances. When detecting the seismics of an alarm call signalling danger from predators, elephants enter a defensive posture and family groups will pack together. Seismic waveforms produced by locomotion appear to travel distances of up to while those from vocalisations travel .
Intelligence and cognition.
Elephants exhibit mirror self-recognition, an indication of self-awareness and cognition that has also been demonstrated in some apes and dolphins. One study of a captive female Asian elephant suggested the animal was capable of learning and distinguishing between several visual and some acoustic discrimination pairs. This individual was even able to score a high accuracy rating when re-tested with the same visual pairs a year later. Elephants are among the species known to use tools. An Asian elephant has been observed modifying branches and using them as flyswatters. Tool modification by these animals is not as advanced as that of chimpanzees. Elephants are popularly thought of as having an excellent memory. This could have a factual basis; they possibly have cognitive maps to allow them to remember large-scale spaces over long periods of time. Individuals appear to be able to keep track of the current location of their family members.
Scientists debate the extent to which elephants feel emotion. They appear to show interest in the bones of their own kind, regardless of whether they are related. As with chimps and dolphins, a dying or dead elephant may elicit attention and aid from others, including those from other groups. This has been interpreted as expressing "concern", however, others would dispute such an interpretation as being anthropomorphic; the "Oxford Companion to Animal Behaviour" (1987) advised that "one is well advised to study the behaviour rather than attempting to get at any underlying emotion".
Conservation.
Status.
African elephants were listed as vulnerable by the International Union for Conservation of Nature (IUCN) in 2008, with no independent assessment of the conservation status of the two forms. In 1979, Africa had an estimated minimum population of 1.3Â million elephants, with a possible upper limit of 3.0Â million. By 1989, the population was estimated to be 609,000; with 277,000 in Central Africa, 110,000 in eastern Africa, 204,000 in southern Africa, and 19,000 in western Africa. About 214,000 elephants were estimated to live in the rainforests, fewer than had previously been thought. From 1977 to 1989, elephant populations declined by 74% in East Africa. After 1987, losses in elephant numbers accelerated, and savannah populations from Cameroon to Somalia experienced a decline of 80%. African forest elephants had a total loss of 43%. Population trends in southern Africa were mixed, with anecdotal reports of losses in Zambia, Mozambique and Angola, while populations grew in Botswana and Zimbabwe and were stable in South Africa. Conversely, studies in 2005 and 2007 found populations in eastern and southern Africa were increasing by an average annual rate of 4.0%. Due to the vast areas involved, assessing the total African elephant population remains difficult and involves an element of guesswork. The IUCN estimates a total of around 440,000 individuals for 2012.
African elephants receive at least some legal protection in every country where they are found, but 70% of their range exists outside protected areas. Successful conservation efforts in certain areas have led to high population densities. As of 2008, local numbers were controlled by contraception or translocation. Large-scale cullings ceased in 1988, when Zimbabwe abandoned the practice. In 1989, the African elephant was listed under Appendix I by the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES), making trade illegal. Appendix II status (which allows restricted trade) was given to elephants in Botswana, Namibia and Zimbabwe in 1997 and South Africa in 2000. In some countries, sport hunting of the animals is legal; Botswana, Cameroon, Gabon, Mozambique, Namibia, South Africa, Tanzania, Zambia, and Zimbabwe have CITES export quotas for elephant trophies.
In 2008, the IUCN listed the Asian elephant as endangered due to a 50% population decline over the past 60â75 years, while CITES lists the species under Appendix I. Asian elephants once ranged from Syria and Iraq (the subspecies "Elephas maximus asurus"), to China (up to the Yellow River) and Java. It is now extinct in these areas, and the current range of Asian elephants is highly fragmented. The total population of Asian elephants is estimated to be around 40,000â50,000, although this may be a loose estimate. It is likely that around half of the population is in India. Although Asian elephants are declining in numbers overall, particularly in Southeast Asia, the population in the Western Ghats appears to be increasing.
Threats.
The poaching of elephants for their ivory, meat and hides has been one of the major threats to their existence. Historically, numerous cultures made ornaments and other works of art from elephant ivory, and its use rivalled that of gold. The ivory trade contributed to the African elephant population decline in the late 20th century. This prompted international bans on ivory imports, starting with the United States in June 1989, and followed by bans in other North American countries, western European countries, and Japan. Around the same time, Kenya destroyed all its ivory stocks. CITES approved an international ban on ivory that went into effect in January 1990. Following the bans, unemployment rose in India and China, where the ivory industry was important economically. By contrast, Japan and Hong Kong, which were also part of the industry, were able to adapt and were not badly affected. Zimbabwe, Botswana, Namibia, Zambia, and Malawi wanted to continue the ivory trade and were allowed to, since their local elephant populations were healthy, but only if their supplies were from elephants that had been culled or died of natural causes.
The ban allowed the elephant to recover in parts of Africa. In January 2012, 650 elephants in Bouba Njida National Park, Cameroon, were killed by Chadian raiders. This has been called "one of the worst concentrated killings" since the ivory ban. Asian elephants are potentially less vulnerable to the ivory trade, as females usually lack tusks. Still, members of the species have been killed for their ivory in some areas, such as Periyar National Park in India. China was the biggest market for poached ivory but announced they would phase out the legal domestic manufacture and sale of ivory products in May, 2015, and in September 2015 China and the U.S.A. "said they would enact a nearly complete ban on the import and export of ivory."
Other threats to elephants include habitat destruction and fragmentation. The Asian elephant lives in areas with some of the highest human populations. Because they need larger amounts of land than other sympatric terrestrial mammals, they are the first to be affected by human encroachment. In extreme cases, elephants may be confined to small islands of forest among human-dominated landscapes. Elephants cannot coexist with humans in agricultural areas due to their size and food requirements. Elephants commonly trample and consume crops, which contributes to conflicts with humans, and both elephants and humans have died by the hundreds as a result. Mitigating these conflicts is important for conservation. One proposed solution is the provision of âurban corridorsâ which allow the animals access to key areas.
Elephants and humans.
Working animal.
Elephants have been working animals since at least the Indus Valley Civilization and continue to be used in modern times. There were 13,000â16,500 working elephants employed in Asia as of 2000. These animals are typically captured from the wild when they are 10â20 years old, when they can be trained quickly and easily, and will have a longer working life. They were traditionally captured with traps and lassos, but since 1950, tranquillisers have been used. Individuals of the Asian species are more commonly trained to be working animals, although the practice has also been attempted in Africa. The taming of African elephants in the Belgian Congo began by decree of Leopold II of Belgium during the 19th century and continues to the present with the Api Elephant Domestication Centre.
Asian elephants perform tasks such as hauling loads into remote areas, moving logs into trucks, transporting tourists around national parks, pulling wagons and leading religious processions. In northern Thailand, the animals are used to digest coffee beans for Black Ivory coffee. They are valued over mechanised tools because they can work in relatively deep water, require relatively little maintenance, need only vegetation and water as fuel and can be trained to memorise specific tasks. Elephants can be trained to respond to over 30 commands. Musth bulls can be difficult and dangerous to work with and are chained until the condition passes. In India, many working elephants are alleged to have been subject to abuse. They and other captive elephants are thus protected under the The Prevention of Cruelty to Animals Act of 1960.
In both Myanamar and Thailand, deforestation and other economic factors have resulted in sizable populations of unemployed elephants resulting in health problems for the elephants themselves as well as economic and safety problems for the people amongst whom they live.
Warfare.
Historically, elephants were considered formidable instruments of war. They were equipped with armour to protect their sides, and their tusks were given sharp points of iron or brass if they were large enough. War elephants were trained to grasp an enemy soldier and toss him to the person riding on them or to pin the soldier to the ground and impale him.
One of the earliest references to war elephants is in the Indian epic "Mahabharata" (written in the 4th century BCE, but said to describe events between the 11th and 8th centuries BCE). They were not used as much as horse-drawn chariots by either the Pandavas or Kauravas. During the Magadha Kingdom (which began in the 6th century BCE), elephants began to achieve greater cultural importance than horses, and later Indian kingdoms used war elephants extensively; 3,000 of them were used in the Nandas (5th and 4th centuries BCE) army, while 9,000 may have been used in the Mauryan army (between the 4th and 2nd centuries BCE). The "Arthashastra" (written around 300 BCE) advised the Mauryan government to reserve some forests for wild elephants for use in the army, and to execute anyone who killed them. From South Asia, the use of elephants in warfare spread west to Persia and east to Southeast Asia. The Persians used them during the Achaemenid Empire (between the 6th and 4th centuries BCE), while Southeast Asian states first used war elephants possibly as early as the 5th century BCE and continued to the 20th century.
Alexander the Great trained his foot soldiers to injure the animals and cause them to panic during wars with both the Persians and Indians. Ptolemy, who was one of Alexander's generals, used corps of Asian elephants during his reign as the ruler of Egypt (which began in 323 BCE). His son and successor Ptolemy II (who began his rule in 285 BCE) obtained his supply of elephants further south in Nubia. From then on, war elephants were employed in the Mediterranean and North Africa throughout the classical period. The Greek king Pyrrhus used elephants in his attempted invasion of Rome in 280 BCE. While they frightened the Roman horses, they were not decisive and Pyrrhus ultimately lost the battle. The Carthaginian general Hannibal took elephants across the Alps during his war with the Romans and reached the Po Valley in 217 BCE with all of them alive, but they later succumbed to disease.
Zoos and circuses.
Elephants were historically kept for display in the menageries of Ancient Egypt, China, Greece and Rome. The Romans in particular pitted them against humans and other animals in gladiator events. In the modern era, elephants have traditionally been a major part of zoos and circuses around the world. In circuses, they are trained to perform tricks. The most famous circus elephant was probably Jumbo (1861 â 15 September 1885), who was a major attraction in the Barnum & Bailey Circus. These animals do not reproduce well in captivity, due to the difficulty of handling musth bulls and limited understanding of female oestrous cycles. Asian elephants were always more common than their African counterparts in modern zoos and circuses. After CITES listed the Asian elephant under Appendix I in 1975, the number of African elephants in zoos increased in the 1980s, although the import of Asians continued. Subsequently, the US received many of its captive African elephants from Zimbabwe, which had an overabundance of the animals. As of 2000, around 1,200 Asian and 700 African elephants were kept in zoos and circuses. The largest captive population is in North America, which has an estimated 370 Asian and 350 African elephants. About 380 Asians and 190 Africans are known to exist in Europe, and Japan has around 70 Asians and 67 Africans.
Keeping elephants in zoos has met with some controversy. Proponents of zoos argue that they offer researchers easy access to the animals and provide money and expertise for preserving their natural habitats, as well as safekeeping for the species. Critics claim that the animals in zoos are under physical and mental stress. Elephants have been recorded displaying stereotypical behaviours in the form of swaying back and forth, trunk swaying or route tracing. This has been observed in 54% of individuals in UK zoos. Elephants in European zoos appear to have shorter lifespans than their wild counterparts at only 17 years, although other studies suggest that zoo elephants live as long those in the wild.
The use of elephants in circuses has also been controversial; the Humane Society of the United States has accused circuses of mistreating and distressing their animals. In testimony to a US federal court in 2009, Barnum & Bailey Circus CEO Kenneth Feld acknowledged that circus elephants are struck behind their ears, under their chins and on their legs with metal-tipped prods, called bull hooks or ankus. Feld stated that these practices are necessary to protect circus workers and acknowledged that an elephant trainer was reprimanded for using an electric shock device, known as a hot shot or electric prod, on an elephant. Despite this, he denied that any of these practices harm elephants. Some trainers have tried to train elephants without the use of physical punishment. Ralph Helfer is known to have relied on gentleness and reward when training his animals, including elephants and lions. In January 2016 Ringling Bros. and Barnum and Bailey circus announced it would retire its touring elephants in May 2016.
Disease transmission.
Like many mammals, elephants can contract and transmit diseases to humans, one of which is tuberculosis. In 2012, two elephants in Tete dâOr zoo, Lyon were diagnosed with the disease. Due to the threat of transmitting tuberculosis to other animals or visitors to the zoo, their euthanasia was initially ordered by city authorities but a court later overturned this decision. At an elephant sanctuary in Tennessee, a 54-year-old African elephant was considered to be the source of tuberculosis infections among eight workers.
Attacks.
Elephants can exhibit bouts of aggressive behaviour and engage in destructive actions against humans. In Africa, groups of adolescent elephants damaged homes in villages after cullings in the 1970s and 1980s. Because of the timing, these attacks have been interpreted as vindictive. In India, male elephants regularly enter villages at night, destroying homes and killing people. Elephants killed around 300 people between 2000 and 2004 in Jharkhand, while in Assam 239 people were reportedly killed between 2001 and 2006.
Local people have reported their belief that some elephants were drunk during their attacks, although officials have disputed this explanation. Purportedly drunk elephants attacked an Indian village a second time in December 2002, killing six people, which led to the killing of about 200 elephants by locals.
Cultural depictions.
Elephants have been represented in art since Paleolithic times. Africa in particular contains many rock paintings and engravings of the animals, especially in the Sahara and southern Africa. In the Far East, the animals are depicted as motifs in Hindu and Buddhist shrines and temples. Elephants were often difficult to portray by people with no first-hand experience with them. The ancient Romans, who kept the animals in captivity, depicted anatomically accurate elephants on mosaics in Tunisia and Sicily. At the beginning of the Middle Ages, when Europeans had little to no access to the animals, elephants were portrayed more like fantasy creatures. They were often depicted with horse- or bovine-like bodies with trumpet-like trunks and tusks like a boar; some were even given hooves. Elephants were commonly featured in motifs by the stonemasons of the Gothic churches. As more elephants began to be sent to European kings as gifts during the 15th century, depictions of them became more accurate, including one made by Leonardo da Vinci. Despite this, some Europeans continued to portray them in a more stylised fashion. Max Ernst's 1921 surrealist painting "The Elephant Celebes" depicts an elephant as a silo with a trunk-like hose protruding from it.
Elephants have been the subject of religious beliefs. The Mbuti people believe that the souls of their dead ancestors resided in elephants. Similar ideas existed among other African tribes, who believed that their chiefs would be reincarnated as elephants. During the 10th century AD, the people of Igbo-Ukwu buried their leaders with elephant tusks. The animals' religious importance is only totemic in Africa but is much more significant in Asia. In Sumatra, elephants have been associated with lightning. Likewise in Hinduism, they are linked with thunderstorms as Airavata, the father of all elephants, represents both lightning and rainbows. One of the most important Hindu deities, the elephant-headed Ganesha, is ranked equal with the supreme gods Shiva, Vishnu, and Brahma. Ganesha is associated with writers and merchants and it is believed that he can give people success as well as grant them their desires. In Buddhism, Buddha is said to have been a white elephant reincarnated as a human. In Islamic tradition, the year 570, when Muhammad was born, is known as the Year of the Elephant. Elephants were thought to be religious themselves by the Romans, who believed that they worshipped the sun and stars. The 'Land of a Million Elephants' was the name of the ancient kingdom of Lan Xang and later the Lan Chang Province and it is now a nickname for Laos.
Elephants are ubiquitous in Western popular culture as emblems of the exotic, especially since â as with the giraffe, hippopotamus and rhinoceros â there are no similar animals familiar to Western audiences. The use of the elephant as a symbol of the US Republican Party began with an 1874 cartoon by Thomas Nast. As characters, elephants are most common in children's stories, in which they are generally cast as models of exemplary behaviour. They are typically surrogates for humans with ideal human values. Many stories tell of isolated young elephants returning to a close-knit community, such as "The Elephant's Child" from Rudyard Kipling's "Just So Stories", Disney's "Dumbo" and Kathryn and Byron Jackson's "The Saggy Baggy Elephant". Other elephant heroes given human qualities include Jean de Brunhoff's Babar, David McKee's Elmer and Dr. Seuss's Horton.
Several cultural references emphasise the elephant's size and exotic uniqueness. For instance, a "white elephant" is a byword for something expensive, useless and bizarre. The expression "elephant in the room" refers to an obvious truth that is ignored or otherwise unaddressed. The story of the blind men and an elephant teaches that reality may be viewed by different perspectives.

</doc>
<doc id="9281" url="https://en.wikipedia.org/wiki?curid=9281" title="Evolutionary linguistics">
Evolutionary linguistics

Evolutionary linguistics is the scientific study of the psychosocial development and cultural evolution of individual languages as well as the origins and development of human language itself. The main challenge in this research is the lack of empirical data: spoken language leaves practically no traces. This led to an abandonment of the field for more than a century. Since the late 1980s, the field has been revived in the wake of progress made in the related fields of psycholinguistics, neurolinguistics, evolutionary anthropology, evolutionary psychology, universal grammar,and cognitive science.
History.
Inspired by the natural sciences, especially by biology, August Schleicher (1821â1868) became the first to compare changing languages to evolving species. He introduced the representation of language families as an evolutionary tree ("Stammbaumtheorie") in articles published in 1853. "Stammbaumtheorie" proved very productive for comparative linguistics, but did not solve the major problem of studying the origin of language: the lack of fossil records. Some scholars abandoned the question of the origin of language as unsolvable. Famously, the "SociÃ©tÃ© Linguistique de Paris" in 1866 refused to admit any further papers on the subject.
Joseph Jastrow published a gestural theory of the evolution of language in the seventh volume of "Science", 1886.
The field re-appeared in 1988 in the "Linguistic Bibliography" as a subfield of psycholinguistics. In 1990, Steven Pinker and Paul Bloom published their paper "Natural Language and Natural Selection" which strongly argued for an adaptationist approach to language origins. Development strengthened further with the establishment (in 1996) of a series of conferences on the Evolution of Language (subsequently known as "Evolang"), promoting a scientific, multi-disciplinary approach to the issue, and interest from major academic publishers (e.g., the "Studies in the Evolution of Language" series has appeared with Oxford University Press since 2001) and from scientific journals.
Recent developments.
Evolutionary linguistics as a field is rapidly emerging as a result of developments in neighboring disciplines. To what extent language's features are determined by genes, a hotly debated dichotomy in linguistics, has had new light shed upon it by the discovery of the "FOXP2" gene. An English family with a severe, heritable language dysfunction was found to have a defective copy of this gene. Mutations of the corresponding gene in mice ("FOXP2" is fairly well conserved; modern humans share the same allele as Neanderthals) cause reductions in size and vocalization rate. If both copies are damaged, the Purkinje layer (a part of the cerebellum that contains better-connected neurons than any other) develops abnormally, runting is more common, and pups die within weeks due to inadequate lung development. Additionally, higher presence of "FOXP2" in songbirds is correlated to song changes, with downregulation causing incomplete and inaccurate song imitation in zebra finches. In general, evidence suggests that the protein is vital to neuroplasticity. There is little support, however, for the idea that "FOXP2" is 'the grammar gene' or that it had much to do with the relatively recent emergence of syntactical speech.
Another controversial dichotomy is the question of whether human language is solely human or on a continuum with (admittedly far removed) animal communication systems. Studies in ethology have forced researchers to reassess many claims of uniquely human abilities for language and speech. For instance, Tecumseh Fitch has argued that the descended larynx is not unique to humans. Similarly, once held uniquely human traits such as formant perception, combinatorial phonology and compositional semantics are now thought to be shared with at least some nonhuman animal species. Conversely, Derek Bickerton and others argue that the advent of abstract words provided a mental basis for analyzing higher-order relations, and that any communication system that remotely resembles human language utterly relies on cognitive architecture that co-evolved alongside language.
As it leaves no fossils, language's form and even its presence are extremely hard or impossible to deduce from physical evidence. Computational modeling is now widely accepted as an approach to assure the internal consistency of language-evolution scenarios. Approximately one-third of all papers presented at the 2010 Evolution of Language conference rely at least in part on computer simulations.
Approaches.
One original researcher in the field is Luc Steels, head of the research units of Sony CSL in Paris and the AI Lab at the Vrije Universiteit Brussel. He and his team are currently investigating ways in which artificial agents self-organize languages with natural-like properties and how meaning can co-evolve with language. Their research is based on the hypothesis that language is a complex adaptive system that emerges through adaptive interactions between agents and continues to evolve in order to remain adapted to the needs and capabilities of the agents. This research has been implemented in fluid construction grammar (FCG), a formalism for construction grammars that has been specially designed for the origins and evolution of language. The approach of computational modeling and the use of robotic agents grounded in real life is claimed to be theory independent. It enables the researcher to find out exactly what cognitive capacities are needed for certain language phenomena to emerge. It also focuses the researcher in formulating hypotheses in a precise and exact manner, whereas theoretical models often stay very vague.
Some linguists, such as John McWhorter, have analyzed the evolution and construction of basic communication methods such as Pidginization and Creolization.
"Nativist" models of "Universal Grammar" are informed by linguistic universals such as the existence of pronouns and demonstratives, and the similarities in each language's process of nominalization (the process of verbs becoming nouns) as well as the reverse, the process of turning nouns into verbs. This is a purely descriptive approach to what we mean by "natural language" without attempting to address its emergence.
Finally there are those archaeologists and evolutionary anthropologists â among them Ian Watts, Camilla Power and Chris Knight (co-founder with James Hurford of the EVOLANG series of conferences) â who argue that 'the origin of language' is probably an insoluble problem. In agreement with Amotz Zahavi, Knight argues that language â being a realm of patent fictions â is a theoretical impossibility in a Darwinian world, where signals must be intrinsically reliable. If we are going to explain language's evolution, according to this view, we must tackle it as part of a wider one â the evolutionary emergence of symbolic culture as such.
EVOLANG Conference.
The Evolution of Language International Conferences have been held biennially since 1996.

</doc>
<doc id="9282" url="https://en.wikipedia.org/wiki?curid=9282" title="ECHELON">
ECHELON

ECHELON, originally a secret government code name, is a surveillance program (signals intelligence / SIGINT collection and analysis network) operated on behalf of the five signatory nations to the UKUSA Security AgreementâAustralia, Canada, New Zealand, the United Kingdom, and the United States, also known as the "Five Eyes".
The ECHELON program was created in the late 1960s to monitor the military and diplomatic communications of the Soviet Union and its Eastern Bloc allies during the Cold War, and was formally established in 1971.
By the end of the 20th century, the system referred to as "ECHELON" had allegedly evolved beyond its military and diplomatic origins, to also become "... a global system for the interception of private and commercial communications."
Name.
The European Parliament's Temporary Committee on the ECHELON Interception System stated, "It seems likely, in view of the evidence and the consistent pattern of statements from a very wide range of individuals and organisations, including American sources, that its name is in fact ECHELON, although this is a relatively minor detail". The U.S. intelligence community uses many code names ("see", for example, CIA cryptonym).
Former NSA employee Margaret Newsham claims that she worked on the configuration and installation of software that makes up the ECHELON system while employed at Lockheed Martin, from 1974 to 1984 in Sunnyvale, California, in the United States, and in Menwith Hill, England, in the UK. At that time, according to Newsham, the code name ECHELON was NSA's term for the computer network itself. Lockheed called it "P415". The software programs were called "SILKWORTH" and "SIRE". A satellite named "VORTEX" intercepted communications. An image available on the internet of a fragment apparently torn from a job description shows Echelon listed along with several other code names.
Britain's "The Guardian" newspaper summarized the capabilities of the ECHELON system as follows:
Reporting and disclosures.
Public disclosures (1988â2000).
In 1988, the first disclosure of the ECHELON surveillance system originated from Margaret Newsham, a Lockheed employee. Newsham told a member of the U.S. Congress that the telephone calls of Strom Thurmond, a Republican U.S. senator, were being collected by the NSA. Congressional investigators determined that "targeting of U.S. political figures would not occur by accident, but was designed into the system from the start."
Also in 1988, an article titled "Somebody's listening", written by investigative journalist Duncan Campbell in the "New Statesman", described the signals intelligence gathering activities of a program code-named "ECHELON". Bamford describes the system as the software controlling the collection and distribution of civilian telecommunications traffic conveyed using communication satellites, with the collection being undertaken by ground stations located in the footprint of the downlink leg.
In 1996, a detailed description of ECHELON was provided by New Zealand journalist Nicky Hager in his 1996 book "Secret Power â New Zealand's Role in the International Spy Network" Two years later, Hager's book was cited by the European Parliament in a report titled "An Appraisal of the Technology of Political Control" (PE 168.184).
In March 1999, for the first time in history, the Australian government admitted that news reports about the top secret UKUSA Agreement were true. Martin Brady, the director of Australia's Defence Signals Directorate (DSD) told the Australian broadcasting channel Nine Network that the DSD "does co-operate with counterpart signals intelligence organisations overseas under the UKUSA relationship"
In 2000, James Woolsey, the former Director of the U.S. Central Intelligence Agency, confirmed that U.S. intelligence uses interception systems and keyword searches to monitor European businesses.
Lawmakers in the United States feared that the ECHELON system could be used to monitor U.S. citizens. According to "The New York Times", the ECHELON system has been "shrouded in such secrecy that its very existence has been difficult to prove." Critics said the ECHELON system emerged from the Cold War as a "Big Brother without a cause".
European Parliament investigation (2000â2001).
The program's capabilities and political implications were investigated by a committee of the European Parliament during 2000 and 2001 with a report published in 2001, In July 2000, the Temporary Committee on the ECHELON Interception System was established by the European parliament to investigate the surveillance network. It was chaired by the Portuguese politician Carlos Coelho, who was in charge of supervising investigations throughout 2000 and 2001.
In May 2001, as the committee finalised its report on the ECHELON system, a delegation travelled to Washington, D.C. to attend meetings with U.S. officials from the following agencies and departments:
All meetings were cancelled by the U.S. government and the committee was forced to end its trip prematurely. According to a BBC correspondent in May 2001, "The US Government still refuses to admit that Echelon even exists"
In July 2001, the Temporary Committee on the ECHELON Interception System released its final report. On 5 September 2001, the European Parliament voted to accept the committee's report.
The European Parliament stated in its report that the term ECHELON is used in a number of contexts, but that the evidence presented indicates that it was the name for a signals intelligence collection system. The report concludes that, on the basis of information presented, ECHELON was capable of interception and content inspection of telephone calls, fax, e-mail and other data traffic globally through the interception of communication bearers including satellite transmission, public switched telephone networks (which once carried most Internet traffic) and microwave links.
Confirmation of ECHELON (2015).
Two internal NSA newsletters from January 2011 and July 2012, published as part of the Snowden-revelations by the website "The Intercept" on 3 August 2015, for the first time confirmed that NSA used the codeword ECHELON and provided some details about the scope of the program: ECHELON was part of an umbrella program codenamed FROSTING, which was established by the NSA in 1966 to collect and process data from communications satellites. FROSTING had two sub-programs:
Organization.
The UKUSA intelligence community was assessed by the European Parliament (EP) in 2000 to include the signals intelligence agencies of each of the member states:
The EP report concluded that it seemed likely that ECHELON is a method of sorting captured signal traffic, rather than a comprehensive analysis tool.
Likely satellite intercept stations.
In 2001, the EP report (p.Â 54 ff) listed the following ground stations as likely to have, or to have had, a role in intercepting transmissions from telecommunications satellites:
Other potentially related stations.
The following stations are listed in the EP report (p.Â 57 ff) as ones whose roles "cannot be clearly established":
History and context.
The ability to intercept communications depends on the medium used, be it radio, satellite, microwave, cellular or fiber-optic. During World War II and through the 1950s, high-frequency ("short-wave") radio was widely used for military and diplomatic communication, and could be intercepted at great distances. The rise of geostationary communications satellites in the 1960s presented new possibilities for intercepting international communications.
In 1964, plans for the establishment of the ECHELON network took off after dozens of countries agreed to establish the International Telecommunications Satellite Organisation (Intelsat), which would own and operate a global constellation of communications satellites.
In 1966, the first Intelsat satellite was launched into orbit. From 1970 to 1971, the Government Communications Headquarters (GCHQ) of Britain began to operate a secret signal station at Morwenstow, near Bude in Cornwall, England. The station intercepted satellite communications over the Atlantic and Indian Oceans. Soon afterwards, the U.S. National Security Agency (NSA) built a second signal station at Yakima, near Seattle, for the interception of satellite communications over the Pacific Ocean.
In 1981, the GCHQ and the NSA started the construction of the first global Wide area network (WAN). Soon afterwards, Australia, Canada, and New Zealand joined the ECHELON system. The report to the European Parliament of 2001 states: "If UKUSA states operate listening stations in the relevant regions of the earth, in principle they can intercept all telephone, fax and data traffic transmitted via such satellites".
Most reports on ECHELON focus on satellite interception; testimony before the European Parliament indicated that separate but similar UK-U.S. systems are in place to monitor communication through undersea cables, microwave transmissions and other lines. The report to the European Parliament points out that interception of private communications by foreign intelligence services is not necessarily limited to the U.S. or British foreign intelligence services.
The role of satellites in point-to-point voice and data communications has largely been supplanted by fiber optics; in 2006, 99% of the world's long-distance voice and data traffic was carried over optical-fiber. The proportion of international communications accounted for by satellite links is said to have decreased substantially to an amount between 0.4% and 5% in Central Europe. Even in less-developed parts of the world, communications satellites are used largely for point-to-multipoint applications, such as video. Thus, the majority of communications can no longer be intercepted by earth stations; they can only be collected by tapping cables and intercepting line-of-sight microwave signals, which is possible only to a limited extent.
Concerns.
British journalist Duncan Campbell and New Zealand journalist Nicky Hager asserted in the 1990s that the United States was exploiting ECHELON traffic for industrial espionage, rather than military and diplomatic purposes. Examples alleged by the journalists include the gear-less wind turbine technology designed by the German firm Enercon and the speech technology developed by the Belgian firm Lernout & Hauspie.
In 2001, the Temporary Committee on the ECHELON Interception System recommended to the European Parliament that citizens of member states routinely use cryptography in their communications to protect their privacy, because economic espionage with ECHELON has been conducted by the U.S. intelligence agencies.
Bamford provides an alternative view, highlighting that legislation prohibits the use of intercepted communications for commercial purposes, although he does not elaborate on how intercepted communications are used as part of an all-source intelligence process. In its report, the committee of the European Parliament stated categorically that the Echelon network was being used to intercept not only military communications, but also private and business ones. In its epigraph to the report, the parliamentary committee quoted Juvenal, "Sed quis custodiet ipsos custodes." ("But who will watch the watchers"). Bamford, in the "Guardian" in May 2001, warned that if Echelon were to continue unchecked, it could become a "cyber secret police, without courts, juries, or the right to a defence".
Alleged examples of espionage conducted by the members of the "Five Eyes" include:
At least one non-commercial journalist has already suggested that technologies likely connected with ECHELON might be used illegally, for unhuman treatment of politically repressed people.
Workings.
The first American satellite ground station for the ECHELON collection program was built in 1971 at a military firing and training center near Yakima, Washington. The facility, which was codenamed JACKKNIFE, was an investment of ca. 21.3 million dollars and had around 90 people. Satellite traffic was intercepted by a 30-meter single dish antenna. The station became fully operational on 4 October 1974. It was connected with NSA headquarters at Fort Meade by a 75-baud secure teletype orderwire channel.
In 1999 the Australian Senate Joint Standing Committee on Treaties was told by Professor Desmond Ball that the Pine Gap facility was used as a ground station for a satellite-based interception network. The satellites were said to be large radio dishes between 20 and 100 meters in diameter in geostationary orbits. The original purpose of the network was to monitor the telemetry from 1970s , air defence- and other radar's capabilities, satellite's ground station's transmissions and ground-based microwave communications.
In popular culture.
The television series "Alias" made recurring references to ECHELON throughout its run.
"Echelon Conspiracy", inspired by the surveillance system ECHELON, is a 2009 action thriller film directed by Greg Marcks. It tells the story of Max Peterson (Shane West), an American computer specialist who attempts to uncover a secret plot to turn the world into a global police state. After being chased down by NSA agent Raymond Burke (Martin Sheen), Peterson decides to flee to Moscow.
The video game series "Tom Clancy's Splinter Cell" also draws inspiration from this. The series features the protagonist, Sam Fisher, a trained operative belonging to a fictional branch of the National Security Agency called Third Echelon (later, in "", the unit is replaced by the Fourth Echelon).
The 2007 film "The Bourne Ultimatum" makes several references to ECHELON. A CIA listening station in London is alerted when ECHELON detects the keyword "Blackbriar" in a cell phone conversation between a journalist and his editor. Later in the film, CIA Deputy Director Pamela Landy requests an "ECHELON package" on the main character, Jason Bourne.
Alternative rock band Thirty Seconds To Mars' first album includes a song called "Echelon". Their fan base is also referred to as the Echelon, though an explanation hasn't been given as to why the fanbase and the song are referred to as such.
In the 2000 computer game "Deus Ex", the signals intelligence supercomputers Daedalus and Icarus (later Helios) are referred to as Echelon IV.

</doc>
<doc id="9284" url="https://en.wikipedia.org/wiki?curid=9284" title="Equation">
Equation

In mathematics, an equation is an equality containing one or more variables. "Solving" the equation consists of determining which values of the variables make the equality true. In this situation, variables are also known as unknowns and the values which satisfy the equality are known as solutions. An equation differs from an identity in that an equation is not necessarily true for all possible values of the variable.
There are many types of equations, and they are found in many areas of mathematics. The techniques used to examine them differ according to their type.
Algebra studies two main families of equations: polynomial equations and, among them, linear equations. Polynomial equations have the form "P"("x")Â =Â 0, where "P" is a polynomial. Linear equations have the form "a"("x")Â +Â "b"Â =Â 0, where "a" is a linear function and "b" is a vector. To solve them, one uses algorithmic or geometric techniques, coming from linear algebra or mathematical analysis. Changing the domain of a function can change the problem considerably. Algebra also studies Diophantine equations where the coefficients and solutions are integers. The techniques used are different and come from number theory. These equations are difficult in general; one often searches just to find the existence or absence of a solution, and, if they exist, to count the number of solutions.
In geometry, equations are used to describe geometric figures. As equations that are considered, such as implicit equations or parametric equations have infinitely many solutions, the objective is now different: instead of given the solutions explicitly or counting them, which is impossible, one uses equations for studying properties of figures. This is the starting idea of algebraic geometry, an important area of mathematics.
Differential equations are equations involving one or more functions and their derivatives. They are "solved" by finding an expression for the function that does not involve derivatives. Differential equations are used to model real-life processes in areas such as physics, chemistry, biology, and economics.
The "=" symbol, which appear in every equation, was invented in 1557 by Robert Recorde, who considered that nothing could be more equal than parallel straight lines with the same length.
Introduction.
Parameters and unknowns.
Equations often contain terms other than the unknowns. These other terms, which are assumed to be "known", are usually called "constants", "coefficients" or "parameters". Usually, the unknowns are denoted by letters at the end of the alphabet, "x", "y", "z", "w", â¦, while coefficients are denoted by letters at the beginning, "a", "b", "c", "d", â¦ . For example, the general quadratic equation is usually written "ax"Â +Â "bx"Â +Â "c"Â =Â 0. The process of finding the solutions, or in case of parameters, expressing the unknowns in terms of the parameters is called solving the equation. Such expressions of the solutions in terms of the parameters are also called "solutions".
A system of equations is a set of "simultaneous equations", usually in several unknowns, for which the common solutions are sought. Thus a "solution to the system" is a set of values for each of the unknowns, which together form a solution to each equation in the system. For example, the system
has the unique solution "x"Â =Â â1, "y"Â =Â 1.
Analogous illustration.
A weighing scale, balance, or seesaw is often presented as an analogy to an equation.
Each side of the balance corresponds to one side of the equation. Different quantities can be placed on each side: if the weights on the two sides are equal the scale balances, corresponding to an equality represented by an equation; if not, then the lack of balance corresponds to an inequality represented by an inequation.
In the illustration, "x", "y" and "z" are all different quantities (in this case real numbers) represented as circular weights, and each of "x", "y", and "z" has a different weight. Addition corresponds to adding weight, while subtraction corresponds to removing weight from what is already there. When equality holds, the total weight on each side is the same.
Identities.
An identity is a statement resembling an equation which is true for all possible values of the variable(s) it contains. Many identities are known in algebra and calculus. In the process of solving an equation, it is often useful to combine it with an identity to produce an equation which is more easily soluble. 
In algebra, a simple identity is the difference of two squares:
which is true for all "x" and "y".
Trigonometry is an area where many identities exist, and are useful in manipulating or solving trigonometric equations, two of many including the sine and cosine functions are:
and 
which are both true for all values of "Î¸". 
For example, to solve the equation:
where "Î¸" is known to be between 0 and 45 degrees, using the identity for the product gives 
yielding the solution
Since the sine function is a periodic function, there are infinitely many solutions if there are no restrictions on "Î¸". In this example, the fact that "Î¸" is between 0 and 45 degrees implies there is only one solution.
Properties.
Two equations or two systems of equations are "equivalent" if they have the same set of solutions. The following operations transform an equation or a system into an equivalent one:
If some function is applied to both sides of an equation, the resulting equation has the solutions of the initial equation among its solutions, but may have further solutions called extraneous solutions. For example, the equation formula_8 has the solution formula_9 Raising both sides to the exponent of 2 (which means applying the function formula_10 to both sides of the equation) changes the equation to formula_11, which not only has the previous solution but also introduces the extraneous solution, formula_12 Moreover, If the function is not defined at some values (such as 1/"x", which is not defined for "x" = 0), solutions existing at those values may be lost. Thus, caution must be exercised when applying such a transformation to an equation.
The above transformations are the basis of most elementary methods for equation solving as well as some less elementary ones, like Gaussian elimination.
Algebra.
Polynomial equations.
An "algebraic equation" or polynomial equation is an equation of the form
where "P" and "Q" are polynomials with coefficients in some field, often the field of the rational numbers. An algebraic equation is "univariate" if it involves only one variable. On the other hand, a polynomial equation may involve several variables, in which case it is called "multivariate" and the term "polynomial equation" is usually preferred to "algebraic equation".
For example,
is an algebraic equation with integer coefficients and
is a multivariate polynomial equation over the rationals.
Some but not all polynomial equations with rational coefficients have a solution that is an algebraic expression with a finite number of operations involving just those coefficients (that is, can be solved algebraically). This can be done for all such equations of degree one, two, three, or four; but for degree five or more it can only be done for some equations but not for all. A large amount of research has been devoted to compute efficiently accurate approximations of the real or complex solutions of an univariate algebraic equation (see Root-finding algorithm) and of the common solutions of several multivariate polynomial equations (see System of polynomial equations).
Systems of linear equations.
A system of linear equations (or "linear system") is a collection of linear equations involving the same set of variables. For example,
is a system of three equations in the three variables . A solution to a linear system is an assignment of numbers to the variables such that all the equations are simultaneously satisfied. A solution to the system above is given by
since it makes all three equations valid. The word "system" indicates that the equations are to be considered collectively, rather than individually.
In mathematics, the theory of linear systems is the basis and a fundamental part of linear algebra, a subject which is used in most parts of modern mathematics. Computational algorithms for finding the solutions are an important part of numerical linear algebra, and play a prominent role in engineering, physics, chemistry, computer science, and economics. A system of non-linear equations can often be approximated by a linear system (see linearization), a helpful technique when making a mathematical model or computer simulation of a relatively complex system.
Geometry.
Analytic geometry.
In Euclidean geometry, it is possible to associate a set of coordinates to each point in space, for example by an orthogonal grid. This method allows one to characterize geometric figures by equations. A plane in three-dimensional space can be expressed as the solution set of an equation of the form formula_19, where formula_20 and formula_21 are real numbers and formula_22 are the unknowns which correspond to the coordinates of a point in the system given by the orthogonal grid. The values formula_20 are the coordinates of a vector perpendicular to the plane defined by the equation. A line is expressed as the intersection of two planes, that is as the solution set of a single linear equation with values in formula_24 or as the solution set of two linear equations with values in formula_25.
A conic section is the intersection of a cone with equation formula_26 and a plane. In other words, in space, all conics are defined as the solution set of an equation of a plane and of the equation of a plane just given. This formalism allows one to determine the positions and the properties of the focuses of a conic.
The use of equations allows one to call on a large area of mathematics to solve geometric questions. The Cartesian coordinate system transforms a geometric problem into an analysis problem, once the figures are transformed into equations; thus the name analytic geometry. This point of view, outlined by Descartes, enriches and modifies the type of geometry conceived of by the ancient Greek mathematicians.
Currently, analytic geometry designates an active branch of mathematics. Although it still uses equations to characterize figures, it also uses other sophisticated techniques such as functional analysis and linear algebra.
Cartesian equations.
A Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a pair of numerical coordinates, which are the signed distances from the point to two fixed perpendicular directed lines, measured in the same unit of length.
One can use the same principle to specify the position of any point in three-dimensional space by three Cartesian coordinates, its signed distances to three mutually perpendicular planes (or, equivalently, by its perpendicular projection onto three mutually perpendicular lines).
The invention of Cartesian coordinates in the 17th century by RenÃ© Descartes (Latinized name: "Cartesius") revolutionized mathematics by providing the first systematic link between Euclidean geometry and algebra. Using the Cartesian coordinate system, geometric shapes (such as curves) can be described by Cartesian equations: algebraic equations involving the coordinates of the points lying on the shape. For example, a circle of radius 2 in a plane may be described as the set of all points whose coordinates "x" and "y" satisfy the equation .
Parametric equations.
A parametric equation for a curve expresses the coordinates of the points of the curve as functions of a variable, called a parameter. For example,
are parametric equations for the unit circle, where "t" is the parameter. Together, these equations are called a parametric representation of the curve.
The notion of "parametric equation" has been generalized to surfaces, manifolds and algebraic varieties of higher dimension, with the number of parameters being equal to the dimension of the manifold or variety, and the number of equations being equal to the dimension of the space in which the manifold or variety is considered (for curves the dimension is "one" and "one" parameter is used, for surfaces dimension "two" and "two" parameters, etc.).
Number theory.
Diophantine equations.
A Diophantine equation is a polynomial equation in two or more unknowns such that only the integer solutions are searched or studied (an integer solution is a solution such that all the unknowns take integer values). A linear Diophantine equation is an equation between two sums of monomials of degree zero or one. An exponential Diophantine equation is one in which exponents on terms can be unknowns.
Diophantine problems have fewer equations than unknown variables and involve finding integers that work correctly for all equations. In more technical language, they define an algebraic curve, algebraic surface, or more general object, and ask about the lattice points on it.
The word "Diophantine" refers to the Hellenistic mathematician of the 3rd century, Diophantus of Alexandria, who made a study of such equations and was one of the first mathematicians to introduce symbolism into algebra. The mathematical study of Diophantine problems that Diophantus initiated is now called Diophantine analysis.
Algebraic and transcendental numbers.
An algebraic number is a number that is a root of a non-zero polynomial equation in one variable with rational coefficients (or equivalently â by clearing denominators â with integer coefficients). Numbers such as that are not algebraic are said to be transcendental. Almost all real and complex numbers are transcendental.
Algebraic geometry.
Algebraic geometry is a branch of mathematics, classically studying zeros of polynomial equations. Modern algebraic geometry is based on more abstract techniques of abstract algebra, especially commutative algebra, with the language and the problems of geometry.
The fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are: plane algebraic curves, which include lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves and quartic curves like lemniscates, and Cassini ovals. A point of the plane belongs to an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of the points of special interest like the singular points, the inflection points and the points at infinity. More advanced questions involve the topology of the curve and relations between the curves given by different equations.
Differential equations.
A differential equation is a mathematical equation that relates some function with its derivatives. In applications, the functions usually represent physical quantities, the derivatives represent their rates of change, and the equation defines a relationship between the two. Because such relations are extremely common, differential equations play a prominent role in many disciplines including engineering, physics, economics, and biology.
In pure mathematics, differential equations are studied from several different perspectives, mostly concerned with their solutions â the set of functions that satisfy the equation. Only the simplest differential equations are solvable by explicit formulas; however, some properties of solutions of a given differential equation may be determined without finding their exact form.
If a self-contained formula for the solution is not available, the solution may be numerically approximated using computers. The theory of dynamical systems puts emphasis on qualitative analysis of systems described by differential equations, while many numerical methods have been developed to determine solutions with a given degree of accuracy.
Ordinary differential equations.
An ordinary differential equation or ODE is an equation containing a function of one independent variable and its derivatives. The term "ordinary" is used in contrast with the term partial differential equation which may be with respect to "more than" one independent variable.
Linear differential equations, which have solutions that can be added and multiplied by coefficients, are well-defined and understood, and exact closed-form solutions are obtained. By contrast, ODEs that lack additive solutions are nonlinear, and solving them is far more intricate, as one can rarely represent them by elementary functions in closed form: Instead, exact and analytic solutions of ODEs are in series or integral form. Graphical and numerical methods, applied by hand or by computer, may approximate solutions of ODEs and perhaps yield useful information, often sufficing in the absence of exact, analytic solutions.
Partial differential equations.
A partial differential equation (PDE) is a differential equation that contains unknown multivariable functions and their partial derivatives. (This is in contrast to ordinary differential equations, which deal with functions of a single variable and their derivatives.) PDEs are used to formulate problems involving functions of several variables, and are either solved by hand, or used to create a relevant computer model.
PDEs can be used to describe a wide variety of phenomena such as sound, heat, electrostatics, electrodynamics, fluid flow, elasticity, or quantum mechanics. These seemingly distinct physical phenomena can be formalised similarly in terms of PDEs. Just as ordinary differential equations often model one-dimensional dynamical systems, partial differential equations often model multidimensional systems. PDEs find their generalisation in stochastic partial differential equations.
Types of equations.
Equations can be classified according to the types of operations and quantities involved. Important types include:

</doc>
<doc id="9285" url="https://en.wikipedia.org/wiki?curid=9285" title="Ethical naturalism">
Ethical naturalism

Ethical naturalism (also called moral naturalism or naturalistic cognitivistic definism) is the meta-ethical view which claims that:
Reductive Naturalism
or 
Non-Reductive Naturalism
This makes ethical naturalism a definist form of moral realism, which is in turn a form of cognitivism. Ethical naturalism stands in opposition to ethical non-naturalism, which denies that moral terms refer to anything other than irreducible moral properties, as well as to all forms of moral anti-realism, including ethical subjectivism (which denies that moral propositions refer to objective facts), error theory (which denies that any moral propositions are true), and non-cognitivism (which denies that moral sentences express propositions at all).
It is important to distinguish the versions of ethical naturalism which have received the most sustained philosophical interest, for example, Cornell Realism, from the position that "the way things are is always the way they ought to be", which few ethical naturalists hold. Ethical naturalism does, however, reject the fact-value distinction: it suggests that inquiry into the natural world can increase our moral knowledge in just the same way it increases our scientific knowledge. Indeed, proponents of ethical naturalism have argued that humanity needs to invest in their science of morality â although the existence of such a science is debated.
Ethical naturalism encompasses any reduction of ethical properties, such as 'goodness', to non-ethical properties; there are many different examples of such reductions, and thus many different varieties of ethical naturalism. Hedonism, for example, is the view that goodness is ultimately just pleasure.
Criticisms.
Ethical naturalism has been criticized most prominently by ethical non-naturalist G. E. Moore, who formulated the open-question argument. Garner and Rosen say that a common definition of "natural property" is one "which can be discovered by sense observation or experience, experiment, or through any of the available means of science." They also say that a good definition of "natural property" is problematic but that "it is only in criticism of naturalism, or in an attempt to distinguish between naturalistic and nonnaturalistic definist theories, that such a concept is needed." R. M. Hare also criticised ethical naturalism because of its fallacious definition of the terms 'good' or 'right' explaining how value-terms being part of our prescriptive moral language are not reducible to descriptive terms: "Value-terms have a special function in language, that of commending; and so they plainly cannot be defined in terms of other words which themselves do not perform this function"
Moral relativism.
When it comes to the moral questions that we might ask, it can be difficult to argue that there is not necessarily some level of meta-ethical relativism â and failure to address this matter is criticized as ethnocentrism. 
As a broad example of relativism, we would no doubt see very different moral systems in an alien race that can only survive by occasionally ingesting one another. As a narrow example, there would be further specific moral opinions for each individual of that species.
Some forms of moral realism are compatible with some degree of meta-ethical relativism. This argument rests on the assumption that one can have a "moral" discussion on various scales; that is, what is "good" for: a certain part of your being (leaving open the possibility of conflicting motives), you as a single individual, your family, your society, your species, your type of species. For example, a moral universalist (and certainly an absolutist) might argue that, just as one can discuss what is 'good and evil' at an individual's level, so too can one make certain "moral" propositions with truth values relative at the level of the species. In other words, the moral relativist need not deem "all" moral propositions as necessarily subjective. The answer to "is free speech normally good for human societies?" is relative in a sense, but the moral realist would argue that an individual can be incorrect in this matter. This may be the philosophical equivalent of the more pragmatic arguments made by some scientists.
Moral nihilism.
Moral nihilists maintain that any talk of an objective morality is incoherent and better off using other terms. Proponents of moral science like Ronald A. Lindsay have counter-argued that their way of understanding "morality" as a practical enterprise is the way we ought to have understood it in the first place. He holds the position that the alternative seems to be the elaborate philosophical reduction of the word "moral" into a vacuous, useless term. Lindsay adds that it is important to reclaim the specific word "Morality" because of the connotations it holds with many individuals.
Morality as a science.
Author Sam Harris has argued that we overestimate the relevance of many arguments against the science of morality, arguments he believes scientists happily and rightly disregard in other domains of science like physics. For example, a scientist may find herself attempting to argue against philosophical skeptics, when Harris says she should be practically asking â as scientists would in any other domain â "why would we listen to a solipsist in the first place?" This, Harris contends, is part of what it means to practice a science of morality.
Physicist Sean Carroll believes that conceiving of morality as a science could be a case of scientific imperialism and insists that what is "good for conscious creatures" is not an adequate working definition of "moral".
In opposition, Vice President at the Center for Inquiry, John Shook, claims that this working definition is more than adequate for science at present, and that disagreement should not immobilize the scientific study of ethics.
Richard Carrier's chapter "Moral Facts Naturally Exist (and Science Could Find Them)" sets out to prove a Moral realism centered around human satisfaction. It was peer reviewed by four philosophers.
In modern times, many thinkers discussing the fact-value distinction and the Is-ought problem have settled on the idea that one cannot derive "ought" from "is". Conversely, Harris maintains that the fact-value distinction is a confusion, proposing that values are really a certain kind of fact. Specifically, Harris suggests that values amount to empirical statements about "the flourishing of conscious creatures in a society". He argues that there are objective answers to moral questions, even if some are difficult or impossible to possess in practice. In this way, he says, science can tell us what to value. Harris adds that we do not demand absolute certainty from predictions in physics so we should not demand that of a science studying morality.

</doc>
<doc id="9286" url="https://en.wikipedia.org/wiki?curid=9286" title="Ethical non-naturalism">
Ethical non-naturalism

Ethical non-naturalism is the meta-ethical view which claims that:
This makes ethical non-naturalism a non-definist form of moral realism, which is in turn a form of cognitivism. Ethical non-naturalism stands in opposition to ethical naturalism, which claims that moral terms and properties are reducible to non-moral terms and properties, as well as to all forms of moral anti-realism, including ethical subjectivism (which denies that moral propositions refer to objective facts), error theory (which denies that any moral propositions are true), and non-cognitivism (which denies that moral sentences express propositions at all).
Definitions and examples.
According to G. E. Moore, "Goodness is a simple, undefinable, non-natural property." To call goodness "non-natural" does not mean that it is supernatural or divine. It does mean, however, that goodness cannot be reduced to natural properties such as needs, wants or pleasures. Moore also stated that a reduction of ethical properties to a divine command would be the same as stating their naturalness. This would be an example of what he referred to as "the naturalistic fallacy."
Moore claimed that goodness is "indefinable", i.e., it cannot be defined in any other terms. This is the central claim of non-naturalism. Thus, the meaning of sentences containing the word "good" cannot be explained entirely in terms of sentences not containing the word "good." One cannot substitute words referring to pleasure, needs or anything else in place of "good."
Some properties, such as hardness, roundness and dampness, are clearly natural properties. We encounter them in the real world and can perceive them. On the other hand, other properties, such as being good and being right, are not so obvious. A great novel is considered to be a good thing; goodness may be said to be a property of that novel. Paying one's debts and telling the truth are generally held to be right things to do; rightness may be said to be a property of certain human actions.
However, these two types of property are quite different. Those natural properties, such as hardness and roundness, can be perceived and encountered in the real world. On the other hand, it is not immediately clear how to physically see, touch or measure the goodness of a novel or the rightness of an action.
A difficult question.
Moore did not consider goodness and rightness to be natural properties, i.e., they cannot be defined in terms of any natural properties. How, then, can we know that anything is good and how can we distinguish good from bad? 
Moral epistemology, the part of epistemology (and/or ethics) that studies how we know moral facts and how moral beliefs are justified, has proposed an answer. British epistemologists, following Moore, suggested that humans have a special faculty, a faculty of moral intuition, which tells us what is good and bad, right and wrong. 
Ethical intuitionists assert that, if we see a good person or a right action, and our faculty of moral intuition is sufficiently developed and unimpaired, we simply intuit that the person is good or that the action is right. Moral intuition is supposed to be a mental process different from other, more familiar faculties like sense-perception, and that moral judgments are its outputs. When someone judges something to be good, or some action to be right, then the person is using the faculty of moral intuition. The faculty is attuned to those non-natural properties. Perhaps the best ordinary notion that approximates moral intuition would be the idea of a conscience.
Another argument for non-naturalism.
Moore also introduced what is called the Open Question Argument, a position he later rejected. 
Suppose a definition of "good" is "pleasure-causing." In other words, if something is good, it causes pleasure; if it causes pleasure, then it is, by definition, good. Moore asserted, however, that we could always ask, "But are pleasure-causing things good?" This would always be an open question. There is no foregone conclusion that, indeed, pleasure-causing things are good. 
In his initial argument, Moore concluded that any similar definition of goodness could be criticized in the same way.

</doc>
<doc id="9288" url="https://en.wikipedia.org/wiki?curid=9288" title="Elvis Presley">
Elvis Presley

Elvis Aaron Presley (January 8, 1935Â â August 16, 1977) was an American singer and actor. Regarded as one of the most significant cultural icons of the 20th century, he is often referred to as "the King of Rock and Roll", or simply, "the King".
Presley was born in Tupelo, Mississippi, as a twinless twin, and when he was 13 years old, he and his family relocated to Memphis, Tennessee. His music career began there in 1954, when he recorded a song with producer Sam Phillips at Sun Records. Accompanied by guitarist Scotty Moore and bassist Bill Black, Presley was an early popularizer of rockabilly, an uptempo, backbeat-driven fusion of country music and rhythm and blues. RCA Victor acquired his contract in a deal arranged by Colonel Tom Parker, who managed the singer for more than two decades. Presley's first RCA single, "Heartbreak Hotel", was released in January 1956 and became a number-one hit in the United States. He was regarded as the leading figure of rock and roll after a series of successful network television appearances and chart-topping records. His energized interpretations of songs and sexually provocative performance style, combined with a singularly potent mix of influences across color lines that coincided with the dawn of the Civil Rights Movement, made him enormously popularâand controversial.
In November 1956, he made his film debut in "Love Me Tender". In 1958, he was drafted into military service. He resumed his recording career two years later, producing some of his most commercially successful work before devoting much of the 1960s to making Hollywood films and their accompanying soundtrack albums, most of which were critically derided. In 1968, following a seven-year break from live performances, he returned to the stage in the acclaimed televised comeback special "Elvis", which led to an extended Las Vegas concert residency and a string of highly profitable tours. In 1973, Presley was featured in the first globally broadcast concert via satellite, "Aloha from Hawaii". Several years of prescription drug abuse severely damaged his health, and he died in 1977 at the age of 42.
Presley is one of the most celebrated and influential musicians of the 20th century. Commercially successful in many genres, including pop, blues and gospel, he is the best-selling solo artist in the history of recorded music, with estimated record sales of around 600 million units worldwide. He won three Grammys, also receiving the Grammy Lifetime Achievement Award at age 36, and has been inducted into multiple music halls of fame.
Life and career.
Early years (1935â53).
Childhood in Tupelo.
Presley was born on January 8, 1935, in Tupelo, Mississippi, the son of Gladys Love (nÃ©e Smith; April 25, 1912Â â August 14, 1958) and Vernon Elvis Presley (April 10, 1916Â â June 26, 1979), in the two-room shotgun house built by Vernon's father in preparation for the child's birth. Jesse Garon Presley, his identical twin brother, was delivered stillborn 35 minutes before him. As an only child, Presley became close to both parents and formed an especially close bond with his mother. The family attended an Assembly of God church, where he found his initial musical inspiration.
Presley's ancestry was primarily a Western European mix, including Scots-Irish, Scottish, German, and some French Norman. Gladys's great-great-grandmother, Morning Dove White, was possibly a Cherokee Native American. Gladys was regarded by relatives and friends as the dominant member of the small family. Vernon moved from one odd job to the next, evidencing little ambition. The family often relied on help from neighbors and government food assistance. The Presleys survived the F5 tornado in the 1936 TupeloâGainesville tornado outbreak. In 1938, they lost their home after Vernon was found guilty of kiting a check written by the landowner, Orville S. Bean, the dairy farmer and cattle-and-hog broker for whom he then worked. He was jailed for eight months, and Gladys and Elvis moved in with relatives.
In September 1941, Presley entered first grade at East Tupelo Consolidated, where his instructors regarded him as "average". He was encouraged to enter a singing contest after impressing his schoolteacher with a rendition of Red Foley's country song "Old Shep" during morning prayers. The contest, held at the Mississippi-Alabama Fair and Dairy Show on October 3, 1945, was his first public performance: dressed as a cowboy, the ten-year-old Presley stood on a chair to reach the microphone and sang "Old Shep". He recalled placing fifth. A few months later, Presley received his first guitar for his birthday; he had hoped for something elseâby different accounts, either a bicycle or a rifle. Over the following year, he received basic guitar lessons from two of his uncles and the new pastor at the family's church. Presley recalled, "I took the guitar, and I watched people, and I learned to play a little bit. But I would never sing in public. I was very shy about it."
Entering a new school, Milam, for sixth grade in September 1946, Presley was regarded as a loner. The following year, he began bringing his guitar in on a daily basis. He played and sang during lunchtime, and was often teased as a "trashy" kid who played hillbilly music. The family was by then living in a largely African-American neighborhood. A devotee of Mississippi Slim's show on the Tupelo radio station WELO, Presley was described as "crazy about music" by Slim's younger brother, a classmate of Presley's, who often took him into the station. Slim supplemented Presley's guitar tuition by demonstrating chord techniques. When his protÃ©gÃ© was 12 years old, Slim scheduled him for two on-air performances. Presley was overcome by stage fright the first time, but succeeded in performing the following week.
Teenage life in Memphis.
In November 1948, the family moved to Memphis, Tennessee. After residing for nearly a year in rooming houses, they were granted a two-bedroom apartment in the public housing complex known as the Lauderdale Courts. Enrolled at L. C. Humes High School, Presley received only a C in music in eighth grade. When his music teacher told him he had no aptitude for singing, he brought in his guitar the next day and sang a recent hit, "Keep Them Cold Icy Fingers Off Me", in an effort to prove otherwise. A classmate later recalled that the teacher "agreed that Elvis was right when he said that she didn't appreciate his kind of singing." He was usually too shy to perform openly, and was occasionally bullied by classmates who viewed him as a "mama's boy". In 1950, he began practicing guitar regularly under the tutelage of Jesse Lee Denson, a neighbor two-and-a-half years his senior. They and three other boysâincluding two future rockabilly pioneers, brothers Dorsey and Johnny Burnetteâformed a loose musical collective that played frequently around the Courts. That September, he began ushering at Loew's State Theater. Other jobs followed, including Precision Tool, Loew's again, and MARL Metal Products.
During his junior year, Presley began to stand out more among his classmates, largely because of his appearance: he grew out his sideburns and styled his hair with rose oil and Vaseline. On his own time, he would head down to Beale Street, the heart of Memphis's thriving blues scene, and gaze longingly at the wild, flashy clothes in the windows of Lansky Brothers. By his senior year, he was wearing them. Overcoming his reticence about performing outside the Lauderdale Courts, he competed in Humes's Annual "Minstrel" show in April 1953. Singing and playing guitar, he opened with "Till I Waltz Again with You", a recent hit for Teresa Brewer. Presley recalled that the performance did much for his reputation: "I wasn't popular in schoolÂ ... I failed musicâonly thing I ever failed. And then they entered me in this talent showÂ ... when I came onstage I heard people kind of rumbling and whispering and so forth, 'cause nobody knew I even sang. It was amazing how popular I became after that."
Presley, who never received formal music training or learned to read music, studied and played by ear. He also frequented record stores with jukeboxes and listening booths. He knew all of Hank Snow's songs, and he loved records by other country singers such as Roy Acuff, Ernest Tubb, Ted Daffan, Jimmie Rodgers, Jimmie Davis, and Bob Wills. The Southern gospel singer Jake Hess, one of his favorite performers, was a significant influence on his ballad-singing style. He was a regular audience member at the monthly All-Night Singings downtown, where many of the white gospel groups that performed reflected the influence of African-American spiritual music. He adored the music of black gospel singer Sister Rosetta Tharpe. Like some of his peers, he may have attended blues venuesâof necessity, in the segregated South, on only the nights designated for exclusively white audiences. He certainly listened to the regional radio stations, such as WDIA-AM, that played "race records": spirituals, blues, and the modern, backbeat-heavy sound of rhythm and blues. Many of his future recordings were inspired by local African-American musicians such as Arthur Crudup and Rufus Thomas. B.B. King recalled that he had known Presley before he was popular, when they both used to frequent Beale Street. By the time he graduated from high school in June 1953, Presley had already singled out music as his future.
First recordings (1953â55).
Sam Phillips and Sun Records.
In August 1953, Presley walked into the offices of Sun Records. He aimed to pay for a few minutes of studio time to record a two-sided acetate disc: "My Happiness" and "That's When Your Heartaches Begin". He would later claim that he intended the record as a gift for his mother, or that he was merely interested in what he "sounded like", although there was a much cheaper, amateur record-making service at a nearby general store. Biographer Peter Guralnick argues that he chose Sun in the hope of being discovered. Asked by receptionist Marion Keisker what kind of singer he was, Presley responded, "I sing all kinds." When she pressed him on who he sounded like, he repeatedly answered, "I don't sound like nobody." After he recorded, Sun boss Sam Phillips asked Keisker to note down the young man's name, which she did along with her own commentary: "Good ballad singer. Hold."
In January 1954, Presley cut a second acetate at Sun Recordsâ"I'll Never Stand In Your Way" and "It Wouldn't Be the Same Without You"âbut again nothing came of it. Not long after, he failed an audition for a local vocal quartet, the Songfellows. He explained to his father, "They told me I couldn't sing." Songfellow Jim Hamill later claimed that he was turned down because he did not demonstrate an ear for harmony at the time. In April, Presley began working for the Crown Electric company as a truck driver. His friend Ronnie Smith, after playing a few local gigs with him, suggested he contact Eddie Bond, leader of Smith's professional band, which had an opening for a vocalist. Bond rejected him after a tryout, advising Presley to stick to truck driving "because you're never going to make it as a singer".
Phillips, meanwhile, was always on the lookout for someone who could bring to a broader audience the sound of the black musicians on whom Sun focused. As Keisker reported, "Over and over I remember Sam saying, 'If I could find a white man who had the Negro sound and the Negro feel, I could make a billion dollars.'" In June, he acquired a demo recording of a ballad, "Without You", that he thought might suit the teenage singer. Presley came by the studio, but was unable to do it justice. Despite this, Phillips asked Presley to sing as many numbers as he knew. He was sufficiently affected by what he heard to invite two local musicians, guitarist Winfield "Scotty" Moore and upright bass player Bill Black, to work something up with Presley for a recording session.
The session, held the evening of July 5, 1954, proved entirely unfruitful until late in the night. As they were about to give up and go home, Presley took his guitar and launched into a 1946 blues number, Arthur Crudup's "That's All Right". Moore recalled, "All of a sudden, Elvis just started singing this song, jumping around and acting the fool, and then Bill picked up his bass, and he started acting the fool, too, and I started playing with them. Sam, I think, had the door to the control booth openÂ ... he stuck his head out and said, 'What are you doing?' And we said, 'We don't know.' 'Well, back up,' he said, 'try to find a place to start, and do it again.'" Phillips quickly began taping; this was the sound he had been looking for. Three days later, popular Memphis DJ Dewey Phillips played "That's All Right" on his "Red, Hot, and Blue" show. Listeners began phoning in, eager to find out who the singer was. The interest was such that Phillips played the record repeatedly during the last two hours of his show. Interviewing Presley on-air, Phillips asked him what high school he attended in order to clarify his color for the many callers who had assumed he was black. During the next few days, the trio recorded a bluegrass number, Bill Monroe's "Blue Moon of Kentucky", again in a distinctive style and employing a jury-rigged echo effect that Sam Phillips dubbed "slapback". A single was pressed with "That's All Right" on the A side and "Blue Moon of Kentucky" on the reverse.
Early live performances and signing with RCA.
The trio played publicly for the first time on July 17 at the Bon Air clubâPresley still sporting his child-size guitar. At the end of the month, they appeared at the Overton Park Shell, with Slim Whitman headlining. A combination of his strong response to rhythm and nervousness at playing before a large crowd led Presley to shake his legs as he performed: his wide-cut pants emphasized his movements, causing young women in the audience to start screaming. Moore recalled, "During the instrumental parts, he would back off from the mike and be playing and shaking, and the crowd would just go wild". Black, a natural showman, whooped and rode his bass, hitting double licks that Presley would later remember as "really a wild sound, like a jungle drum or something".
Soon after, Moore and Black quit their old band to play with Presley regularly, and DJ and promoter Bob Neal became the trio's manager. From August through October, they played frequently at the Eagle's Nest club and returned to Sun Studio for more recording sessions, and Presley quickly grew more confident on stage. According to Moore, "His movement was a natural thing, but he was also very conscious of what got a reaction. He'd do something one time and then he would expand on it real quick." Presley made what would be his only appearance on Nashville's "Grand Ole Opry" on October 2; after a polite audience response, "Opry" manager Jim Denny told Phillips that his singer was "not bad" but did not suit the program. Two weeks later, Presley was booked on "Louisiana Hayride", the "Opry"s chief, and more adventurous, rival. The Shreveport-based show was broadcast to 198 radio stations in 28 states. Presley had another attack of nerves during the first set, which drew a muted reaction. A more composed and energetic second set inspired an enthusiastic response. House drummer D. J. Fontana brought a new element, complementing Presley's movements with accented beats that he had mastered playing in strip clubs. Soon after the show, the "Hayride" engaged Presley for a year's worth of Saturday-night appearances. Trading in his old guitar for $8 (and seeing it promptly dispatched to the garbage), he purchased a Martin instrument for $175, and his trio began playing in new locales including Houston, Texas, and Texarkana, Arkansas.
By early 1955, Presley's regular "Hayride" appearances, constant touring, and well-received record releases had made him a regional star, from Tennessee to West Texas. In January, Neal signed a formal management contract with Presley and brought the singer to the attention of Colonel Tom Parker, whom he considered the best promoter in the music business. Having successfully managed top country star Eddy Arnold, Parker was now working with the new number-one country singer, Hank Snow. Parker booked Presley on Snow's February tour. When the tour reached Odessa, Texas, a 19-year-old Roy Orbison saw Presley for the first time: "His energy was incredible, his instinct was just amazing.Â ... I just didn't know what to make of it. There was just no reference point in the culture to compare it." Presley made his television debut on March 3 on the KSLA-TV broadcast of "Louisiana Hayride". Soon after, he failed an audition for "Arthur Godfrey's Talent Scouts" on the CBS television network. By August, Sun had released ten sides credited to "Elvis Presley, Scotty and Bill"; on the latest recordings, the trio were joined by a drummer. Some of the songs, like "That's All Right", were in what one Memphis journalist described as the "R&B idiom of negro field jazz"; others, like "Blue Moon of Kentucky", were "more in the country field", "but there was a curious blending of the two different musics in both". This blend of styles made it difficult for Presley's music to find radio airplay. According to Neal, many country-music disc jockeys would not play it because he sounded too much like a black artist and none of the rhythm-and-blues stations would touch him because "he sounded too much like a hillbilly." The blend came to be known as rockabilly. At the time, Presley was variously billed as "The King of Western Bop", "The Hillbilly Cat", and "The Memphis Flash".
Presley renewed Neal's management contract in August 1955, simultaneously appointing Parker as his special adviser. The group maintained an extensive touring schedule throughout the second half of the year. Neal recalled, "It was almost frightening, the reaction that came to Elvis from the teenaged boys. So many of them, through some sort of jealousy, would practically hate him. There were occasions in some towns in Texas when we'd have to be sure to have a police guard because somebody'd always try to take a crack at him. They'd get a gang and try to waylay him or something." The trio became a quartet when "Hayride" drummer Fontana joined as a full member. In mid-October, they played a few shows in support of Bill Haley, whose "Rock Around the Clock" had been a number-one hit the previous year. Haley observed that Presley had a natural feel for rhythm, and advised him to sing fewer ballads.
At the Country Disc Jockey Convention in early November, Presley was voted the year's most promising male artist. Several record companies had by now shown interest in signing him. After three major labels made offers of up to $25,000, Parker and Phillips struck a deal with RCA Victor on November 21 to acquire Presley's Sun contract for an unprecedented $40,000. Presley, at 20, was still a minor, so his father signed the contract. Parker arranged with the owners of Hill and Range Publishing, Jean and Julian Aberbach, to create two entities, Elvis Presley Music and Gladys Music, to handle all the new material recorded by Presley. Songwriters were obliged to forgo one third of their customary royalties in exchange for having him perform their compositions. By December, RCA had begun to heavily promote its new singer, and before month's end had reissued many of his Sun recordings.
Commercial breakout and controversy (1956â58).
First national TV appearances and debut album.
On January 10, 1956, Presley made his first recordings for RCA in Nashville. Extending the singer's by now customary backup of Moore, Black, and Fontana, RCA enlisted pianist Floyd Cramer, guitarist Chet Atkins, and three background singers, including first tenor Gordon Stoker of the popular Jordanaires quartet, to fill out the sound. The session produced the moody, unusual "Heartbreak Hotel", released as a single on January 27. Parker finally brought Presley to national television, booking him on CBS's "Stage Show" for six appearances over two months. The program, produced in New York, was hosted on alternate weeks by big band leaders and brothers Tommy and Jimmy Dorsey. After his first appearance, on January 28, introduced by disc jockey Bill Randle, Presley stayed in town to record at RCA's New York studio. The sessions yielded eight songs, including a cover of Carl Perkins' rockabilly anthem "Blue Suede Shoes". In February, Presley's "I Forgot to Remember to Forget", a Sun recording initially released the previous August, reached the top of the "Billboard" country chart. Neal's contract was terminated and, on March 2, Parker became Presley's manager.
RCA Victor released Presley's self-titled debut album on March 23. Joined by five previously unreleased Sun recordings, its seven recently recorded tracks were of a broad variety. There were two country songs and a bouncy pop tune. The others would centrally define the evolving sound of rock and roll: "Blue Suede Shoes"â"an improvement over Perkins' in almost every way", according to critic Robert Hilburnâand three R&B numbers that had been part of Presley's stage repertoire for some time, covers of Little Richard, Ray Charles, and The Drifters. As described by Hilburn, these "were the most revealing of all. Unlike many white artistsÂ ... who watered down the gritty edges of the original R&B versions of songs in the '50s, Presley reshaped them. He not only injected the tunes with his own vocal character but also made guitar, not piano, the lead instrument in all three cases." It became the first rock-and-roll album to top the "Billboard" chart, a position it held for 10 weeks. While Presley was not an innovative guitarist like Moore or contemporary African American rockers Bo Diddley and Chuck Berry, cultural historian Gilbert B. Rodman argues that the album's cover image, "of Elvis having the time of his life on stage "with a guitar in his hands" played a crucial role in positioning the guitarÂ ... as the instrument that best captured the style and spirit of this new music."
"Milton Berle Show" and "Hound Dog".
Presley made the first of two appearances on NBC's "Milton Berle Show" on April 3. His performance, on the deck of the USS "Hancock" in San Diego, prompted cheers and screams from an audience of sailors and their dates. A few days later, a flight taking Presley and his band to Nashville for a recording session left all three badly shaken when an engine died and the plane almost went down over Arkansas. Twelve weeks after its original release, "Heartbreak Hotel" became Presley's first number-one pop hit. In late April, Presley began a two-week residency at the New Frontier Hotel and Casino on the Las Vegas Strip. The shows were poorly received by the conservative, middle-aged hotel guestsâ"like a jug of corn liquor at a champagne party," wrote a critic for "Newsweek." Amid his Vegas tenure, Presley, who had serious acting ambitions, signed a seven-year contract with Paramount Pictures. He began a tour of the Midwest in mid-May, taking in 15 cities in as many days. He had attended several shows by Freddie Bell and the Bellboys in Vegas and was struck by their cover of "Hound Dog", a hit in 1953 for blues singer Big Mama Thornton by songwriters Jerry Leiber and Mike Stoller. It became the new closing number of his act. After a show in La Crosse, Wisconsin, an urgent message on the letterhead of the local Catholic diocese's newspaper was sent to FBI director J. Edgar Hoover. It warned that "Presley is a definite danger to the security of the United States.Â ... i actions and motions were such as to rouse the sexual passions of teenaged youth.Â ... After the show, more than 1,000 teenagers tried to gang into Presley's room at the auditorium.Â ... Indications of the harm Presley did just in La Crosse were the two high school girlsÂ ... whose abdomen and thigh had Presley's autograph."
The second "Milton Berle Show" appearance came on June 5 at NBC's Hollywood studio, amid another hectic tour. Berle persuaded the singer to leave his guitar backstage, advising, "Let 'em see you, son." During the performance, Presley abruptly halted an uptempo rendition of "Hound Dog" with a wave of his arm and launched into a slow, grinding version accentuated with energetic, exaggerated body movements. Presley's gyrations created a storm of controversy. Newspaper critics were outraged: Jack Gould of "The New York Times" wrote, "Mr. Presley has no discernible singing ability.Â ... His phrasing, if it can be called that, consists of the stereotyped variations that go with a beginner's aria in a bathtub.Â ... His one specialty is an accented movement of the bodyÂ ... primarily identified with the repertoire of the blond bombshells of the burlesque runway." Ben Gross of the New York "Daily News" opined that popular music "has reached its lowest depths in the 'grunt and groin' antics of one Elvis Presley.Â ... Elvis, who rotates his pelvisÂ ... gave an exhibition that was suggestive and vulgar, tinged with the kind of animalism that should be confined to dives and bordellos". Ed Sullivan, whose own variety show was the nation's most popular, declared him "unfit for family viewing". To Presley's displeasure, he soon found himself being referred to as "Elvis the Pelvis", which he called "one of the most childish expressions I ever heard, comin' from an adult."
"Steve Allen Show" and first Sullivan appearance.
The Berle shows drew such high ratings that Presley was booked for a July 1 appearance on NBC's "Steve Allen Show" in New York. Allen, no fan of rock and roll, introduced a "new Elvis" in a white bow tie and black tails. Presley sang "Hound Dog" for less than a minute to a basset hound wearing a top hat and bow tie. As described by television historian Jake Austen, "Allen thought Presley was talentless and absurdÂ ... set things up so that Presley would show his contrition". Allen, for his part, later wrote that he found Presley's "strange, gangly, country-boy charisma, his hard-to-define cuteness, and his charming eccentricity intriguing" and simply worked the singer into the customary "comedy fabric" of his program. Just before the final rehearsal for the show, Presley told a reporter, "I'm holding down on this show. I don't want to do anything to make people dislike me. I think TV is important so I'm going to go along, but I won't be able to give the kind of show I do in a personal appearance." Presley would refer back to the Allen show as the most ridiculous performance of his career. Later that night, he appeared on "Hy Gardner Calling", a popular local TV show. Pressed on whether he had learned anything from the criticism to which he was being subjected, Presley responded, "No, I haven't, I don't feel like I'm doing anything wrong.Â ... I don't see how any type of music would have any bad influence on people when it's only music.Â ... I mean, how would rock 'n' roll music make anyone rebel against their parents?"
The next day, Presley recorded "Hound Dog", along with "Any Way You Want Me" and "Don't Be Cruel". The Jordanaires sang harmony, as they had on "The Steve Allen Show"; they would work with Presley through the 1960s. A few days later, the singer made an outdoor concert appearance in Memphis at which he announced, "You know, those people in New York are not gonna change me none. I'm gonna show you what the real Elvis is like tonight." In August, a judge in Jacksonville, Florida, ordered Presley to tame his act. Throughout the following performance, he largely kept still, except for wiggling his little finger suggestively in mockery of the order. The single pairing "Don't Be Cruel" with "Hound Dog" ruled the top of the charts for 11 weeksâa mark that would not be surpassed for 36 years. Recording sessions for Presley's second album took place in Hollywood during the first week of September. Leiber and Stoller, the writers of "Hound Dog," contributed "Love Me."
Allen's show with Presley had, for the first time, beaten CBS's "Ed Sullivan Show" in the ratings. Sullivan, despite his June pronouncement, booked the singer for three appearances for an unprecedented $50,000. The first, on September 9, 1956, was seen by approximately 60 million viewersâa record 82.6 percent of the television audience. Actor Charles Laughton hosted the show, filling in while Sullivan recuperated from a car accident. Presley appeared in two segments that night from CBS Television City in Los Angeles. According to Elvis legend, Presley was shot from only the waist up. Watching clips of the Allen and Berle shows with his producer, Sullivan had opined that Presley "got some kind of device hanging down below the crotch of his pantsâso when he moves his legs back and forth you can see the outline of his cock.Â ... I think it's a Coke bottle.Â ... We just can't have this on a Sunday night. This is a family show!" Sullivan publicly told "TV Guide", "As for his gyrations, the whole thing can be controlled with camera shots." In fact, Presley was shown head-to-toe in the first and second shows. Though the camerawork was relatively discreet during his debut, with leg-concealing closeups when he danced, the studio audience reacted in customary style: screaming. Presley's performance of his forthcoming single, the ballad "Love Me Tender", prompted a record-shattering million advance orders. More than any other single event, it was this first appearance on "The Ed Sullivan Show" that made Presley a national celebrity of barely precedented proportions.
Accompanying Presley's rise to fame, a cultural shift was taking place that he both helped inspire and came to symbolize. Igniting the "biggest pop craze since Glenn Miller and Frank SinatraÂ ... Presley brought rock'n'roll into the mainstream of popular culture", writes historian Marty Jezer. "As Presley set the artistic pace, other artists followed.Â ... Presley, more than anyone else, gave the young a belief in themselves as a distinct and somehow unified generationâthe first in America ever to feel the power of an integrated youth culture."
Crazed crowds and film debut.
The audience response at Presley's live shows became increasingly fevered. Moore recalled, "He'd start out, 'You ain't nothin' but a Hound Dog,' and they'd just go to pieces. They'd always react the same way. There'd be a riot every time." At the two concerts he performed in September at the Mississippi-Alabama Fair and Dairy Show, 50 National Guardsmen were added to the police security to prevent crowd trouble. "Elvis", Presley's second album, was released in October and quickly rose to number one. The album includes "Old Shep", which he sung at the talent show in 1945, and which now marked the first time he played piano on an RCA session. According to Guralnick, one can hear "in the halting chords and the somewhat stumbling rhythm both the unmistakable emotion and the equally unmistakable valuing of emotion over technique." Assessing the musical and cultural impact of Presley's recordings from "That's All Right" through "Elvis", rock critic Dave Marsh wrote that "these records, more than any others, contain the seeds of what rock & roll was, has been and most likely what it may foreseeably become."
Presley returned to the Sullivan show at its main studio in New York, hosted this time by its namesake, on October 28. After the performance, crowds in Nashville and St. Louis burned him in effigy. His first motion picture, "Love Me Tender", was released on November 21. Though he was not top billed, the film's original titleâ"The Reno Brothers"âwas changed to capitalize on his latest number one record: "Love Me Tender" had hit the top of the charts earlier that month. To further take advantage of Presley's popularity, four musical numbers were added to what was originally a straight acting role. The film was panned by the critics but did very well at the box office.
On December 4, Presley dropped into Sun Records where Carl Perkins and Jerry Lee Lewis were recording and jammed with them. Though Phillips no longer had the right to release any Presley material, he made sure the session was captured on tape. The results became legendary as the "Million Dollar Quartet" recordingsâJohnny Cash was long thought to have played as well, but he was present only briefly at Phillips' instigation for a photo opportunity. The year ended with a front-page story in "The Wall Street Journal" reporting that Presley merchandise had brought in $22 million on top of his record sales, and "Billboard"s declaration that he had placed more songs in the top 100 than any other artist since records were first charted. In his first full year at RCA, one of the music industry's largest companies, Presley had accounted for over 50 percent of the label's singles sales.
Leiber and Stoller collaboration and draft notice.
Presley made his third and final "Ed Sullivan Show" appearance on January 6, 1957âon this occasion indeed shot only down to the waist. Some commentators have claimed that Parker orchestrated an appearance of censorship to generate publicity. In any event, as critic Greil Marcus describes, Presley "did not tie himself down. Leaving behind the bland clothes he had worn on the first two shows, he stepped out in the outlandish costume of a pasha, if not a harem girl. From the make-up over his eyes, the hair falling in his face, the overwhelmingly sexual cast of his mouth, he was playing Rudolph Valentino in "The Sheik", with all stops out." To close, displaying his range and defying Sullivan's wishes, Presley sang a gentle black spiritual, "Peace in the Valley". At the end of the show, Sullivan declared Presley "a real decent, fine boy".
Two days later, the Memphis draft board announced that Presley would be classified 1-A and would probably be drafted sometime that year.
Each of the three Presley singles released in the first half of 1957 went to number one: "Too Much", "All Shook Up", and "(Let Me Be Your) Teddy Bear". Already an international star, he was attracting fans even where his music was not officially released. Under the headline "Presley Records a Craze in Soviet", "The New York Times" reported that pressings of his music on discarded X-ray plates were commanding high prices in Leningrad. Between film shoots and recording sessions, the singer also found time to purchase an 18-room mansion eight miles (13Â km) south of downtown Memphis for himself and his parents: Graceland. When he reported to the film studio for his second film, the Technicolor "Loving You", released in July, "The makeup man said that with his eyes he should photograph well with black hair, so they dyed it." "Loving You", the accompanying soundtrack, was Presley's third straight number one album. The title track was written by Leiber and Stoller, who were then retained to write four of the six songs recorded at the sessions for "Jailhouse Rock", Presley's next film. The songwriting team effectively produced the "Jailhouse" sessions and developed a close working relationship with Presley, who came to regard them as his "good-luck charm".
Leiber remembered initially finding Presley "not quite authenticâafter all, he was a white singer, and my standards were black." According to Stoller, the duo was "surprised at the kind of knowledge that he had about black music. We figured that he had these remarkable pipes and all that, but we didn't realize that he knew so much about the blues. We were quite surprised to find out that he knew as much about it as we did. He certainly knew a lot more than we did about country music and gospel music." Leiber remembered the recording process with Presley, "He was fast. Any demo you gave him he knew by heart in ten minutes." As Stoller recalled, Presley "was 'protected'" by his manager and entourage. "He was removed. â¦ They kept him separate."
Presley undertook three brief tours during the year, continuing to generate a crazed audience response. A Detroit newspaper suggested that "the trouble with going to see Elvis Presley is that you're liable to get killed." Villanova students pelted him with eggs in Philadelphia, and in Vancouver, the crowd rioted after the end of the show, destroying the stage. Frank Sinatra, who had famously inspired the swooning of teenaged girls in the 1940s, condemned the new musical phenomenon. In a magazine article, he decried rock and roll as "brutal, ugly, degenerate, vicious.Â ... It fosters almost totally negative and destructive reactions in young people. It smells phoney and false. It is sung, played and written, for the most part, by cretinous goons.Â ... This rancid-smelling aphrodisiac I deplore." Asked for a response, Presley said, "I admire the man. He has a right to say what he wants to say. He is a great success and a fine actor, but I think he shouldn't have said it.Â ... This is a trend, just the same as he faced when he started years ago."
Leiber and Stoller were again in the studio for the recording of "Elvis' Christmas Album". Toward the end of the session, they wrote a song on the spot at Presley's request: "Santa Claus Is Back In Town", an innuendo-laden blues. The holiday release stretched Presley's string of number one albums to four and would eventually become the best selling Christmas album of all time. After the session, Moore and Blackâdrawing only modest weekly salaries, sharing in none of Presley's massive financial successâresigned. Though they were brought back on a per diem basis a few weeks later, it was clear that they had not been part of Presley's inner circle for some time. On December 20, Presley received his draft notice. He was granted a deferment to finish the forthcoming "King Creole", in which $350,000 had already been invested by Paramount and producer Hal Wallis. A couple of weeks into the new year, "Don't", another Leiber and Stoller tune, became Presley's tenth number one seller. It had been only 21 months since "Heartbreak Hotel" had brought him to the top for the first time. Recording sessions for the "King Creole" soundtrack were held in Hollywood mid-January. Leiber and Stoller provided three songs and were again on hand, but it would be the last time they worked closely with Presley. A studio session on February 1 marked another ending: it was the final occasion on which Black was to perform with Presley. He died in 1965.
Military service and mother's death (1958â60).
On March 24, Presley was inducted into the U.S. Army as a private at Fort Chaffee, near Fort Smith, Arkansas. His arrival was a major media event. Hundreds of people descended on Presley as he stepped from the bus; photographers then accompanied him into the fort. Presley announced that he was looking forward to his military stint, saying he did not want to be treated any differently from anyone else: "The Army can do anything it wants with me."
Soon after Presley commenced basic training at Fort Hood, Texas, he received a visit from Eddie Fadal, a businessman he had met on tour. According to Fadal, Presley had become convinced his career was finishedâ"He firmly believed that." But then, during a two-week leave in early June, Presley recorded five songs in Nashville. In early August, his mother was diagnosed with hepatitis and her condition rapidly worsened. Presley, granted emergency leave to visit her, arrived in Memphis on August 12. Two days later, she died of heart failure, aged 46. Presley was devastated; their relationship had remained extremely closeâeven into his adulthood, they would use baby talk with each other and Presley would address her with pet names.
After training, Presley joined the 3rd Armored Division in Friedberg, Germany, on October 1. Introduced to amphetamines by a sergeant while on maneuvers, he became "practically evangelical about their benefits"ânot only for energy, but for "strength" and weight loss, as wellâand many of his friends in the outfit joined him in indulging. The Army also introduced Presley to karate, which he studied seriously, later including it in his live performances. Fellow soldiers have attested to Presley's wish to be seen as an able, ordinary soldier, despite his fame, and to his generosity. He donated his Army pay to charity, purchased TV sets for the base, and bought an extra set of fatigues for everyone in his outfit.
While in Friedberg, Presley met 14-year-old Priscilla Beaulieu. They would eventually marry after a seven-and-a-half-year courtship. In her autobiography, Priscilla says that despite his worries that it would ruin his career, Parker convinced Presley that to gain popular respect, he should serve his country as a regular soldier rather than in Special Services, where he would have been able to give some musical performances and remain in touch with the public. Media reports echoed Presley's concerns about his career, but RCA producer Steve Sholes and Freddy Bienstock of Hill and Range had carefully prepared for his two-year hiatus. Armed with a substantial amount of unreleased material, they kept up a regular stream of successful releases. Between his induction and discharge, Presley had ten top 40 hits, including "Wear My Ring Around Your Neck", the best-selling "Hard Headed Woman", and "One Night" in 1958, and "(Now and Then There's) A Fool Such as I" and the number one "A Big Hunk o' Love" in 1959. RCA also generated four albums compiling old material during this period, most successfully "Elvis' Golden Records" (1958), which hit number three on the LP chart.
Focus on films (1960â67).
"Elvis Is Back".
Presley returned to the United States on March 2, 1960, and was honorably discharged with the rank of sergeant on March 5. The train that carried him from New Jersey to Tennessee was mobbed all the way, and Presley was called upon to appear at scheduled stops to please his fans. On the night of March 20, he entered RCA's Nashville studio to cut tracks for a new album along with a single, "Stuck on You", which was rushed into release and swiftly became a number one hit. Another Nashville session two weeks later yielded a pair of his best-selling singles, the ballads "It's Now or Never" and "Are You Lonesome Tonight?", along with the rest of "Elvis Is Back!" The album features several songs described by Greil Marcus as full of Chicago blues "menace, driven by Presley's own super-miked acoustic guitar, brilliant playing by Scotty Moore, and demonic sax work from Boots Randolph. Elvis's singing wasn't sexy, it was pornographic." As a whole, the record "conjured up the vision of a performer who could be all things", in the words of music historian John Robertson: "a flirtatious teenage idol with a heart of gold; a tempestuous, dangerous lover; a gutbucket blues singer; a sophisticated nightclub entertainer; raucous rocker".
Presley returned to television on May 12 as a guest on ""âironic for both stars, given Sinatra's not-so-distant excoriation of rock and roll. Also known as "Welcome Home Elvis", the show had been taped in late March, the only time all year Presley performed in front of an audience. Parker secured an unheard-of $125,000 fee for eight minutes of singing. The broadcast drew an enormous viewership.
"G.I. Blues", the soundtrack to Presley's first film since his return, was a number one album in October. His first LP of sacred material, "His Hand in Mine", followed two months later. It reached number 13 on the U.S. pop chart and number 3 in Great Britain, remarkable figures for a gospel album. In February 1961, Presley performed two shows for a benefit event in Memphis, on behalf of 24 local charities. During a luncheon preceding the event, RCA presented him with a plaque certifying worldwide sales of over 75 million records. A 12-hour Nashville session in mid-March yielded nearly all of Presley's next studio album, "Something for Everybody". As described by John Robertson, it exemplifies the Nashville sound, the restrained, cosmopolitan style that would define country music in the 1960s. Presaging much of what was to come from Presley himself over the next half-decade, the album is largely "a pleasant, unthreatening pastiche of the music that had once been Elvis's birthright." It would be his sixth number one LP. Another benefit concert, raising money for a Pearl Harbor memorial, was staged on March 25, in Hawaii. It was to be Presley's last public performance for seven years.
Lost in Hollywood.
Parker had by now pushed Presley into a heavy film making schedule, focused on formulaic, modestly budgeted musical comedies. Presley at first insisted on pursuing more serious roles, but when two films in a more dramatic veinâ"Flaming Star" (1960) and "Wild in the Country" (1961)âwere less commercially successful, he reverted to the formula. Among the 27 films he made during the 1960s, there were few further exceptions. His films were almost universally panned; critic Andrew Caine dismissed them as a "pantheon of bad taste". Nonetheless, they were virtually all profitable. Hal Wallis, who produced nine of them, declared, "A Presley picture is the only sure thing in Hollywood."
Of Presley's films in the 1960s, 15 were accompanied by soundtrack albums and another 5 by soundtrack EPs. The films' rapid production and release schedulesâhe frequently starred in three a yearâaffected his music. According to Jerry Leiber, the soundtrack formula was already evident before Presley left for the Army: "three ballads, one medium-tempo umbe, one up-tempo, and one break blues boogie". As the decade wore on, the quality of the soundtrack songs grew "progressively worse". Julie Parrish, who appeared in "Paradise, Hawaiian Style" (1966), says that he hated many of the songs chosen for his films. The Jordanaires' Gordon Stoker describes how Presley would retreat from the studio microphone: "The material was so bad that he felt like he couldn't sing it." Most of the film albums featured a song or two from respected writers such as the team of Doc Pomus and Mort Shuman. But by and large, according to biographer Jerry Hopkins, the numbers seemed to be "written on order by men who never really understood Elvis or rock and roll." Regardless of the songs' quality, it has been argued that Presley generally sang them well, with commitment. Critic Dave Marsh heard the opposite: "Presley isn't trying, probably the wisest course in the face of material like 'No Room to Rumba in a Sports Car' and 'Rock-a-Hula Baby.'"
In the first half of the decade, three of Presley's soundtrack albums hit number one on the pop charts, and a few of his most popular songs came from his films, such as "Can't Help Falling in Love" (1961) and "Return to Sender" (1962). ("Viva Las Vegas", the title track to the 1964 film, was a minor hit as a B-side, and became truly popular only later.) But, as with artistic merit, the commercial returns steadily diminished. During a five-year spanâ1964 through 1968âPresley had only one top-ten hit: "Crying in the Chapel" (1965), a gospel number recorded back in 1960. As for non-film albums, between the June 1962 release of "Pot Luck" and the November 1968 release of the soundtrack to the television special that signaled his comeback, only one LP of new material by Presley was issued: the gospel album "How Great Thou Art" (1967). It won him his first Grammy Award, for Best Sacred Performance. As Marsh described, Presley was "arguably the greatest white gospel singer of his time n really the last rock & roll artist to make gospel as vital a component of his musical personality as his secular songs."
Shortly before Christmas 1966, more than seven years since they first met, Presley proposed to Priscilla Beaulieu. They were married on May 1, 1967, in a brief ceremony in their suite at the Aladdin Hotel in Las Vegas. The flow of formulaic films and assembly-line soundtracks rolled on. It was not until October 1967, when the "Clambake" soundtrack LP registered record low sales for a new Presley album, that RCA executives recognized a problem. "By then, of course, the damage had been done", as historians Connie Kirchberg and Marc Hendrickx put it. "Elvis was viewed as a joke by serious music lovers and a has-been to all but his most loyal fans."
Comeback (1968â73).
"Elvis": the '68 Comeback Special.
Presley's only child, Lisa Marie, was born on February 1, 1968, during a period when he had grown deeply unhappy with his career. Of the eight Presley singles released between January 1967 and May 1968, only two charted in the top 40, and none higher than number 28. His forthcoming soundtrack album, "Speedway", would die at number 82 on the "Billboard" chart. Parker had already shifted his plans to television, where Presley had not appeared since the Sinatra Timex show in 1960. He maneuvered a deal with NBC that committed the network to both finance a theatrical feature and broadcast a Christmas special.
Recorded in late June in Burbank, California, the special, called simply "Elvis", aired on December 3, 1968. Later known as the '68 Comeback Special, the show featured lavishly staged studio productions as well as songs performed with a band in front of a small audienceâPresley's first live performances since 1961. The live segments saw Presley clad in tight black leather, singing and playing guitar in an uninhibited style reminiscent of his early rock-and-roll days. Bill Belew, who designed this outfit, gave it a Napoleonic standing collar (Presley customarily wore high collars because he believed his neck looked too long), a design feature that he would later make a major trademark of the outfits Presley wore on stage in his later years. Director and coproducer Steve Binder had worked hard to reassure the nervous singer and to produce a show that was far from the hour of Christmas songs Parker had originally planned. The show, NBC's highest rated that season, captured 42 percent of the total viewing audience. Jon Landau of "Eye" magazine remarked, "There is something magical about watching a man who has lost himself find his way back home. He sang with the kind of power people no longer expect of rock 'n' roll singers. He moved his body with a lack of pretension and effort that must have made Jim Morrison green with envy." Dave Marsh calls the performance one of "emotional grandeur and historical resonance."
By January 1969, the single "If I Can Dream", written for the special, reached number 12. The soundtrack album broke into the top ten. According to friend Jerry Schilling, the special reminded Presley of what "he had not been able to do for years, being able to choose the people; being able to choose what songs and not being told what had to be on the soundtrack.Â ... He was out of prison, man." Binder said of Presley's reaction, "I played Elvis the 60-minute show, and he told me in the screening room, 'Steve, it's the greatest thing I've ever done in my life. I give you my word I will never sing a song I don't believe in.'"
"From Elvis In Memphis" and the International.
Buoyed by the experience of the Comeback Special, Presley engaged in a prolific series of recording sessions at American Sound Studio, which led to the acclaimed "From Elvis in Memphis". Released in June 1969, it was his first secular, non-soundtrack album from a dedicated period in the studio in eight years. As described by Dave Marsh, it is "a masterpiece in which Presley immediately catches up with pop music trends that had seemed to pass him by during the movie years. He sings country songs, soul songs and rockers with real conviction, a stunning achievement."
Presley was keen to resume regular live performing. Following the success of the Comeback Special, offers came in from around the world. The London Palladium offered Parker $28,000 for a one-week engagement. He responded, "That's fine for me, now how much can you get for Elvis?" In May, the brand new International Hotel in Las Vegas, boasting the largest showroom in the city, announced that it had booked Presley, scheduling him to perform 57 shows over four weeks beginning July 31. Moore, Fontana, and the Jordanaires declined to participate, afraid of losing the lucrative session work they had in Nashville. Presley assembled new, top-notch accompaniment, led by guitarist James Burton and including two gospel groups, The Imperials and The Sweet Inspirations. Nonetheless, he was nervous: his only previous Las Vegas engagement, in 1956, had been dismal, and he had neither forgotten nor forgiven that failure. To revise his approach to performances, Presley visited Las Vegas hotel showrooms and lounges, at one of which, that of the Flamingo, he encountered Tom Jones, whose aggressive style was similar to his own 1950s approach; the two became friends. Already studying karate at the time, Presley recruited Bill Belew to design variants of karatekas's "gis" for him; these, in jumpsuit form, would be his "stage uniforms" in his later years. Parker, who intended to make Presley's return the show business event of the year, oversaw a major promotional push. For his part, hotel owner Kirk Kerkorian arranged to send his own plane to New York to fly in rock journalists for the debut performance.
Presley took to the stage without introduction. The audience of 2200, including many celebrities, gave him a standing ovation before he sang a note and another after his performance. A third followed his encore, "Can't Help Falling in Love" (a song that would be his closing number for much of the 1970s). At a press conference after the show, when a journalist referred to him as "The King", Presley gestured toward Fats Domino, who was taking in the scene. "No," Presley said, "that's the real king of rock and roll." The next day, Parker's negotiations with the hotel resulted in a five-year contract for Presley to play each February and August, at an annual salary of $1 million. "Newsweek" commented, "There are several unbelievable things about Elvis, but the most incredible is his staying power in a world where meteoric careers fade like shooting stars." "Rolling Stone" called Presley "supernatural, his own resurrection." In November, Presley's final non-concert film, "Change of Habit", opened. The double album "From Memphis To Vegas/From Vegas To Memphis" came out the same month; the first LP consisted of live performances from the International, the second of more cuts from the American Sound sessions. "Suspicious Minds" reached the top of the chartsâPresley's first U.S. pop number one in over seven years, and his last.
Cassandra Peterson, later television's Elvira, met Presley during this period in Las Vegas, where she was working as a showgirl. She recalls of their encounter, "He was so anti-drug when I met him. I mentioned to him that I smoked marijuana, and he was just appalled. He said, 'Don't ever do that again.'" Presley was not only deeply opposed to recreational drugs, he also rarely drank. Several of his family members had been alcoholics, a fate he intended to avoid.
Back on tour and meeting Nixon.
Presley returned to the International early in 1970 for the first of the year's two month-long engagements, performing two shows a night. Recordings from these shows were issued on the album "On Stage". In late February, Presley performed six attendance-recordâbreaking shows at the Houston Astrodome. In April, the single "The Wonder of You" was issuedâa number one hit in Great Britain, it topped the U.S. adult contemporary chart, as well. MGM filmed rehearsal and concert footage at the International during August for the documentary "". Presley was by now performing in a jumpsuit, which would become a trademark of his live act. During this engagement, he was threatened with murder unless $50,000 was paid. Presley had been the target of many threats since the 1950s, often without his knowledge. The FBI took the threat seriously and security was stepped up for the next two shows. Presley went onstage with a Derringer in his right boot and a .45 pistol in his waistband, but the concerts went off without incident.
The album "That's the Way It Is", produced to accompany the documentary and featuring both studio and live recordings, marked a stylistic shift. As music historian John Robertson notes, "The authority of Presley's singing helped disguise the fact that the album stepped decisively away from the American-roots inspiration of the Memphis sessions towards a more middle-of-the-road sound. With country put on the back burner, and soul and R&B left in Memphis, what was left was very classy, very clean white popâperfect for the Las Vegas crowd, but a definite retrograde step for Elvis." After the end of his International engagement on September 7, Presley embarked on a week-long concert tour, largely of the South, his first since 1958. Another week-long tour, of the West Coast, followed in November.
On December 21, 1970, Presley engineered a meeting with President Richard Nixon at the White House, where he expressed his patriotism and his contempt for the hippies, the growing drug culture, and the counterculture in general. He asked Nixon for a Bureau of Narcotics and Dangerous Drugs badge, to add to similar items he had begun collecting and to signify official sanction of his patriotic efforts. Nixon, who apparently found the encounter awkward, expressed a belief that Presley could send a positive message to young people and that it was therefore important he "retain his credibility". Presley told Nixon that the Beatles, whose songs he regularly performed in concert during the era, exemplified what he saw as a trend of anti-Americanism and drug abuse in popular culture. (Presley and his friends had had a four-hour get-together with the Beatles five years earlier.) On hearing reports of the meeting, Paul McCartney later said he "felt a bit betrayed" and commented: "The great joke was that we were taking llega drugs, and look what happened to him", a reference to Presley's death, hastened by prescription drug abuse.
The U.S. Junior Chamber of Commerce named Presley one of its annual Ten Most Outstanding Young Men of the Nation on January 16, 1971. Not long after, the City of Memphis named the stretch of Highway 51 South on which Graceland is located "Elvis Presley Boulevard". The same year, Presley became the first rock and roll singer to be awarded the Lifetime Achievement Award (then known as the Bing Crosby Award) by the National Academy of Recording Arts and Sciences, the Grammy Award organization. Three new, non-film Presley studio albums were released in 1971, as many as had come out over the previous eight years. Best received by critics was "Elvis Country", a concept record that focused on genre standards. The biggest seller was "Elvis Sings the Wonderful World of Christmas", "the truest statement of all", according to Greil Marcus. "In the midst of ten painfully genteel Christmas songs, every one sung with appalling sincerity and humility, one could find Elvis tom-catting his way through six blazing minutes of 'Merry Christmas, Baby,' a raunchy old Charles Brown blues.Â ... If resley' sin was his lifelessness, it was his sinfulness that brought him to life". According to Guralnick, "the one real highlight" of one of the 1971 sessions were the recording of "I Will Be True," "It's Still Here," and "I'll Take You Home Again, Kathleen," a trio of songs that Presley recorded in a rare solo set, sitting at the piano after everyone else had gone home: "Yearning, wistfulness, loneliness, need--all were communicated with a naked lack of adornment that Elvis was seeming to find increasingly difficult to display in the formal process of recording."
Marriage breakdown and "Aloha from Hawaii".
MGM again filmed Presley in April 1972, this time for "Elvis on Tour", which went on to win the Golden Globe Award for Best Documentary Film that year. His gospel album "He Touched Me", released that month, would earn him his second Grammy Award, for Best Inspirational Performance. A 14-date tour commenced with an unprecedented four consecutive sold-out shows at New York's Madison Square Garden. The evening concert on July 10 was recorded and issued in LP form a week later. "" became one of Presley's biggest-selling albums. After the tour, the single "Burning Love" was releasedâPresley's last top ten hit on the U.S. pop chart. "The most exciting single Elvis has made since 'All Shook Up'", wrote rock critic Robert Christgau. "Who else could make 'It's coming closer, the flames are now licking my body' sound like an assignation with James Brown's backup band?"
Presley and his wife, meanwhile, had become increasingly distant, barely cohabiting. In 1971, an affair he had with Joyce Bova resultedâunbeknownst to himâin her pregnancy and an abortion. He often raised the possibility of her moving into Graceland, saying that he was likely to leave Priscilla. The Presleys separated on February 23, 1972, after Priscilla disclosed her relationship with Mike Stone, a karate instructor Presley had recommended to her. Priscilla relates that when she told him, Presley "grabbedÂ ... and forcefully made love to" her, declaring, "This is how a real man makes love to his woman." Five months later, Presley's new girlfriend, Linda Thompson, a songwriter and one-time Memphis beauty queen, moved in with him. Presley and his wife filed for divorce on August 18. According to Joe Moscheo of the Imperials, the failure of Presley's marriage "was a blow from which he never recovered."
In January 1973, Presley performed two benefit concerts for the Kui Lee Cancer Fund in connection with a groundbreaking TV special, "Aloha from Hawaii". The first show served as a practice run and backup should technical problems affect the live broadcast two days later. Aired as scheduled on January 14, "Aloha from Hawaii" was the first global concert satellite broadcast, reaching millions of viewers live and on tape delay. Presley's costume became the most recognized example of the elaborate concert garb with which his latter-day persona became closely associated. As described by Bobbie Ann Mason, "At the end of the show, when he spreads out his American Eagle cape, with the full stretched wings of the eagle studded on the back, he becomes a god figure." The accompanying double album, released in February, went to number one and eventually sold over 5 million copies in the United States. It proved to be Presley's last U.S. number one pop album during his lifetime.
At a midnight show the same month, four men rushed onto the stage in an apparent attack. Security men leapt to Presley's defense, and the singer's karate instinct took over as he ejected one invader from the stage himself. Following the show, he became obsessed with the idea that the men had been sent by Mike Stone to kill him. Though they were shown to have been only overexuberant fans, he raged, "There's too much pain in meÂ ... Stone us die." His outbursts continued with such intensity that a physician was unable to calm him, despite administering large doses of medication. After another two full days of raging, Red West, his friend and bodyguard, felt compelled to get a price for a contract killing and was relieved when Presley decided, "Aw hell, let's just leave it for now. Maybe it's a bit heavy."
Health deterioration and death (1973â77).
Medical crises and last studio sessions.
Presley's divorce took effect on October 9, 1973. He was now becoming increasingly unwell. Twice during the year he overdosed on barbiturates, spending three days in a coma in his hotel suite after the first incident. Toward the end of 1973, he was hospitalized, semicomatose from the effects of Demerol addiction. According to his main physician, Dr. George C. Nichopoulos, Presley "felt that by getting rug from a doctor, he wasn't the common everyday junkie getting something off the street." Since his comeback, he had staged more live shows with each passing year, and 1973 saw 168 concerts, his busiest schedule ever. Despite his failing health, in 1974 he undertook another intensive touring schedule.
Presley's condition declined precipitously in September. Keyboardist Tony Brown remembers the singer's arrival at a University of Maryland concert: "He fell out of the limousine, to his knees. People jumped to help, and he pushed them away like, 'Don't help me.' He walked on stage and held onto the mike for the first thirty minutes like it was a post. Everybody's looking at each other like, Is the tour gonna happen?" Guitarist John Wilkinson recalled, "He was all gut. He was slurring. He was so fucked up.Â ... It was obvious he was drugged. It was obvious there was something terribly wrong with his body. It was so bad the words to the songs were barely intelligible.Â ... I remember crying. He could barely get through the introductions". Wilkinson recounted that a few nights later in Detroit, Michigan, "I watched him in his dressing room, just draped over a chair, unable to move. So often I thought, 'Boss, why don't you just cancel this tour and take a year offÂ ...?' I mentioned something once in a guarded moment. He patted me on the back and said, 'It'll be all right. Don't you worry about it.'" Presley continued to play to sellout crowds. As cultural critic Marjorie Garber describes, he was now widely seen as a garish pop crooner: "in effect he had become Liberace. Even his fans were now middle-aged matrons and blue-haired grandmothers."
On July 13, 1976, Vernon Presleyâwho had become deeply involved in his son's financial affairsâfired "Memphis Mafia" bodyguards Red West (Presley's friend since the 1950s), Sonny West, and David Hebler, citing the need to "cut back on expenses". Presley was in Palm Springs at the time, and some suggest the singer was too cowardly to face the three himself. Another associate of Presley's, John O'Grady, argued that the bodyguards were dropped because their rough treatment of fans had prompted too many lawsuits. However, Presley's stepbrother David Stanley has claimed that the bodyguards were fired because they were becoming more outspoken about Presley's drug dependency.
RCA, which had enjoyed a steady stream of product from Presley for over a decade, grew anxious as his interest in spending time in the studio waned. After a December 1973 session that produced 18 songs, enough for almost two albums, he did not enter the studio in 1974. Parker sold RCA on another concert record, "". Recorded on March 20, it included a version of "How Great Thou Art" that would win Presley his third and final competitive Grammy Award. (All three of his competitive Grammy winsâout of 14 total nominationsâwere for gospel recordings.) Presley returned to the studio in Hollywood in March 1975, but Parker's attempts to arrange another session toward the end of the year were unsuccessful. In 1976, RCA sent a mobile studio to Graceland that made possible two full-scale recording sessions at Presley's home. Even in that comfortable context, the recording process was now a struggle for him.
For all the concerns of his label and manager, in studio sessions between July 1973 and October 1976, Presley recorded virtually the entire contents of six albums. Though he was no longer a major presence on the pop charts, five of those albums entered the top five of the country chart, and three went to number one: "Promised Land" (1975), "From Elvis Presley Boulevard, Memphis, Tennessee" (1976), and "Moody Blue" (1977). The story was similar with his singlesâthere were no major pop hits, but Presley was a significant force in not just the country market, but on adult contemporary radio as well. Eight studio singles from this period released during his lifetime were top ten hits on one or both charts, four in 1974 alone. "My Boy" was a number one adult contemporary hit in 1975, and "Moody Blue" topped the country chart and reached the second spot on the adult contemporary chart in 1976. Perhaps his most critically acclaimed recording of the era came that year, with what Greil Marcus described as his "apocalyptic attack" on the soul classic "Hurt". "If he felt the way he sounded", Dave Marsh wrote of Presley's performance, "the wonder isn't that he had only a year left to live but that he managed to survive that long."
Final year and death.
Presley and Linda Thompson split in November 1976, and he took up with a new girlfriend, Ginger Alden. He proposed to Alden and gave her an engagement ring two months later, though several of his friends later claimed that he had no serious intention of marrying again. Journalist Tony Scherman writes that by early 1977, "Presley had become a grotesque caricature of his sleek, energetic former self. Hugely overweight, his mind dulled by the pharmacopoeia he daily ingested, he was barely able to pull himself through his abbreviated concerts." In Alexandria, Louisiana, the singer was on stage for less than an hour and "was impossible to understand". Presley failed to appear in Baton Rouge; he was unable to get out of his hotel bed, and the rest of the tour was cancelled. Despite the accelerating deterioration of his health, he stuck to most touring commitments. In Rapid City, South Dakota, "he was so nervous on stage that he could hardly talk", according to Presley historian Samuel Roy, and unable to "perform any significant movement." Guralnick relates that fans "were becoming increasingly voluble about their disappointment, but it all seemed to go right past Elvis, whose world was now confined almost entirely to his room and his spiritualism books." A cousin, Billy Smith, recalled how Presley would sit in his room and chat for hours, sometimes recounting favorite Monty Python sketches and his own past escapades, but more often gripped by paranoid obsessions that reminded Smith of Howard Hughes. "Way Down", Presley's last single issued during his lifetime, came out on June 6. His final concert was held in Indianapolis, Indiana at Market Square Arena, on June 26.
The book "", cowritten by the three bodyguards fired the previous year, was published on August 1. It was the first exposÃ© to detail Presley's years of drug misuse. He was devastated by the book and tried unsuccessfully to halt its release by offering money to the publishers. By this point, he suffered from multiple ailments: glaucoma, high blood pressure, liver damage, and an enlarged colon, each aggravatedâand possibly causedâby drug abuse. Genetic analysis of a hair sample in 2014 found evidence of genetic variants that could have caused his glaucoma, migraines and hypertrophic cardiomyopathy.
Presley was scheduled to fly out of Memphis on the evening of August 16, 1977, to begin another tour. That afternoon, Ginger Alden discovered him unresponsive on his bathroom floor. Attempts to revive him failed, and death was officially pronounced at 3:30Â pm at Baptist Memorial Hospital.
President Jimmy Carter issued a statement that credited Presley with having "permanently changed the face of American popular culture". Thousands of people gathered outside Graceland to view the open casket. One of Presley's cousins, Billy Mann, accepted $18,000 to secretly photograph the corpse; the picture appeared on the cover of the "National Enquirer"s biggest-selling issue ever. Alden struck a $105,000 deal with the "Enquirer" for her story, but settled for less when she broke her exclusivity agreement. Presley left her nothing in his will.
Presley's funeral was held at Graceland, on Thursday, August 18. Outside the gates, a car plowed into a group of fans, killing two women and critically injuring a third. Approximately 80,000 people lined the processional route to Forest Hill Cemetery, where Presley was buried next to his mother. Within a few days, "Way Down" topped the country and UK pop charts.
Following an attempt to steal the singer's body in late August, the remains of both Presley and his mother were reburied in Graceland's Meditation Garden on OctoberÂ 2.
Since his death, there have been numerous alleged sightings of Presley. A long-standing theory among some fans is that he faked his death. Fans have noted alleged discrepancies in the death certificate, reports of a wax dummy in his original coffin and numerous accounts of Presley planning a diversion so he could retire in peace.
Questions over cause of death.
"Drug use was heavily implicated" in Presley's death, writes Guralnick. "No one ruled out the possibility of anaphylactic shock brought on by the codeine pillsÂ ... to which he was known to have had a mild allergy." A pair of lab reports filed two months later each strongly suggested that polypharmacy was the primary cause of death; one reported "fourteen drugs in Elvis' system, ten in significant quantity." Forensic historian and pathologist Michael Baden views the situation as complicated: "Elvis had had an enlarged heart for a long time. That, together with his drug habit, caused his death. But he was difficult to diagnose; it was a judgment call."
The competence and ethics of two of the centrally involved medical professionals were seriously questioned. Before the autopsy was complete and toxicology results known, medical examiner Dr. Jerry Francisco declared the cause of death as cardiac arrhythmia, a condition that can be determined only in someone who is still alive. Allegations of a cover-up were widespread. While Presley's main physician, Dr. Nichopoulos, was exonerated of criminal liability for the singer's death, the facts were startling: "In the first eight months of 1977 alone, he had rescribe more than 10,000 doses of sedatives, amphetamines and narcotics: all in Elvis's name." His license was suspended for three months. It was permanently revoked in the 1990s after the Tennessee Medical Board brought new charges of over-prescription.
Amidst mounting pressure in 1994, the Presley autopsy was reopened. Coroner Dr. Joseph Davis declared, "There is nothing in any of the data that supports a death from drugs. In fact, everything points to a sudden, violent heart attack." Whether or not combined drug intoxication was in fact the cause, there is little doubt that polypharmacy contributed significantly to Presley's premature death.
Since 1977.
Between 1977 and 1981, six posthumously released singles by Presley were top ten country hits. Graceland was opened to the public in 1982. Attracting over half a million visitors annually, it is the second most-visited home in the United States, after the White House. It was declared a National Historic Landmark in 2006.
Presley has been inducted into five music halls of fame: the Rock and Roll Hall of Fame (1986), the Country Music Hall of Fame (1998), the Gospel Music Hall of Fame (2001), the Rockabilly Hall of Fame (2007), and the Memphis Music Hall of Fame (2012). In 1984, he received the W. C. Handy Award from the Blues Foundation and the Academy of Country Music's first Golden Hat Award. In 1987, he received the American Music Awards' Award of Merit.
A Junkie XL remix of Presley's "A Little Less Conversation" (credited as "Elvis Vs JXL") was used in a Nike advertising campaign during the 2002 FIFA World Cup. It topped the charts in over 20 countries, and was included in a compilation of Presley's number one hits, "ELV1S", that was also an international success. In 2003, a remix of "Rubberneckin'", a 1969 recording of Presley's, topped the U.S. sales chart, as did a 50th-anniversary re-release of "That's All Right" the following year. The latter was an outright hit in Great Britain, reaching number three on the pop chart.
In 2005, another three reissued singles, "Jailhouse Rock", "One Night"/"I Got Stung", and "It's Now or Never", went to number one in the United Kingdom. A total of 17 Presley singles were reissued during the year; all made the British top five. For the fifth straight year, "Forbes" named Presley the top-earning deceased celebrity, with a gross income of $45 million. He placed second in 2006, returned to the top spot the next two years, and ranked fourth in 2009. The following year, he was ranked second, with his highest annual income everâ$60 millionâspurred by the celebration of his 75th birthday and the launch of Cirque du Soleil's "Viva Elvis" show in Las Vegas. In November 2010, "Viva Elvis: The Album" was released, setting his voice to newly recorded instrumental tracks. As of mid-2011, there were an estimated 15,000 licensed Presley products. He was again the second-highest-earning deceased celebrity.
Presley holds the records for most songs charting in "Billboard"s top 40 and top 100: chart statistician Joel Whitburn calculates the respective totals as 104 and 151; Presley historian Adam Victor gives 114 and 138. Presley's rankings for top-ten and number-one hits vary depending on how the double-sided "Hound Dog/Don't Be Cruel" and "Don't/I Beg of You" singles, which precede the inception of "Billboard"s unified Hot 100 chart, are analyzed. According to Whitburn's analysis, Presley and Madonna share the record for most top ten hits with 38; per "Billboard"s current assessment, he ranks second with 36. Whitburn and "Billboard" concur that the Beatles hold the record for most number-one hits with 20, and that Mariah Carey is second with 18. Whitburn has Presley also with 18, and thus tied for second; "Billboard" has him third with 17. Presley retains the record for cumulative weeks at number one: alone at 80, according to Whitburn and the Rock and Roll Hall of Fame; tied with Carey at 79, according to "Billboard". He holds the records for most British number-one hits with 21, and top-ten hits with 76.
In 2008, an 1800-year-old Roman bust described as bearing a "striking" resemblance to Elvis was displayed ahead of an intended auction. A spokesman for the auctioneers said that fans could "be forgiven for thinking that their idol may well have lived a previous life in Rome."
On the anniversary date of his death, every year since 1997, thousands of people gather at his home in Memphis to celebrate his memory, during a candlelight ritual.
Musical style.
Influences.
Presley's earliest musical influence came from gospel. His mother recalled that from the age of two, at the Assembly of God church in Tupelo attended by the family, "he would slide down off my lap, run into the aisle and scramble up to the platform. There he would stand looking at the choir and trying to sing with them." In Memphis, Presley frequently attended all-night gospel singings at the Ellis Auditorium, where groups such as the Statesmen Quartet led the music in a style that, Guralnick suggests, sowed the seeds of Presley's future stage act:
As a teenager, Presley's musical interests were wide-ranging, and he was deeply informed about African American musical idioms as well as white ones (see "Teenage life in Memphis"). Though he never had any formal training, he was blessed with a remarkable memory, and his musical knowledge was already considerable by the time he made his first professional recordings in 1954 at the age of 19. When Jerry Leiber and Mike Stoller met him two years later, they were astonished at his encyclopedic understanding of the blues. At a press conference the following year, he proudly declared, "I know practically every religious song that's ever been written."
Genres.
Presley was a central figure in the development of rockabilly, according to music historians. Katherine Charlton even calls him "rockabilly's originator", though Carl Perkins has explicitly stated that "a Phillips, Elvis, and I didn't create rockabilly." and, according to Michael Campbell, "Bill Haley recorded the first big rockabilly hit." "It had been there for quite a while", says Scotty Moore. "Carl Perkins was doing basically the same sort of thing up around Jackson, and I know for a fact Jerry Lee Lewis had been playing that kind of music ever since he was ten years old." However, "Rockabilly crystallized into a recognizable style in 1954 with Elvis Presley's first release, on the Sun label", writes Craig Morrison. Paul Friedlander describes the defining elements of rockabilly, which he similarly characterizes as "essentiallyÂ ... an Elvis Presley construction": "the raw, emotive, and slurred vocal style and emphasis on rhythmic feeling the blues with the string band and strummed rhythm guitar country". In "That's All Right", the Presley trio's first record, Scotty Moore's guitar solo, "a combination of Merle Travisâstyle country finger-picking, double-stop slides from acoustic boogie, and blues-based bent-note, single-string work, is a microcosm of this fusion."
At RCA, Presley's rock and roll sound grew distinct from rockabilly with group chorus vocals, more heavily amplified electric guitars and a tougher, more intense manner. While he was known for taking songs from various sources and giving them a rockabilly/rock and roll treatment, he also recorded songs in other genres from early in his career, from the pop standard "Blue Moon" at Sun to the country ballad "How's the World Treating You?" on his second LP to the blues of "Santa Claus Is Back In Town". In 1957, his first gospel record was released, the four-song EP "Peace in the Valley". Certified as a million seller, it became the top-selling gospel EP in recording history. Presley would record gospel periodically for the rest of his life.
After his return from military service in 1960, Presley continued to perform rock and roll, but the characteristic style was substantially toned down. The reason why the music from this period lacks the drama from his Fifties recordings, critic Dave Marsh writes, is "because what we're hearing is not genius discovering itself but the sound of genius at work." His first post-Army single, the number one hit "Stuck on You", is typical of this shift. RCA publicity materials referred to its "mild rock beat"; discographer Ernst Jorgensen calls it "upbeat pop". The modern blues/R&B sound captured so successfully on "Elvis Is Back!" was essentially abandoned for six years until such 1966â67 recordings as "Down in the Alley" and "Hi-Heel Sneakers", though Marsh holds that while he may have recorded few blues songs in the early to middle Sixties, "blues informs almost everything here." The singer's output during most of the 1960s emphasized pop music, often in the form of ballads such as "Are You Lonesome Tonight?", a number one in 1960. While that was a dramatic number, most of what Presley recorded for his film soundtracks was in a much lighter vein. Notable numbers in other genres are the No. 1 hits "It's Now or Never" of 1960, based on the Italian aria "O Sole Mio" and concluding with a "full-voiced operatic cadence," and the 1962 hit "She's Not You" which "integrates the Jordanaires so completely, it's practically doo-wop."
While Presley performed several of his classic ballads for the '68 Comeback Special, the sound of the show was dominated by aggressive rock and roll. He would record few new straight-ahead rock and roll songs thereafter; as he explained, they were "hard to find". A significant exception was "Burning Love", his last major hit on the pop charts. Like his work of the 1950s, Presley's subsequent recordings reworked pop and country songs, but in markedly different permutations. His stylistic range now began to embrace a more contemporary rock sound as well as soul and funk. Much of "Elvis In Memphis", as well as "Suspicious Minds", cut at the same sessions, reflected his new rock and soul fusion. In the mid-1970s, many of his singles found a home on country radio, the field where he first became a star.
Vocal style and range.
The general development of Presley's voice is described by critic Dave Marsh as "A voice, high and thrilled in the early days, lower and perplexed in the final months." Marsh credits Presley with the introduction of the "vocal stutter" on 1955's "Baby Let's Play House." When on "Don't Be Cruel" Presley "slides into a 'mmmmm' that marks the transition between the first two verses," he shows "how masterful his relaxed style really is." Marsh describes the singing on "Can't Help Falling in Love" to be of "gentle insistence and delicacy of phrasing," with the line "'Shall I stay'" pronounced as if the words are fragile as crystal." On the operatic "It's Now or Never" Presley "was reaching for something more than he had ever attempted before," and, according to discographer Jorgensen, later the same year the melody to "Surrender", a number also based on an Italian original, "Torna A Sorrento", "required an even greater demonstration of vocal powers." 
Jorgensen calls the 1966 recording of "How Great Thou Art" "an extraordinary fulfillment of his vocal ambitions," as Presley had "crafted for himself an ad-hoc arrangement in which he took every part of the four-part vocal, from h bass intro to the soaring heights of the song's operatic climax," in the process becoming "a kind of one-man quartet." Guralnick finds "Stand By Me" from the same sessions "a beautifully articulated, almost nakedly yearning performance," but, by contrast, feels that Presley reaches beyond his powers on "Where No One Stands Alone" on which "he was reduced to a kind of inelegant bellowing to push out a sound" that Jake Hess would have no problem with. Hess himself thought that while others may have a voice as great or greater than Presley's, "he had that certain something that everyone searches for all during their lifetime." Guralnick attempts to pinpoint that something: "The warmth of his voice, his controlled use of both vibrato technique and natural falsetto range, the subtlety and deeply felt conviction of his singing were all qualities recognizably belonging to his talent but just as recognizably not to be achieved without sustained dedication and effort."
Presley's singing to his own "necessarily limited, both rhythmically and melodically," piano accompaniment, such as can be heard on the 1967 recording of "You'll Never Walk Alone", for Guralnick are always special occasions, because "it was always a measure of his engagement when he sat down at the keyboard to play." Describing his piano technique as "staccato style," Jorgensen finds that on "Without Love" from the 1969 sessions, "his gospel-flavored treatment took it to a level of spirituality rarely matched in his career." Presley also played the instrument on the "impassioned version" of the sessions's next song, "I'll Hold You in My Heart," of which Guralnick writes that "there is something magical about the moment that only the most inspired singing can bring about, as Elvis loses himself in the music, words no longer lend themselves to literal translation, and singer and listener both are left emotionally wrung out by the time the song finally limps to an end." 
Marsh praises his 1968 reading of "U.S. Male", "bearing down on the hard guy lyrics, not sending them up or overplaying them but tossing them around with that astonishingly tough yet gentle assurance that he brought to his Sun records." The performance on "In the Ghetto" is, according to Jorgensen, "devoid of any of his characteristic vocal tricks or mannerisms," instead relying on "the astonishing clarity and sensitivity of his voice." Guralnick describes the tenderness in the singing of the same song of "such unassuming, almost translucent eloquence, it is so quietly confident in its simplicity" that one is reminded of the Sun period, "offering equal parts yearning and social compassion." On "Suspicious Minds" from the same sessions Guralnick hears essentially the same "remarkable mixture of tenderness and poise," but supplemented with "an expressive quality somewhere between stoicism (at suspected infidelity) and anguish (over impending loss)."
Music critic Henry Pleasants observes that "Presley has been described variously as a baritone and a tenor. An extraordinary compassÂ ... and a very wide range of vocal color have something to do with this divergence of opinion." He identifies Presley as a high baritone, calculating his range as two octaves and a third, "from the baritone low G to the tenor high B, with an upward extension in falsetto to at least a D-flat. Presley's best octave is in the middle, D-flat to D-flat, granting an extra full step up or down." In Pleasants' view, his voice was "variable and unpredictable" at the bottom, "often brilliant" at the top, with the capacity for "full-voiced high Gs and As that an opera baritone might envy". Scholar Lindsay Waters, who figures Presley's range as 2Â¼ octaves, emphasizes that "his voice had an emotional range from tender whispers to sighs down to shouts, grunts, grumbles and sheer gruffness that could move the listener from calmness and surrender, to fear." Presley was always "able to duplicate the open, hoarse, ecstatic, screaming, shouting, wailing, reckless sound of the black rhythm-and-blues and gospel singers," writes Pleasants, and also demonstrated a remarkable ability to assimilate many other vocal styles.
Racial issues.
When Dewey Phillips first aired "That's All Right" on Memphis radio, many listeners who contacted the station by phone and telegram to ask for it again assumed that its singer was black. From the beginning of his national fame, Presley expressed respect for African American performers and their music, and disregard for the norms of segregation and racial prejudice then prevalent in the South. Interviewed in 1956, he recalled how in his childhood he would listen to blues musician Arthur Crudupâthe originator of "That's All Right"â"bang his box the way I do now, and I said if I ever got to the place where I could feel all old Arthur felt, I'd be a music man like nobody ever saw." "The Memphis World", an African American newspaper, reported that Presley, "the rock 'n' roll phenomenon", "cracked Memphis's segregation laws" by attending the local amusement park on what was designated as its "colored night". Such statements and actions led Presley to be generally hailed in the black community during the early days of his stardom. By contrast, many white adults, according to "Billboard"s Arnold Shaw, "did not like him, and condemned him as depraved. Anti-negro prejudice doubtless figured in adult antagonism. Regardless of whether parents were aware of the Negro sexual origins of the phrase 'rock 'n' roll', Presley impressed them as the visual and aural embodiment of sex."
Despite the largely positive view of Presley held by African Americans, a rumor spread in mid-1957 that he had at some point announced, "The only thing Negroes can do for me is buy my records and shine my shoes." A journalist with the national African American weekly "Jet", Louie Robinson, pursued the story. On the set of "Jailhouse Rock", Presley granted Robinson an interview, though he was no longer dealing with the mainstream press. He denied making such a statement or holding in any way to its racist view: "I never said anything like that, and people who know me know that I wouldn't have said it â¦ A lot of people seem to think I started this business. But rock 'n' roll was here a long time before I came along. Nobody can sing that kind of music like colored people. Let's face it: I can't sing like Fats Domino can. I know that." Also, Red Robinson stated, "Take a look at the things that are only publicized now, of how he'd be driving down the street and see a destitute black woman with a little child. He went and bought her a Cadillac. Now if this guy hated blacks, he wouldnât even have gone near them". Robinson found no evidence that the remark had ever been made, and on the contrary elicited testimony from many individuals indicating that Presley was anything but racist. Blues singer Ivory Joe Hunter, who had heard the rumor before he visited Graceland one evening, reported of Presley, "He showed me every courtesy, and I think he's one of the greatest." Dudley Brooks, an African-American composer and studio musician who worked with Presley during the 1950s and 1960s, also disputed allegations that Presley was a racist. Though the rumored remark was wholly discredited at the time, it was still being used against Presley decades later. The identification of Presley with racismâeither personally or symbolicallyâwas expressed most famously in the lyrics of the 1989 rap hit "Fight the Power", by Public Enemy: "Elvis was a hero to most / But he never meant shit to me / Straight-up racist that sucker was / Simple and plain".
The persistence of such attitudes was fueled by resentment over the fact that Presley, whose musical and visual performance idiom owed much to African American sources, achieved the cultural acknowledgment and commercial success largely denied his black peers. Into the 21st century, the notion that Presley had "stolen" black music still found adherents. Notable among African American entertainers expressly rejecting this view was Jackie Wilson, who argued, "A lot of people have accused Elvis of stealing the black man's music, when in fact, almost every black solo entertainer copied his stage mannerisms from Elvis." And throughout his career, Presley plainly acknowledged his debt. Addressing his '68 Comeback Special audience, he said, "Rock 'n' roll music is basically gospel or rhythm and blues, or it sprang from that. People have been adding to it, adding instruments to it, experimenting with it, but it all boils down to ha." Nine years earlier, he had said, "Rock 'n' roll has been around for many years. It used to be called rhythm and blues."
Influence of Colonel Parker and others.
Parker and the Aberbachs.
Once he became Presley's manager, Colonel Tom Parker insisted on exceptionally tight control over his client's career. Songwriter Robert B. Sherman (of the Sherman Brothers) bore witness to the deal being forged between Hill and Range co-owner Jean Aberbach and The Colonel in 1955. Early on, "The Colonel" and his Hill and Range allies, the brothers Jean and Julian Aberbach, perceived the close relationship that developed between Presley and songwriters Jerry Leiber and Mike Stoller as a serious threat to that control. Parker effectively ended the relationship, deliberately or not, with the new contract he sent Leiber in early 1958. Leiber thought there was a mistakeâthe sheet of paper was blank except for Parker's signature and a line on which to enter his. "There's no mistake, boy, just sign it and return it," Parker directed. "Don't worry, we'll fill it in later." Leiber declined, and Presley's fruitful collaboration with the writing team was over. Other respected songwriters lost interest in or simply avoided writing for Presley because of the requirement that they surrender a third of their usual royalties.
By 1967, Parker's contracts with Presley gave him 50 percent of most of the singer's earnings from recordings, films, and merchandise. Beginning in February 1972, he took a third of the profit from live appearances; a January 1976 agreement entitled him to half of that as well. Priscilla Presley noted that, "Elvis detested the business side of his career. He would sign a contract without even reading it." Presley's friend Marty Lacker regarded Parker as a "hustler and a con artist. He was only interested in 'now money'âget the buck and get gone."
Lacker was instrumental in convincing Presley to record with Memphis producer Chips Moman and his handpicked musicians at American Sound Studio in early 1969. The American Sound sessions represented a significant departure from the control customarily exerted by Hill and Range. Moman still had to deal with the publisher's staff on site, whose song suggestions he regarded as unacceptable. He was on the verge of quitting, until Presley ordered the Hill and Range personnel out of the studio. Although RCA executive Joan Deary was later full of praise for the producer's song choices and the quality of the recordings, Moman, to his fury, received neither credit on the records nor royalties for his work.
Throughout his entire career, Presley performed in only three venues outside the United Statesâall of them in Canada, during brief tours there in 1957. Rumors that he would play overseas for the first time were fueled in 1974 by a million-dollar bid for an Australian tour. Parker was uncharacteristically reluctant, prompting those close to Presley to speculate about the manager's past and the reasons for his apparent unwillingness to apply for a passport. Parker ultimately squelched any notions Presley had of working abroad, claiming that foreign security was poor and the venues unsuitable for a star of his magnitude.
Parker arguably exercised tightest control over Presley's film career. In 1957, Robert Mitchum asked Presley to costar with him in "Thunder Road", on which Mitchum was writer and producer. According to George Klein, one of his oldest friends, Presley was offered starring roles in "West Side Story" and "Midnight Cowboy". In 1974, Barbra Streisand approached Presley to star with her in the remake of "A Star is Born". In each case, any ambitions the singer may have had to play such parts were thwarted by his manager's negotiating demands or flat refusals. In Lacker's description, "The only thing that kept Elvis going after the early years was a new challenge. But Parker kept running everything into the ground." The prevailing attitude may have been summed up best by the response Leiber and Stoller received when they brought a serious film project for Presley to Parker and the Hill and Range owners for their consideration. In Leiber's telling, Jean Aberbach warned them to never again "try to interfere with the business or artistic workings of the process known as Elvis Presley."
Memphis Mafia.
In the early 1960s, the circle of friends with whom Presley constantly surrounded himself until his death came to be known as the "Memphis Mafia". "Surrounded by the parasitic presence", as journalist John Harris puts it, "it was no wonder that as he slid into addiction and torpor, no-one raised the alarm: to them, Elvis was the bank, and it had to remain open." Tony Brown, who played piano for Presley regularly in the last two years of the singer's life, observed his rapidly declining health and the urgent need to address it: "But we all knew it was hopeless because Elvis was surrounded by that little circle of peopleÂ ... all those so-called friends". In the Memphis Mafia's defense, Marty Lacker has said, "resle was his own man.Â ... If we hadn't been around, he would have been dead a lot earlier."
Larry Geller became Presley's hairdresser in 1964. Unlike others in the Memphis Mafia, he was interested in spiritual questions and recalls how, from their first conversation, Presley revealed his secret thoughts and anxieties: "I mean there "has" to be a purposeÂ ... there's got to be a reasonÂ ... why I was chosen to be Elvis Presley.Â ... I swear to God, no one knows how lonely I get. And how empty I really feel." Thereafter, Geller supplied him with books on religion and mysticism, which the singer read voraciously. Presley would be preoccupied by such matters for much of his life, taking trunkloads of books with him on tour.
Sex symbol.
Presley's physical attractiveness and sexual appeal were widely acknowledged. "He was once beautiful, astonishingly beautiful", in the words of critic Mark Feeney. Television director Steve Binder, no fan of Presley's music before he oversaw the '68 Comeback Special, reported, "I'm straight as an arrow and I got to tell you, you stop, whether you're male or female, to look at him. He was that good looking. And if you never knew he was a superstar, it wouldn't make any difference; if he'd walked in the room, you'd know somebody special was in your presence." His performance style, as much as his physical beauty, was responsible for Presley's eroticized image. Writing in 1970, critic George Melly described him as "the master of the sexual simile, treating his guitar as both phallus and girl." In his Presley obituary, Lester Bangs credited him as "the man who brought overt blatant vulgar sexual frenzy to the popular arts in America." Ed Sullivan's declaration that he perceived a soda bottle in Presley's trousers was echoed by rumors involving a similarly positioned toilet roll tube or lead bar.
While Presley was marketed as an icon of heterosexuality, some cultural critics have argued that his image was ambiguous. In 1959, "Sight and Sound"s Peter John Dyer described his onscreen persona as "aggressively bisexual in appeal". Brett Farmer places the "orgasmic gyrations" of the title dance sequence in "Jailhouse Rock" within a lineage of cinematic musical numbers that offer a "spectacular eroticization, if not homoeroticization, of the male image". In the analysis of Yvonne Tasker, "Elvis was an ambivalent figure who articulated a peculiar feminised, objectifying version of white working-class masculinity as aggressive sexual display."
Reinforcing Presley's image as a sex symbol were the reports of his dalliances with various Hollywood stars and starlets, from Natalie Wood in the 1950s to Connie Stevens and Ann-Margret in the 1960s to Candice Bergen and Cybill Shepherd in the 1970s. June Juanico of Memphis, one of Presley's early girlfriends, later blamed Parker for encouraging him to choose his dating partners with publicity in mind. Presley never grew comfortable with the Hollywood scene, and most of these relationships were insubstantial.
Lifestyle.
Presley was known for a life of luxury and excess, as exemplified by his estate at Graceland. He owned a number of expensive cars, including three pink Cadillacs, immortalized in his version of the song "Baby, Let's Play House", in which Presley replaced the line "you may get religion" with "you may have a Pink Cadillac".
A number of stories, both real and exaggerated, detail Presley's appetite for rich or heavy food. He was said to enjoy the Southern cuisine of his upbringing, including chicken-fried steak and biscuits and gravy. Presley is commonly associated with rich sandwiches, including the Fool's Gold Loaf and peanut butter, banana and bacon sandwiches, now commonly called an "Elvis sandwich".
Legacy.
Presley's rise to national attention in 1956 transformed the field of popular music and had a huge effect on the broader scope of popular culture. As the catalyst for the cultural revolution that was rock and roll, he was central not only to defining it as a musical genre but in making it a touchstone of youth culture and rebellious attitude. With its racially mixed originsârepeatedly affirmed by Presleyârock and roll's occupation of a central position in mainstream American culture facilitated a new acceptance and appreciation of black culture. In this regard, Little Richard said of Presley, "He was an integrator. Elvis was a blessing. They wouldn't let black music through. He opened the door for black music." Al Green agreed: "He broke the ice for all of us." President Jimmy Carter remarked on his legacy in 1977: "His music and his personality, fusing the styles of white country and black rhythm and blues, permanently changed the face of American popular culture. His following was immense, and he was a symbol to people the world over of the vitality, rebelliousness, and good humor of his country." Presley also heralded the vastly expanded reach of celebrity in the era of mass communication: at the age of 21, within a year of his first appearance on American network television, he was one of the most famous people in the world.
Presley's name, image, and voice are instantly recognizable around the globe. He has inspired a legion of impersonators. In polls and surveys, he is recognized as one of the most important popular music artists and influential Americans. "Elvis Presley is the greatest cultural force in the twentieth century", said composer and conductor Leonard Bernstein. "He introduced the beat to everything and he changed everythingâmusic, language, clothes. It's a whole new social revolutionâthe sixties came from it." Bob Dylan described the sensation of first hearing Presley as "like busting out of jail".
On the 25th anniversary of Presley's death, "The New York Times" observed, "All the talentless impersonators and appalling black velvet paintings on display can make him seem little more than a perverse and distant memory. But before Elvis was camp, he was its opposite: a genuine cultural force.Â ... Elvis's breakthroughs are underappreciated because in this rock-and-roll age, his hard-rocking music and sultry style have triumphed so completely." Not only Presley's achievements, but his failings as well, are seen by some cultural observers as adding to the power of his legacy, as in this description by Greil Marcus:
Elvis Presley is a supreme figure in American life, one whose presence, no matter how banal or predictable, brooks no real comparisons.Â ... The cultural range of his music has expanded to the point where it includes not only the hits of the day, but also patriotic recitals, pure country gospel, and really dirty blues.Â ... Elvis has emerged as a great "artist," a great "rocker," a great "purveyor of schlock," a great "heart throb," a great "bore," a great "symbol of potency," a great "ham," a great "nice person," and, yes, a great American.
Discography.
A vast number of recordings have been issued under Presley's name. The total number of his original master recordings has been variously calculated as 665 and 711. His career began and he was most successful during an era when singles were the primary commercial medium for pop music. In the case of his albums, the distinction between "official" studio records and other forms is often blurred. For most of the 1960s, his recording career focused on soundtrack albums. In the 1970s, his most heavily promoted and best-selling LP releases tended to be concert albums. This summary discography lists only the albums and singles that reached the top of one or more of the following charts: the main U.S. "Billboard" pop chart; the "Billboard" country chart, the genre chart with which he was most identified (there was no country album chart before 1964); and the official British pop chart.
The year given, in the table below, is the year the record first reached number one, rather than its original year of release. For instance: "Elvis' 40 Greatest", released in 1974, a compilation on the budget Arcade label, was the fourth highest selling album of the year in the United Kingdom; at the time, the main British chart did not rank such compilations, relegating them to a chart for midpriced and TV-advertised albums, which "Elvis' 40 Greatest" topped for 15 weeks. The policy was altered in 1975, allowing the album to hit number one on the main chart in 1977, following Presley's death.
Before late 1958, rather than unified pop and country singles charts, "Billboard" had as many as four charts for each, separately ranking records according to sales, jukebox play, jockey spins (i.e., airplay), and, in the case of pop, a general "Top 100". "Billboard" now regards the sales charts as definitive for the period. Widely cited chart statistician Joel Whitburn accords historical releases the highest ranking they achieved among the separate charts. Presley discographer Ernst Jorgensen refers only to the Top 100 chart for pop hits. All of the 1956â58 songs listed here as number one US pop hits reached the top of both the sales and with three exceptions, the Top 100 charts: "I Want You, I Need You, I Love You" (three), "Hound Dog" (two, behind its flip side, "Don't Be Cruel"), and "Hard Headed Woman" (two).
Several Presley singles reached number one in the United Kingdom as double A-sides; in the United States, the respective sides of those singles were ranked separately by "Billboard". In the United States, Presley also had five or six number-one R&B singles and seven number-one adult contemporary singles; in 1964, his "Blue Christmas" topped the Christmas singles chart during a period when "Billboard" did not rank holiday singles in its primary pop chart. He also had number-one hits in many countries beside the US and UK.
TV concert specials

</doc>
<doc id="9294" url="https://en.wikipedia.org/wiki?curid=9294" title="The Evil Dead">
The Evil Dead

The Evil Dead is a 1981 American supernatural horror film written and directed by Sam Raimi and executive produced by Raimi and Bruce Campbell, who also stars alongside Ellen Sandweiss and Betsy Baker. The film focuses on five college students vacationing in an isolated cabin in a remote wooded area. After they find an audiotape that releases a legion of demons and spirits, members of the group suffer from demonic possession, leading to increasingly gory mayhem. Raimi and the cast produced the short film "Within the Woods" as a "prototype" to build the interest of potential investors, which secured Raimi US$90,000 to produce "The Evil Dead". The film was shot on location in a remote cabin located in Newport, Tennessee, in a difficult filming process that proved extremely uncomfortable for the majority of the cast and crew.
The low-budget horror film attracted the interest of producer Irvin Shapiro, who helped screen the film at the 1982 Cannes Film Festival. Horror author Stephen King gave a rave review of the film, which helped convince New Line Cinema to serve as its distributor. Though a meager commercial success in the United States, the film made its budget back through worldwide distribution, and grossed $2.4 million during its theatrical run. Both early and later critical reception were universally positive and in the years since its release, "The Evil Dead" has developed a reputation as one of the largest cult films and has been cited among the greatest horror films of all time. "The Evil Dead" launched the careers of Campbell and Raimi, who would collaborate on several films together throughout the years, including Raimi's "Spider-Man" trilogy.
The film has spawned a media franchise, beginning with two sequels written and directed by Raimi, "Evil Dead II" (1987) and "Army of Darkness" (1992), as well as video games, comic books, and in 2015, a TV show, ""Ash vs. Evil Dead" on the STARZ! network. The film's protagonist Ash Williams (Campbell) is regarded as a cult icon. The fourth film, serving as a reboot, a remake, and a sequel, was titled "Evil Dead" and was released in 2013. Raimi co-produced the film alongside Campbell and the franchise producer, Robert Tapert. As with the other films, "Ash vs. Evil Dead"" was created and produced by Sam and Ivan Raimi, with Campbell also executive producing.
Plot.
Five Michigan State University students - Ash Williams (Bruce Campbell), his girlfriend Linda (Betsy Baker), Ash's sister Cheryl (Ellen Sandweiss), their friend Scotty, and his girlfriend Shelly - venture into the Tennessee hills to vacation in an isolated cabin for their spring break. They soon run into trouble, first narrowly avoiding another motorist, then having a sudden scare as the bridge near the cabin begins to collapse as they cross. That night, while Cheryl is making a drawing of a clock, her hand becomes violently possessed by a mysterious entity, causing her to draw a picture that looks like a book with a deformed, evil face. She fails to mention the incident to the others, dismissing it as her imagination.
When the trapdoor to the cellar mysteriously flies open during dinner, Ash and Scotty go down to investigate and find the "Naturom Demonto", a Sumerian version of the "Book of the Dead", along with a tape recording of incantations, which, when played by Ash then Scotty, unleashes evil demons and spirits. Cheryl becomes hysterical when a tree crashes through the window, and she retires to her room. Later, she hears strange voices and goes outside to investigate. She is attacked and raped by demonically possessed trees, but manages to escape. The others do not believe her story, but Ash agrees to drive her to town where she can find a place to stay for the night. However, they find that the only bridge connecting the cabin to the rest of the world has been destroyed. Back at the cabin, Ash listens to more of the tape while the girls play cards, Cheryl then becomes demonically possessed, telling them that the demons will kill them. She then stabs Linda in the ankle with a pencil, and Scotty locks her in the cellar.
Shelly is the next to become possessed; she attacks Scotty, who eventually dismembers her with an axe. They bury her, and Scotty, shaken by her death, leaves to find an alternate trail through the woods.
Checking on Linda, Ash discovers that she, too, has become possessed. Scotty returns, suffering from grave injuries caused by the possessed trees. Before losing consciousness, he tells Ash that a trail does exist but is impossible because of the trees. Linda and Cheryl unsuccessfully attempt to deceive Ash into believing they are no longer possessed, only to attack him again. He locks Linda outside the cabin and tends to Scotty's injuries, but she sneaks in through the back door and attacks Ash with a dagger, which he uses to impale her. Taking her body to the woodshed, Ash tries to force himself to dismember her with a chainsaw, but finds himself unable to do it and buries her instead. She rises from the grave and attacks him, forcing him to decapitate her with a shovel.
Returning to the cabin, Ash finds that Cheryl has escaped from the cellar. Arming himself with a shotgun, he finds her hiding outside and shoots her in the shoulder. He then descends into the cellar to search for more shotgun shells after barricading the doors. While there, he hears voices and sees blood seeping from numerous crevices and openings in the walls.
A demonically possessed Scotty tries to kill Ash as Cheryl breaks through the door. During their fight, Ash sees that the "Book of the Dead" has fallen near the fireplace and is starting to burn, as are Cheryl and Scotty. As Cheryl raises a fireplace poker to impale him, Ash snatches the book and throws it into the fire. With the book burned, Cheryl and Scotty fall apart and spray blood all over Ash, as he watches in horror. After they're both dead, Ash hears an ominous voice say, "Join us".
As the sun rises, Ash heads outside to his car. An unseen evil speeds through the forest, breaks through the doors of the cabin and descends upon him. He turns around and screams in terror before the film cuts abruptly to the end credits.
Production.
Background and writing.
Raimi and Campbell grew up together, and have been friends from a young age. The duo directed several low-budget Super 8 mm film projects together. Several were comedies, including "Clockwork" and "It's Murder!". Shooting a suspense scene in "It's Murder!" inspired Raimi to approach a career in the horror genre, and after researching horror cinema at drive-in theaters, Raimi was set on directing a horror film. The idea was to shoot a short film first, which would attract the interest of producers, and then use the money gained from that to shoot a full-length project. The short film that Raimi created was called "Within the Woods". It was produced for $1,600, but for "The Evil Dead", Raimi needed over $100,000.
To generate funds for the film, Raimi approached Phil Gillis, a lawyer to one of his friends. Raimi showed him "Within the Woods", and although Gillis was not impressed by the short film, he offered Raimi legal advice on how to produce "The Evil Dead". With his advice in mind, Raimi asked a variety of people for donations, and even eventually "begged" some. Campbell had to ask several of his own family members, and Raimi asked every individual he thought could be interested. He eventually raised enough money to produce a full-length film, though not the full amount he originally wanted.
With enough money to produce the film, Raimi and Campbell set out to make what was then titled "Book of the Dead", a name inspired by Raimi's interest in the writer H. P. Lovecraft. The film was supposed to be a remake of "Within the Woods", with higher production values and a full-length running time. Raimi turned 20 just before shooting began, and he considered the project his "rite of passage".
Pre-production and casting.
Raimi asked for help and assistance from several of his friends and past collaborators to make "The Evil Dead". Campbell was cast as Ash Williams, the main character. To acquire more actors for the project, Raimi put an ad in "The Detroit News". Betsy Baker was one of the actresses who responded, and Ellen Sandweiss, who appeared in "Within the Woods", was also cast. The crew consisted almost entirely of Raimi and Campbell's friends and family. The make-up adviser for "Within the Woods", Tom Sullivan, was brought on to compose the effects after expressing a positive reaction to working with Raimi.
Without any formal assistance from location scouts, the cast had to find filming locations on their own. The crew initially attempted to shoot the film in Raimi's hometown of Royal Oak, Michigan, but instead chose Morristown, Tennessee, as Tennessee was the only state that expressed enthusiasm for the project. The crew quickly found a remote cabin located several miles away from any other buildings. During pre-production, the 13 crew members had to stay at the cabin, leading to several people sleeping in the same room. The living conditions were notoriously difficult, with several arguments breaking out between crew members.
Steve Frankel was the only carpenter on set, which made him the art direction's sole contributor. For exterior shots, Frankel had to produce several elaborate props with a circular saw. Otherwise, the cabin mostly remained the way it was found during production. The cabin had no plumbing, but phone lines were connected to it.
Filming.
Because of the crew's inexperience, filming was a "comedy of errors". The first day of filming led to the crew getting lost in the woods during a scene shot on a bridge. Several crew members became injured during the shoot, and because of the cabin's remoteness, securing medical assistance was difficult. One notably gruesome moment on set involved ripping off Baker's eyelashes during removal of her face-mask. Because of the low budget, contact lenses as thick as glass had to be applied to the actors to achieve the "demonic eyes" effect. The lenses took ten minutes to apply, and could only be left on for about fifteen minutes because eyes could not "breathe" with them applied. Campbell later commented that to get the effect of wearing these lenses, they had to put "Tupperware" over their eyes.
Raimi developed a sense of "mise en scÃ¨ne", coming up with ideas for scenes at a fast rate. He had drawn several crude illustrations to help him break down the flow of scenes. The crew was surprised when Raimi began using dutch angles during shots to build atmosphere during scenes. To accommodate Raimi's style of direction, several elaborate, low-budget rigs had to be built, since the crew could not afford a camera dolly. One involved the "vas-o-cam", which relied on a mounted camera that was slid down long wood platforms to create a more fluid sense of motion.
A camera trick used to emulate a Steadicam inexpensively was the "shaky cam", which involved mounting the camera to a piece of wood and having two camera operators sprint around the swamp.
Raimi had been a big fan of the "The Three Stooges" franchise during his youth, and it inspired him to use "fake shemps" during production. In any scene that required a background shot of a character, he would use another actor as a substitute to save time if the original actor was preoccupied. During a close-up involving Richard DeManicor's hand opening a curtain, Raimi used his own hand in the scene since it was more convenient. His brother Ted Raimi was used as a substitute in many scenes when the original actor was either busy or preoccupied.
Raimi famously enjoyed "torturing" his actors. Raimi believed that to capture pain and anger in his actors, he had to abuse them a little at times, saying, "if everyone was in extreme pain and misery, that would translate into a horror." Producer Robert Tapert agreed with Raimi, commenting that he "enjoyed when an actor bleeds." While shooting a scene with Campbell running down a hill, Campbell tripped and injured his leg. Raimi enjoyed poking Campbell's injury with a stick he found in the woods. Because of the copious amounts of blood in the film, the crew produced gallons of fake blood with karo syrup. It took Campbell hours to remove the sticky substance from himself. Several actors had inadvertently been stabbed or thrown into objects during production.
On the last few days on set, the conditions had become so poor that the crew began burning furniture to stay warm. Since only exterior shots needed to be filmed at that point, they burned nearly every piece of furniture left. Several actors went days without showering, and because of the freezing conditions, several caught colds and other illnesses. Campbell later described the filming process as nearly "twelve weeks of mirthless exercise in agony", though he allowed that he did manage to have fun while on set. On January 23, 1980, filming was finished and almost every crew member left the set to return home, with Campbell staying with Raimi. While looking over the footage that had been shot, Raimi discovered that a few pick-ups were required to fill in missing shots. Four days of re-shoots were then done to complete the film. The final moment involved Campbell having "monster-guts" splattered on him in the basement.
Editing.
After the extensive filming process, Raimi had a "mountain of footage" that he had to put together. He chose a Detroit editing association, where he met Edna Paul, to cut the film. Paul's assistant was Joel Coen of the Coen brothers, who helped with the film's editing. Paul edited a majority of the film, although Coen notably edited the shed sequence. Coen had been inspired by Raimi's "Within the Woods" and liked the idea of producing a prototype film to help build the interest of investors. Joel used the concept to help make "Blood Simple" with his brother Ethan, and he and Raimi became friends following the editing process.
The film's first cut ran at around 117 minutes, which Campbell called an impressive achievement in light of the 65-minute length of the screenplay. It was then edited down to a more marketable 85 minutes. Raimi was inspired by the fact that Brian De Palma was editing his own film "Blow Out" with John Travolta at the same sound facility. One of the most intricate moments during editing was the stop-motion sequence where the corpses "melted", which took hours to cut properly. The film had unique sounds that required extensive recording from the crew. Several sounds were not recorded properly during shooting, which meant the effects had to be redone in the editing rooms. Dead chickens were stabbed to replicate the sounds of mutilated flesh, and Campbell had to scream into a microphone for several hours.
Much like "Within the Woods", "The Evil Dead" needed to be blown up to 35mm, then the industry standard, to be played at movie theaters. The relatively large budget made this a much simpler process with "The Evil Dead" than it had been with the short film.
Promotion and distribution rights.
With the film completed, Raimi and the crew decided to celebrate with a "big premiere". They chose to screen the film at Detroit's Redford Theatre, which Campbell had often visited as a child. Raimi opted to have the most theatrical premiere possible, using custom tickets and wind tracks set in the theater, and ordering ambulances outside the theater to build atmosphere. The premiere setup was inspired by horror director William Castle, who would often attempt to scare his audiences by using gimmicks. Local turnout for the premiere exceeded the cast's expectations, with a thousand patrons showing up. The audiences responded enthusiastically to the premiere, which led to Raimi's idea of "touring" the film to build hype.
Raimi showed the film to anyone willing to watch it, booking meetings with distribution agents and anyone with experience in the film industry. Eventually Raimi came across Irvin Shapiro, the man who was responsible for the distribution of George A. Romero's "Night of the Living Dead" and other famous horror films. Upon first viewing the film, he joked that while it "wasn't "Gone with the Wind"", it had commercial potential, and he expressed an interest in distributing it. It was his idea not to use the then-title "Book of the Dead", because it made the film sound boring. Raimi brainstormed several ideas, eventually going with "The Evil Dead", deemed the "least worst" title. Shapiro also advised distributing the film worldwide to garner a larger income, though it required a further financial investment by Raimi, who managed to scrape together what little money he had.
Shapiro was a founder of the Cannes Film Festival, and allowed Raimi to screen the film at the 1982 festival out of competition. Stephen King was present at its screening and gave the film a rave review. "USA Today" released an article about King's favorite horror films; the author cited "The Evil Dead" as his fifth favorite film of the genre. The film severely affected King, who commented that while watching the film at Cannes, he was "registering things had never seen in a movie before". He became one of the film's largest supporters during the early efforts to find a distributor, eventually describing it as the "most ferociously original film of the year", a quote used in the film's promotional pieces. King's comments attracted the interest of critics, who otherwise would likely have dismissed the low-budget thriller.
The film's press attracted the attention of British film distribution agent Stephen Woolley. Though he considered the film a big risk, Woolley decided to take on the job of releasing the film in the United Kingdom. The film was promoted in an unconventional manner for a film of its budget, receiving marketing on par with that of larger budget films. Dozens of promotional pieces, including film posters and trailers, were showcased in the UK, heavy promotion rarely expended on such a low-budget film. Woolley was impressed by Raimi, whom he called "charming", and was an admirer of the film, which led to his taking more risks with the film's promotion than he normally would have.
"Fangoria" started covering the film in late 1982, writing several articles about the film's long production history. Early critical reception at the time was very positive, and along with "Fangoria", King, and Shapiro's approval, the film generated an impressive amount of interest before its commercial premiere. New Line Cinema, one of the distributors interested in the film, negotiated an agreement to distribute it domestically. The film had several "sneak previews" before its commercial release, including screenings in New York and Detroit. Audience reception at both screenings was widely enthusiastic, and interest was built for the film to such an extent that wider distribution was planned. New Line Cinema wrote Raimi a check large enough to pay off all the investors, and decided to release the film in a unique manner: simultaneously into both cinemas and onto VHS, with substantial domestic promotion.
Later in 1994, New Line Cinema was acquired by Ted Turner's Turner Broadcasting System, which then merged with Time Warner in 1996. While fellow Turner-owned studios New Line eventually became units of Warner Bros., New Line was kept as its own separate entity until February 28, 2008, when Time Warner CEO Jeffrey Bewkes announced that New Line would shut down as a separately operated studio.
Commercial release.
Because of its large promotional campaign, the film performed above expectations at the box office. It grossed a total of $2,400,000 worldwide, nearly eight times its production budget. However, the initial domestic gross was described as "disappointing." It opened in 15 theaters and grossed $108,000 in its opening weekend. Word of mouth later spread, and the film became a "sleeper hit", making over $600,000 domestically and nearly $2,000,000 overseas. In its first week of release in 1983 two years later, the film made Â£100,000 in the UK and quickly became that week's best-selling video release. It became the best-selling video in the country that year, out-grossing large-budget horror releases such as "The Shining". Its impressive European performance was chalked up to its heavy promotion there and the more open-minded nature of audiences.
The film's release was met with controversy. Raimi made the film as gruesome as possible with neither interest in nor fear of censorship, which led to the film's receiving an X rating and being named a "video nasty". Films with this label were quite violent and disturbing, and the title was often held by pornographic and other X-rated films. While "The Evil Dead" was not pornographic in nature, it was considered one of the most violent films of its time, and censors had issues with the film's content, which impacted some of its commercial potential. The film was called the "number one nasty" in a nod to its status as both a nasty and the year's best-selling video release. Writer Bruce Kawin described "The Evil Dead" as one of the most notorious splatter films of its day, along with "Cannibal Holocaust" and "I Spit on Your Grave". The film was banned either theatrically or on video in some countries.
Home video release.
The first VHS release of "The Evil Dead" was by Thorn EMI in 1983, and Thorn's successor company HBO /Cannon Video later repackaged the film. Congress Video, a company notable for public domain films, issued their version in 1989.
The resurgence of "The Evil Dead" in the home-video market came through two companies that restored the film from its negatives and issued special editions in 1998: Anchor Bay Entertainment on VHS, and Elite Entertainment on laserdisc. Anchor Bay was responsible for the film's first DVD release in 1999, and between them, Elite and Anchor Bay have released six different DVD versions of "The Evil Dead", most notably a 2002 "Book Of The Dead" edition, packaged in a latex replica of the "Necronomicon" sculpted by Tom Sullivan. The film's high-definition debut was in a 2010 Blu-ray.
Reception.
Early reception.
Upon its release, contemporary critical opinion was mostly positive. Bob Martin, editor of "Fangoria", reviewed the film before its formal premiere and proclaimed that it "might be the exception to the usual run of low-budget horror films". The "Los Angeles Times" called the film an "instant classic", proclaiming it as "probably the grisliest well-made movie ever." In a 1982 review, staff from the trade magazine "Variety" wrote that the film "emerges as the "nec plus ultra" of low-budget gore and shock effect", commenting that the "powerful" and inventive camerawork was key to creating a sense of dread.
British press for the film was positive; Kim Newman of "Monthly Film Bulletin", Richard Cook of "NME", and Julian Petley of "Film and Filming" all gave the film good reviews during its early release. Petley and Cook compared the film to other contemporary horror films, writing that the film expressed more imagination and "youthful enthusiasm" than an average horror film. Cook described the camera work by Raimi as "audacious", stating that the film's visceral nature was greatly helped by the style of direction. Woolley, Newman, and several critics complimented the film for its unexpected use of black comedy, which elevated the film above its genre's potential trappings. All three critics compared the film to the surrealistic work of Georges Franju and Jean Cocteau, noting the cinephilic references to Cocteau's film "Orpheus". Writer Lynn Schofield Clark in his novel "From Angels to Aliens" compared the film to better-known horror films such as "The Exorcist" and "The Omen", citing it as a key supernatural thriller.
Later reception.
The film continues to receive universal acclaim from modern critics. The review aggregator website Rotten Tomatoes reported a 95% approval rating with an average rating of 8.1/10, based on an aggregation of 55 reviews. It summarized the film: "This classic low budget horror film combines just the right amount of gore and black humor, giving "The Evil Dead" an equal amount of thrills and laughs." "Empire" magazine stated the film's "reputation was deserved", writing that the film was impressive considering its low budget and the cast's inexperienced nature. He commented that the film successfully blended the "bizarre" combination of "Night of the Living Dead", "The Texas Chain Saw Massacre" and "The Three Stooges". A reviewer for Film4 rated "The Evil Dead" four-and-a-half stars out of five, musing that the film was "energetic, original and icky" and concluding that Raimi's "splat-stick debut is a tight little horror classic that deserves its cult reputation, despite the best efforts of the censors."
Slant Magazine's Ed Gonzales compared the film to Dario Argento's work, citing Raimi's "unnerving wide angle work" as an important factor to the film's atmosphere. He mused that Raimi possessed an "almost unreal ability to suggest the presence of intangible evil", which was what prevented the movie from being "B-movie schlock". BBC critic Martyn Glanville awarded the film four stars out of five, writing that for Raimi, it served as a better debut film than Tobe Hooper's "The Texas Chainsaw Massacre" or Wes Craven's "The Last House on the Left". Glanville noted that other than the "ill-advised trees-that-rape scene", the film is "one of the great modern horror films, an even more impressive when one considers its modest production values."
Filmcritic.com's Christopher Null gave the film the same rating as Glanville, writing that "Raimi's biggest grossout is schlock horror done the right way" and comparing it to Romero's "Night of the Living Dead" in its ability to create stark atmosphere. "Chicago Reader" writer Pat Graham commented that the film featured several "clever" turns on the standard horror formula, adding that Raimi's "anything-for-an-effect enthusiasm pays off in lots of formally inventive bits." The make-up effects in one of the final scenes was called "amazing" by "Time Out" critic Stephen Garrett, who commented that although the film was light on character development, the "relentless" barrage of violent imagery made for an entertaining film. The same site later cited the film as the 41st greatest horror movie ever made. Phelim O'Neill of "The Guardian" combined "The Evil Dead" and its sequel "Evil Dead II" and listed them as the 23rd best horror film ever made, announcing that the former film "stands above its mostly forgotten peers in the 80s horror boom." "Complex Magazine" composed a list of the twenty-five best horror movies available on Netflix, listing "The Evil Dead" at No. 21. Don Summer, in his book "Horror Movie Freak", and writer Kate Egan have both cited the film as a horror classic.
J.C. MaÃ§ek III of "PopMatters" said, "What is unquestionable is that the Raimis and their pals created a monster in "The Evil Dead". It started as a disastrous failure to obtain a big break with a too long, too perilous shoot (note Campbellâs changing hairstyle in the various scenes of the one-day plot). The film went through name changes and bannings only to survive as not only 'the ultimate experience in grueling horror' but as an oft-imitated and cashed-in-on classic, with 30 years of positive reviews to prove it."
Aftermath.
While "The Evil Dead" received a favorable critical opinion back when it was initially released, it failed to be established as a cultural standing. It was, however, a box-office success, which led to Campbell and Raimi teaming up again for the release of another movie. Joel Coen and his brother Ethan had collaborated as directors and released the film "Blood Simple", to critical acclaim. According to Campbell, Ethan, then an accountant, expressed surprise when the duo succeeded. The Coen brothers and Raimi collaborated on a screenplay, which was released shortly after "The Evil Dead". The film, "Crimewave", was a box-office failure. The film's production was a "disaster" according to Campbell, who stated that "missteps" like "Crimewave" usually lead to the end of a director's career. Other people involved with the film expressed similar disappointment with the project. Fortunately, Raimi had the studio support to make a sequel to "The Evil Dead", which he initially decided to make out of desperation.
"Evil Dead II" was filmed and released in 1987, and was also a box-office success. A second, and currently final, sequel was released in 1993, "Army of Darkness". Campbell returned as the lead character Ash Williams in both films. At that time, Raimi had become a successful director, attracting Hollywood's interest. His 1990 superhero film "Darkman" was another box-office success, which led to an increased budget for "Army of Darkness". "Army of Darkness" had 22.8 times the budget of the original "Evil Dead", though it was not considered to be a box-office success like its two predecessors. "Evil Dead II" received general acclaim from critics and is often considered to be better than the original, and "Army of Darkness" received mostly positive reviews. The series has often attracted attention because each sequel featured more comedic qualities than the last, progressing into "weirder" territory with each film.
Unofficial sequels were also made in Italyâwhere the film was known as "La Casa" ("The House")âby Joe D'Amato's Filmirage. In 1988, D'Amato produced two films labeled as sequels to "Evil Dead II", Umberto Lenzi's "Ghosthouse" ("La Casa 3"), and "Witchery" ("La Casa 4"), starring Linda Blair and David Hasselhoff. In 1990, D'Amato produced his final "La Casa" film, "Beyond Darkness" ("La Casa 5"). "" was reissued in Italy as "La Casa 6", and "The Horror Show" was then released in Italy as "La Casa 7".
Legacy.
"The Evil Dead" and its sequels have become one of the largest cult film trilogies in history. David Lavery, in his book "The Essential Cult TV Reader", surmised that Campbell's "career is a practical guide to becoming a cult idol". The film launched the careers of Raimi and Campbell, who have since collaborated frequently. Raimi has worked with Campbell in virtually all of his films since, and Campbell has appeared in cameo roles in all three of Raimi's "Spider-Man" films, (as well as a very brief appearance at the end of Darkman) which have become some of the highest-grossing films in history. Though it has often been considered an odd choice for Raimiâa director known for his violent horror filmsâto direct a family-friendly franchise, the hiring was mostly inspired by Raimi's passion for the comic books as a kid. Raimi returned to the horror-comedy genre in 2009 with "Drag Me to Hell".
Critics have often compared Campbell's later performances to his role in "Evil Dead", which has been called his defining role. Campbell's performance as Ash has been compared to roles ranging from his performance of Elvis Presley in the film "Bubba Ho-tep" to the bigamous demon in the "The X-Files" episode "Terms of Endearment". Campbell's fan base gradually developed after the release of "Evil Dead II" and his short-lived series "The Adventures of Brisco County, Jr.". He is a regular favorite at most fan conventions and often draws sold-out auditoriums at his public appearances. "The Evil Dead" developed a substantial cult following throughout the years, and has often been cited as a defining cult classic.
"The Evil Dead" has spawned a media franchise. A video game adaptation of the same name was for the Commodore 64 in 1984, as was a trilogy of PlayStation and PlayStation 2 games in the 1990s: ', ' and '. Ted Raimi did voices for the trilogy, and Campbell returned as the voice of Ash. The character Ash became the main character of a comic book franchise. Ash has fought both Freddy Krueger and Jason Voorhees in the "Freddy vs. Jason vs. Ash" series, Herbert West in "Army of Darkness vs. Re-Animator", zombie versions of the Marvel Comics superhero team "Avengers" in "Marvel Zombies vs. The Army of Darkness", and has even saved the life of a fictional Barack Obama in '. In January 2008, Dark Horse Comics began releasing a four-part monthly comic book mini-series, written by Mark Verheiden and drawn by John Bolton, based on "The Evil Dead".
In addition, the film has inspired a stage musical, "", which was produced with the permission of Raimi and Campbell. The musical has run on and off since its inception in 2003. A remake of the film was released in 2013, directed by Fede Alvarez and produced by Raimi and Campbell. It features actress Jane Levy as the main character, with Ash not appearing. Campbell does make a brief, uncredited cameo appearance at the end of the film in a short post-credits scene.
In 2015, an ongoing continuation of the films called "Ash vs. Evil Dead" premiered on the Starz Network. The first episode was directed by Raimi, and Campbell is reprising his role as Ash. The series is being produced by Renaissance, and follows an older Ash as he encounters more spirits and demons from the Necronomicon.

</doc>

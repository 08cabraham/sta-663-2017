<doc id="11461" url="https://en.wikipedia.org/wiki?curid=11461" title="Francis Crick">
Francis Crick

Francis Harry Compton Crick (8 June 1916 – 28 July 2004) was a British molecular biologist, biophysicist, and neuroscientist, most noted for being a co-discoverer of the structure of the DNA molecule in 1953 with James Watson. Together with Watson and Maurice Wilkins, he was jointly awarded the 1962 Nobel Prize in Physiology or Medicine "for their discoveries concerning the molecular structure of nucleic acids and its significance for information transfer in living material".
Crick was an important theoretical molecular biologist and played a crucial role in research related to revealing the genetic code. He is widely known for use of the term "central dogma" to summarize the idea that genetic information flow in cells is essentially one-way, from DNA to RNA to protein.
During the remainder of his career, he held the post of J.W. Kieckhefer Distinguished Research Professor at the Salk Institute for Biological Studies in La Jolla, California. His later research centered on theoretical neurobiology and attempts to advance the scientific study of human consciousness. He remained in this post until his death; "he was editing a manuscript on his death bed, a scientist until the bitter end" according to Christof Koch.
Early life and education.
Crick was the first son of Harry Crick (1887–1948) and Annie Elizabeth Crick (née Wilkins; 1879–1955). He was born and raised in Weston Favell, then a small village near the English town of Northampton, in which Crick’s father and uncle ran the family’s boot and shoe factory. His grandfather, Walter Drawbridge Crick (1857–1903), an amateur naturalist, wrote a survey of local foraminifera (single-celled protists with shells), corresponded with Charles Darwin, and had two gastropods (snails or slugs) named after him.
At an early age, Francis was attracted to science and what he could learn about it from books. As a child, he was taken to church by his parents. But by about age 12, he said he did not want to go anymore, as he preferred a scientific search for answers over religious belief.
Walter Crick, his uncle, lived in a small house on the south side of Abington Avenue; he had a shed at the bottom of his little garden where he taught Crick to blow glass, do chemical experiments and to make photographic prints. When he was eight or nine he transferred to the most junior form of the Northampton Grammar School, on the Billing Road. This was about 1 1/4 miles from his home so he could walk there and back, by Park Avenue South and Abington Park Crescent, but he more often went by bus or, later, by bicycle. The teacher – a Miss Holding – was an inspired teacher and made everything interesting. The teaching in the higher forms was satisfactory, but not as stimulating. After the age of 14, he was educated at Mill Hill School in London (on scholarship), where he studied mathematics, physics, and chemistry with his best friend John Shilston. He shared the Walter Knox Prize for Chemistry on Mill Hill School's Foundation Day, Friday, 7 July 1933. He declared that his success was inspired by the quality of teaching he received whilst a pupil at Mill Hill.
At the age of 21, Crick earned a Bachelor of Science degree in physics from University College London. Crick had failed to gain a place at a Cambridge college, probably through failing their requirement for Latin. Crick began his PhD at UCL but was interrupted by WWII. He later became a PhD student and Honorary Fellow of Gonville and Caius College, Cambridge and mainly worked at the Cavendish Laboratory and the Medical Research Council (MRC) Laboratory of Molecular Biology in Cambridge. He was also an Honorary Fellow of Churchill College, Cambridge and of University College, London.
Crick began a Ph.D. research project on measuring viscosity of water at high temperatures (which he later described as "the dullest problem imaginable") in the laboratory of physicist Edward Neville da Costa Andrade at University College, London, but with the outbreak of World War II (in particular, an incident during the Battle of Britain when a bomb fell through the roof of the laboratory and destroyed his experimental apparatus), Crick was deflected from a possible career in physics. During his second year as a PhD student, however, he was awarded the Carey Foster Research Prize, a great honour. He did postdoctoral work at the Polytechnic Institute of Brooklyn.
During World War II, he worked for the Admiralty Research Laboratory, from which emerged a group of many notable scientists, including David Bates, Robert Boyd, George Deacon, John Gunn, Harrie Massey, and Nevill Mott; he worked on the design of magnetic and acoustic mines, and was instrumental in designing a new mine that was effective against German minesweepers.
Post-World War II life and work.
In 1947, aged 31, Crick began studying biology and became part of an important migration of physical scientists into biology research. This migration was made possible by the newly won influence of physicists such as Sir John Randall, who had helped win the war with inventions such as ``: radar. Crick had to adjust from the "elegance and deep simplicity" of physics to the "elaborate chemical mechanisms that natural selection had evolved over billions of years." He described this transition as, "almost as if one had to be born again." According to Crick, the experience of learning physics had taught him something important—hubris—and the conviction that since physics was already a success, great advances should also be possible in other sciences such as biology. Crick felt that this attitude encouraged him to be more daring than typical biologists who tended to concern themselves with the daunting problems of biology and not the past successes of physics.
For the better part of two years, Crick worked on the physical properties of cytoplasm at Cambridge's Strangeways Research Laboratory, headed by Honor Bridget Fell, with a Medical Research Council studentship, until he joined Max Perutz and John Kendrew at the Cavendish Laboratory. The Cavendish Laboratory at Cambridge was under the general direction of Sir Lawrence Bragg, who had won the Nobel Prize in 1915 at the age of 25. Bragg was influential in the effort to beat a leading American chemist, Linus Pauling, to the discovery of DNA's structure (after having been pipped at the post by Pauling's success in determining the alpha helix structure of proteins). At the same time Bragg's Cavendish Laboratory was also effectively competing with King's College London, whose Biophysics department was under the direction of Sir John Randall. (Randall had refused Crick's application to work at King's College.) Francis Crick and Maurice Wilkins of King's College were personal friends, which influenced subsequent scientific events as much as the close friendship between Crick and James Watson. Crick and Wilkins first met at King's College and not, as erroneously recorded by two authors, at the Admiralty during World War II.
He married twice, fathered three children and was the grandfather of six grandchildren; his brother Anthony (born in 1918) predeceased him in 1966.
Spouses:
Children:
Grandchildren
Death.
Crick died of colon cancer on the morning of 28 July 2004 at the University of California, San Diego (UCSD) Thornton Hospital in La Jolla; he was cremated and his ashes were scattered into the Pacific Ocean. A public memorial was held on 27 September 2004 at the Salk Institute, La Jolla, near San Diego, California; guest speakers included James Watson, Sydney Brenner, Alex Rich, Seymour Benzer, Aaron Klug, Christof Koch, Pat Churchland, Vilayanur Ramachandran, Tomaso Poggio, Leslie Orgel, Terry Sejnowski, his son Michael Crick, and his youngest daughter Jacqueline Nichols. A private memorial for family and colleagues was held on 3 August 2004.
Research.
Crick was interested in two fundamental unsolved problems of biology: how molecules make the transition from the non-living to the living, and how the brain makes a conscious mind. He realized that his background made him more qualified for research on the first topic and the field of biophysics. It was at this time of Crick’s transition from physics to biology that he was influenced by both Linus Pauling and Erwin Schrödinger. It was clear in theory that covalent bonds in biological molecules could provide the structural stability needed to hold genetic information in cells. It only remained as an exercise of experimental biology to discover exactly which molecule was the genetic molecule. In Crick’s view, Charles Darwin’s theory of evolution by natural selection, Gregor Mendel’s genetics and knowledge of the molecular basis of genetics, when combined, revealed the secret of life. Crick had the very optimistic view that life would very soon be created in a test tube. However, some people (such as fellow researcher and colleague Esther Lederberg) thought that Crick was unduly optimistic 
It was clear that some macromolecule such as a protein was likely to be the genetic molecule. However, it was well known that proteins are structural and functional macromolecules, some of which carry out enzymatic reactions of cells. In the 1940s, some evidence had been found pointing to another macromolecule, DNA, the other major component of chromosomes, as a candidate genetic molecule. In the 1944 Avery-MacLeod-McCarty experiment, Oswald Avery and his collaborators showed that a heritable phenotypic difference could be caused in bacteria by providing them with a particular DNA molecule.
However, other evidence was interpreted as suggesting that DNA was structurally uninteresting and possibly just a molecular scaffold for the apparently more interesting protein molecules. Crick was in the right place, in the right frame of mind, at the right time (1949), to join Max Perutz’s project at the University of Cambridge, and he began to work on the X-ray crystallography of proteins. X-ray crystallography theoretically offered the opportunity to reveal the molecular structure of large molecules like proteins and DNA, but there were serious technical problems then preventing X-ray crystallography from being applicable to such large molecules.
1949–1950.
Crick taught himself the mathematical theory of X-ray crystallography. During the period of Crick's study of X-ray diffraction, researchers in the Cambridge lab were attempting to determine the most stable helical conformation of amino acid chains in proteins (the Alpha helix). Linus Pauling was the first to identify the 3.6 amino acids per helix turn ratio of the Alpha helix. Crick was witness to the kinds of errors that his co-workers made in their failed attempts to make a correct molecular model of the α helix; these turned out to be important lessons that could be applied, in the future, to the helical structure of DNA. For example, he learned the importance of the structural rigidity that double bonds confer on molecular structures which is relevant both to peptide bonds in proteins and the structure of nucleotides in DNA.
1951–1953: DNA structure.
In 1951 and 1952, together with William Cochran and Vladimir Vand, Crick assisted in the development of a mathematical theory of X-ray diffraction by a helical molecule. This theoretical result matched well with X-ray data for proteins that contain sequences of amino acids in the Alpha helix conformation. Helical diffraction theory turned out to also be useful for understanding the structure of DNA.
Late in 1951, Crick started working with James Watson at Cavendish Laboratory at the University of Cambridge, England. Using "Photo 51" (the X-ray diffraction results of Rosalind Franklin and her graduate student Raymond Gosling of King's College London, given to them by Gosling and Franklin's colleague Maurice Wilkins), Watson and Crick together developed a model for a helical structure of DNA, which they published in 1953. For this and subsequent work they were jointly awarded the Nobel Prize in Physiology or Medicine in 1962 with Maurice Wilkins.
When James Watson came to Cambridge, Crick was a 35-year-old graduate student (due to his work during WWII) and Watson was only 23, but he already had a Ph.D. They shared an interest in the fundamental problem of learning how genetic information might be stored in molecular form. Watson and Crick talked endlessly about DNA and the idea that it might be possible to guess a good molecular model of its structure. A key piece of experimentally-derived information came from X-ray diffraction images that had been obtained by Maurice Wilkins, Rosalind Franklin, and their research student, Raymond Gosling. In November 1951, Wilkins came to Cambridge and shared his data with Watson and Crick. Alexander Stokes (another expert in helical diffraction theory) and Wilkins (both at King's College) had reached the conclusion that X-ray diffraction data for DNA indicated that the molecule had a helical structure—but Franklin vehemently disputed this conclusion. Stimulated by their discussions with Wilkins and what Watson learned by attending a talk given by Franklin about her work on DNA, Crick and Watson produced and showed off an erroneous first model of DNA. Their hurry to produce a model of DNA structure was driven in part by the knowledge that they were competing against Linus Pauling. Given Pauling's recent success in discovering the Alpha helix, they feared that Pauling might also be the first to determine the structure of DNA.
Many have speculated about what might have happened had Pauling been able to travel to Britain as planned in May 1952. As it was, his political activities caused his travel to be restricted by the U. S. government and he did not visit the UK until later, at which point he met none of the DNA researchers in England. At any rate he was preoccupied with proteins at the time, not DNA. Watson and Crick were not officially working on DNA. Crick was writing his Ph.D. thesis; Watson also had other work such as trying to obtain crystals of myoglobin for X-ray diffraction experiments. In 1952, Watson performed X-ray diffraction on tobacco mosaic virus and found results indicating that it had helical structure. Having failed once, Watson and Crick were now somewhat reluctant to try again and for a while they were forbidden to make further efforts to find a molecular model of DNA.
Of great importance to the model building effort of Watson and Crick was Rosalind Franklin's understanding of basic chemistry, which indicated that the hydrophilic phosphate-containing backbones of the nucleotide chains of DNA should be positioned so as to interact with water molecules on the outside of the molecule while the hydrophobic bases should be packed into the core. Franklin shared this chemical knowledge with Watson and Crick when she pointed out to them that their first model (from 1951, with the phosphates inside) was obviously wrong.
Crick described what he saw as the failure of Maurice Wilkins and Rosalind Franklin to cooperate and work towards finding a molecular model of DNA as a major reason why he and Watson eventually made a second attempt to do so. They asked for, and received, permission to do so from both William Lawrence Bragg and Wilkins. In order to construct their model of DNA, Watson and Crick made use of information from unpublished X-ray diffraction images of Franklin's (shown at meetings and freely shared by Wilkins), including preliminary accounts of Franklin's results/photographs of the X-ray images that were included in a written progress report for the King's College laboratory of Sir John Randall from late 1952.
It is a matter of debate whether Watson and Crick should have had access to Franklin's results without her knowledge or permission, and before she had a chance to formally publish the results of her detailed analysis of her X-ray diffraction data which were included in the progress report. However, Watson and Crick found fault in her steadfast assertion that, according to her data, a helical structure was not the only possible shape for DNA—so they had a dilemma. In an effort to clarify this issue, Max Ferdinand Perutz later published what had been in the progress report, and suggested that nothing was in the report that Franklin herself had not said in her talk (attended by Watson) in late 1951. Further, Perutz explained that the report was to a Medical Research Council (MRC) committee that had been created in order to "establish contact between the different groups of people working for the Council". Randall's and Perutz's laboratories were both funded by the MRC.
It is also not clear how important Franklin's unpublished results from the progress report actually were for the model-building done by Watson and Crick. After the first crude X-ray diffraction images of DNA were collected in the 1930s, William Astbury had talked about stacks of nucleotides spaced at 3.4 angström (0.34 nanometre) intervals in DNA. A citation to Astbury's earlier X-ray diffraction work was one of only eight references in Franklin's first paper on DNA. Analysis of Astbury's published DNA results and the better X-ray diffraction images collected by Wilkins and Franklin revealed the helical nature of DNA. It was possible to predict the number of bases stacked within a single turn of the DNA helix (10 per turn; a full turn of the helix is 27 angströms .7 n in the compact A form, 34 angströms .4 n in the wetter B form). Wilkins shared this information about the B form of DNA with Crick and Watson. Crick did not see Franklin's B form X-ray images (Photo 51) until after the DNA double helix model was published.
One of the few references cited by Watson and Crick when they published their model of DNA was to a published article that included Sven Furberg's DNA model that had the bases on the inside. Thus, the Watson and Crick model was not the first "bases in" model to be proposed. Furberg's results had also provided the correct orientation of the DNA sugars with respect to the bases. During their model building, Crick and Watson learned that an antiparallel orientation of the two nucleotide chain backbones worked best to orient the base pairs in the centre of a double helix. Crick's access to Franklin's progress report of late 1952 is what made Crick confident that DNA was a double helix with antiparallel chains, but there were other chains of reasoning and sources of information that also led to these conclusions.
As a result of leaving King's College for Birkbeck College, Franklin was asked by John Randall to give up her work on DNA. When it became clear to Wilkins and the supervisors of Watson and Crick that Franklin was going to the new job, and that Linus Pauling was working on the structure of DNA, they were willing to share Franklin's data with Watson and Crick, in the hope that they could find a good model of DNA before Pauling was able. Franklin's X-ray diffraction data for DNA and her systematic analysis of DNA's structural features was useful to Watson and Crick in guiding them towards a correct molecular model. The key problem for Watson and Crick, which could not be resolved by the data from King's College, was to guess how the nucleotide bases pack into the core of the DNA double helix.
Another key to finding the correct structure of DNA was the so-called Chargaff ratios, experimentally determined ratios of the nucleotide subunits of DNA: the amount of guanine is equal to cytosine and the amount of adenine is equal to thymine. A visit by Erwin Chargaff to England in 1952 reinforced the salience of this important fact for Watson and Crick. The significance of these ratios for the structure of DNA were not recognized until Watson, persisting in building structural models, realized that A:T and C:G pairs are structurally similar. In particular, the length of each base pair is the same. Chargaff had also pointed out to Watson that, in the aqueous, saline environment of the cell, the predominant tautomers of the pyrimidine (C and T) bases would be the amine and keto configurations of cytosine and thymine, rather than the imino and enol forms that Crick and Watson had assumed. They consulted Jerry Donohue who confirmed the most likely structures of the nucleotide bases. The base pairs are held together by hydrogen bonds, the same non-covalent interaction that stabilize the protein α-helix. The correct structures were essential for the positioning of the hydrogen bonds. These insights led Watson to deduce the true biological relationships of the A:T and C:G pairs. After the discovery of the hydrogen bonded A:T and C:G pairs, Watson and Crick soon had their anti-parallel, double helical model of DNA, with the hydrogen bonds at the core of the helix providing a way to "unzip" the two complementary strands for easy replication: the last key requirement for a likely model of the genetic molecule. As important as Crick's contributions to the discovery of the double helical DNA model were, he stated that without the chance to collaborate with Watson, he would not have found the structure by himself.
Crick did tentatively attempt to perform some experiments on nucleotide base pairing, but he was more of a theoretical biologist than an experimental biologist. There was another near-discovery of the base pairing rules in early 1952. Crick had started to think about interactions between the bases. He asked John Griffith to try to calculate attractive interactions between the DNA bases from chemical principles and quantum mechanics. Griffith's best guess was that A:T and G:C were attractive pairs. At that time, Crick was not aware of Chargaff's rules and he made little of Griffith's calculations, although it did start him thinking about complementary replication. Identification of the correct base-pairing rules (A-T, G-C) was achieved by Watson "playing" with cardboard cut-out models of the nucleotide bases, much in the manner that Linus Pauling had discovered the protein alpha helix a few years earlier. The Watson and Crick discovery of the DNA double helix structure was made possible by their willingness to combine theory, modeling and experimental results (albeit mostly done by others) to achieve their goal.
The DNA double helix structure proposed by Watson and Crick was based upon "Watson-Crick" bonds between the four bases most frequently found in DNA (A, C, T, G) and RNA (A, C, U, G). However, later research showed that triple-stranded, quadruple-stranded and other more complex DNA molecular structures required Hoogsteen base pairing. The entire field of synthetic biology began with work by researchers such as Erik T. Kool, in which bases other than A, C, T and G are used in a synthetic DNA. In addition to synthetic DNA there are also attempts to construct synthetic codons, synthetic endonucleases, synthetic proteins and synthetic zinc fingers. Using synthetic DNA, instead of there being 4 codons, if there are n new bases there could be as many as n codons. Research is currently being done to see if codons can be expanded to more than 3 bases. These new codons can code for new amino acids. These synthetic molecules can be used not only in medicine, but in creation of new materials.
The discovery was made on 28 February 1953; the first Watson/Crick paper appeared in "Nature" on 25 April 1953. Sir Lawrence Bragg, the director of the Cavendish Laboratory, where Watson and Crick worked, gave a talk at Guy's Hospital Medical School in London on Thursday 14 May 1953 which resulted in an article by Ritchie Calder in The News Chronicle of London, on Friday 15 May 1953, entitled "Why You Are You. Nearer Secret of Life." The news reached readers of The New York Times the next day; Victor K. McElheny, in researching his biography, "Watson and DNA: Making a Scientific Revolution", found a clipping of a six-paragraph New York Times article written from London and dated 16 May 1953 with the headline "Form of 'Life Unit' in Cell Is Scanned." The article ran in an early edition and was then pulled to make space for news deemed more important. (The New York Times subsequently ran a longer article on 12 June 1953). The university's undergraduate newspaper "Varsity" also ran its own short article on the discovery on Saturday 30 May 1953. Bragg's original announcement of the discovery at a Solvay conference on proteins in Belgium on 8 April 1953 went unreported by the British press.
In a seven-page, handwritten letter to his son at a British boarding school on 19 March 1953 Crick explained his discovery, beginning the letter "My Dear Michael, Jim Watson and I have probably made a most important discovery...". The letter was put up for auction at Christie's New York on 10 April 2013 with an estimate of $1 to $2 million, eventually selling for $6,059,750, the largest amount ever paid for a letter at auction.
Sydney Brenner, Jack Dunitz, Dorothy Hodgkin, Leslie Orgel, and Beryl M. Oughton, were some of the first people in April 1953 to see the model of the structure of DNA, constructed by Crick and Watson; at the time they were working at Oxford University's Chemistry Department. All were impressed by the new DNA model, especially Brenner who subsequently worked with Crick at Cambridge in the Cavendish Laboratory and the new Laboratory of Molecular Biology. According to the late Dr. Beryl Oughton, later Rimmer, they all travelled together in two cars once Dorothy Hodgkin announced to them that they were off to Cambridge to see the model of the structure of DNA. Orgel also later worked with Crick at the Salk Institute for Biological Studies.
In addition, the entire field of synthetic biology began with researchers such as Erik T. Kool, where bases other than A, C, T and G are used in a synthetic DNA. In addition to synthetic DNA there are also attempts to construct synthetic codons, synthetic endonucleases, synthetic proteins and synthetic zinc fingers. Using synthetic DNA, instead of there being 4 codons, if there are n new bases there could be as many as n codons. Research is currently being done to see if codons can be expanded to more than 3 bases. These new codons can code for new amino acids. These synthetic molecules can be used not only in medicine, but in creation of new materials.
Molecular biology.
In 1954, at the age of 37, Crick completed his Ph.D. thesis: "X-Ray Diffraction: Polypeptides and Proteins" and received his degree. Crick then worked in the laboratory of David Harker at Brooklyn Polytechnic Institute, where he continued to develop his skills in the analysis of X-ray diffraction data for proteins, working primarily on ribonuclease and the mechanisms of protein synthesis. David Harker, the American X-ray crystallographer, was described as "the John Wayne of crystallography" by Vittorio Luzzati, a crystallographer at the Centre for Molecular Genetics in Gif-sur-Yvette near Paris, who had worked with Rosalind Franklin.
After the discovery of the double helix model of DNA, Crick's interests quickly turned to the biological implications of the structure. In 1953, Watson and Crick published another article in "Nature" which stated: "it therefore seems likely that the precise sequence of the bases is the code that carries the genetical information".
In 1956, Crick and Watson speculated on the structure of small viruses. They suggested that spherical viruses such as Tomato bushy stunt virus had icosahedral symmetry and were made from 60 identical subunits.
After his short time in New York, Crick returned to Cambridge where he worked until 1976, at which time he moved to California. Crick engaged in several X-ray diffraction collaborations such as one with Alexander Rich on the structure of collagen. However, Crick was quickly drifting away from continued work related to his expertise in the interpretation of X-ray diffraction patterns of proteins.
George Gamow established a group of scientists interested in the role of RNA as an intermediary between DNA as the genetic storage molecule in the nucleus of cells and the synthesis of proteins in the cytoplasm (the RNA Tie Club). It was clear to Crick that there had to be a code by which a short sequence of nucleotides would specify a particular amino acid in a newly synthesized protein. In 1956, Crick wrote an informal paper about the genetic coding problem for the small group of scientists in Gamow's RNA group. In this article, Crick reviewed the evidence supporting the idea that there was a common set of about 20 amino acids used to synthesize proteins. Crick proposed that there was a corresponding set of small "adaptor molecules" that would hydrogen bond to short sequences of a nucleic acid, and also link to one of the amino acids. He also explored the many theoretical possibilities by which short nucleic acid sequences might code for the 20 amino acids.
During the mid-to-late 1950s Crick was very much intellectually engaged in sorting out the mystery of how proteins are synthesized. By 1958, Crick's thinking had matured and he could list in an orderly way all of the key features of the protein synthesis process:
The adaptor molecules were eventually shown to be tRNAs and the catalytic "ribonucleic-protein complexes" became known as ribosomes. An important step was later realization (in 1960) that the messenger RNA was not the same as the ribosomal RNA. None of this, however, answered the fundamental theoretical question of the exact nature of the genetic code. In his 1958 article, Crick speculated, as had others, that a triplet of nucleotides could code for an amino acid. Such a code might be "degenerate", with 4×4×4=64 possible triplets of the four nucleotide subunits while there were only 20 amino acids. Some amino acids might have multiple triplet codes. Crick also explored other codes in which, for various reasons, only some of the triplets were used, "magically" producing just the 20 needed combinations. Experimental results were needed; theory alone could not decide the nature of the code. Crick also used the term "central dogma" to summarize an idea that implies that genetic information flow between macromolecules would be essentially one-way:
Some critics thought that by using the word "dogma", Crick was implying that this was a rule that could not be questioned, but all he really meant was that it was a compelling idea without much solid evidence to support it. In his thinking about the biological processes linking DNA genes to proteins, Crick made explicit the distinction between the materials involved, the energy required, and the information flow. Crick was focused on this third component (information) and it became the organizing principle of what became known as molecular biology. Crick had by this time become a highly influential theoretical molecular biologist.
Proof that the genetic code is a degenerate triplet code finally came from genetics experiments, some of which were performed by Crick. The details of the code came mostly from work by Marshall Nirenberg and others who synthesized synthetic RNA molecules and used them as templates for "in vitro" protein synthesis. Nirenberg first announced his results to a small audience in Moscow at a 1961 conference. Crick's reaction was to invite Nirenberg to deliver his talk to a larger audience.
Controversy.
An enduring controversy has been generated by Watson and Crick's use of DNA X-ray diffraction data collected by Rosalind Franklin and her student Raymond Gosling. The controversy arose from the fact that some of Franklin's unpublished data were used without her knowledge or consent by Watson and Crick in their construction of the double helix model of DNA. Of the four DNA researchers, only Rosalind Franklin had a degree in chemistry: Wilkins and Crick had backgrounds in physics, Watson in molecular biology.
Prior to publication of the double helix structure, Watson and Crick had little direct interaction with Franklin herself. They were, however, aware of her work, more aware than she herself realized. Watson was present at a lecture, given in November 1951, where Franklin presented the two forms of the molecule, type A and type B, and discussed the position of the phosphate units on the external part of the molecule. She also specified the amount of water to be found in the molecule in accordance with other parts of it, data that have considerable importance in terms of the stability of the molecule. Franklin was the first to discover and formulate these facts, which in fact constituted the basis for all later attempts to build a model of the molecule. Before this both Linus Pauling and Watson and Crick had generated erroneous models with the chains inside and the bases pointing outwards. Her identification of the space group for DNA crystals revealed to Crick that the two DNA strands were antiparallel.
In January 1953, James Watson was shown an X-ray photograph of B-DNA (called photograph 51), by Maurice Wilkins. Maurice Wilkins had been given photograph 51 by Rosalind Franklin's Ph.D. student Raymond Gosling. Wilkins and Gosling had worked together in the Medical Research Council's (MRC) Biophysics Unit before director John Randall appointed Franklin to take over both DNA diffraction work and guidance of Gosling's thesis. It appears that Randall did not communicate effectively with them about Franklin's appointment, contributing to confusion and friction between Wilkins and Franklin.
In the middle of February 1953, Crick's thesis advisor, Max Perutz, gave Crick a copy of a report written for a Medical Research Council biophysics committee visit to King's in December 1952, containing data from the King's group, including some of Rosalind Franklin's crystallographic calculations.
Franklin was unaware that photograph 51 and other information had been shared with Crick and Watson. She wrote a series of three draft manuscripts, two of which included a double helical DNA backbone. Her two A form manuscripts reached Acta Crystallographica in Copenhagen on 6 March 1953, one day before Crick and Watson had completed their model.
The X-ray diffraction images collected by Gosling and Franklin provided the best evidence for the helical nature of DNA. Franklin's experimental work thus proved crucial in Watson and Crick's discovery. Her experimental results provided estimates of the water content of DNA crystals, and these results were most consistent with the three sugar-phosphate backbones being on the outside of the molecule. Franklin's X-Ray photograph showed that the backbones had to be on the outside. Although she at first insisted vehemently that her data did not force one to conclude that DNA has a helical structure, in the drafts she submitted in 1953 she argues for a double helical DNA backbone. Her identification of the space group for DNA crystals revealed to Crick that the DNA strands were antiparallel, which helped Watson and Crick decide to look for DNA models with two antiparallel polynucleotide strands.
In summary, Watson and Crick had three sources for Franklin's unpublished data: 1) her 1951 seminar, attended by Watson, 2) discussions with Wilkins, who worked in the same laboratory with Franklin, 3) a research progress report that was intended to promote coordination of Medical Research Council-supported laboratories. Watson, Crick, Wilkins and Franklin all worked in MRC laboratories.
Crick and Watson felt that they had benefited from collaborating with Wilkins. They offered him a co-authorship on the article that first described the double helix structure of DNA. Wilkins turned down the offer, a fact that may have led to the terse character of the acknowledgment of experimental work done at King's College in the eventual published paper. Rather than make any of the DNA researchers at King's College co-authors on the Watson and Crick double helix article, the solution that was arrived at was to publish two additional papers from King's College along with the helix paper. Brenda Maddox suggests that because of the importance of her experimental results in Watson and Crick's model building and theoretical analysis, Franklin should have had her name on the original Watson and Crick paper in "Nature". Franklin and Gosling submitted their own joint 'second' paper to "Nature" at the same time as Wilkins, Stokes, and Wilson submitted theirs (i.e. the 'third' paper on DNA).
Watson's portrayal of Franklin in "The Double Helix" (written after Franklin's death when libel laws did not apply anymore) was negative and gave the appearance that she was Wilkins' assistant and was unable to interpret her own DNA data.
The X-ray diffraction images collected by Franklin provided the best evidence for the helical nature of DNA. While Franklin's experimental work proved important to Crick and Watson's development of a correct model, she herself could not realize it at the time. When she left King's College, Director Sir John Randall insisted that all DNA work belonged exclusively to King's and ordered Franklin to not even think about it. Franklin subsequently did superb work in J. D. Bernal's Lab at Birkbeck College with the tobacco mosaic virus extending ideas on helical construction.
Views on religion.
Crick referred to himself as a humanist, which he defined as the belief "that human problems can and must be faced in terms of human moral and intellectual resources without invoking supernatural authority." He publicly called for humanism to replace religion as a guiding force for humanity, writing:
Crick was especially critical of Christianity:
Crick once joked, "Christianity may be OK between consenting adults in private but should not be taught to young children."
In his book "Of Molecules and Men", Crick expressed his views on the relationship between science and religion. After suggesting that it would become possible for a computer to be programmed so as to have a soul, he wondered: at what point during biological evolution did the first organism have a soul? At what moment does a baby get a soul? Crick stated his view that the idea of a non-material soul that could enter a body and then persist after death is just that, an imagined idea. For Crick, the mind is a product of physical brain activity and the brain had evolved by natural means over millions of years. He felt that it was important that evolution by natural selection be taught in schools and that it was regrettable that English schools had compulsory religious instruction. He also considered that a new scientific world view was rapidly being established, and predicted that once the detailed workings of the brain were eventually revealed, erroneous Christian concepts about the nature of humans and the world would no longer be tenable; traditional conceptions of the "soul" would be replaced by a new understanding of the physical basis of mind. He was sceptical of organized religion, referring to himself as a skeptic and an agnostic with "a strong inclination towards atheism".
In 1960, Crick accepted an honorary fellowship at Churchill College, Cambridge, one factor being that the new college did not have a chapel. Some time later a large donation was made to establish a chapel and the College Council decided to accept it. Crick resigned his fellowship in protest.
In October 1969 Crick participated in a celebration of the 100th year of the journal "Nature" in which he attempted to make some predictions about what the next 30 years would hold for molecular biology. His speculations were later published in "Nature". Near the end of the article, Crick briefly mentioned the search for life on other planets, but he held little hope that extraterrestrial life would be found by the year 2000. He also discussed what he described as a possible new direction for research, what he called "biochemical theology". Crick wrote "so many people pray that one finds it hard to believe that they do not get some satisfaction from it".
Crick suggested that it might be possible to find chemical changes in the brain that were molecular correlates of the act of prayer. He speculated that there might be a detectable change in the level of some neurotransmitter or neurohormone when people pray. He might have been imagining substances such as dopamine that are released by the brain under certain conditions and produce rewarding sensations. Crick's suggestion that there might someday be a new science of "biochemical theology" seems to have been realized under an alternative name: there is now the new field of neurotheology. Crick's view of the relationship between science and religion continued to play a role in his work as he made the transition from molecular biology research into theoretical neuroscience.
Crick asked in 1998 "and if some of the Bible is manifestly wrong, why should any of the rest of it be accepted automatically? ... And what would be more important than to find our true place in the universe by removing one by one these unfortunate vestiges of earlier beliefs?"
In 2003 he was one of 22 Nobel laureates who signed the Humanist Manifesto.
Directed panspermia.
During the 1960s, Crick became concerned with the origins of the genetic code. In 1966, Crick took the place of Leslie Orgel at a meeting where Orgel was to talk about the origin of life. Crick speculated about possible stages by which an initially simple code with a few amino acid types might have evolved into the more complex code used by existing organisms. At that time, everyone thought of proteins as the only kind of enzymes and ribozymes had not yet been found. Many molecular biologists were puzzled by the problem of the origin of a protein replicating system that is as complex as that which exists in organisms currently inhabiting Earth. In the early 1970s, Crick and Orgel further speculated about the possibility that the production of living systems from molecules may have been a very rare event in the universe, but once it had developed it could be spread by intelligent life forms using space travel technology, a process they called "directed panspermia". In a retrospective article, Crick and Orgel noted that they had been overly pessimistic about the chances of abiogenesis on Earth when they had assumed that some kind of self-replicating protein system was the molecular origin of life.
In 1976 Crick addressed the origin of protein synthesis in a paper with Sydney Brenner, Aaron Klug, and George Pieczenik. In this paper, based on Pieczenik's work, they speculate that code constraints on nucleotide sequences allow protein synthesis without the need for a ribosome. It, however, requires a five base binding between the mRNA and tRNA with a flip of the anti-codon creating a triplet coding, even though it is a five-base physical interaction. Thomas H. Jukes pointed out that the code constraints on the mRNA sequence required for this translation mechanism is still preserved.
Neuroscience and other interests.
Crick's period at Cambridge was the pinnacle of his long scientific career, but he left Cambridge in 1977 after 30 years, having been offered (and having refused) the Mastership of Gonville & Caius. James Watson claimed at a Cambridge conference marking the 50th anniversary of the discovery of the structure of DNA in 2003: "Now perhaps it's a pretty well kept secret that one of the most uninspiring acts of the University of Cambridge over this past century was to turn down Francis Crick when he applied to be the Professor of Genetics, in 1958. Now there may have been a series of arguments, which led them to reject Francis. It was really saying, don't push us to the frontier." The apparently "pretty well kept secret" had already been recorded in Soraya De Chadarevian's "Designs For Life: Molecular Biology After World War II", published by CUP in 2002. His major contribution to molecular biology in Cambridge is well documented in The History of the University of Cambridge: Volume 4 (1870 to 1990), which was published by Cambridge University Press in 1992.
According to the University of Cambridge's genetics department official website, the electors of the professorship could not reach consensus, prompting the intervention of then University Vice-Chancellor Lord Adrian. Lord Adrian first offered the professorship to a compromise candidate, Guido Pontecorvo, who refused, and is said to have offered it then to Crick, who also refused.
In 1976, Crick took a sabbatical year at the Salk Institute for Biological Studies in La Jolla, California. Crick had been a nonresident fellow of the Institute since 1960. Crick wrote, "I felt at home in Southern California." After the sabbatical, Crick left Cambridge in order to continue working at the Salk Institute. He was also a professor at the University of California, San Diego. He taught himself neuroanatomy and studied many other areas of neuroscience research. It took him several years to disengage from molecular biology because exciting discoveries continued to be made, including the discovery of alternative splicing and the discovery of restriction enzymes, which helped make possible genetic engineering. Eventually, in the 1980s, Crick was able to devote his full attention to his other interest, consciousness. His autobiographical book, "", includes a description of why he left molecular biology and switched to neuroscience.
Upon taking up work in theoretical neuroscience, Crick was struck by several things:
Crick hoped he might aid progress in neuroscience by promoting constructive interactions between specialists from the many different subdisciplines concerned with consciousness. He even collaborated with neurophilosophers such as Patricia Churchland. In 1983, as a result of their studies of computer models of neural networks, Crick and Mitchison proposed that the function of REM sleep is to remove certain modes of interactions in networks of cells in the mammalian cerebral cortex; they called this hypothetical process 'reverse learning' or 'unlearning'. In the final phase of his career, Crick established a collaboration with Christof Koch that lead to publication of a series of articles on consciousness during the period spanning from 1990 to 2005. Crick made the strategic decision to focus his theoretical investigation of consciousness on how the brain generates visual awareness within a few hundred milliseconds of viewing a scene. Crick and Koch proposed that consciousness seems so mysterious because it involves very short-term memory processes that are as yet poorly understood. Crick also published a book describing how neurobiology had reached a mature enough stage so that consciousness could be the subject of a unified effort to study it at the molecular, cellular and behavioural levels. Crick's book "The Astonishing Hypothesis" made the argument that neuroscience now had the tools required to begin a scientific study of how brains produce conscious experiences. Crick was skeptical about the value of computational models of mental function that are not based on details about brain structure and function.
Reactions.
Crick was often described as very talkative, with Watson – in "The Double Helix" – implying lack of modesty. His personality combined with his scientific accomplishments produced many opportunities for Crick to stimulate reactions from others, both inside and outside the scientific world, which was the centre of his intellectual and professional life. Crick spoke rapidly, and rather loudly, and had an infectious and reverberating laugh, and a lively sense of humour. One colleague from the Salk Institute described him as "a brainstorming intellectual powerhouse with a mischievous smile... Francis was never mean-spirited, just incisive. He detected microscopic flaws in logic. In a room full of smart scientists, Francis continually reearned his position as the heavyweight champ."
Eugenics.
Crick occasionally expressed his views on eugenics, usually in private letters. For example, Crick advocated a form of positive eugenics in which wealthy parents would be encouraged to have more children. He once remarked, "In the long run, it is unavoidable that society will begin to worry about the character of the next generation... It is not a subject at the moment which we can tackle easily because people have so many religious beliefs and until we have a more uniform view of ourselves I think it would be risky to try and do anything in the way of eugenics... I would be astonished if, in the next 100 or 200 years, society did not come round to the view that they would have to try to improve the next generation in some extent or one way or another."
Creationism.
Crick was a firm critic of Young Earth creationism. In the 1987 United States Supreme Court case "Edwards v. Aguillard", Crick joined a group of other Nobel laureates who advised, "'Creation-science' simply has no place in the public-school science classroom." Crick was also an advocate for the establishment of Darwin Day as a British national holiday.
Recognition.
In addition to his third share of the 1962 Nobel prize for Physiology or Medicine, he received many awards and honours, including the Royal and Copley medals of the Royal Society (1972 and 1975), and also the Order of Merit (on 27 November 1991); he refused an offer of a CBE in 1963 and later refused an offer of a knighthood, but was often referred to in error as 'Sir Francis Crick' and even on occasions as 'Lord Crick.'
The award of Nobel prizes to John Kendrew and Max Perutz, and to Crick, Watson, and Wilkins was satirised in a short sketch in the BBC TV programme That Was The Week That Was with the Nobel Prizes being referred to as 'The Alfred Nobel Peace Pools.'
Francis Crick Medal and Lecture.
The Francis Crick Medal and Lecture was established in 2003 following an endowment by his former colleague, Sydney Brenner, joint winner of the 2002 Nobel Prize in Physiology and Medicine. The lecture is delivered annually in any field of biological sciences, with preference given to the areas in which Francis Crick himself worked. Importantly, the lectureship is aimed at younger scientists, ideally under 40, or whose career progression corresponds to this age. , Crick lecture have been delivered by Julie Ahringer, Dario Alessi, Ewan Birney, Simon Boulton, Jason Chin, Simon Fisher, Matthew Hurles, Gilean McVean, Duncan Odom, Geraint Rees, Sarah Teichmann and Daniel Wolpert.
Francis Crick Institute.
The Francis Crick Institute is a £660,000,000 biomedical research centre currently under construction, located in London, United Kingdom. The Francis Crick Institute is a partnership between Cancer Research UK, Imperial College London, King's College London, the Medical Research Council, University College London (UCL) and the Wellcome Trust. Once completed in 2016, it will be the largest centre for biomedical research and innovation in Europe.
Francis Crick Graduate Lectures.
The University of Cambridge Graduate School of Biological, Medical and Veterinary Sciences hosts The Francis Crick Graduate Lectures. The first two lectures were by John Gurdon and Tim Hunt.

</doc>
<doc id="11463" url="https://en.wikipedia.org/wiki?curid=11463" title="Francis van Aarssens">
Francis van Aarssens

Baron Francis van Aarssens or Baron François van Aerssen (27 September 1572 - 27 December 1641), from 1611 on lord of Sommelsdijk, was a diplomat and statesman of the United Provinces.
Biography.
He was born in Brussels, the son of Cornelis van Aarsens, also a statesman. His talents commended him to the notice of Advocate Johan van Oldenbarnevelt, who sent him, at the age of 26 years, as a diplomatic agent of the states-general to the court of France. He took a considerable part in the negotiations of the Twelve Years' Truce in 1609.
His conduct of affairs having displeased the French king, he was recalled from his post by Oldenbarneveldt in 1616. Such was the hatred he henceforth conceived against his former benefactor, that he did his very utmost to effect Oldebarneveldt's ruin. He was one of the packed court of judges who in 1619 condemned the aged statesman to death. For his share in this judicial murder a deep stain rests on the memory of Aarssens.
He afterwards became the confidential counsellor of Maurice, Prince of Orange, and afterwards of Frederick Henry, Prince of Orange, in their conduct of the foreign affairs of the republic. He was sent on special embassies to Venice, Germany and England, and displayed so much diplomatic skill and finesse that Cardinal Richelieu ranked him among the three greatest politicians of his time. He died, aged 69, in The Hague.

</doc>
<doc id="11464" url="https://en.wikipedia.org/wiki?curid=11464" title="Frigate">
Frigate

A frigate is any of several types of warship, the term having been used for ships of various sizes and roles over the last few centuries.
In the 17th century, this term was used for any warship built for speed and maneuverability, the description often used being "frigate-built". These could be warships carrying their principal batteries of carriage-mounted guns on a single deck or on two decks (with further smaller carriage-mounted guns usually carried on the forecastle and quarterdeck of the vessel). The term was generally used for ships too small to stand in the line of battle, although early line-of-battle ships were frequently referred to as frigates when they were built for speed.
In the 18th century, the term referred to ships that were usually as long as a ship of the line and were square-rigged on all three masts (full rigged), but were faster and with lighter armament, used for patrolling and escort. In the definition adopted by the British Admiralty, they were rated ships of at least 28 guns, carrying their principal armaments upon a single continuous deck — the upper deck — while ships of the line possessed two or more continuous decks bearing batteries of guns.
In the late 19th century (beginning about 1858 with the construction of prototypes by the British and French navies), the armoured frigate was a type of ironclad warship that for a time was the most powerful type of vessel afloat. The term "frigate" was used because such ships still mounted their principal armaments on a single continuous upper deck. The later 19th-century battleship thus developed from the frigate rather than from the ship of the line.
In modern navies, frigates are used to protect other warships and merchant-marine ships, especially as anti-submarine warfare (ASW) combatants for amphibious expeditionary forces, underway replenishment groups, and merchant convoys. Ship classes dubbed "frigates" have also more closely resembled corvettes, destroyers, cruisers, and even battleships. The rank "frigate captain" derives from the name of this type of ship.
Age of sail.
Origins.
The term "frigate" (Italian: "fregata"; Spanish/Catalan/Portuguese/Sicilian: "fragata"; Dutch: "fregat"; French: "fregate") originated in the Mediterranean in the late 15th century, referring to a lighter galleass type ship with oars, sails and a light armament, built for speed and maneuverability. The etymology of the word is unknown, although it may have originated as a corruption of "", a Latin word for an open vessel with no lower deck. "Aphractus" was, in turn, derived from the Ancient Greek phrase ἄφρακτος ναῦς ("aphraktos naus"), or "undefended ship".
In 1583, during the Eighty Years' War, Habsburg Spain recovered the Southern Netherlands from the rebellious Dutch. This soon led to the occupied ports being used as bases for privateers, the Dunkirkers, to attack the shipping of the Dutch and their allies. To achieve this they developed small, maneuverable, sail-only vessels that came to be referred to as frigates. The success of these Dunkirker vessels influenced the ship design of the Dutch and other navies contending with them but because most regular navies required ships of greater endurance than the Dunkirker frigates could provide, the term was soon applied less exclusively to any relatively fast and elegant sail-only war ship. In French, the term "frigate" became a verb, meaning 'to build long and low', and an adjective, adding further confusion. Even the huge English could be described as "a delicate frigate" by a contemporary after her upper decks were reduced in 1651.
The navy of the Dutch Republic was the first navy to build the larger ocean-going frigates. The Dutch navy had three principal tasks in the struggle against Spain: to protect Dutch merchant ships at sea, to blockade the ports of Spanish-held Flanders to damage trade and halt enemy privateering, and to fight the Spanish fleet and prevent troop landings. The first two tasks required speed, shallowness of draft for the shallow waters around the Netherlands, and the ability to carry sufficient supplies to maintain a blockade. The third task required heavy armament, sufficient to fight against the Spanish fleet. The first of these larger battle-capable frigates were built around 1600 at Hoorn in Holland. By the later stages of the Eighty Years War the Dutch had switched entirely from the heavier ships still used by the English and Spanish to the lighter frigates, carrying around 40 guns and weighing around 300 tons.
The effectiveness of the Dutch frigates became most visible in the Battle of the Downs in 1639, encouraging most other navies, especially the English, to adopt similar designs.
The fleets built by the Commonwealth of England in the 1650s generally consisted of ships described as "frigates", the largest of which were two-decker 'great frigates' of the third rate. Carrying 60 guns, these vessels were as big and capable as 'great ships' of the time; however, most other frigates at the time were used as 'cruisers': independent fast ships. The term "frigate" implied a long hull design, which relates directly to speed (see hull speed) and also, in turn, helped the development of the broadside tactic in naval warfare.
At this time, a further design evolved, reintroducing oars to create the galley frigate such as of 1676 which was rated as a 32-gun fifth rate but also had a bank of 40 oars set below the upper deck which could be used to propel the ship in the absence of a favourable wind.
In Danish, the word "fregat" is often applied to warships carrying as few as 16 guns, such as which the British classified as a sloop.
Under the rating system of the Royal Navy, by the middle of the 18th century, the term "frigate" was technically restricted to single-decked ships of the fifth rate, though small 28-gun frigates were classed as sixth rate.
Classic design.
The classic sailing frigate, well-known today for its role in the Napoleonic wars, can be traced back to French developments in the second quarter of the 18th century. The French-built "Médée" of 1740 is often regarded as the first example of this type. These ships were square-rigged and carried all their main guns on a single continuous upper deck. The lower deck, known as the "gun deck", now carried no armament, and functioned as a "berth deck" where the crew lived, and was in fact placed below the waterline of the new frigates.
A total of fifty-nine French sailing frigates were built between 1777 and 1790, with a standard design averaging a hull length of and an average draught of . The new frigates recorded sailing speeds of up to , significantly faster than their predecessor vessels. They were able to fight with all their guns when the seas were so rough that comparable two-deckers had to close the gun-ports on their lower decks (see the Action of 13 January 1797, for an example when this was decisive). Like the larger 74 which was developed at the same time, the new frigates sailed well and were good fighting vessels due to a combination of long hulls and low upperworks compared to vessels of comparable size and firepower.
The Royal Navy captured a handful of the new French frigates during the War of the Austrian Succession (1740–1748) and were impressed by them, particularly for their inshore handling capabilities. They soon built copies and started to adapt the type to their own needs, setting the standard for other frigates as the leading naval power. The first British frigates carried 28 guns including an upper deck battery of twenty-four 9-pounder guns (the remaining four smaller guns were carried on the quarter deck) but soon developed into fifth-rate ships of 32 or 36 guns including an upper deck battery of twenty-six 12-pounder guns, with the remaining six or ten smaller guns carried on the quarter deck and forecastle. From around 1778, a larger "heavy" frigate was developed with a main battery of twenty-six or twenty-eight 18-pounder guns (again with the remaining ten smaller guns carried on the quarter deck and forecastle).
Both British and American frigates could (and usually did) additionally carry smaller carriage-mounted guns on their quarter decks and forecastles (the superstructures above the upper deck). Technically, rated ships with fewer than 28 guns could not be classed as frigates but as "post ships"; however, in common parlance most post ships were often described as "frigates", the same casual misuse of the term being extended to smaller two-decked ships that were too small to stand in the line of battle.
Royal Navy frigates of the late 18th century included the 1780-vintage "Perseverance" class, which measured around 900 tons burthen and carried 36 guns; this successful class was followed by numerous other classes that measured over 1,000 tons burthen and carried 38 guns.
Heavy frigates.
In 1797, three of the United States Navy's first six major ships were rated as 44-gun frigates (or "super-frigates"), which operationally carried fifty-six to sixty 24-pounder long guns and 32-pounder or 42-pounder carronades on two decks; by all regards they were exceptionally powerful and tough. These ships were so well-armed that they were often regarded as equal to ships of the line, and after a series of losses at the outbreak of the War of 1812, Royal Navy fighting instructions ordered British frigates (usually of 38 guns or less) to never engage American frigates at any less than a 2:1 advantage. , preserved as a museum ship by the US Navy, is the oldest commissioned warship afloat, and is a surviving example of a frigate from the Age of Sail. "Constitution" and her sister ships and were created in a response to deal with the Barbary Coast pirates and in conjunction with the Naval Act of 1794. The three big frigates, when built, had a distinctive building pattern which minimised "hogging" (in which the centre of the keel rises while both ends drop) and improves hydrodynamic efficiency.
The hull was designed so that all the weight from the guns was upon the keel itself. Joshua Humphreys proposed that only live oak, a tree that grew only in America, should be used to build these ships. The method was to use diagonal riders, eight on each side that sat at a 45 degree angle. These beams of live oak were about two feet wide and around a foot thick and helped to maintain the shape of the hull, serving also to reduce flexibility and to minimize impacts. These ideas were considered revolutionary in the late 18th and early 19th century. A three-layer method was used in which the planks along the sides of the hull were laid horizontally across the ribs, making a crossing or checker board pattern. The sides of the ship could be as thick as 25 inches, and were able to absorb substantial damage. The strength of this braced construction earned USS "Constitution" the nickname "Old Ironsides".
Role.
Frigates were perhaps the hardest-worked of warship types during the Age of Sail. While smaller than a ship-of-the-line, they were formidable opponents for the large numbers of sloops and gunboats, not to mention privateers or merchantmen. Able to carry six months' stores, they had very long range; and vessels larger than frigates were considered too valuable to operate independently.
Frigates scouted for the fleet, went on commerce-raiding missions and patrols, and conveyed messages and dignitaries. Usually, frigates would fight in small numbers or singly against other frigates. They would avoid contact with ships-of-the-line; even in the midst of a fleet engagement it was bad etiquette for a ship of the line to fire on an enemy frigate which had not fired first. Frigates were involved in fleet battles, often as "repeating frigates". In the smoke and confusion of battle, signals made by the fleet commander, whose flagship might be in the thick of the fighting, might be missed by the other ships of the fleet. Frigates were therefore stationed to windward or leeward of the main line of battle, and had to maintain a clear line of sight to the commander's flagship. Signals from the flagship were then repeated by the frigates, which themselves standing out of the line and clear from the smoke and disorder of battle, could be more easily seen by the other ships of the fleet. If damage or loss of masts prevented the flagship from making clear conventional signals, the repeating frigates could interpret them and hoist their own in the correct manner, passing on the commander's instructions clearly.
For officers in the Royal Navy, a frigate was a desirable posting. Frigates often saw action, which meant a greater chance of glory, promotion, and prize money.
Unlike larger ships that were placed in ordinary, frigates were kept in service in peacetime as a cost-saving measure and to provide experience to frigate captains and officers which would be useful in wartime. Frigates could also carry marines for boarding enemy ships or for operations on shore; in 1832, the frigate landed a party of 282 sailors and Marines ashore in the US Navy's first Sumatran expedition.
Common armament was one gundeck with 24–30 long guns, from 8- to 24-pounders (3.6 to 11 kg), with up to a dozen light guns or carronades on the quarterdeck and forecastle above.
Frigates remained a crucial element of navies until the mid-19th century. The first ironclads were classified as "frigates" because of the number of guns they carried. However, terminology changed as iron and steam became the norm, and the role of the frigate was assumed first by the protected cruiser and then by the light cruiser.
Frigates are often the vessel of choice in historical naval novels due to their relative freedom compared to ships of the line (kept for fleet actions) and smaller vessels (generally assigned to a home port and less widely ranging). For example, the Patrick O'Brian Aubrey–Maturin series, C. S. Forester's Horatio Hornblower series and Alexander Kent's Richard Bolitho series. The motion picture "" features a reconstructed historic frigate, HMS "Rose", to depict Aubrey's frigate HMS "Surprise".
Age of steam.
Vessels classed as frigates continued to play a great role in navies with the adoption of steam power in the 19th century. In the 1830s, navies experimented with large paddle steamers equipped with large guns mounted on one deck, which were termed "paddle frigates".
From the mid-1840s on, frigates which more closely resembled the traditional sailing frigate were built with steam engines and screw propellers. These "screw frigates", built first of wood and later of iron, continued to perform the traditional role of the frigate until late in the 19th century.
Armoured frigate.
From 1859, armour was added to ships based on existing frigate and ship of the line designs. The additional weight of the armour on these first ironclad warships meant that they could have only one gun deck, and they were technically frigates, even though they were more powerful than existing ships-of-the-line and occupied the same strategic role. The phrase "armoured frigate" remained in use for some time to denote a sail-equipped, broadside-firing type of ironclad.
After 1875, the term "frigate" fell out of use. Vessels with armoured sides were designated as "battleships" or "armoured cruisers", while "protected cruisers" only possessed an armoured deck, and unarmoured vessels, including frigates and sloops, were classified as "unprotected cruisers".
Second World War.
Modern frigates are related to earlier frigates only by name. The term "frigate" was readopted during the Second World War by the British Royal Navy to describe an anti-submarine escort vessel that was larger than a corvette, smaller than a destroyer, and about equal in size and capability to the American destroyer escort. Anti-submarine escorts had previously been classified as sloops by the Royal Navy, and the s of 1939–1945 were as large as the new types of frigate, and more heavily armed. Twenty-two of these were reclassified as frigates after the war, as were the remaining 24 smaller s.
The frigate was introduced to remedy some of the shortcomings inherent in the corvette design: limited armament, a hull form not suited to open-ocean work, a single shaft which limited speed and maneuverability, and a lack of range. The frigate was designed and built to the same mercantile construction standards (scantlings) as the corvette, allowing manufacture by yards unused to warship construction. The first frigates of the (1941) were essentially two sets of corvette machinery in one larger hull, armed with the latest Hedgehog anti-submarine weapon.
The frigate possessed less offensive firepower and speed than a destroyer, but such qualities were not required for anti-submarine warfare. Submarines were slow while submerged, and ASDIC sets did not operate effectively at speeds of over . Rather, the frigate was an austere and weatherly vessel suitable for mass-construction and fitted with the latest innovations in anti-submarine warfare. As the frigate was intended purely for convoy duties, and not to deploy with the fleet, it had limited range and speed.
The contemporary German "Flottenbegleiter" ("fleet escorts"), also known as "F-Boats", were essentially frigates. They were based on a pre-war "Oberkommando der Marine" concept of vessels which could fill roles such as fast minesweeper, minelayer, merchant escort and anti-submarine vessel. Because of the Treaty of Versailles their displacement was officially limited to 600 tons, although in reality they exceeded this by about 100 tons. F-boats had two stacks and two 105 mm gun turrets. The design was flawed because of its narrow beam, sharp bow and unreliable high pressure steam turbines. F-boats were succeeded in operational duties by Type 35 and Elbing class torpedo boats. "Flottenbegleiter" remained in service as advanced training vessels.
It was not until the Royal Navy's of 1944 that a British design classified as a "frigate" was produced for fleet use, although it still suffered from limited speed. These anti-aircraft frigates, built on incomplete hulls, were similar to the United States Navy's destroyer escorts (DE), although the latter had greater speed and offensive armament to better suit them to fleet deployments. The destroyer escort concept came from design studies by the General Board of the United States Navy in 1940, as modified by requirements established by a British commission in 1941 prior to the American entry into the war, for deep-water escorts. The American-built destroyer escorts serving in the British Royal Navy were rated as Captain-class frigates. The U.S. Navy's two Canadian-built and 96 British-influenced, American-built frigates that followed originally were classified as "patrol gunboats" (PG) in the U.S. Navy but on 15 April 1943 were all reclassified as patrol frigates (PF).
Moored on the Thames Embankment in London are two surviving Royal Navy anti-submarine sloops, which are the predecessors of the Second World War frigates:
Contemporary.
Guided-missile role.
The introduction of the surface-to-air missile after the Second World War made relatively small ships effective for anti-aircraft warfare: the "guided missile frigate." In the USN, these vessels were called "ocean escorts" and designated "DE" or "DEG" until 1975 – a holdover from the Second World War destroyer escort or "DE". The Royal Canadian Navy and British Royal Navy maintained the use of the term "frigate"; likewise, the French Navy refers to missile-equipped ship, up to cruiser-sized ships, by the name of "frégate", while smaller units are named "aviso". The Soviet Navy used the term "guard-ship" ("сторожевой корабль").
From the 1950s to the 1970s, the United States Navy commissioned ships classed as guided missile frigates which were actually anti-aircraft warfare cruisers built on destroyer-style hulls. Some of these ships—the , , and es—were nuclear-powered. These "frigates" were roughly mid-way in size between cruisers and destroyers. This was similar to the use of the term "frigate" during the age of sail during which it referred to a medium-sized warship, but it was inconsistent with conventions used by other contemporary navies which regarded frigates as being smaller than destroyers. During the 1975 ship reclassification, the large American frigates were redesignated as cruisers or destroyers, while ocean escorts (the American classification for ships smaller than destroyers) were renamed as frigates. It was in the late 1970s that the US Navy introduced the 51-ship "Oliver Hazard Perry"-class guided missile frigates (FFG), the last of which was decommissioned in 2015.
One of the most successful post-1945 designs was the British , which was used by several navies. Laid down in 1959, the "Leander"s were based on the previous Type 12 anti-submarine frigate but equipped for anti-aircraft use as well. They were used by the UK into the 1990s, at which point some were sold onto other navies. The "Leander" design, or improved versions of it, were licence-built for other navies.
Nearly all modern frigates are equipped with some form of offensive or defensive missiles, and as such are rated as guided-missile frigates (FFG). Improvements in surface-to-air missiles (e.g., the Eurosam Aster 15) allow modern guided-missile frigates to form the core of many modern navies and to be used as a fleet defence platform, without the need for specialised anti-air warfare frigates.
Other uses.
The Royal Navy Type 61 "Salisbury" class were "air direction" frigates equipped to track aircraft. To this end they had reduced armament compared to the Type 41 "Leopard"-class air-defence frigates built on the same hull.
Multi-role frigates like the MEKO 200, and es are designed for navies needing warships deployed in a variety of situations that a general frigate class would not be able to fulfill and not requiring the need for deploying destroyers.
Anti-submarine role.
At the opposite end of the spectrum, some frigates are specialised for anti-submarine warfare. Increasing submarine speeds towards the end of the Second World War (see German Type XXI submarine) greatly reduced the margin of speed superiority of frigate over submarine. The frigate could no longer be slow and powered by mercantile machinery and consequently postwar frigates, such as the "Whitby" class, were faster.
Such ships carry improved sonar equipment, such as the variable depth sonar or towed array, and specialised weapons such as torpedoes, forward-throwing weapons such as Limbo and missile-carried anti-submarine torpedoes such as ASROC or Ikara. Surface-to-air missiles such as Sea Sparrow and surface-to-surface missiles such as Exocet give them defensive and offensive capabilities. The Royal Navy's original Type 22 frigate is an example of a specialised anti-submarine warfare frigate.
Especially for anti-submarine warfare, most modern frigates have a landing deck and hangar aft to operate helicopters, eliminating the need for the frigate to close with unknown sub-surface threats, and using fast helicopters to attack nuclear submarines which may be faster than surface warships. For this task the helicopter is equipped with sensors such as sonobuoys, wire-mounted dipping sonar and magnetic anomaly detectors to identify possible threats, and torpedoes or depth-charges to attack them.
With their onboard radar helicopters can also be used to reconnoitre over-the-horizon targets and, if equipped with anti-ship missiles such as Penguin or Sea Skua, to attack them. The helicopter is also invaluable for search and rescue operation and has largely replaced the use of small boats or the jackstay rig for such duties as transferring personnel, mail and cargo between ships or to shore. With helicopters these tasks can be accomplished faster and less dangerously, and without the need for the frigate to slow down or change course.
Further developments.
Stealth technology has been introduced in modern frigate design. Frigate shapes are designed to offer a minimal radar cross section, which also lends them good air penetration; the maneuverability of these frigates has been compared to that of sailing ships. Examples are the French with the Aster 15 missile for anti-missile capabilities, the German and s, the Turkish type frigates with the MK-41 VLS, and the Indian and es with the Brahmos missile system.
The modern French Navy applies the term first-class frigate and second-class frigate to both destroyers and frigates in service. Pennant numbers remain divided between F-series numbers for those ships internationally recognised as frigates and D-series pennant numbers for those more traditionally recognised as destroyers. This can result in some confusion as certain classes are referred to as frigates in French service while similar ships in other navies are referred to as destroyers. This also results in some recent classes of French ships being among the largest in the world to carry the rating of frigate.
In the German Navy, frigates were used to replace aging destroyers; however in size and role the new German frigates exceed the former class of destroyers. The future German F125-class frigate will be the largest class of frigates worldwide with a displacement of more than 7,200 tons. The same was done in the Spanish Navy, which went ahead with the deployment of the first Aegis frigates, the s.
Littoral Combat Ship (LCS).
Some new classes of ships similar to corvettes are optimized for high-speed deployment and combat with small craft rather than combat between equal opponents; an example is the U.S. Littoral Combat Ship (LCS). As of mid-2015, all s in the United States Navy were to decommissioned, and their role partially being assumed by the new LCS. While the LCS class ships are smaller than the frigate class they will replace, they offer a similar degree of weaponry while requiring less than half the crew complement and offering a top speed of over . A major advantage for the LCS ships is that they are designed around specific mission modules allowing them to fulfill a variety of roles. The modular system also allows for most upgrades to be performed ashore and installed later into the ship, keeping the ships available for deployment for the maximum time.
The latest U.S. deactivation plans will retire all "Oliver Hazard Perry"-class frigates by October 2015, which will be the first time that the U.S. Navy has been without a frigate class of ships since 1943 (technically is rated as a frigate and is still in commission, but does not count towards Navy force levels).
The remaining 20 LCSs to be acquired from 2019 and onwards that will be enhanced will be designated as frigates, and existing ships given modifications may also have their classification changed to "FF" as well.
See also.
Lists.
Note that Algerian, Tripolitan and Tunisian sail frigates are listed under Turkey. All Italian city-state frigates are listed under Italy.

</doc>
<doc id="11466" url="https://en.wikipedia.org/wiki?curid=11466" title="Francisco Franco">
Francisco Franco

Francisco Paulino Hermenegildo Teódulo Franco Bahamonde (; 4 December 1892 – 20 November 1975) was a Spanish general and the Caudillo of Spain from 1936/1939 until his death in 1975. Coming from a military family background, he became the youngest general in Spain and one of the youngest generals in Europe in the 1920s.
As a conservative monarchist, he was shocked when the monarchy was removed and replaced with a republic in 1931. With the 1936 elections, the conservative Spanish Confederation of Autonomous Right-wing Groups lost by a narrow margin and the leftist Popular Front came to power. Looking to overthrow the republic, Franco and other generals staged a partially successful coup, which started the Spanish Civil War. With the death of the other generals, Franco quickly became his faction's only leader.
Franco's ultranationalist faction received military support from several fascist groups, especially Nazi Germany and the Kingdom of Italy, while the Republican side was supported by Spanish communists and anarchists. It also received help from the Soviet Union, Mexico, and the International Brigades. Leaving half a million dead, the war was eventually won by Franco in 1939. He established an autocratic dictatorship, which he defined as a totalitarian state. Franco proclaimed himself head of state and government under the title El Caudillo (the Chief), a term similar to Il Duce (Italian) and Der Führer (German). During the Francoist regime, only one political party was legal: a merger of the monarchist party and the fascist party that helped him during the war, FET y de las JONS.
Franco led a series of politically-motivated violent acts, including but not limited to concentration camps, forced labor and executions, mostly against political and ideological enemies, causing an estimated 200,000 to 400,000 deaths, depending on how death in the more than 190 concentration camps is considered. Franco's Spain maintained an official policy of neutrality during World War II, with the exception of the Blue Division that fought for Germany against the Soviet Union. By the 1950s, the nature of his regime changed from an extreme form of dictatorship to a semi-pluralist authoritarian system. During the Cold War Franco appeared as one of the world's foremost anticommunist figures; consequently his regime was assisted by the United States, and was asked to join the United Nations and come under NATO's protection. By the 1960s Spain saw progressive economic development and some democratic improvements.
After a 36-year rule, Franco died in 1975. He restored the monarchy before his death, which made King Juan Carlos I his successor, who led the Spanish transition to democracy. After a referendum, a new constitution was adopted, which effectively created a democratic regime in Spain.
Early life.
Franco was born at half past noon on 4 December 1892 at 108 Calle Frutos Saavedra in Ferrol, Galicia. He was baptised thirteen days later at the military church of San Francisco, with the baptismal name Francisco Paulino Hermenegildo Teódulo; Francisco for his paternal grandfather, Paulino for his godfather, Hermenegildo for his maternal grandmother and godmother, and Teódulo for the saint day of his birth.
His father was of Andalusian ancestry. After relocating to Galicia, the family were strongly involved in the Spanish Navy, and over the span of two centuries produced naval officers for six uninterrupted generations, down to Franco's father Nicolás Franco y Salgado Araújo (22 November 1855 – 22 February 1942).
His mother was María del Pilar Bahamonde y Pardo de Andrade (1865 – 28 February 1934) and she was an upper middle-class Roman Catholic. His parents married in 1890. The young Franco spent much of his childhood with his two brothers, Nicolás (Ferrol, 1891–1977), later a naval officer and diplomat who in time was married to María Isabel Pascual del Pobil y Ravello, and Ramón, and his two sisters, María del Pilar (Ferrol, 1894 – Madrid, 1989), later wife of Alonso Jaráiz y Jeréz, and María de la Paz (Ferrol, 1899 – Ferrol, 1903).
Military career.
Rif War and advancement through the ranks.
Francisco was to follow his father into the Navy, but as a result of the Spanish–American War the country lost much of its navy as well as most of its colonies. Not needing any more officers, the Naval Academy admitted no new entrants from 1906 to 1913. To his father's chagrin, Francisco decided to try the Spanish Army. In 1907, he entered the Infantry Academy in Toledo, graduating in 1910 as a lieutenant. Two years later, he obtained a commission to Morocco. Spanish efforts to occupy their new African protectorate provoked the protracted Rif War (from 1909 to 1927) with native Moroccans. Their tactics resulted in heavy losses among Spanish military officers, and also provided an opportunity to earn promotion through merit. It was said that officers would receive either "la caja o la faja" (a coffin or a general's sash). Franco quickly gained a reputation as a good officer. In 1913, Franco transferred into the newly formed regulares: Moroccan colonial troops with Spanish officers, who acted as shock troops. This transfer into a perilous role may have been decided because Franco failed to win the hand of his first love, Sofía Subirán.
In 1916, aged 23 and already a captain, he was shot by enemy machine gun fire. He was badly wounded in the abdomen, specifically the liver, in a skirmish at "El Biutz" and possibly lost a testicle. The physicians of the battle later concluded that his intestines were spared because he inhaled when he was shot. His survival marked him permanently in the eyes of the native troops as a man of "baraka" (good luck). He was recommended for Spain's highest honor for gallantry, the coveted "Cruz Laureada de San Fernando", but instead received the "Cross of Maria Cristina, First Class". With that he was promoted to major at the end of February 1917. This made him the youngest major in the Spanish army. From 1917 to 1920, he served in Spain. In 1920, Lieutenant Colonel José Millán Astray, a histrionic but charismatic officer, founded the Spanish Foreign Legion, on similar lines to the French Foreign Legion. Franco became the Legion's second-in-command and returned to Africa. On 24 July 1921, the poorly commanded and overextended Spanish Army suffered a crushing defeat at Annual from Rif tribesmen led by the Abd el-Krim brothers. The Legion and supporting units relieved the Spanish enclave of Melilla after a three-day forced march led by Franco. In 1923, by now a lieutenant colonel, he was made commander of the Legion.
That year, he married María del Carmen Polo y Martínez-Valdès. Three years later the couple had a daughter, María del Carmen. Following his honeymoon Franco was summoned to Madrid to be presented to King Alfonso XIII. This and other occasions of royal attention would mark him during the Republic as a monarchical officer. Promoted to colonel, Franco led the first wave of troops ashore at Al Hoceima in 1925. This landing in the heartland of Abd el-Krim's tribe, combined with the French invasion from the south, spelled the beginning of the end for the short-lived Republic of the Rif. Franco's recognition eventually caught up with him and he was promoted to brigadier general on 3 February 1926. This made him the youngest general in Spain, and perhaps the youngest general of Europe. In 1928 Franco was appointed director of the newly created General Military Academy of Zaragoza, a new college for all army cadets, replacing the former separate institutions for young men seeking to become officers in infantry, cavalry, artillery, and other branches of the army. Franco was removed as Director of the Zaragoza Military Academy in 1931; about 95% of his former Zaragoza cadets later came to side with him in the Civil War.
During the Second Spanish Republic.
With the fall of the monarchy in 1931, Franco did not take any notable stand. But the closing of the Academy in June by War Minister Manuel Azaña provoked his first clash with the Spanish Republic. Azaña found Franco's farewell speech to the cadets insulting. Franco stressed in his speech the Republic's need for discipline and respect. For six months Franco was without a post and under surveillance.
Franco was a subscriber to the journal of Acción Española, an ultra-right wing monarchist organization, and a firm believer in the Jewish-Masonic-Bolshevik conspiracy or "contubernio" (filthy cohabitation)—'one of Franco's favourite words'; a conspiracy in which Jews, Freemasons and leftists allegedly sought the destruction of Christian Europe, with Spain the principal target.
On 5 February 1932 he was given a command in A Coruña. Franco avoided involvement in José Sanjurjo's attempted coup that year, and even wrote a hostile letter to Sanjurjo expressing his anger over the attempt. As a side result of Azaña's military reform, in January 1933, Franco was relegated from the first to the 24th in the list of brigadiers; the same year, on 17 February, he was given the military command of the Balearic Islands: a post above his rank.
New elections held in October 1933 resulted in a center-right majority. In opposition to this government, a revolutionary communist/anarchist movement broke out on 5 October 1934. This uprising was rapidly quelled in most of the country, but gained a stronghold in Asturias, with the support of the miners' unions. Franco, already General of Division and aide to the war minister, Diego Hidalgo, was put in command of the operations directed to suppress the insurgency. Troops of the Spanish Army of Africa carried this out, with General Eduardo López Ochoa as commander in the field. After two weeks of heavy fighting (and a death toll estimated between 1,200 and 2,000), the rebellion was suppressed.
The insurgency in Asturias (see Asturian miners' strike of 1934) sharpened the antagonism between Left and Right. Franco and López Ochoa (who, prior to the campaign in Asturias, had been seen as a left-leaning officer) emerged as officers prepared to use 'troops against Spanish civilians as if they were a foreign enemy'. Franco described the rebellion to a journalist in Oviedo as, 'a frontier war and its fronts are socialism, communism and whatever attacks civilization in order to replace it with barbarism.' Though the colonial units sent to the north by the government at Franco's recommendation consisted of the Spanish Foreign Legion and the Moroccan Regulares Indigenas, the right wing press portrayed the Asturian rebels as lackeys of a foreign Jewish-Bolshevik conspiracy. At the start of the Civil War, López Ochoa was assassinated. Some time after these events, Franco was briefly commander-in-chief of the Army of Africa (from 15 February onwards), and from 19 May 1935 on, Chief of the General Staff.
General election of 1936.
After the ruling centre-right coalition collapsed amid the Straperlo corruption scandal, new elections were scheduled. Two wide coalitions formed: the Popular Front on the left, ranging from Republican Union Party to Communists, and the Frente Nacional on the right, ranging from the center radicals to the conservative Carlists. On 16 February 1936, the left won by a narrow margin. Growing political bitterness surfaced again. The government and its supporters, the Popular Front, had launched a campaign against the Opposition whom they accused of plotting against the Republic. According to the right-wing opposition, the real enemies of the Republic were not on the Right but on the Left; Spain was in imminent danger of falling under a "Communist dictatorship", and therefore by fighting the democratically elected Popular Front they, the opposition, were merely doing their duty in defence of law and order and of the freedom and the fundamental rights of the Spanish people.
On 23 February Franco was sent to the Canary Islands to serve as the islands' military commander, an appointment perceived by him as a "destierro" (banishment). Meanwhile, a conspiracy led by Emilio Mola was taking shape. In June, Franco was contacted and a secret meeting was held within the forest of La Esperanza on Tenerife to discuss starting a military coup. (An obelisk commemorating this historic meeting was erected at the site in a clearing at Las Raíces.)
Outwardly Franco maintained an ambiguous attitude almost until July. On 23 June 1936 he wrote to the head of the government, Casares Quiroga, offering to quell the discontent in the Spanish Republican Army, but received no reply. The other rebels were determined to go ahead "con Paquito o sin Paquito" (with "Paquito" or without "Paquito"; "Paquito" being a diminutive of "Paco", which in turn is short for "Francisco"), as it was put by José Sanjurjo, the honorary leader of the military uprising. After various postponements, 18 July was fixed as the date of the uprising. The situation reached a point of no return and, as presented to Franco by Mola, the coup was unavoidable and he had to choose a side. He decided to join the rebels and was given the task of commanding the Army of Africa. A privately owned DH 89 De Havilland Dragon Rapide, flown by two British MI6 agents, Cecil Bebb and Hugh Pollard, was chartered in England on 11 July to take Franco to Africa.
The assassination of the right-wing opposition leader José Calvo Sotelo by government police troops, possibly in retaliation for the murder of José Castillo, precipitated the uprising. On 17 July one day earlier than planned, the African Army rebelled, detaining their commanders. On 18 July, Franco published a manifesto and left for Africa, where he arrived the next day to take command.
A week later the rebels, who soon called themselves the "Nationalists", controlled a third of Spain; however most naval units remained under control of the Republican loyalist forces, which left Franco isolated. The coup had failed in the attempt to bring a swift victory, but the Spanish Civil War had begun.
From the Spanish Civil War to World War II.
The Spanish Civil War began in July 1936 and officially ended with Franco's victory in April 1939, leaving 190,000 to 500,000 dead. Despite the Non-Intervention Agreement of August 1936, the war was marked by foreign intervention on behalf of both sides, leading to international repercussions. The nationalist side was supported by Fascist Italy, which sent the "Corpo Truppe Volontarie", and later by Nazi Germany, which assisted with the Condor Legion. They were opposed by the Soviet Union and communist, socialists and anarchists within Spain. The United Kingdom and France strictly adhered to the arms embargo, provoking dissensions within the French Popular Front coalition led by Léon Blum, but the Republican side was nonetheless supported by the Soviet Union and volunteers fighting in the International Brigades (see for example Ken Loach's "Land and Freedom").
Because Adolf Hitler and Joseph Stalin used the war as a testing ground for modern warfare, some historians, such as Ernst Nolte, have considered the Spanish Civil War, along with World War II, part of a European Civil War lasting from 1936 to 1945 and characterized mainly as a left/right ideological conflict. This interpretation has not found acceptance among most historians, who consider the Spanish Civil War and Second World War to be two distinct conflicts. Among other things, they point to the political heterogeneity on both sides ("See Spanish Civil War: other factions") and criticize a monolithic interpretation which overlooks the local nuances of Spanish history.
The first months.
Following the 18 July 1936 "pronunciamiento", Franco assumed the leadership of the 30,000 soldiers of the Spanish Army of Africa. The first days of the insurgency were marked with a serious need to secure control over the Spanish Moroccan Protectorate. On one side, Franco had to win the support of the natives and their (nominal) authorities, and, on the other, had to ensure his control over the army. His method was the summary execution of some 200 senior officers loyal to the Republic (one of them his own cousin). His loyal bodyguard was shot by Manuel Blanco. Franco's first problem was how to move his troops to the Iberian Peninsula, since most units of the Navy had remained in control of the Republic and were blocking the Strait of Gibraltar. He requested help from Benito Mussolini, who responded with an unconditional offer of arms and planes; in Germany Wilhelm Canaris, the head of the "Abwehr" military intelligence, persuaded Hitler to support the Nationalists. From 20 July onward Franco was able, with a small group of 22 mainly German Junkers Ju 52 aircraft, to initiate an air bridge to Seville, where his troops helped to ensure the rebel control of the city. Through representatives, he started to negotiate with the United Kingdom, Germany, and Italy for more military support, and above all for more aircraft. Negotiations were successful with the last two on 25 July and aircraft began to arrive in Tetouan on 2 August. On 5 August Franco was able to break the blockade with the newly arrived air support, successfully deploying a ship convoy with some 2,000 soldiers.
In early August, the situation in western Andalusia was stable enough to allow him to organize a column (some 15,000 men at its height), under the command of then Lieutenant-Colonel Juan Yagüe, which would march through Extremadura towards Madrid. On 11 August Mérida was taken, and on 15 August Badajoz, thus joining both nationalist-controlled areas. Additionally, Mussolini ordered a voluntary army, the "Corpo Truppe Volontarie" (CTV) of some 12,000 Italians of fully motorized units to Seville and Hitler added to them a professional squadron from the Luftwaffe (2JG/88) with about 24 planes. All these planes had the Nationalist Spanish insignia painted on them, but were flown by Italian and German nationals. The backbone of Franco's aviation in those days were the Italian SM.79 and SM.81 bombers, the biplane Fiat CR.32 fighter and the German Junkers Ju 52 cargo-bomber and the Heinkel He 51 biplane fighter.
On 21 September, with the head of the column at the town of Maqueda (some 80 km away from Madrid), Franco ordered a detour to free the besieged garrison at the Alcázar of Toledo, which was achieved on 27 September. This controversial decision gave the Popular Front time to strengthen its defences in Madrid and hold the city that year, but the holding of Alcázar was an important morale and propaganda success for the Nationalists.
Rise to power.
The designated leader of the uprising, General José Sanjurjo, died on 20 July 1936 in a plane crash. Therefore, in the nationalist zone, "Political life ceased." Initially, only military command mattered; this was divided into regional commands (Emilio Mola in the North, Gonzalo Queipo de Llano in Seville commanding Andalusia, Franco with an independent command and Miguel Cabanellas in Zaragoza commanding Aragon). The Spanish Army of Morocco itself was split into two columns, one commanded by General Juan Yagüe and the other commanded by Colonel José Varela.
From 24 July a coordinating "junta" was established, based at Burgos. Nominally led by Cabanellas, as the most senior general, it initially included Mola, three other generals, and two colonels; Franco was later added in early August. On 21 September it was decided that Franco was to be commander-in-chief (this unified command was opposed only by Cabanellas), and, after some discussion, with no more than a lukewarm agreement from Queipo de Llano and from Mola, also head of government. He was, doubtlessly, helped to this primacy by the fact that, in late July, Hitler had decided that all of Germany's aid to the nationalists would go to Franco.
Mola had been somewhat discredited as the main planner of the attempted coup that had now degenerated into a civil war, and was strongly identified with the Carlist monarchists and not at all with the Falange, a party with Fascist leanings and connections ("phalanx", a far-right Spanish political party founded by José Antonio Primo de Rivera), nor did he have good relations with Germany; Queipo de Llano and Cabanellas had both previously rebelled against the dictatorship of Miguel Primo de Rivera and were therefore discredited in some nationalist circles; and Falangist leader José Antonio Primo de Rivera was in prison in Alicante (he would be executed a few months later) and the desire to keep a place open for him prevented any other Falangist leader from emerging as a possible head of state. Franco's previous aloofness from politics meant that he had few active enemies in any of the factions that needed to be placated, and also he had cooperated in recent months with both Germany and Italy.
On 1 October 1936, in Burgos, Franco was publicly proclaimed as "Generalísimo" of the National army and "Jefe del Estado" (Head of State). When Mola was killed in another air accident a year later (which some believe was an assassination) (2 June 1937), no military leader was left from those who organized the conspiracy against the Republic between 1933 and 1935.
Military command.
Franco personally guided military operations from this time until the end of the war. After the failed assault on Madrid in November 1936, Franco settled on a piecemeal approach to winning the war, rather than bold maneuvering. As with his decision to relieve the garrison at Toledo, this approach has been subject of some debate; some of his decisions, such as in June 1938 when he preferred to head for Valencia instead of Catalonia, remain particularly controversial from a military viewpoint. However, Valencia, Castellon and Alicante saw the last Republican troops defeated by Franco.
Although both Germany and Italy provided military support to Franco, the degree of influence of both powers on his direction of the war seems to have been very limited. Nevertheless, the Italian troops, despite not being always effective, were present in most of the large operations in large numbers, while the German aircraft helped the Nationalist air force dominate the skies for most of the war. António de Oliveira Salazar's Portugal also openly assisted the Nationalists from the start, contributing some 20,000 troops.
Franco's direction of the German and Italian forces was limited, particularly in the direction of the Condor Legion, but he was by default their supreme commander, and they rarely made decisions on their own. For reasons of prestige it was decided to continue assisting Franco until the end of the war, and Italian and German troops paraded on the day of the final victory in Madrid.
Political command.
From 1937 to 1948 the Franco regime was doctrinally at least a semi-fascist state, the categorical fascism of the FET (Falange Española Tradicionalista) as state party being mitigated above all by the confessional nature of the regime—creating the strange hybrid known to some as clerical fascism and to Amando de Miguel as "fascismo frailuno" (friar fascism). 
On 19 April 1937 Franco managed to fuse the ideologically incompatible national-syndicalist Falange ("Phalanx", a fascist Spanish political party founded by José Antonio Primo de Rivera) and the Carlist monarchist parties into one party under his rule, dubbed "Falange Española Tradicionalista y de las Juntas de Ofensiva Nacional-Sindicalista" (FET y de las JONS), which became the only legal party in 1939. Unlike some other fascist movements, the Falangists did develop an official program, the Twenty-Seven Points. These exhibited all the main points of fascistic doctrine. Franco made himself "jefe nacional" (National Chief) of the new FET ("Falange Española Tradicionalista"; Traditionalist Spanish Phalanx) with a secretary, Junta Political and National Council to be named subsequently by himself. Five days later (24 April) the raised-arm Fascist salute of the Falange was made the official salute of the Nationalist regime. In 1939 the fascist style heavily predominated, with ritualistic invocations of "Franco, Franco, Franco." The Falangists' hymn, "Cara al Sol", became the semi-national anthem of Franco's not-yet-established regime.
This new political formation appeased the pro-Nazi Falangists while tempering them with the anti-German Carlists. Franco's brother-in-law Ramón Serrano Súñer, who was his main political advisor, was able to turn the various parties under Franco against each other to absorb a series of political confrontations against Franco himself. Franco expelled the original leading members of both the Carlists (Manuel Fal Condé) and the Falangists (Manuel Hedilla) to secure his political future. Franco also appeased the Carlists by exploiting the Republicans' anti-clericalism in his propaganda, in particular concerning the "Martyrs of the war". While the loyalist forces presented the war as a struggle to defend the Republic against Fascism, Franco depicted himself as the defender of "Catholic Spain" against "atheist Communism."
The end of the Civil War.
Before the fall of Catalonia in February 1939, the Prime Minister of Spain Juan Negrín unsuccessfully proposed, in the meeting of the Cortes in Figueres, capitulation with the sole condition of respecting the lives of the vanquished. Negrín was ultimately deposed by Colonel Segismundo Casado, later joined by José Miaja.
Thereafter only Madrid (see History of Madrid) and a few other areas remained under control of the government forces. On 27 February Chamberlain and Daladier's governments recognized the Franco regime, before the official end of the war. The PCE (the Spanish Communist Party) attempted a mutiny in Madrid with the aim of re-establishing Negrín's leadership, but José Miaja retained control. On 28 March 1939, with the help of pro-Franco forces inside the city (the "fifth column" General Mola had mentioned in propaganda broadcasts in 1936), Madrid fell to the Nationalists. The next day, Valencia, which had held out under the guns of the Nationalists for close to two years, also surrendered. Victory was proclaimed on 1 April 1939, when the last of the Republican forces surrendered. On the same day, Franco placed his sword upon the altar of a church and in a vow, promised that he would never again take up his sword unless Spain itself was threatened with invasion.
At least 70,000 people were executed during the civil war. Franco's victory was followed by thousands of summary executions (from 15,000 to 25,000 people) and imprisonments, while many were put to forced labour, building railways, drying out swamps, digging canals ("La Corchuela", the Canal of the Bajo Guadalquivir), construction of the Valle de los Caídos monument, etc. The 1940 shooting of the president of the Catalan government, Lluís Companys, was one of the most notable cases of this early suppression of opponents and dissenters. According to Gabriel Jackson, the number of victims of the "White Terror" (executions and hunger or illness in prisons) only between 1939 and 1943 was 200,000.
Leftists suffered a high death toll. The Spanish intelligentsia and atheists were also targeted for liquidation, as well as military and government figures who had remained loyal to the Madrid government during the civil war.
In his history of the Spanish Civil War, Antony Beevor "reckons Franco's ensuing 'white terror' claimed 200,000 lives. The 'red terror' had already killed 38,000." Julius Ruiz concludes that "although the figures remain disputed, a minimum of 37,843 executions were carried out in the Republican zone with a maximum of 150,000 executions (including 50,000 after the war) in Nationalist Spain."
Despite the official end of the war, guerrilla resistance to Franco (known as "the "maquis"") was widespread in many mountainous regions, and continued well into the 1950s. In 1944, a group of republican veterans, which also fought in the French resistance against the Nazis, invaded the Val d'Aran in northwest Catalonia, but they were quickly defeated.
The end of the war led to hundreds of thousands of exiles, mostly to France (but also Mexico, Chile, Cuba, the USA and so on.). On the other side of the Pyrenees, refugees were confined in internment camps of the French Third Republic, such as Camp Gurs or Camp Vernet, where 12,000 Republicans were housed in squalid conditions (mostly soldiers from the Durruti Division). The 17,000 refugees housed in Gurs were divided into four categories (Brigadists, pilots, "Gudaris" and ordinary 'Spaniards'). The "Gudaris" (Basques) and the pilots easily found local backers and jobs, and were allowed to quit the camp, but the farmers and ordinary people, who could not find relations in France, were encouraged by the Third Republic, in agreement with the Francoist government, to return to Spain. The great majority did so and were turned over to the Francoist authorities in Irún. From there they were transferred to the Miranda de Ebro camp for "purification" according to the Law of Political Responsibilities.
After the proclamation by Marshal Philippe Pétain of the Vichy France regime, the refugees became political prisoners, and the French police attempted to round up those who had been liberated from the camp. Along with other "undesirables", they were sent to the Drancy internment camp before being deported to Nazi Germany. 5,000 Spaniards thus died in Mauthausen concentration camp. The Chilean poet Pablo Neruda, who had been named by the Chilean President Pedro Aguirre Cerda special consul for immigration in Paris, was given responsibility for what he called "the noblest mission I have ever undertaken": shipping more than 2,000 Spanish refugees, who had been housed by the French in squalid camps, to Chile on an old cargo ship, the "Winnipeg".
World War II.
In September 1939 World War II broke out in Europe, and on 23 October 1940 Hitler and Franco met in Hendaye in France to discuss the possibility of Spain's entry on the side of the Axis. However, Franco's demands, which included food, military equipment, and Spanish control of Gibraltar and French North Africa proved too much for Hitler, and no agreement was reached. (An oft-cited remark attributed to Hitler is that the German leader would rather have some teeth extracted than to have to deal further with Franco.) Although Franco's tactics had received important support from Adolf Hitler and Benito Mussolini during the Spanish civil war, Franco remained emphatically neutral in the Second World War, but nonetheless offered various kinds of support to Italy and Germany. He allowed Spanish soldiers to volunteer to fight in the German Army against the USSR (the Blue Division), but forbade Spaniards to fight in the West against the democracies. Franco's common ground with Hitler was particularly weakened by Hitler's propagation of Nazi mysticism and his attempts to manipulate Christianity, which went against Franco's fervent commitment to defending Christianity and Catholicism. Contributing to the disagreement was an ongoing dispute over German mining rights in Spain. Some historians argue that Franco made demands he knew Hitler would not accede to in order to stay out of the war. (German resistance leader Wilhelm Canaris had secretly briefed him on which demands would be found excessive.) Other historians argue that Franco, as the leader of a destroyed country in chaos following a brutal three-year civil war, simply had nothing to offer the Germans and their military.
Yet, after the Fall of France in June 1940, Spain did adopt a pro-Axis non-belligerency stance (for example, he offered Spanish naval facilities to German ships and U-boats) until returning to complete neutrality in 1943 when the tide of the war had turned decisively against Germany and its allies. In 1940 Franco also considered blocking allied access to the Mediterranean Sea by invading British-controlled Gibraltar, but he abandoned the idea after learning that the plan would have likely failed and it would have given the British the grounds to declare war on Spain and thus give Great Britain and its allies an excellent opportunity to take both the Canary Islands and Spanish Morocco, as well as possibly invade mainland Spain itself. Some volunteer Spanish troops (the "División Azul", or "Blue Division")—not given official state sanction by Franco—went to fight on the Eastern Front under German command from 1941 to 1943. Some historians have argued that not all of the Blue Division were true volunteers and that Franco expended relatively small but significant resources to aid the Axis powers' battle against the Soviet Union.
Franco was initially disliked by Cuban President Fulgencio Batista, who, during World War II, had suggested a joint U.S.-Latin American assault on Spain in order to overthrow Franco's regime.
According to the recent discovery of a World War II document, Franco ordered his provincial governors to compile a list of Jews while he negotiated an alliance with the Axis powers. Franco supplied Reichsführer-SS Heinrich Himmler with a list of 6,000 Jews in Spain, for the Nazis' "Final Solution". Despite the creation of the list, there is no evidence of any Jew seeking refuge from Germany being sent back to Germany. That the list of Spanish Jews was produced may have not reflected Franco's personal beliefs about Jewry. Although Franco made occasional negative references to Jews, he had Jewish friends in Morocco and even publicly stopped an outbreak of discrimination against Jews in Morocco. When Franco became dictator, no official attacks on Jews were ever countenanced by his government, nor did he ever hand Jews over to Germany. Spanish Jews in the army served Franco with the same conditions as anyone else. Spain ended up helping more Jews than any other neutral nation during World War II. Furthermore, Spanish diplomats extended their diplomatic protection over Jews in Hungary, Czechoslovakia and the Balkans.
On 14 June 1940 Spanish forces in Morocco occupied Tangier (a city under the rule of the League of Nations) and did not leave it until the war's end in 1945.
Spain under Franco.
Franco was recognized as the Spanish head of state by Britain and France in February 1939. Already proclaimed "Generalísimo" of the Nationalists and "Jefe del Estado" (Head of State) in October 1936, he thereafter assumed the official title of "Su Excelencia el Jefe de Estado" ("His Excellency the Head of State"). However, he was also referred to in state and official documents as "Caudillo de España" ("the Leader of Spain"), and sometimes called "el Caudillo de la Última Cruzada y de la Hispanidad" ("the Leader of the Last Crusade and of the Hispanic heritage") and "el Caudillo de la Guerra de Liberación contra el Comunismo y sus Cómplices" ("the Leader of the War of Liberation Against Communism and Its Accomplices").
In 1947 Franco proclaimed Spain a monarchy, but did not designate a monarch. This gesture was largely done to appease the monarchists in the "Movimiento Nacional" (Carlists and Alfonsists). Despite his own monarchist sympathies, Franco did not feel it was time to have a king to rule the country yet, let alone single out any specific candidate for the role. Accordingly, he left the throne vacant, proclaiming himself as a "de facto" regent for life. At the same time Franco appropriated many of the privileges of a king. He wore the uniform of a Captain General (a rank traditionally reserved for the King) and resided in the El Pardo Palace. In addition he began walking under a canopy, and his portrait appeared on most Spanish coins and postage stamps. He also added "by the grace of God", a phrase usually part of the styles of monarchs, to his style.
Franco initially sought support from various groups. His administration marginalized fascist ideologues in favor of technocrats, many of whom were linked with Opus Dei, who promoted economic modernization.
Although Franco and Spain under his rule adopted some trappings of fascism, he, and Spain under his rule, are generally not considered to be fascist; among the distinctions, fascism entails a revolutionary aim to transform society, where Franco did not seek to do so, and, to the contrary, although authoritarian, was by nature conservative and traditional. Stanley Payne notes: "scarcely any of the serious historians and analysts of Franco consider the generalissimo to be a core fascist". The few consistent points in Franco's long rule were above all authoritarianism, nationalism, Catholicism, anti-Freemasonry, and anti-Communism.
The aftermath of the Civil War was socially bleak: many of those who had supported the Republic fled into exile. Spain lost thousands of doctors, nurses, teachers, lawyers, judges, professors, businessmen, artists, etc. Many of those who had to stay lost their jobs or lost their rank. Sometimes those jobs were given to unskilled and even untrained personnel. This deprived the country of many of its brightest minds, and also of a very capable workforce. However, this was done to keep Spain's citizens consistent with the ideals sought by the Nationalists and Franco.
With the end of World War II, Spain suffered from the economic consequences of its isolation from the international community. This situation ended in part when, in the light of Cold War tensions and of Spain's strategic location, the United States entered into a trade and military alliance with Franco. This historic alliance commenced with United States President Eisenhower's visit in 1953 which resulted in the Pact of Madrid. Spain was then admitted to the UN in 1955.
In 1952 a syndicate from Dallas, Texas, including Jack Crichton, Everette Lee DeGolyer, and Clint Murchison sought drilling rights to petroleum in Spain. The operation was handled by Delta Drilling Company.
Political oppression.
The first decade of Franco's rule following the end of the Civil War in 1939 saw continued oppression and the killing of an undetermined number of political opponents. Estimation is difficult and controversial, but the number of people killed probably lies somewhere between 15,000 and 50,000.
By the start of the 1950s Franco's state had become less violent, but during his entire rule, non-government trade unions and all political opponents across the political spectrum, from communist and anarchist organizations to liberal democrats and Catalan or Basque separatists, were either suppressed or tightly controlled by all means, up to and including violent police repression. The "Confederación Nacional del Trabajo" (CNT) and the "Unión General de Trabajadores" (UGT) trade unions were outlawed, and replaced in 1940 by the corporatist "Sindicato Vertical". The Spanish Socialist Workers' Party and the "Esquerra Republicana de Catalunya" (ERC) were banned in 1939, while the Communist Party of Spain (PCE) went underground. The Basque Nationalist Party (PNV) went into exile, and in 1959 the ETA armed group was created to wage a low-intensity war against Franco.
Franco's Spanish nationalism promoted a unitary national identity by repressing Spain's cultural diversity. Bullfighting and flamenco were promoted as national traditions while those traditions not considered "Spanish" were suppressed. Franco's view of Spanish tradition was somewhat artificial and arbitrary: while some regional traditions were suppressed, Flamenco, an Andalusian tradition, was considered part of a larger, national identity. All cultural activities were subject to censorship, and many, such as the Sardana, the national dance of Catalunya, were plainly forbidden (often in an erratic manner). This cultural policy relaxed with time, most notably in the late 1960s and early 1970s.
Franco also used language politics in an attempt to establish national homogeneity. He promoted the use of Castilian Spanish and suppressed other languages such as Catalan, Galician, and Basque. The legal usage of languages other than Castilian was forbidden. All government, notarial, legal and commercial documents were to be drawn up exclusively in Castilian and any written in other languages were deemed null and void. The usage of any other language was forbidden in schools, in advertising, and on road and shop signs. For unofficial use, citizens continued to speak these languages. This was the situation throughout the 1940s and to a lesser extent during the 1950s, but after 1960 the non-Castilian Spanish languages were freely spoken and written, and reached bookshops and stages, although they never received official status.
On the other hand, the Catholic Church was upheld as the established church of the Spanish State, and regained many of the traditional privileges it had lost under the Republic. Civil servants had to be Catholic, and some official jobs even required a "good behavior" statement by a priest. Civil marriages which had taken place under Republican Spain were declared null and void unless confirmed by the Catholic Church. Divorce was forbidden, and also contraceptives and abortion.
Most country towns and rural areas were patrolled by pairs of "Guardia Civil", a military police for civilians, which functioned as Franco's chief means of social control. Larger cities and capitals were mostly under the Policia Armada, or "grises" ("greys", due to the color of its uniform) as they were called.
Student revolts at universities in the late 1960s and early 1970s were violently repressed by the heavily armed "Policía Armada" (Armed Police). Plainclothes secret police worked inside Spanish universities. In May 1972, an American student was arrested by university secret police in Barcelona and charged and imprisoned under martial law for the crime of wearing an old Spanish Army jacket.
The enforcement by public authorities of traditional Catholic values was a stated intent of the regime, mainly by using a law (the "Ley de Vagos y Maleantes", Vagrancy Act) enacted by Azaña. The remaining nomads of Spain (Gitanos and Mercheros like El Lute) were especially affected. Through this law, homosexuality, pedophilia and prostitution were in 1954 made criminal offenses, although its application was seldom consistent.
Women in Francoist Spain.
Francoism professed a devotion to the traditional role of a woman in society, that is loving child to her parents and brothers, faithful to her husband, residing with her family. Official propaganda confined the role of women to family care and motherhood. Immediately after the war most progressive laws passed by the Republic aimed at equality between the sexes were nullified. Women could not become judges, or testify in a trial. They could not become university professors. Their affairs and economy had to be managed by fathers and husbands. Even in the 1970s a woman fleeing from an abusive husband could be arrested and imprisoned for "abandoning the home" ("abandono del hogar"). Until the 1970s a woman could not have a bank account without a co-sign by her father or husband. In the 1960s and 1970s these restrictions were somewhat relaxed, but it was not until after Franco's death that a more egalitarian view of the sexes was adopted.
Spanish colonial empire and decolonisation.
Spain attempted to retain control of its colonial empire throughout Franco's rule. During the Algerian War (1954–62), Madrid became the base of the "Organisation de l'armée secrète" (OAS) right-wing French Army group which sought to preserve French Algeria. Despite this, Franco was forced to make some concessions. When French Morocco became independent in 1956, he surrendered Spanish Morocco to Mohammed V, retaining only a few enclaves (the "Plazas de soberanía"). The year after, Mohammed V invaded Spanish Sahara during the Ifni War (known as the "Forgotten War" in Spain). Only in 1975, with the Green March, did Morocco take control of all of the former Spanish territories in the Sahara.
In 1968, under United Nations pressure, Franco granted Spain's colony of Equatorial Guinea its independence, and the next year ceded the exclave of Ifni to Morocco. Under Franco, Spain also pursued a campaign to force a negotiation on the British overseas territory of Gibraltar, and closed its border with that territory in 1969. The border would not be fully reopened until 1985.
Economic policy.
The Civil War had ravaged the Spanish economy. Infrastructure had been damaged, workers killed, and daily business severely hampered. For more than a decade after Franco's victory, the devastated economy recovered very slowly. Franco initially pursued a policy of autarky, cutting off almost all international trade. The policy had devastating effects, and the economy stagnated. Only black marketeers could enjoy an evident affluence.
On the brink of bankruptcy, a combination of pressure from the United States, the IMF and, most importantly, the technocrats from Opus Dei, managed to convince the regime to adopt a freer market economy. Many of the old guard in charge of the economy were replaced by "technocrata", despite some initial opposition from Franco. From the mid-1950s there was modest acceleration in economic activity after some minor reforms and a relaxation of controls. But the growth proved too much for the economy, with shortages and inflation breaking out towards the end of the 1950s.
When Franco replaced his ideological ministers with the apolitical technocrats, the regime implemented several development policies that included deep economic reforms. After a recession, growth took off from 1959, creating an economic boom that lasted until 1974, and became known as the "Spanish Miracle".
Concurrent with the absence of social reforms, and the economic power shift, a tide of mass emigration commenced to other European countries, and to a lesser extent, to South America. Emigration helped the regime in two ways. The country got rid of populations it would not have been able to keep in employment, and the emigrants supplied the country with much needed monetary remittances.
During the 1960s, the wealthy classes of Francoist Spain experienced further increases in wealth, particularly those who remained politically faithful, while a burgeoning middle class became visible as the "economic miracle" progressed. International firms established factories in Spain where salaries were low, company taxes very low, strikes forbidden and workers' health or state protections almost unheard of. State-owned firms like the car manufacturer SEAT, truck builder Pegaso and oil refiner INH, massively expanded production. Furthermore, Spain was virtually a new mass market. Spain became the second-fastest growing economy in the world between 1959 and 1973, just behind Japan. By the time of Franco's death in 1975, Spain still lagged behind most of Western Europe but the gap between its per capita GDP and that of the leading Western European countries had narrowed greatly, and the country had developed a large industrialized economy.
Regions.
Franco was reluctant to enact any form of administrative and legislative decentralisation and kept a fully centralized government with a similar administrative structure to that established by the House of Bourbon and General Miguel Primo de Rivera y Orbaneja. Such structures were both based on the model of the French centralised State. The main drawback of this kind of management is that government attention and initiatives were irregular, and often depended more on the goodwill of regional Government representatives than on regional needs. Thus, inequalities in schooling, health care or transport facilities among regions were patent: classically affluent regions like Madrid, Catalonia, or the Basque Country fared much better than Extremadura, Galicia or Andalusia. Some regions, like Extremadura or La Mancha did not have a university.
The Basque Country and Catalonia were among the regions that offered the strongest resistance to Franco in the Civil War. Franco dissolved the autonomy granted by the Second Spanish Republic to these two regions and to Galicia. Franco abolished the centuries-old fiscal privileges and autonomy (the "fueros") in two of the three Basque provinces: Guipuzcoa and Biscay, but kept them for Álava which had sided with the nationalists in the civil war.
Among Franco's greatest area of support during the civil war was Navarre, the northern half of which was Basque-speaking. Navarre remained a separate region from the Basque Country and Franco also decided to preserve its centuries-old fiscal privileges and autonomy, the so-called Fueros of Navarre. The regional privileges for Álava and Navarre were kept because Álava and Navarre had participated in the initial "coup d'état" against the Republican government on 18 July 1936.
Franco abolished the official statute and recognition of the Basque, Galician, and Catalan languages that the Second Spanish Republic had granted for the first time in the history of Spain. He returned to Castilian as the only official language of the State and education. The Franco era corresponded with the popularisation of the compulsory national educational system and the development of modern mass media, both controlled by the State and in the Castilian language, and heavily reduced the number of speakers of Basque, Catalan and Galician, as happened during the second half of the 20th century with other European minority languages which were not officially protected, such as Scottish Gaelic or French Breton. By the 1970s the majority of the population in urban areas could not speak the minority language or, as in some Catalan towns, their social use had been abandoned, leaving them limited to family use. Because of the already fragile situation of the Basque language before the Civil War, it became the most endangered language in Spain. By the 1970s Basque lacked a sufficient number of new speakers to assure its future, and moved closer to extinction. It is now recognised that the Basque language would have disappeared in a few more decades if the same linguistic policies had been preserved. This was the main reason that drove the Francoist provincial government of Álava to create a network of Basque medium schools (Ikastola) in 1973 which were State-financed.
Franco and the United States.
At the end of World War II, Spain's fascist dealings made it an international pariah and kept the country out of the United Nations, the Marshall Plan and NATO; in the 1950s, however, Spain's strategic location and hostility towards the Soviet Union led the U.S. to reconsider its position towards Spain and entered into a trade and military alliance as part of its policy of containment.
This historic alliance began with the signing of the Pact of Madrid in 1953, which guaranteed American support for Franco's regime. Spain was admitted to the United Nations in 1955 and Eisenhower visited Spain.
President Richard Nixon toasted Franco, and, after Franco's death, stated: "General Franco was a loyal friend and ally of the United States." American military facilities in Spain built during this era included Naval Station Rota, Morón Air Base, and Torrejón Air Base.
Death and funeral.
In 1969 Franco designated Prince Juan Carlos de Borbón, who had been educated by him in Spain, with the new title of Prince of Spain, as his heir-apparent. This designation came as a surprise for the Carlist pretender to the throne, as well as for Juan Carlos' father, Don Juan, the Count of Barcelona, who had a superior claim to the throne, but was feared by Franco to be too liberal. By 1973 Franco had surrendered the function of prime minister ("Presidente del Gobierno"), remaining only as head of state and commander in chief of the military.
As his final years progressed, tension within the various factions of the "Movimiento" would consume Spanish political life, as varying groups jockeyed for position to control the country's future. The death on 20 December 1973 of prime minister Luis Carrero Blanco in a spectacular bombing by ETA eventually gave an edge to the liberalizing faction. On 19 July 1974 the aged Franco fell ill from various health problems, and Juan Carlos took over as Acting Head of State. Franco soon recovered, and on 2 September he resumed his duties as Head of State. One year later he fell ill once again from more health problems including a long battle with Parkinson's disease. On 30 October 1975, he fell into a coma and was put on life support. Franco's family agreed to disconnect the life-support machines, and he died just after midnight on 20 November 1975, at the age of 82—just two weeks before his 83rd birthday—the same date as the death of José Antonio Primo de Rivera, founder of the Falange. However the historian Ricardo de la Cierva claims to have been told, around 6 pm on 19 November, that Franco had already died. After Franco's death, and according to his own wishes, he was buried at Valle de los Caídos, a colossal memorial built by the forced labour of political prisoners to honour the Francoist casualties of the Spanish Civil War. Franco's funeral was attended by Prince Rainier III of Monaco, the Chilean dictator General Augusto Pinochet, who revered Franco and modelled his leadership style in Chile in the way Franco led Spain, Bolivia's dictator General Hugo Banzer, Jordan's King Hussein and US Vice President Nelson Rockefeller.
Legacy.
In Spain and abroad, the legacy of Franco remains controversial. The Oxford Dictionary uses Franco's regime as an example of fascism.
The length of his rule, the suppression of opposition, and the effective propaganda sustained through the years have made a detached evaluation almost impossible. Franco had won the hearts of many and was then able to win the Civil War; Churchill said that if he was a Spaniard living in Spain he would have supported Franco. For 40 years, Spaniards, and particularly children at school were told that Divine Providence had sent him to save Spain from chaos and poverty.
In 2006 the BBC reported that Maciej Giertych, an MEP of the clerical-nationalist League of Polish Families, had expressed admiration for Franco, stating that he "guaranteed the maintenance of traditional values in Europe".
Many Spaniards, particularly those who suffered under Franco's rule, have sought to remove official recognition of his regime. Most government buildings and streets that were named after him during his long rule reverted to their original names. Owing to Franco's human rights record, the Spanish government in 2007 banned all official public references to the Franco regime and removed any statues, street names and memorials associated with the regime, with reportedly the last statue in Santander being removed in 2008. Churches that retain plaques commemorating Franco and the victims of his Republican opponents may lose state aid. Since 1978 the national anthem of Spain, the "Marcha Real", has not been accompanied by the lyrics introduced by Franco. Recent attempts to give the national anthem new lyrics have failed due to lack of consensus.
In March 2006, the Permanent Commission of the Parliamentary Assembly of the Council of Europe unanimously adopted a resolution "firmly" condemning the "multiple and serious violations" of human rights committed in Spain under the Francoist regime from 1939 to 1975. The resolution was at the initiative of Leo Brincat and of the historian Luis María de Puig, and was the first international official condemnation of the repression enacted by Franco's regime. The resolution also urged public access to be given to historians (professional and amateurs) to the various archives of the Francoist regime, including those of the private "Fundación Francisco Franco" which, as well as other Francoist archives, remain as of 2006 inaccessible to the public. The "Fundación Francisco Franco" received various archives from the El Pardo Palace, and is alleged to have sold some of them to private individuals. Furthermore, it urged the Spanish authorities to set up an underground exhibition in the Valle de los Caidos monument to explain the "terrible" conditions in which it was built. Finally, it proposed the construction of monuments to commemorate Franco's victims in Madrid and other important cities.
In Spain, a commission to repair the dignity and restore the memory of the victims of Francoism ("Comisión para reparar la dignidad y restituir la memoria de las víctimas del franquismo") was approved in the summer of 2004, and is directed by the socialist vice-president María Teresa Fernández de la Vega.
Recently the Association for the Recovery of Historical Memory (ARHM) initiated a systematic search for mass graves of people executed during Franco's regime, which has been supported since the Spanish Socialist Workers' Party's (PSOE) victory during the 2004 elections by José Luis Rodríguez Zapatero's government. A "Ley de la memoria histórica de España" (Law on the Historical Memory of Spain) was approved on 28 July 2006 by the Council of Ministers, but it took until 31 October 2007 for the Congress of Deputies to approve an amended version as "The Bill to recognise and extend rights and to establish measures in favour of those who suffered persecution or violence during the Civil War and the Dictatorship" (in common parlance still known as Law of Historical Memory). The Senate approved the bill on 10 December 2007. Among other things, the law is supposed to enforce an official recognition of the crimes committed against civilians during the Francoist rule and organize under state supervision the search for mass graves.
Official endeavors to preserve the historical memory of the Franco regime include exhibitions like the one the Museu d'Història de Catalunya (Catalonian Museum of History) organized around the prison experience.
The accumulated wealth of Franco's family (including much real estate inherited from Franco, such as the "Pazo de Meirás", the "Canto del Pico" in Torrelodones and the Cornide Palace in A Coruña), and its murky provenance, have also become matters of public discussion. Estimates of the family's wealth have ranged from 350 million to 600 million euros, well above what could possibly be accumulated from investing his official income. When Franco was ill, the francoist Cortes voted a large public pension for his wife Carmen Polo, which the later democratic governments kept paying. At the time of her death in 1988, Carmen Polo was receiving more than 12.5 million pesetas (four million more than Felipe González, then head of the government).

</doc>
<doc id="11467" url="https://en.wikipedia.org/wiki?curid=11467" title="Flash Crowd">
Flash Crowd

"Flash Crowd" is a 1973 English language novella by science fiction author Larry Niven, one of a series about the social consequence of inventing an instant, practically free transfer booth that could take one anywhere on Earth in milliseconds.
One consequence not foreseen by the builders of the system was that with the almost immediate reporting of newsworthy events, tens of thousands of people worldwide — along with criminals — would teleport to the scene of anything interesting, thus creating disorder and confusion. The plot centers around a television journalist who, after being fired for his inadvertent role in inciting a post-robbery riot in Los Angeles, seeks to independently investigate the teleportation system for the flaws in its design allowing for such spontaneous riots to occur. His investigation takes him to destinations and people around the world within the matter of less than 12 hours before he gets his chance to plead his case on television, and he encounters the wide-ranging effects of displacements upon aspects of human behavior such as settlement, crime, natural resources, agriculture, waste management and tourism.
Use in other works.
In various other books, for example "Ringworld", Niven suggests that easy transportation might be disruptive to traditional behavior and open the way for new forms of parties, spontaneous congregations, or shopping trips around the world. The central character in "Ringworld", celebrating his birthday, teleports across time-zones to "lengthen" his birthday multiple times (particularly notable since the first edition had the error of the character heading the wrong direction, increasing that edition's value).
Niven's essay "Exercise in Speculation: The Theory and Practice of Teleportation" was published in the collection "All the Myriad Ways" In it he discusses the ideas that underlie his teleportation stories.
Similar references.
On the World Wide Web, a similar phenomenon can occur, when a web site catches the attention of a large number of people, and gets an unexpected and overloading surge of traffic. This usage was first coined by John Pettitt of Beyond.com in 1996. Multiple other terms for the phenomenon exist, often coming from the name of a particular prominent, high-traffic site whose normal base of viewers can constitute a flash crowd when directed to a less famous website. Notorious examples include the "Slashdot effect", the "Instalanche" (when a smaller site gets links by the popular blog Instapundit), or a website being "Farked" or Drudged (where the target site is crashed due to the large number of hits in a short time).

</doc>
<doc id="11469" url="https://en.wikipedia.org/wiki?curid=11469" title="August Kekulé">
August Kekulé

Friedrich August Kekulé, later Friedrich August Kekule von Stradonitz () (7 September 1829 – 13 July 1896) was a German organic chemist. From the 1850s until his death, Kekulé was one of the most prominent chemists in Europe, especially in theoretical chemistry. He was the principal founder of the theory of chemical structure.
Name.
Kekulé never used his first given name; he was known throughout his life as August Kekulé. After he was ennobled by the Kaiser in 1895, he adopted the name August Kekule von Stradonitz, without the French acute accent over the second "e". The French accent had apparently been added to the name by Kekulé's father during the Napoleonic occupation of Hesse by France, to ensure that French speakers pronounced the third syllable.
Early years.
The son of a civil servant, Kekulé was born in Darmstadt, the capital of the Grand Duchy of Hesse. After graduating from secondary school (the Grand Ducal Gymnasium in Darmstadt), in the fall of 1847 he entered the University of Giessen, with the intention of studying architecture. After hearing the lectures of Justus von Liebig in his first semester, he decided to study chemistry. Following four years of study in Giessen and a brief compulsory military service, he took temporary assistantships in Paris (1851–52), in Chur, Switzerland (1852–53), and in London (1853–55), where he was decisively influenced by Alexander Williamson. His Giessen doctoral degree was awarded in the summer of 1852.
Theory of chemical structure.
In 1856 Kekulé became Privatdozent at the University of Heidelberg. In 1858 he was hired as full professor at the University of Ghent, then in 1867 he was called to Bonn, where he remained for the rest of his career. Basing his ideas on those of predecessors such as Williamson, Edward Frankland, William Odling, Auguste Laurent, Charles Adolphe Wurtz and others, Kekulé was the principal formulator of the theory of chemical structure (1857–58). This theory proceeds from the idea of atomic valence, especially the tetravalence of carbon (which Kekulé announced late in 1857) and the ability of carbon atoms to link to each other (announced in a paper published in May 1858), to the determination of the bonding order of all of the atoms in a molecule. Archibald Scott Couper independently arrived at the idea of self-linking of carbon atoms (his paper appeared in June 1858), and provided the first molecular formulas where lines symbolize bonds connecting the atoms. For organic chemists, the theory of structure provided dramatic new clarity of understanding, and a reliable guide to both analytic and especially synthetic work. As a consequence, the field of organic chemistry developed explosively from this point. Among those who were most active in pursuing early structural investigations were, in addition to Kekulé and Couper, Frankland, Wurtz, Alexander Crum Brown, Emil Erlenmeyer, and Aleksandr Mikhailovich Butlerov.
Kekulé's idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them using what he called their "Verwandtschaftseinheiten" ("affinity units", now called "valences" or "bonds"), was based largely on evidence from chemical reactions, rather than on instrumental methods that could peer directly into the molecule, such as X-ray crystallography. Such physical methods of structural determination had not yet been developed, so chemists of Kekulé's day had to rely almost entirely on so-called "wet" chemistry. Some chemists, notably Adolph Wilhelm Hermann Kolbe, heavily criticized the use of structural formulas that were offered, as he thought, without proof. However, most chemists followed Kekulé's lead in pursuing and developing what some have called "classical" structure theory, which was modified after the discovery of electrons (1897) and the development of quantum mechanics (in the 1920s).
The idea that the number of valences of a given element was invariant was a key component of Kekulé's version of structural chemistry. This generalization suffered from many exceptions, and was subsequently replaced by the suggestion that valences were fixed at certain oxidation states. For example, periodic acid according to Kekuléan structure theory could be represented by the chain structure I-O-O-O-O-H. By contrast, the modern structure of (meta) periodic acid has all four oxygen atoms surrounding the iodine in a tetrahedral geometry.
Benzene.
Kekulé's most famous work was on the structure of benzene. In 1865 Kekulé published a paper in French (for he was then still in Francophone Belgium) suggesting that the structure contained a six-membered ring of carbon atoms with alternating single and double bonds. The next year he published a much longer paper in German on the same subject.
The empirical formula for benzene had been long known, but its highly unsaturated structure was a challenge to determine. Archibald Scott Couper in 1858 and Joseph Loschmidt in 1861 suggested possible structures that contained multiple double bonds or multiple rings, but the study of aromatic compounds was in its earliest years, and too little evidence was then available to help chemists decide on any particular structure.
More evidence was available by 1865, especially regarding the relationships of aromatic isomers. Kekulé argued for his proposed structure by considering the number of isomers observed for derivatives of benzene. For every monoderivative of benzene (CHX, where X = Cl, OH, CH, NH, etc.) only one isomer was ever found, implying that all six carbons are equivalent, so that substitution on any carbon gives only a single possible product. For diderivatives such as the toluidines, CH(NH)(CH), three isomers were observed, for which Kekulé proposed structures with the two substituted carbon atoms separated by one, two and three carbon-carbon bonds, later named ortho, meta, and para isomers respectively.
The counting of possible isomers for diderivatives was however criticized by Albert Ladenburg, a former student of Kekulé, who argued that Kekulé's 1865 structure implied two distinct "ortho" structures, depending on whether the substituted carbons are separated by a single or a double bond. Since ortho derivatives of benzene were never actually found in more than one isomeric form, Kekulé modified his proposal in 1872 and suggested that the benzene molecule oscillates between two equivalent structures, in such a way that the single and double bonds continually interchange positions. This implies that all six carbon-carbon bonds are equivalent, as each is single half the time and double half the time. A firmer theoretical basis for a similar idea was later proposed in 1928 by Linus Pauling, who replaced Kekulé's oscillation by the concept of resonance between quantum-mechanical structures.
The ouroboros dream.
The new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry after 1865 that in 1890 the German Chemical Society organized an elaborate appreciation in Kekulé's honor, celebrating the twenty-fifth anniversary of his first benzene paper. Here Kekulé spoke of the creation of the theory. He said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake seizing its own tail (this is an ancient symbol known as the ouroboros). This vision, he said, came to him after years of studying the nature of carbon-carbon bonds.
A similar humorous depiction of benzene had appeared in 1886 in the "Berichte der Durstigen Chemischen Gesellschaft" (Journal of the Thirsty Chemical Society), a parody of the "Berichte der Deutschen Chemischen Gesellschaft", only the parody had monkeys seizing each other in a circle, rather than snakes as in Kekulé's anecdote. Some historians have suggested that the parody was a lampoon of the snake anecdote, possibly already well-known through oral transmission even if it had not yet appeared in print. Others have speculated that Kekulé's story in 1890 was a re-parody of the monkey spoof, and was a mere invention rather than a recollection of an event in his life. 
Kekulé's 1890 speech, in which these anecdotes appeared, has been translated into English. If one takes the anecdote as the memory of a real event, circumstances mentioned in the story suggest that it must have happened early in 1862.
He told yet another anecdote in 1890, of a vision of dancing atoms and molecules that led to his theory of structure. This happened, he claimed, while he was riding on the upper deck of a horse-drawn omnibus in London. This probably occurred in the late summer of 1855.
Honors.
In 1895 Kekulé was ennobled by Kaiser Wilhelm II of Germany, giving him the right to add "von Stradonitz" to his name, referring to a possession of his patrilineal ancestors in Stradonice, Bohemia. This title was used by his son, genealogist Stephan Kekulé von Stradonitz. Of the first five Nobel Prizes in Chemistry, Kekulé's students won three: van 't Hoff in 1901, Fischer in 1902 and Baeyer in 1905.
A larger-than-life size monument of Kekulé is situated in front of the former Chemical Institute at the University of Bonn. His monument is often decorated by students, e.g. for Valentine's Day.

</doc>
<doc id="11472" url="https://en.wikipedia.org/wiki?curid=11472" title="Frederick III, Holy Roman Emperor">
Frederick III, Holy Roman Emperor

Frederick III (21 September 1415 – 19 August 1493), called the Peaceful, was Holy Roman Emperor from 1452 until his death, the first emperor of the House of Habsburg. He was the penultimate emperor to be crowned by the Pope, and the last to be crowned in Rome.
Prior to his imperial coronation, he was duke of the Inner Austrian lands of Styria, Carinthia and Carniola from 1424, and also acted as regent over the Duchy of Austria (as Frederick V) from 1439. He was elected and crowned King of Germany (as Frederick IV) in 1440. He was the longest-reigning German monarch when in 1493, after ruling his domains for more than 53 years, he was succeeded by his son Maximilian I.
During his reign, Frederick concentrated on re-uniting the Habsburg "hereditary lands" of Austria and took a lesser interest in Imperial affairs. Nevertheless, by his dynastic entitlement to Hungary as well as by the Burgundian inheritance, he laid the foundations for the later Habsburg Empire. Mocked as "Arch-Sleepyhead of the Holy Roman Empire" () during his lifetime, he is today increasingly seen as an efficient ruler.
Early life.
Born at the Tyrolean residence of Innsbruck in 1415, Frederick was the eldest son of the Inner Austrian duke Ernest the Iron, a member of the Leopoldian line of the Habsburg dynasty, and his second wife Cymburgis of Masovia. According to the 1379 Treaty of Neuberg, the Leopoldinian branch ruled over the duchies of Styria, Carinthia and Carniola, or what was referred to as Inner Austria. Only three of Frederick's eight siblings survived childhood: his younger brother Albert (later to be Albert VI, archduke of Austria), and his sisters Margaret (later the electress of Saxony) and Catherine. In 1424, nine-year-old Frederick's father died, making Frederick the duke of Inner Austria, as Frederick V, with his uncle, Duke Frederick IV of Tyrol, acting as regent.
From 1431, Frederick tried to obtain majority (to be declared "of age", and thus allowed to rule) but for several years was denied by his relatives. Finally, in 1435, Albert V, duke of Austria (later Albert II, the king of Germany), awarded him the rule over his Inner Austrian heritage. Almost from the beginning, Frederick's younger brother Albert asserted his rights as a co-ruler, as the beginning of a long rivalry. Already in these years, Frederick had begun to use the symbolic A.E.I.O.U. signature as a kind of motto with various meanings. In 1436 he made a pilgrimage to the Holy Land, accompanied by numerous nobles knighted by the Order of the Holy Sepulchre, which earned him great reputation.
Upon the death of his uncle Duke Frederick IV in 1439, Frederick took over the regency of Tyrol and Further Austria for the duke's heir Sigismund. Again he had to ward off the claims raised by his brother Albert VI; he prevailed by the support of the Tyrolean aristocracy. Likewise he acted as regent for his nephew Ladislaus the Posthumous, son of late King Albert II and his consort Elizabeth of Luxembourg, in the duchy of Austria (Further Austria). (Ladislaus would unfortunately die before coming of age). Frederick was now the undisputed head of the Habsburg dynasty, though his regency in the lands of the Albertinian Line (Further Austria) was still viewed with suspicion.
In 1442, Frederick allied himself with Rudolf Stüssi, burgomaster of Zurich, against the Old Swiss Confederacy in the Old Zurich War (Alter Zürichkrieg). In 1448, he entered into the Concordat of Vienna with the Holy See, which remained in force until 1806 and regulated the relationship between the Habsburgs and the Holy See.
As a cousin of late King Albert II, Frederick became a candidate for the imperial election. On 2 February 1440, the prince-electors convened at Frankfurt and unanimously elected him King of the Romans as Frederick IV; his rule was still based on his hereditary lands of Styria, Carinthia and Carniola, or Inner Austria. 
In 1452, at the age of 37, Frederick III travelled to Italy to receive his bride and to be crowned Holy Roman Emperor. His fiancée, the 18-year-old "infanta" Eleanor, daughter of King Edward of Portugal, landed at Livorno after a 104-day trip. Her dowry would help Frederick alleviate his debts and cement his power. The couple met at Siena on 24 February and proceeded together to Rome. As per tradition, they spent a night outside the walls of Rome before entering the sitting on 9 March, where Frederick and Pope Nicholas V exchanged friendly greetings. Because the emperor had been unable to retrieve the Iron Crown of Lombardy from the cathedral of Monza where it was kept, nor be crowned King of Italy by the archbishop of Milan (on account of Frederick's dispute with Francesco Sforza, lord of Milan), he convinced the pope to crown him as such with the German crown, which had been brought for the purpose. This coronation took place on the morning of 16 March, in spite of the protests of the Milanese ambassadors, and in the afternoon Frederick and Eleanor were married by the pope. Finally, on 19 March, Frederick and Eleanor were anointed in St Peter's Basilica by the Vice-Chancellor Francesco Condulmer and Frederick was then crowned with the Imperial Crown by the pope. Frederick was the last Emperor to be crowned in Rome; his great-grandson Charles V was the last emperor to be crowned, but this was done in Bologna.
Personality.
Frederick's style of rulership was marked by hesitation and a sluggish pace of decision making. The Italian humanist Enea Silvio Piccolomini, later Pope Pius II, who at one time worked at Frederick's court, described the Emperor as a person who wanted to conquer the world while remaining seated. Although this was regarded as a character flaw in older academic research, his delaying tactics are now viewed as a means of coping with political challenges in far-flung territorial possessions. Frederick is credited with having the ability to sit out difficult political situations patiently.
According to contemporary accounts, Frederick had difficulties developing emotional closeness to other persons, including his children and wife Eleanor. In general, Frederick kept himself away from women, the reasons for which are not known. As Frederick was rather distant to his family, Eleanor had a great influence on the raising and education of Frederick's children, and she therefore played an important role in the House of Habsburg's rise to prominence.
Emperor.
Frederick's political initiatives were hardly bold, but they were still successful. His first major opponent was his brother Albert VI, who challenged his rule. He did not manage to win a single conflict on the battlefield against him, and thus resorted to more subtle means. He held his second cousin once removed Ladislaus the Posthumous, the ruler of the Archduchy of Austria, Hungary and Bohemia, (born in 1440) as a prisoner and attempted to extend his guardianship over him in perpetuity to maintain his control over Lower Austria. Ladislaus was freed in 1452 by the Lower Austrian estates. He acted similarly towards his first cousin Sigismund of the Tyrolian line of the Habsburg family. Despite those efforts, he failed to gain control over Hungary and Bohemia in the Bohemian War (1468–1478) and was even defeated in the Austrian-Hungarian War (1477–1488) by the Hungarian King Matthias Corvinus in 1485, who managed to maintain residence in Vienna until his death five years later (see Siege of Vienna (1485)).
Ultimately, Frederick prevailed in all those conflicts by outliving his opponents and sometimes inheriting their lands, as was the case with Ladislaus, from whom he gained Lower Austria in 1457, and with his brother Albert VI, whom he succeeded in Upper Austria. These conflicts forced him into an anachronistic itinerant existence, as he had to move his court between various places through the years, residing in Graz, Linz and Wiener Neustadt. Wiener Neustadt owes him its castle and the "New Monastery".
Still, in some ways his policies were astonishingly successful. In the Siege of Neuss (1474–75), he forced Charles the Bold of Burgundy to give up his daughter Mary of Burgundy as wife to Frederick's son Maximilian. With the inheritance of Burgundy, the House of Habsburg began to rise to predominance in Europe. This gave rise to the saying "Let others wage wars, but you, happy Austria, shall marry", which became a motto of the dynasty.
The marriage of his daughter Kunigunde to Albert IV, Duke of Bavaria, was another result of intrigues and deception, but must be counted as a defeat for Frederick. Albert illegally took control of some imperial fiefs and then asked to marry Kunigunde (who lived in Innsbruck, far from her father), offering to give her the fiefs as a dower. Frederick agreed at first, but after Albert took over yet another fief, Regensburg, Frederick withdrew his consent. On January 2, 1487, however, before Frederick's change of heart could be communicated to his daughter, Kunigunde married Albert. A war was prevented only through the mediation of the Emperor's son, Maximilian.
In some smaller matters, Frederick was quite successful: in 1469 he managed to establish bishoprics in Vienna and Wiener Neustadt, a step that no previous Duke of Austria had been able to achieve.
Frederick's personal motto was the mysterious string A.E.I.O.U., which he imprinted on all his belongings. He never explained its meaning, leading to many different interpretations being presented, although it has been claimed that shortly before his death he said it stands for "Alles Erdreich ist Österreich untertan" (English: "All the world is subject to Austria.") It may well symbolise his own understanding of the historical importance and meaning of his rule and of the early gaining of the Imperial title.
Marriage and children.
Frederick had five children from his marriage with Eleanor of Portugal:
For the last 10 years of Frederick's life, he and Maximilian ruled jointly.
Death.
Frederick III died in 1493, aged 77, at Linz. His left foot had become gangrenous, and was amputated. He survived this procedure, but continued infection prompted amputation of his left leg, after which he was said to have bled to death.
His grave, built by Nikolaus Gerhaert von Leyden, in St. Stephen's Cathedral, Vienna, is one of the most important works of sculptural art of the late Middle Ages. (His amputated leg was buried with him.) The heavily adorned tomb was not completed until 1513, two decades after Frederick's death, and has survived in its original condition.

</doc>
<doc id="11475" url="https://en.wikipedia.org/wiki?curid=11475" title="Fuerteventura">
Fuerteventura

Fuerteventura (; loosely translated as "Strong Winds" or a corruption of the French term for "Great Adventure") is one of the Canary Islands, in the Atlantic Ocean off the coast of Africa, politically part of Spain. At , it is the second largest of the Canary Islands, after Tenerife. It was declared a biosphere reserve by UNESCO in May 2009. Its capital is Puerto del Rosario.
History.
Precolonial history.
The first settlers are believed to have arrived here from North Africa - the word "Mahorero" ("Majorero") or "Maho" is still used today to describe the people of Fuerteventura and comes from the ancient word 'mahos' meaning a type of goatskin shoe worn by the original inhabitants. They lived in caves and semi-subterranean dwellings, a few of which have been discovered and excavated revealing relics of early tools and pottery. In antiquity, the island was known as "Planaria", among other names, in reference to the flatness of most of its landscape.
In the 11th century BC, the Phoenician settlers arrived in Fuerteventura and Lanzarote. Several Spanish and Portuguese expeditions occurred in about 1340 around the island and the island were inhabited by Maurs and were afflicted with European slave holders. By the time of the conquest, the island was divided into two Guanches kingdoms, one following the king Guize and the other Ayoze. The territories of these tribes were called Maxorata (in the north) and Jandía (in the south). The kingdoms were separated by a wall whose remains are still preserved today. The wall crossed the La Pared isthmus. The ancient name for the island, Erbania, refers to that wall.
The conquest.
The conquest began in 1402, commanded by Jean de Béthencourt and Gadifer de la Salle. They arrived with only 63 sailors out of the original 283 as so many had deserted. After arriving and settling in Lanzarote, the invaders made their first excursions to the neighbouring islands. In 1404, Bethencourt and Gadifer founded Betancuria, the first settlement on the island. After numerous difficulties, Gadifer took charge of the invasion, while Bethencourt went to the Spanish peninsula to seek the recognition and support of the Castilian king.
In 1405, the French conqueror Jean de Béthencourt completed his conquest of the island and gave his name to the former capital, Betancuria, on the west coast (Puerto Rosario took over the mantle as island capital in 1835). The name of the island itself comes from fuerte (strong) and ventura (wind) as mentioned by mallorcan navigator Angelino Dulcert in 1339.
The first census showed a population of 1,200 inhabitants. Following that, the population increased gradually. In 1476 the territory became the "Señorío Territorial de Fuerteventura", a subject of the Catholic Monarchs. Over the years, the island has been invaded by the Spanish, French and the English.
Colonial Fuerteventura.
The island suffered from various pirate incursions. A Berber expedition invaded in 1593, sweeping as far as the capital. Various castles were built to protect against this type of attack. The castles were built all along the coast. The population all moved inland as a second protective measure. Because of the invasions, the first Captain General was sent to Fuerteventura, charged with defending the island in the name of the crown. With him came a number of Sergeant Majors. Betancuria became the religious capital of the island
Two pirate attacks took place in 1740, when, within a month of one another, two bands of English privateers attempted to loot the town of Tuineje. These Pirate attacks on Fuerteventura in 1740 were ruthlessly put down by the local population and the island's militia.
The military regiment was created in 1708. Its colonel assumed the title of Governor at Arms, a hereditary lifetime appointment which stayed in the hands of the Sánchez-Dumpiérrez family. Over time they acquired more power in the other islands through the family of Arias de Saavedra, the Lady of Fuerteventura. The same year, the religious leader created the Assistant Parish of La Oliva and Pájara, to launch in 1711. On 17 December 1790 he created the Assistant Parish of Tuineje, which became a new parish division on 23 June 1792 under the bishop Tavira with lands including part of the Jandía peninsular with a population of 1,670 inhabitants. In 1780 the barrilla growing economy began.
In 1852, the free trade zone was extended by Isabella II to the Canary Islands. The military rule over the island which began from 1708 dissolved in 1859 and Puerto de Cabras (now Puerto del Rosario) became entirely the new capital.
The Canary Islands obtained the right to self-govern in 1912.
In 1927, Fuerteventura and Lanzarote became part of the province of Gran Canaria.
By the 1940s the island had an airport (just west of Puerto del Rosario on the road to Tindaya, still visible today).
Tourism arrived in the mid-1960s with the building of the present airport at El Mattoral and the first tourist hotels.
The seat of the island government ("cabildo insular") is in Puerto del Rosario. A total of 74,983 people (2003) live on the island.
Since the island is close to Africa, many illegal immigrants try to enter the European Union through it, by a dangerous boat trip from Morocco.
Environment.
Geography.
The elongated island has an area of . The island is long and wide. It is part of the province of Las Palmas. It is divided into six municipalities:
100 individual settlements are distributed through these municipalities. A nearby islet, Islote de Lobos, is part of the municipality of La Oliva.
Located just off the coast of north Africa, it is the second biggest of the islands, after Tenerife, and has the longest beaches in the archipelago. The island is a destination for sun, beach and watersports enthusiasts. It lies on the same latitude as Florida and Mexico and temperatures here rarely fall below or rise above . There are no fewer than 152 beaches along its coastline — of fine, white sand and of black volcanic shingle.
Geology.
Fuerteventura is the oldest island in the Canary Islands dating back 20 million years to a volcanic eruption from the Canary hotspot. The majority of the island was created about 5 million years ago and since then has been eroded by wind and other weather. On the seabed off the west coast of the island rests a block of rock long and wide, which appears to have slid off the island largely intact at some point in prehistory, similar to the predicted future collapse of Cumbre Vieja, a geological fault on the neighboring island, La Palma. The last volcanic activity in Fuerteventura was between 4,000 and 5,000 years ago.
The highest point in Fuerteventura is Mount Jandía (807 m) in the southwestern part of the island. Geographical features include Istmo de la Pared which is wide and is the narrowest part of Fuerteventura. The island is divided into two parts, the northern portion which is Maxorata and the southwestern part called the Jandía peninsula. 
Beaches.
Fuerteventura was chosen among 500 European destinations by the Quality Coast International Certification Program of the European Coastal and Marine Union as one of the most attractive tourist destinations for visitors interested in cultural heritage, environment and sustainability.
Climate.
The climate on Fuerteventura is pleasant throughout the year. The island is also often referred to as "the island of eternal spring". The sea adjusts the temperature making the hot Sahara winds blow away from the island. The island's name in English translates as "strong fortune" or "strong wind", the Spanish word for wind being "viento". During the winter months, temperatures average a high of and a low of around , whereas during the summer a mean high of and a low of can be expected. Precipitation is about per year, most of which falls in autumn and winter. October is the month with highest rainfall.
A sandstorm known as the Calima (similar to the Sirocco wind that blows North from the Sahara into Europe) blows southwestward from the Sahara Desert and can cause high temperatures, low visibility and drying air. Temperatures during this phenomenon rise temporarily by approximately 10 degrees Celsius. The wind brings in fine white sand, visibility can drop to between or even lower and can even bring African locusts to the island.
Wildlife.
The island is home to one of the two surviving populations of the threatened Canarian Egyptian vulture. It is also inhabited by many wild dogs and cats. On the barren, rocky land there are Barbary ground squirrels and geckos. Fuerteventura also hosts several migratory and nesting birds. The island has significant populations of the collared dove, common swifts and several finch species especially in the vicinity of holiday developments.
Despite its arid climate, the island is also home to a surprisingly large insect fauna. Butterflies which commonly occur on the island include the clouded yellow (Colias hyale) and the bath white ("Pontia daplidice") which feeds on xerophytic cruciferae. The island is also home the monarch butterfly ("Danaus plexippus") and its close African relative "Danaus chrysippus". Around holiday developments such as Caleta de Fuste, water is relatively abundant, and dragonfly species including the blue emperor, "Anax imperator" and the scarlet darter, "Crocothemis erythraea" can be found. The islands sand dunes and shoreline are home to a number of bee and wasp species including the large Eumenid caterpillar hunting wasp, "Delta dimidiatipenne" and the striking blue banded bee, ("Amegilla canifrons").
Hawkmoths also occur on the island. One of the more notable species is "Hyles tithymali" which feeds on endemic spurges such as "Euphorbia regis-jubae". "Acherontia atropos", the deaths-head hawkmoth also occurs on the island presumably feeding on members of the Solanaceae, for example, "Datura innoxia" and "Nicotiana glauca" which are common weeds in the vicinity of human habitation.
Demographics.
Population.
The island has a population of 74,983. Throughout its long history, Fuerteventura has suffered from a population decline due to the economic situation and the climate, which have made it into a desert island. However, the development of tourism during the 1980s has caused the population to grow year on year since then, doubling it in a little less than a decade.
In 2005, with 86,642 registered inhabitants, the Fuerteventura population was formed by the following:
Comparing this data with the 2001 census shows that the number of permanent residents born on the island has increased by just 3,000. The number who have moved in from abroad has increased by 22,910, making this the biggest contributor to population growth in recent years.
Education.
The island has 116 schools, with a total of 14,337 pupils. Of these, 45 are primary schools, ten are secondary schools, six are for Baccalaureate students and four are vocational colleges.
Fuerteventura also has a centre linked with the National University of Distance Education, offering courses in many subjects including economics, business studies, law, history and tourism.
State administration.
Fuerteventura is governed by the Island Department of the Government of Spain, which holds the rank of a Government Subdepartment. The government building is located in the centre of the capital city, in front of the parish church of the Virgin of Rosario, the patron saint of Puerto del Rosario municipality.
This institution is charged with representing the Government of Spain on the island, and managing all the functions that are not under control of the Canarian Government. This includes the following public services:
Since 30 June 2007, the island's governor has been Eustaquio Juan Santana Gil. 4
Island Council of Fuerteventura.
The councils, formed as part of the Councils Act of 1912, administer the Canary Islands and have two principal functions. On one hand, they perform services for the Autonomous Community, and on the other, they are the local government centre for the island. In the 2003 elections, Mario Cabrera González was elected as president representing the Canarian Coalition, with 31.02% of the votes, followed by the Spanish Socialist Workers' Party with 27.53%, represented by the Vice President Domingo Fuentes Curbelo.
Municipalities.
The island is divided into six municipalities with their respective city councils which form part of the FECAM (Federation of Canarian Municipalities). They are governed by the basic legislation of the local regime and their respective organic rules. The populations of the municipalities are as follows:
In turn, these municipalities are organised into two associations: the "Mancomunidad de Municipios del Centro-Norte de Fuerteventura" formed from La Oliva and Puerto del Rosario, and the remaining municipalities make up the "Mancomunidad de Municipios del Centro-Sur de Fuerteventura".
Economy.
The economy of Fuerteventura is mainly based on tourism. Primary tourist areas are located around the existing towns of Corralejo in the north and Morro Jable in Jandia, plus the purely tourist development of Caleta de Fuste, south of Puerto del Rosario. Other main industries are fishing and agriculture (cereals and vegetables). The famous Majorero cheese is locally made from the milk of the indigenous majorera goat.
In 2009, Fuerteventura recorded the highest EU regional unemployment rate at a NUTS3 level, at 29.2 percent.
Tourism.
The first tourist hotel was built in 1965 followed by the construction of Fuerteventura Airport at El Matorral, heralding the dawn of a new era for the island. Fuerteventura, with its 3,000 sunshine hours a year, was placed firmly on the world stage as a major European holiday destination.
While having fully developed tourist facilities, the island has not experienced the overdevelopment found on some other islands and consequently caters for visitors attracted by its rugged natural beauty.
The summer Trade Winds and winter swells of the Atlantic make this a year-round surfers' paradise, with more exposed areas on the north and west shores such as Corralejo and El Cotillo proving most popular. Wind surfing takes places at locations around the island. Sailors, scuba divers and big-game fishermen are all drawn to these clear blue Atlantic waters where whales, dolphins, marlin and turtles are all common sights. With many hills present throughout the Island, hikers are also attracted to this Island.
Excellent sandy beaches are found in many locations. Western beaches, such as those around El Cotillo, can experience strong surf. The beaches adjoining the extensive sand dunes east of Corralejo are popular, as are the more protected extensive sandy shores of the Playa de Sotavento de Jandia on the southeastern coast between Costa Calma and the Morro Jable. Naked sun bathing and swimming are the norm almost on all beaches.
Much of the interior, with its large plains, lavascapes and volcanic mountains, consists of protected areas, although there are organised tours and vehicular access across them.
Art and culture.
Traditional holidays.
Like the rest of the Canaries, Carnival is traditionally one of the biggest festivals celebrated on the island. It is celebrated in different ways in all the towns during February and March. These festivities have a different theme each year. They include activities such as parades and galas to choose the Carnival King.
Concerts and festivals.
There are many concerts and festivals held in the auditoriums, such as the Festival of Canarian Music. They are also held in smaller venues across the island, featuring bands such as Estopa, Van Gogh's Ear, and King Afrhica.
Festival Internacional de Cometas/International Kite Festival is held on the second week of November each year centering on the Corralejo Beaches. It attracts kitefliers and kite surfers from all over Europe. It is popular because the winds are warm and constant and the beaches become filled with hundreds of colourful kites of all shapes and sizes.
Auditoriums.
Fuerteventura has three auditoriums. These are used for all types of performing art. They are also used for non-artistic purposes, such as conferences, charity galas and political meetings.
Central library.
The Central Library of the Island is located in Antigua's city centre, in the public university. In addition to providing the traditional library services, it has an 180-seat multipurpose room, air conditioning, a wifi zone, and a multimedia room used for seminars, presentations, film festivals etc.
Museums and exhibition spaces.
The island has several museums with different themes and plenty of exhibition spaces, both public and private. These include:
Sculpture park.
In addition to the museums, the capital Puerto del Rosario has an open-air sculpture park consisting of around 100 sculptures by different artists scattered across the city. Most of them were created for the International Symposium of Sculpture celebrated annually since 2001. During the festival, artists come from all over the world to erect their sculptures in the open air, in full view of passers by.
Main sights.
Sites of interest include Corralejo and El Jable to the north which are made up of fine sand dunes whilst the south is filled with long beaches and remote bays. The constant winds blowing onto the beaches provide a paradise for windsurfing. Surfing is common on the west and north coasts where there are large waves. Windsurfing is common around Corralejo and Playas de Sotavento and wave sailing (windsurfing on the waves) on the coast along the northern half of the island. El Cotillo is a small fishing village in the north-west of the Island famous for a very long beach to the south of the village and few very calm beaches to the north. The northern beaches frequented by snorkeling enthusiasts and sun worshippers alike are referred to as lakes by the locals. 
At Cofete on the western side of Jandía a remote and imposing house - Villa Winter - looks out to sea across wide and generally empty beaches. It was reputedly built by a Mr Winter on land given by Generalisimo Franco. Despite being one of the most beautiful part of Fuerteventura Cofete has very little touristic facilities.
For a time, the beaches were home to a popular accidental attraction. On 18 January 1994 the once-beautiful and proud United States Lines ocean liner SS "American Star" (former "America", USS "West Point", "Australis") was beached in Playa de Garcey during a severe storm. Within a year, it broke in two and later lost its back half. By 2007 the rest of the severely deteriorated ship had collapsed onto its port side, gradually keeling over further and almost completely submerged. By 2008-2012, most of the remains finally slipped below the surface.
Food.
The cuisine is fairly basic due to the customs and climate conditions. They share this simplicity with the other Canary islands, and similarly to them, they use a large quantity of fish. They also use whatever they can grow in the near-barren land. This includes papas arrugadas, a dish of wrinkled potatoes usually served with mojo, which is a hot pepper sauce or with puchero canario, a meat stew.
Seafood is prepared in many ways traditionally, such as pejines (salted fish), jareas, or sancocho (a type of stew) made from fish, generally the grouper, corvina or sama, boiled after salting, and served with mojo, potatoes, or gofio (a type of grain). People are also very keen on the mussels and limpets collected on the island's coasts.
They also use meat such as beef and pork to make different dishes or simply to for braising, but their main meat is goat, both from the kids and from the older animals. They eat the goat roasted or stewed. Goats are not only useful for their meat - the Fuerteventurans also use the milk to make the cheese majorero, which has won many prizes. The majorero is mostly made of goats milk, and occasionally it is up to 15% ewes milk. It is cured in pimento oil or gofio meal. Majorero and palmero cheese are the only two Canarian cheeses with protected denomination of origin.
Sport.
Many sports are commonly played in Fuerteventura, both in the open air and in sports centres across the island.
Native sports.
These are the Canarian sports found on the island:
Canarian wrestling.
The wrestling takes place in a ring of sand called the "terrero". Inside it, the two contestants try to knock each other over. Fuerteventura has 14 terreros distributed through all the towns except Betancuria.
The island also has a school wrestling league organized by the council and a programme to promote this sport in clubs. Twelve wrestling schools participate in this, based in Antigua, Costa Calma, El Matorral, La Lajita, Lajares, Las Playitas, Morro Jable, Puerto del Rosario, Tefía, Tetir, Unión Sur and Villaverde.
Juego del Palo.
Juego del Palo is a Canarian martial art which literally translates as "game of the stick". It is played by two players both armed with sticks. They aim to defeat each other without making contact with their opponent's body. The origin of this game is unclear. All we know is that it is based on a method of combat used by the precolonial Canarian people.
Fuerteventura has the following Palo clubs:
Canarian boules.
This is a similar game to the French Pétanque which is actually played very little on the island, although there are a few teams and courts. Basically the game consists of scoring points by rolling a ball to get it as near as possible to an object called a "mingue" or "boliche". It is played on a rectangular sand or earth pitch which is long and wide.
Watersports.
The sea and climate conditions make the island the perfect place for a huge variety of watersports.
Surfing, windsurfing and kitesurfing.
Many types of surfing are popular on the island, including traditional surfing, windsurfing (where the board is propelled by a sail) and most recently kitesurfing. The island has many schools and courses dedicated to teaching these sports.
The sports where Fuerteventura has the most impact internationally are windsurfing and kitesurfing, mainly due to the International Windsurfing and Kiteboarding Championship. This has run since 1985 and is held at Playas de Sotavento in Pájara municipality. Many important wind and kitesurfing figures compete in this championship, such as the several-times world windsurfing champion Björn Dunkerbeck and Gisela Pulido, the very young kiteboarding champion from Tarifa.
Many Canarian windsurfers are on the Canarian Waveriders circuit, which has been based in Corralejo since 2005.
Diving.
Diving schools are just as frequent as surfing ones, all around the coast of Fuerteventura. Unlike the other islands of the archipelago, Fuerteventura has a shelf which at some points goes up to , making it an ideal place to practice this sport.
Two of the most useful points for diving are the coast off Playa del Matorral in the South, and the zone between Lobos Island and Corralejo in the north. It is here in Corralejo that the International Sea and Submarine Photography Festival takes places, known as Fimarsub Corralejo - Lobos. During the festival there are beginners' lessons, professional dives, lessons in underwater photography, screenings and other events related to the sport.
Swimming.
There are many swimming pools on the island but the most obvious place to swim is in the open sea. There is an annual swim from Lobos Island to Fuerteventura, held every year since 1999. The event attracts amateur swimmers from all over the Canaries and Spain, and also swimming professionals such as David Meca and Maarten Van der Weijden, the paralympist Jesús Collado Alarcón who won gold medals for 100m backstroke and butterfly in Athens 2004, and Xavi Torres Ramis, the paralympic champion in Barcelona '92, Sydney and Atlanta.
Sailing.
The island holds competitions involving different types of boat, such as the lateen and the Optimist. An interesting event is the Tour of Fuerteventura by Kayak, which is organised as a series of stages rather than a competition, and is an easy way to explore the island.
Fishing.
The most notable competition here is the Gran Tarajal Fishing Open.
Other sports.
Since 2004 the Marcha Ciclotourista has been held in La Oliva and the Criterium Ciclista has been held in Corralejo (also part of the La Oliva municipality) since 2005. Participants include Euskaltel-Euskadi, T-Mobile and a team from Orbea. These competitions have contributed to local interest in the sport and the first professional local team, the Fuerteventura-Canarias, was formed, initially run by Óscar Guerrero, director of Kaiku, although they have not competed for the past few seasons.
There are various motocross circuits on the island, including "Los Alares" in Antigua and "Isla de Fuerteventura" in Puerto del Rosario municipality. They hold regular trials, some of which form part of the Canarian Regional Motocross Championship. Throughout the year there are gravel rally races. Two are part of the Canarian Dirt Rally Championship. These are the Antiguan Rally and the La Oliva Rally.
The island's main football clubs are UD Pájara Playas de Jandía and CD Corralejo, who play in Group XII of the Spanish Tercera División.
The resort Playitas on the south coast is since around 2008 equipped with a swimming pool and has become a destination for triathlon training camps for Europeans. An annual race called Challenge Fuerteventura is held there on the half ironman distance.

</doc>
<doc id="11476" url="https://en.wikipedia.org/wiki?curid=11476" title="Fairmount, Indiana">
Fairmount, Indiana

Fairmount is a town in Fairmount Township, Grant County in the east central part of the U.S. state of Indiana. The population was 2,954 at the 2010 census. It is ninety kilometers (fifty-five miles) northeast of Indianapolis. Largely a bedroom community to its three thousand citizens, Fairmount is best known as the boyhood home of actor James Dean, who is buried there.
Geography.
Fairmount is located at (40.417702, −85.648942).
According to the 2010 census, Fairmount has a total area of , all land.
Demographics.
2010 census.
As of the census of 2010, there were 2,954 people, 1,241 households, and 837 families residing in the town. The population density was . There were 1,350 housing units at an average density of . The racial makeup of the town was 98.6% White, 0.1% African American, 0.2% Native American, 0.2% Asian, 0.2% from other races, and 0.7% from two or more races. Hispanic or Latino of any race were 0.9% of the population.
There were 1,241 households of which 31.2% had children under the age of 18 living with them, 48.6% were married couples living together, 14.1% had a female householder with no husband present, 4.8% had a male householder with no wife present, and 32.6% were non-families. 28.0% of all households were made up of individuals and 12% had someone living alone who was 65 years of age or older. The average household size was 2.38 and the average family size was 2.85.
The median age in the town was 40.3 years. 23.9% of residents were under the age of 18; 8.4% were between the ages of 18 and 24; 23.2% were from 25 to 44; 28% were from 45 to 64; and 16.5% were 65 years of age or older. The gender makeup of the town was 48.5% male and 51.5% female.
2000 census.
As of the census of 2000, there were 2,992 people, 1,226 households, and 859 families residing in the town. The population density was 2,033.0 people per square mile (785.9/km²). There were 1,325 housing units at an average density of 900.3 per square mile (348.0/km²). The racial makeup of the town was 98.30% White, 0.17% Black or African American, 0.70% Native American, 0.20% Asian, 0.07% from other races, and 0.57% from two or more races. Hispanic or Latino of any race were 0.43% of the population.
There were 1,226 households out of which 31.2% had children under the age of 18 living with them, 55.5% were married couples living together, 11.0% had a female householder with no husband present, and 29.9% were non-families. 26.5% of all households were made up of individuals and 12.5% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.91.
In the town the population was spread out with 25.2% under the age of 18, 8.2% from 18 to 24, 28.2% from 25 to 44, 24.3% from 45 to 64, and 14.1% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 90.5 males. For every 100 females age 18 and over, there were 90.0 males.
The median income for a household in the town was $33,843, and the median income for a family was $44,033. Males had a median income of $31,136 versus $23,041 for females. The per capita income for the town was $18,029. About 7.4% of families and 9.1% of the population were below the poverty line, including 11.8% of those under age 18 and 7.8% of those age 65 or over.
History.
The Fairmount area was settled in the 1830s mostly by Quakers from North Carolina. The town was laid out in 1850 and named for Fairmount Park in Philadelphia; it was formally incorporated in 1870.
After a large deposit of natural gas was found in 1887, Fairmount became part of the Indiana Gas Boom and a center of the glass industry for the rest of the 19th century. Shortly after the depletion of the gas in 1900 the automobile industry set up factories in the nearby large cities, and Fairmount became a bedroom community, restoring some of its lost prosperity.
In the 1940s, James Dean lived with an aunt and uncle, Ortense and Marcus Winslow on a farm north of Fairmount. He attended Fairmount High School, graduating in 1949. After his death in 1955, Dean was buried in Park Cemetery. In 1996, a small Memorial Park north of the town's business district was dedicated in his memory with a bronze bust by Hollywood artist Kenneth Kendall.
During the prosperity of the 1960s, Fairmount enjoyed a time of building with a new town hall, water works, post office and elementary school. At the end of the decade the local school district merged with a neighboring one, forming the Madison-Grant united school district. A new high school was built for this district, and Fairmount High School became a middle school. When a new junior high school was opened in 1986, the Fairmount High School building was permanently closed.
Fairmount was hit hard by the recession of 1980–1982, which brought the permanent loss of factory jobs and the failure of many farms, but rebounded later in the decade. Fairmount is still relatively prosperous despite the ill fortunes of nearby industrial cities and a steady loss of population.
In September 1988, The James Dean Gallery opened in a restored Victorian House on North Main Street. Over the years the Museum Exhibit has been toured by nearly 200,000 visitors who come from around the world to visit the hometown of James Dean. Also in 1988, English musician Morrissey filmed the music video for his single Suedehead; a song inspired by his lifelong admiration of Dean, in the town.
The annual James Dean Festival takes place during the last full weekend in September and includes a Custom & Hot Rod Car Show, The Grand Parade, Street Fair, Carnival Rides, Live Entertainment, a 1950s Dance Contest and the James Dean lookalike Contest.
On September 30 of each year there is a Memorial Service for James Dean at The Back Creek Friends Church, south of The Winslow Farm.
Education.
Madison-Grant United School Corporation operates public schools.
Schools serving Fairmount:

</doc>
<doc id="11477" url="https://en.wikipedia.org/wiki?curid=11477" title="Epistles to the Thessalonians">
Epistles to the Thessalonians

There are two Epistles to the Thessalonians in the Bible:

</doc>
<doc id="11478" url="https://en.wikipedia.org/wiki?curid=11478" title="Free verse">
Free verse

Free verse is an open form of poetry. It does not use consistent meter patterns, rhyme, or any other musical pattern. It thus tends to follow the rhythm of natural speech.
Prefatory.
Poets have explained that free verse is not totally free; 'its only freedom is from the tyrant demands of the metered line'. Free verse displays some elements of form. Most free verse, for example, self-evidently continues to observe a convention of the poetic line in some sense, at least in written representations, though retaining a potential degree of linkage. Donald Hall goes as far as to say that "the "form" of free verse is as binding and as liberating as the "form" of a rondeau", and T. S. Eliot wrote, "No verse is free for the man who wants to do a good job". 
Kenneth Allott the poet/critic said the adoption by some poets of vers libre arose from 'mere desire for novelty, the imitation of Whitman, the study of Jacobean dramatic blank verse, and the awareness of what French poets had already done to the Alexandrine in France'. The American critic John Livingston Lowes in 1916 observed 'Free verse may be written as very beautiful prose; prose may be written as very beautiful free verse. Which is which?'
Some poets have considered free verse restrictive in its own way. In 1922 Robert Bridges voiced his reservations in the essay 'Humdrum and Harum-Scarum.' Robert Frost later remarked that writing free verse was like "playing tennis without a net." William Carlos Williams said "being an art form, verse cannot be free in the sense of having no limitations or guiding principles". Yvor Winters, the poet/critic said "the free verse that is really verse, the best that is, of W.C. Williams, H. D., Marianne Moore, Wallace Stevens, and Ezra Pound is the antithesis of free"
Antecedents.
As the name "vers libre" suggests, this technique of using more irregular cadences is often said to be derived from the practices of 19th-century French poets such as Gustave Kahn and Jules Laforgue in his "Derniers vers" of 1890.Taupin, the USA based French poet/critic concluded that free verse and vers libre are not synonymous, since 'The French language tends to give equal weight to each spoken syllable, whereas English syllables vary in quantity according to whether stressed or unstressed'.
The sort of cadencing that we now recognize in free verse can be traced back at least as far as the Hebrew psalmist poetry of the Bible. By referring to it is possible to argue that free verse in English first appeared in the 1380s in the John Wycliffe translation of the Psalms and was repeated in different form in most biblical translations ever since. Walt Whitman, who based his long lines in "Leaves of Grass" on the phrasing of the King James Bible, influenced later American free verse practitioners, notably Allen Ginsberg. One form of free verse was employed by Christopher Smart in a long poem called Jubilate Agno, written sometime between 1759 and 1763 but not published until 1939.
Many poets of the Victorian era experimented with free verse. Christina Rossetti, Coventry Patmore, and T. E. Brown all wrote examples of rhymed but unmetered verse. Poems such as W. E. Henley's 'Discharged' (from his "In Hospital" sequence). Free verse in English was persuasively advocated by critic T. E. Hulme in his "A Lecture on Modern Poetry" (1908). Later in the preface to "Some Imagist Poets" 1916, he comments, 'Only the name is new, you will find something much like vers libre in Dryden's "Threnodia Augustalis"; a great deal of Milton's "Samson Agonistes"..and the oldest in Chaucer's "House of Fame".'
In France, a few pieces in Arthur Rimbaud's prose poem collection Illuminations were arranged in manuscript in lines, rather than prose and in the Netherlands, tachtiger (i.e. member of 1880s generation of innovative poets) Frederik van Eeden employed the form at least once (in his poem "Waterlelie" quot;water lily&quot).
Goethe (particularly in some early poems, such as "Prometheus") and Hölderlin used free verse occasionally, due in part to a misinterpretation of the meter used in Pindar's poetry; in Hölderlin's case, he also continued to write unmetered poems after discovering this error. The German poet Heinrich Heine made an important contribution to the development of free verse with 22 poems, written in two-poem cycles called 'Die Nordsee' (The North Sea) (written 1825-1826). These were first published in "Buch der Lieder" (Book of Songs) in 1827.
Form and structure.
Although free verse requires no meter, rhyme, or other traditional poetic techniques, a poet can still use them to create some sense of structure. A clear example of this can be found in Walt Whitman's poems, where he repeats certain phrases and uses commas to create both a rhythm and structure. 
Pattern and discipline is to be found in free verse: the internal pattern of sounds, the choice of exact words, and the effect of associations give free verse its beauty. With the Imagists free verse became a discipline and acquired status as a legitimate poetic form. Herbert Read however, noting that 'the Imagist Ezra Pound gave free verse its musical structure to an extent that parodoxically it was no longer free'.
Due to of a lack of predetermined form, free verse poems have the potential to take truly unique shapes. Unrestrained by traditional boundaries, Yvor Winters described this as 'attempts to widen experience by establishing 'abnormal' conventions', the poet possesses more license to express, and has more control over the development of the poem. This could allow for a more spontaneous and individualized product
Technically, free verse has been described as 'spaced prose', a mosaic of verse and prose experience.

</doc>
<doc id="11479" url="https://en.wikipedia.org/wiki?curid=11479" title="F. W. de Klerk">
F. W. de Klerk

Frederik Willem de Klerk (; born 18 March 1936) is a South African politician who served as the country's State President from September 1989 to May 1994. He was the seventh and last head of state of South Africa under the apartheid era. De Klerk was also leader of the National Party (which later became the New National Party) from February 1989 to September 1997.
De Klerk helped to broker the end of apartheid, South Africa's policies of racial segregation and discrimination, and supported the transformation of South Africa into a non-racial democracy by entering into the negotiations that resulted in all citizens having equal voting and other rights. He won the Félix Houphouët-Boigny Peace Prize in 1991, the Prince of Asturias Award in 1992 and the Nobel Peace Prize in 1993 along with Nelson Mandela for his role in the ending of apartheid.
He was one of the deputy presidents of South Africa during the presidency of Nelson Mandela until 1996, and is the most recent white South African and Afrikaner to have held the position. In 1997 he retired from active politics. He continues to remain active as a lecturer internationally. After the deaths of P.W. Botha in 2006 and Marais Viljoen in 2007, de Klerk is the last surviving State President of South Africa.
Background and early career.
The name "de Klerk" is derived from Le Clerc, Le Clercq, and de Clercq and is of French Huguenot origin (meaning "clergyman" or "literate" in old French). De Klerk noted that he is also of Dutch descent, with an Indian ancestor from the late 1600s or early 1700s. He is also said to be descended from the Khoi interpreter known as Krotoa or Eva.
De Klerk was born in Johannesburg, in the then Transvaal Province of the Union of South Africa, to Johannes "Jan" de Klerk and Hendrina Cornelia Coetzer – "her forefather was a Kutzer who stems from Austria". He came from a family environment in which the conservatism of traditional white South African politics was deeply ingrained. His paternal great-grandfather was Senator Johannes Cornelis "Jan" van Rooy. His aunt was married to NP Prime Minister J. G. Strijdom. In 1948, the year when the NP swept to power in whites-only elections on an apartheid platform, F. W. de Klerk's father, Johannes "Jan" de Klerk, became secretary of the NP in the Transvaal province and later rose to the positions of cabinet minister and President of the Senate, becoming interim State President in 1975. His brother Willem is a liberal newspaperman and one of the founders of the Democratic Party. De Klerk graduated from Monument High School in Krugersdorp. De Klerk graduated in 1958 from the Potchefstroom University with BA and LL.B degrees (the latter "cum laude"). Following graduation, de Klerk practised law in Vereeniging in the Transvaal. In 1959 he married Marike Willemse, with whom he had two sons and a daughter.
"F.W.", pronounced "eff-veer", as he became popularly known, was first elected to the House of Assembly in 1969 as the member for Vereeniging, and entered the cabinet in 1978. De Klerk had been offered a professorship of administrative law at Potchefstroom in 1972 but he declined the post because he was serving in Parliament. In 1978, he was appointed Minister of Posts and Telecommunications and Social Welfare and Pensions by Prime Minister Vorster. Under Prime Minister and later State President P. W. Botha, he held a succession of ministerial posts, including Posts and Telecommunications and Sports and Recreation (1978–1979), Mines, Energy and Environmental Planning (1979–1980), Mineral and Energy Affairs (1980–1982), Internal Affairs (1982–1985), and National Education and Planning (1984–1989). He became Transvaal provincial National Party leader in 1982. In 1985, he became chairman of the Minister's Council in the House of Assembly.
Ending apartheid.
For most of his career, de Klerk had a very conservative reputation. The NP's Transvaal branch was historically the most staunchly conservative wing of the party, and he supported continued segregation of universities while Minister of National Education. It thus came as a surprise when in 1989 he placed himself at the head of "verligte" ("enlightened") forces within the governing party who had come to believe that apartheid could not be maintained forever. This wing favoured beginning negotiations while there was still time to get reasonable terms.
P. W. Botha resigned as leader of the National Party after an apparent stroke, and de Klerk defeated Botha's preferred successor, finance minister Barend du Plessis, in the race to succeed him. A month later, the NP caucus nominated de Klerk as state president. Botha initially refused to resign, saying that he intended to serve out his full five-year term, which expired in 1990. He even hinted that he might run for re-election. However, after protracted negotiations, Botha agreed to resign after the September 1989 parliamentary elections and hand power to de Klerk. However, Botha abruptly resigned on 14 August, and de Klerk was named acting state president until 20 September, when he was elected to a full five-year term as state president.
In some of his first speeches after assuming the party leadership, he called for a non-racist South Africa and for negotiations about the country's future. A couple of months later, in February 1990, he suddenly lifted the bans on the African National Congress (ANC) and the Communist Party of South Africa, released Nelson Mandela and other political prisoners. In legislative terms, he enabled the gradual end of apartheid. De Klerk also opened the way for the negotiations of the government with the anti-apartheid-opposition about a new constitution for the country. Nevertheless, he was accused by Anthony Sampson of complicity in the violence between the ANC, the Inkatha Freedom Party and elements of the security forces. In "", Sampson accuses de Klerk of permitting his ministers to build their own criminal empires.
His presidency was dominated by the negotiation process, mainly between his NP government and the ANC, which led to the democratization of South Africa. In 1992, de Klerk held a whites-only referendum on ending apartheid, with the result being an overwhelming "yes" vote to continue negotiations to end apartheid. Nelson Mandela was distrustful of the role played by de Klerk in the negotiations, particularly as he believed that de Klerk was knowledgeable about 'third force' attempts to foment violence in the country and destabilize the negotiations.
In 1990, de Klerk gave orders to end South Africa's nuclear weapons programme; the process of nuclear disarmament was essentially completed in 1991. The existence of the programme was not officially acknowledged before 1993.
In 1993, de Klerk and Mandela were jointly awarded the Nobel Peace Prize for their work in ending apartheid. The awarding of the prize to de Klerk was controversial, especially in the light of de Klerk's reported admission that he ordered a massacre of supposed Azanian Peoples' Liberation Army fighters, including teenagers, shortly before going to Oslo in 1993. It appears that this massacre may form part of the basis for criminal charges that the Anti-Racism Action Forum is laying against de Klerk in early 2016. Further, de Klerk's role in the destabilization of the country during the negotiation process through the operation of a 'third force' came to the attention of the Truth and Reconciliation Commission, and was never ultimately clarified.
After the first universal elections in 1994, de Klerk became deputy president in the government of national unity under Nelson Mandela, a post he kept until 1996. In 1997 he resigned the leadership of the National Party and retired from politics.
Later life.
In 1996, de Klerk was offered the Harper Fellowship at Yale Law School. He later declined, citing protests at the university. De Klerk did, however, speak at Central Connecticut State University the day before his fellowship would have begun.
In 1998, de Klerk and his wife of 38 years, Marike de Klerk, were divorced following the discovery of his affair with Elita Georgiades, then the wife of Tony Georgiades, a Greek shipping tycoon who had allegedly given de Klerk and the NP financial support. Soon after his divorce, de Klerk and Georgiades were married. His divorce and remarriage scandalised conservative South African opinion, especially among the Calvinist Afrikaners. In 1999, his autobiography, "The Last Trek – A New Beginning", was published. In 2001, following the murder of his wife, the manuscript of her own autobiography, "A Place Where the Sun Shines Again", was submitted to De Klerk, who urged the publishers to suppress a chapter dealing with his infidelity.
In 1999, de Klerk established the pro-peace FW de Klerk Foundation of which he is the chairman. De Klerk is also chairman of the Global Leadership Foundation, headquartered in London, which he set up in 2004, an organisation which works to support democratic leadership, prevent and resolve conflict through mediation and promote good governance in the form of democratic institutions, open markets, human rights and the rule of law. It does so by making available, discreetly and in confidence, the experience of former leaders to today's national leaders. It is a not-for-profit organisation composed of former heads of government and senior governmental and international organisation officials who work closely with heads of government on governance-related issues of concern to them.
On 4 December 2001, Marike de Klerk was found stabbed and violently strangled to death in her Cape Town flat. De Klerk, who was on a brief visit to Stockholm, Sweden, to celebrate the 100-year anniversary of the Nobel Prize foundation, announced he would immediately return to mourn his dead ex-wife. The atrocity was reportedly condemned strongly by South African president Thabo Mbeki and Winnie Mandela, among others, who openly spoke in favour of Marike de Klerk. On 6 December 21-year-old security guard Luyanda Mboniswa was arrested for the murder. On 15 May 2003, he received two life sentences for murder, as well as three years for breaking into Marike de Klerk's apartment.
In 2004, de Klerk announced that he was quitting the New National Party and seeking a new political home after it was announced that the NNP would merge with the ruling ANC. That same year, while giving an interview to US journalist Richard Stengel, de Klerk was asked whether South Africa had turned out the way he envisioned it back in 1990. His response was: "There are a number of imperfections in the new South Africa where I would have hoped that things would be better, but on balance I think we have basically achieved what we set out to achieve. And if I were to draw balance sheets on where South Africa stands now, I would say that the positive outweighs the negative by far. There is a tendency by commentators across the world to focus on the few negatives which are quite negative, like how are we handling AIDS, like our role vis-à-vis Zimbabwe. But the positives – the stability in South Africa, the adherence to well-balanced economic policies, fighting inflation, doing all the right things in order to lay the basis and the foundation for sustained economic growth – are in place." In 2008, he repeated in a speech that "despite all the negatives facing South Africa, he is very positive about the country".
In 2006, he underwent surgery for a malignant tumour in his colon, discovered after an examination on 3 June. His condition deteriorated sharply, and he underwent a second operation after developing respiratory problems. On 13 June, it was announced that he was to undergo a tracheotomy. He recovered and on 11 September 2006 gave a speech at Kent State University Stark Campus.
In January 2007, de Klerk was a speaker promoting peace and democracy in the world at the "Towards a Global Forum on New Democracies" event in Taipei, Taiwan, along with other dignitaries including Poland's Lech Wałęsa and Taiwan's then president Chen Shui-Bian.
De Klerk is an Honorary Patron of the University Philosophical Society and Honorary Chairman of the Prague Society for International Cooperation. He has also received the Gold Medal for Outstanding Contribution to Public Discourse from the College Historical Society for his contribution to ending apartheid.
De Klerk is also a Member of the Advisory Board of the Global Panel Foundation based in Berlin, Copenhagen, New York, Prague, Sydney and Toronto – founded by the Dutch entrepreneur Bas Spuybroek in 1988, with the support of Dutch billionaire Frans Lurvink and former Dutch Foreign Minister Hans van den Broek. The Global Panel Foundation is known for its behind-the-scenes work in public policy and the annual presentation of the Hanno R. Ellenbogen Citizenship Award with the Prague Society for International Cooperation.
After the inauguration of Jacob Zuma as South Africa's president in May 2009, de Klerk said he is optimistic that Zuma and his government can "confound the prophets of doom".
In a BBC interview broadcast in April 2012, he said he lived in an all-white neighbourhood. He had five servants, three coloured and two black: "We are one great big family together; we have the best of relationships." About Nelson Mandela, he said, "When Mandela goes it will be a moment when all South Africans put away their political differences, will take hands, and will together honour maybe the biggest known South African that has ever lived."
Upon hearing of the death of Mandela, de Klerk said: "He was a great unifier and a very, very special man in this regard beyond everything else he did. This emphasis on reconciliation was his biggest legacy."
In 2015, de Klerk wrote to The Times newspaper in the UK criticising moves to remove a statue to Cecil Rhodes at Oriel College in Oxford. He was subsequently taken to task by activists who described it as 'ironic' that the last apartheid President should be defending one of the architects of apartheid. There have also been calls for him to be stripped of his Nobel Peace Prize.

</doc>
<doc id="11488" url="https://en.wikipedia.org/wiki?curid=11488" title="Furlong">
Furlong

A furlong is a measure of distance in imperial units and U.S. customary units equal to one-eighth of a mile, equivalent to 660 feet, 220 yards, 40 rods, or 10 chains. Using the international definition of the inch as exactly 25.4 millimetres, one furlong is 201.168 metres. However, the United States does not uniformly use this conversion ratio. Older ratios are in use for surveying purposes in some states, leading to variations in the length of the furlong of about two parts per million, or 0.4 millimetres ( inch). This variation is too small to have many practical consequences. Five furlongs are about 1.0 kilometre (1.00584 km is the exact value, according to the international conversion).
History.
The name "furlong" derives from the Old English words ' (furrow) and ' (long). Dating back at least to early Anglo-Saxon times, it originally referred to the length of the furrow in one acre of a ploughed open field (a medieval communal field which was divided into strips). The system of long furrows arose because turning a team of oxen pulling a heavy plough was difficult. This offset the drainage advantages of short furrows and meant furrows were made as long as possible. An acre is an area that is one furlong long and one chain (66 feet or 22 yards) wide. For this reason, the furlong was once also called an acre's length, though in modern usage an area of one acre can be of any shape. The term furlong, or shot, was also used to describe a grouping of adjacent strips within an open field.
Among the early Anglo-Saxons, the rod was the fundamental unit of land measurement. A furlong was forty rods, an acre four by 40 rods, or four rods by one furlong. and thus 160 square rods. At the time, the Saxons used the North German foot, which was 10 percent longer than the foot of today. When England changed to the shorter foot in the late 13th century, rods and furlongs remained unchanged, since property boundaries were already defined in rods and furlongs. The only thing that changed was the number of feet and yards in a rod or a furlong, and the number of square feet and square yards in an acre. The definition of the rod went from 15 old feet to new feet, or from 5 old yards to new yards. The furlong went from 600 old feet to 660 new feet, or from 200 old yards to 220 new yards. The acre went from 36,000 old square feet to 43,560 new square feet, or from 4,000 old square yards to 4,840 new square yards.
The furlong was historically viewed as being equivalent to the Roman stade ("stadium"), which in turn derived from the Greek system. For example, the King James Bible uses the term "furlong" in place of the Greek "stadion", although more recent translations often use miles or kilometres in the main text and give the original numbers in footnotes.
In the Roman system, there were 625 feet to the "stadium", eight "stadia" to the mile, and three miles to the league. A league was considered to be the distance a man could walk in one hour, and the mile (from "mille", "meaning thousand") consisted of 1,000 "passus" (paces, five feet, or double-step).
After the fall of the Roman Empire, medieval Europe continued with the Roman system, which the people proceeded to diversify, leading to serious complications in trade, taxation, etc. Around the year 1300, by royal decree England standardized a long list of measures. Among the important units of distance and length at the time were the foot, yard, rod(or pole), furlong, and the mile. The rod was defined as yards or feet, and the mile was eight furlongs, so the definition of the furlong became 40 rods and that of the mile became 5,280 feet (eight furlongs/mile times 40 rods/furlong times feet/rod).
A description from 1675 states, "Dimensurator or Measuring Instrument whereof the mosts usual has been the Chain, and the common length for English Measures four Poles, as answering indifferently to the Englishs Mile and Acre, 10 such Chains in length making a Furlong, and 10 single square Chains an Acre, so that a square Mile contains 640 square Acres." —John Ogilby, Britannia, 1675
The official use of the furlong was abolished in the United Kingdom under the Weights and Measures Act 1985, an act that also abolished the official use of many other traditional units of measurement.
Use.
In Myanmar, furlongs are currently used in conjunction with miles to indicate distances on highway signs. Mileposts on the Yangon-Mandalay Expressway use miles and furlongs.
In the rest of the world, the furlong has very limited use, with the notable exception of horse racing in most English-speaking countries, including Canada and the United States. The distances for horse-racing in Australia were converted to metric in 1972; but, in the United Kingdom, Ireland, Canada, and the United States, races are still given in miles and furlongs.
The city of Chicago's street numbering system allots a measure of 800 address units to each mile, in keeping with the city's system of eight blocks per mile. This means that every block in a typical Chicago neighborhood (in either North/South or East/West direction but rarely both) is approximately one furlong in length. Salt Lake City's blocks are also each a square furlong in the downtown area. The blocks become less regular in shape further from the center, but the numbering system (800 units to each mile) remains the same everywhere in Salt Lake County. Bus stops in Ann Arbor, Michigan, are about a furlong apart. Blocks in central Logan, Utah, and in large sections of Phoenix, Arizona, are similarly a square furlong in extent (eight to a mile, which explains the series of freeway exits: 19th Ave, 27th, 35th, 43rd, 51st, 59th ...). City blocks in the Hoddle Grid of Melbourne are also one furlong in length.
Much of Ontario, Canada, was originally surveyed on a ten-furlong grid, with major roads being laid out along the grid lines. Now that distances are shown on road signs in kilometres, it is obvious that these major roads are almost exactly two kilometres apart. The exits on highways running through Toronto, for example, are generally at intervals of two kilometres.
The furlong is also a base unit of the humorous FFF system of units.
Conversion to SI units.
The exact conversion of the furlong to SI units varies slightly among English-speaking countries. In Canada and the United Kingdom,
which define the furlong in terms of the international yard of exactly 0.9144 metres, a furlong is 201.168 m.
Australia does not formally define the furlong, but it does define the chain and link in terms of the international yard.
In the United States, which defines the furlong, chain, rod, and link in terms of the U.S. survey foot of exactly metre, a furlong is approximately 201.1684 m long. The United States does not formally define a "survey yard". The difference of approximately two parts per million between the U.S. value and the "international" value is insignificant for most practical measurements.

</doc>
<doc id="11489" url="https://en.wikipedia.org/wiki?curid=11489" title="File">
File

File or filing may refer to:

</doc>
<doc id="11490" url="https://en.wikipedia.org/wiki?curid=11490" title="Fundamental frequency">
Fundamental frequency

The fundamental frequency, often referred to as simply as the fundamental, is defined as the lowest frequency of a periodic waveform. In music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present. In terms of a superposition of sinusoids (e.g. Fourier series), the fundamental frequency is the lowest frequency sinusoidal in the sum. In some contexts, the fundamental is usually abbreviated as f" (or FF), indicating the lowest frequency counting from zero. In other contexts, it is more common to abbreviate it as f", the first harmonic. (The second harmonic is then f = 2⋅f, etc. In this context, the zeroth harmonic would be 0 Hz.)
Explanation.
All sinusoidal and many non-sinusoidal waveforms are periodic, which is to say they repeat exactly over time. A single period is thus the smallest repeating unit of a signal, and one period describes the signal completely. We can show a waveform is periodic by finding some period "T" for which the following equation is true:
Where "x"("t") is the function of the waveform.
This means that for multiples of some period T the value of the signal is always the same. The largest possible value of T for which this is true is called the fundamental period and the fundamental frequency ("f") is:
Where "f" is the fundamental frequency and "T" is the fundamental period.
For a tube of length "L" with one end closed and the other end open the wavelength of the fundamental harmonic is 4"L", as indicated by the top two animations on the right. Hence,
Therefore, using the relation
where "v" is the speed of the wave, we can find the fundamental frequency in terms of the speed of the wave and the length of the tube:
If the ends of the same tube are now both closed or both opened as in the bottom two animations on the right, the wavelength of the fundamental harmonic becomes 2"L". By the same method as above, the fundamental frequency is found to be
At 20 °C (68 °F) the speed of sound in air is 343 m/s (1129 ft/s). This speed is temperature dependent and does increase at a rate of 0.6 m/s for each degree Celsius increase in temperature (1.1 ft/s for every increase of 1 °F).
The velocity of a sound wave at different temperatures:-
In music.
In music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present. The fundamental may be created by vibration over the full length of a string or air column, or a higher harmonic chosen by the player. The fundamental is one of the harmonics. A harmonic is any member of the harmonic series, an ideal set of frequencies that are positive integer multiples of a common fundamental frequency. The reason a fundamental is also considered a harmonic is because it is 1 times itself.
The fundamental is the frequency at which the entire wave vibrates. Overtones are other sinusoidal components present at frequencies above the fundamental. All of the frequency components that make up the total waveform, including the fundamental and the overtones, are called partials. Together they form the harmonic series. Overtones which are perfect integer multiples of the fundamental are called harmonics. When an overtone is near to being harmonic, but not exact, it is sometimes called a harmonic partial, although they are often referred to simply as harmonics. Sometimes overtones are created that are not anywhere near a harmonic, and are just called partials or inharmonic overtones.
The fundamental frequency is considered the "first harmonic" and the "first partial." The numbering of the partials and harmonics is then usually the same; the second partial is the second harmonic, etc. But if there are inharmonic partials, the numbering no longer coincides. Overtones are numbered as they appear "above" the fundamental. So strictly speaking, the "first" overtone is the "second" partial (and usually the "second" harmonic). As this can result in confusion, only harmonics are usually referred to by their numbers, and overtones and partials are described by their relationships to those harmonics.
Mechanical systems.
Consider a spring, fixed at one end and having a mass attached to the other; this would be a single degree of freedom (SDoF) oscillator. Once set into motion it will oscillate at its natural frequency. For a single degree of freedom oscillator, a system in which the motion can be described by a single coordinate, the natural frequency depends on two system properties: mass and stiffness; (providing the system is undamped). The radian frequency, "ω", can be found using the following equation:
Where:
"k" = stiffness of the spring
"m" = mass 
"ω" = radian frequency (radians per second)
From the radian frequency, the natural frequency, "f", can be found by simply dividing "ω" by 2"π". Without first finding the radian frequency, the natural frequency can be found directly using:
Where:
"f" = natural frequency in hertz (cycles/second)
"k" = stiffness of the spring (Newtons/meter or N/m)
"m" = mass(kg) 
while doing the modal analysis of structures and mechanical equipment, the frequency of 1st mode is called fundamental frequency.

</doc>
<doc id="11491" url="https://en.wikipedia.org/wiki?curid=11491" title="Fable">
Fable

Fable is a literary genre: a succinct fictional story, in prose or verse, that features animals, mythical creatures, plants, inanimate objects, or forces of nature that are anthropomorphized (given human qualities, such as verbal communication) and that illustrates or leads to an interpretation of a moral lesson (a "moral"), which may at the end be added explicitly as a pithy maxim.
A fable differs from a parable in that the latter "excludes" animals, plants, inanimate objects, and forces of nature as actors that assume speech or other powers of humankind.
Usage has not always been so clearly distinguished. In the King James Version of the New Testament, " ("mythos"") was rendered by the translators as "fable" in the First Epistle to Timothy, the Second Epistle to Timothy, the Epistle to Titus and the First Epistle of Peter.
A person who writes fables is a fabulist.
History.
The fable is one of the most enduring forms of folk literature, spread abroad, modern researchers agree, less by literary anthologies than by oral transmission. Fables can be found in the literature of almost every country.
Aesopic or Aesop's fable.
The varying corpus denoted "Aesopica" or "Aesop's Fables" includes most of the best-known western fables, which are attributed to the legendary Aesop, supposed to have been a slave in ancient Greece around 550 BC. When Babrius set down fables from the "Aesopica" in verse for a Hellenistic Prince "Alexander," he expressly stated at the head of Book II that this type of "myth" that Aesop had introduced to the "sons of the Hellenes" had been an invention of "Syrians" from the time of "Ninos" (personifying Nineveh to Greeks) and Belos ("ruler"). Epicharmus of Kos and Phormis are reported as having been among the first to invent comic fables. Many familiar fables of Aesop include "The Crow and the Pitcher", "The Tortoise and the Hare" and "The Lion and the Mouse". In ancient Greek and Roman education, the fable was the first of the "progymnasmata"—training exercises in prose composition and public speaking—wherein students would be asked to learn fables, expand upon them, invent their own, and finally use them as persuasive examples in longer forensic or deliberative speeches. The need of instructors to teach, and students to learn, a wide range of fables as material for their declamations resulted in their being gathered together in collections, like those of Aesop.
Africa.
African oral culture has a rich story-telling tradition. As they have for thousands of years, people of all ages in Africa continue to interact with nature, including plants, animals and earthly structures such as rivers, plains and mountains. Grandparents enjoy enormous respect in African societies and fill the new role of story-telling during retirement years. Children and, to some extent, adults are mesmerized by good story-tellers when they become animated in their quest to tell a good fable.
India.
India has a rich tradition of fabulous novels, mostly explainable by the fact that the culture derives traditions and learns qualities from natural elements. Most of the gods are some form of animals with ideal qualities. Also hundreds of fables were composed in ancient India during the first millennium BC, often as stories within frame stories. Indian fables have a mixed cast of humans and animals. The dialogues are often longer than in fables of Aesop and often witty as the animals try to outwit one another by trickery and deceit. In Indian fables, man is not superior to the animals. The tales are often comical. The Indian fable adhered to the universally known traditions of the fable.
The best examples of the fable in India are the Panchatantra and the Jataka Tales. These included Vishnu Sarma's "Panchatantra", the "Hitopadesha", "Vikram and The Vampire", and Syntipas' "Seven Wise Masters", which were collections of fables that were later influential throughout the Old World. Ben E. Perry (compiler of the "Perry Index" of Aesop's fables)has argued controversially that some of the Buddhist "Jataka tales" and some of the fables in the "Panchatantra" may have been influenced by similar Greek and Near Eastern ones. Earlier Indian epics such as Vyasa's "Mahabharata" and Valmiki's "Ramayana" also contained fables within the main story, often as side stories or back-story. The most famous fables from the Middle East were the "One Thousand and One Nights", also known as the "Arabian Nights".
Europe.
Fables had a further long tradition through the Middle Ages, and became part of European high literature. During the 17th century, the French fabulist Jean de La Fontaine (1621–1695) saw the soul of the fable in the moral — a rule of behavior. Starting with the Aesopian pattern, La Fontaine set out to satirize the court, the church, the rising bourgeoisie, indeed the entire human scene of his time. La Fontaine's model was subsequently emulated by England's John Gay (1685–1732); Poland's Ignacy Krasicki (1735–1801); Italy's (1739–1812) and (1754–1827); Serbia's Dositej Obradović (1742–1811); Spain's Félix María de Samaniego (1745–1801) and Tomás de Iriarte y Oropesa (1750–1791); France's Jean-Pierre Claris de Florian (1755–94); and Russia's Ivan Krylov (1769–1844).
Modern era.
In modern times, while the fable has been trivialized in children's books, it has also been fully adapted to modern adult literature. Felix Salten's "Bambi" (1923) is a "Bildungsroman" — a story of a protagonist's coming-of-age — cast in the form of a fable. James Thurber used the ancient fable style in his books "Fables for Our Time" (1940) and "Further Fables for Our Time" (1956), and in his stories "The Princess and the Tin Box" in "The Beast in Me and Other Animals" (1948) and "The Last Clock: A Fable for the Time, Such As It Is, of Man" in "Lanterns and Lances" (1961). Władysław Reymont's "The Revolt" (1922), a metaphor for the Bolshevik Revolution of 1917, described a revolt by animals that take over their farm in order to introduce "equality." George Orwell's "Animal Farm" (1945) similarly satirized Stalinist Communism in particular, and totalitarianism in general, in the guise of animal fable.
In the 21st century the Neapolitan writer Sabatino Scia is the author of more than two hundred fables, that he describes as “western protest fables.” The characters are not only animals, but also Things, Beings and Elements from nature. Scia’s aim is the same as in the traditional fable, playing the role of revealer of human society.
In Latin America, the brothers Juan and Victor Ataucuri Garcia have contributed to the resurgence of the fable. But they do so with a novel idea: use the fable as a means of dissemination of traditional literature of that place. In the book "Peruvian Fables" published in 2003, they have collected myths, legends, beliefs Andean and Amazonian Peru, to write as fables. The result has been an extraordinary work rich in regional nuances. Here we discover the relationship between man and his origin, with nature, with its history, its customs and beliefs then become norms and values.

</doc>
<doc id="11492" url="https://en.wikipedia.org/wiki?curid=11492" title="Foot">
Foot

The foot (plural feet) is an anatomical structure found in many vertebrates. It is the terminal portion of a limb which bears weight and allows locomotion. In many animals with feet, the foot is a separate organ at the terminal part of the leg made up of one or more segments or bones, generally including claws or nails.
Structure.
The human foot is a strong and complex mechanical structure containing 26 bones, 33 joints (20 of which are actively articulated), and more than a hundred muscles, tendons, and ligaments. The joints of the foot are the ankle and subtalar joint and the interphalangeal articulations of the foot.
An anthropometric study of 1197 North American adult Caucasian males (mean age 35.5 years) found that a man's foot length was 26.3 cm with a standard deviation of 1.2 cm.
The foot can be subdivided into the hindfoot, the midfoot, and the forefoot:
The "hindfoot" is composed of the talus (or ankle bone) and the calcaneus (or heel bone). The two long bones of the lower leg, the tibia and fibula, are connected to the top of the talus to form the ankle. Connected to the talus at the subtalar joint, the calcaneus, the largest bone of the foot, is cushioned underneath by a layer of fat.
The five irregular bones of the "midfoot", the cuboid, navicular, and three cuneiform bones, form the arches of the foot which serves as a shock absorber. The midfoot is connected to the hind- and fore-foot by muscles and the plantar fascia.
The "forefoot" is composed of five toes and the corresponding five proximal long bones forming the metatarsus. Similar to the fingers of the hand, the bones of the toes are called phalanges and the big toe has two phalanges while the other four toes have three phalanges. The joints between the phalanges are called interphalangeal and those between the metatarsus and phalanges are called metatarsophalangeal (MTP).
Both the midfoot and forefoot constitute the "dorsum" (the area facing upwards while standing) and the "planum" (the area facing downwards while standing).
The "instep" is the arched part of the foot between the toes and the ankle.
There can be many sesamoid bones near the metatarsophalangeal joints, although they are only regularly present in the distal portion of the first metatarsal bone.
Arches.
The human foot has two longitudinal arches and a transverse arch maintained by the interlocking shapes of the foot bones, strong ligaments, and pulling muscles during activity. The slight mobility of these arches when weight is applied to and removed from the foot makes walking and running more economical in terms of energy. As can be examined in a footprint, the medial longitudinal arch curves above the ground. This arch stretches from the heel bone over the "keystone" ankle bone to the three medial metatarsals. In contrast, the lateral longitudinal arch is very low. With the cuboid serving as its keystone, it redistributes part of the weight to the calcaneus and the distal end of the fifth metatarsal. The two longitudinal arches serve as pillars for the transverse arch which run obliquely across the tarsometatarsal joints. Excessive strain on the tendons and ligaments of the feet can result in fallen arches or flat feet.
Muscles.
The muscles acting on the foot can be classified into extrinsic muscles, those originating on the anterior or posterior aspect of the lower leg, and intrinsic muscles, originating on the dorsal (top) or plantar (base) aspects of the foot.
Extrinsic.
All muscles originating on the lower leg except the popliteus muscle are attached to the bones of the foot. The tibia and fibula and the interosseous membrane separate these muscles into anterior and posterior groups, in their turn subdivided into subgroups and layers.
"Anterior group"
"Extensor group": tibialis anterior originates on the proximal half of the tibia and the interosseous membrane and is inserted near the tarsometatarsal joint of the first digit. In the non-weight-bearing leg tibialis anterior flexes the foot dorsally and lift its medial edge (supination). In the weight-bearing leg it brings the leg towards the back of the foot, like in rapid walking. Extensor digitorum longus arises on the lateral tibial condyle and along the fibula to be inserted on the second to fifth digits and proximally on the fifth metatarsal. The extensor digitorum longus acts similar to the tibialis anterior except that it also dorsiflexes the digits. Extensor hallucis longus originates medially on the fibula and is inserted on the first digit. As the name implies it dorsiflexes the big toe and also acts on the ankle in the unstressed leg. In the weight-bearing leg it acts similar to the tibialis anterior.
"Peroneal group": peroneus longus arises on the proximal aspect of the fibula and peroneus brevis below it on the same bone. Together, their tendons pass behind the lateral malleolus. Distally, peroneus longus crosses the plantar side of the foot to reach its insertion on the first tarsometatarsal joint, while peroneus brevis reaches the proximal part of the fifth metatarsal. These two muscles are the strongest pronators and aid in plantar flexion. Longus also acts like a bowstring that braces the transverse arch of the foot.
"Posterior group"
The "superficial layer" of posterior leg muscles is formed by the triceps surae and the plantaris. The triceps surae consists of the soleus and the two heads of the gastrocnemius. The heads of gastrocnemius arise on the femur, proximal to the condyles, and soleus arises on the proximal dorsal parts of the tibia and fibula. The tendons of these muscles merge to be inserted onto the calcaneus as the Achilles tendon. Plantaris originates on the femur proximal to the lateral head of the gastrocnemius and its long tendon is embedded medially into the Achilles tendon. The triceps surae is the primary plantar flexor and its strength becomes most obvious during ballet dancing. It is fully activated only with the knee extended because the gastrocnemius is shortened during knee flexion. During walking it not only lifts the heel, but also flexes the knee, assisted by the plantaris.
In the "deep layer" of posterior muscles tibialis posterior arises proximally on the back of the interosseous membrane and adjoining bones and divides into two parts in the sole of the foot to attach to the tarsus. In the non-weight-bearing leg, it produces plantar flexion and supination, and, in the weight-bearing leg, it proximates the heel to the calf. flexor hallucis longus arises on the back of the fibula (i.e. on the lateral side), and its relatively thick muscle belly extends distally down to the flexor retinaculum where it passes over to the medial side to stretch across the sole to the distal phalanx of the first digit. The popliteus is also part of this group, but, with its oblique course across the back of the knee, does not act on the foot.
Intrinsic.
On the "back" (top) "of the foot", the tendons of extensor digitorum brevis and extensor hallucis brevis lie deep to the system of long extrinsic extensor tendons. They both arise on the calcaneus and extend into the dorsal aponeurosis of digits one to four, just beyond the penultimate joints. They act to dorsiflex the digits.
Similar to the intrinsic muscles of the hand, there are three groups of muscles in the "sole of foot", those of the first and last digits, and a central group:
"Muscles of the big toe": abductor hallucis stretches medially along the border of the sole, from the calcaneus to the first digit. Below its tendon, the tendons of the long flexors pass through the tarsal canal. It is an abductor and a weak flexor, and also helps maintain the arch of the foot. flexor hallucis brevis arises on the medial cuneiform bone and related ligaments and tendons. An important plantar flexor, it is crucial for ballet dancing. Both these muscles are inserted with two heads proximally and distally to the first metatarsophalangeal joint. Adductor hallucis is part of this group, though it originally formed a separate system (see contrahens.) It has two heads, the oblique head originating obliquely across the central part of the midfoot, and the transverse head originating near the metatarsophalangeal joints of digits five to three. Both heads are inserted into the lateral sesamoid bone of the first digit. Adductor hallucis acts as a tensor of the plantar arches and also adducts the big toe and then might plantar flex the proximal phalanx.
"Muscles of the little toe": Stretching laterally from the calcaneus to the proximal phalanx of the fifth digit, abductor digiti minimi form the lateral margin of the foot and is the largest of the muscles of the fifth digit. Arising from the base of the fifth metatarsal, flexor digiti minimi is inserted together with abductor on the first phalanx. Often absent, opponens digiti minimi originates near the cuboid bone and is inserted on the fifth metatarsal bone. These three muscles act to support the arch of the foot and to plantar flex the fifth digit.
"Central muscle group": The four lumbricals arise on the medial side of the tendons of flexor digitorum longus and are inserted on the medial margins of the proximal phalanges. Quadratus plantae originates with two slips from the lateral and medial margins of the calcaneus and inserts into the lateral margin of the flexor digitorum tendon. It is also known as flexor accessorius. Flexor digitorum brevis arise inferiorly on the calcaneus and its three tendons are inserted into the middle phalanges of digits two to four (sometimes also the fifth digit). These tendons divide before their insertions and the tendons of flexor digitorum longus pass through these divisions. Flexor digitorum brevis flexes the middle phalanges. It is occasionally absent. Between the toes, the dorsal and plantar interossei stretch from the metatarsals to the proximal phalanges of digits two to five. The plantar interossei adducts and the dorsal interossei abducts these digits and are also plantar flexors at the metatarsophalangeal joints.
Clinical significance.
Due to their position and function, feet are exposed to a variety of potential infections and injuries, including athlete's foot, bunions, ingrown toenails, Morton's neuroma, plantar fasciitis, plantar warts and stress fractures. In addition, there are several genetic disorders that can affect the shape and function of the feet, including a club foot or flat feet.
This leaves humans more vulnerable to medical problems that are caused by poor leg and foot alignments. Also, the wearing of shoes, sneakers and boots can impede proper alignment and movement within the ankle and foot. For example, High-heeled footwear are known to throw off the natural weight balance (this can also affect the lower back). For the sake of posture, flat soles with no heels are advised.
A doctor who specializes in the treatment of the feet practices podiatry and is called a podiatrist. A pedorthist specializes in the use and modification of footwear to treat problems related to the lower limbs.
Fractures of the foot include:
Foot sweat is the major cause of foot odor. Sweat itself is odorless, but it creates a beneficial environment for certain bacteria to grow and produce bad-smelling substances.
Pronation.
In anatomy, pronation is a rotational movement of the forearm (at the radioulnar joint) or foot (at the subtalar and talocalcaneonavicular joints). Pronation of the foot refers to how the body distributes weight as it cycles through the gait. During the gait cycle the foot can pronate in many different ways based on rearfoot and forefoot function. Types of pronation include neutral pronation, underpronation (supination), and overpronation.
An individual who neutrally pronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will roll in a medial direction, such that the weight is distributed evenly across the metatarsus. In this stage of the gait, the knee will generally, but not always, track directly over the hallux.
This rolling inwards motion as the foot progresses from heel to toe is the way that the body naturally absorbs shock. Neutral pronation is the most ideal, efficient type of gait when using a heel strike gait; in a forefoot strike, the body absorbs shock instead via flexation of the foot.
As with a neutral pronator, an individual who overpronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, however, the foot will roll too far in a medial direction, such that the weight is distributed unevenly across the metatarsus, with excessive weight borne on the hallux. In this stage of the gait, the knee will generally, but not always, track inwards.
An overpronator does not absorb shock efficiently. Imagine someone jumping onto a diving board, but the board is so flimsy that when it is struck, it bends and allows the person to plunge straight down into the water instead of back into the air. Similarly, an overpronator's arches will collapse, or the ankles will roll inwards (or a combination of the two) as they cycle through the gait. An individual whose bone structure involves external rotation at the hip, knee, or ankle will be more likely to overpronate than one whose bone structure has internal rotation or central alignment. An individual who overpronates tends to wear down their running shoes on the medial (inside) side of the shoe towards the toe area.
When choosing a running or walking shoe, a person with overpronation can choose shoes that have good inside support—usually by strong material at the inside sole and arch of the shoe. It is usually visible. The inside support area is marked by strong greyish material to support the weight when a person lands on the outside foot and then roll onto the inside foot.
An individual who underpronates also initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will not roll far enough in a medial direction. The weight is distributed unevenly across the metatarsus, with excessive weight borne on the fifth metatarsal, towards the lateral side of the foot. In this stage of the gait, the knee will generally, but not always, track laterally of the hallux.
Like an overpronator, an underpronator does not absorb shock efficiently – but for the opposite reason. The underpronated foot is like a diving board that, instead of failing to spring someone in the air because it is too flimsy, fails to do so because it is too rigid. There is virtually no give. An underpronator's arches or ankles don't experience much motion as they cycle through the gait. An individual whose bone structure involves internal rotation at the hip, knee, or ankle will be more likely to underpronate than one whose bone structure has external rotation or central alignment. Usually – but not always – those who are bow-legged tend to underpronate. An individual who underpronates tends to wear down their running shoes on the lateral (outside) side of the shoe towards the rear of the shoe in the heel area.
Society and culture.
Humans usually wear shoes or similar footwear for protection from hazards when walking outside. There are a number of contexts where it is considered inappropriate to wear shoes. Some people consider it rude to wear shoes into a house and a Māori Marae should only be entered with bare feet.
Foot fetishism is the most common form of sexual fetish.
Other animals.
A paw is the soft foot of a mammal, generally a quadruped, that has claws or nails. A hard foot is called a hoof.
Depending on style of locomotion, animals can be classified as plantigrade (sole walking), digitigrade (toe walking), or unguligrade (nail walking).
The metatarsals are the bones that make up the main part of the foot in humans, and part of the leg in large animals or paw in smaller animals. The number of metatarsals are directly related to the mode of locomotion with many larger animals having their digits reduced to two (elk, cow, sheep) or one (horse). The metatarsal bones of feet and paws are tightly grouped compared to, most notably, the human hand where the thumb metacarpal diverges from the rest of the metacarpus.

</doc>
<doc id="11493" url="https://en.wikipedia.org/wiki?curid=11493" title="Fallout shelter">
Fallout shelter

A fallout shelter is an enclosed space specially designed to protect occupants from radioactive debris or fallout resulting from a nuclear explosion. Many such shelters were constructed as civil defense measures during the Cold War.
During a nuclear explosion, matter vaporized in the resulting fireball is exposed to neutrons from the explosion, absorbs them, and becomes radioactive. When this material condenses in the rain, it forms dust and light sandy materials that resembles ground pumice. The fallout emits alpha and beta particles, as well as gamma rays.
Much of this highly radioactive material falls to earth, subjecting anything within the line of sight to radiation, becoming a significant hazard. A fallout shelter is designed to allow its occupants to minimize exposure to harmful fallout until radioactivity has decayed to a safer level.
History.
During the Cold War, many countries built fallout shelters for high-ranking government officials and crucial military facilities, such as Project Greek Island and Cheyenne Mountain nuclear bunker in the United States and Canada's Emergency Government Headquarters. Plans were made, however, to use existing buildings with sturdy below-ground-level basements as makeshift fallout shelters. These buildings were usually placarded with the yellow and black trefoil sign.
The National Emergency Alarm Repeater (NEAR) program was developed in the United States 1956 during the Cold War to supplement the existing siren warning systems and radio broadcasts in the event of a nuclear attack. The N.E.A.R. civilian alarm device was engineered and tested but the program was not viable and was terminated in 1967. In the U.S. in September 1961, under the direction of Steuart L. Pittman, the federal government started the Community Fallout Shelter Program. A letter from President Kennedy advising the use of fallout shelters appeared in the September 1961 issue of "Life" magazine.
In November 1961, in "Fortune" magazine, an article by Gilbert Burck appeared that outlined the plans of Nelson Rockefeller, Edward Teller, Herman Kahn, and Chet Holifield for an enormous network of concrete lined underground fallout shelters throughout the United States sufficient to shelter millions of people to serve as a refuge in case of nuclear war.
Similar projects have been undertaken in Finland, which requires all buildings with area over 600 m² to have an NBC shelter, and Norway, which requires all buildings with an area over 1000 m² to have a shelter.
The former Soviet Union and other Eastern Bloc countries often designed their underground mass-transit and subway tunnels to serve as bomb and fallout shelters in the event of an attack.
Germany has protected shelters for 3% of its population, Austria for 30%, Finland for 70%, Sweden for 81% and Switzerland for 114%.
Switzerland.
Switzerland built an extensive network of fallout shelters, not only through extra hardening of government buildings such as schools, but also through a building regulation requiring nuclear shelters in residential buildings since the 1960s (the first legal basis in this sense dates from 4 October 1963). Later, the law ensured that all residential building built after 1978 contained a nuclear shelter able to withstand a blast from a 12 megaton explosion at a distance of 700 metres. The "Federal Law on the Protection of the Population and Civil Protection" still requires nowadays that every inhabitant should have a place in a shelter close to where they live. 
The Swiss authorities also maintain large communal shelters (such as the Sonnenberg Tunnel) stocked with over four months of food and fuel. The reference "Nuclear War Survival Skills" declared that, as of 1986, "Switzerland has the best civil defense system, one that already includes blast shelters for over 85 percent of all its citizens." As of 2006, there were about 300,000 shelters built in private homes, institutions and hospitals, as well as 5,100 public shelters for a total of 8.6 million places, a level of coverage equal to 114% of the population. 
In Switzerland, most residential shelters are no longer stocked with the food and water required for prolonged habitation and a large number have been converted by the owners to other uses (e.g., wine cellars, ski rooms, gyms). But the owner still has the obligation to ensure the maintenance of the shelter.
Details of shelter construction.
Shielding.
A basic fallout shelter consists of shields that reduce gamma ray exposure by a factor of 1000. The required shielding can be accomplished with 10 times the thickness of any quantity of material capable of cutting gamma ray exposure in half. Shields that reduce gamma ray intensity by 50% (1/2) include 1 cm (0.4 inch) of lead, 6 cm (2.4 inches) of concrete, 9 cm (3.6 inches) of packed earth or 150 m (500 ft) of air. When multiple thicknesses are built, the shielding multiplies. Thus, a practical fallout shield is ten halving-thicknesses of packed earth, reducing gamma rays by approximately 1024 times (2).
Usually, an expedient purpose-built fallout shelter is a trench; with a strong roof buried by c. 1 m (3 ft) of earth. The two ends of the trench have ramps or entrances at right angles to the trench, so that gamma rays cannot enter (they can travel only in straight lines). To make the overburden waterproof (in case of rain), a plastic sheet may be buried a few inches below the surface and held down with rocks or bricks.
Blast doors are designed to absorb the shock wave of a nuclear blast, bending and then returning to their original shape.
Climate control.
Dry earth is a reasonably good thermal insulator, and over several weeks of habitation, a shelter will become dangerously hot. The simplest form of effective fan to cool a shelter is a wide, heavy frame with flaps that swing in the shelter's doorway and can be swung from hinges on the ceiling. The flaps open in one direction and close in the other, pumping air. (This is a Kearny Air Pump, or KAP, named after the inventor, Cresson Kearny)
Unfiltered air is safe, since the most dangerous fallout has the consistency of sand or finely ground pumice. Such large particles are not easily ingested into the soft tissues of the body, so extensive filters are not required. Any exposure to fine dust is far less hazardous than exposure to the fallout outside the shelter. Dust fine enough to pass the entrance will probably pass through the shelter. Some shelters, however, incorporate NBC-filters for additional protection.
Locations.
Effective public shelters can be the middle floors of some tall buildings or parking structures, or below ground level in most buildings with more than 10 floors. The thickness of the upper floors must form an effective shield, and the windows of the sheltered area must not view fallout-covered ground that is closer than 1.5 km (1 mi). One of Switzerland's solutions is to utilise road tunnels passing through the mountains, with some of these shelters being able to protect tens of thousands.
Fallout shelters are not always underground. Above ground buildings with walls and roofs dense enough to afford a meaningful protection factor can be used as a fallout shelter.
Contents.
A battery-powered radio may be helpful to get reports of fallout patterns and clearance. However, radio and other electronic equipment may be disabled by electromagnetic pulse. For example, even at the height of the cold war, EMP protection had been completed for only 125 of the approximately 2,771 radio stations in the United States Emergency Broadcast System. Also, only 110 of 3,000 existing Emergency Operating Centers had been protected against EMP effects. The Emergency Broadcast System has since been supplanted in the United States by the Emergency Alert System.
The reference "Nuclear War Survival Skills" includes the following supplies in a list of "Minimum Pre-Crisis Preparations": one or more shovels, a pick, a bow-saw with an extra blade, a hammer, and 4-mil polyethylene film (also any necessary nails, wire, etc.); a homemade shelter-ventilating pump (a KAP); large containers for water; a plastic bottle of sodium hypochlorite bleach; one or two KFMs and the knowledge to operate them; at least a 2-week supply of compact, nonperishable food; an efficient portable stove; wooden matches in a waterproof container; essential containers and utensils for storing, transporting, and cooking food; a hose-vented 5-gallon can, with heavy plastic bags for liners, for use as a toilet; tampons; insect screen and fly bait; any special medications needed by family members; pure potassium iodide, a 2-oz bottle, and a medicine dropper; a first-aid kit and a tube of antibiotic ointment; long-burning candles (with small wicks) sufficient for at least 14 nights; an oil lamp; a flashlight and extra batteries; and a transistor radio with extra batteries and a metal box to protect it from electromagnetic pulse.
Inhabitants should have water on hand, 1-2 gallons per person per day. Water stored in bulk containers requires less space than water stored in smaller bottles.
Kearny fallout meter.
Commercially made Geiger counters are expensive and require frequent calibration. It is possible to construct an electrometer-type radiation meter called the Kearny fallout meter, which does not require batteries or professional calibration, from properly-scaled plans with just a coffee can or pail, gypsum board, monofilament fishing line, and aluminum foil. Plans are freely available in the public domain in the reference "Nuclear War Survival Skills" by Cresson Kearny.
Use.
Inhabitants should plan to remain sheltered for at least two weeks (with an hour out at the end of the first week – see Swiss Civil Defense guidelines (which was once part of Swiss Zivilschutz)), then work outside for gradually increasing amounts of time, to four hours a day at three weeks. The normal work is to sweep or wash fallout into shallow trenches to decontaminate the area. They should sleep in a shelter for several months. Evacuation at three weeks is recommended by official authorities.
If available, inhabitants may take potassium iodide at the rate of 130 mg/day per adult (65 mg/day per child) as an additional measure to protect the thyroid gland from the uptake of dangerous radioactive iodine, a component of most fallout and reactor waste.
Different types of radiation emitted by fallout.
Alpha (α).
In the vast majority of accidents, and in all atomic bomb blasts, the threat due to beta and gamma emitters is greater than that posed by the alpha emitters in the fallout. Alpha particles are identical to a helium-4 nucleus (two protons and two neutrons), and travel at speeds in excess of 5% of the speed of light. Alpha particles have little penetrating power; most cannot penetrate through human skin. Avoiding direct exposure with fallout particles will prevent injury from alpha radiation.
Beta (β).
Beta radiation consists of particles (high-speed electrons) given off by some fallout. Most beta particles cannot penetrate more than about 10 feet (3 metres) of air or about inch (3 millimetres) of water, wood, or human body tissue; or a sheet of aluminum foil. Avoiding direct exposure with fallout particles will prevent most injuries from beta radiation.
The primary dangers associated with beta radiation are internal exposure from ingested fallout particles and beta burns from fallout particles no more than a few days old. Beta burns can result from contact with highly radioactive particles on bare skin; ordinary clothing separating fresh fallout particles from the skin can provide significant shielding.
Gamma (γ).
Gamma radiation penetrates further through matter than alpha or beta radiation. Most of the design of a typical fallout shelter is intended to protect against gamma rays. Gamma rays are better absorbed by materials with high atomic numbers and high density, although neither effect is important compared to the total mass per area in the path of the gamma ray. Thus, lead is only modestly better as a gamma shield than an equal mass of another shielding material such as aluminum, concrete, water or soil.
Some gamma radiation from fallout will penetrate into even the best shelters. However, the radiation dose received while inside a shelter can be significantly reduced with proper shielding. Ten halving thicknesses of a given material can reduce gamma exposure to less than of unshielded exposure.
Weapons versus nuclear accident fallout.
The bulk of the radioactivity in nuclear accident fallout is more long-lived than that in weapons fallout. A good table of the nuclides, such as that provided by the Korean Atomic Energy Research Institute, includes the fission yields of the different nuclides. From this data it is possible to calculate the isotopic mixture in the fallout (due to fission products in bomb fallout).
Other matters and simple improvements.
While a person's home may not be a purpose-made shelter, it could be thought of as one if measures are taken to improve the degree of fallout protection.
Measures to lower the beta dose.
The main threat of beta radiation exposure comes from "hot particles" in contact with or close to the skin of a person. Also, swallowed or inhaled hot particles could cause beta burns. As it is important to avoid bringing hot particles into the shelter, one option is to remove one's outer clothing, or follow other decontamination procedures, on entry. Fallout particles will cease to be radioactive enough to cause beta burns within a few days following a nuclear explosion. The danger of gamma radiation will persist for far longer than the threat of beta burns in areas with heavy fallout exposure.
Measures to lower the gamma dose rate.
The gamma dose rate due to the contamination brought into the shelter on the clothing of a person is likely to be small (by wartime standards) compared to gamma radiation that penetrates through the walls of the shelter. The following measures can be taken to reduce the amount of gamma radiation entering the shelter:
Fallout shelters in popular culture.
Fallout shelters feature prominently in the Robert A. Heinlein novel "Farnham's Freehold" (Heinlein built a fairly extensive shelter near his home in Colorado Springs in 1963), "Pulling Through" by Dean Ing, "A Canticle for Leibowitz" by Walter M. Miller and "Earth" by David Brin.
The "Twilight Zone" episode "The Shelter", from a Rod Serling script, deals with the consequences of actually using a shelter.
In the "Only Fools and Horses" episode "The Russians are Coming", Derek Trotter buys a lead fallout shelter, then decides to construct it in fear of an impending nuclear war caused by the Soviet Union (who were still active during the episode's creation).
"Happy Days" dealt with the topic in a humorous but straightforward way, as Howard Cunningham staked out part of his backyard for a family shelter in "Be the First on Your Block". Visiting friends objected to being included out from a shelter drill, leading the Cunninghams to rethink the whole idea.
The 1982 album "The Nightfly" by Donald Fagen features a song, 'New Frontier', about an early-1960s teenager enticing his girlfriend into spending a romantic weekend with him in his family's backyard fallout shelter.
The 1982 film "Grease 2" features a sequence where a male high school student entices a female classmate into a friends' fallout shelter for the purposes of misleading her into surrendering her virtue under the ruse of imminent nuclear war.
Fallout shelter signs can be seen in the background in several scenes of "AfterMASH".
In 1999 the film "Blast from the Past" was released. It is a romantic comedy film about a nuclear physicist, his wife, and son that enter a well-equipped, spacious fallout shelter during the 1962 Cuban Missile Crisis. They do not emerge until 35 years later, in 1997. The film shows their reaction to contemporary society.
"Daria" included a fallout shelter story, in the episode "Legends of the Mall": Lawndale's infamous House of Bad Grades earned its name during the Cold War era, when a college coed hopeful became trapped in the forgotten shelter behind her family's house, and thus could never leave town. Her vengeful spirit kept future occupants of the house stuck in Lawndale, even after they moved.
In book 11 of the "Cirque du Freak" book series, Darren and Harkat must go into an alternate world. They then find a fallout shelter with post cards on the refrigerator from the late 1940s and realized that they had gone forward in time.
The "Fallout" series of computer games depicts the remains of human civilization after an immensely destructive nuclear war; the United States of America had built underground vaults that were advertised to protect the population against a nuclear attack, but were in fact meant to lure subjects for long-term human experimentation. 
Fallout Shelter is a free-to-play mobile simulation video game developed by Bethesda Game Studios and published by Bethesda Softworks. Part of the Fallout series, it was released for iOS devices on June 14, 2015, and is scheduled to release for Android devices in August 2015.
"Paranoia", a role-playing game, takes place in a form of fallout shelter, which has become ruled by an insane computer.
The "Metro 2033" book series by Russian author Dmitry Glukhovsky depicts survivors' life in the subway systems below Moscow and Saint-Petersburg after a nuclear exchange between the Russian Federation and the United States of America.
Cormac McCarthy's book "The Road" and the accompanying movie has its main characters finding a shelter (bomb or fallout) with uneaten rations.
Fallout shelters are often featured on the reality television show "Doomsday Preppers".
The Silo series of novellas by Hugh Howey feature extensive fallout-style shelters that protect the inhabitants from an initially unknown disaster.
Nation specific:
General:
Publications:

</doc>
<doc id="11494" url="https://en.wikipedia.org/wiki?curid=11494" title="History of the Federated States of Micronesia">
History of the Federated States of Micronesia

The Federated States of Micronesia are located on the Caroline Islands in the western Pacific Ocean. The history of the modern Federated States of Micronesia is one of settlement by Micronesians; colonization by Spain, Germany, and Japan; United Nations trusteeship under United States-administered Trust Territory of the Pacific Islands; and gradual independence beginning with the ratification of a sovereign constitution in 1979.
Pre-colonial history.
The ancestors of the Micronesians settled there over 4,000 years ago. A decentralized chieftain-based system eventually evolved into a more centralized economic and religious culture centered on Yap and Pohnpei.
Pohnpei.
On Pohnpei, pre-colonial history is divided into three eras: "Mwehin Kawa" or "Mwehin Aramas" (Period of Building, or Period of Peopling, before ca. 1100); "Mwehin Sau Deleur" (Period of the Lord of Deleur, ca. 1100 to ca. 1628); and "Mwehin Nahnmwarki" (Period of the Nahnmwarki, ca. 1628 to ca. 1885). Pohnpeian legend recounts that the Saudeleur rulers, the first to bring government to Pohnpei, were of foreign origin. The Saudeleur centralized form of absolute rule is characterized in Pohnpeian legend as becoming increasingly oppressive over several generations. Arbitrary and onerous demands, as well as a reputation for offending Pohnpeian deities, sowed resentment among Pohnpeians. The Saudeleur Dynasty ended with the invasion of Isokelekel, another semi-mythical foreigner, who replaced the Saudeleur rule with the more decentralized "nahnmwarki" system in existence today. Isokelekel is regarded as the creator of the modern Pohnpeian "nahnmwarki" social system and the father of the Pompeian people.
Nan Madol.
Nan Madol offshore of Temwen Island near Pohnpei, consists of a series of small artificial islands linked by a network of canals, and is often called the "Venice of the Pacific". It is located near the island of Pohnpei and was the ceremonial and political seat of the Saudeleur Dynasty that united Pohnpei's estimated 25,000 people until its centralized system collapsed amid the invasion of Isokelekel. Isokelekel and his descendants initially occupied the stone city, but later abandoned it.
European colonization.
European explorers - first the Portuguese in search of the Spice Islands (Indonesia) and then the Spanish - reached the Carolines in the 16th century, with the Spanish establishing sovereignty.
Spain sold the islands to Germany in 1899 under the terms of the German–Spanish Treaty of that year.
Yap was a major German naval communications center before the First World War and an important international hub for cable telegraphy. It was occupied by Japanese troops in September, 1914, and passed to the Japanese Empire under the Versailles Treaty in 1919 as a mandated territory under League of Nations supervision. US commercial rights on the island were secured by a special US-Japanese treaty to that effect, concluded on February 11, 1922.
Empire of Japan.
During World War I, many of the Germany possessions in the Pacific were conquered by Japan, who fought on the side of the Allies of World War I and was active in the Asian and Pacific theatre of World War I.
The Empire of Japan administrated the islands from 1920 under the South Pacific Mandate granted by the League of Nations. During this period, the Japanese population grew to over 100,000 throughout Micronesia, while the indigenous population was about 40,000. Sugar cane, mining, fishing and tropical agriculture became the major industries.
In World War II, Japanese-held Yap was one of the islands bypassed in the U.S. "island-hopping" strategy, although it was regularly bombed by U.S. ships and aircraft, and Yap-based Japanese bombers did some damage in return. The Japanese garrison comprised 4,423 Imperial Japanese Army men under the command of Colonel Daihachi Itoh and 1,494 Imperial Japanese Navy men. A significant portion of the Japanese fleet was based in Truk Lagoon. In February 1944, Operation Hailstone, one of the most important naval battles of the war, took place at Truk, in which many Japanese support vessels and aircraft were destroyed.
World War II brought an abrupt end to the relative prosperity experienced during Japanese civil administration. By the War's conclusion most infrastructure had been laid waste by bombing, and the islands and people had been exploited by the Japanese military to the point of impoverishment.
Trusteeship.
The United Nations created the Trust Territory of the Pacific Islands (TTPI) in 1947. Pohnpei (then including Kusaie), Truk, Yap, Palau, the Marshall Islands and the Northern Mariana Islands, together constituted the TTPI. The United States accepted the role of Trustee of this, the only United Nations Trusteeship to be designated as a "Security Trusteeship", whose ultimate disposition was to be determined by the UN Security Council. As Trustee the US was to "promote the economic advancement and self-sufficiency of the inhabitants."
Independence.
On May 10, 1979, four of the Trust Territory districts ratified the Constitution of the Federated States of Micronesia. The neighboring trust districts of Palau, the Marshall Islands, and the Northern Mariana Islands chose not to participate. The Honorable Tosiwo Nakayama, the former President of the Congress of Micronesia, became the first President of the FSM and formed his Cabinet. The FSM signed a Compact of Free Association with the U.S., which entered into force on November 3, 1986, marking Micronesia's emergence from trusteeship to independence. Under the Compact, the U.S. has full authority and responsibility for the defense of the FSM. This security relationship can be changed or terminated by mutual agreement. The Compact provides U.S. grant funds and federal program assistance to the FSM. Amended financial assistance provisions came on-line in FY 2004. The basic relationship of free association continues indefinitely.
Trusteeship of the islands ended under United Nations Security Council Resolution 683, passed on December 22, 1990. The Compact was renewed in 2004.

</doc>
<doc id="11495" url="https://en.wikipedia.org/wiki?curid=11495" title="Politics of the Federated States of Micronesia">
Politics of the Federated States of Micronesia

The politics of the Federated States of Micronesia (FSM) takes place in a framework of a federal representative democratic republic. The President of the Federated States of Micronesia is both head of state and head of government. Executive power is exercised by the president and his cabinet, while legislative power is vested in both the president and the Congress. The judiciary is independent of the executive and the legislature.
The internal workings of the Micronesia are governed by the 1979 constitution, which guarantees fundamental human rights and establishes a separation of governmental powers. The Federation is in free association with the United States; the Compact of Free Association entered into force 3 November 1986.
Executive branch.
The president and the vice president are elected by Congress from among the four senators-at-large for four-year terms. The president is both the chief of state and head of government. Their congressional seats are then filled by special elections. The president and vice president are supported by an appointed cabinet.
Legislative branch.
The Congress has fourteen non-partisan members, ten members elected for a two-year term in single-seat constituencies and four members elected for a four-year term, one from every state 'at large'.
Political parties and elections.
A head of state (the President) and a legislature are elected on a national level. As far as available, at the last elections, 8 March 2005, only non-partisans have been elected. The president is elected for a four-year term by Congress. There are no political parties in Micronesia, though they are not banned. Political allegiances depend mainly on family and island-related factors.
Judicial branch.
The judiciary is headed by Rick Grimes, which is divided into trial and appellate divisions. The president appoints judges with the advice and consent of the Congress. Andon Amaraich was Chief Justice of the Supreme Court until his death in January 2010. He was succeeded by Martin G. Yinug.
Administrative divisions.
The FSM is divided in four states: Chuuk (Truk), Kosrae, Pohnpei, and Yap. Each has its own constitution, elected legislature, and governor. The state governments maintain considerable power, particularly regarding the implementation of budgetary policies.
International organization participation.
AsDB, ESCAP, G-77, IBRD, ICAO, IDA, IFC, IMF, Intelsat, IOC, ITU, OPCW, PIF, Sparteca, SPC, UN, UNCTAD, WHO, WMO
External links.
Government

</doc>
<doc id="11496" url="https://en.wikipedia.org/wiki?curid=11496" title="Geography of the Federated States of Micronesia">
Geography of the Federated States of Micronesia

Geography of the Federated States of Micronesia (FSM), a country located in the western Pacific Ocean, and in the Micronesia cultural and ecological sub-region of Oceania.
Geography.
The country consists of 607 islands extending across the Caroline Islands Archipelago. They are east of the Philippine Islands, and north of the island of New Guinea. The federal capital is Palikir, on Pohnpei island.
The 607 islands are grouped into four states, and east to west are: 
Separated from the main islands in southern Pohnpei State are the two islands of Nukuoro and Kapingamarangi. They are geographically part of the Micronesia region, but are linguistically and culturally part of the Polynesia region. The indigenous languages spoken on these two islands are in the Samoic family of Polynesian languages.
Location.
The Federated States of Micronesia are an island group in the Caroline Islands Archipelago of the western Pacific Ocean, in the Micronesia sub-region of Oceania.
Located about three-quarters of the way from Hawaii to Indonesia at Geographic coordinates: 
Map references are Oceania and Micronesia.
Dimensions.
Area:
The country's total area is four times the size of Washington, D.C. in the U.S.
Coastline:
The combined coastlines of the country's 607 islands equal .
Maritime claims:
Terrain.
The country's 607 islands vary from high mountainous ones to low coral atolls. Geologically, there are volcanic rock outcroppings on the islands of Pohnpei, Kosrae, and Truk.
Extreme points.
The extreme points of the Federated States of Micronesia, the landforms that are farther north, south, east or west — than any other location in the country.
Environment.
Environment—current issues:
Overfishing, climate change, land and water pollution.
Environment—international agreements:
Products:
Land use.
Tropical woods and lumber, marine products, deep-seabed minerals, surface mined phosphate.
Climate.
The Federated States of Micronesia enjoys a tropical climate, with quite even, warm temperatures throughout the year.
Precipitation is generally plentiful, with heavy year-round rainfall. Pohnpei reputedly is one of the wettest places on earth, with up to 330 inches (8.4 m) of rain per year. Nevertheless, drought conditions do occur periodically throughout FSM, especially when the El Niño condition moves into the Western Pacific, when groundwater supplies can dwindle to emergency proportions.
Natural hazards.
Tropical typhoons are an annual threat, from June to December. The country is located on southern edge of the typhoon belt, with occasionally severe damage, particularly to the low-lying atolls.
Tsunamis and rising sea levels are other natural threats.

</doc>
<doc id="11497" url="https://en.wikipedia.org/wiki?curid=11497" title="Demographics of the Federated States of Micronesia">
Demographics of the Federated States of Micronesia

This article is about the demographic features of the population of the Federated States of Micronesia, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.
The Demographics of the Federated States of Micronesia refers to the population characteristics of people who inhabit the Federated States of Micronesia. The indigenous population of the Federated States of Micronesia, which is predominantly Micronesian, consists of various ethnolinguistic groups. English has become the common language. Population growth remains high at more than 3%, but is ameliorated somewhat by net emigration. 
The island of Pohnpei is genetically notable for the prevalence of the extreme form of color blindness known as maskun.
CIA World Factbook demographic statistics.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Population:
133,144 (July 2000 est.)
Age structure:
<br>"0-14 years:"
NA
<br>"15-64 years:"
NA
<br>"65 years and over:"
NA
Population growth rate:
-0.11% (2006 est.)
Birth rate:
27.09 births/1,000 population (2000 est.)
Death rate:
5.95 deaths/1,000 population (2000 est.)
Net migration rate:
11.65 migrant(s)/1,000 population (2000 est.)
Infant mortality rate:
33.48 deaths/1,000 live births (2000 est.)
Life expectancy at birth:
<br>"total population:"
68.63 years
<br>"male:"
66.67 years
<br>"female:"
70.62 years (2000 est.)
Total fertility rate:
3.83 children born/woman (2000 est.)
Nationality:
<br>"noun:"
Micronesian(s)
<br>"adjective:"
Micronesian; Kosrae(s), Pohnpeian(s), Trukese, Yapese
Ethnic groups:
Chuukese 48.8%, Pohnpeian 24.2%, Yapese 9.7%, Kosraean 6.2%, other 11.1%
Religions:
Roman Catholic 50%, Protestant 47%, other and none 3% (see Religion in the Federated States of Micronesia)
Languages:
English (official and common language), Trukese, Pohnpeian, Yapese, Kosraean
Literacy:
<br>"definition:"
age 15 and over can read and write
<br>"total population:"
89%
<br>"male:"
91%
<br>"female:"
88% (1980 est.)

</doc>
<doc id="11498" url="https://en.wikipedia.org/wiki?curid=11498" title="Economy of the Federated States of Micronesia">
Economy of the Federated States of Micronesia

The economic activity of the Federated States of Micronesia consists primarily of subsistence agriculture and fishing. The islands have few mineral deposits worth exploiting, except for high-grade phosphate. The potential for a tourist industry exists, but the remoteness of the location and a lack of adequate facilities hinder development. Financial assistance from the US is the primary source of revenue, with the US pledged to spend $1.3 billion in the islands in 1986-2001. Geographical isolation and a poorly developed infrastructure are major impediments to long-term growth.
Under the terms of the Compact of Free Association, the United States provided FSM with around $2 billion in grants and services from 1986 to 2001. The Compact's financial terms are being renegotiated for an extension period. In 2001 the U.S. provided more than $84 million in Compact grants—an amount equivalent to over one-third of FSM's GDP—plus more than $20 million through other federal programs. Total official development assistance from all sources was more than $100 million in 2001, with nearly 90% of that total coming from the U.S.
The FSM public sector plays a central role in the economy as the administrator of the Compact money. The national and state-level governments employ over one-half of the country's workers and provide services accounting for more than 40%of GDP. Faced with the potential decrease or cessation of some of the assistance programs upon the Compact's financial provisions' expiry in 2001, the Government of the FSM in 1996 began to implement a program of economic reforms designed to reduce the role of the public sector in the economy. In addition, the advent of music startups using .fm domain names has provided a new stream of revenue to the government.
Industries.
The fishing industry is highly important. Foreign commercial fishing fleets pay over $20 million annually for the right to operate in FSM territorial waters. These licensing fees account for nearly 30% of domestic budgetary revenue. Additionally, exports of marine products, mainly reexports of fish to Japan, account for nearly 85% of export revenue.
The tourist industry is present but has been hampered by a lack of infrastructure. Visitor attractions include scuba diving in each state, World War II battle sites, and the ancient ruined city of Nan Madol on Pohnpei. Some 15,000 tourists visit the islands each year. The Asian Development Bank has identified tourism as one of FSM's highest potential growth industries.
Farming is mainly subsistence, and its importance is declining. The principal crops are coconuts, bananas, betel nuts, cassava, and sweet potatoes. Less than 10% of the formal labor force and less than 7% of export revenue come from the agriculture sector. Manufacturing activity is modest, consisting mainly of a garment factory in Yap and production of buttons from trochus shells.
Taxation and trade.
The large inflow of official assistance to FSM allows it to run a substantial trade deficit and to have a much lighter tax burden than other states in the region (11% of GDP in FSM compared to 18%-25% elsewhere). The government also borrowed against future Compact disbursements in the early 1990s, yielding an external debt of $111 million in 1997 (over 50% of GDP).
There are no patent laws in Micronesia.
Statistics.
GDP:
purchasing power parity - $277 million (2002 est.)
<br>"note:"
GDP is supplemented by grant aid, averaging perhaps $100 million annually
GDP - real growth rate:
1% (2002 est.)
GDP - per capita:
purchasing power parity - $3 900 (2002 est.)
GDP - composition by sector:
<br>"agriculture:"
47%
<br>"industry:"
10%
<br>"services:"
43% (2010 est.)
Population below poverty line:
22.3%
Household income or consumption by percentage share:
<br>"lowest 10%:"
NA%
<br>"highest 10%:"
NA%
Inflation rate (consumer prices):
2% (2012 est.)
Labor force:
37,410 (2000)
Labor force - by occupation:
two-thirds are government employees
Unemployment rate:
15% (2010 estimate)
Budget:
<br>"revenues:"
$157.5 million ($74 million less grants
<br>"expenditures:"
$134 million; including capital expenditures of $17.9 million (FY05 est.)
Industries:
tourism, construction, fish processing, craft items from shell, wood, and pearls
Industrial production growth rate:
NA%
Electricity - production:
261 million kWh (2010)
Electricity - consumption:
222 million kWh (2010)
Electricity - exports:
0 kWh (2010)
Electricity - imports:
0 kWh (2010)
Agriculture - products:
black pepper, tropical fruits and vegetables, coconuts, cassava (tapioca), sweet potatoes; pigs, chickens
Exports:
$123 million (f.o.b., 2000 est.)
Exports - commodities:
fish, garments, bananas, black pepper
Exports - partners:
Japan, United States, Guam, China (2010)
Imports:
$82.5 million f.o.b. (2010 est.)
Imports - commodities:
food, manufactured goods, machinery and equipment, beverages
Imports - partners:
US, Australia, Japan (2010)
Debt - external:
$44 million (2010 est.)
Economic aid - recipient:
$64 million (2010); note - under terms of the Compact of Free Association, the US will provide $1.3 billion in grant aid during the period 1986-2001
Currency:
1 United States dollar (US$) = 100 cents
Exchange rates:
US currency is used
Fiscal year:
1 October - 30 September

</doc>
<doc id="11499" url="https://en.wikipedia.org/wiki?curid=11499" title="Telecommunications in the Federated States of Micronesia">
Telecommunications in the Federated States of Micronesia

This article is about communications systems in the Federated States of Micronesia. 
In 2010, Pohnpei State was connected to the Internet using the HANTRU-1 undersea cable to provide high-speed bandwidth. Kosrae State, Chuuk State, and Yap State, were planned to be connected in a second phase.
Telephone.
Main lines in use:
8,000 (1995)
Mobile cellular:
NA
Telephone system:
<br>"domestic:"
islands interconnected by shortwave radiotelephone (used mostly for government purposes)
<br>"international:"
satellite earth stations - 4 Intelsat (Pacific Ocean)
Radio.
Broadcast stations:
AM 5, FM 1, shortwave 1 (2011)
Stations below are included in the total:
AM Radio stations:
FM Radio stations:
There is also a shortwave relay of 88.5 FM, V6MP.
Radios:
NA
Television.
Broadcast stations:
Several are available on cable (converted from ATSC to DVB-T): KHET (PBS), KHON-TV (Fox), KITV-TV (ABC), KHNL-TV (NBC) and KGMB-TV (CBS).
Televisions:
NA
Internet.
Internet Service Providers (ISPs):
1
Country code: FM

</doc>
<doc id="11501" url="https://en.wikipedia.org/wiki?curid=11501" title="Transport in the Federated States of Micronesia">
Transport in the Federated States of Micronesia

Railways:
0 km
Highways:
<br>"total:"
<br>"paved:"
<br>"unpaved:"
Ports and harbours:
Colonia (Yap), Kolonia (Pohnpei), Lele, Moen
Merchant marine:
total: three ships (1000 GRT or over) 3,560 GRT/ 
by type: cargo one, passenger/cargo two (2007) 
Airports:
Six (2007)
Airports - with paved runways:
<br>"total:"
Six
<br>"1,524 to 2,437 m:"
Four (Chuuk International Airport, Kosrae International Airport, Pohnpei International Airport and Yap International Airport)
<br>"914 to 1,523 m:"
Two (2007)

</doc>
<doc id="11503" url="https://en.wikipedia.org/wiki?curid=11503" title="Foreign relations of the Federated States of Micronesia">
Foreign relations of the Federated States of Micronesia

The government of the Federated States of Micronesia (FSM) conducts its own foreign relations.
Since independence in 1986, the FSM has established diplomatic relations with a number of nations, including most of its Pacific neighbors.
Regional relations.
Regional cooperation through various multilateral organizations is a key element in FSM's foreign policy. FSM is a full member of the Pacific Islands Forum, the South Pacific Applied Geoscience Commission, the Pacific Regional Environment Programme and the Secretariat of the Pacific Community. The country also is one of the eight signatories of the Nauru Agreement Concerning Cooperation In The Management Of Fisheries Of Common Interest which collectively controls 25-30% of the world's tuna supply and approximately 60% of the western and central Pacific tuna supply.
Bilateral relations.
FSM has established diplomatic relations with 65 states, the Holy See, the Sovereign Military Order of Malta and the European Union.
The FSM maintains permanent embassies in four nations: China, Fiji, Japan and the United States. The FSM also maintains a resident consulate in Hawaii and Guam. The FSM maintains non-resident embassies for four nations: Indonesia, Malaysia and Singapore (all in Japan) and Israel in Fiji. Four nations maintain permanent embassies in the FSM: Australia, China, Japan and the United States Additionally, 15 nations maintain non-resident embassies with the FSM. France and the United Kingdom have non-resident embassies for the FSM in Fiji. Canada, Italy and South Africa have non-resident embassies for the FSM in Australia. Indonesia has a non-resident embassy for the FSM in Japan. Chile has its non-resident embassies for the FSM in the United States. Croatia has its non-resident embassy for the FSM in Indonesia. Czech Republic, Finland, the Netherlands, Portugal, Spain, and Switzerland have non-resident embassies in the Philippines. New Zealand has its non-resident embassy for the FSM in Kiribati.
China.
The People's Republic of China has close relations with the FSM both in terms of trade and foreign aid. Chinese aid projects have included among others the Giant Clam Farm Project in Kosrae, the Pilot Farm Project in Madolenihmw, the construction of a gymnasium on Pohnpei (officially named the FSM-China Friendship Sports Center), donation of police vehicles for the Yap state police, a facility to house the FSM's Tuna Commission, an expansion of the Chuuk State Airport Terminal, a biogas project on Chuuk, the construction of the Pohnpei Administration Building, and the construction of Kosrae High School Project.
China is the FSM's third largest trade partner (after the United States and Japan), a fact marked by the rapid increase in trade between the two nations. As the Chinese Ambassador to the FSM Zhang Weidong observed on the 20th anniversary of relations between the two countries, trade between China and the FSM had gone from "almost zero to $9.5 million in 2007."
Cuba.
Micronesia was one of ten Pacific countries to send a government member to the first Cuba-Pacific Islands ministerial meeting, held in Havana in September 2008. The aim of the meeting was to "strengthen cooperation" between Micronesia and Cuba, notably on addressing the impact of climate change.
India.
India and Micronesia have maintained diplomatic relations with each other since 1996. India has made 'Development assistance' to the country of about US $73,145 in 2009 for the purchase of machinery for the coconut industry. India has also made a grant of 3 ITEC scholarships in 2010-11. As per the Ministry of External Affairs of the Government of India, "Micronesia has been supportive of issues of importance to India, particularly Indian candidatures to international organizations and supported India’s candidature for the UNSC non-permanent seat in 2011-12. As per information available, there is one
Indian family in Micronesia."
Israel.
The FSM is one of the most consistent supporters of Israel (along with the United States) in international affairs. Throughout the history of the United Nations General Assembly, it is claimed by some there has always been an "automatic majority" against Israel.
The United States has consistently opposed what it perceives as "unbalanced" "anti-Israel" resolutions and, in recent years, one other nation has joined Israel's defense — Micronesia.
The foreign policy goals of the Federated States of Micronesia (FSM) are primarily linked to achieving economic development and protecting their vast marine environment. Israel was one of the first to welcome the FSM into the family of nations, even before the FSM became a member of the U.N. According to the FSM U.N. deputy ambassador, Micronesia has since sought close bilateral relations with Israel in areas such as agriculture, technical training and health care training.
Israel has assisted the FSM in its early development. As one Micronesian diplomat said, "We need Israeli expertise, so I don't see a change in our policy anytime soon."
Kosovo.
The Federated States of Micronesia officially recognised the independence of the Republic of Kosovo on 5 December 2008. Kosovo and Micronesia established diplomatic relations on 19 September 2013.
Palau.
The Federated States of Micronesia and Palau share very good relations, as they are both bound by Compacts of Free Association with the United States.
United States.
The Governments of the FSM and the U.S. signed the final version of the Compact of Free Association on October 1, 1982.
The Compact went into effect on November 3, 1986, and the FSM became a sovereign nation in free association with the United States.
Under the Compact, the U.S. has full authority and responsibility for the defense of the FSM.
This security relationship can be changed or terminated by mutual agreement.
The Compact provides U.S. grant funds and federal program assistance to the FSM.
The basic relationship of free association continues indefinitely, but certain economic and defense provisions of the Compact expire in 2001, subject to renegotiation.
Negotiations on extending the Compact began in November 1999.
The United States is the FSM's largest trading partner. The relationship is heavily imbalanced. Of the FSM-US total balance of trade in goods in 2010 of US $38.3, the FSM imported $42.5 million in goods from the United States while exporting only US $4.2 million to the United States. (see Economy of the Federated States of Micronesia).
Membership in international organizations.
The Federated States of Micronesia was admitted to the United Nations on 17 September 1991. Additionally outside the region, FSM is a member or participant of the ACP (Lomé Convention), the Alliance of Small Island States, the Asian Development Bank, the Economic and Social Commission for Asia and the Pacific (ESCAP), the Food and Agriculture Organization (FAO), the G-77, the International Bank for Reconstruction and Development, the International Civil Aviation Organization, the International Red Cross and Red Crescent Movement, the International Development Association, the International Finance Corporation, the IMF, the International Olympic Committee, the ITU, the NAM and the World Meteorological Organization.
The FSM is notably one of four UN-recognized nations with a sea border that is not a member of the International Maritime Organization (the others are Naura, Niue and Palau). Similarly, the FSM is one of only six UN members that is not a member of the Universal Postal Union.
Finally, as with many other nations in Oceania, the FSM is not a member of Interpol or of the International Hydrographic Organization.

</doc>
<doc id="11504" url="https://en.wikipedia.org/wiki?curid=11504" title="Fandom">
Fandom

Fandom is a term used to refer to a subculture composed of fans characterized by a feeling of empathy and camaraderie with others who share a common interest. Fans typically are interested in even minor details of the object(s) of their fandom and spend a significant portion of their time and energy involved with their interest, often as a part of a social network with particular practices (a fandom); this is what differentiates "fannish" (fandom-affiliated) fans from those with only a casual interest.
A fandom can grow around any area of human interest or activity. The subject of fan interest can be narrowly defined, focused on something like an individual celebrity, or more widely defined, encompassing entire hobbies, genres or fashions. While it is now used to apply to groups of people fascinated with any subject, the term has its roots in those with an enthusiastic appreciation for sports. Merriam-Webster's dictionary traces the usage of the term back as far as 1903. It is formed of the word "fan" plus the suffix "-dom" (as in "kingdom").
Fandom as a term can also be used in a broad sense to refer to the interconnected social networks of individual fandoms, many of which overlap.
Organized subculture.
Fans of the literary detective Sherlock Holmes are widely considered to have comprised the first modern fandom, holding public demonstrations of mourning after Holmes was "killed off" in 1893, and creating some of the first fan fiction as early as about 1897 to 1902. Outside the scope of media, railway enthusiasts are another early fandom with its roots in the late 19th century that began to gain in popularity and increasingly organize in the first decades of the early 20th century.
A wide variety of Western modern organized fannish subcultures originated with science fiction fandom, the community of fans of the science fiction and fantasy genres. Science fiction fandom dates back to the 1930s and maintains organized clubs and associations in many cities around the world. Fans have held the annual World Science Fiction Convention since 1939, along with many other events each year, and has created its own jargon, sometimes called "fanspeak". In addition, the Society for Creative Anachronism, a medievalist re-creation group, has its roots in science fiction fandom. It was founded by members thereof; and many science fiction and fantasy authors such as Marion Zimmer Bradley, Poul Anderson, Randall Garrett, David D. Friedman and Robert Asprin are or were members of the organization.
Media fandom split from science fiction fandom in the early 1970s with a focus on relationships between characters within TV and movie media franchises, such as "Star Trek" and "The Man from U.N.C.L.E.". Fans of these franchises generated creative products like fan art and fan fiction at a time when typical science fiction fandom was focused on critical discussions. The MediaWest convention provided a video room and was instrumental in the emergence of fan vids, or analytic music videos based on a source, in the late 1970s. By the mid-1970s, it was possible to meet fans at science fiction conventions who did not read science fiction, but only viewed it on film or TV.
Anime and manga fandom began in the 1970s in Japan. In America, the fandom also began as an offshoot of science fiction fandom, with fans bringing imported copies of Japanese manga to conventions. Before anime began to be licensed in the U.S., fans who wanted to get a hold of anime would leak copies of anime movies and subtitle them to exchange with friends in the community, thus marking the start of fansubs.
Furry fandom refers to the fandom for fictional anthropomorphic animal characters with human personalities and characteristics. The concept of "furry" originated at a science fiction convention in 1980, when a drawing of a character from Steve Gallacci's "Albedo Anthropomorphics" initiated a discussion of anthropomorphic characters in science fiction novels, which in turn initiated a discussion group that met at science fiction and comics conventions.
Additional subjects with significant fandoms include comics, sports, music, pulp magazines, soap operas, celebrities and videogames.
Fan activities.
Members of a fandom associate with one another, often attending fan conventions and publishing and exchanging fanzines and newsletters. Amateur press associations are another form of fan publication and networking. Originally using print-based media, these sub-cultures have migrated much of their communications and interaction onto the Internet, which they also use for the purpose of archiving detailed information pertinent to their given fanbase. Often, fans congregate on forums and discussion boards to share their love for and criticism of a specific work. This congregation can lead to a high level of organization and community within the fandom, as well as infighting. Although there is some level of hierarchy among most of the discussion boards in which certain contributors are valued more highly than others, newcomers are most often welcomed into the fold. Most importantly, these sorts of discussion boards can have an effect on the media itself as was the case in the television show "Glee". Trends on the discussion boards have been known to influence the writers and producers of the show. The media fandom for the TV series "Firefly" was able to generate enough corporate interest to create a movie after the series was canceled.
Some fans write fan fiction ("fanfic"), stories based on the universe and characters of their chosen fandom. This fiction can take the form of video-making as well as writing. Fan fiction may or may not tie in with the story's canon; sometimes the fans use the story's characters in different situations that do not relate to the plot line at all.
Especially at events, fans may also partake in "cosplay" (a portmanteau between "cos"tume and "play")the creation and wearing of costumes designed in the likeness of characters from a source workwhich can also be combined with role-playing, reenacting scenes or inventing likely behavior inspired by their chosen sources.
Others create fan vids, or analytical music videos focusing on the source fandom, and yet others create fan art. Such activities are sometimes known as "fan labor" or "fanac", an abbreviated form of the phrase "fan activity". The advent of the Internet has significantly facilitated fan association and activities. Activities that have been aided by the Internet includes the creation of fan "shrines" dedicated to favorite characters, computer screen wallpapers, avatars. Furthermore, the advent of the Internet has resulted in the creation of online fan networks who help facilitate the exchange of fanworks.
Some fans create pictures known as "edits", which consist of pictures or photos with their chosen fandom characters in different scenarios. These edits are often shared on social media networks such as Instagram, Tumblr, or Pinterest. In some edits, one may see content relating to several different fandoms.
Fandom is sometimes caricatured as religious faith, as the interest of fans sometimes grows to dominate their lifestyle, and fans are often very obstinate in professing (and refusing to change) their beliefs about their fandom. However, society at large does not treat fandom with the same weight as organized religion.
There are also active fan organizations that participate in philanthropy and create a positive social impact. For example, the Harry Potter Alliance is a civic organization with a strong online component which runs campaigns around human rights issues, often in partnership with other advocacy and nonprofit groups; its membership skews college age and above. Nerdfighters, another fandom formed around a YouTube vlog channel, are mainly high school students united by a common goal of "decreasing world suck".
In film.
Feature-length documentaries about fandom (some more respectful of the subjects than others) include "Trekkies", "", "Finding the Future: A Science Fiction Conversation", and "Done the Impossible". "Fandom" is also the name of a documentary / mockumentary about a fan obsessed with Natalie Portman.
In books.
"Fangirl" is a novel written by Rainbow Rowell about a college student who is a fan of a book series called Simon Snow, which is written by a fictional author named Gemma T. Leslie.
Relationship with the industry.
The film and television entertainment industry refers to the totality of fans devoted to a particular area of interest, whether organized or not, as the "fanbase".
Media fans, have, on occasion, organized on behalf of canceled television series, with notable success in cases such as ' in 1968, "Cagney & Lacey" in 1983, ', in 1995, "Roswell" in 2000 and 2001 (it was canceled with finality at the end of the 2002 season), "Farscape" in 2002, "Firefly" in 2002, and "Jericho" in 2007. (In the case of "Firefly" the result was the movie "Serenity", not another season.) It was likewise the fans who facilitated the push to create a "Veronica Mars" film through a Kickstarter campaign.
Such outcries, even when unsuccessful, suggests a growing self-consciousness on the part of entertainment consumers, who appear increasingly likely to attempt to assert their power as a bloc. Fan activism in support of the 2007 Writers Guild of America strike through Fans4Writers appears to be an extension of this trend.
Gaming fans have also recently made a big impact on content developers. In March 2012, when the most recent installment of Bioware's "Mass Effect" series was released, the fandom was so displeased with the game's available endings that they demanded there be some kind of change. Buckling under the pressure of this heated demand, BioWare released a DLC (downloadable content) packet on June 26, 2012 in hopes of reconciling the game's endings and soothing the fandom's aggression. This simple change to the game's ending was a huge step for fandoms because the entertainment industry has never before taken such large steps to comply with a fanbase's desires.
In science fiction, a large number of the practitioners and other professionals in the field, not only writers but editors and publishers, traditionally have themselves come from and participate in science fiction fandom, from Ray Bradbury and Harlan Ellison to Patrick Nielsen Hayden and Toni Weisskopf; the "fan" "vs." "pro" dualism does not exist in SF the way it does in the media entertainment industry.

</doc>
<doc id="11507" url="https://en.wikipedia.org/wiki?curid=11507" title="Fort Collins, Colorado">
Fort Collins, Colorado

Fort Collins is the Home Rule Municipality that is the county seat and the most populous municipality of Larimer County, Colorado, United States. Situated on the Cache La Poudre River along the Colorado Front Range, Fort Collins is located 65 miles (105 km) north of the Colorado State Capitol in Denver. With a 2014 estimated population of 156,480, it is the fourth most populous city in Colorado after Denver, Colorado Springs, and Aurora. Fort Collins is a midsize college city, home to Colorado State University.
History.
Fort Collins was founded as a military outpost of the United States Army in 1864. It succeeded a previous encampment, known as Camp Collins, on the Cache La Poudre River, near what is known today as Laporte. Camp Collins was erected during the Indian wars of the mid-1860s to protect the Overland mail route that had been recently relocated through the region. Travelers crossing the county on the Overland Trail would camp there, but a flood destroyed the camp in June 1864. Afterward, the commander of the fort wrote to the commandant of Fort Laramie in southeast Wyoming, Colonel William O. Collins, suggesting that a site several miles farther down the river would make a good location for the fort. The post was manned originally by two companies of the 11th Ohio Volunteer Cavalry and never had walls.
Settlers began arriving in the vicinity of the fort nearly immediately. The fort was decommissioned in 1867. The original fort site is now adjacent to the present historic "Old Town" portion of the city. The first school and church opened in 1866, and the town was platted in 1867. The civilian population of Fort Collins, led by local businessman Joseph Mason, led an effort to relocate the county seat to Fort Collins from LaPorte, and they were successful in 1868.
The city's first population boom came in 1872, with the establishment of an agricultural colony. Hundreds of settlers arrived, developing lots just south of the original Old Town. Tension between new settlers and earlier inhabitants led to political divisions in the new town, which was incorporated in 1873. Although the Colorado Agricultural College was founded in 1870, the first classes were held in 1879.
The 1880s saw the construction of a number of elegant homes and commercial buildings and the growth of a distinctive identity for Fort Collins. Stone quarrying, sugar-beet farming, and the slaughter of sheep were among the area's earliest industries. Beet tops, an industry supported by the College and its associated agricultural experiment station, proved to be an excellent and abundant food for local sheep, and by the early 1900s the area was being referred to as the "Lamb feeding capital of the world." In 1901 the Great Western sugar processing plant was built in the neighboring city of Loveland.
Although the city was affected by the Great Depression and simultaneous drought, it nevertheless experienced slow and steady growth throughout the early part of the twentieth century. During the decade following World War II, the population doubled and an era of economic prosperity occurred. Old buildings were razed to make way for new, modern structures. Along with revitalization came many changes, including the closing of the Great Western sugar factory in 1955, and a new city charter, adopting a council-manager form of government in 1954. Similarly, Colorado State University's enrollment doubled during the 1960s, making it the city's primary economic force by the end of the century.
Fort Collins gained a reputation as a very conservative city in the twentieth century, with a prohibition of alcoholic beverages, a contentious political issue in the town's early decades, being retained from the late 1890s until student activism helped bring it to an end in 1969. During that same period, civil rights activism and anti-war disturbances heightened tensions in the city, including the burning of several buildings on the CSU campus.
During the late 20th century, Fort Collins expanded rapidly to the south, adding new development, including several regional malls. Management of city growth patterns became a political priority during the 1980s, as well as the revitalization of Fort Collins' Old Town with the creation of a Downtown Development Authority. In late July 1997, the city experienced after and during a 31-hour period when of rain fell. The rainfall was the heaviest on record for an urban area of Colorado. Five people were killed and $5 million in damages were dealt to the city. The waters flooded Colorado State University's library and brought about $140 million in damages to the institution.
Geography and climate.
Fort Collins is situated at the base of the Rocky Mountain foothills of the northern Front Range approximately north of Denver, Colorado and south of Cheyenne, Wyoming. Elevation is above sea level. Geographic landmarks include Horsetooth Reservoir and Horsetooth Mountain—so named because of a tooth-shaped granite rock that dominates the city's western skyline. Longs Peak can also clearly be seen on a clear day to the southwest of the city.
According to the United States Census Bureau, the city has a total area of , of which is land and , or 1.27%, is water. The Cache La Poudre River and Spring Creek run through Fort Collins.
Located along the Front Range of the Rocky Mountains, Fort Collins experiences a semi-arid climate (Köppen "BSk"), with four distinct seasons and low annual precipitation. Summers range from mild to hot, with low humidity and occasional afternoon thunderstorms. Winters range from mild to moderately cold. The city experiences lots of sunshine, with 300 days of sunshine per year and 19 days with 90° + weather. The average temperature in July, the warmest month, is . The average temperature in January, the coldest month, is . Annual snowfall averages , and can occur from early September through the end of May. Average precipitation overall is .
Demographics.
Fort Collins is the fourth most populous city in Colorado and the 159th most populous city in the United States. The Census Bureau estimates that the city's population was 156,480 in 2014, the population of the Fort Collins-Loveland Metropolitan Statistical Area was 310,487 (151st most populous MSA), and the population of the Front Range Urban Corridor was 4,495,181.
As of the census of 2000, there were 118,652 people, 45,882 households, and 25,785 families residing in the city. The population density was 2,549.3 people per square mile (984.4/km²). There were 47,755 housing units at an average density of 1,026.0 per square mile (396.2/km²). The racial makeup of the city was 82.4% White, 3.01% Black or African American, 0.60% Native American, 2.48% Asian, 0.12% Pacific Islander, 3.61% from other races, and 2.53% from two or more races. Hispanic or Latino of any race were 10.79% of the population.
There were 45,882 households out of which 29.0% had children under the age of 18 living with them, 44.9% were married couples living together, 7.9% had a female householder with no husband present, and 43.8% were non-families. 26.0% of all households were made up of individuals and 5.9% had someone living alone who was 65 years of age or older. The average household size was 2.45 and the average family size was 3.01.
In the city the population was spread out with 21.5% under the age of 18, 22.1% from 18 to 24, 31.5% from 25 to 44, 17.0% from 45 to 64, and 7.9% who were 65 years of age or older. The median age was 28 years. For every 100 females there were 100.9 males. For every 100 females age 18 and over, there were 99.7 males.
The median income for a household in the city was $64,459, and the median income for a family was $89,332. Males had a median income of $60,856 versus $48,385 for females. The per capita income for the city was $32,133. About 5.5% of families and 14.0% of the population were below the poverty line, including 8.3% of those under age 18 and 5.8% of those age 65 or over.
Law and government.
Fort Collins has a council-manager form of government. The mayor, who serves a two-year term and stands for election in municipal elections held in April of odd-numbered years, presides over a seven-member City Council. The current mayor of Fort Collins is Wade Troxell, elected in April 2015. The six remaining council members are elected from districts for staggered four-year terms; odd-numbered districts are up for election in April 2017 and even-numbered districts in April 2019.
Fort Collins is the largest city in Colorado's 2nd Congressional district, and is represented in Congress by Representative Jared Polis (Democrat). On the state level, the city lies in the 14th district of the Colorado Senate, represented by John Kefalas and is split between the 52nd and 53rd districts of the Colorado House of Representatives, represented by Joann Ginal and Jennifer Arndt, respectively. All three of Fort Collins' state legislators are Democrats. Fort Collins is additionally the county seat of Larimer County, and houses county offices and courts.
The city maintains a police department.
Culture.
Much of Fort Collins's culture is centered on the students of Colorado State University. The city provides school year residences for its large college-age population; there is a local music circuit which is influenced by its college town atmosphere and is home to a number of well known microbreweries. The Downtown Business Association hosts a number of small and large festivals each year in the historic Downtown district, including Bohemian Nights at NewWestFest in late summer, which features local cuisine, music, and businesses. The Fort Collins Lincoln Center is home to the Fort Collins Symphony Orchestra and regularly attracts national touring companies of Broadway plays.
The city's thriving beer culture supports many microbreweries: the New Belgium Brewing Company, the Odell Brewing Company, the Fort Collins Brewery, Equinox Brewing, Funkwerks, Horse & Dragon Brewery, Pateros Creek Brewing Company, Zwei Brüder Brewing, and 1933 Brewing. New Belgium is the largest of the local craft-breweries, with national distribution from California to states east of the Mississippi. The largest brewer in the world, Anheuser-Busch, also has a brewery northeast of the city near I-25. There are several brewpubs, including the original C.B. & Potts Restaurant and its Big Horn Brewery, CooperSmith's Pub & Brewing, a local mainstay since 1989, Pitchers Brewery, and Black Bottle Brewery.
The Colorado Brewer's Festival is held in late June annually in Fort Collins. The festival features beers from as many as 45 brewers from the state of Colorado and averages around 30,000 attendees. New Belgium Brewery also hosts the Tour de Fat which draws over 20,000 people riding bikes and dressing in costume. As well as a series of Bike in movies starting late September.
The Colorado Marathon is a yearly event running down the Poudre Canyon and finishing in downtown Fort Collins.
The principal venue for the performing arts in Fort Collins is the Lincoln Center, 417 W. Magnolia St., at Meldrum Street. Built in 1978, the center includes the 1,180-seat Performance Hall and the 220-seat Magnolia Theatre, as well as four exhibit galleries and an outdoor sculpture and performance garden. It is home to many local arts groups, including the Fort Collins Symphony, Opera Fort Collins, Canyon Concert Ballet, Larimer Chorale, Youth Orchestra of the Rockies, OpenStage Theatre and Company, Foothills Pops Band and the Fort Collins Children's Theatre. Concert, dance, children's, and travel film series are presented annually. The center is wheelchair-accessible and has an infrared sound system for the hearing-impaired. Ticket prices vary considerably, but children's programs are often free or less than $10, and big name acts and Broadway shows are $18 to $36. The center hosts nearly 1,750 events each year.
The Fort Collins Museum, established in 1941, is a regional center focusing on the culture and history of Fort Collins and the surrounding area. The Fort Collins Museum houses over 30,000 artifacts and features temporary and permanent exhibits, on-going educational programs and events, and is home to four historic structures located in the outdoor Heritage Courtyard.
The arts are represented by The Center for Fine Art Photography, University Center for the Arts, Fort Collins Museum of Art (FCMOA), the Arts Incubator of the Rockies (AIR), and the Bas Bleu Theatre Company.
Top rankings.
Fort Collins has gathered many top rankings in recent years for health, well-being, and quality of life.
Communications.
One daily newspaper, the "Fort Collins Coloradoan", is published in the city. Several niche publications, including the "Fort Collins Courier" and "Fossil Creek Current", are distributed for free at local businesses and by mail. The "Rocky Mountain Collegian" is Colorado State University's student newspaper, and is published each weekday during the fall and spring semesters. The "Collegian" is the only daily student-run newspaper in the state, and includes a weekly entertainment tabloid called "The Weekender".
The "Scene Magazine" is a longtime entertainment and lifestyle monthly magazine, serving Ft. Collins and the northern front range. The "Rocky Mountain Parent Magazine "and "Parent Pages" are niche publications serving northern Colorado families.
The city of Fort Collins publishes the "Recreator," a popular seasonal guide to recreational activities and facilities in Fort Collins. The "Recreator" has continually been published for over 30 years. It is distributed via direct mail, online and locally at libraries, recreation centers and businesses.
The "Northern Colorado Business Report" is also housed in Fort Collins, and is the largest business-to-business newspaper in Northern Colorado. It covers Larimer and Weld counties.
Colorado State University funds a student-run radio station that focuses on underground and local music, KCSU-FM; and KRFC is the local Front Range Public Radio, a volunteer radio station.
One local television station provided coverage of Fort Collins and the surrounding area, NoCo Channel 5, a CBS affiliate, until the a new station owner decided to shutter operations. Fort Collins has Public, educational, and government access (PEG) cable TV channels. City Cable 14 is the local Government-access television (GATV) cable channel, and broadcasts city and county meetings, as well as studio-produced local programming. Poudre School District and Colorado State University each have public access stations as well. There is also a Fort Collins Public Access Network (PAN) station, channel 97 on Comcast, which broadcasts 24 hours a day.
Education.
K-12 public education is provided through Poudre School District (PSD), the second-largest employer in Fort Collins after Colorado State University. Fort Collins is home to four major high schools and several charter schools with middle school and high school grades. They include Fort Collins High School, Rocky Mountain High School, Poudre High School, Fossil Ridge High School, Centennial High School, Polaris School for Expeditionary Learning Outward Bound, Ridgeview Classical Schools, and Liberty Common High School. Liberty Common High School and Liberty Common School are the same, with LCHS housing grades 7–12 and LCS housing K-6.
The Poudre School District is also home to ten middle schools, including Lesher Middle IB World School, Blevins Middle School, Boltz Middle School, Cache La Poudre Middle School, Kinard Core Knowledge Middle School, Lincoln IB World Middle School, Polaris Expeditionary Learning School, Preston Middle School, Webber Middle School, and Wellington Middle School. Liberty Common School and Ridgeview Classical Schools are K–12 schools and therefore also have middle school students.
PSD is home to 32 elementary schools. The elementary schools range from neighborhood schools to specialized schools, core knowledge programs and the IB program. Among the schools housing the core knowledge program are Moore Core Knowledge, O'Dea Core Knowledge, Traut Core Knowledge, Zach Core Knowledge and Ridgeview Classical Schools. Bennett IB World School, Dunn IB World School and McGraw IB World School house the IB program. In addition, PSD is home to a bilingual educational experience at Harris Bilingual. Other schools with an entrance selection include the Lab School and Traut Core Knowledge. The newest elementary school is Bethke, a Core Knowledge school in Timnath, that started in the fall of 2008.
The city has a number of private and charter schools. Ridgeview Classical Schools was rated by "U.S. News & World Report" (December 2008) among the top ten charter high schools in the nation. T.R. Paul Academy of Arts and Knowledge is a charter school formerly known as Northern Colorado Academy of Arts and Knowledge. Heritage Christian Academy (formerly known as Heritage Christian School) is a private, pre-K–12 school.
Higher education.
Colorado State University heads up the choices in higher education. Front Range Community College also maintains a campus in the city, and grants associate's degrees in arts, science, general studies, and applied science. The college offers 17 high school vocational programs and more than 90 continuing education classes. Additionally, the University of Phoenix and Regis University maintain satellite campuses there.
The Institute of Business & Medical Careers provides professional training in the business and medical professions. The institute's first campus was established in the city in 1987.
The Fort Collins Public Library was established in 1900, the sixth public library in the state. The library formed a regional library district through a ballot measure in 2006. It has been renamed Poudre River Public Library District. The district operates three branches: the Old Town Library is located in downtown Fort Collins; the Harmony library is hosted at Front Range Community College; and the Council Tree Library, which opened in 2009, is at the Front Range Village Shopping Center. The library participates in cooperative projects with the local school district and Colorado State University.
Fort Collins has a range of research institutes. Facilities are maintained by the Centers for Disease Control and Prevention's Division of Vector-Borne Diseases, the Center for Advanced Technology and the Colorado Water Resource Research Institute. Other facilities include the Cooperative Institute for Research in the Atmosphere, the Institute for Scientific Computing, the U.S. Forest Service Experimental Station, the National Center for Genetic Resources Preservation (NCGRP), and the U.S.D.A. Crops Research Laboratory.
Economy.
Major industries and commercial activity.
Fort Collins' economy has a mix of manufacturing and service-related businesses. Fort Collins manufacturing includes Woodward Governor, Anheuser-Busch, and Otterbox. Many high-tech companies have relocated to Fort Collins because of the resources of Colorado State University and its research facilities. Hewlett Packard, Intel, AMD, Avago, Beckman Coulter, National Semiconductor, LSI, Rubicon Water and Pelco all have offices in Fort Collins. Other industries include clean energy, bioscience, and agri-tech businesses.
The largest employers of Fort Collins residents at the turn of the century were the following:
Regional economic development partners include the City of Fort Collins Economic Health Office, Northern Colorado Economic Development Corporation, Small Business Development Center, and Rocky Mountain Innovation Initiative (RMI2).
In 2013, Fort Collins ranked No. 7 on "Forbes"' list of the Best Places for Business and Careers, just below Denver (ranked No. 6).
Sustainability programs.
FortZED is growing to be the world's largest zero energy district. The FortZED area encompasses the Downtown area of Fort Collins and the main campus of Colorado State University.
FortZED is a set of active projects and initiatives, created by public-private partnerships, which utilize smart grid and renewable energy technologies to achieve local power generation and energy demand management. Federal, state, and local funding are making the project a reality. The U.S. Department of Energy has contributed $6.3 million, the Colorado Department of Local Affairs has contributed $778,000 while locally, private companies and foundations have contributed nearly $8 million.
Transportation.
Allegiant Air offered regular passenger airplane service into the nearby Fort Collins / Loveland Airport, but the airline ended commercial flights to this airport. Elite Airways resumed commercial air service at the airport on August 27, 2015, providing non-stop flights to the Chicago Rockford International Airport in Illinois.
The city's former general aviation airport, known as Fort Collins Downtown Airport (3V5), opened in 1966 and closed in 2006.
Fort Collins's downtown streets form a grid with Interstate 25 running north and south on the east side of the city. Many of the streets are named after the town's founders. U.S. Highway 287 becomes College Avenue inside the city and is the busiest street; It runs north and south, effectively bisecting the city, and serving as the east–west meridian, while Mountain Avenue is the north-south. SH 14 runs concurrent with US 287 at the northern city limit to Jefferson Street, running southeast along Jefferson (later turning into Riverside Avenue), then turning east onto Mulberry Street where it goes east out of the city after an interchange with Interstate 25.
The city bus system, known as Transfort, operates more than a dozen routes throughout Fort Collins Monday through Saturday, except major holidays.
The Mason Corridor (MAX) is a bus rapid transit that provides service parallel to College Avenue from Downtown Fort Collins to a transit center just south of Harmony Road. The trip takes approximately 15 minutes from end to end with various stops between. The service began in May 2014. The Mason Corridor and the Mason Express are intended to be the center of future transit-oriented development.
Fort Collins is connected to Loveland, Berthoud, and Longmont via the FLEX regional bus route.
Taxi service is provided 24 hours a day, 365 days per year by Northern Colorado Yellow Cab. Pedicabs are also available from HopON LLC and Dream team Pedicabs. Northern Colorado Yellow Cab operates the largest fleet of wheelchair accessible vehicles in Northern Colorado, and also provides courier and paratransit services.
Bicycling is a popular and viable means of transportation in Fort Collins. There are more than of designated bikeways in Fort Collins, including on street designated bike lanes, and the Spring Creek and Poudre River Trails, both paved. There is also a dirt trail, the Foothills Trail, parallel to Horsetooth Reservoir from Dixon Reservoir north to Campeau Open Space and Michaud Lane.
The Fort Collins Bicycle Library lends bicycles to visitors, students, and residents looking to explore the city of Fort Collins. There are self-guided tours from the "Bike the Sites" collection, including a Brewery Tour, Environmental Learning Tour, and the Historic Tour. The Bike Library is centrally located in the heart of downtown Fort Collins in Old Town Square.
In 2013 the League of American Bicyclists designated Fort Collins as a Platinum-level Bicycle Friendly Community – one of four in the United States.
Fort Collins also once had a municipally owned trolley service with three branches from the intersection of Mountain and College avenues. It was closed in 1951 after ceasing to be profitable. In 1983–84, a portion of the Mountain Avenue line and one of the original trolley cars, Car 21, were restored as a heritage trolley service, under the same name used by the original system, the Fort Collins Municipal Railway. This has been in operation since the end of 1984 on weekends and holidays in the spring and summer, as a tourist- and cultural/educational attraction small fee applies to ride.
Commercial shipping.
Parcel service for Fort Collins is provided by FedEx, Airport Express, DHL, Burlington Air Express, UPS, and Purolator. Fort Collins has two-day rail freight access to the West Coast or the East Coast and has eight motor freight carriers. Many local industrial sites have rail freight spur service. The city is served by Union Pacific and Burlington Northern Santa Fe railroads.
Shane Swartz 1993-1994 U.S. National Amateur Boxing Champion at 165 lbs. and Gold medalist at 1993-1994 U.S. Olympic Festival. Boxed amateur and professional. 
In popular culture.
Fort Collins is known along with Marceline, Missouri as one of the towns that inspired the design of Main Street, U.S.A. inside the main entrance of the many 'Disneyland'-style parks run by The Walt Disney Company around the world. Harper Goff, who worked on Main Street, U.S.A. with Walt, showed Walt some photos of his childhood home of Fort Collins, Colorado. Walt liked the look, and so many of the features of the town were incorporated into Main Street, U.S.A.
Fort Collins was the setting of the infamous Balloon boy hoax of October 15, 2009.

</doc>
<doc id="11508" url="https://en.wikipedia.org/wiki?curid=11508" title="Francis Drake">
Francis Drake

Sir Francis Drake, vice admiral ( – 27 January 1596) was an English sea captain, privateer, navigator, slaver, and politician of the Elizabethan era. Drake carried out the second circumnavigation of the world in a single expedition, from 1577 to 1580, and was the first to complete the voyage as captain while leading the expedition throughout the entire circumnavigation. With his incursion into the Pacific he inaugurated an era of privateering and piracy in the western coast of the Americasan area that had previously been free of piracy.
Elizabeth I of England awarded Drake a knighthood in the year of 1581. He was second-in-command of the English fleet against the Spanish Armada in 1588. He died of dysentery in January of 1596 after unsuccessfully attacking San Juan, Puerto Rico.
His exploits made him a hero to the English but a pirate to the Spaniards to whom he was known as "El Draque". King Philip II was said to have offered a reward of 20,000 ducats, about £4 million (US$6.5m) by modern standards, for his life.
Birth and early years.
Francis Drake was born in Tavistock, Devon, England. Although his birth is not formally recorded, it is known that he was born while the Six Articles were in force. "Drake was two and twenty when he obtained the command of the "Judith"" (1566). This would date his birth to 1544. A date of c.1540 is suggested from two portraits: one a miniature painted by Nicholas Hilliard in 1581 when he was allegedly 42, the other painted in 1594 when he was said to be 53.
He was the eldest of the twelve sons of Edmund Drake (1518–1585), a Protestant farmer, and his wife Mary Mylwaye. The first son was alleged to have been named after his godfather Francis Russell, 2nd Earl of Bedford.
Because of religious persecution during the Prayer Book Rebellion in 1549, the Drake family fled from Devonshire into Kent. There the father obtained an appointment to minister the men in the King's Navy. He was ordained deacon and was made vicar of Upnor Church on the Medway. Drake's father apprenticed Francis to his neighbour, the master of a barque used for coastal trade transporting merchandise to France. The ship master was so satisfied with the young Drake's conduct that, being unmarried and childless at his death, he bequeathed the barque to Drake.
Marriage and family.
Francis Drake married Mary Newman in 1569. She died 12 years later, in 1581. In 1585, Drake married Elizabeth Sydenham—born circa 1562, the only child of Sir George Sydenham, of Combe Sydenham, who was the High Sheriff of Somerset. After Drake's death, the widow Elizabeth eventually married Sir William Courtenay of Powderham. As Sir Francis Drake had no children, his estate and titles passed on to his nephew (also named Francis).
Sailing career.
At age 23, Drake made his first voyage to the Americas, sailing with his second cousin, Sir John Hawkins, on one of a fleet of ships owned by his relatives, the Hawkins family of Plymouth. In 1568 Drake was again with the Hawkins fleet when it was trapped by the Spaniards in the Mexican port of San Juan de Ulúa. He escaped along with Hawkins.
Following the defeat at San Juan de Ulúa, Drake vowed revenge. He made two voyages to the West Indies, in 1570 and 1571, of which little is known.
In 1572, he embarked on his first major independent enterprise. He planned an attack on the Isthmus of Panama, known to the Spanish as Tierra Firme and the English as the Spanish Main. This was the point at which the silver and gold treasure of Peru had to be landed and sent overland to the Caribbean Sea, where galleons from Spain would pick it up at the town of Nombre de Dios. Drake left Plymouth on 24 May 1572, with a crew of 73 men in two small vessels, the "Pascha" (70 tons) and the "Swan" (25 tons), to capture Nombre de Dios.
His first raid was late in July 1572. Drake and his men captured the town and its treasure. When his men noticed that Drake was bleeding profusely from a wound, they insisted on withdrawing to save his life and left the treasure. Drake stayed in the area for almost a year, raiding Spanish shipping and attempting to capture a treasure shipment.
In 1573, he joined Guillaume Le Testu, a French buccaneer, in an attack on a richly laden mule train. Drake and his party found that they had captured around 20 tons of silver and gold. They buried much of the treasure, as it was too much for their party to carry. (An account of this may have given rise to subsequent stories of pirates and buried treasure.) Wounded, Le Testu was captured and later beheaded. The small band of adventurers dragged as much gold and silver as they could carry back across some 18 miles of jungle-covered mountains to where they had left the raiding boats. When they got to the coast, the boats were gone. Drake and his men, downhearted, exhausted and hungry, had nowhere to go and the Spanish were not far behind.
At this point Drake rallied his men, buried the treasure on the beach, and built a raft to sail with two volunteers ten miles along the surf-lashed coast to where they had left the flagship. When Drake finally reached its deck, his men were alarmed at his bedraggled appearance. Fearing the worst, they asked him how the raid had gone. Drake could not resist a joke and teased them by looking downhearted. Then he laughed, pulled a necklace of Spanish gold from around his neck and said "Our voyage is made, lads!" By 9 August 1573, he had returned to Plymouth.
Circumnavigation of the earth (1577–1580).
With the success of the Panama isthmus raid, in 1577 Elizabeth I of England sent Drake to start an expedition against the Spanish along the Pacific coast of the Americas. Drake used the Plans that Sir Richard Grenville had received the Patent for in 1574 from Elizabeth, which was rescinded a year later after protests from Philip of Spain. He set out from Plymouth on 15 November 1577, but bad weather threatened him and his fleet. They were forced to take refuge in Falmouth, Cornwall, from where they returned to Plymouth for repair.
After this major setback, he set sail again on 13 December, aboard "Pelican", with four other ships and 164 men. He soon added a sixth ship, "Mary" (formerly "Santa Maria"), a Portuguese merchant ship that had been captured off the coast of Africa near the Cape Verde Islands. He also added its captain, Nuno da Silva, a man with considerable experience navigating in South American waters.
Drake's fleet suffered great attrition; he scuttled both "Christopher" and the flyboat "Swan" due to loss of men on the Atlantic crossing. He made landfall at the gloomy bay of San Julian, in what is now Argentina. Ferdinand Magellan had called here half a century earlier, where he put to death some mutineers.
Drake's men saw weathered and bleached skeletons on the grim Spanish gibbets. They discovered that "Mary" had rotting timbers, so they burned the ship. Following Magellan's example, Drake tried and executed his own 'mutineer' Thomas Doughty. Drake decided to remain the winter in San Julian before attempting the Strait of Magellan.
Entering the Pacific (1578).
The three remaining ships of his convoy departed for the Magellan Strait at the southern tip of South America. A few weeks later (September 1578) Drake made it to the Pacific, but violent storms destroyed one of the three ships, the "Marigold" (captained by John Thomas) in the strait and caused another, the "Elizabeth" captained by John Wynter, to return to England, leaving only the "Pelican". After this passage, the "Pelican" was pushed south and discovered an island which Drake called Elizabeth Island. Drake, like navigators before him, probably reached a latitude of 55°S (according to astronomical data quoted in Hakluyt's "The Principall Navigations, Voiages and Discoveries of the English Nation" of 1589) along the Chilean coast. In the Magellan Strait Francis and his men engaged in skirmish with local indigenous people becoming the first Europeans to kill indigenous peoples in southern Patagonia. During Francis stay in the strait crew members discovered that an infusion made of the bark of "Drimys winteri" could be used as remedy against scurvy. Captain Winter ordered the collection of great amounts of bark – hence the scientific name. 
Despite popular lore, it seems unlikely that he reached Cape Horn or the eponymous Drake Passage, because his descriptions do not fit the first and his shipmates denied having seen an open sea. The first report of his discovery of an open channel south of Tierra del Fuego was written after the 1618 publication of the voyage of Willem Schouten and Jacob le Maire around Cape Horn in 1616.
He pushed onwards in his lone flagship, now renamed the "Golden Hind" in honour of Sir Christopher Hatton (after his coat of arms). The "Golden Hind" sailed north along the Pacific coast of South America, attacking Spanish ports and pillaging towns. Some Spanish ships were captured, and Drake used their more accurate charts. Before reaching the coast of Peru, Drake visited Mocha Island, where he was seriously injured by hostile Mapuche. Later he sacked the port of Valparaíso further north in Chile where he also captured a ship full of Chilean wine.
Capture of Spanish treasure ships.
Near Lima, Drake captured a Spanish ship laden with 25,000 pesos of Peruvian gold, amounting in value to 37,000 ducats of Spanish money (about £7m by modern standards). Drake also discovered news of another ship, "Nuestra Señora de la Concepción", which was sailing west towards Manila. It would come to be called the "Cacafuego". Drake gave chase and eventually captured the treasure ship, which proved his most profitable capture.
Aboard "Nuestra Señora de la Concepción", Drake found of gold, a golden crucifix, jewels, 13 chests full of royals of plate and 26 tons of silver. Drake was naturally pleased at his good luck in capturing the galleon and he showed it by dining with the captured ship's officers and gentleman passengers. He offloaded his captives a short time later, and gave each one gifts appropriate to their rank, as well as a letter of safe conduct.
Coast of California: Nova Albion (1579).
After looting the Cacafuego, Drake turned north, hoping to meet another Spanish treasure ship coming south on its return from Manila to Acapulco. Although he failed to find a treasure ship, Drake reputedly sailed as far north as the 38th parallel, landing on the coast of California on 17 June 1579. He found a good port, landed, repaired and restocked his vessels, then stayed for a time, keeping friendly relations with the Coast Miwok natives. He claimed the land in the name of the Holy Trinity for the English Crown, called "Nova Albion"—Latin for "New Britain". Assertions that he left some of his men behind as an embryo "colony" are founded on the reduced number who were with him in the Moluccas.
The precise location of the port was carefully guarded to keep it secret from the Spaniards, and several of Drake's maps may have been altered to this end. All first-hand records from the voyage, including logs, paintings and charts, were lost when Whitehall Palace burned in 1698. A bronze plaque inscribed with Drake's claim to the new lands – Drake's Plate of Brass – fitting the description in his account, was discovered in Marin County, California but was later declared a hoax. Now a National Historic Landmark, the officially recognised location of Drake's New Albion is Drakes Bay, California.
Across the Pacific and around Africa.
Drake left the Pacific coast, heading southwest to catch the winds that would carry his ship across the Pacific, and a few months later reached the Moluccas, a group of islands in the western Pacific, in eastern modern-day Indonesia. While there, "Golden Hind" became caught on a reef and was almost lost. After the sailors waited three days for expedient tides and dumped cargo, they freed the barque. Befriending a sultan king of the Moluccas, Drake and his men became involved in some intrigues with the Portuguese there. He made multiple stops on his way toward the tip of Africa, eventually rounded the Cape of Good Hope, and reached Sierra Leone by 22 July 1580.
Return to Plymouth (1580).
On 26 September, "Golden Hind" sailed into Plymouth with Drake and 59 remaining crew aboard, along with a rich cargo of spices and captured Spanish treasures. The Queen's half-share of the cargo surpassed the rest of the crown's income for that entire year. Drake was hailed as the first Englishman to circumnavigate the Earth (and the second such voyage arriving with at least one ship intact, after Elcano's in 1520).
The Queen declared that all written accounts of Drake's voyages were to become the Queen's secrets of the Realm, and Drake and the other participants of his voyages on the pain of death sworn to their secrecy; she intended to keep Drake's activities away from the eyes of rival Spain. Drake presented the Queen with a jewel token commemorating the circumnavigation. Taken as a prize off the Pacific coast of Mexico, it was made of enamelled gold and bore an African diamond and a ship with an ebony hull.
For her part, the Queen gave Drake a jewel with her portrait, an unusual gift to bestow upon a commoner, and one that Drake sported proudly in his 1591 portrait by Marcus Gheeraerts now at the National Maritime Museum, Greenwich. On one side is a state portrait of Elizabeth by the miniaturist Nicholas Hilliard, on the other a sardonyx cameo of double portrait busts, a regal woman and an African male. The "Drake Jewel", as it is known today, is a rare documented survivor among sixteenth-century jewels; it is conserved at the Victoria and Albert Museum, London.
Award of knighthood.
Queen Elizabeth awarded Drake a knighthood aboard "Golden Hind" in Deptford on 4 April 1581; the dubbing being performed by a French diplomat, Monsieur de Marchaumont, who was negotiating for Elizabeth to marry the King of France's brother, Francis, Duke of Anjou. By getting the French diplomat involved in the knighting, Elizabeth was gaining the implicit political support of the French for Drake's actions. During the Victorian era, in a spirit of nationalism, the story was promoted that Elizabeth I had done the knighting.
Award of arms.
After receiving his knighthood Drake unilaterally adopted the armorials of the ancient Devon family of Drake of Ash, near Musbury, to whom he claimed a distant but unspecified kinship. These arms were: "Argent, a wyvern wings displayed and tail nowed gules", and the crest, "a dexter arm Proper grasping a battle axe Sable, headed Argent". The head of that family, also a distinguished sailor, Sir Bernard Drake (d.1586), angrily refuted Sir Francis's claimed kinship and his right to bear his family's arms. That dispute led to "a box in the ear" being given to Sir Francis by Sir Bernard at court, as recorded by John Prince in his "Worthies of Devon" (1697). Queen Elizabeth, to assuage matters, awarded Sir Francis his own coat of arms, blazoned as follows:
The above is considered by students of heraldry to be an early example of "debased arms" due to their over-complexity, particularly as regards the crest. The motto, "Sic Parvis Magna", translated literally, is: "Thus great things from small things (come)". The hand out of the clouds, labelled "Auxilio Divino", means "With Divine Help". The full achievement is depicted in the form of a large coloured plaster overmantel in the Lifetimes Gallery at Buckland Abbey
Nevertheless, Drake continued to quarter his new arms with the wyvern gules. The arms adopted by his nephew Sir Francis Drake, 1st Baronet (1588–1637) of Buckland were the arms of Drake of Ash, but the wyvern without a "nowed" (knotted) tail.
Political career.
In September 1581, Drake became the Mayor of Plymouth, and was a member of parliament in 1581, for an unknown constituency (possibly Camelford), and again in 1584 for Bossiney and Plymouth in 1593.
Purchase of Buckland Abbey.
In 1580 Drake purchased Buckland Abbey via intermediaries from Sir Richard Greynvile, hiding who was actually purchasing the Abbey, a large manor house near Yelverton in Devon, from Sir Richard. He lived there for fifteen years, until his final voyage, and it remained in his family for several generations. Buckland Abbey is now in the care of the National Trust and a number of mementos of his life are displayed there.
Great Expedition.
War had already been declared by Phillip II after the Treaty of Nonsuch, so the Queen through Francis Walsingham ordered Sir Francis Drake to lead an expedition to attack the Spanish colonies in a kind of preemptive strike. An expedition left Plymouth in September 1585 with Drake in command of twenty one ships with 1,800 soldiers under Christopher Carleill. He first attacked Vigo in Spain and held the place for two weeks ransoming supplies. He then plundered Santiago in the Cape Verde islands after which the fleet then sailed across the Atlantic, sacked the port of Santo Domingo and captured the city of Cartagena de Indias in present-day Colombia. On 6 June 1586, during the return leg of the voyage, he raided the Spanish fort of San Augustín in Spanish Florida.
After the raids he then went on to find Sir Walter Raleigh's settlement much further North at Roanoke which he replenished and also took back with him all of the original colonists before Sir Richard Greynvile arrived with supplies and more colonists. He finally reached England on 22 July, when he sailed into Portsmouth, England to a hero's welcome.
Spanish Armada.
Encouraged by these acts Philip II ordered a planned invasion of England.
Cadiz raid.
In another pre-emptive strike, Drake "singed the beard of the King of Spain" in 1587 by sailing a fleet into Cadiz and also Corunna, two of Spain's main ports, and occupied the harbours. He destroyed 37 naval and merchant ships. The attack delayed the Spanish invasion by a year. Over the next month, Drake patrolled the Iberian coasts between Lisbon and Cape St. Vincent, intercepting and destroying ships on the Spanish supply lines. Drake estimated that he captured around 1600–1700 tons of barrel staves, enough to make 25,000 to for containing provisions.
Defeat of the Spanish Armada.
Drake was vice admiral in command of the English fleet (under Lord Howard of Effingham) when it overcame the Spanish Armada that was attempting to invade England in 1588. As the English fleet pursued the Armada up the English Channel in closing darkness, Drake broke off and captured the Spanish galleon "Rosario", along with Admiral Pedro de Valdés and all his crew. The Spanish ship was known to be carrying substantial funds to pay the Spanish Army in the Low Countries. Drake's ship had been leading the English pursuit of the Armada by means of a lantern. By extinguishing this for the capture, Drake put the fleet into disarray overnight.
On the night of 29 July, along with Howard, Drake organised fire-ships, causing the majority of the Spanish captains to break formation and sail out of Calais into the open sea. The next day, Drake was present at the Battle of Gravelines. He wrote as follows to Admiral Henry Seymour after coming upon part of the Spanish Armada, whilst aboard "Revenge" on 31 July 1588 (21 July 1588 O.S.):Coming up to them, there has passed some common shot between some of our fleet and some of them; and as far as we perceive, they are determined to sell their lives with blows.
The most famous (but probably apocryphal) anecdote about Drake relates that, prior to the battle, he was playing a game of bowls on Plymouth Hoe. On being warned of the approach of the Spanish fleet, Drake is said to have remarked that there was plenty of time to finish the game and still beat the Spaniards. There is no known eyewitness account of this incident and the earliest retelling of it was printed 37 years later. Adverse winds and currents caused some delay in the launching of the English fleet as the Spanish drew nearer, perhaps prompting a popular myth of Drake's cavalier attitude to the Spanish threat.
Drake-Norris Expedition.
In 1589, the year after defeating the Armada, Drake and Sir John Norreys were given three tasks. They were ordered to first seek out and destroy the remaining ships, second they were to support the rebels in Lisbon, Portugal against King Philip II (then king of Spain and Portugal), and third they were to take the Azores if possible. Drake and Norreys destroyed a few ships in the harbour of A Coruña in Spain but lost more than 12,000 lives and 20 ships. This delayed Drake, and he was forced to forgo hunting the rest of the surviving ships and head on to Lisbon.
Defeat and Death.
Drake's seafaring career continued into his mid-fifties. In 1595, he failed to conquer the port of Las Palmas, and following a disastrous campaign against Spanish America, where he suffered a number of defeats, he unsuccessfully attacked San Juan de Puerto Rico, eventually losing the Battle of San Juan.
The Spanish gunners from El Morro Castle shot a cannonball through the cabin of Drake's flagship, and he survived; but a few weeks later, in January 1596, he died of dysentery when he was about 55, while anchored off the coast of Portobelo, Panama, where some Spanish treasure ships had sought shelter. Following his death, the English fleet withdrew.
Before dying, he asked to be dressed in his full armour. He was buried at sea in a lead coffin, near Portobelo. Divers continue to search for the coffin.
Cultural impact.
In the UK there are various places named after him, especially in Plymouth, Devon, where various places carry his name, including the naval base (HMS Drake), Drake's Island and a roundabout named Drake Circus, along with a shopping mall named after the roundabout. Plymouth Hoe is also home to a statue of Drake.
In the United States Drakes Bay and Sir Francis Drake Boulevard of Marin County, California are both named after him, as well as the high school in San Anselmo, California. The boulevard runs between Drakes Bay at Point Reyes to Point San Quentin on San Francisco Bay. A large hotel in Union Square, San Francisco also bears his name. Additionally, the Sir Francis Drake Channel in the British Virgin Islands bears his name.
In British Columbia, Canada, where some theorize he may also have landed to the north of the usual site considered to be Nova Albion, various mountains were named in the 1930s for him, or in connection with Elizabeth I or other figures of that era, including Mount Sir Francis Drake, Mount Queen Bess, and the Golden Hinde, the highest mountain on Vancouver Island.
Drake's will was the focus of a vast confidence scheme which Oscar Hartzell perpetrated in the 1920s and 1930s. He convinced thousands of people, mostly in the American Midwest, that Drake's fortune was being held by the British government, and had compounded to a huge amount. If their last name was Drake they might be eligible for a share if they paid Hartzell to be their agent. The swindle continued until a copy of Drake's will was brought to Hartzell's mail fraud trial and he was convicted and imprisoned.
Drake was portrayed by the Canadian actor Matheson Lang in the 1935 film "Drake of England". Modern workings of stories involving Drake include the 1961 British television series "Sir Francis Drake", and the 2009 US television movie "The Immortal Voyage of Captain Drake".
In 2003, he was the namesake of the Drake Tribe in "".
Drake's execution of Thomas Doughty is the subject of Robert E. Howard's Solomon Kane poem, "."
Nathan Drake, a fictional descendant of Sir Francis Drake, searches for lost treasure supposedly found by Sir Francis during his circumnavigation in the video game ', and again in '.
In Popular Culture.
At the Memorial Service for the Challenger Disaster, U.S. President Ronald Reagan says that it was 390 years to the day from the death of Drake to the Disaster, but the Disaster occurred on 28th January, 1986, while Drake's demise took place, as noted above, on 27th January, 1596, and even accounting for the differences in the Julian Calendar and the Gregorian Calendar, the dates are close, but not exact.
Controversies.
Slave trading.
Drake accompanied his second cousin Sir John Hawkins in making the third English slave-trading expeditions, making fortunes through the abduction and transportation of West African people, and then exchanging them for high-value goods. The first Englishman recorded to have taken slaves from Africa was John Lok, a London trader who, in 1555, brought to England five slaves from Guinea.
A second London trader taking slaves at that time was William Towerson whose fleet sailed into Plymouth following his 1556 voyage to Africa and from Plymouth on his 1557 voyage. Despite the exploits of Lok and Towerson, John Hawkins of Plymouth is widely acknowledged to be an early pioneer of the English slave trade. While Hawkins made only three such trips, ultimately the English were to dominate the trade.
Around 1563 Drake first sailed west to the Spanish Main, on a ship owned and commanded by John Hawkins, with a cargo of people forcibly removed from the coast of West Africa. The Englishmen sold their African captives into slavery in Spanish plantations. In general, the kidnapping and forced transportation of people was considered to be a criminal offence under English law at the time, although legal protection did not extend to slaves, non-Protestants or criminals. Hawkins' own account of his actions (in which Drake took part) cites two sources for their victims. One was military attacks on African towns and villages, the other was attacking Portuguese slave ships.
Conflict in the Caribbean.
During his early days as a slave-trader, Drake took an immediate dislike to the Spanish, at least in part due to their Catholicism and inherent distrust of non-Spanish. His hostility is said to have increased over an incident at San Juan de Ulúa in 1568, when Drake was sailing with the fleet of his second cousin John Hawkins. Whilst negotiating to resupply and repair at the Spanish port, the fleet were attacked by Spanish warships, with all but two of the English ships lost. Drake survived the attack by swimming.
The most celebrated of Drake's adventures along the Spanish Main was his capture of the Spanish Silver Train at Nombre de Dios in March 1573. With a crew including many French privateers and Maroons—African slaves who had escaped the Spanish—Drake raided the waters around Darien (in modern Panama) and tracked the Silver Train to the nearby port of Nombre de Dios. He made off with a fortune in gold, but had to leave behind another fortune in silver, because it was too heavy to carry back to England.
It was during this expedition that he climbed a high tree in the central mountains of the Isthmus of Panama and thus became the first Englishman to see the Pacific Ocean. He remarked as he saw it that he hoped one day an Englishman would be able to sail it—which he would do years later as part of his circumnavigation of the world.
When Drake returned to Plymouth after the raids, the government signed a temporary truce with King Philip II of Spain and so was unable to acknowledge Drake's accomplishment officially. Drake was considered a hero in England and a pirate in Spain for his raids.
Ireland.
In 1575, Drake was present at the Rathlin Island Massacre, which was a part of the English plantation effort in Ulster, where 600 men, women, and children were massacred after surrendering.
Francis Drake was in charge of the ships which transported John Norreys' troops to Rathlin Island, commanding a small frigate called "Falcon", with a total complement of 25. At the time of the massacre, he was charged with the task of keeping Scottish vessels from bringing reinforcements to Rathlin Island. The people who were massacred were, in fact, the families of Sorley Boy MacDonnell's followers.
Execution of Thomas Doughty.
On his voyage to interfere with Spanish treasure fleets, Drake had several quarrels with his co-commander Thomas Doughty and on 3 June 1578, accused him of witchcraft and charged him with mutiny and treason in a shipboard trial. Drake claimed to have a (never presented) commission from the Queen to carry out such acts and denied Doughty a trial in England. The main pieces of evidence against Doughty were the testimony of the ship's carpenter, Edward Bright, who after the trial was promoted to master of the ship "Marigold", and Doughty's admission of telling Lord Burghley, a vocal opponent of agitating the Spanish, of the intent of the voyage. Drake consented to his request of Communion and dined with him, of which Francis Fletcher had this strange account:
Drake had Thomas Doughty beheaded on 2 July 1578. When the ship's chaplain Francis Fletcher in a sermon suggested that the woes of the voyage in January 1580 were connected to the unjust demise of Doughty, Drake chained the clergyman to a hatch cover and pronounced him excommunicated.

</doc>
<doc id="11512" url="https://en.wikipedia.org/wiki?curid=11512" title="Fast Fourier transform">
Fast Fourier transform

A fast Fourier transform (FFT) algorithm computes the discrete Fourier transform (DFT) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. An FFT rapidly computes such transformations by factorizing the DFT matrix into a product of sparse (mostly zero) factors. As a result, it manages to reduce the complexity of computing the DFT from formula_1, which arises if one simply applies the definition of DFT, to formula_2, where formula_3 is the data size.
Fast Fourier transforms are widely used for many applications in engineering, science, and mathematics. The basic ideas were popularized in 1965, but some algorithms had been derived as early as 1805. In 1994 Gilbert Strang described the FFT as "the most important numerical algorithm of our lifetime" and it was included in Top 10 Algorithms of 20th Century by the IEEE journal Computing in Science & Engineering.
Overview.
There are many different FFT algorithms involving a wide range of mathematics, from simple complex-number arithmetic to group theory and number theory; this article gives an overview of the available techniques and some of their general properties, while the specific algorithms are described in subsidiary articles linked below.
The DFT is obtained by decomposing a sequence of values into components of different frequencies. This operation is useful in many fields (see discrete Fourier transform for properties and applications of the transform) but computing it directly from the definition is often too slow to be practical. An FFT is a way to compute the same result more quickly: computing the DFT of "N" points in the naive way, using the definition, takes O("N") arithmetical operations, while an FFT can compute the same DFT in only O("N" log "N") operations. The difference in speed can be enormous, especially for long data sets where "N" may be in the thousands or millions. In practice, the computation time can be reduced by several orders of magnitude in such cases, and the improvement is roughly proportional to "N" / log("N"). This huge improvement made the calculation of the DFT practical; FFTs are of great importance to a wide variety of applications, from digital signal processing and solving partial differential equations to algorithms for quick multiplication of large integers.
The best-known FFT algorithms depend upon the factorization of "N", but there are FFTs with O("N" log "N") complexity for all "N", even for prime "N". Many FFT algorithms only depend on the fact that formula_4 is an "N"-th primitive root of unity, and thus can be applied to analogous transforms over any finite field, such as number-theoretic transforms. Since the inverse DFT is the same as the DFT, but with the opposite sign in the exponent and a 1/"N" factor, any FFT algorithm can easily be adapted for it.
History.
The development of fast algorithms for DFT can be traced to Gauss's unpublished work in 1805 when he needed it to interpolate the orbit of asteroids Pallas and Juno from sample observations. His method was very similar to the one published in 1965 by Cooley and Tukey, who are generally credited for the invention of the modern generic FFT algorithm. While Gauss's work predated even Fourier's results in 1822, he did not analyze the computation time and eventually used other methods to achieve his goal.
Between 1805 and 1965, some versions of FFT were published by other authors. Yates in 1932 published his version called "interaction algorithm", which provided efficient computation of Hadamard and Walsh transforms. Yates' algorithm is still used in the field of statistical design and analysis of experiments. In 1942, Danielson and Lanczos published their version to compute DFT for x-ray crystallography, a field where calculation of Fourier transforms presented a formidable bottleneck. While many methods in the past had focused on reducing the constant factor for formula_1 computation by taking advantage of "symmetries", Danielson and Lanczos realized that one could use the "periodicity" and apply a "doubling trick" to get formula_2 runtime.
Cooley and Tukey published a more general version of FFT in 1965 that is applicable when N is composite and not necessarily a power of 2. Tukey came up with the idea during a meeting of President Kennedy’s Science Advisory Committee where a discussion topic involved detecting nuclear tests by the Soviet Union by setting up sensors to surround the country from outside. To analyze the output of these sensors, a fast Fourier transform algorithm would be needed. Tukey's idea was taken by Richard Garwin and given to Cooley (both worked at IBM's Watson labs) for implementation while hiding the original purpose from him for security reasons. The pair published the paper in a relatively short six months. As Tukey didn't work at IBM, the patentability of the idea was doubted and the algorithm went into the public domain, which, through the computing revolution of the next decade, made FFT one of the indispensable algorithms in digital signal processing.
Definition and speed.
An FFT computes the DFT and produces exactly the same result as evaluating the DFT definition directly; the most important difference is that an FFT is much faster. (In the presence of round-off error, many FFT algorithms are also much more accurate than evaluating the DFT definition directly, as discussed below.)
Let "x", ..., "x" be complex numbers. The DFT is defined by the formula
Evaluating this definition directly requires O("N") operations: there are "N" outputs "X", and each output requires a sum of "N" terms. An FFT is any method to compute the same results in O("N" log "N") operations. More precisely, all known FFT algorithms require Θ("N" log "N") operations (technically, O only denotes an upper bound), although there is no known proof that a lower complexity score is impossible.(Johnson and Frigo, 2007)
To illustrate the savings of an FFT, consider the count of complex multiplications and additions. Evaluating the DFT's sums directly involves "N" complex multiplications and "N"("N"−1) complex additions f which O("N") operations can be saved by eliminating trivial operations such as multiplications by . The well-known radix-2 Cooley–Tukey algorithm, for "N" a power of 2, can compute the same result with only ("N"/2)log("N") complex multiplications (again, ignoring simplifications of multiplications by 1 and similar) and "N"log("N") complex additions. In practice, actual performance on modern computers is usually dominated by factors other than the speed of arithmetic operations and the analysis is a complicated subject (see, e.g., Frigo & Johnson, 2005), but the overall improvement from O("N") to O("N" log "N") remains.
Algorithms.
Cooley–Tukey algorithm.
By far the most commonly used FFT is the Cooley–Tukey algorithm. This is a divide and conquer algorithm that recursively breaks down a DFT of any composite size "N" = "N""N" into many smaller DFTs of sizes "N" and "N", along with O("N") multiplications by complex roots of unity traditionally called twiddle factors (after Gentleman and Sande, 1966).
This method (and the general idea of an FFT) was popularized by a publication of J. W. Cooley and J. W. Tukey in 1965, but it was later discovered that those two authors had independently re-invented an algorithm known to Carl Friedrich Gauss around 1805 (and subsequently rediscovered several times in limited forms).
The best known use of the Cooley–Tukey algorithm is to divide the transform into two pieces of size "N"/2 at each step, and is therefore limited to power-of-two sizes, but any factorization can be used in general (as was known to both Gauss and Cooley/Tukey). These are called the radix-2 and mixed-radix cases, respectively (and other variants such as the split-radix FFT have their own names as well). Although the basic idea is recursive, most traditional implementations rearrange the algorithm to avoid explicit recursion. Also, because the Cooley–Tukey algorithm breaks the DFT into smaller DFTs, it can be combined arbitrarily with any other algorithm for the DFT, such as those described below.
Other FFT algorithms.
There are other FFT algorithms distinct from Cooley–Tukey.
Cornelius Lanczos did pioneering work on the FFS and FFT with G.C. Danielson (1940).
For "N" = "N""N" with coprime "N" and "N", one can use the Prime-Factor (Good-Thomas) algorithm (PFA), based on the Chinese Remainder Theorem, to factorize the DFT similarly to Cooley–Tukey but without the twiddle factors. The Rader-Brenner algorithm (1976) is a Cooley–Tukey-like factorization but with purely imaginary twiddle factors, reducing multiplications at the cost of increased additions and reduced numerical stability; it was later superseded by the split-radix variant of Cooley–Tukey (which achieves the same multiplication count but with fewer additions and without sacrificing accuracy). Algorithms that recursively factorize the DFT into smaller operations other than DFTs include the Bruun and QFT algorithms. (The Rader-Brenner and QFT algorithms were proposed for power-of-two sizes, but it is possible that they could be adapted to general composite "n". Bruun's algorithm applies to arbitrary even composite sizes.) Bruun's algorithm, in particular, is based on interpreting the FFT as a recursive factorization of the polynomial "z"−1, here into real-coefficient polynomials of the form "z"−1 and "z" + "az" + 1.
Another polynomial viewpoint is exploited by the Winograd algorithm, which factorizes "z"−1 into cyclotomic polynomials—these often have coefficients of 1, 0, or −1, and therefore require few (if any) multiplications, so Winograd can be used to obtain minimal-multiplication FFTs and is often used to find efficient algorithms for small factors. Indeed, Winograd showed that the DFT can be computed with only O("N") irrational multiplications, leading to a proven achievable lower bound on the number of multiplications for power-of-two sizes; unfortunately, this comes at the cost of many more additions, a tradeoff no longer favorable on modern processors with hardware multipliers. In particular, Winograd also makes use of the PFA as well as an algorithm by Rader for FFTs of "prime" sizes.
Rader's algorithm, exploiting the existence of a generator for the multiplicative group modulo prime "N", expresses a DFT of prime size "n" as a cyclic convolution of (composite) size "N"−1, which can then be computed by a pair of ordinary FFTs via the convolution theorem (although Winograd uses other convolution methods). Another prime-size FFT is due to L. I. Bluestein, and is sometimes called the chirp-z algorithm; it also re-expresses a DFT as a convolution, but this time of the "same" size (which can be zero-padded to a power of two and evaluated by radix-2 Cooley–Tukey FFTs, for example), via the identity formula_8.
FFT algorithms specialized for real and/or symmetric data.
In many applications, the input data for the DFT are purely real, in which case the outputs satisfy the symmetry
and efficient FFT algorithms have been designed for this situation (see e.g. Sorensen, 1987). One approach consists of taking an ordinary algorithm (e.g. Cooley–Tukey) and removing the redundant parts of the computation, saving roughly a factor of two in time and memory. Alternatively, it is possible to express an "even"-length real-input DFT as a complex DFT of half the length (whose real and imaginary parts are the even/odd elements of the original real data), followed by O("N") post-processing operations.
It was once believed that real-input DFTs could be more efficiently computed by means of the discrete Hartley transform (DHT), but it was subsequently argued that a specialized real-input DFT algorithm (FFT) can typically be found that requires fewer operations than the corresponding DHT algorithm (FHT) for the same number of inputs. Bruun's algorithm (above) is another method that was initially proposed to take advantage of real inputs, but it has not proved popular.
There are further FFT specializations for the cases of real data that have even/odd symmetry, in which case one can gain another factor of (roughly) two in time and memory and the DFT becomes the discrete cosine/sine transform(s) (DCT/DST). Instead of directly modifying an FFT algorithm for these cases, DCTs/DSTs can also be computed via FFTs of real data combined with O("N") pre/post processing.
Computational issues.
Bounds on complexity and operation counts.
A fundamental question of longstanding theoretical interest is to prove lower bounds on the complexity and exact operation counts of fast Fourier transforms, and many open problems remain. It is not even rigorously proved whether DFTs truly require Ω("N" log("N")) (i.e., order "N" log("N") or greater) operations, even for the simple case of power of two sizes, although no algorithms with lower complexity are known. In particular, the count of arithmetic operations is usually the focus of such questions, although actual performance on modern-day computers is determined by many other factors such as cache or CPU pipeline optimization.
Following pioneering work by Winograd (1978), a tight Θ("N") lower bound "is" known for the number of real multiplications required by an FFT. It can be shown that only formula_10 irrational real multiplications are required to compute a DFT of power-of-two length formula_11. Moreover, explicit algorithms that achieve this count are known (Heideman & Burrus, 1986; Duhamel, 1990). Unfortunately, these algorithms require too many additions to be practical, at least on modern computers with hardware multipliers (Duhamel, 1990; Frigo & Johnson, 2005).
A tight lower bound is "not" known on the number of required additions, although lower bounds have been proved under some restrictive assumptions on the algorithms. In 1973, Morgenstern proved an Ω("N" log("N")) lower bound on the addition count for algorithms where the multiplicative constants have bounded magnitudes (which is true for most but not all FFT algorithms). This result, however, applies only to the unnormalized Fourier transform (which is a scaling of a unitary matrix by a factor of formula_12), and does not explain why the Fourier matrix is harder to compute than any other unitary matrix (including the identity matrix) under the same scaling. Pan (1986) proved an Ω("N" log("N")) lower bound assuming a bound on a measure of the FFT algorithm's "asynchronicity", but the generality of this assumption is unclear. For the case of power-of-two "N", Papadimitriou (1979) argued that the number formula_13 of complex-number additions achieved by Cooley–Tukey algorithms is "optimal" under certain assumptions on the graph of the algorithm (his assumptions imply, among other things, that no additive identities in the roots of unity are exploited). (This argument would imply that at least formula_14 real additions are required, although this is not a tight bound because extra additions are required as part of complex-number multiplications.) Thus far, no published FFT algorithm has achieved fewer than formula_13 complex-number additions (or their equivalent) for power-of-two "N".
A third problem is to minimize the "total" number of real multiplications and additions, sometimes called the "arithmetic complexity" (although in this context it is the exact count and not the asymptotic complexity that is being considered). Again, no tight lower bound has been proven. Since 1968, however, the lowest published count for power-of-two "N" was long achieved by the split-radix FFT algorithm, which requires formula_16 real multiplications and additions for "N" > 1. This was recently reduced to formula_17 (Johnson and Frigo, 2007; Lundy and Van Buskirk, 2007). A slightly larger count (but still better than split radix for "N"≥256) was shown to be provably optimal for "N"≤512 under additional restrictions on the possible algorithms (split-radix-like flowgraphs with unit-modulus multiplicative factors), by reduction to a Satisfiability Modulo Theories problem solvable by brute force (Haynal & Haynal, 2011).
Most of the attempts to lower or prove the complexity of FFT algorithms have focused on the ordinary complex-data case, because it is the simplest. However, complex-data FFTs are so closely related to algorithms for related problems such as real-data FFTs, discrete cosine transforms, discrete Hartley transforms, and so on, that any improvement in one of these would immediately lead to improvements in the others (Duhamel & Vetterli, 1990).
Approximations.
All of the FFT algorithms discussed above compute the DFT exactly (in exact arithmetic, i.e. neglecting floating-point errors). A few "FFT" algorithms have been proposed, however, that compute the DFT "approximately", with an error that can be made arbitrarily small at the expense of increased computations. Such algorithms trade the approximation error for increased speed or other properties. For example, an approximate FFT algorithm by Edelman et al. (1999) achieves lower communication requirements for parallel computing with the help of a fast multipole method. A wavelet-based approximate FFT by Guo and Burrus (1996) takes sparse inputs/outputs (time/frequency localization) into account more efficiently than is possible with an exact FFT. Another algorithm for approximate computation of a subset of the DFT outputs is due to Shentov et al. (1995). The Edelman algorithm works equally well for sparse and non-sparse data, since it is based on the compressibility (rank deficiency) of the Fourier matrix itself rather than the compressibility (sparsity) of the data. Conversely, if the data are sparse—that is, if only "K" out of "N" Fourier coefficients are nonzero—then the complexity can be reduced to O("K"log("N")log("N"/"K")), and this has been demonstrated to lead to practical speedups compared to an ordinary FFT for N/K>32 in a large-N example (N=2) using a probabilistic approximate algorithm (which estimates the largest "K" coefficients to several decimal places).
Accuracy.
Even the "exact" FFT algorithms have errors when finite-precision floating-point arithmetic is used, but these errors are typically quite small; most FFT algorithms, e.g. Cooley–Tukey, have excellent numerical properties as a consequence of the pairwise summation structure of the algorithms. The upper bound on the relative error for the Cooley–Tukey algorithm is O(ε log "N"), compared to O(ε"N") for the naïve DFT formula, where ε is the machine floating-point relative precision. In fact, the root mean square (rms) errors are much better than these upper bounds, being only O(ε √log "N") for Cooley–Tukey and O(ε √"N") for the naïve DFT (Schatzman, 1996). These results, however, are very sensitive to the accuracy of the twiddle factors used in the FFT (i.e. the trigonometric function values), and it is not unusual for incautious FFT implementations to have much worse accuracy, e.g. if they use inaccurate trigonometric recurrence formulas. Some FFTs other than Cooley–Tukey, such as the Rader-Brenner algorithm, are intrinsically less stable.
In fixed-point arithmetic, the finite-precision errors accumulated by FFT algorithms are worse, with rms errors growing as O(√"N") for the Cooley–Tukey algorithm (Welch, 1969). Moreover, even achieving this accuracy requires careful attention to scaling to minimize loss of precision, and fixed-point FFT algorithms involve rescaling at each intermediate stage of decompositions like Cooley–Tukey.
To verify the correctness of an FFT implementation, rigorous guarantees can be obtained in O("N"log("N")) time by a simple procedure checking the linearity, impulse-response, and time-shift properties of the transform on random inputs (Ergün, 1995).
Multidimensional FFTs.
As defined in the multidimensional DFT article, the multidimensional DFT
transforms an array "x" with a "d"-dimensional vector of indices formula_19 by a set of "d" nested summations (over formula_20 for each "j"), where the division n/N, defined as formula_21, is performed element-wise. Equivalently, it is the composition of a sequence of "d" sets of one-dimensional DFTs, performed along one dimension at a time (in any order).
This compositional viewpoint immediately provides the simplest and most common multidimensional DFT algorithm, known as the row-column algorithm (after the two-dimensional case, below). That is, one simply performs a sequence of "d" one-dimensional FFTs (by any of the above algorithms): first you transform along the "n" dimension, then along the "n" dimension, and so on (or actually, any ordering works). This method is easily shown to have the usual O("N"log("N")) complexity, where formula_22 is the total number of data points transformed. In particular, there are "N"/"N" transforms of size "N", etcetera, so the complexity of the sequence of FFTs is:
In two dimensions, the "x" can be viewed as an formula_24 matrix, and this algorithm corresponds to first performing the FFT of all the rows (resp. columns), grouping the resulting transformed rows (resp. columns) together as another formula_24 matrix, and then performing the FFT on each of the columns (resp. rows) of this second matrix, and similarly grouping the results into the final result matrix.
In more than two dimensions, it is often advantageous for cache locality to group the dimensions recursively. For example, a three-dimensional FFT might first perform two-dimensional FFTs of each planar "slice" for each fixed "n", and then perform the one-dimensional FFTs along the "n" direction. More generally, an asymptotically optimal cache-oblivious algorithm consists of recursively dividing the dimensions into two groups formula_26 and formula_27 that are transformed recursively (rounding if "d" is not even) (see Frigo and Johnson, 2005). Still, this remains a straightforward variation of the row-column algorithm that ultimately requires only a one-dimensional FFT algorithm as the base case, and still has O("N"log("N")) complexity. Yet another variation is to perform matrix transpositions in between transforming subsequent dimensions, so that the transforms operate on contiguous data; this is especially important for out-of-core and distributed memory situations where accessing non-contiguous data is extremely time-consuming.
There are other multidimensional FFT algorithms that are distinct from the row-column algorithm, although all of them have O("N"log("N")) complexity. Perhaps the simplest non-row-column FFT is the vector-radix FFT algorithm, which is a generalization of the ordinary Cooley–Tukey algorithm where one divides the transform dimensions by a vector formula_28 of radices at each step. (This may also have cache benefits.) The simplest case of vector-radix is where all of the radices are equal (e.g. vector-radix-2 divides "all" of the dimensions by two), but this is not necessary. Vector radix with only a single non-unit radix at a time, i.e. formula_29, is essentially a row-column algorithm. Other, more complicated, methods include polynomial transform algorithms due to Nussbaumer (1977), which view the transform in terms of convolutions and polynomial products. See Duhamel and Vetterli (1990) for more information and references.
Other generalizations.
An O("N"log("N")) generalization to spherical harmonics on the sphere "S" with "N" nodes was described by Mohlenkamp, along with an algorithm conjectured (but not proven) to have O("N" log("N")) complexity; Mohlenkamp also provides an implementation in the libftsh library. A spherical-harmonic algorithm with O("N"log("N")) complexity is described by Rokhlin and Tygert.
The Fast Folding Algorithm is analogous to the FFT, except that it operates on a series of binned waveforms rather than a series of real or complex scalar values. Rotation (which in the FFT is multiplication by a complex phasor) is a circular shift of the component waveform.
Various groups have also published "FFT" algorithms for non-equispaced data, as reviewed in Potts "et al." (2001). Such algorithms do not strictly compute the DFT (which is only defined for equispaced data), but rather some approximation thereof (a non-uniform discrete Fourier transform, or NDFT, which itself is often computed only approximately). More generally there are various other methods of spectral estimation.
Applications.
FFT's importance derives from the fact that in signal processing and image processing it has made working in frequency domain equally computationally feasible as working in temporal or spatial domain. Some of the important applications of FFT includes,
References.
The following articles are cited parenthetically in the article: 

</doc>
<doc id="11513" url="https://en.wikipedia.org/wiki?curid=11513" title="Fort William, Highland">
Fort William, Highland

Fort William ( "The Garrison") is the second largest settlement in the Highlands of Scotland with around 10,000 inhabitants — and the largest town: only the city of Inverness is larger.
Fort William is a major tourist centre, with Glen Coe just to the south, Aonach Mòr to the east and Glenfinnan to the west, on the Road to the Isles. It is a centre for hillwalking and climbing due to its proximity to Ben Nevis and many other Munro mountains. It is also known for its nearby downhill mountain bike track. It is the start/end of both the West Highland Way (Milngavie-Fort William) and the Great Glen Way (a walk/cycle way Fort William-Inverness).
Around 726 people (7.33% of the population) can speak Gaelic.
Etymology.
Questions over the town's English name are various. The post-Glorious Revolution fort was named "Fort William" after William of Orange, and the settlement that grew around it was called "Maryburgh", after his wife. This settlement was later renamed "Gordonsburgh", and then "Duncansburgh" before being renamed "Fort William", this time after Prince William, Duke of Cumberland; known to some Scots as "Butcher Cumberland". Given these origins, there have been various suggestions over the years to rename the town (for example, to "Invernevis"). These proposals have led to nothing yet.
Questions over the town's Gaelic name are equally interesting. The Gaelic name for the town is "An Gearasdan", and this is the result of a transliteration from the French term Garrison. French loan-words in the Gaelic language are very rare, and can only correspond with specific times in Scottish history: during David I's politically pacifying introduction of a Norman aristocracy in Scotland after the Norman conquest of England, and the period covering the Auld Alliance.
The most likely derivation for the town's Franco-Gaelic name is from the Scoto-Norman Clan Comyn, who built Inverlochy Castle in the Norman style that is familiar throughout Scotland during this period. French loan-words that take root during the Auld Alliance are far more common in the Scots language than in Gaelic.
History.
Historically, this area of Lochaber was strongly Clan Cameron country, and there were a number of mainly Cameron settlements in the area (such as Blarmacfoldach). The nearby settlement of Inverlochy was the main settlement in the area before the building of the fort, and was also site of the Battle of Inverlochy.
The town grew in size as a settlement when the fort was constructed to control the population after Oliver Cromwell's invasion during the Wars of the Three Kingdoms, and then to suppress the Jacobite uprisings of the 18th century.
In the Jacobite rising known as the Forty-Five, Fort William was besieged for two weeks by the Jacobites, from 20 March to 3 April 1746. However, although the Jacobites had captured both of the other forts in the chain of three Great Glen fortifications (Fort Augustus and the original Fort George) they failed to take Fort William.
During the Second World War, Fort William was the home of HMS "St Christopher" which was a training base for Royal Navy Coastal Forces.
More on the history of the town and the region can be found in the West Highland Museum on the High Street.
Fort William is the northern end of the West Highland Way, a long distance route which runs through the Scottish Highlands to Milngavie, on the outskirts of Glasgow, and the start/end point of the Great Glen Way, which runs between Fort William and Inverness.
On 2 June 2006, a fire destroyed McTavish's Restaurant in Fort William High Street along with the two shops which were part of the building. The restaurant had been open since the 1970s and prior to that the building had been Fraser's Cafe since the 1920s. Development work began in 2012 on new hotel accommodation and street-level shops and these opened in 2014.
Future development.
A "Waterfront" development has been proposed by the Council though there is not overwhelming support for this in the town. The development would have included a hotel, some shops and some housing but it was discovered early in 2008 that it was unlikely to be completed before 2020. It was announced in April 2010 that the project had been abandoned.
Geography.
Fort William lies near the head of Loch Linnhe, one of Scotland's longest sea lochs, beside the mouth of the rivers Nevis and Lochy. They join in the intertidal zone to briefly become one river before discharging to the sea. The town and its suburbs are surrounded by picturesque mountains.
The town is centred on the High Street, which was pedestrianised in the 1990s. Off this there are several squares. Monzie Square (named after the Cameron Campbells of Monzie, Perthshire, former landowners in the town), Station Square, where the long-since demolished railway station used to be, Gordon Square (named for the Gordons, who owned land where the town now stands in the late 18th century, during which time the town was named Gordonsburgh), and Cameron Square — formerly known as Town Hall Square. There is also Fraser Square which is not so square-like since it now opens out into Middle Street but it still houses the Imperial Hotel.
The main residential areas of the town are unseen from the high street or the A82 main road. Upper Achintore and the Plantation spread steeply uphill from above the high street.
Inverlochy, Claggan, An-Aird, Lochyside, Caol, Banavie and Corpach outwith the town are the other main residential areas. These areas are built on much flatter land than the town.
Glenfinnan, away, is home of the Glenfinnan Monument (Jacobite era) and the famous Glenfinnan Viaduct (as seen on a Bank Of Scotland £10 note). The viaduct has become known to millions in recent years as the "Harry Potter Bridge" after it featured in the films of the books by J.K. Rowling, specifically "Harry Potter and the Chamber of Secrets". Glenfinnan has also been used in "Charlotte Gray" and "Highlander".
Just outside the town is a large aluminium plant operated by Alcan and powered by the Lochaber hydroelectric scheme, in its day the biggest tunnelling project in the world. This was formerly served by the Lochaber Narrow Gauge Railway better known locally as the Puggy Line.
Location.
Originally based on the still-existent village of Inverlochy, the town lies at the southern end of the Great Glen, on the shores of Loch Linnhe and Loch Eil. It is close to Ben Nevis, the highest mountain in the British Isles, and Glen Nevis. When the railway opened to Fort William on 7 August 1894, the station was given prime position at the south end of the town. The consequence was that the town was separated from the lochside by railway tracks until the 1970s when the present by-pass was built, and the station was re-located to the north end.
Climate.
Fort William has an oceanic climate ("Cfb") with moderate, but generally cool, temperatures and abundant precipitation.
Transport.
The West Highland Line passes through Fort William. Owing to the difficult terrain in the area, the line from Glasgow, to the south, enters from the northeast. Trains from Glasgow to Mallaig, the terminus of the line, have to reverse at Fort William railway station.
An overnight train, the Caledonian sleeper, has its terminus at Fort William. This service is known colloquially as 'The Deerstalker'.
A bus station outside the railway station is served by local buses and express coaches.
The Caledonian Canal connects the Scottish east coast at Inverness with the west coast at Corpach near Fort William.
Sports.
Mountain biking.
Just outside the town, parallel to the Nevis Range Gondola, there is a large downhill mountain bike track which attracts thousands of visitors every year, including international competitors and fans.
Each year since 2001, Fort William has hosted a round of UCI Mountain Bike World Cup, and in 2007 it hosted the UCI Mountain Bike & Trials World Championships ('The Worlds'). Also a trials competition is held, at the various courses at the bottom.
Winners of key men's downhill events at Fort William are:
Winners of key women's downhill events at Fort William are:
Winners of key women's 4-cross events at Fort William are:
Motorcycle trials.
Fort William is the home of the Scottish Six Day Motorcycle Trial (SSDT), held annually in the first full week of May. It attracts many competitors from all across the globe and in 2011 the event celebrated its centenary year.
Others.
Fort William has two major shinty teams, Fort William Shinty Club and Kilmallie Shinty Club. It also has a football team, Fort William F.C., that competes in the Scottish Highland Football League and plays home games at Claggan Park. There is also a cricket club at Fort William that participates in the North of Scotland Cricket Association league. (NoSCA).
In addition, the town is home to Lochaber Rugby Club and to the Lochaber Yacht Club, a Community Amateur Sports Club that was founded in 1954.
As a film location.
Movies filmed in or near Fort William include "Being Human", "Braveheart", "Highlander", "Restless Natives", "the Harry Potter series" and "Rob Roy". The TV series "Rockface" was filmed mainly around Fort William and some scenes of "Monarch of the Glen" were filmed around Lochaber although mostly near Newtonmore. "Local Hero" shot the internal Houston scenes in Fort William.
Festival.
In a celebration of mountains and the culture that surrounds them, and in recognition of the importance of climbing and walking tourism to the town, the Fort William Mountain Festival is held there each year. For a number of years, this volunteer-led festival has concentrated mostly around film but, starting in the Year of Highland Culture - Highland 2007, its scope was widened, and it dropped the word 'film' from its title.
Education.
Lochaber High School is the local high school and serves a large catchment area which includes the surrounding villages. The town itself is served by three primary schools, one of which is a Catholic school.

</doc>
<doc id="11515" url="https://en.wikipedia.org/wiki?curid=11515" title="List of French expressions in English">
List of French expressions in English

English contains many words of French origin, such as "art", "competition", "force", "machine", "money", "police", "publicity", "role", "routine", "table", and many other anglicized French words. These are pronounced according to English rules of phonology, rather than French. Around 45% of English vocabulary is of French origin, most coming from the Anglo-Norman spoken by the upper classes in England for several hundred years after the Norman Conquest, before the language settled into what became Modern English.
This article, however, covers words and phrases that generally entered the lexicon later, as through literature, the arts, diplomacy, and other cultural exchanges not involving conquests. As such, they have not lost their character as Gallicisms, or words that seem unmistakably foreign and "French" to an English speaker.
The phrases are given as used in English, and may seem correct modern French to English speakers, but may not be recognized as such by French speakers as many of them are now defunct or have drifted in meaning. A general rule is that, if the word or phrase retains French diacritics or is usually printed in italics, it has retained its French identity.
Few of these phrases are common knowledge to all English speakers, and for some English speakers most are rarely if ever used in daily conversation, but for other English speakers many of them are a routine part of both their conversational and their written vocabulary.
c'est la guerre: "That's war!", or...
Used in English and French.
C.
c'est la vie: "That's life!" or "Such is life!"
Not used as such in French.
Through the evolution of the language, many words and phrases are no longer used in modern French. Also there are expressions that, even though grammatically correct, do not have the same meaning in French as the English words derived from them. Some older word usages still appear in Quebec French.
French phrases in international air-sea rescue.
International authorities have adopted a number of words and phrases from French for use by speakers of all languages in voice communications during air-sea rescues. Note that the "phonetic" versions of spelling are presented as shown and not the .
It is a serious breach in most countries, and in international zones, to use any of these phrases without justification.
"See Mayday (distress signal) for a more detailed explanation."
See also.
 

</doc>
<doc id="11516" url="https://en.wikipedia.org/wiki?curid=11516" title="Financial rand">
Financial rand

The South African financial rand was the most visible part of a system of capital controls. Although the financial rand was abolished in March 1995, the capital controls remain in place. These capital controls are locally referred to as "exchange controls".
Capital controls have been in place in South Africa in various guises on an uninterrupted basis since the outbreak of World War II, when Great Britain and its dominions implemented the Sterling area.
Following the 1960 Sharpeville massacre, South Africa experienced significant outflows of foreign exchange on the capital account of the balance of payments and instituted an additional level of capital controls, known as the Blocked Rand system. This had the principal effect of blocking outflows of capital to the other countries in the Sterling Area, notably Britain.
To some extent the Blocked Rand system mirrored Germany's Reichsbank system introduced under Hjalmar Schacht in 1937, called "aski" accounts—short for "Auslaender Sonderkonten fuer Inlandszahlungen" ("foreigners' special accounts for inland payments"). In other words, creating a closed loop system that did not create a claim on the foreign exchange reserves of the Third Reich, or in this case South Africa.
The report of the De Kock Commission on Exchange Controls tabled in November 1978, proposed a gradual easing of exchange controls. This saw the replacement of the Blocked Rand by the Financial Rand in early 1979. In line with this policy, the Financial Rand itself was abolished in 1983 and non-residents could repatriate the majority of their South African investments via the Commercial Rand.
This easing was, however, short-lived and the Financial Rand system was re-introduced on 1 September 1985. The outflows during 1984–1985 were largely the result of economic sanctions in response to apartheid. At the same time, the government enacted the exchange controls. Investments in South Africa by foreigners could only be sold for financial rand.
The financial rand system provided for two exchange rates for the rand, one for current account transactions, and one for capital account transactions for non-residents. Investments made in South Africa by non-residents could only be sold for financial rand, and limitations were placed on the convertibility of financial rand into foreign currencies. Financial rand had the ISO 4217 currency code ZAL. The financial had a previous life, from January 1979 to February 1983. The 1985 crisis coincided with a default (then called a "standstill") on foreign debt by the apartheid government.

</doc>
<doc id="11517" url="https://en.wikipedia.org/wiki?curid=11517" title="List of FIPS country codes">
List of FIPS country codes

This is a list of FIPS 10-4 country codes for "Countries, Dependencies, Areas of Special Sovereignty, and Their Principal Administrative Divisions".
The two-letter country codes were used by the US government for geographical data processing in many publications, such as the CIA World Factbook. The standard is also known as DAFIF 0413 ed 7 Amdt. No. 3 (Nov 2003) and as DIA 65-18 (Defense Intelligence Agency, 1994, "Geopolitical Data Elements and Related Features").
The FIPS standard includes both the codes for independent countries (similar but sometimes incompatible with the ISO 3166-1 alpha-2 standard) and the codes for top-level subdivision of the countries (similar to but usually incompatible with the ISO 3166-2 standard). The ISO 3166 codes are used by the United Nations and for Internet top-level country code domains.
Non-sovereign entities are in italics.
On September 2, 2008, FIPS 10-4 was one of ten standards withdrawn by NIST as a Federal Information Processing Standard. It was replaced in the U.S. Government by the Geopolitical Entities, Names, and Codes (GENC), which is based on ISO 3166.
The complete standard can be found at:
Updates to previous version of the standard (before FIPS-10 was withdrawn in September 2008) are at:
Updates to the standard since September 2008 are at:
External links.
Related websites

</doc>
<doc id="11519" url="https://en.wikipedia.org/wiki?curid=11519" title="Fair Isle">
Fair Isle

Fair Isle (Old Norse "Friðarey"; Scottish Gaelic "Fara") is an island in northern Scotland, lying around halfway between mainland Shetland and the Orkney islands. It is known for its bird observatory and a traditional style of knitting.
Geography.
 the most remote inhabited island in the United Kingdom. It is administratively part of Shetland and is roughly equidistant from Sumburgh Head some to the north-east on the Mainland of Shetland and North Ronaldsay, Orkney, some to the south-west. Fair Isle is long and wide. It has an area of , making it the tenth largest of the Shetland Islands. It gives its name to one of the British Sea Areas.
The majority of the sixty islanders live in the crofts on the southern half of the island, with the northern half consisting of rocky moorland. The western coast consists of cliffs of up to in height.
History.
Fair Isle has been occupied since the Bronze Age which is remarkable because of the lack of raw materials on the island, although it is surrounded by rich fishing waters. There are two known Iron Age sites – a promontory fort at Landberg and the foundations of a house underlying an early Christian settlement at Kirkigeo.
Most of the place-names date from after the ninth-century Norse settlement of the Northern Isles. By that time the croft lands had clearly been in use for many centuries.
On 20 August 1588 the flagship of the Spanish Armada, "El Gran Grifón", was shipwrecked in the cove of Stroms Heelor, forcing its 300 sailors to spend six weeks living with the islanders. The wreck was discovered in 1970. The large Canadian sailing ship "Black Watch" was wrecked on Fair Isle in 1877.
Fair Isle was bought by the National Trust for Scotland in 1954 from George Waterston, the founder of the bird observatory.
The population has been decreasing steadily from about 400 in 1900. There are currently around 55 permanent residents on the island, including the majority crofters who work the land. It has 14 scheduled monuments, ranging from the earliest signs of human activity to the remains of a Second World War radar station. The two automated lighthouses are protected as listed buildings.
The island houses a series of high-technology relay stations carrying vital TV, radio, telephone and military communication links between Shetland, Orkney and the Scottish mainland. In this respect it continues its historic role as a signal-station, linking the mainland and the more remote island systems. In 1976, when television relay equipment was updated to permit colour broadcasts to Shetland, the new equipment was housed in former World War Two radar station buildings on Fair Isle. Many television signals are relayed from Orkney to Shetland (rather than from the Scottish mainland) via Orkney's Keelylang Hill transmitter station.
Economy.
Over the centuries the island changed hands many times. Trading links with Northern Europe are reflected in Fair Isle Haa, a traditional Hanseatic trading booth located not far from the South Harbour, traditionally used by residents of the southern part of the island. Rent was usually paid to absentee landlords (who rarely visited) in butter, cloth and fish oil.
Fishing has always been an important industry for the island. In 1702, the Dutch, who were interested in Shetland's herring fisheries, fought a naval battle against the French warships just off the island.
Fair Isle is also noted for its woollen jumpers, with knitting forming an important source of income for the women of the islands. The principal activity for the male islanders is crofting.
In January 2004, Fair Isle was granted Fairtrade Island status.
Bird observatory.
Fair Isle has a permanent bird observatory, founded by George Waterston in 1948. Because of its importance as a bird migration watchpoint, it provides most of the accommodation on the island. The first director of the observatory was Kenneth Williamson. It is unusual amongst bird observatories in providing catered, rather than hostel-style, accommodation.
Many rare species of bird have been found on the island, and it is probably the best place in western Europe to see skulking Siberian passerines such as Pechora pipit, lanceolated warbler and Pallas's grasshopper warbler. In spring 2008 a calandra lark was identified in April, and in May a Caspian plover was observed, only the fourth such record for the UK. On 6 June a citril finch was found and identified by Islander Tommy Hyndman, a first record for Britain. September was highlighted by brown flycatcher, red-flanked bluetail and Siberian thrush.
Fair Isle can claim to be the best place to find rare birds in Britain with at least 27 first records. Spring 2009 started well with notable birds including white-tailed eagle, green-winged teal, red-rumped swallow and a brown-headed cowbird (second for Britain). The island is home to an endemic subspecies of Eurasian wren, the Fair Isle wren "Troglodytes troglodytes fridariensis".
Infrastructure.
There are no pubs or restaurants on the island, though meals are available for the public at the restaurant of the Bird Observatory, and its little bar is also open in the evening. There is one shop, and one school (see below). There is a community hall available for meetings and social events.
Electricity supply.
Fair Isle is not connected to the national grid and electricity is provided by the Fair Isle Electricity Company. Power is generated by two diesel generators and two wind turbines. Diesel generators are automatically switched off if wind turbines provide sufficient power. Excess capacity is distributed through a separate network for home heating, with remote frequency-sensitive programmable relays controlling water heaters and storage heaters in the buildings of the community.
Communication.
Fair Isle is home to two GSM 900 MHz base stations operated by Vodafone and O.
Emergency services.
Fair Isle has a fire station equipped with a single fire appliance, and staffed by a retained fire crew of local volunteers. It was originally part of the Highlands and Islands Fire and Rescue Service, which was absorbed into the national Scottish Fire and Rescue Service on 1 April 2013. A locally organised volunteer fire brigade was formed in 1996 by island residents. This was later absorbed into the statutory fire service, with professional training provided, and the local service designated a retained fire crew. The first purpose-built fire engine was stationed to the island in 2002. In October 2011 a contract for the construction of a £140,000 purpose-built fire station was awarded to Shetland company Ness Engineering, who completed the construction and equipping of the fire station, including its connection to the island power and water supplies, and the installation of a rain-water harvesting system within the building. The new fire station was officially opened on 14 March 2013.
There is a small Coastguard cliff-rescue team on the island. Like the fire service, the Coastguard is a retained (volunteer) emergency service. The Fair Isle Coastguard cliff rescue team were the first British Coastguard unit to be equipped with a quadbike. The quadbike is painted in H M Coastguard livery, with reflective Battenburg markings and has an optional equipment trailer.
There are no emergency medical services on Fair Isle. Routine medical care is provided by a community nurse. In the event of accident and emergency the community nurse provides first aid until casualties can be removed to Shetland Mainland, usually by fixed-wing air ambulance. In severe weather conditions the Coastguard helicopter can sometimes undertake medical evacuations when the air ambulance is grounded.
Transport.
Air.
Fair Isle Airport serves the island with flights to Tingwall Airport near Lerwick, and weekly to Sumburgh. Private aircraft use the facility and scheduled flights arrive twice daily, three days a week. There is a small terminal building, but facilities are otherwise very limited. Fire cover is provided by the island fire service.
There is also a helipad at the South Fair Isle lighthouse, for official use by the Northern Lighthouse Board and Coastguard helicopters.
Sea.
There are two main harbours (north harbour and south harbour), both formed naturally. The north harbour is the main route for goods, provisions, and Royal Mail postal services arriving at and departing from the island. The ferry "Good Shepherd IV" plies between Fair Isle north harbour and Grutness on Shetland Mainland.
Road.
A road network connects the populated areas of the island, along its full length.
Education.
Fair Isle has one primary school, with two classrooms. There is a full-time head teacher, and a part-time assistant teacher. The number of pupils varies over time, but is generally between 5 and 10, with 5 pupils in 2014/2015. Islanders of secondary school age are generally educated off-island, on Shetland Mainland, where they board in halls of residence, returning to the island during holiday periods.
Religion.
Christianity is the only formally organised religion on Fair Isle. There are two churches, one Methodist, and one Church of Scotland (Presbyterian). The Methodist Church has a resident non-stipendiary minister, who reports to a full-time minister on Shetland Mainland. The Methodist Church was constructed in 1886. The Church of Scotland church was built in 1892. The Church of Scotland parish which contains Fair Isle is Dunrossness, which is linked with Sandwick, Cunningsburgh and Quarff parish. The congregation's minister the Rev. Charles H Greig.
Wartime military role.
During the Second World War, the Royal Air Force built a radar station on top of Ward Hill during the Battle of the Atlantic. The ruined buildings and nissen huts are still present. A cable-operated narrow gauge railway lies disused, though it was once used to send supplies up to the summit of Ward Hill.
On 17 January 1941, a German Heinkel He 111 bomber, modified as a meteorological aircraft, crashed on the island; wreckage remains on the crash-site to the present day. The aircraft had been flying on a routine weather reconnaissance flights from its base at Oldenburg in Germany. It was intercepted by RAF Hawker Hurricane fighters from 3 Squadron, based at RAF Sumburgh; both of the aircraft's engines were damaged and several of the five crew were wounded. The pilot managed to make a crash-landing on Fair Isle to avoid ditching his crippled aircraft in the sea. Two crew died and three survived. The dead crew were buried in the island's churchyard; the survivors were detained by the islanders and remained for several days until weather conditions allowed them to be taken off the island by means of the Shetland Lifeboat.
Climate.
Fair Isle experiences an oceanic climate (Köppen "Cfb", bordering on a subpolar oceanic climate ("Cfc"), with cool summers and mild winters. This is especially pronounced due to its location far from any sizeable landmass; Fair Isle has the smallest overall temperature range (least continental) of any weather station in the British Isles: an absolute maximum of and an absolute minimum of since 1951. This 60+ year temperature span is actually smaller than many places in inland southern England will record within a given three-month period. 
The lowest temperature recorded in recent years was in February 2010. Rainfall, at under 1000 mm is lower than one might expect for somewhere often in the main path of Atlantic depressions. This is explained by a lack of heavy convective rainfall during spring and summer months due to the absence of warm surface conditions.
Fair Isle's ocean moderation is so strong that areas on the same latitudes in the Scandinavian inland less than 1000 kilometres to the east have average summer highs 2–3 degrees higher than Fair Isle's all-time record heat, for example the Norwegian capital of Oslo and the Swedish capital of Stockholm. The −5 all-time low is uniquely mild for European locations on the 59th parallel north. The winter daily means are comparable to many areas as far south in the British Isles as south-central England, due to the extreme maritime moderation.

</doc>
<doc id="11520" url="https://en.wikipedia.org/wiki?curid=11520" title="Four Feather Falls">
Four Feather Falls

Four Feather Falls was the third puppet TV show produced by Gerry Anderson for Granada Television. It was based on an idea by Barry Gray, who also wrote the show's music. The series was the first to use an early version of Anderson's Supermarionation puppetry. Thirty-nine 13-minute episodes were produced, broadcast by Granada from February until November 1960. The setting is the late 19th-century fictional Kansas town of Four Feather Falls, where the hero of the series, Tex Tucker, is a sheriff. The four feathers of the title refers to four magical feathers given to Tex by the Indian chief Kalamakooya as a reward for saving his grandson: two allowed Tex's guns to swivel and fire without being touched whenever he was in danger, and two conferred the power of speech on Tex's horse and dog.
Tex's speaking voice was provided by Nicholas Parsons, and his singing voice by Michael Holliday. The series has never been repeated on British television, but it was released on DVD in 2005.
Production.
American Western television shows such as "Wagon Train" and "Gunsmoke" were popular with British audiences, therefore Gerry Anderson and his business partner Arthur Provis decided to make a cowboy series, based on an idea offered to them by Barry Gray. Anderson considered the puppets with static heads, made by Christine Glanville for his earlier productions, to be unacceptable because the viewer could not tell which character was talking unless its puppet moved up or down. Anderson's aim was to make the puppets look as realistic as possible, the beginning of the Supermarionation puppetry process, although that term was not coined until his next series, "Supercar".
The puppets' papier-mâché heads were replaced by interchangeable hollow fibre glass heads with internal rods that could move the eyes from side to side. The heads also contained sound-activated solenoids, which allowed the puppets' lips to move automatically in synchronisation with the dialogue. The electronics of the day required more space than would be available in a human-scale head, therefore all the puppets in "Four Feather Falls" had oversized heads.
Except for the pilot episode, which was made in AP Films' studios at Islet Park, the series was produced in a converted warehouse in the Slough Trading Estate. The cast assembled to record each script without seeing the puppets, much like recording a radio series; synchronisation of each character's speech with the movement of its puppet's mouth was performed later. The show was filmed in black and white. Its tight budget precluded the use of sophisticated special effects, and less-costly alternatives were used. For example, to achieve the effect of muzzle flashes, small specks of black paint were carefully applied to the 35 mm negatives so they would appear as white flashes on the finished prints. The wires used to control the puppets were eight feet long and made of tungsten, an improvement on the curtain wire used in the two earlier series, and were only 1/200 of an inch thick. Being shiny, the wires had to be blackened. The puppets were made one-third life size with the puppeteers on a bridge eight feet above the set. The horses moved by being pulled along on a trolley, which meant the viewer never saw their feet when they were moving.
Continuity for the series was provided by Sylvia Thamm who married Gerry Anderson.
Plot.
The series is set in the fictitious late 19th-century Western town of Four Feather Falls, Kansas, and features the adventures of its sheriff, Tex Tucker. In the first episode, Grandpa Twink relates the story of how it all began to grandson, Little Jake. Tex is riding up from the valley and comes across a lost and hungry Indian boy, Makooya and saves him. Tex is given four magic feathers by the boy's grandfather, chief Kalamakooya, as a reward for saving his grandson. Two of the feathers allow his guns to swivel and fire automatically (often while Tex's hands are raised), and the other two allow his horse, Rocky, and his dog, Dusty, to speak. As Tex, his horse, and dog are very thirsty, Kalamakooya also makes a waterfall where there had been no water before, and so when the town was built it was named after Tex's feathers and the waterfall.
The characters of the town are Grandpa Twink, who does little but rest in a chair; his grandson Little Jake, the only child in town; Ma Jones, who runs the town store; Doc Haggerty; Slim Jim, the bartender of the Denison saloon; Marvin Jackson, the bank manager; and Dan Morse, the telegraphist. Other characters appeared from time to time for only one episode, often just visiting town. The villains included Pedro, who was introduced in the first show and Fernando, who first appeared in the second episode as a sidekick and someone Pedro could blame when things went wrong, as they always did. Big Ben was another villain who appeared from time to time, as did Red Scalp, a renegade Indian. Other villains only appeared in single episodes.
Syndication.
The series has not been repeated or rerun in Britain since its original broadcast. In December 2004 it was announced that the rights had been acquired by Network Distributing, and it was released on three Region 2 DVDs in May 2005. It is the only Supermarionation series not yet released to DVD in North America as of January 2006. Sylvia Anderson wrote two British children's annuals based on the show, published by Collins in 1960 and 1961. The first book featured a short text story based on the pilot episode of the TV series.
Music.
The show's music and song lyrics were composed by Barry Gray. Michael Holliday provided Tex's singing voice, and Tommy Reilly performed the harmonica pieces. The best known song to come out of the series was "Four Feather Falls", sung in some episodes by Michael Holliday in the style of Bing Crosby and sometimes incorrectly described as the theme song to the series. The closing theme song was "Two Gun Tex of Texas." Holliday was paid £2000 for his singing work on the pilot episode, equivalent to about £38,000 as of 2010, a significant part of the show's £6000 budget. In all, Holliday recorded six songs for the series: "Four Feather Falls", "The Phantom Rider", "The Rick-Rick-A-Rackety Train", "Happy Hearts and Friendly Faces", "My Home Town", and "Two Gun Tex of Texas".
Cast.
Denise Bryer had worked with Anderson on "The Adventures of Twizzle", and he wanted her to play some of the voices in "Four Feather Falls". Anderson visited Bryer at her home with some scripts and asked her husband, Nicholas Parsons, to help by reading some of the other parts, including the sheriff Tex Tucker. Anderson liked Parsons' interpretation and offered him the job of providing Tex's speaking voice.
References.
Notes
Citations
Bibliography

</doc>
<doc id="11522" url="https://en.wikipedia.org/wiki?curid=11522" title="Fly-by-wire">
Fly-by-wire

Fly-by-wire (FBW) is a system that replaces the conventional manual flight controls of an aircraft with an electronic interface. The movements of flight controls are converted to electronic signals transmitted by wires (hence the fly-by-wire term), and flight control computers determine how to move the actuators at each control surface to provide the ordered response. The fly-by-wire system also allows automatic signals sent by the aircraft's computers to perform functions without the pilot's input, as in systems that automatically help stabilize the aircraft, or prevent unsafe operation of the aircraft outside of its performance envelope.
Development.
Mechanical and hydro-mechanical flight control systems are relatively heavy and require careful routing of flight control cables through the aircraft by systems of pulleys, cranks, tension cables and hydraulic pipes. Both systems often require redundant backup to deal with failures, which increases weight. Both have limited ability to compensate for changing aerodynamic conditions. Dangerous characteristics such as stalling, spinning and pilot-induced oscillation (PIO), which depend mainly on the stability and structure of the aircraft concerned rather than the control system itself, can still occur with these systems.
The term "fly-by-wire" implies a purely electrically signaled control system. It is used in the general sense of computer-configured controls, where a computer system is interposed between the operator and the final control actuators or surfaces. This modifies the manual inputs of the pilot in accordance with control parameters.
Side-sticks, centre sticks, or conventional flight control yokes can be used to fly FBW aircraft.
Basic operation.
Command.
Fly-by wire systems are quite complex, but their operation can be explained in simple terms. When a pilot moves the control column (or sidestick), a signal is sent to a computer (analogous to moving a game controller) the signal is sent through multiple wires (channels) to ensure that the signal reaches the computer. A 'Triplex' is when there are three channels being used. In an Analog system, the computer receives the signals, performs a calculation (adds the signal voltages and divides by the number of signals received to find the mean average voltage) and adds another channel. These four 'Quadruplex' signals are then sent to the control surface actuator, and the surface begins to move. Potentiometers in the actuator send a signal back to the computer (usually a negative voltage) reporting the position of the actuator. When the actuator reaches the desired position, the two signals (incoming and outgoing) cancel each other out and the actuator stops moving (completing a feedback loop). In a Digital Fly By Wire Flight Control System complex software interprets digital signals from the pilots control input sensors and performs calculations based on the Flight Control Laws programmed into the Flight Control Computers and input from the Air Data Inertial Reference Units and other sensors. The computer then commands the flight control surfaces to adopt a configuration that will achieve the desired flight path. 
Automatic stability systems.
Fly-by-wire control systems allow aircraft computers to perform tasks without pilot input. Automatic stability systems operate in this way. Gyroscopes fitted with sensors are mounted in an aircraft to sense movement changes in the pitch, roll and yaw axes. Any movement (from straight and level flight for example) results in signals to the computer, which automatically moves control actuators to stabilize the aircraft.
Safety and redundancy.
Aircraft systems may be quadruplexed (four independent channels) to prevent loss of signals in the case of failure of one or even two channels. High performance aircraft that have fly-by-wire controls (also called CCVs or Control-Configured Vehicles) may be deliberately designed to have low or even negative stability in some flight regimes, the rapid-reacting CCV controls compensating for the lack of natural stability.
Pre-flight safety checks of a fly-by-wire system are often performed using built-in test equipment (BITE). On programming the system, either by the pilot or groundcrew, a number of control movement steps are automatically performed. Any failure will be indicated to the crews.
Some aircraft, the Panavia Tornado for example, retain a very basic hydro-mechanical backup system for limited flight control capability on losing electrical power; in the case of the Tornado this allows rudimentary control of the stabilators only for pitch and roll axis movements.
Weight saving.
A FBW aircraft can be lighter than a similar design with conventional controls. This is partly due to the lower overall weight of the system components, and partly because the natural stability of the aircraft can be relaxed, slightly for a transport aircraft and more for a maneuverable fighter, which means that the stability surfaces that are part of the aircraft structure can therefore be made smaller. These include the vertical and horizontal stabilizers (fin and tailplane) that are (normally) at the rear of the fuselage. If these structures can be reduced in size, airframe weight is reduced. The advantages of FBW controls were first exploited by the military and then in the commercial airline market. The Airbus series of airliners used full-authority FBW controls beginning with their A320 series, see A320 flight control (though some limited FBW functions existed on A310). Boeing followed with their 777 and later designs.
Electronic fly-by-wire systems can respond flexibly to changing aerodynamic conditions, by tailoring flight control surface movements so that aircraft response to control inputs is appropriate to flight conditions. Electronic systems require less maintenance, whereas mechanical and hydraulic systems require lubrication, tension adjustments, leak checks, fluid changes, etc. Placing circuitry between pilot and aircraft can enhance safety. For example, the control system can try to prevent a stall, or it can stop the pilot from over stressing the airframe.
The main concern with fly-by-wire systems is reliability. While traditional mechanical or hydraulic control systems usually fail gradually, the loss of all flight control computers could immediately render the aircraft uncontrollable. For this reason, most fly-by-wire systems incorporate either redundant computers (triplex, quadruplex etc.), some kind of mechanical or hydraulic backup or a combination of both. A "mixed" control system such as the latter is not desirable and modern FBW aircraft normally avoid it by having more independent FBW channels, thereby reducing the possibility of overall failure to minuscule levels that are acceptable to the independent regulatory and safety authority responsible for aircraft design, testing and certification before operational service.
History.
Electronic signalling of the control surfaces was first tested in the 1930s, on the Soviet Tupolev ANT-20. This replaced long runs of mechanical and hydraulic connections with electrical ones.
The first pure electronic fly-by-wire aircraft with no mechanical or hydraulic backup was the Apollo Lunar Landing Research Vehicle (LLRV), first flown in 1964.
The first non-experimental aircraft that was designed and flown (in 1958) with a fly-by-wire flight control system was the Avro Canada CF-105 Arrow, a feat not repeated with a production aircraft until Concorde in 1969. This system also included solid-state components and system redundancy, was designed to be integrated with a computerised navigation and automatic search and track radar, was flyable from ground control with data uplink and downlink, and provided artificial feel (feedback) to the pilot.
In the UK the two seater Avro 707B was flown with a Fairey system with mechanical backup in the early to mid-60s. The programme was curtailed when the airframe ran out of flight time.
The first digital fly-by-wire fixed-wing aircraft without a mechanical backup to take to the air (in 1972) was an F-8 Crusader, which had been modified electronically by NASA of the United States as a test aircraft. This was preceded in 1964 by the LLRV which pioneered fly-by-wire flight with no mechanical backup. Control was through a digital computer with three analogue backup channels. In the USSR the Sukhoi T-4 also flew. At about the same time in the United Kingdom a trainer variant of the British Hawker Hunter fighter was modified at the British Royal Aircraft Establishment with fly-by-wire flight controls for the right-seat pilot. This was test-flown, with the left-seat pilot having conventional flight controls for safety reasons, and with the capability for him to override and turn off the fly-by-wire system. It flew in April 1972.
Analog systems.
All "fly-by-wire" flight control systems eliminate the complexity, the fragility, and the weight of the mechanical circuit of the hydromechanical or electromechanical flight control systems. Fly-by-wire replace those with electronic circuits. The control mechanisms in the cockpit now operate signal transducers, which in turn generate the appropriate electronic commands. These are next processed by an electronic controller, either an analog one, or more modernly, a digital one. Aircraft and spacecraft autopilots are now part of the electronic controller.
The hydraulic circuits are similar except that mechanical servo valves are replaced with electrically controlled servo valves, operated by the electronic controller. This is the simplest and earliest configuration of an analog fly-by-wire flight control system. In this configuration, the flight control systems must simulate "feel". The electronic controller controls electrical feel devices that provide the appropriate "feel" forces on the manual controls. This was used in Concorde, the first production fly-by-wire airliner.
In more sophisticated versions, analog computers replaced the electronic controller. The canceled 1950s Canadian supersonic interceptor, the Avro Canada CF-105 Arrow, employed this type of system. Analog computers also allowed some customization of flight control characteristics, including relaxed stability. This was exploited by the early versions of F-16, giving it impressive maneuverability.
Digital systems.
A digital fly-by-wire flight control system is similar to its analog counterpart. However, the signal processing is done by digital computers and the pilot literally can "fly-via-computer". This also increases the flexibility of the flight control system, since the digital computers can receive input from any aircraft sensor (such as the altimeters and the pitot tubes). This also increases the electronic stability, because the system is less dependent on the values of critical electrical components in an analog controller.
The computers sense position and force inputs from pilot controls and aircraft sensors. They solve differential equations to determine the appropriate command signals that move the flight controls to execute the intentions of the pilot.
The programming of the digital computers enable flight envelope protection. In this aircraft designers precisely tailor an aircraft's handling characteristics, to stay within the overall limits of what is possible given the aerodynamics and structure of the aircraft. For example, the computer in flight envelope protection mode can try to prevent the aircraft from being handled dangerously by preventing pilots from exceeding preset limits on the aircraft's flight-control envelope, such as those that prevent stalls and spins, and which limit airspeeds and g forces on the airplane. Software can also be included that stabilize the flight-control inputs to avoid pilot-induced oscillations.
Since the flight-control computers continuously "fly" the aircraft, pilot's workloads can be reduced. Also, in military and naval applications, it is now possible to fly military aircraft that have relaxed stability. The primary benefit for such aircraft is more maneuverability during combat and training flights, and the so-called "carefree handling" because stalling, spinning and other undesirable performances are prevented automatically by the computers.
Digital flight control systems enable inherently unstable combat aircraft, such as the Lockheed F-117 Nighthawk and the Northrop Grumman B-2 Spirit flying wing to fly in usable and safe manners.
Legislation.
The Federal Aviation Administration (FAA) of the United States has adopted the RTCA/DO-178B, titled "Software Considerations in Airborne Systems and Equipment Certification", as the certification standard for aviation software. Any safety-critical component in a digital fly-by-wire system including applications of the laws of aeronautics and computer operating systems will need to be certified to DO-178B Level A, which is applicable for preventing potential catastrophic failures.
Nevertheless, the top concern for computerized, digital, fly-by-wire systems is reliability, even more so than for analog electronic control systems. This is because the digital computers that are running software are often the only control path between the pilot and aircraft's flight control surfaces. If the computer software crashes for any reason, the pilot may be unable to control an aircraft. Hence virtually all fly-by-wire flight control systems are either triply or quadruply redundant in their computers and electronics. These have three or four flight-control computers operating in parallel, and three or four separate data buses connecting them with each control surface.
Redundancy.
If one of the flight-control computers crashes, or is damaged in combat, or suffers from "insanity" caused by electromagnetic pulses, the others overrule the faulty one (or even two of them), they continue flying the aircraft safely, and they can either turn off or re-boot the faulty computers. Any flight-control computer whose results disagree with the others is ruled to be faulty, and it is either ignored or re-booted. (In other words, it is voted-out of control by the others.)
In addition, most of the early digital fly-by-wire aircraft also had an analog electrical, a mechanical, or a hydraulic back-up flight control system. The Space Shuttle has, in addition to its redundant set of four digital computers running its primary flight-control software, a fifth back-up computer running a separately developed, reduced-function, software flight-control system – one that can be commanded to take over in the event that a fault ever affects all of the computers in the other four. This back-up system serves to reduce the risk of total flight-control-system failure ever happening because of a general-purpose flight software fault that has escaped notice in the other four computers.
For airliners, flight-control redundancy improves their safety, but fly-by-wire control systems also improve economy in flight because they are lighter, and they eliminate the need for many mechanical, and heavy, flight-control mechanisms. Furthermore, most modern airliners have computerized systems that control their jet engine throttles, air inlets, fuel storage and distribution system, in such a way to minimize their consumption of jet fuel. Thus, digital control systems do their best to reduce the cost of flights.
Airbus/Boeing.
Airbus and Boeing commercial airplanes differ in their approaches in using fly-by-wire systems. In Airbus airliners, the flight-envelope control system always retains ultimate flight control when flying under normal law, and it will not permit the pilots to fly outside these performance limits unless flying under alternate law. However, in the event of multiple failures of redundant computers, the A320 does have a mechanical back-up system for its pitch trim and its rudder. The A340-600 has a purely electrical (not electronic) back-up rudder control system, and beginning with the new A380 airliner, all flight-control systems have back-up systems that are purely electrical through the use of a so-called "three-axis Backup Control Module" (BCM)
With the Boeing 777 model airliners, the two pilots can completely override the computerized flight-control system to permit the aircraft to be flown beyond its usual flight-control envelope during emergencies. Airbus's strategy, which began with the Airbus A320, has been continued on subsequent Airbus airliners.
Engine digital control.
The advent of FADEC (Full Authority Digital Engine Control) engines permits operation of the flight control systems and autothrottles for the engines to be fully integrated. On modern military aircraft other systems such as autostabilization, navigation, radar and weapons system are all integrated with the flight control systems. FADEC allows maximum performance to be extracted from the aircraft without fear of engine misoperation, aircraft damage or high pilot workloads.
In the civil field, the integration increases flight safety and economy. The Airbus A320 and its fly-by-wire brethren are protected from dangerous situations such as low-speed stall or overstressing by flight envelope protection. As a result, in such conditions, the flight control systems commands the engines to increase thrust without pilot intervention. In economy cruise modes, the flight control systems adjust the throttles and fuel tank selections more precisely than all but the most skillful pilots. FADEC reduces rudder drag needed to compensate for sideways flight from unbalanced engine thrust. On the A330/A340 family, fuel is transferred between the main (wing and center fuselage) tanks and a fuel tank in the horizontal stabilizer, to optimize the aircraft's center of gravity during cruise flight. The fuel management controls keep the aircraft's center of gravity accurately trimmed with fuel weight, rather than drag-inducing aerodynamic trims in the elevators.
Further developments.
Fly-by-optics.
Fly-by-optics is sometimes used instead of fly-by-wire because it offers a higher data transfer rate, immunity to electromagnetic interference, and lighter weight. In most cases, the cables are just changed from electrical to optical fiber cables. Sometimes it is referred to as "fly-by-light" due to its use of fiber optics. The data generated by the software and interpreted by the controller remain the same.
Power-by-wire.
Having eliminated the mechanical transmission circuits in fly-by-wire flight control systems, the next step is to eliminate the bulky and heavy hydraulic circuits. The hydraulic circuit is replaced by an electrical power circuit. The power circuits power electrical or self-contained electrohydraulic actuators that are controlled by the digital flight control computers. All benefits of digital fly-by-wire are retained.
The biggest benefits are weight savings, the possibility of redundant power circuits and tighter integration between the aircraft flight control systems and its avionics systems. The absence of hydraulics greatly reduces maintenance costs. This system is used in the Lockheed Martin F-35 Lightning II and in Airbus A380 backup flight controls. The Boeing 787 will also incorporate some electrically operated flight controls (spoilers and horizontal stabilizer), which will remain operational with either a total hydraulics failure and/or flight control computer failure.
Fly-by-wireless.
Wiring adds a considerable amount of weight to an aircraft; therefore, researchers are exploring implementing fly-by-wireless solutions. Fly-by-wireless systems are very similar to fly-by-wire systems, however, instead of using a wired protocol for the physical layer a wireless protocol is employed.
In addition to reducing weight, implementing a wireless solution has the potential to reduce costs throughout an aircraft's life cycle. For example, many key failure points associated with wire and connectors will be eliminated thus hours spent troubleshooting wires and connectors will be reduced. Furthermore, engineering costs could potentially decrease because less time would be spent on designing wiring installations, late changes in an aircraft's design would be easier to manage, etc.
Intelligent flight control system.
A newer flight control system, called intelligent flight control system (IFCS), is an extension of modern digital fly-by-wire flight control systems. The aim is to intelligently compensate for aircraft damage and failure during flight, such as automatically using engine thrust and other avionics to compensate for severe failures such as loss of hydraulics, loss of rudder, loss of ailerons, loss of an engine, etc. Several demonstrations were made on a flight simulator where a Cessna-trained small-aircraft pilot successfully landed a heavily damaged full-size concept jet, without prior experience with large-body jet aircraft. This development is being spearheaded by NASA Dryden Flight Research Center. It is reported that enhancements are mostly software upgrades to existing fully computerized digital fly-by-wire flight control systems.

</doc>
<doc id="11523" url="https://en.wikipedia.org/wiki?curid=11523" title="Falklands War">
Falklands War

The Falklands War (), also known as the Falklands Conflict, Falklands Crisis, and the "Guerra del Atlántico Sur" (Spanish for "South Atlantic War"), was a ten-week war between Argentina and the United Kingdom over two British overseas territories in the South Atlantic: the Falkland Islands and South Georgia and the South Sandwich Islands. It began on Friday, 2 April 1982, when Argentina invaded and occupied the Falkland Islands (and, the following day, South Georgia and the South Sandwich Islands) in an attempt to establish the sovereignty it had claimed over them. On 5 April, the British government dispatched a naval task force to engage the Argentine Navy and Air Force before making an amphibious assault on the islands. The conflict lasted 74 days and ended with the Argentine surrender on 14 June 1982, returning the islands to British control. In total, 649 Argentine military personnel, 255 British military personnel, and three Falkland Islanders died during the hostilities.
The conflict was a major episode in the protracted confrontation over the territories' sovereignty. Argentina asserted (and maintains) that the islands are Argentine territory, and the Argentine government thus characterised its military action as the reclamation of its own territory. The British government regarded the action as an invasion of a territory that had been a Crown colony since 1841. Falkland Islanders, who have inhabited the islands since the early 19th century, are predominantly descendants of British settlers, and favour British sovereignty. Neither state, however, officially declared war (both sides did declare the Islands areas a war zone and officially recognised that a state of war existed between them) and hostilities were almost exclusively limited to the territories under dispute and the area of the South Atlantic where they lie.
The conflict has had a strong impact in both countries and has been the subject of various books, articles, films, and songs. Patriotic sentiment ran high in Argentina, but the outcome prompted large protests against the ruling military government, hastening its downfall. In the United Kingdom, the Conservative Party government, bolstered by the successful outcome, was re-elected the following year. The cultural and political weight of the conflict has had less effect in Britain than in Argentina, where it remains a continued topic for discussion.
Relations between the United Kingdom and Argentina were restored in 1989 following a meeting in Madrid, Spain, at which the two countries' governments issued a joint statement. No change in either country's position regarding the sovereignty of the Falkland Islands was made explicit. In 1994, Argentina's claim to the territories was added to its constitution.
Lead-up to the conflict.
In the period leading up to the warand, in particular, following the transfer of power between the military dictators General Jorge Rafael Videla and General Roberto Eduardo Viola late in March 1981Argentina had been in the midst of a devastating economic stagnation and large-scale civil unrest against the military "junta" that had been governing the country since 1976. In December 1981 there was a further change in the Argentine military regime bringing to office a new "junta" headed by General Leopoldo Galtieri (acting president), Brigadier Basilio Lami Dozo and Admiral Jorge Anaya. Anaya was the main architect and supporter of a military solution for the long-standing claim over the islands, calculating that the United Kingdom would never respond militarily.
By opting for military action, the Galtieri government hoped to mobilise the long-standing patriotic feelings of Argentines towards the islands, and thus divert public attention from the country's chronic economic problems and the regime's ongoing human rights violations. Such action would also bolster its dwindling legitimacy. The newspaper "La Prensa" speculated in a step-by-step plan beginning with cutting off supplies to the Islands, ending in direct actions late in 1982, if the UN talks were fruitless.
The ongoing tension between the two countries over the islands increased on 19 March when a group of Argentine scrap metal merchants (actually infiltrated by Argentine marines) raised the Argentine flag at South Georgia, an act that would later be seen as the first offensive action in the war. The Royal Navy ice patrol vessel was dispatched from Stanley to South Georgia in response, subsequently leading to the invasion of South Georgia by Argentine forces on 3 April. The Argentine military junta, suspecting that the UK would reinforce its South Atlantic Forces, ordered the invasion of the Falkland Islands to be brought forward to 2 April.
Britain was initially taken by surprise by the Argentine attack on the South Atlantic islands, despite repeated warnings by Royal Navy captain Nicholas Barker and others. Barker believed that Defence Secretary John Nott's 1981 review (in which Nott described plans to withdraw the "Endurance", Britain's only naval presence in the South Atlantic) sent a signal to the Argentines that Britain was unwilling, and would soon be unable, to defend its territories and subjects in the Falklands.
Argentine invasion.
On 2 April 1982, Argentine forces mounted amphibious landings off the Falkland Islands, following the civilian occupation of South Georgia on 19 March, before the Falklands War began. The invasion was met with a nominal defence organised by the Falkland Islands' Governor Sir Rex Hunt, giving command to Major Mike Norman of the Royal Marines. The events of the invasion included the landing of Lieutenant Commander Guillermo Sanchez-Sabarots' Amphibious Commandos Group, the attack on Moody Brook barracks, the engagement between the troops of Hugo Santillan and Bill Trollope at Stanley, and the final engagement and surrender at Government House.
Initial British response.
Word of the invasion first reached Britain from Argentine sources. A Ministry of Defence operative in London had a short telex conversation with Governor Hunt's telex operator, who confirmed that Argentines were on the island and in control. Later that day, BBC journalist Laurie Margolis spoke with an islander at Goose Green via amateur radio, who confirmed the presence of a large Argentine fleet and that Argentine forces had taken control of the island. "Operation Corporate" was the codename given to the British military operations in the Falklands War. The commander of task force operations was Admiral Sir John Fieldhouse. Operations lasted from 1 April 1982 to 20 June 1982.
The British undertook a series of military operations as a means of recapturing the Falklands from Argentine occupation. The British government had taken action prior to the 2 April invasion. In response to events on South Georgia, the submarines and were ordered to sail south on 29 March, whilst the stores ship Royal Fleet Auxiliary (RFA) "Fort Austin" was dispatched from the Western Mediterranean to support HMS "Endurance". Lord Carrington had wished to send a third submarine, but the decision was deferred due to concerns about the impact on operational commitments. Coincidentally, on 26 March, the submarine left Gibraltar and it was assumed in the press it was heading south. There has since been speculation that the effect of those reports was to panic the Argentine junta into invading the Falklands before nuclear submarines could be deployed.
The following day, during a crisis meeting headed by the Prime Minister Margaret Thatcher, the Chief of the Naval Staff, Admiral Sir Henry Leach, advised them that "Britain could and should send a task force if the islands are invaded". On 1 April, Leach sent orders to a Royal Navy force carrying out exercises in the Mediterranean to prepare to sail south. Following the invasion on 2 April, after an emergency meeting of the cabinet, approval was given to form a task force to retake the islands. This was backed in an emergency session of the House of Commons the next day.
On 6 April, the British Government set up a War Cabinet to provide day-to-day political oversight of the campaign. This was the critical instrument of crisis management for the British with its remit being to "keep under review political and military developments relating to the South Atlantic, and to report as necessary to the Defence and Overseas Policy Committee". Until it was dissolved on 12 August, the War Cabinet met at least daily. Although Margaret Thatcher is described as dominating the War Cabinet, Lawrence Freedman notes in the "Official History of the Falklands Campaign" that she did not ignore opposition or fail to consult others. However, once a decision was reached she "did not look back".
Position of third party countries.
On the evening of 3 April, the United Kingdom's United Nations ambassador Sir Anthony Parsons put a draft resolution to the United Nations Security Council. The resolution, which condemned the hostilities and demanded the immediate Argentine withdrawal from the Islands, was adopted by the council the following day as United Nations Security Council Resolution 502, which passed with ten votes in support, one against (Panama) and four abstentions (China, the Soviet Union, Poland and Spain). The UK received further political support from the Commonwealth of Nations and the European Economic Community. The EEC also provided economic support by imposing economic sanctions on Argentina. Argentina itself was politically backed by a majority of countries in Latin America and some members of the Non-Aligned Movement. On 20 May 1982, the Prime Minister of New Zealand, Rob Muldoon, announced that he would make HMNZS "Canterbury", a Leander-class frigate, available for use where the British thought fit to release a Royal Navy vessel for the Falklands.
The war was an unexpected event in a world strained by the Cold War and the North–South divide. The response of some countries was the effort to mediate the crisis and later as the war began, the support (or criticism) based in terms of anti-colonialism, political solidarity, historical relationships or realpolitik.
The United States was concerned by the prospect of Argentina turning to the Soviet Union for support, and initially tried to mediate an end to the conflict. However, when Argentina refused the US peace overtures, US Secretary of State Alexander Haig announced that the United States would prohibit arms sales to Argentina and provide material support for British operations. Both Houses of the US Congress passed resolutions supporting the US action siding with the United Kingdom.
The US provided the United Kingdom with military equipment ranging from submarine detectors to the latest missiles. President Ronald Reagan approved the Royal Navy's request to borrow the Sea Harrier-capable amphibious assault ship if the British lost an aircraft carrier. The United States Navy developed a plan to help the British man the ship with American military contractors, likely retired sailors with knowledge of the "Iwo Jima"s systems. France provided dissimilar aircraft training so Harrier pilots could train against the French aircraft used by Argentina. French and British intelligence also worked to prevent Argentina from obtaining more Exocet missiles on the international market, while at the same time Peru attempted to purchase 12 missiles for Argentina, in a failed secret operation. Chile gave support to Britain in the form of intelligence about the Argentine military and early warning intelligence on Argentine air movements. Throughout the war, Argentina was afraid of a Chilean military intervention in Patagonia and kept some of her best mountain regiments away from the Falklands near the Chilean border as a precaution.
In recent years, it has become known that a listening post located in Fauske, Norway was vital in giving the British intelligence information regarding Argentine fleet locations. The listening post was designated Fauske II by Norway. The information was "stolen" from Soviet spy satellites, which were the only space assets that covered the South Atlantic. Western powers such as the United States and the UK did not have their own satellite presence in this area at the time. A high ranking British military source claimed that the intelligence the British got from the Fauske II post as "Incredibly vital":
While France overtly backed the United Kingdom, a French technical team remained in Argentina throughout the war. French government sources have said that the French team was engaged in intelligence-gathering; however, it simultaneously provided direct material support to the Argentines, identifying and fixing faults in Exocet missile launchers. According to the book "Operation Israel", advisers from Israel Aerospace Industries were already in Argentina and continued their work during the conflict. The book also claims that Israel sold weapons and drop tanks in a secret operation in Peru. Peru also openly sent "Mirages, pilots and missiles" to Argentina during the war. Peru had earlier transferred ten Hercules transport planes to Argentina soon after the British Task Force had set sail in April 1982. Nick van der Bijl records that, after the Argentine defeat at Goose Green, Venezuela and Guatemala offered to send paratroops to the Falklands. Through Libya, under Muammar Gaddafi, Argentina received 20 launchers and 60 SA-7 missiles, as well as machine guns, mortars and mines; all in all, the load of four trips of two Boeing 707s of the AAF, refuelled in Recife with the knowledge and consent of the Brazilian government. Some of these clandestine logistics operations were mounted by the Soviet Union.
British Task Force.
The British government had no contingency plan for an invasion of the islands, and the task force was rapidly put together from whatever vessels were available. The nuclear submarine set sail from France on 4 April, whilst the two aircraft carriers and , in the company of escort vessels, left Portsmouth only a day later. On its return to Southampton from a world cruise on 7 April, the ocean liner was requisitioned and set sail two days later with 3 Commando Brigade aboard. The ocean liner "Queen Elizabeth 2" was also requisitioned and left Southampton on 12 May with 5th Infantry Brigade on board. The whole task force eventually comprised 127 ships: 43 Royal Navy vessels, 22 Royal Fleet Auxiliary ships and 62 merchant ships.
The retaking of the Falkland Islands was considered extremely difficult. The US Navy considered a successful counter-invasion "...a military impossibility." Firstly, the British were significantly constrained by the disparity in deployable air cover. The British had 42 aircraft (28 Sea Harriers and 14 Harrier GR.3s) available for air combat operations, against approximately 122 serviceable jet fighters, of which about 50 were used as air superiority fighters and the remainder as strike aircraft, in Argentina's air forces during the war. Crucially, the British lacked Airborne early warning and control (AEW) aircraft. Planning also considered the Argentine surface fleet and the threat posed by Exocet-equipped vessels or the two Type 209 submarines.
By mid-April, the Royal Air Force had set up the airbase of RAF Ascension Island, co-located with Wideawake Airfield (USA) on the mid-Atlantic British overseas territory of Ascension Island, including a sizeable force of Avro Vulcan B Mk 2 bombers, Handley Page Victor K Mk 2 refuelling aircraft, and McDonnell Douglas Phantom FGR Mk 2 fighters to protect them. Meanwhile, the main British naval task force arrived at Ascension to prepare for active service. A small force had already been sent south to recapture South Georgia.
Encounters began in April; the British Task Force was shadowed by Boeing 707 aircraft of the Argentine Air Force during their travel to the south. Several of these flights were intercepted by Sea Harriers outside the British-imposed exclusion zone; the unarmed 707s were not attacked because diplomatic moves were still in progress and the UK had not yet decided to commit itself to armed force. On 23 April, a Brazilian commercial Douglas DC-10 from VARIG Airlines en route to South Africa was intercepted by British Harriers who visually identified the civilian plane.
Recapture of South Georgia and the attack on "Santa Fe".
The South Georgia force, "Operation Paraquet", under the command of Major Guy Sheridan RM, consisted of Marines from 42 Commando, a troop of the Special Air Service (SAS) and Special Boat Service (SBS) troops who were intended to land as reconnaissance forces for an invasion by the Royal Marines. All were embarked on RFA "Tidespring". First to arrive was the HMS "Conqueror" on 19 April, and the island was over-flown by a radar-mapping Handley Page Victor on 20 April.
The first landings of SAS troops took place on 21 April, but—with the southern hemisphere autumn setting in—the weather was so bad that their landings and others made the next day were all withdrawn after two helicopters crashed in fog on Fortuna Glacier. On 23 April, a submarine alert was sounded and operations were halted, with "Tidespring" being withdrawn to deeper water to avoid interception. On 24 April, the British forces regrouped and headed in to attack.
On 25 April, after resupplying the Argentine garrison in South Georgia, the submarine ARA "Santa Fe" was spotted on the surface by a Westland Wessex HAS Mk 3 helicopter from , which attacked the Argentine submarine with depth charges. launched a Westland Wasp HAS.Mk.1 helicopter, and launched a Westland Lynx HAS Mk 2. The Lynx launched a torpedo, and strafed the submarine with its pintle-mounted general purpose machine gun; the Wessex also fired on "Santa Fe" with its GPMG. The Wasp from as well as two other Wasps launched from fired AS-12 ASM antiship missiles at the submarine, scoring hits. "Santa Fe" was damaged badly enough to prevent her from diving. The crew abandoned the submarine at the jetty at King Edward Point on South Georgia.
With "Tidespring" now far out to sea, and the Argentine forces augmented by the submarine's crew, Major Sheridan decided to gather the 76 men he had and make a direct assault that day. After a short forced march by the British troops and a naval bombardment demonstration by two Royal Navy vessels ("Antrim" and "Plymouth"), the Argentine forces surrendered without resistance. The message sent from the naval force at South Georgia to London was, "Be pleased to inform Her Majesty that the White Ensign flies alongside the Union Jack in South Georgia. God Save the Queen." The Prime Minister, Margaret Thatcher, broke the news to the media, telling them to "Just rejoice at that news, and congratulate our forces and the Marines!"
Black Buck raids.
On 1 May, British operations on the Falklands opened with the "Black Buck 1" attack (of a series of five) on the airfield at Stanley. A Vulcan bomber from Ascension flew on an round trip dropping conventional bombs across the runway at Stanley and back to Ascension. The mission required repeated refuelling, and required several Victor tanker aircraft operating in concert, including tanker to tanker refuelling. The overall effect of the raids on the war is difficult to determine, and the raids consumed precious tanker resources from Ascension, but also prevented Argentina from stationing fast jets on the islands.
The raids did minimal damage to the runway, and damage to radars was quickly repaired. the Royal Air Force Web site still states that all the three bombing missions had been successful, but historian Lawrence Freedman, who had access to classified documents, said in a 2005 book that the subsequent bombing missions were failures. Argentine sources said that the Vulcan raids influenced Argentina to withdraw some of its Mirage IIIs from Southern Argentina to the Buenos Aires Defence Zone. This was later described as propaganda by Falklands veteran Commander Nigel Ward. In any case, the effect of the Vulcan raids on Argentina's deployment of defensive fighters was watered down when British officials made clear that there would be no strikes on air bases in Argentina.
Of the five Black Buck raids, three were against Stanley Airfield, with the other two anti-radar missions using Shrike anti-radiation missiles.
Escalation of the air war.
The Falklands had only three airfields. The longest and only paved runway was at the capital, Stanley, and even that was too short to support fast jets (although an arrestor gear was fitted in April to support Skyhawks). Therefore, the Argentines were forced to launch their major strikes from the mainland, severely hampering their efforts at forward staging, combat air patrols and close air support over the islands. The effective loiter time of incoming Argentine aircraft was low, and they were later compelled to overfly British forces in any attempt to attack the islands.
The first major Argentine strike force comprised 36 aircraft (A-4 Skyhawks, IAI Daggers, English Electric Canberras, and Mirage III escorts), and was sent on 1 May, in the belief that the British invasion was imminent or landings had already taken place. Only a section of Grupo 6 (flying IAI Dagger aircraft) found ships, which were firing at Argentine defences near the islands. The Daggers managed to attack the ships and return safely. This greatly boosted morale of the Argentine pilots, who now knew they could survive an attack against modern warships, protected by radar ground clutter from the Islands and by using a late pop up profile. Meanwhile, other Argentine aircraft were intercepted by BAE Sea Harriers operating from . A Dagger and a Canberra were shot down.
Combat broke out between Sea Harrier FRS Mk 1 fighters of No. 801 Naval Air Squadron and Mirage III fighters of Grupo 8. Both sides refused to fight at the other's best altitude, until two Mirages finally descended to engage. One was shot down by an AIM-9L Sidewinder air-to-air missile (AAM), while the other escaped but was damaged and without enough fuel to return to its mainland air base. The plane made for Stanley, where it fell victim to friendly fire from the Argentine defenders.
As a result of this experience, Argentine Air Force staff decided to employ A-4 Skyhawks and Daggers only as strike units, the Canberras only during the night, and Mirage IIIs (without air refuelling capability or any capable AAM) as decoys to lure away the British Sea Harriers. The decoying would be later extended with the formation of the Escuadrón Fénix, a squadron of civilian jets flying 24 hours-a-day simulating strike aircraft preparing to attack the fleet. On one of these flights, an Air Force Learjet was shot down, killing the squadron commander, Vice Commodore Rodolfo De La Colina, the highest-ranking Argentine officer to die in the war.
Stanley was used as an Argentine strongpoint throughout the conflict. Despite the Black Buck and Harrier raids on Stanley airfield (no fast jets were stationed there for air defence) and overnight shelling by detached ships, it was never out of action entirely. Stanley was defended by a mixture of surface-to-air missile (SAM) systems (Franco-German Roland and British Tigercat) and Swiss-built Oerlikon 35 mm twin anti-aircraft cannons. Lockheed Hercules transport night flights brought supplies, weapons, vehicles, and fuel, and airlifted out the wounded up until the end of the conflict.
The only Argentine Hercules shot down by the British was lost on 1 June when TC-63 was intercepted by a Sea Harrier in daylight when it was searching for the British fleet north-east of the islands after the Argentine Navy retired its last SP-2H Neptune due to airframe attrition.
Various options to attack the home base of the five Argentine Etendards at Río Grande were examined and discounted (Operation Mikado), subsequently five Royal Navy submarines lined up, submerged, on the edge of Argentina's territorial limit to provide early warning of bombing raids on the British task force.
Sinking of ARA "General Belgrano".
Two British naval task forces (one of surface vessels and one of submarines) and the Argentine fleet were operating in the neighbourhood of the Falklands and soon came into conflict. The first naval loss was the World War II-vintage Argentine light cruiser ARA "General Belgrano". The nuclear-powered submarine HMS "Conqueror" sank "General Belgrano" on 2 May. Three hundred and twenty-three members of "General Belgrano"s crew died in the incident. Over 700 men were rescued from the open ocean despite cold seas and stormy weather. The losses from "General Belgrano" totalled nearly half of the Argentine deaths in the Falklands conflict and the loss of the ship hardened the stance of the Argentine government.
Regardless of controversies over the sinking, due to disagreement on the exact nature of the Maritime Exclusion Zone and whether "General Belgrano" had been returning to port at the time of the sinking, it had a crucial strategic effect: the elimination of the Argentine naval threat. After her loss, the entire Argentine fleet, with the exception of the conventional submarine ARA "San Luis", returned to port and did not leave again during the fighting. The two escorting destroyers and the battle group centred on the aircraft carrier ARA "Veinticinco de Mayo" both withdrew from the area, ending the direct threat to the British fleet that their pincer movement had represented.
In a separate incident later that night, British forces engaged an Argentine patrol gunboat, the ARA "Alferez Sobral", that was searching for the crew of the Argentine Air Force Canberra light bomber shot down on 1 May. Two Royal Navy Lynx helicopters fired four Sea Skua missiles at her. Badly damaged and with eight crew dead, "Alferez Sobral" managed to return to Puerto Deseado two days later. The Canberra's crew were never found.
Sinking of HMS "Sheffield".
On 4 May, two days after the sinking of "General Belgrano", the British lost the Type 42 destroyer to fire following an Exocet missile strike from the Argentine 2nd Naval Air Fighter/Attack Squadron.
"Sheffield" had been ordered forward with two other Type 42s to provide a long-range radar and medium-high altitude missile picket far from the British carriers. She was struck amidships, with devastating effect, ultimately killing 20 crew members and severely injuring 24 others. The ship was abandoned several hours later, gutted and deformed by the fires that continued to burn for six more days. She finally sank outside the Maritime Exclusion Zone on 10 May.
The incident is described in detail by Admiral Sandy Woodward in his book "One Hundred Days", Chapter One. Woodward was a former commanding officer of "Sheffield".
The tempo of operations increased throughout the second half of May as the United Nations' attempts to mediate a peace were rejected by the British, who felt that any delay would make a campaign impractical in the South Atlantic storms. The destruction of "Sheffield" (the first Royal Navy ship sunk in action since World War II) had a profound impact on the British public, bringing home the fact that the "Falklands Crisis", as the BBC News put it, was now an actual "shooting war".
British special forces operations.
Given the threat to the British fleet posed by the Etendard-Exocet combination, plans were made to use C-130s to fly in some SAS troops to attack the home base of the five Etendards at Río Grande, Tierra del Fuego. The operation was codenamed "Mikado." The operation was later scrapped, after acknowledging that its chances of success were limited, and replaced with a plan to use HMS "Onyx" to drop SAS operatives several miles offshore at night for them to make their way to the coast aboard rubber inflatables and proceed to destroy Argentina's remaining Exocet stockpile.
An SAS reconnaissance team was dispatched to carry out preparations for a seaborne infiltration. A Westland Sea King helicopter carrying the assigned team took off from HMS "Invincible" on the night of 17 May, but bad weather forced it to land from its target and the mission was aborted. The pilot flew to Chile, landed south of Punta Arenas, and dropped off the SAS team. The helicopter's crew of three then destroyed the aircraft, surrendered to Chilean police on 25 May, and were repatriated to the UK after interrogation. The discovery of the burnt-out helicopter attracted considerable international attention. Meanwhile, the SAS team crossed and penetrated deep into Argentina, but cancelled their mission after the Argentines suspected an SAS operation and deployed some troops to search for them. The SAS men were able to return to Chile, and took a civilian flight back to the UK.
On 14 May the SAS carried out a raid on Pebble Island on the Falklands, where the Argentine Navy had taken over a grass airstrip for FMA IA 58 Pucará light ground-attack aircraft and Beechcraft T-34 Mentors, which resulted in the destruction of several aircraft.
Land battles.
Landing at San Carlos—Bomb Alley.
During the night of 21 May, the British Amphibious Task Group under the command of Commodore Michael Clapp (Commodore, Amphibious Warfare – COMAW) mounted "Operation Sutton", the amphibious landing on beaches around San Carlos Water, on the northwestern coast of East Falkland facing onto Falkland Sound. The bay, known as "Bomb Alley" by British forces, was the scene of repeated air attacks by low-flying Argentine jets.
The men of 3 Commando Brigade were put ashore as follows: 2nd Battalion, Parachute Regiment (2 Para) from the RORO ferry "Norland" and 40 Commando Royal Marines from the amphibious ship were landed at San Carlos (Blue Beach), 3rd Battalion, Parachute Regiment (3 Para) from the amphibious ship was landed at Port San Carlos (Green Beach) and 45 Commando from RFA "Stromness" was landed at Ajax Bay (Red Beach). Notably, the waves of eight LCUs and eight LCVPs were led by Major Ewen Southby-Tailyour, who had commanded the Falklands detachment NP8901 from March 1978 to 1979. 42 Commando on the ocean liner was a tactical reserve. Units from the Royal Artillery, Royal Engineers, etc. and armoured reconnaissance vehicles were also put ashore with the landing craft, the Round Table class LSL and mexeflote barges. Rapier missile launchers were carried as underslung loads of Sea Kings for rapid deployment.
By dawn the next day, they had established a secure beachhead from which to conduct offensive operations. From there, Brigadier Julian Thompson's plan was to capture Darwin and Goose Green before turning towards Port Stanley. Now, with the British troops on the ground, the Argentine Air Force began the night bombing campaign against them using Canberra bomber planes until the last day of the war (14 June).
At sea, the paucity of the British ships' anti-aircraft defences was demonstrated in the sinking of on 21 May, on 24 May, and MV "Atlantic Conveyor" (struck by two AM39 Exocets) on 25 May along with a vital cargo of helicopters, runway-building equipment and tents. The loss of all but one of the Chinook helicopters being carried by the Atlantic Conveyor was a severe blow from a logistical perspective.
Also lost on this day was , a sister to , whilst in company with after being ordered to act as a decoy to draw away Argentine aircraft from other ships at San Carlos Bay. and were badly damaged. However, many British ships escaped being sunk because of weaknesses of the Argentine pilots' bombing tactics described below.
To avoid the highest concentration of British air defences, Argentine pilots released ordnance from very low altitude, and hence their bomb fuzes did not have sufficient time to arm before impact. The low release of the retarded bombs (some of which the British had sold to the Argentines years earlier) meant that many never exploded, as there was insufficient time in the air for them to arm themselves. A simple free-fall bomb in a low altitude release, impacts almost directly below the aircraft, which is then within the lethal fragmentation zone of the explosion.
A retarded bomb has a small parachute or air brake that opens to reduce the speed of the bomb to produce a safe horizontal separation between the two. The fuze for a retarded bomb requires that the retarder be open a minimum time to ensure safe separation. The pilots would have been aware of this—but due to the high concentration required to avoid SAMs, Anti-Aircraft Artillery (AAA), and British Sea Harriers, many failed to climb to the necessary release point. The Argentine forces solved the problem by fitting improvised retarding devices, allowing the pilots to effectively employ low-level bombing attacks on 8 June.
In his autobiographical account of the Falklands War, Admiral Woodward blamed the BBC World Service for disclosing information that led the Argentines to change the retarding devices on the bombs. The World Service reported the lack of detonations after receiving a briefing on the matter from a Ministry of Defence official. He describes the BBC as being more concerned with being "fearless seekers after truth" than with the lives of British servicemen. Colonel 'H'. Jones levelled similar accusations against the BBC after they disclosed the impending British attack on Goose Green by 2 Para.
Thirteen bombs hit British ships without detonating. Lord Craig, the retired Marshal of the Royal Air Force, is said to have remarked: "Six better and we would have lost" although "Ardent" and "Antelope" were both lost despite the failure of bombs to explode.
The fuzes were functioning correctly, and the bombs were simply released from too low an altitude.
Battle of Goose Green.
From early on 27 May until 28 May, 2 Para, (approximately 500 men) with artillery support from 8 (Alma) Commando Battery, Royal Artillery, approached and attacked Darwin and Goose Green, which was held by the Argentine 12th Infantry Regiment.
After a tough struggle that lasted all night and into the next day, the British won the battle; in all, 17 British and 47 Argentine soldiers were killed. In total 961 Argentine troops (including 202 Argentine Air Force personnel of the "Condor" airfield) were taken prisoner.
The BBC announced the taking of Goose Green on the BBC World Service before it had actually happened. It was during this attack that Lieutenant Colonel H. Jones, the commanding officer of 2 Para, was killed at the head of his battalion while charging into the well-prepared Argentine positions. He was posthumously awarded the Victoria Cross.
With the sizeable Argentine force at Goose Green out of the way, British forces were now able to break out of the San Carlos beachhead. On 27 May, men of 45 Cdo and 3 Para started a loaded march across East Falkland towards the coastal settlement of Teal Inlet.
Special forces on Mount Kent.
Meanwhile, 42 Commando prepared to move by helicopter to Mount Kent. Unknown to senior British officers, the Argentine generals were determined to tie down the British troops in the Mount Kent area, and on 27 and 28 May they sent transport aircraft loaded with Blowpipe surface-to-air missiles and commandos (602nd Commando Company and 601st National Gendarmerie Special Forces Squadron) to Stanley. This operation was known as Operation AUTOIMPUESTA (Self-Determination-Initiative).
For the next week, the SAS and the Mountain and Arctic Warfare Cadre (M&AWC) of 3 Commando Brigade waged intense patrol battles with patrols of the volunteers' 602nd Commando Company under Major Aldo Rico, normally 2nd in Command of the 22nd Mountain Infantry Regiment. Throughout 30 May, Royal Air Force Harriers were active over Mount Kent. One of them, Harrier "XZ963", flown by Squadron Leader Jerry Pook—in responding to a call for help from D Squadron, attacked Mount Kent's eastern lower slopes, and that led to its loss through small-arms fire. Pook was subsequently awarded the Distinguished Flying Cross.
The Argentine Navy used their last AM39 Exocet missile attempting to attack on 30 May. There are Argentine claims that the missile struck; however, the British have denied this, some citing that shot it down. When "Invincible" returned to the UK after the war, she showed no signs of missile damage.
On 31 May, the M&AWC defeated Argentine Special Forces at the Battle of Top Malo House. A 13-strong Argentine Army Commando detachment (Captain José Vercesi's 1st Assault Section, 602nd Commando Company) found itself trapped in a small shepherd's house at Top Malo. The Argentine commandos fired from windows and doorways and then took refuge in a stream bed from the burning house. Completely surrounded, they fought 19 M&AWC marines under Captain Rod Boswell for 45 minutes until, with their ammunition almost exhausted, they elected to surrender.
Three Cadre members were badly wounded. On the Argentine side, there were two dead, including Lieutenant Ernesto Espinoza and Sergeant Mateo Sbert (who were posthumously decorated for their bravery). Only five Argentines were left unscathed. As the British mopped up Top Malo House, Lieutenant Fraser Haddow's M&AWC patrol came down from Malo Hill, brandishing a large Union Flag. One wounded Argentine soldier, Lieutenant Horacio Losito, commented that their escape route would have taken them through Haddow's position.
601st Commando tried to move forward to rescue 602nd Commando Company on Estancia Mountain. Spotted by 42 Commando, they were engaged with 81mm mortars and forced to withdraw to Two Sisters mountain. The leader of 602nd Commando Company on Estancia Mountain realised his position had become untenable and after conferring with fellow officers ordered a withdrawal.
The Argentine operation also saw the extensive use of helicopter support to position and extract patrols; the 601st Combat Aviation Battalion also suffered casualties. At about 11.00 am on 30 May, an Aerospatiale SA-330 Puma helicopter was brought down by a shoulder-launched Stinger surface-to-air missile (SAM) fired by the SAS in the vicinity of Mount Kent. Six National Gendarmerie Special Forces were killed and eight more wounded in the crash.
As Brigadier Thompson commented, "It was fortunate that I had ignored the views expressed by Northwood HQ that reconnaissance of Mount Kent before insertion of 42 Commando was superfluous. Had D Squadron not been there, the Argentine Special Forces would have caught the Commando before de-planing and, in the darkness and confusion on a strange landing zone, inflicted heavy casualties on men and helicopters."
Bluff Cove and Fitzroy.
By 1 June, with the arrival of a further British troops of the 5th Infantry Brigade, the new British divisional commander, Major General Jeremy Moore RM, had sufficient force to start planning an offensive against Stanley. During this build-up, the Argentine air assaults on the British naval forces continued, killing 56. Of the dead, 32 were from the Welsh Guards on RFA "Sir Galahad" and RFA "Sir Tristram" on 8 June. According to Surgeon-Commander Rick Jolly of the Falklands Field Hospital, more than 150 men suffered burns and injuries of some kind in the attack, including, famously, Simon Weston.
The Guards were sent to support an advance along the southern approach to Stanley. On 2 June, a small advance party of 2 Para moved to Swan Inlet house in a number of Army Westland Scout helicopters. Telephoning ahead to Fitzroy, they discovered that the area was clear of Argentines and (exceeding their authority) commandeered the one remaining RAF Chinook helicopter to frantically ferry another contingent of 2 Para ahead to Fitzroy (a settlement on Port Pleasant) and Bluff Cove (a settlement on Port Fitzroy).
This uncoordinated advance caused great difficulties in planning for the commanders of the combined operation, as they now found themselves with a string of indefensible positions on their southern flank. Support could not be sent by air as the single remaining Chinook was already heavily oversubscribed. The soldiers could march, but their equipment and heavy supplies would need to be ferried by sea.
Plans were drawn up for half the Welsh Guards to march light on the night of 2 June, whilst the Scots Guards and the second half of the Welsh Guards were to be ferried from San Carlos Water in the Landing Ship Logistics (LSL) "Sir Tristram" and the landing platform dock (LPD) "Intrepid" on the night of 5 June. "Intrepid" was planned to stay one day and unload itself and as much of "Sir Tristram" as possible, leaving the next evening for the relative safety of San Carlos. Escorts would be provided for this day, after which "Sir Tristram" would be left to unload using a Mexeflote (a powered raft) for as long as it took to finish.
Political pressure from above to not risk the LPD forced Commodore Clapp to alter this plan. Two lower-value LSLs would be sent, but with no suitable beaches to land on, "Intrepid"s landing craft would need to accompany them to unload. A complicated operation across several nights with "Intrepid" and her sister ship sailing half-way to dispatch their craft was devised.
The attempted overland march by half the Welsh Guards failed, possibly as they refused to march light and attempted to carry their equipment. They returned to San Carlos and landed directly at Bluff Cove when "Fearless" dispatched her landing craft. "Sir Tristram" sailed on the night of 6 June and was joined by "Sir Galahad" at dawn on 7 June. Anchored apart in Port Pleasant, the landing ships were near Fitzroy, the designated landing point.
The landing craft should have been able to unload the ships to that point relatively quickly, but confusion over the ordered disembarcation point (the first half of the Guards going direct to Bluff Cove) resulted in the senior Welsh Guards infantry officer aboard insisting that his troops should be ferried the far longer distance directly to Port Fitzroy/Bluff Cove. The alternative was for the infantrymen to march via the recently repaired Bluff Cove bridge (destroyed by retreating Argentine combat engineers) to their destination, a journey of around seven miles (11 km).
On "Sir Galahad"s stern ramp there was an argument about what to do. The officers on board were told that they could not sail to Bluff Cove that day. They were told that they had to get their men off ship and onto the beach as soon as possible as the ships were vulnerable to enemy aircraft. It would take 20 minutes to transport the men to shore using the LCU and Mexeflote. They would then have the choice of walking the seven miles to Bluff Cove or wait until dark to sail there. The officers on board said that they would remain on board until dark and then sail. They refused to take their men off the ship. They possibly doubted that the bridge had been repaired due to the presence on board "Sir Galahad" of the Royal Engineer Troop whose job it was to repair the bridge. The Welsh Guards were keen to rejoin the rest of their Battalion, who were potentially facing the enemy without their support. They had also not seen any enemy aircraft since landing at San Carlos and may have been overconfident in the air defences. Ewen Southby-Tailyour gave a direct order for the men to leave the ship and go to the beach. The order was ignored.
The longer journey time of the landing craft taking the troops directly to Bluff Cove and the squabbling over how the landing was to be performed caused an enormous delay in unloading. This had disastrous consequences. Without escorts, having not yet established their air defence, and still almost fully laden, the two LSLs in Port Pleasant were sitting targets for two waves of Argentine A-4 Skyhawks.
The disaster at Port Pleasant (although often known as Bluff Cove) would provide the world with some of the most sobering images of the war as TV news video footage showed Navy helicopters hovering in thick smoke to winch survivors from the burning landing ships.
British casualties were 48 killed and 115 wounded. Three Argentine pilots were also killed. The air strike delayed the scheduled British ground attack on Stanley by two days. However, Argentine General Mario Menendez, commander of Argentine forces in the Falklands, was told that 900 British soldiers had died. He expected that the losses would cause enemy morale to drop and the British assault to stall.
Fall of Stanley.
On the night of 11 June, after several days of painstaking reconnaissance and logistic build-up, British forces launched a brigade-sized night attack against the heavily defended ring of high ground surrounding Stanley. Units of 3 Commando Brigade, supported by naval gunfire from several Royal Navy ships, simultaneously attacked in the Battle of Mount Harriet, Battle of Two Sisters, and Battle of Mount Longdon. Mount Harriet was taken at a cost of 2 British and 18 Argentine soldiers. At Two Sisters, the British faced both enemy resistance and friendly fire, but managed to capture their objectives. The toughest battle was at Mount Longdon. British forces were bogged down by assault rifle, mortar, machine gun, artillery fire, sniper fire, and ambushes. Despite this, the British continued their advance.
During this battle, 13 were killed when , straying too close to shore while returning from the gun line, was struck by an improvised trailer-based Exocet MM38 launcher taken from the destroyer ARA "Seguí" by Argentine Navy technicians. On the same day, Sergeant Ian McKay of 4 Platoon, B Company, 3 Para died in a grenade attack on an Argentine bunker, which earned him a posthumous Victoria Cross. After a night of fierce fighting, all objectives were secured. Both sides suffered heavy losses.
The night of 13 June saw the start of the second phase of attacks, in which the momentum of the initial assault was maintained. 2 Para, with light armour support from The Blues and Royals, captured Wireless Ridge, with the loss of 3 British and 25 Argentine lives, and the 2nd battalion, Scots Guards captured Mount Tumbledown at the Battle of Mount Tumbledown, which cost 10 British and 30 Argentine lives.
With the last natural defence line at Mount Tumbledown breached, the Argentine town defences of Stanley began to falter. In the morning gloom, one company commander got lost and his junior officers became despondent. Private Santiago Carrizo of the 3rd Regiment described how a platoon commander ordered them to take up positions in the houses and "if a Kelper resists, shoot him", but the entire company did nothing of the kind.
A ceasefire was declared on 14 June and the commander of the Argentine garrison in Stanley, Brigade General Mario Menéndez, surrendered to Major General Jeremy Moore the same day.
Recapture of South Sandwich Islands.
On 20 June, the British retook the South Sandwich Islands (which involved accepting the surrender of the Southern Thule Garrison at the "Corbeta Uruguay" base), and declared hostilities over. Argentina had established Corbeta Uruguay in 1976, but prior to 1982 the United Kingdom had contested the existence of the Argentine base only through diplomatic channels.
Casualties.
In total 907 were killed during the 74 days of the conflict:
Of the 86 Royal Navy personnel, 22 were lost in , 19 + 1 lost in , 19 + 1 lost in and 13 lost in .
Fourteen naval cooks were among the dead, the largest number from any one branch in the Royal Navy.
Thirty-three of the British Army's dead came from the Welsh Guards, 21 from the 3rd Battalion, the Parachute Regiment, 18 from the 2nd Battalion, the Parachute Regiment, 19 from the Special Air Service, 3 from Royal Signals and 8 from each of the Scots Guards and Royal Engineers. The 1st battalion/7th Duke of Edinburgh's Own Gurkha Rifles lost one man killed.
Two more British deaths may be attributed to Operation Corporate, bringing the total to 260:
There were Argentine and 777 British non-fatal casualties.
Further information about the field hospitals and hospital ships is at Ajax Bay and List of hospitals and hospital ships of the Royal Navy. On the Argentine side beside the Military Hospital at Port Stanley, the Argentine Air Force Mobile Field Hospital was deployed at Comodoro Rivadavia.
Red Cross Box.
Before British offensive operations began, the British and Argentine governments agreed to establish an area on the high seas where both sides could station hospital ships without fear of attack by the other side. This area, a circle 20 nautical miles in diameter, was referred to as the Red Cross Box (), about north of Falkland Sound). Ultimately, the British stationed four ships (HMS "Hydra", HMS "Hecla" and HMS "Herald" and the primary hospital ship "Uganda") within the box, while the Argentines stationed three ("Almirante Irizar", "Bahia Paraiso" and "Puerto Deseado").
The hospital ships were non-warships converted to serve as hospital ships. The three British naval vessels were survey vessels and "Uganda" was a passenger liner. "Almirante Irizar" was an icebreaker, "Bahia Paraiso" was an Antarctic supply transport and "Puerto Deseado" was a survey ship. The British and Argentine vessels operating within the Box were in radio contact and there was some transfer of patients between the hospital ships. For example, the British hospital ship SS "Uganda" on four occasions transferred patients to an Argentine hospital ship. The British naval hospital ships operated as casualty ferries, carrying casualties from both sides from the Falklands to "Uganda" and operating a shuttle service between the Red Cross Box and Montevideo.
Throughout the conflict officials of the International Committee of the Red Cross (ICRC) conducted inspections to verify that all concerned were abiding by the rules of the Geneva Convention. On 12 June, some personnel transferred from the Argentine hospital ship to the British ships by helicopter. Argentine naval officers also inspected the British casualty ferries in the estuary of the River Plate.
British casualty evacuation.
"Hydra" worked with "Hecla" and "Herald", to take casualties from "Uganda" to Montevideo, Uruguay, where a fleet of Uruguayan ambulances would meet them. RAF VC10 aircraft then flew the casualties to the UK for transfer to the Princess Alexandra Royal Air Force Hospital at RAF Wroughton, near Swindon.
Aftermath.
This brief war brought many consequences for all the parties involved, besides the considerable casualty rate and large materiel loss, especially of shipping and aircraft, relative to the deployed military strengths of the opposing sides.
In the United Kingdom, Margaret Thatcher's popularity increased. The success of the Falklands campaign was widely regarded as the factor in the turnaround in fortunes for the Conservative government, who had been trailing behind the SDP-Liberal Alliance in the opinion polls for months before the conflict began, but after the success in the Falklands the Conservatives returned to the top of the opinion polls by a wide margin and went on to win the following year's general election by a landslide. Subsequently, Defence Secretary Nott's proposed cuts to the Royal Navy were abandoned.
The islanders subsequently had full British citizenship restored in 1983, their lifestyle improved by investments Britain made after the war and by the liberalisation of economic measures that had been stalled through fear of angering Argentina. In 1985, a new constitution was enacted promoting self-government, which has continued to devolve power to the islanders.
In Argentina, the Falklands War meant that a possible war with Chile was avoided. Further, Argentina returned to a democratic government in the 1983 general election, the first free general election since 1973. It also had a major social impact, destroying the military's image as the "moral reserve of the nation" that they had maintained through most of the 20th century.
Various figures have been produced for the number of veterans who have committed suicide since the war. Some studies have estimated that 264 British veterans and 350–500 Argentine veterans have committed suicide since 1982. However, a detailed study of British veterans of the war commissioned by the UK Ministry of Defence found that only 95 had died from "intentional self-harm and events of undetermined intent (suicides and open verdict deaths)", a ratio no higher than that of the general population.
Military analysis.
Militarily, the Falklands conflict remains the largest air-naval combat operation between modern forces since the end of the Second World War. As such, it has been the subject of intense study by military analysts and historians. The most significant "lessons learned" include: the vulnerability of surface ships to anti-ship missiles and submarines, the challenges of co-ordinating logistical support for a long-distance projection of power, and reconfirmation of the role of tactical air power, including the use of helicopters.
In 1986, the BBC broadcast the "Horizon" programme, "In the Wake of HMS Sheffield", which discussed lessons learned from the conflict—and measures since taken to implement them, such as stealth ships and close-in weapon systems.
Memorials.
In addition to memorials on the islands, there is a memorial in the crypt of St Paul's Cathedral, London to the British war dead. In Argentina, there is a memorial at Plaza San Martín in Buenos Aires, in Rosario, and in Ushuaia.
During the war, British dead were put into plastic body bags and buried in mass graves. After the war, the bodies were recovered; 14 were reburied at Blue Beach Military Cemetery and 64 were returned to Britain.
Many of the Argentine dead are buried in the Argentine Military Cemetery west of the Darwin Settlement. The government of Argentina declined an offer by Britain to have the bodies repatriated to the mainland.
Minefields.
As of 2011, there were 113 uncleared minefields on the Falkland Islands and unexploded ordnance (UXOs) covering an area of . Of this area, on the Murrell Peninsula were classified as being "suspected minefields" – the area had been heavily pastured for the previous 25 years without incident. It was estimated that these minefields had anti-personnel mines and anti-tank mines. No human casualties from mines or UXO have been reported in the Falkland Islands since 1984, and no civilian mine casualties have ever occurred on the islands. The UK reported six military personnel were injured in 1982 and a further two injured in 1983. Most military accidents took place while clearing the minefields in the immediate aftermath of the 1982 conflict or in the process of trying to establish the extent of the minefield perimeters, particularly where no detailed records existed.
On 9 May 2008, the Falkland Islands Government asserted that the minefields, which represent 0.1% of the available farmland on the islands "present no long term social or economic difficulties for the Falklands," and that the impact of clearing the mines would cause more problems than containing them. However, the British Government, in accordance with its commitments under the Mine Ban Treaty has a commitment to clear the mines by the end of 2019.
In May 2012, it was announced that of Stanley Common (which lies between the Stanley – Mount Pleasant road and the shoreline) was made safe and had been opened to the public, opening up a stretch of coastline and a further two kilometres of shoreline along Mullet's Creek.
Press and publicity.
Argentina.
Selected war correspondents were regularly flown to Port Stanley in military aircraft to report on the war. Back in Buenos Aires, newspapers and magazines faithfully reported on "the heroic actions of the largely conscript army and its successes".
Officers from the intelligence services were attached to the newspapers and 'leaked' information confirming the official communiqués from the government. The glossy magazines "Gente" and "Siete Días" swelled to 60 pages with colour photographs of British warships in flames – many of them faked – and bogus eyewitness reports of the Argentine commandos' guerrilla war on South Georgia (6 May) and an already dead Pucará pilot's attack on HMS "Hermes" (Lt. Daniel Antonio Jukic had been killed at Goose Green during a British air strike on 1 May). Most of the faked photos actually came from the tabloid press. One of the best remembered headlines was "Estamos ganando" ("We're winning") from the magazine "Gente", that would later use variations of it.
The Argentine troops on the Falkland Islands could read "Gaceta Argentina"—a newspaper intended to boost morale among the servicemen. Some of its untruths could easily be unveiled by the soldiers who recovered corpses.
The "Malvinas course" united the Argentines in a patriotic atmosphere that protected the junta from critics, and even opponents of the military government supported Galtieri; Ernesto Sabato said: "Don't be mistaken, Europe; it is not a dictatorship who is fighting for the Malvinas, it is the whole Nation. Opponents of the military dictatorship, like me, are fighting to extirpate the last trace of colonialism." The "Madres de Plaza de Mayo" were even exposed to death threats from ordinary people.
HMS "Invincible" was repeatedly sunk in the Argentine press, and on 30 April 1982 the Argentine magazine "Tal Cual" showed Prime Minister Thatcher with an eyepatch and the text: "Pirate, witch and assassin. Guilty!" Three British reporters sent to Argentina to cover the war from the Argentine perspective were jailed until the end of the war.
United Kingdom.
Seventeen newspaper reporters, two photographers, two radio reporters and three television reporters with five technicians sailed with the Task Force to the war. The Newspaper Publishers' Association selected them from among 160 applicants, excluding foreign media.
The hasty selection resulted in the inclusion of two journalists among the war reporters who were interested only in Queen Elizabeth II's son Prince Andrew, who was serving in the conflict. The Prince flew a helicopter on multiple missions, including anti-surface warfare, Exocet missile decoy and casualty evacuation.
Merchant vessels had the civilian Inmarsat uplink, which enabled written telex and voice report transmissions via satellite. had a facsimile machine that was used to upload 202 pictures from the South Atlantic over the course of the war. The Royal Navy leased bandwidth on the US Defense Satellite Communications System for worldwide communications. Television demands a thousand times the data rate of telephone, but the Ministry of Defence was unsuccessful in convincing the US to allocate more bandwidth.
TV producers suspected that the enquiry was half-hearted; since the Vietnam War television pictures of casualties and traumatised soldiers were recognised as having negative propaganda value. However, the technology only allowed uploading a single frame per 20 minutes – and only if the military satellites were allocated 100% to television transmissions. Videotapes were shipped to Ascension Island, where a broadband satellite uplink was available, resulting in TV coverage being delayed by three weeks.
The press was very dependent on the Royal Navy, and was censored on site. Many reporters in the UK knew more about the war than those with the Task Force.
The Royal Navy expected Fleet Street to conduct a Second World War-style positive news campaign but the majority of the British media, especially the BBC, reported the war in a neutral fashion. These reporters referred to "the British troops" and "the Argentinian troops" instead of "our lads" and the "Argies". The two main tabloid papers presented opposing viewpoints: "The Daily Mirror" was decidedly anti-war, whilst "The Sun" became well known for headlines such as "Stick It Up Your Junta!," which, along with the reporting in other tabloids, led to accusations of xenophobia
Cultural impact.
There were wide-ranging influences on popular culture in both the UK and Argentina, from the immediate postwar period to the present. The then elderly Argentine writer Jorge Luis Borges described the war as "a fight between two bald men over a comb". The words "yomp" and "Exocet" entered the British vernacular as a result of the war. The Falklands War also provided material for theatre, film and TV drama and influenced the output of musicians. In Argentina, the military government banned the broadcasting of music in the English language, giving way to the rise of local rock musicians.

</doc>
<doc id="11524" url="https://en.wikipedia.org/wiki?curid=11524" title="Fahrenheit">
Fahrenheit

Fahrenheit is a temperature scale based on one proposed in 1724 by the German physicist Daniel Gabriel Fahrenheit (1686–1736), after whom the scale is named. It uses the degree Fahrenheit (symbol °F) as the unit. There exist several accounts of how he originally defined his scale. The lower defining point, 0 degrees, was established as the temperature of a solution of brine made from equal parts of ice and salt. Further limits were established as the melting point of water (32 degrees) and his best estimate of the average human body temperature (96 degrees, about 2.5 degrees less than modern measurements). The scale is now usually defined by two fixed points: the temperature at which water freezes into ice is defined as 32 degrees, and the boiling point of water is defined to be 212 degrees, a 180-degree separation, as defined at sea level and standard atmospheric pressure.
By the end of the 20th century, Fahrenheit was only used as the official temperature scale in the United States, the Bahamas, Belize, the Cayman Islands, and Palau. All other countries in the world now use the Celsius scale, defined since 1954 by absolute zero being −273.15 °C and the triple point of water being at 0.01 °C. However, the Fahrenheit scale remains in common unofficial use in many of the current and former US unincorporated territories.
Definition and conversions.
On the Fahrenheit scale, the freezing point of water is 32 degrees Fahrenheit (°F) and the boiling point is 212 °F (at standard atmospheric pressure). This puts the boiling and freezing points of water exactly 180 degrees apart. Therefore, a degree on the Fahrenheit scale is of the interval between the freezing point and the boiling point. On the Celsius scale, the freezing and boiling points of water are 100 degrees apart. A temperature interval of 1 °F is equal to an interval of  degrees Celsius. The Fahrenheit and Celsius scales intersect at −40° (−40 °F and −40 °C represent the same temperature).
Absolute zero is −273.15 °C or −459.67 °F. The "Rankine" temperature scale uses degree intervals of the same size as those of the Fahrenheit scale, except that absolute zero is 0 R—the same way that the "Kelvin" temperature scale matches the Celsius scale, except that absolute zero is 0 K.
The Fahrenheit scale uses the symbol ° to denote a point on the temperature scale (as does Celsius) and the letter F to indicate the use of the Fahrenheit scale ("e.g." "Gallium melts at 85.5763 °F"), as well as to denote a difference between temperatures or an uncertainty in temperature ("e.g." "The output of the heat exchanger experiences an increase of 72 °F" and "Our standard uncertainty is ±5 °F").
For an exact conversion, the following formulas can be applied:
An approximate conversion between degrees Celsius and degrees Fahrenheit is as follows:
This formula gives an answer correct to within ±2.8 °C from 1 °F to 100 °F and is exact at 50 °F (calculations below).
History.
Fahrenheit proposed his temperature scale in 1724, basing it on three reference points of temperature. In his initial scale (which is not the final Fahrenheit scale), the zero point is determined by placing the thermometer in brine: he used a mixture of ice, water, and ammonium chloride, a salt, at a 1:1:1 ratio. This is a frigorific mixture which stabilizes its temperature automatically: that stable temperature was defined as 0 °F (−17.78 °C). The second point, at 32 degrees, was a mixture of ice and water without the ammonium chloride at a 1:1 ratio. The third point, 96 degrees, was approximately the human body temperature, then called "blood-heat".
According to a story and trivia questions in Germany, Fahrenheit actually chose the lowest air temperature measured in his hometown Danzig in winter 1708/09 as 0 °F, and only later had the need to be able to make this value reproducible using brine. This is one explanation given why 0 °F is −17.78 °C, but the ammonium chloride cooling temperature actually is −3 °C, whereas that of NaCl is −21.1 °C; the other explanation is that he did not have a good enough brine solution to obtain the eutectic equilibrium exactly (i.e. he might have had a mixture of salts, or it had not fully dissolved). In any case, the definition of the Fahrenheit scale has changed since.
According to a letter Fahrenheit wrote to his friend Herman Boerhaave, his scale was built on the work of Ole Rømer, whom he had met earlier. In Rømer's scale, brine freezes at zero, water freezes and melts at 7.5 degrees, body temperature is 22.5, and water boils at 60 degrees. Fahrenheit multiplied each value by four in order to eliminate fractions and increase the granularity of the scale. He then re-calibrated his scale using the melting point of ice and normal human body temperature (which were at 30 and 90 degrees); he adjusted the scale so that the melting point of ice would be 32 degrees and body temperature 96 degrees, so that 64 intervals would separate the two, allowing him to mark degree lines on his instruments by simply bisecting the interval six times (since 64 is 2 to the sixth power).
Fahrenheit observed that water boils at about 212 degrees using this scale. Later, other scientists decided to redefine the scale slightly to make the freezing point exactly 32 °F, and the boiling point exactly 212 °F or 180 degrees higher. It is for this reason that normal human body temperature is approximately 98° (oral temperature) on the revised scale (whereas it was 90° on Fahrenheit's multiplication of Rømer, and 96° on his original scale).
The Rankine temperature scale was based upon the Fahrenheit temperature scale, with its zero representing absolute zero instead.
Usage.
The Fahrenheit scale was the primary temperature standard for climatic, industrial and medical purposes in English-speaking countries until the 1960s. In the late 1960s and 1970s, the Celsius scale replaced Fahrenheit in almost all of those countries—with the notable exception of the United States—typically during their metrication process.
Fahrenheit is used in the Bahamas, Belize, the Cayman Islands, Palau, and the United States and associated territories of American Samoa and the U.S. Virgin Islands for everyday applications (although Puerto Rico and Guam use Celsius alongside Fahrenheit as well). For example, U.S. weather forecasts, food cooking, and freezing temperatures are typically given in degrees Fahrenheit. Scientists, such as meteorologists, use Celsius or Kelvin in all countries.
Early in the twentieth century, Halsey and Dale suggested that the resistance to the use of centigrade (now Celsius) system in the U.S. included the larger size of each degree Celsius and the lower zero point in the Fahrenheit system.
Canada has passed legislation favoring the International System of Units, while also maintaining legal definitions for traditional Canadian imperial units. Canadian weather reports are conveyed using degrees Celsius with occasional reference to Fahrenheit especially for cross-border broadcasts. Virtually all Canadian ovens make legal use of the Fahrenheit scale. Thermometers, both digital and analog, sold in Canada usually employ both the Celsius and Fahrenheit scales. Also, in some instances (swimming pool temperature or cooking temperatures for example), temperatures are still expressed in Fahrenheit.
Within the European Union, it is mandatory to use kelvins or degrees Celsius when quoting temperature for "economic, public health, public safety and administrative" purposes, though degrees Fahrenheit may be used alongside degrees Celsius as a supplementary unit. For example, the laundry symbols used in the United Kingdom follow the recommendations of ISO 3758:2005 showing the temperature of the washing machine water in degrees Celsius only. The equivalent label in North America uses one to six dots to denote temperature with an optional temperature in degrees Celsius.
Within the unregulated sector, such as journalism, the use of Fahrenheit in the United Kingdom follows no fixed pattern with degrees Fahrenheit often appearing alongside degrees Celsius. "The Daily Mail", on its daily weather page, quotes Celsius first, followed by Fahrenheit in brackets, "The Daily Telegraph" does not mention Fahrenheit on its daily weather page while "The Times" also has an all-metric daily weather page but has a Celsius-to-Fahrenheit conversion table. When publishing news stories, much of the UK press adopted a convention of using degrees Celsius in headlines relating to low temperatures and Fahrenheit for high temperatures. In February 2006, the writer of an article in "The Times" suggested that the rationale was one of emphasis: "−6 °C" sounds colder than "21 °F" and "94 °F" sounds more impressive than "34 °C".
Unicode representation of symbol.
Unicode provides the Fahrenheit symbol at codepoint . However, this is a compatibility character encoded for roundtrip compatibility with legacy encodings. The Unicode standard explicitly discourages the use of this character: "The sequence + is preferred over , and those two sequences should be treated as identical for searching."

</doc>
<doc id="11525" url="https://en.wikipedia.org/wiki?curid=11525" title="Florence">
Florence

Florence ( ; ) is the capital city of the Italian region of Tuscany and of the Metropolitan City of Florence. It is the most populous city in Tuscany, with approximately 382,000 inhabitants, expanding to over 1,520,000 in the metropolitan area.
Florence is famous for its history: a centre of medieval European trade and finance and one of the wealthiest cities of the time, it is considered the birthplace of the Renaissance, and has been called "the Athens of the Middle Ages". A turbulent political history includes periods of rule by the powerful Medici family, and numerous religious and republican revolutions. From 1865 to 1871 the city was the capital of the recently established Kingdom of Italy.
The Historic Centre of Florence attracts millions of tourists each year, and Euromonitor International ranked the city as the world's 89th most visited in 2012, with 1.8 million visitors. It was declared a World Heritage Site by UNESCO in 1982. The city is noted for its culture, Renaissance art and architecture and monuments. The city also contains numerous museums and art galleries, such as the Uffizi Gallery and the Palazzo Pitti, and still exerts an influence in the fields of art, culture and politics. Due to Florence's artistic and architectural heritage, it has been ranked by "Forbes" as one of the most beautiful cities in the world.
Florence is an important city in Italian fashion, being ranked in the top 51 fashion capitals of the world; furthermore, it is a major national economic centre, as well as a tourist and industrial hub. In 2008, the city had the 17th highest average income in Italy.
History.
Florence originated as a Roman city, and later, after a long period as a flourishing trading and banking medieval commune, it was the birthplace of the Italian Renaissance. According to the "Encyclopædia Britannica", it was politically, economically, and culturally one of the most important cities in Europe and the world from the 14th to 16th centuries.
The language spoken in the city during the 14th century was, and still is, accepted as the Italian language. Almost all the writers and poets in Italian literature of the "golden age" are in some way connected with Florence, leading ultimately to the adoption of the Florentine dialect, above all the local dialects, as a literary language of choice.
Starting from the late Middle Ages, Florentine money—in the form of the gold florin—financed the development of industry all over Europe, from Britain to Bruges, to Lyon and Hungary. Florentine bankers financed the English kings during the Hundred Years War. They similarly financed the papacy, including the construction of their provisional capital of Avignon and, after their return to Rome, the reconstruction and Renaissance embellishment of Rome.
Florence was home to the Medici, one of history's most important noble families. Lorenzo de' Medici was considered a political and cultural mastermind of Italy in the late 15th century. Two members of the family were popes in the early 16th century: Leo X and Clement VII. Catherine de Medici married king Henry II of France and, after his death in 1559, reigned as regent in France. The Medici reigned as Grand Dukes of Tuscany, starting with Cosimo I de' Medici in 1569 and ending with the death of Gian Gastone de' Medici in 1737.
Roman origins.
Florence was established by Lucius Cornelius Sulla in 80 BC as a settlement for his veteran soldiers and was named originally "Fluentia", owing to the fact that it was built between two rivers, which was later changed to "Florentia". It was built in the style of an army camp with the main streets, the "cardo" and the "decumanus", intersecting at the present "Piazza della Repubblica". Situated at the "Via Cassia", the main route between Rome and the north, and within the fertile valley of the Arno, the settlement quickly became an important commercial centre.
In centuries to come, the city experienced turbulent periods of Ostrogothic rule, during which the city was often troubled by warfare between the Ostrogoths and the Byzantines, which may have caused the population to fall to as few as 1,000 people. Peace returned under Lombard rule in the 6th century. Florence was conquered by Charlemagne in 774 and became part of the Duchy of Tuscany, with Lucca as capital. The population began to grow again and commerce prospered. In 854, Florence and Fiesole were united in one county.
Second millennium.
Margrave Hugo chose Florence as his residency instead of Lucca at about 1000 AD. The Golden Age of Florentine art began around this time. In 1013, construction began on the Basilica di San Miniato al Monte. The exterior of the baptistery was reworked in Romanesque style between 1059, and 1128. This period also saw the eclipse of Florence's formerly powerful rival Pisa (defeated by Genoa in 1284 and subjugated by Florence in 1406), and the exercise of power by the mercantile elite following an anti-aristocratic movement, led by Giano della Bella, that resulted in a set of laws called the Ordinances of Justice (1293).
Middle Ages and Renaissance.
Rise of the Medici.
Of a population estimated at 94,000 before the Black Death of 1348, about 25,000 are said to have been supported by the city's wool industry: in 1345 Florence was the scene of an attempted strike by wool combers ("ciompi"), who in 1378 rose up in a brief revolt against oligarchic rule in the Revolt of the Ciompi. After their suppression, Florence came under the sway (1382–1434) of the Albizzi family, bitter rivals of the Medici.
In the 15th century, Florence was among the largest cities in Europe, considered rich and economically successful. Life was not idyllic for all residents though, among whom there were great disparities in wealth. Cosimo de' Medici was the first Medici family member to essentially control the city from behind the scenes. Although the city was technically a democracy of sorts, his power came from a vast patronage network along with his alliance to the new immigrants, the "gente nuova" (new people). The fact that the Medici were bankers to the pope also contributed to their ascendancy. Cosimo was succeeded by his son Piero, who was, soon after, succeeded by Cosimo's grandson, Lorenzo in 1469. Lorenzo was a great patron of the arts, commissioning works by Michelangelo, Leonardo da Vinci and Botticelli. Lorenzo was an accomplished musician and brought composers and singers to Florence, including Alexander Agricola, Johannes Ghiselin, and Heinrich Isaac. By contemporary Florentines (and since), he was known as "Lorenzo the Magnificent" (Lorenzo il Magnifico).
Following Lorenzo de' Medici's death in 1492, he was succeeded by his son Piero II. When the French king Charles VIII invaded northern Italy, Piero II chose to resist his army. But when he realized the size of the French army at the gates of Pisa, he had to accept the humiliating conditions of the French king. These made the Florentines rebel and they expelled Piero II. With his exile in 1494, the first period of Medici rule ended with the restoration of a republican government.
Savonarola and Machiavelli.
During this period, the Dominican friar Girolamo Savonarola had become prior of the San Marco monastery in 1490. He was famed for his penitential sermons, lambasting what he viewed as widespread immorality and attachment to material riches. He blamed the exile of the Medicis as the work of God, punishing them for their decadence. He seized the opportunity to carry through political reforms leading to a more democratic rule. But when Savonarola publicly accused Pope Alexander VI of corruption, he was banned from speaking in public. When he broke this ban, he was excommunicated. The Florentines, tired of his extreme teachings, turned against him and arrested him. He was convicted as a heretic and burned at the stake on the Piazza della Signoria on 23 May 1498.
A second individual of unusually acute insight was Niccolò Machiavelli, whose prescriptions for Florence's regeneration under strong leadership have often been seen as a legitimization of political expediency and even malpractice. In other words, Machiavelli was a sort of political thinker, perhaps most renowned for his political handbook, titled The Prince, which is about ruling and the exercise of power. Commissioned by the Medici, Machiavelli also wrote the Florentine Histories, the history of the city. Florentines drove out the Medici for a second time and re-established a republic on 16 May 1527. Restored twice with the support of both Emperor and Pope, the Medici in 1537 became hereditary dukes of Florence, and in 1569 Grand Dukes of Tuscany, ruling for two centuries. In all Tuscany, only the Republic of Lucca (later a Duchy) and the Principality of Piombino were independent from Florence.
18th and 19th centuries.
The extinction of the Medici dynasty and the accession in 1737 of Francis Stephen, duke of Lorraine and husband of Maria Theresa of Austria, led to Tuscany's temporary inclusion in the territories of the Austrian crown. It became a secundogeniture of the Habsburg-Lorraine dynasty, who were deposed for the House of Bourbon-Parma in 1801, themselves deposed in December 1807 when Tuscany was annexed by France. Florence was the prefecture of the French département of Arno from 1808 to the fall of Napoleon in 1814. The Habsburg-Lorraine dynasty was restored on the throne of Tuscany at the Congress of Vienna but finally deposed in 1859. Tuscany became a region of the Kingdom of Italy in 1861.
Florence replaced Turin as Italy's capital in 1865 and, in an effort to modernise the city, the old market in the Piazza del Mercato Vecchio and many medieval houses were pulled down and replaced by a more formal street plan with newer houses. The Piazza (first renamed Piazza Vittorio Emmanuele II, then Piazza della Repubblica, the present name) was significantly widened and a large triumphal arch was constructed at the west end. This development was unpopular and was prevented from continuing by the efforts of several British and American people living in the city. A museum recording the destruction stands nearby today.
The country's second capital city was superseded by Rome six years later, after the withdrawal of the French troops made its addition to the kingdom possible.
20th century.
After doubling during the 19th century, Florence's population was to triple in the 20th, resulting from growth in tourism, trade, financial services and industry.
During World War II the city experienced a year-long German occupation (1943–1944) and was declared an open city. The Allied soldiers who died driving the Germans from Tuscany are buried in cemeteries outside the city (Americans about nine kilometres () south of the city, British and Commonwealth soldiers a few kilometres east of the centre on the right bank of the Arno). In 1944, the retreating Germans demolished the bridges along the Arno linking the district of Oltrarno to the rest of the city, making it difficult for the British troops to cross. However, at the last moment Charle Steinhauslin, at the time consulate of 26 countries in Florence, convinced the German general in Italy that the Ponte Vecchio was not to be destroyed due to its historical value.
Instead, an equally historic area of streets directly to the south of the bridge, including part of the Corridoio Vasariano, was destroyed using mines. Since then the bridges have been restored to their original forms using as many of the remaining materials as possible, but the buildings surrounding the Ponte Vecchio have been rebuilt in a style combining the old with modern design. Shortly before leaving Florence, as they knew that they would soon have to retreat, the Germans executed many freedom fighters and political opponents publicly, in streets and squares including the Piazza Santo Spirito.
At the end of World War II in Europe, in May 1945, the U.S. Army's Information and Educational Branch was ordered to establish an overseas university campus for demobilized American service men and women in Florence, Italy. The first American University for service personnel was established in June 1945 at the School of Aeronautics in Florence, Italy. Some 7,500 soldier-students were to pass through the University during its four one-month sessions (see G. I. American Universities).
In November 1966, the Arno flooded parts of the centre, damaging many art treasures. Around the city there are tiny placards on the walls noting where the flood waters reached at their highest point.
Geography.
Florence lies in a basin formed by the hills of Careggi, Fiesole, Settignano, Arcetri, Poggio Imperiale and Bellosguardo (Florence). The Arno river and three other minor rivers flow through it.
Climate.
Florence has a humid subtropical climate ("Cfa"), slightly tending to Mediterranean ("Csa"). It has hot summers with moderate or light rainfall and cool, damp winters. As Florence lacks a prevailing wind, summer temperatures are higher than along the coast. Rainfall in summer is convectional, while relief rainfall dominates in the winter. Snow is infrequent. The highest officially recorded temperature was on 26 July 1983 and the lowest was on 12 January 1985.
Government.
The legislative body of the municipality is the City Council ("Consiglio Comunale"), which is composed of 36 councillors elected every five years with a proportional system, contextually to the mayoral elections. The executive body is the City Committee ("Giunta Comunale"), composed by 7 assessors, that is nominated and presieded over by a directly elected Mayor. The current mayor of Florence is Dario Nardella.
The municipality of Florence is subdivided into five administrative Boroughs ("Quartieri"). Each Borough is governed by a Council ("Consiglio") and a President, elected contextually to the city Mayor. The urban organization is governed by the Italian Constitution (art. 114). The Boroughs have the power to advise the Mayor with nonbinding opinions on a large spectrum of topics (environment, construction, public health, local markets) and exercise the functions delegated to them by the City Council; in addition they are supplied with an autonomous founding in order to finance local activities. The Boroughs are:
All of the five boroughs are governed by the Democratic Party.
The current Italian Prime Minister, Matteo Renzi, served as mayor from 2009 to 2014.
Main sights.
Florence is known as the "cradle of the Renaissance" ("la culla del Rinascimento") for its monuments, churches, and buildings. The best-known site of Florence is the domed cathedral of the city, Santa Maria del Fiore, known as "The Duomo", whose dome was built by Filippo Brunelleschi. The nearby Campanile (partly designed by Giotto) and the Baptistery buildings are also highlights. The dome, 600 years after its completion, is still the largest dome built in brick and mortar in the world. In 1982, the historic centre of Florence (Italian: "centro storico di Firenze") was declared a World Heritage Site by the UNESCO. The centre of the city is contained in medieval walls that were built in the 14th century to defend the city. At the heart of the city, in Piazza della Signoria, is Bartolomeo Ammanati's Fountain of Neptune (1563–1565), which is a masterpiece of marble sculpture at the terminus of a still functioning Roman aqueduct.
The layout and structure of Florence in many ways harkens back to the Roman era, where it was designed as a garrison settlement. Nevertheless, the majority of the city was built during the Renaissance. Despite the strong presence of Renaissance architecture within the city, traces of medieval, Baroque, Neoclassical and modern architecture can be found. The Palazzo Vecchio as well as the Duomo, or the city's Cathedral, are the two buildings which dominate Florence's skyline.
The River Arno, which cuts through the old part of the city, is as much a character in Florentine history as many of the people who lived there. Historically, the locals have had a love-hate relationship with the Arno – which alternated between nourishing the city with commerce, and destroying it by flood.
One of the bridges in particular stands out — the Ponte Vecchio ("Old Bridge"), whose most striking feature is the multitude of shops built upon its edges, held up by stilts. The bridge also carries Vasari's elevated corridor linking the Uffizi to the Medici residence (Palazzo Pitti). Although the original bridge was constructed by the Etruscans, the current bridge was rebuilt in the 14th century. It is the only bridge in the city to have survived World War II intact. It is the first example in the western world of a bridge built using segmental arches, that is, arches less than a semicircle, to reduce both span-to-rise ratio and the numbers of pillars to allow lesser encumbrance in the riverbed (being in this much more successful than the Roman Alconétar Bridge).
The church of San Lorenzo contains the Medici Chapel, the mausoleum of the Medici family—the most powerful family in Florence from the 15th to the 18th century. Nearby is the Uffizi Gallery, one of the finest art museums in the world – founded on a large bequest from the last member of the Medici family.
The Uffizi is located at the corner of Piazza della Signoria, a site important for being the centre of Florence's civil life and government for centuries. The Palazzo della Signoria facing it is still home of the municipal government. The Loggia dei Lanzi provided the setting for all the public ceremonies of the republican government. Many significant episodes in the history of art and political changes were staged here, such as:
The Piazza della Signoria is the location of a number of statues by other sculptors such as Donatello, Giambologna, Ammannati and Cellini, although some have been replaced with copies to preserve the originals.
Monuments, museums and religious buildings.
Florence contains several palaces and buildings from various eras. The Palazzo Vecchio is the town hall of Florence and also an art museum. This large Romanesque crenellated fortress-palace overlooks the Piazza della Signoria with its copy of Michelangelo's David statue as well the gallery of statues in the adjacent Loggia dei Lanzi. Originally called the "Palazzo della Signoria", after the Signoria of Florence, the ruling body of the Republic of Florence, it was also given several other names: "Palazzo del Popolo", "Palazzo dei Priori", and "Palazzo Ducale", in accordance with the varying use of the palace during its long history. The building acquired its current name when the Medici duke's residence was moved across the Arno to the Palazzo Pitti. It is linked to the Uffizi and the Palazzo Pitti through the Corridoio Vasariano.
Palazzo Medici Riccardi, designed by Michelozzo di Bartolomeo for Cosimo il Vecchio, of the Medici family, is another major edifice, and was built between 1445 and 1460. It was well known for its stone masonry that includes rustication and ashlar. Today it is the head office of the Metropolitan City of Florence and hosts museums and the Riccardiana Library. The Palazzo Strozzi, an example of civil architecture with its rusticated stone, was inspired by the Palazzo Medici, but with more harmonious proportions. Today the palace is used for international expositions like the annual antique show (founded as the Biennale del'Antiquariato in 1959), fashion shows and other cultural and artistic events. Here also is the seat of the Istituto Nazionale del Rinascimento and the noted Gabinetto Vieusseux, with the library and reading room. Aside from these palaces and buildings, there are several others, including the Palazzo Rucellai, designed by Leon Battista Alberti between 1446 and 1451 and executed, at least in part, by Bernardo Rossellino; the Palazzo Davanzati, which houses the museum of the Old Florentine House; the Palazzo delle Assicurazioni Generali, designed in the Neo-Renaissance style in 1871; the Palazzo Spini Feroni, in Piazza Santa Trinita, a historic 13th-century private palace, owned since the 1920s by shoe-designer Salvatore Ferragamo; as well as various others, including the Palazzo Borghese, the Palazzo di Bianca Cappello, the Palazzo Antinori, and the Royal building of Santa Maria Novella.
Florence contains numerous museums and art galleries where some of the world's most important works of art are held. The city is one of the best preserved Renaissance centres of art and architecture in the world and has a high concentration of art, architecture and culture. In the ranking list of the 15 most visited Italian art museums, ⅔ are represented by Florentine museums. The Uffizi is one of these; one of the most famous and important art galleries in the world, it has a very large collection of international and Florentine art. The gallery is articulated in many halls, cataloged by schools and chronological order. Engendered by the Medici family's artistic collections through the centuries, it houses works of art by various painters and artists. The Vasari Corridor is another gallery, built connecting the Palazzo Vecchio with the Pitti Palace passing by the Uffizi and over the Ponte Vecchio. The Galleria dell' Accademia houses a Michelangelo collection, including the David. It has a collection of Russian icons and works by various artists and painters. Furthermore, other museums and galleries include the Bargello, which concentrates on sculpture works by artists including Donatello, Giambologna and Michelangelo; the Palazzo Pitti, containing part of the Medici family's former private collection. In addition to the Medici collection, the palace's galleries contain many Renaissance works, including several by Raphael and Titian, large collections of costumes, ceremonial carriages, silver, porcelain and a gallery of modern art dating from the 18th century. Adjoining the palace are the Boboli Gardens, elaborately landscaped and with numerous sculptures.
There are several different churches and religious buildings in Florence. The cathedral is the Santa Maria del Fiore. The San Giovanni Baptistery is located in front of the cathedral, and is decorated by numerous artists, notably by Lorenzo Ghiberti with the "Gates of Paradise". Other churches in Florence include the Basilica of Santa Maria Novella, located in Santa Maria Novella square (near the Firenze Santa Maria Novella railway station) which contains works by Masaccio, Paolo Uccello, Filippino Lippi and Domenico Ghirlandaio; the Basilica of Santa Croce, the principal Franciscan church in the city, which is situated on the Piazza di Santa Croce, about 800 metres south east of the Duomo, and is the burial place of some of the most illustrious Italians, such as Michelangelo, Galileo, Machiavelli, Foscolo, Gentile, Rossini, and Marconi, thus it is known also as the Temple of the Italian Glories (Tempio dell'Itale Glorie); the Basilica of San Lorenzo, which is one of the largest churches in the city, situated at the centre of Florence's main market district, and the burial place of all the principal members of the Medici family from Cosimo il Vecchio to Cosimo III; Santo Spirito, in the Oltrarno quarter, facing the square with the same name; Orsanmichele, whose building was constructed on the site of the kitchen garden of the monastery of San Michele, now demolished; Santissima Annunziata, a Roman Catholic basilica and the mother church of the Servite order; Ognissanti, which was founded by the lay order of the Umiliati, and is among the first examples of Baroque architecture built in the city; the Santa Maria del Carmine, in the Oltrarno district of Florence, which is the location of the Brancacci Chapel, housing outstanding Renaissance frescoes by Masaccio and Masolino da Panicale, later finished by Filippino Lippi; the Medici Chapel, in the San Lorenzo; as well as several others, including Santa Trinita, San Marco, Santa Felicita, Badia Fiorentina, San Gaetano, San Miniato al Monte, Florence Charterhouse, and Santa Maria del Carmine. The city additionally contains the Orthodox Russian church of Nativity, and the Great Synagogue of Florence, built in the 19th century.
Additionally, Florence contains various theatres and cinemas. The Odeon Cinema of the Palazzo dello Strozzino is one of the oldest movie theatres in the city. Established from 1920 to 1922 in a wing of the Palazzo dello Strozzino, it used to be called the "Cinema Teatro Savoia" (Savoy Cinema-Theatre), yet was later called "Odeon". The Teatro della Pergola, located in the centre of the city on the eponymous street, is an opera house built in the 17th century. Another theatre is the Teatro Comunale (or "Teatro del Maggio Musicale Fiorentino"), originally built as the open-air amphitheatre, the "Politeama Fiorentino Vittorio Emanuele", which was inaugurated on 17 May 1862 with a production of Donizetti's "Lucia di Lammermoor" and which seated 6,000 people. There are several other theatres, such as the Saloncino Castinelli, the Teatro Puccini, the Teatro Verdi, the Teatro Goldoni and the Teatro Niccolini.
Squares, streets and parks.
Aside from such monuments, Florence contains numerous major squares ("piazze") and streets. The Piazza della Repubblica is a square in the city centre, location of the cultural cafes and bourgeois palaces. Among the square's cafes (like Caffè Gilli, Paszkowski or the Hard Rock Cafè), the Giubbe Rosse cafe has long been a meeting place for artists and writers, notably those of Futurism. The Piazza Santa Croce is another; dominated by the Basilica of Santa Croce, it is a rectangular square in the centre of the city where the Calcio Fiorentino is played every year. Furthermore, there is the Piazza Santa Trinita, a square near the Arno that mark the end of the Via de' Tornabuoni street.
Other squares include the Piazza San Marco, the Piazza Santa Maria Novella, the Piazza Beccaria and the Piazza della Libertà. The centre additionally contains several streets. Such include the Via Camillo Cavour, one of the main roads of the northern area of the historic centre; the Via Ghibellina, one of central Florence's longest streets; the Via dei Calzaiuoli, one of most central streets of the historic centre of the which links "Piazza del Duomo" to "Piazza della Signoria", winding parallel to via Roma and "Piazza della Repubblica"; the Via de' Tornabuoni, a luxurious street in the city centre that goes from Antinori square to ponte Santa Trinita, across Piazza Santa Trinita, characterised by the presence of fashion boutiques; the Viali di Circonvallazione, 6-lane boulevards surrounding the northern part of the historic centre; as well as others, such as Via Roma, Via degli Speziali, Via de' Cerretani, and the Viale dei Colli.
Florence also contains various parks and gardens. Such include the Boboli Gardens, the Parco delle Cascine, the Giardino Bardini and the Giardino dei Semplici, amongst others.
Demographics.
In 1200 the city was home to 50,000 people. By 1300 the population of the city proper was 120,000, with an additional 300,000 living in the Contado. Between 1500 and 1650 the population was around 70,000.
, the population of the city proper is 370,702, while Eurostat estimates that 696,767 people live in the urban area of Florence. The Metropolitan Area of Florence, Prato and Pistoia, constituted in 2000 over an area of roughly , is home to 1.5 million people. Within Florence proper, 46.8% of the population was male in 2007 and 53.2% were female. Minors (children aged 18 and less) totalled 14.10 percent of the population compared to pensioners, who numbered 25.95 percent. This compares with the Italian average of 18.06 percent (minors) and 19.94 percent (pensioners). The average age of Florence resident is 49 compared to the Italian average of 42. In the five years between 2002 and 2007, the population of Florence grew by 3.22 percent, while Italy as a whole grew by 3.56 percent. The birth rate of Florence is 7.66 births per 1,000 inhabitants compared to the Italian average of 9.45 births.
As of 2009, 87.46% of the population was Italian. An estimated 6,000 Chinese live in the city. The largest immigrant group came from other European countries (mostly Romanians and Albanians): 3.52%, East Asia (mostly Chinese and Filipino): 2.17%, the Americas: 1.41%, and North Africa (mostly Moroccan): 0.9%.
Economy.
Tourism is, by far, the most important of all industries and most of the Florentine economy relies on the money generated by international arrivals and students studying in the city. Manufacturing and commerce, however, still remain highly important. Florence is also Italy's 17th richest city in terms of average workers' earnings, with the figure being €23,265 (the overall city's income is €6,531,204,473), coming after Mantua, yet surpassing Bolzano.
In 2013, Florence was listed as the second best world city by "Condé Nast Traveler".
Industry, commerce and services.
Florence is a major production and commercial centre in Italy, where the Florentine industrial complexes in the suburbs produce all sorts of goods, from furniture, rubber goods, chemicals, and food. However, traditional and local products, such as antiques, handicrafts, glassware, leatherwork, art reproductions, jewelry, souvenirs, elaborate metal and iron-work, shoes, accessories and high fashion clothes also dominate a fair sector of Florence's economy. The city's income relies partially on services and commercial and cultural interests, such as annual fairs, theatrical and lyrical productions, art exhibitions, festivals and fashion shows, such as the Calcio Fiorentino. Heavy industry and machinery also take their part in providing an income. In Nuovo Pignone, numerous factories are still present, and small-to medium industrial businesses are dominant. The Florence-Prato-Pistoia industrial districts and areas were known as the 'Third Italy' in the 1990s, due to the exports of high-quality goods and automobile (especially the Vespa) and the prosperity and productivity of the Florentine entrepreneurs. Some of these industries even rivaled the traditional industrial districts in Emilia-Romagna and Veneto due to high profits and productivity.
Tourism.
Tourism is the most significant industry in central Florence. From April to October, tourists outnumber local population. Tickets to the Uffizi and Accademia museums are regularly sold out and large groups regularly fill the basilicas of Santa Croce and Santa Maria Novella, both of which charge for entry. Tickets for The Uffizi and Accademia can be purchased online prior to visiting. In 2010, readers of "Travel + Leisure" magazine ranked the city as their third favourite tourist destination. Studies by Euromonitor International have concluded that cultural and history-oriented tourism is generating significantly increased spending throughout Europe.
Florence is believed to have the greatest concentration of art (in proportion to its size) in the world. Thus, cultural tourism is particularly strong, with world-renowned museums such as the Uffizi selling over 1.6 million tickets a year. The city's convention centre facilities were restructured during the 1990s and host exhibitions, conferences, meetings, social forums, concerts and other events all year.
Florence has approximately 35,000 hotel beds and 23,000 other accommodation facilities (campsites, guesthouses, youth hostels and farmhouses), giving potential for overall stays to exceed 10 million visitor/nights a year. Visitors also include thousands of day-trippers brought in by cruise ships (to Livorno) and by road and rail. In 2007, the city ranked as the world's 59th most visited city, with over 1.729 million arrivals for the year. It has been estimated that just under one-third of tourists are Italians, the remainder comprising Americans (20%), Germans (13%), Japanese (8%), Britons (7.8%), French (5.7%) and Spaniards (5%).
Food and wine production.
Food and wine have long been an important staple of the economy. Florence is the most important city in Tuscany, one of the great wine-growing regions in the world. The Chianti region is just south of the city, and its Sangiovese grapes figure prominently not only in its Chianti Classico wines but also in many of the more recently developed Supertuscan blends. Within to the west is the Carmignano area, also home to flavorful sangiovese-based reds. The celebrated Chianti Rufina district, geographically and historically separated from the main Chianti region, is also few kilometres east of Florence. More recently, the Bolgheri region (about southwest of Florence) has become celebrated for its "Super Tuscan" reds such as Sassicaia and Ornellaia.
Culture.
Art.
Florence has a legendary artistic heritage. Cimabue and Giotto, the fathers of Italian painting, lived in Florence as well as Arnolfo and Andrea Pisano, renewers of architecture and sculpture; Brunelleschi, Donatello and Masaccio, forefathers of the Renaissance, Ghiberti and the Della Robbias, Filippo Lippi and Angelico; Botticelli, Paolo Uccello and the universal genius of Leonardo da Vinci and Michelangelo.
Their works, together with those of many other generations of artists, are gathered in the several museums of the town: the Uffizi Gallery, the Palatina gallery with the paintings of the "Golden Ages", the Bargello with the sculptures of the Renaissance, the museum of San Marco with Fra Angelico's works, the Academy, the chapels of the Medicis Buonarroti's house with the sculptures of Michelangelo, the following museums: Bardini, Horne, Stibbert, Romano, Corsini, The Gallery of Modern Art, the Museo dell'Opera del Duomo, the museum of Silverware and the museum of Precious Stones.
Great monuments are the landmarks of Florentine artistic culture: the Florence Baptistery with its mosaics; the Cathedral with its sculptures, the medieval churches with bands of frescoes; public as well as private palaces: Palazzo Vecchio, Palazzo Pitti, Palazzo Medici Riccardi, Palazzo Davanzati; monasteries, cloisters, refectories; the "Certosa". In the archeological museum includes documents of Etruscan civilization. In fact the city is so rich in art that some first time visitors experience the Stendhal syndrome as they encounter its art for the first time.
Florentine architects such as Filippo Brunelleschi (1377–1466) and Leon Battista Alberti (1404–1472) were among the fathers of both Renaissance and Neoclassical architecture.
The cathedral, topped by Brunelleschi's dome, dominates the Florentine skyline. The Florentines decided to start building it – late in the 13th century, without a design for the dome. The project proposed by Brunelleschi in the 14th century was the largest ever built at the time, and the first major dome built in Europe since the two great domes of Roman times – the Pantheon in Rome, and Hagia Sophia in Constantinople. The dome of Santa Maria del Fiore remains the largest brick construction of its kind in the world. In front of it is the medieval Baptistery. The two buildings incorporate in their decoration the transition from the Middle Ages to the Renaissance. In recent years, most of the important works of art from the two buildings – and from the nearby Giotto's Campanile, have been removed and replaced by copies. The originals are now housed in the Museum dell'Opera del Duomo, just to the east of the Cathedral.
Florence has large numbers of art-filled churches, such as San Miniato al Monte, San Lorenzo, Santa Maria Novella, Santa Trinita, Santa Maria del Carmine, Santa Croce, Santo Spirito, the Annunziata, Ognissanti and numerous others.
Artists associated with Florence range from Arnolfo di Cambio and Cimabue to Giotto, Nanni di Banco, and Paolo Uccello; through Lorenzo Ghiberti, and Donatello and Massaccio and the della Robbia family; through Fra Angelico and Botticelli and Piero della Francesca, and on to Michelangelo and Leonardo da Vinci. Others include Benvenuto Cellini, Andrea del Sarto, Benozzo Gozzoli, Domenico Ghirlandaio, Filippo Lippi, Bernardo Buontalenti, Orcagna, Pollaiuolo, Filippino Lippi, Verrocchio, Bronzino, Desiderio da Settignano, Michelozzo, the Rossellis, the Sangallos, and Pontormo. Artists from other regions who worked in Florence include Raphael, Andrea Pisano, Giambologna, Il Sodoma and Peter Paul Rubens.
The Uffizi and the Pitti Palace are two of the most famous picture galleries in the world. Two superb collections of sculpture are in the Bargello and the Museum of the Works of the Duomo. They are filled with the creations of Donatello, Verrochio, Desiderio da Settignano, Michelangelo and others. The Galleria dell'Accademia has Michelangelo's David – perhaps the most well-known work of art anywhere, plus the unfinished statues of the slaves Michelangelo created for the tomb of Pope Julius II. Other sights include the medieval city hall, the Palazzo della Signoria (also known as the Palazzo Vecchio), the Archeological Museum, the Museum of the History of Science, the Palazzo Davanzatti, the Stibbert Museum, St. Marks, the Medici Chapels, the Museum of the Works of Santa Croce, the Museum of the Cloister of Santa Maria Novella, the Zoological Museum ("La Specola"), the Bardini, and the Museo Horne. There is also a collection of works by the modern sculptor, Marino Marini, in a museum named after him. The Strozzi Palace is the site of special exhibits.
Language.
Florentine ("fiorentino"), spoken by inhabitants of Florence and its environs, is a Tuscan dialect and the immediate parent language to modern Italian.
Its vocabulary and pronunciation are largely identical to standard Italian, though the hard "c" between two vowels (as in "ducato") is pronounced as a fricative , similar to an English "h". This gives Florentines a highly recognizable accent (the so-called gorgia toscana). Other traits include using a form of the subjunctive mood last commonly used in medieval times, a frequent usage in everyday speech of the modern subjunctive, and a shortened pronunciation of the definite article, instead of "il".
Dante, Petrarch, and Boccaccio pioneered the use of the vernacular instead of the Latin used for most literary works at the time.
Literature.
Despite Latin being the main language of the courts and the Church, writers such as Dante Alighieri and many others used their own language, the Florentine dialect, in composing their works. The oldest literary pieces written in vernacular language go as far back as the 13th century. Florence's literature fully blossomed in the 14th century, when not only Dante with his "Divine Comedy" (1306–1321) and Petrarch, but also poets such as Guido Cavalcanti and Lapo Gianni composed their most important works. Dante's masterpiece is the "Divine Comedy", which mainly deals with the poet himself taking an allegoric and moral tour of Hell, Purgatory and finally Heaven, during which he meets numerous mythological or real characters of his age or before. He is first guided by the Roman poet Virgil, whose non-Christian beliefs damned him to Hell. Later on he is joined by Beatrice, who guides him through Heaven.
In the 14th century, Petrarch and Giovanni Boccaccio led the literary scene in Florence after Dante's death in 1321. Petrarch was an all-rounder writer, author and poet, but was particularly known for his "Canzoniere", or the Book of Songs, where he conveyed his unremitting love for Laura. His style of writing has since become known as "Petrarchism". Boccaccio was better known for his "Decameron", a slightly grim story of Florence during the 1350s bubonic plague, known as the Black Death, when some people fled the ravaged city to an isolated country mansion, and spent their time there recounting stories and novellas taken from the medieval and contemporary tradition. All of this is written in a series of 100 distinct novellas.
In the 16th century, during the Renaissance, Florence was the hometown of political writer and philosopher Niccolò Machiavelli, whose ideas on how rulers should govern the land, detailed in "The Prince", spread across European courts and enjoyed enduring popularity for centuries. These principles became known as "Machiavellianism".
Music.
Florence became a musical centre during the Middle Ages and music and the performing arts remain an important part of its culture. During the Renaissance there were four kinds of musical patronage in the city with respect to both sacred and secular music: state, corporate, church, and private. and it was here that the Florentine Camerata convened in the mid-16th century and experimented with setting tales of Greek mythology to music and staging the result—in other words, the first operas, setting the wheels in motion not just for the further development of the operatic form, but for later developments of separate "classical" forms such as the symphony.
Opera was invented in Florence in the late 16th century.
Composers and musicians who have lived in Florence include Piero Strozzi (1550 – after 1608), Giulio Caccini (1551–1618) and Mike Francis (1961–2009).
Cinema.
Florence has been a setting for numerous works of fiction and movies, including the novels and associated films, such as "Light in the Piazza", "Calmi Cuori Appassionati", "Hannibal", "A Room with a View", "Tea with Mussolini" and "Virgin Territory". The city is home to renowned Italian actors and actresses, such as Roberto Benigni, Leonardo Pieraccioni and Vittoria Puccini.
Cuisine.
Florentine food grows out of a tradition of peasant eating rather than rarefied high cooking. The majority of dishes are based on meat. The whole animal was traditionally eaten; tripe ("trippa") and stomach ("lampredotto") were once regularly on the menu and still are sold at the food carts stationed throughout the city. Antipasti include "crostini toscani", sliced bread rounds topped with a chicken liver-based pâté, and sliced meats (mainly prosciutto and salame, often served with melon when in season). The typically saltless Tuscan bread, obtained with natural levain frequently features in Florentine courses, especially in its soups, "ribollita" and "pappa al pomodoro", or in the salad of bread and fresh vegetables called "panzanella" that is served in summer. The "bistecca alla fiorentina" is a large (the customary size should weigh around 1200 grams – "40 oz.") – the "date" steak – T-bone steak of Chianina beef cooked over hot charcoal and served very rare with its more recently derived version, the "tagliata", sliced rare beef served on a bed of arugula, often with slices of Parmesan cheese on top. Most of these courses are generally served with local olive oil, also a prime product enjoying a worldwide reputation. <br> Among the desserts, "schiacciata alla fiorentina" ("white flatbread cake") is one of the most popular; it is a very soft cake, prepared with extremely simple ingredients as it is peculiar of the florentine cuisine, and it is typically eaten on Carnival time.
Research activity.
Research institutes and university departments are located within the Florence area and within two campuses at
Polo di Novoli and Polo Scientifico di Sesto Fiorentino as well as in the Research Area of Consiglio Nazionale delle Ricerche.
Science and discovery.
Florence has been an important scientific centre for centuries, notably during the Renaissance with scientists such as Leonardo da Vinci.
Florentines were one of the driving forces behind the Age of Discovery. Florentine bankers financed Henry the Navigator and the Portuguese explorers who pioneered the route around Africa to India and the Far East. It was a map drawn by the Florentine Paolo dal Pozzo Toscanelli, a student of Brunelleschi, that Christopher Columbus used to sell his "enterprise" to the Spanish monarchs, and which he used on his first voyage. Mercator's "Projection" is a refined version of Toscanelli's – taking into account the Americas, of which the Florentine was, obviously, ignorant.
Galileo and other scientists pioneered the study of optics, ballistics, astronomy, anatomy, and so on. Pico della Mirandola, Leonardo Bruni, Machiavelli, and many others laid the groundwork for our understanding of science.
Fashion.
By the year 1300 Florence had become a center of textile production in Europe. Many of the rich families in Renaissance Florence were major purchasers of locally produced fine clothing, and the specialists of fashion in the economy and culture of Florence during that period is often underestimated. Florence is regarded by some as the birthplace and earliest center of the modern (post World War Two) fashion industry in Italy. The Florentine "soirées" of the early 1950s organized by Giovanni Battista Giorgini were events where several now-famous Italian designers participated in group shows and first garnered international attention. Florence has served as the home of the Italian fashion company Salvatore Ferragamo since 1928. Gucci, Roberto Cavalli, and Emilio Pucci are also headquartered in Florence. Other major players in the fashion industry such as Prada and Chanel have large offices and stores in Florence or its outskirts. Florence's main upscale shopping street is Via de' Tornabuoni, where major luxury fashion houses and jewelry labels, such as Armani and Bulgari, have their elegant boutiques. Via del Parione and Via Roma are other streets that are also well known for their high-end fashion stores.
Historical evocations.
"Scoppio del Carro".
The "Scoppio del Carro" ("Explosion of the Cart") is a celebration of the First Crusade. During the day of Easter, a cart, which the Florentines call the "Brindellone" and which is led by four white oxen, is taken to the Piazza del Duomo between the Baptistery of St. John the Baptist ("Battistero di San Giovanni") and the Florence Cathedral ("Santa Maria del Fiore"). The cart is connected by a rope to the interior of the church. Near the cart there is a model of a dove, which, according to legend, is a symbol of good luck for the city: at the end of the Easter mass, the dove emerges from the nave of the Duomo and ignites the fireworks on the cart.
"Calcio Storico".
"Calcio Storico Fiorentino" ("Historic Florentine Football"), sometimes called "Calcio in costume", is a traditional sport, regarded as a forerunner of soccer, though the actual gameplay most closely resembles rugby. The event originates from the Middle Ages, when the most important Florentine nobles amused themselves playing while wearing bright costumes. The most important match was played on 17 February 1530, during the siege of Florence. That day Papal troops besieged the city while the Florentines, with contempt of the enemies, decided to play the game notwithstanding the situation. The game is played in the Piazza di Santa Croce. A temporary arena is constructed, with bleachers and a sand-covered playing field. A series of matches are held between four teams representing each "quartiere "(quarter) of Florence during late June and early July. There are four teams: Azzurri (light blue), Bianchi (white), Rossi (red) and Verdi (green). The Azzurri are from the quarter of Santa Croce, Bianchi from the quarter of Santo Spirito, Verdi are from San Giovanni and Rossi from Santa Maria Novella.
Transport.
The principal public transport network within the city is run by the ATAF and Li-nea bus company, with tickets available at local tobacconists, bars and newspaper stalls. Individual tickets, or a pass called the Carta Agile with multiple rides (10, 21 or 35), may be used on ATAF&Li-nea buses, Tramvia, and 2nd class local trains but only within city railway stations. Once on the bus, tickets must be stamped (or swiped for the Carta Agile) using the machines on board, unlike train tickets which must be validated before boarding. The main bus station is next to Santa Maria Novella railway station. Trenitalia runs trains between the railway stations within the city, and to other destinations around Italy and Europe. The central railway station, Santa Maria Novella railway station, is located about northwest of the Piazza del Duomo. There are two other important stations: Campo Di Marte and Rifredi. Most bundled routes are Firenze—Pisa, Firenze—Viareggio and Firenze-Arezzo (along the main line to Rome). Other local railways connect Florence with Borgo San Lorenzo in the Mugello area (Faentina railway) and Siena.
Long distance buses are run by the SITA, Copit, CAP companies. The transit companies also accommodate travellers from the Amerigo Vespucci Airport, which is five kilometres () west of the city centre, and which has scheduled services run by major European carriers.
The centre of the city is closed to through-traffic, although buses, taxis and residents with appropriate permits are allowed in. This area is commonly referred to as the ZTL ("Zona Traffico Limitato"), which is divided into five subsections. Residents of one section, therefore, will only be able to drive in their district and perhaps some surrounding ones. Cars without permits are allowed to enter after 7.30 pm, or before 7.30 am. The rules shift during the tourist-filled summers, putting more restrictions on where one can get in and out.
In an effort to reduce air pollution and car traffic in the city, a multi-line tram network called "Tramvia" is under construction. The first line began operation on 14 February 2010 and connects Florence's primary intercity railway station (Santa Maria Novella) with the southwestern suburb of Scandicci. This line is long and has 14 stops. The construction of a second line began on 5 November 2011, construction was stopped due to contractors' difficulties but should restart in a few months, completion is now previewed in 2017. This second line will connect Florence's airport with the city centre. A third line (from Santa Maria Novella to the Careggi area, where are the most important hospitals of Florence) has gained governmental approval, its construction will follow the second line's timeline.
Railway station.
Firenze Santa Maria Novella railway station is the main national and international railway station in Florence and is used by 59 million people every year. The building, designed by Giovanni Michelucci, was built in the "Italian Rationalism" style and it is one of the major rationalist buildings in Italy. It is located in "Piazza della Stazione", near the Fortezza da Basso (a masterpiece of the military Renaissance architecture) and the Viali di Circonvallazione, and in front of the Basilica of Santa Maria Novella's apse, from which it takes its name.
A new high-speed rail station is under construction and is contracted to be operational by 2015. It is planned to be connected to Vespucci airport, Santa Maria Novella railway station, and to the city centre by the second line of Tramvia. The architectural firms Foster + Partners and Lancietti Passaleva Giordo and Associates designed this new rail station.
Airport.
Florence Airport, Peretola is one of two main airports in the Tuscany region, the other being Galileo Galilei International Airport in Pisa.
Sport.
Florence is represented by ACF Fiorentina, which plays in Serie A, the top league of Italian football. They play their games at the Stadio Artemio Franchi, which currently holds 47,282. The city is home of Coverciano, the main training ground of the Italian national team, and the technical department of the Italian Football Federation.
Florence was selected to host the 2013 UCI World Road Cycling Championships.
International relations.
Twin towns and sister cities.
Florence is twinned with:
<br>

</doc>
<doc id="11526" url="https://en.wikipedia.org/wiki?curid=11526" title="Quotient group">
Quotient group

A quotient group or factor group is a mathematical group obtained by aggregating similar elements of a larger group using an equivalence relation that preserves the group structure. For example, the cyclic group of addition modulo "n" can be obtained from the integers by identifying elements that differ by a multiple of "n" and defining a group structure that operates on each such class (known as a congruence class) as a single entity. It is part of the mathematical field known as group theory.
In a quotient of a group, the equivalence class of the identity element is always a normal subgroup of the original group, and the other equivalence classes are precisely the cosets of that normal subgroup. The resulting quotient is written , where "G" is the original group and "N" is the normal subgroup. (This is pronounced ""G" mod "N"," where "mod" is short for modulo.)
Much of the importance of quotient groups is derived from their relation to homomorphisms. The first isomorphism theorem states that the image of any group "G" under a homomorphism is always isomorphic to a quotient of "G". Specifically, the image of "G" under a homomorphism is isomorphic to where ker("φ") denotes the kernel of "φ".
The dual notion of a quotient group is a subgroup, these being the two primary ways of forming a smaller group from a larger one. Any normal subgroup has a corresponding quotient group, formed from the larger group by eliminating the distinction between elements of the subgroup. In category theory, quotient groups are examples of quotient objects, which are dual to subobjects. For other examples of quotient objects, see quotient ring, quotient space (linear algebra), quotient space (topology), and quotient set.
Definition and illustration.
Given a group "G" and a subgroup "H", and an element "a" in "G", then one can consider the corresponding left coset : "aH":={ "ah" : "h" in "H" }. Cosets are a natural class of subsets of a group; for example consider the abelian group "G" of integers, and the subgroup "H" of even integers. Then there are exactly two cosets: "0 + H", which are the even integers, and "1 + H", which are the odd integers (here we are using additive notation for the binary operation instead of multiplicative notation). 
For a general subgroup "H", it is desirable to define a compatible group operation on the set of all possible cosets, { "aH" : "a" in "G" }. This is possible exactly when "H" is a normal subgroup, as we will see below. A subgroup "N" of a group "G" is normal if and only if the coset equality "aN" = "Na" holds for all "a" in "G". A normal subgroup of "G" is denoted . 
Definition.
Let "N" be a normal subgroup of a group "G". We define the set "G"/"N" to be the set of all left cosets of "N" in "G", i.e., . Define an operation on "G"/"N" as follows. For each "aN" and "bN" in "G"/"N", the product of "aN" and "bN" is ("aN")("bN"). This defines an operation on "G"/"N", because we have the following equalities of subsets of "G":
Here we have used in an important way that "N" is a normal subgroup. One checks that this operation on "G"/"N" is associative, has identity element "N", and the inverse of an element "aN" of "G"/"N" is "a""N". Therefore, the set "G"/"N" together with the operation defined above forms a group; this is known as the quotient group of "G" by "N".
Because of the normality of "N", the left cosets and right cosets of "N" in "G" are equal, and so we could have instead defined "G"/"N" to be the set of right cosets of "N" in "G".
Example: Addition modulo 6.
For example, consider the group with addition modulo 6: "G" = {0, 1, 2, 3, 4, 5}. Consider the subgroup "N" = {0, 3}, which is normal because "G" is abelian. Then the set of (left) cosets is of size three:
The binary operation defined above makes this set into a group, known as the quotient group, which in this case is isomorphic to the cyclic group of order 3.
Motivation for the name "quotient".
The reason "G"/"N" is called a quotient group comes from division of integers. When dividing 12 by 3 one obtains the answer 4 because one can regroup 12 objects into 4 subcollections of 3 objects. The quotient group is the same idea, however we end up with a group for a final answer instead of a number because groups have more structure than an arbitrary collection of objects.
To elaborate, when looking at "G"/"N" with "N" a normal subgroup of "G", the group structure is used to form a natural "regrouping". These are the cosets of "N" in "G". Because we started with a group and normal subgroup, the final quotient contains more information than just the number of cosets (which is what regular division yields), but instead has a group structure itself.
Examples.
Consider the group of integers Z (under addition) and the subgroup 2Z consisting of all even integers. This is a normal subgroup, because Z is abelian. There are only two cosets: the set of even integers and the set of odd integers; therefore, the quotient group Z/2Z is the cyclic group with two elements. This quotient group is isomorphic with the set with addition modulo 2; informally, it is sometimes said that Z/2Z "equals" the set with addition modulo 2.
A slight generalization of the last example. Once again consider the group of integers Z under addition. Let "n" be any positive integer. We will consider the subgroup "nZ of Z consisting of all multiples of "n". Once again "nZ is normal in Z because Z is abelian. The cosets are the collection {"nZ, 1+"nZ, ..., ("n"−2)+"nZ, ("n"−1)+"nZ}. An integer "k" belongs to the coset "r"+"nZ, where "r" is the remainder when dividing "k" by "n". The quotient Z/"nZ can be thought of as the group of "remainders" modulo "n". This is a cyclic group of order "n".
The twelfth roots of unity, which are points on the unit circle, form a multiplicative abelian group "G", shown on the picture on the right as colored balls with the number at each point giving its complex argument. Consider its subgroup "N" made of the fourth roots of unity, shown as red balls. This normal subgroup splits the group into three cosets, shown in red, green and blue. One can check that the cosets form a group of three elements (the product of a red element with a blue element is blue, the inverse of a blue element is green, etc.). Thus, the quotient group "G"/"N" is the group of three colors, which turns out to be the cyclic group with three elements.
Consider the group of real numbers R under addition, and the subgroup Z of integers. The cosets of Z in R are all sets of the form "a"+Z, with a real number. Adding such cosets is done by adding the corresponding real numbers, and subtracting 1 if the result is greater than or equal to 1. The quotient group R/Z is isomorphic to the circle group S, the group of complex numbers of absolute value 1 under multiplication, or correspondingly, the group of rotations in 2D about the origin, i.e., the special orthogonal group SO(2). An isomorphism is given by (see Euler's identity).
If "G" is the group of invertible 3 × 3 real matrices, and "N" is the subgroup of 3 × 3 real matrices with determinant 1, then "N" is normal in "G" (since it is the kernel of the determinant homomorphism). The cosets of "N" are the sets of matrices with a given determinant, and hence "G"/"N" is isomorphic to the multiplicative group of non-zero real numbers. The group "N" is known as the special linear group SL(3).
Consider the abelian group (that is, the set with addition modulo 4), and its subgroup . The quotient group is . This is a group with identity element , and group operations such as }. Both the subgroup and the quotient group are isomorphic with Z.
Consider the multiplicative group formula_1. The set "N" of "n"th residues is a multiplicative subgroup isomorphic to formula_2. Then "N" is normal in "G" and the factor group "G"/"N" has the cosets "N", (1+"n")"N", (1+"n")N, ..., (1+"n")N. The Pallier cryptosystem is based on the conjecture that it is difficult to determine the coset of a random element of "G" without knowing the factorization of "n".
Properties.
The quotient group is isomorphic to the trivial group (the group with one element), and is isomorphic to "G".
The order of , by definition the number of elements, is equal to , the index of "N" in "G". If "G" is finite, the index is also equal to the order of "G" divided by the order of "N". Note that may be finite, although both "G" and "N" are infinite (e.g. ).
There is a "natural" surjective group homomorphism , sending each element "g" of "G" to the coset of "N" to which "g" belongs, that is: . The mapping "π" is sometimes called the "canonical projection of G onto ". Its kernel is "N".
There is a bijective correspondence between the subgroups of "G" that contain "N" and the subgroups of ; if "H" is a subgroup of "G" containing "N", then the corresponding subgroup of is "π"("H"). This correspondence holds for normal subgroups of "G" and as well, and is formalized in the lattice theorem.
Several important properties of quotient groups are recorded in the fundamental theorem on homomorphisms and the isomorphism theorems.
If "G" is abelian, nilpotent, solvable, cyclic or finitely generated, then so is .
If "H" is a subgroup in a finite group "G", and the order of "H" is one half of the order of "G", then "H" is guaranteed to be a normal subgroup, so exists and is isomorphic to "C". This result can also be stated as "any subgroup of index 2 is normal", and in this form it applies also to infinite groups. Furthermore, if "p" is the smallest prime number dividing the order of a finite group, "G", then if has order "p", "H" must be a normal subgroup of "G". 
Given "G" and a normal subgroup "N", then "G" is a group extension of by "N". One could ask whether this extension is trivial or split; in other words, one could ask whether "G" is a direct product or semidirect product of "N" and . This is a special case of the extension problem. An example where the extension is not split is as follows: Let "G" = Z = {0,1,2,3}, and "N" = { 0, 2 }, which is isomorphic to Z. Then is also isomorphic to Z. But Z has only the trivial automorphism, so the only semi-direct product of "N" and is the direct product. Since Z is different from , we conclude that "G" is not a semi-direct product of "N" and .
Quotients of Lie groups.
If "G" is a Lie group and "N" is a normal Lie subgroup of "G", the quotient is also a Lie group. In this case, the original group "G" has the structure of a fiber bundle (specifically, a principal "N"-bundle), with base space and fiber "N".
For a non-normal Lie subgroup "N", the space of left cosets is not a group, but simply a differentiable manifold on which "G" acts. The result is known as a homogeneous space.

</doc>
<doc id="11527" url="https://en.wikipedia.org/wiki?curid=11527" title="Fundamental theorem on homomorphisms">
Fundamental theorem on homomorphisms

In abstract algebra, the fundamental theorem on homomorphisms, also known as the fundamental homomorphism theorem, relates the structure of two objects between which a homomorphism is given, and of the kernel and image of the homomorphism.
The homomorphism theorem is used to prove the isomorphism theorems.
Group theoretic version.
Given two groups "G" and "H" and a group homomorphism "f" : "G"→"H", let "K" be a normal subgroup in "G" and φ the natural surjective homomorphism "G"→"G"/"K" (where "G"/"K" is a quotient group). If "K" is a subset of ker("f") then there exists a unique homomorphism "h":"G"/"K"→"H" such that "f" = "h" φ.
In other words, the natural projection φ is universal among homomorphisms on "G" that map "K" to the identity element.
The situation is described by the following commutative diagram:
By setting "K" = ker("f") we immediately get the first isomorphism theorem.
Other versions.
Similar theorems are valid for monoids, vector spaces, modules, and rings.

</doc>
<doc id="11528" url="https://en.wikipedia.org/wiki?curid=11528" title="FCO">
FCO

FCO may mean:

</doc>
<doc id="11529" url="https://en.wikipedia.org/wiki?curid=11529" title="Fermion">
Fermion

In particle physics, a fermion (a name coined by Paul Dirac from the surname of Enrico Fermi) is any particle characterized by Fermi–Dirac statistics. These particles obey the Pauli exclusion principle. Fermions include all quarks and leptons, as well as any composite particle made of an odd number of these, such as all baryons and many atoms and nuclei. Fermions differ from bosons, which obey Bose–Einstein statistics.
A fermion can be an elementary particle, such as the electron, or it can be a composite particle, such as the proton. According to the spin-statistics theorem in any reasonable relativistic quantum field theory, particles with integer spin are bosons, while particles with half-integer spin are fermions.
Besides this spin characteristic, fermions have another specific property: they possess conserved baryon or lepton quantum numbers. Therefore what is usually referred as the spin statistics relation is in fact a spin statistics-quantum number relation.
As a consequence of the Pauli exclusion principle, only one fermion can occupy a particular quantum state at any given time. If multiple fermions have the same spatial probability distribution, then at least one property of each fermion, such as its spin, must be different. Fermions are usually associated with matter, whereas bosons are generally force carrier particles, although in the current state of particle physics the distinction between the two concepts is unclear. Weakly interacting fermions can also display bosonic behavior under extreme conditions. At low temperature fermions show superfluidity for uncharged particles and superconductivity for charged particles.
Composite fermions, such as protons and neutrons, are the key building blocks of everyday matter.
Elementary fermions.
The Standard Model recognizes two types of elementary fermions: quarks and leptons. In all, the model distinguishes 24 different fermions. There are six quarks (up, down, strange, charm, bottom and top quarks), and six leptons (electron, electron neutrino, muon, muon neutrino, tau particle and tau neutrino), along with the corresponding antiparticle of each of these.
Mathematically, fermions come in three types - Weyl fermions (massless), Dirac fermions (massive), and Majorana fermions (each its own antiparticle). Most Standard Model fermions are believed to be Dirac fermions, although it is unknown at this time whether the neutrinos are Dirac or Majorana fermions. Dirac fermions can be treated as a combination of two Weyl fermions. In July 2015, Weyl fermions have been experimentally realized in Weyl semimetals.
Composite fermions.
Composite particles (such as hadrons, nuclei, and atoms) can be bosons or fermions depending on their constituents. More precisely, because of the relation between spin and statistics, a particle containing an odd number of fermions is itself a fermion. It will have half-integer spin.
Examples include the following:
The number of bosons within a composite particle made up of simple particles bound with a potential has no effect on whether it is a boson or a fermion.
Fermionic or bosonic behavior of a composite particle (or system) is only seen at large (compared to size of the system) distances. At proximity, where spatial structure begins to be important, a composite particle (or system) behaves according to its constituent makeup.
Fermions can exhibit bosonic behavior when they become loosely bound in pairs. This is the origin of superconductivity and the superfluidity of helium-3: in superconducting materials, electrons interact through the exchange of phonons, forming Cooper pairs, while in helium-3, Cooper pairs are formed via spin fluctuations.
The quasiparticles of the fractional quantum Hall effect are also known as composite fermions, which are electrons with an even number of quantized vortices attached to them.
Skyrmions.
In a quantum field theory, there can be field configurations of bosons which are topologically twisted. These are coherent states (or solitons) which behave like a particle, and they can be fermionic even if all the constituent particles are bosons. This was discovered by Tony Skyrme in the early 1960s, so fermions made of bosons are named skyrmions after him.
Skyrme's original example involved fields which take values on a three-dimensional sphere, the original nonlinear sigma model which describes the large distance behavior of pions. In Skyrme's model, reproduced in the large N or string approximation to quantum chromodynamics (QCD), the proton and neutron are fermionic topological solitons of the pion field.
Whereas Skyrme's example involved pion physics, there is a much more familiar example in quantum electrodynamics with a magnetic monopole. A bosonic monopole with the smallest possible magnetic charge and a bosonic version of the electron will form a fermionic dyon.
The analogy between the Skyrme field and the Higgs field of the electroweak sector has been used to postulate that all fermions are skyrmions. This could explain why all known fermions have baryon or lepton quantum numbers and provide a physical mechanism for the Pauli exclusion principle.

</doc>
<doc id="11530" url="https://en.wikipedia.org/wiki?curid=11530" title="Fred Savage">
Fred Savage

Frederick Aaron "Fred" Savage (born July 9, 1976) is an American actor, director, and producer. He is best known for his role as Kevin Arnold in the American television series "The Wonder Years". He has earned several awards and nominations, such as People's Choice Awards and Young Artist Awards.
Early life.
Savage was born in Highland Park, Illinois, the son of Joanne and Lewis Savage, who was an industrial real estate broker and consultant. Fred grew up in Glencoe, IL, before moving out to California. His brother is actor Ben Savage, and his sister is actress/musician Kala Savage. His grandparents were Jewish immigrants from Poland, Ukraine, Germany, and Latvia. He was raised Reform Jewish.
Education.
Savage was educated at Brentwood School, a private co-educational day school in Brentwood, in the Westside area of Los Angeles County in California. He graduated from Stanford University in 1999, with a bachelor's degree in English and as a member of Sigma Alpha Epsilon.
Career.
Acting.
Savage's first screen performance was in the television show "Morningstar/Eveningstar", at age 9. He then appeared onscreen in "The Boy Who Could Fly", "Dinosaurs!", and several television shows, including "The Twilight Zone" and "Crime Story" before gaining national attention as the grandson in the 1987 film "The Princess Bride" opposite Peter Falk. 
In 1988, Savage appeared as Kevin Arnold on "The Wonder Years", the role for which he is best known, and for which he received two Golden Globe nominations and two Emmy nominations for Outstanding Lead Actor in a Comedy Series. At the age of thirteen he was the youngest actor ever to receive these honors. He remained on the show until it ended in 1993. During this period, he appeared in several films, most notably "Vice Versa" (1988), and also starred in "Little Monsters". After "The Wonder Years", Savage primarily did guest and supporting roles, such as the show "Boy Meets World" (which starred his brother Ben) and in the film "Austin Powers in Goldmember" as The Mole.
Savage has lent his voice to several animated projects, including "Family Guy", "Kim Possible", "Justice League Unlimited", "Oswald", and "". His two lead roles since "The Wonder Years" were on the short-lived sitcoms "Working" and "Crumbs".
Savage appeared as a serial rapist on a 2003 episode of "" and as a womanizing professor on "Boy Meets World". He ranked at #27 on VH1's "100 Greatest Kid Stars".
In July 2008, Savage guest-starred in the web series "The Rascal" on Crackle.
In 2015, Savage returned to acting with the Fox series "The Grinder". Producer Nick Stoller approached Savage about playing the role of Stewart on "The Grinder". Savage was uninterested in acting at first but agreed to meet with the producers of the series because his children attended school with Stoller's children. Savage eventually agreed to take on the role.
Directing and Producing.
In 1999, Savage began his directing career in which he helmed episodes of over a dozen television series. Savage's first directing credit was on the short-lived NBC sitcom "Working" which also starred Savage. Following Working, Savage began observing production on the Disney Channel show "Even Stevens" to further learn the craft of directing. Savage also learned by shadowing Amy Sherman-Palladino, Todd Holland, and James Burrows. 
His credits include "Boy Meets World", "Drake & Josh" and "Ned's Declassified" for Nickelodeon, as well as "That's So Raven", "Hannah Montana" and "Wizards of Waverly Place" for Disney Channel. Additionally, Savage has directed for prime-time network sitcoms including "Modern Family" and "2 Broke Girls".
Besides directing several episodes, Savage co-produced the Disney Channel Original Series "Phil of the Future". In 2007, he was nominated for a Directors Guild award for the "Phil" episode "Not-So-Great-Great Grandpa".
Savage has served as a producer for several episodes of "It's Always Sunny in Philadelphia", "Friends with Benefits", "Party Down", "Phil of the Future", "The Crazy Ones", and "Happy Endings".
In 2007, he made his feature film directing debut with the film "Daddy Day Camp".
Personal life.
Savage is married to his childhood friend Jennifer Lynn Stone. They have two sons and a daughter.

</doc>
<doc id="11531" url="https://en.wikipedia.org/wiki?curid=11531" title="Futurians">
Futurians

The Futurians were a group of science fiction fans, many of whom became editors and writers as well. The Futurians were based in New York City and were a major force in the development of science fiction writing and science fiction fandom in the years 1937-1945.
Origins of the group.
As described in Isaac Asimov's autobiography "In Memory Yet Green", the Futurians spun off from the Greater New York Science Fiction Club (headed by Sam Moskowitz, later an influential SF editor and historian) over ideological differences, with the Futurians wishing to take a more overt political stance. Other sources indicate that Donald A. Wollheim was pushing for a more left-wing direction with a goal of leading fandom toward a political ideal, all of which Moskowitz resisted. As a result, Wollheim broke off from the Greater New York group and founded the Futurians in September, 1938. The fans following Moskowitz reorganized into the Queens Science Fiction Club.
Frederik Pohl, in his autobiography "The Way the Future Was", said that the origin of the Futurians lay with the Science Fiction League founded by Hugo Gernsback in 1934, the local New York City chapter of which was called the "Brooklyn Science Fiction League" or BSFL, headed by G. G. Clark.
Wollheim, John Michel, and Robert A. W. Lowndes were also members of the BSFL. Along with Pohl, the four started calling themselves the "Quadrumvirate". Pohl, commenting about that time, said "we four marched from Brooklyn to the sea, leaving a wide scar of burned out clubs behind us. We changed clubs the way Detroit changes tailfins, every year had a new one, and last year's was junk".
There were several club names during that period, before finally settling on the Futurians. In 1935 there was the "East New York Science Fiction League" (ENYSFL), later the "Independent League for Science Fiction" (ILSF). In 1936 came the International Cosmos Science Club (ICSC), which also involved Will Sykora. Pohl then says that "on reflection 'Cosmos' seemed to take in a bit more territory than was justified, so we changed it to the International Scientific Association (it wasn't International either, but then it also wasn't scientific)". The ISA then was renamed New York Branch-International Scientific Association (NYB-ISA).
In 1937, after the falling-out with Will Sykora and others, the "Quadrumvirate" went on to found the Futurians. Will Sykora then founded the Queens Science Fiction League with Sam Moskowitz and James V. Taurasi. Later, the QSFL changed into New Fandom. Pohl said as the conflicts between New Fandom and the Futurians were "Addicted to Feuds", that "No CIA nor KGB ever wrestled so valiantly for the soul of an emerging nation as New Fandom and the Futurians did for science fiction".
Most of the group's members also had professional ambitions within science fiction and related fields, and collectively were very effective at achieving this goal, as the roster of members suggests. At one point in the earliest 1940s, approximately half of all the pulp sf and fantasy magazines in the U.S. were being edited by Futurians: Frederik Pohl at the Popular Publications offshoot Fictioneers, Inc. ("Astonishing Stories" and "Super-Science Stories"); Robert Lowndes at Columbia Publications, most notably with "Science Fiction" and "Future Fiction" (though through the decade to come, Lowndes's responsibilities would expand to other types of fiction magazine in the chain), and Donald Wollheim at the very marginal Albing Publications with the short-lived, micro-budgeted "Cosmic Stories" and "Stirring Science Stories" (Wollheim soon moved on to Avon Books; Doë "Leslie Perri" Baumgardt also worked on a romance fiction title for Albing). Most of these projects had small editorial budgets, and relied in part, or occasionally entirely, on contributions from fellow Futurians for their contents.
Political tendencies.
At the time the Futurians were formed, Donald Wollheim was strongly attracted by communism and believed that followers of science fiction "should actively work for the realization of the scientific world-state as the only genuine justification for their activities and existence". It was to this end that Wollheim formed the Futurians, and many of its members were in some degree interested in the political applications of science fiction. Members of the Futurians, including Wollheim, Michel, Lowndes, and Cohen briefly became interested in Technocracy, a utopian movement led by Howard Scott, and attended a study course, although they later dismissed Scott as a "crackpot".
Hence the group included supporters of Trotskyism, like Judith Merril and others who would have been deemed far left for the era (Frederik Pohl became a member of the Communist Party in 1936, but later quit in 1939). On the other hand, several members were political moderates or apolitical, and in the case of James Blish arguably right-wing. Damon Knight in "The Futurians" indicates that Blish at that time felt Fascism was interesting in theory, if repellent as it was then being practised. More solid evidence is that Blish admired the work of Oswald Spengler.
Pohl, in his autobiography, "The Way the Future Was", said Wollheim voted for Republican Presidential Candidate Alfred Landon in 1936.

</doc>
<doc id="11532" url="https://en.wikipedia.org/wiki?curid=11532" title="First Fandom">
First Fandom

First Fandom is an informal association of early, active and well-known science fiction fans.
In 1958 a number of fans at Midwestcon realized amid table-talk that they all had been active in fandom for more than 20 years. This inspired the creation of an organization for longstanding fans under the initial chairmanship of Robert A. Madle. Originally only those fans who were known to have been active in fandom before the cutoff date, January 1, 1938, were eligible. Such fannish activity (or "fanac") including writing to letter columns in science fiction magazines, having been published in fanzines, or having participated in science fiction oriented clubs, or just generally doing fannish things.
The term itself is an oblique reference to Olaf Stapledon's classic science fiction epic "Last and First Men". In this book the stages of mankind are enumerated. Thus early 1950s historian of fandom Jack Speer began to label successive generations of fans as First Fandom, Second Fandom, Third Fandom, and so forth... all the way to Seventh Fandom and beyond.
Currently the organization allows several classes of membership. For example, a "Dinosaur" is a member who was active before the first Worldcon (World Science Fiction Convention) held on July 4, 1939, while "Associate Membership" requires provable activity in fandom for more than three decades.
First Fandom annually presents its Hall of Fame Award and Sam Moskowitz Archive Award for excellence in science fiction collecting. at the beginning of the Hugo Awards Ceremony at the World Science Fiction Convention.
There is an analogous informal society in Finnish fandom called the "Dinosaur Club"; the cutoff being the first major Finnish con Kingcon.
References.
1. Bob Madle's American Letter Nebula Science Fiction 1959.

</doc>
<doc id="11536" url="https://en.wikipedia.org/wiki?curid=11536" title="Fianna Fáil">
Fianna Fáil

Fianna Fáil , also known as Fianna Fáil, The Republican Party, is a centrist to centre-right and conservative political party in the Republic of Ireland. It was founded as an Irish republican party on 23 March 1926 after a split in Sinn Féin on the issue of abstentionism. Fianna Fáil's name is traditionally translated into English as "Soldiers of Destiny", although a more accurate rendition would be "Warriors of Fál" ("Fál" being a legendary name for Ireland). Historically, Fianna Fáil has been seen as to the left of Fine Gael and to the right of Sinn Féin and the Labour Party. It is generally seen as a "catch all" populist party, representing a broad range of people from all social classes. Fianna Fáil has led governments including parties of the centre-left (Labour and the Green Party) and of the centre-right (the now-defunct Progressive Democrats). It has been led by Micheál Martin since January 2011.
The party is also organised in Northern Ireland but has yet to contest an election there.
History.
Fianna Fáil was founded by Éamon de Valera when he and a number of other members split from Sinn Féin when his motion — which called for elected members be allowed to take their seats in Dáil Éireann if and when the controversial Oath of Allegiance was removed — failed to pass at the Sinn Féin Ard Fheis in 1926. The party adopted its name on 2 April of the same year. Though his new party, Fianna Fáil, was also opposed to the Treaty settlement, it adopted a different approach of aiming to make the Irish Free State a republic. The Fianna Fáil's platform of economic autarky had appeal among the farmers, working-class people and the poor, whilst alienating more affluent classes.
From the formation of the first Fianna Fáil government on 9 March 1932 until the election of 2011, the party was in power for 61 of 79 years. Its longest continuous period in office was 15 years and 11 months (March 1932–February 1948). Its single longest period out of office, in the 20th century, has been four years and four months (March 1973–July 1977). Seven of the party's eight leaders have served as Taoiseach.
Fianna Fáil joined the Alliance of Liberals and Democrats for Europe (ALDE) party on 16 April 2009, and the party's Members of the European Parliament (MEPs) sat in the ALDE Group during the 7th European Parliament term from June 2009 to 1 July 2014. The party is an observer affiliate of the Liberal International.
It was the largest party in the Dáil at every general election from the 1932 general election until the 2011 general election, when it suffered the worst defeat of a sitting government in the history of the Irish state. This loss was described as "historic" in its proportions, and "unthinkable". The party moved from being the largest party to the third-largest party in the Dáil.
Organisation and structure.
Fianna Fáil's success was credited by "The Irish Times" to its local structure. The basic unit was the "cumann" (branch) which were then grouped into "comhairle ceantair" (district branch) and a "comhairle dáil ceantair" (constituency branch) in every constituency. At the party's height, it had 3,000 cumainn, an average of 75 per constituency. The party claimed 55,000 members in 2004, a figure which Eoin O'Malley, a political scientist, considers exaggerated compared to membership figures for other parties.
However, since the early 1990s the cumann structure was weakened. As every cumann was entitled to three votes to selection conventions irrespective of size, a large number of cumainn became in effect "paper cumainn" only used to ensure an aspiring or sitting candidate got enough votes. Another problem arose with the emergence of parallel organisations grouped around candidates or elected officials. Supporters and election workers for a particular candidate were loyal to a candidate and not to the party. If the candidate was to leave the party, through either resignation, retirement or defeat at election, the candidate's supporters would often depart. Although this phenomenon was nothing new, (the most famous example being Neil Blaney's "Donegal Mafia") it increased significantly from the early 1990s particularly in the Dublin Region with former Taoiseach Bertie Ahern's "Drumcondra mafia" and the separate groups supporting Tom Kitt and Séamus Brennan in Dublin South largely separate from the official party structure.
Since the 2007 election, the party's structure has significantly weakened. This was in part exacerbated by significant infighting between candidates in the run up to the 2011 general election. The Irish Times estimated that half of its 3,000 cumainn are effectively moribund. This fraction rises in Dublin with the exception of Dublin West, the former seat of both Brian Lenihan, Snr and Brian Lenihan, Jnr.
Ideology.
Fianna Fáil is seen as a typical catch-all party. R. Ken Carty wrote of Fianna Fáil and Fine Gael that they were 'heterogeneous in their bases of support, relatively undifferentiated in terms of policy or programme, and remarkably stable in their support levels'. Evidence from expert surveys, opinion polls and candidate surveys all fail to identify strong distinctions between the two largest parties, Fianna Fáil and Fine Gael. Many point to Ireland's civil war politics and feel that the basis for the division is the disagreement about the strategy to achieve a united Ireland. Kevin Byrne and political scientist Eoin O'Malley rejected this and have argued that the differences between the two parties goes much further back in Irish history. They linked the parties to different nationalist traditions (Irish Enlightenment and Gaelic Nationalist) which in turn could be linked to migrations of Anglo-Norman and new English into Ireland and the 'native' Gaelic population.
The party's name and logo incorporates the words 'The Republican Party'. According to Fianna Fáil, "Republican here stands both for the unity of the island and a commitment to the historic principles of European republican philosophy, namely liberty, equality and fraternity."
Leadership and president.
Although the posts of leader and party president of Fianna Fáil are separate, with the former elected by the Parliamentary Party and the latter elected by the Ardfheis (thus allowing for the posts to be held by different people, in theory), in practice they have always been held by the one person. However, as the Ardfheis may have already been held in any given year by the time a new leader is elected, the selection of the new party president might not take place until the next year.
The following are the terms of office as party leader and as Taoiseach:
Ógra Fianna Fáil.
Fianna Fáil's youth wing is called Ógra Fianna Fáil. Formed in 1975, it plays an active role in recruiting new members and supporting election campaigns. Ógra also plays an important role in the party organisation where it has five representatives on the Ard Chomhairle (National Executive).
Senator Thomas Byrne was the last nominated head or Cathaoirleach (Chairperson) of Ógra Fianna Fáil, before the youth wing introduced widespread oganisational reform following the heavy electoral defeat suffered by the whole party in 2011.
Fianna Fáil and Northern Ireland politics.
On 17 September 2007 Fianna Fáil announced that the party would, for the first time, organise in Northern Ireland.
The then Foreign Minister Dermot Ahern was asked to chair a committee on the matter: "In the period ahead Dermot Ahern will lead efforts to develop that strategy for carrying through this policy, examining timescales and structures. We will act gradually and strategically. We are under no illusions. It will not be easy. It will challenge us all. But I am confident we will succeed."
The party embarked on its first ever recruitment drive north of the border in September 2007 in northern universities, and established two 'Political Societies', the William Drennan Cumann in Queens University, Belfast, and the Watty Graham Cumann in UU Magee, Derry, which subsequently became official units of Fianna Fáil's youth wing, attaining full membership and voting rights, and attained official voting delegates at the 2012 Árd Fheis.
Bertie Ahern announced on 7 December 2007 that Fianna Fáil had been registered in Northern Ireland by the UK Electoral Commission.
The Party's Ard Fheis in 2009 unanimously passed a motion to organise in Northern Ireland by establishing forums, rather than cumainn, in each of the North's six counties. In December 2009, Fianna Fáil secured its first Northern Assembly MLA when Gerry McHugh, an independent MLA, announced he had joined the party. Mr. McHugh confirmed that although he had joined the party, he would continue to sit as an independent MLA. In June 2010, Fianna Fáil opened its first official office in the North in Crossmaglen, County Armagh. The then Taoiseach Brian Cowen officially opened the office, accompanied by Ministers Éamon Ó Cuív and Dermot Ahern and Deputies Rory O’Hanlon and Margaret Conlon. Discussing the party's slow development towards all-Ireland politics, Mr. Cowen observed: "We have a very open and pragmatic approach. We are a constitutional republican party and we make no secret of the aspirations on which this party was founded. It has always been very clear in our mind what it is we are seeking to achieve, that is to reconcile this country and not being prisoners of our past history. To be part of a generation that will build a new Ireland, an Ireland of which we can all be proud.".
There has been speculation about an eventual merger with the Social Democratic and Labour Party (SDLP), formerly the main Irish nationalist party in the Northern Ireland, but now smaller than Sinn Féin. This has been met with a negative reaction with former Deputy Leader of the SDLP, Seamus Mallon, stating he would be opposed to any such merger. The former leader of the SDLP, Margaret Ritchie, has also stated publicly that she opposes any merger famously announcing to the Labour Party Conference that such a merger would not happen on her "watch". At the 2010 Irish Labour Party conference she further criticised Fianna Fáil's record in government and also the National Asset Management Agency On 23 February 2008, it was announced that a former UUP councillor, Colonel Harvey Bicker, had joined Fianna Fáil.
Fianna Fáil has registered with the UK Electoral Commission and is a recognised party in Northern Ireland. However, it has not contested any elections in Northern Ireland. At the party's 2014 Ard Fheis, a motion was passed without debate to stand candidates for election north of the border for the first time in 2019.
On 13 November 2015 Ógra Fianna Fáil held their first National Youth Conference in Newry in Northern Ireland.
In European institutions.
In the European Parliament from 1999 to 2009, Fianna Fáil was a leading member of Union for Europe of the Nations (UEN), a small national-conservative and Eurosceptic parliamentary group. European political commentators had often noted substantive ideological differences between the party and its colleagues, whose strongly conservative stances had at times prompted domestic criticism of Fianna Fáil. Fianna Fáil MEPs had been an attached to the European Progressive Democrats (1973–1984), European Democratic Alliance (1984–1995), and Union for Europe (1995–1999) groups before the creation of UEN.
Party headquarters, over the objections of some MEPs, had made several attempts to sever the party's links to the European right, including an aborted 2004 agreement to join the European Liberal Democrat and Reform (ELDR) Party, with whom it already sat in the Council of Europe under the Alliance of Liberals and Democrats for Europe (ALDE) banner. On 27 February 2009, Taoiseach Brian Cowen announced that Fianna Fáil proposed to join the ELDR Party and intended to sit with them in the Alliance of Liberals and Democrats for Europe (ALDE) Group in the European Parliament after the 2009 European elections. The change was made official on 17 April 2009, when FF joined the ELDR Party.
In October 2009, it was reported that Fianna Fáil had irritated its new Liberal colleagues by failing to vote for the motion on press freedom in Italy (resulting in its defeat by a majority of one in the Parliament) and by trying to scupper their party colleagues' initiative for gay rights. In January 2010, a report by academic experts writing for the votewatch.eu site found that FF "do not seem to toe the political line" of the ALDE Group "when it comes to budget and civil liberties" issues.
In the 2014 European elections, Fianna Fáil received 22.3% of first-preference votes but only returned a single MEP, a reduction in representation of two MEPs from the previous term. This was due to a combination of the party's vote further dropping in Dublin and a two candidate strategy in the Midlands North West constituency, which backfired, resulting in sitting MEP Pat the Cope Gallagher losing his seat. On 23 June 2014, returning MEP Brian Crowley announced that he intended to sit with the European Conservatives and Reformists (ECR) rather than the ALDE group during the upcoming 8th term of the European parliament. The following day on 24 June 2014 Crowley had the Fianna Fáil party whip withdrawn.

</doc>
<doc id="11539" url="https://en.wikipedia.org/wiki?curid=11539" title="Fujiwara clan">
Fujiwara clan

, descending from the Nakatomi clan and through them Ame-no-Koyane-no-Mikoto, was a powerful family of regents in Japan.
The clan originated when the founder, Nakatomi no Kamatari (614–669), was rewarded by Emperor Tenji with the honorific "Fujiwara", which evolved as a surname for Kamatari and his descendants. In time, Fujiwara became known as a clan name.
The Fujiwara dominated the Japanese politics of Heian period (794–1185) through the monopoly of regent positions, "sesshō" and "kampaku". The family's primary strategy for central influence was through the marrying of Fujiwara daughters to emperors. Through this, the Fujiwara would gain influence over the next emperor who would, according to family tradition of that time, be raised in the household of his mother's side and owe loyalty to his grandfather.
As abdicated Emperors took over power by exercising "insei" (, cloistered rule) at the end of 11th century, then followed by the rise of warrior class, the Fujiwara gradually lost its control over mainstream politics.
Beyond the 12th century, they continued to monopolize the titles of sesshō and kampaku for much of the time until the system was abolished in the Meiji era. Though their influence declined, the clan remained close advisors to the succeeding Emperors.
Asuka/Nara period.
The Fujiwara clan's political influence was initiated during the Asuka period. Nakatomi no Kamatari, a member of the lower-nobility Nakatomi family led a coup against the Soga in 645 and initiated a series of sweeping government reforms that would be known as the Taika Reform. In 668 Emperor Tenji (reigned 668–671), bestowed the "kabane" on Kamatari. The surname passed to the descendants of Fujiwara no Fuhito (659–720), the second son and heir of Kamatari, who was prominent at the court of several emperors and empresses during the early Nara period. He made his daughter Miyako a concubine of Emperor Mommu. Her son, Prince Obito became Emperor Shōmu. Fuhito succeeded in making another of his daughters, Kōmyōshi, the empress consort of Emperor Shōmu. She was the first empress (like Empress Wu in China) consort of Japan who was not a daughter of the imperial family itself. Fuhito had four sons; and each of them became the progenitor of a cadet branch of the clan: 
Among them, the Hokke came to be considered as the leaders of the entire clan.
Heian period.
During the Heian period of Japanese history, the Hokke managed to establish a hereditary claim to the position of regent, either for an underage emperor ("sesshō") or for an adult one ("kampaku"). Some prominent Fujiwaras occupied these positions more than once, and for more than one emperor. Lesser members of the Fujiwara were court nobles, provincial governors and vice governors, members of the provincial aristocracy, and samurai. The Fujiwara was one of the four great families that dominated Japanese politics during the Heian Period (794–1185), and the most important of them at that time. The others were the Tachibana, the Taira and the Minamoto. The Fujiwara exercised tremendous power, especially during the period of regency governments in 10th and 11th centuries, having many emperors as practically puppet monarchs.
The Fujiwara dominated the government of Japan 794–1160. There is no clear starting point of their dominance. However, their domination of civil administration was lost by the establishment of the first shogunate (i.e., Kamakura shogunate) under Minamoto no Yoritomo in 1192.
Fujiwara princes initially served as highest ministers of the imperial Court ("kampaku") and regents ("sesshō") for underage monarchs. The Fujiwara were the proverbial "power behind the throne" for centuries. Apparently they never aspired to supplant the imperial dynasty. Instead, the clan's influence stemmed from its matrimonial alliances with the imperial family. Because consorts of crown princes, younger sons, and emperors were generally Fujiwara women, the male heads of the Fujiwara house were often the father-in-law, brother-in-law, uncle, or maternal grandfather of the emperor. The family reached the peak of its power under Fujiwara no Michinaga (966–1027), a longtime "kampaku" who was the grandfather of three emperors, the father of six empresses or imperial consorts, and the grandfather of seven additional imperial consorts; it is no exaggeration to say that it was Michinaga who ruled Japan during this period, not the titular Emperors.
Fujiwara regime in the Heian period.
The Fujiwara Regency was the main feature of government of the entire Heian era. Kyoto (Heian-kyō) was geopolitically a better seat of government; with good river access to the sea, it could be reached by land routes from the eastern provinces.
Just before the move to the Heian-kyō, the Emperor had abolished universal conscription in 8 and soon local, private militaries came into being. The Fujiwara, Taira, and Minamoto were among the most prominent families supported by the new military class.
In the ninth and tenth centuries, much authority was lost to the great families, who disregarded the Chinese-style land and tax systems imposed by the government in Kyoto. Stability came to Heian Japan, but, even though succession was ensured for the Imperial family through heredity, power again concentrated in the hands of one noble family, the Fujiwara.
Family administrations now became public institutions. As the most powerful family, the Fujiwara governed Japan and determined the general affairs of state, such as succession to the throne. Family and state affairs were thoroughly intermixed, a pattern followed among other families, monasteries, and even the imperial family.
As the Soga had taken control of the throne in the sixth century, the Fujiwara by the ninth century had intermarried with the imperial family, and one of their members was the first head of the Emperor's Private Office. Another Fujiwara became regent for his grandson, then a minor emperor, and yet another was appointed "kampaku" (regent for an adult emperor). Toward the end of the ninth century, several emperors tried, but failed, to check the Fujiwara. For a time, however, during the reign of Emperor Daigo (897–930), the Fujiwara regency was suspended as he ruled directly.
Nevertheless, the Fujiwara were not demoted by Emperor Daigo but actually became stronger during his reign. Central control of Japan had continued to decline, and the Fujiwara, along with other great families and religious foundations, acquired ever larger "shōen" and greater wealth during the early tenth century. By the early Heian period, the "shōen" had obtained legal status, and the large religious establishments sought clear titles in perpetuity, waiver of taxes, and immunity from government inspection of the "shōen" they held. Those people who worked the land found it advantageous to transfer title to shōen holders in return for a share of the harvest. People and lands were increasingly beyond central control and taxation, a de facto return to conditions before the Taika Reform.
Within decades of Emperor Daigo's death, the Fujiwara had absolute control over the court. By the year 1000, Fujiwara no Michinaga was able to enthrone and dethrone emperors at will. Little authority was left for traditional officialdom, and government affairs were handled through the Fujiwara family's private administration. The Fujiwara had become what historian George B. Sansom has called "hereditary dictators."
The Fujiwara presided over a period of cultural and artistic flowering at the imperial court and among the aristocracy. There was great interest in graceful poetry and vernacular literature. Japanese writing had long depended on Chinese ideograms ("kanji"), but these were now supplemented by "kana", two types of phonetic Japanese script: "katakana", a mnemonic device using parts of Chinese ideograms; and "hiragana", a cursive form of "kanji" writing and an art form in itself. "Hiragana" gave written expression to the spoken word and, with it, to the rise in Japan's famous vernacular literature, much of it written by court women who had not been trained in Chinese as had their male counterparts. Three late tenth century and early eleventh century women presented their views of life and romance at the Heian court in "Kagerō Nikki" ("The Gossamer Years") by "the mother of Michitsuna", "Makura no Sōshi" ("The Pillow Book") by Sei Shōnagon, and "Genji Monogatari" ("Tale of Genji") by Murasaki Shikibu (herself a Fujiwara). Indigenous art also flourished under the Fujiwara after centuries of imitating Chinese forms. Vividly colored "yamato-e" (Japanese style) paintings of court life and stories about temples and shrines became common in the mid and late Heian periods, setting patterns for Japanese art to this day.
Decline in food production, growth of the population, and competition for resources among the great families all led to the gradual decline of Fujiwara power and gave rise to military disturbances in the mid-tenth and eleventh centuries. Members of the Fujiwara, Taira, and Minamoto families—all of whom had descended from the imperial family—attacked one another, claimed control over vast tracts of conquered land, set up rival regimes, and generally broke the peace of Japan.
The Fujiwara controlled the throne until the reign of Emperor Go-Sanjō (1068–73), the first emperor not born of a Fujiwara mother since the ninth century. Emperor Go-Sanjō, determined to restore imperial control through strong personal rule, implemented reforms to curb Fujiwara influence. He also established an office to compile and validate estate records with the aim of reasserting central control. Many "shōen" were not properly certified, and large landholders, like the Fujiwara, felt threatened with the loss of their lands. Emperor Go-Sanjō also established the "In no chō", or Office of the Cloistered Emperor, which was held by a succession of emperors who abdicated to devote themselves to behind-the-scenes governance, or "insei" (Cloistered rule).
The "In no chō" filled the void left by the decline of Fujiwara power. Rather than being banished, the Fujiwara were mostly retained in their old positions of civil dictator and minister of the center while being bypassed in decision making. In time, many of the Fujiwara were replaced, mostly by members of the rising Minamoto family. While the Fujiwara fell into disputes among themselves and formed northern and southern factions, the insei system allowed the paternal line of the imperial family to gain influence over the throne. The period from 1086 to 1156 was the age of supremacy of the "In no chō" and of the rise of the military class throughout the country. Military might rather than civil authority dominated the government.
A struggle for succession in the mid-twelfth century gave the Fujiwara an opportunity to regain their former power. Fujiwara no Yorinaga sided with the retired emperor in a violent battle in 1158 against the heir apparent, who was supported by the Taira and Minamoto. In the end, the Fujiwara were destroyed, the old system of government supplanted, and the "insei" system left powerless as bushi took control of court affairs, marking a turning point in Japanese history. Within a year, the Taira and Minamoto clashed, and a twenty-year period of Taira ascendancy began. The Taira were seduced by court life and ignored problems in the provinces. Finally, Minamoto Yoritomo (1147–1199) rose from his headquarters at Kamakura (in the Kantō region, southwest of modern Tokyo) to defeat the Taira, and with them the child emperor Emperor Antoku they controlled, in the Genpei War (1180–1185).
After this downfall, the younger branches of the Fujiwara clan turned their focus from politics to the arts, producing any number of literary luminaries like Fujiwara no Shunzei or Fujiwara no Teika.
Descent.
Only forty years after Michinaga's death, his Fujiwara heirs were not able to prevent the ascension of Emperor Go-Sanjō (reigned 1068–1073), the first emperor since Emperor Uda whose mother was not a Fujiwara. The system of government by retired emperor ("daijō tennō") (cloistered rule) beginning from 1087 further weakened the Fujiwara's control over the Imperial Court.
The Fujiwara-dominated Heian period approached its end along disturbances of 12th century. The dynastic struggle known as the Hōgen Disturbance ("Hōgen no Ran") led to the Taira emerging as the most powerful clan in 1156. During the Heiji Disturbance ("Heiji no Ran") in 1160 the Taira defeated the coalition of Fujiwara and Minamoto forces. This defeat marked the end of the Fujiwara's dominance.
Fission.
During the 13th century, the Fujiwara northern house ("Hokke") was split into the five regent houses: Konoe, Takatsukasa, Kujō, Nijō and Ichijō. They had a "monopoly" to the offices of "sesshō" and "kampaku", and served in turn. The political power had shifted away from the court nobility in Kyoto to the new warrior class in the countryside. However, Fujiwara princes remained close advisors, regents and ministers to the emperors for centuries, even until the 20th century (Prince Konoe and Morihiro Hosokawa). As such, they had a certain political power and much influence, as often the rival warriors and later bakufu sought their alliance. Oda Nobunaga and his sister Oichi were descended from the Taira and Fujiwara clans; regent Toyotomi Hideyoshi and shogun Tokugawa Ieyasu were related by marriage to the Fujiwara clan. Empress Shōken, wife of Emperor Meiji, was a descendant of the Fujiwara clan and, through Gracia Hosokawa, of the Minamoto clan.
Until the marriage of the Crown Prince Hirohito (Emperor Shōwa) to Princess Nagako of Kuni (posthumously Empress Kōjun) in January 1924, the principal consorts of emperors and crown princes had always been recruited from one of the Sekke Fujiwara. Imperial princesses were often married to Fujiwara lords – throughout a millennium at least. As recently as Emperor Shōwa's third daughter, the late former Princess Takanomiya (Kazoku), and Prince Mikasa's elder daughter, the former Princess Yasuko, married into Takatsukasa and Konoe families, respectively. Likewise a daughter of the last Tokugawa Shogun married a second cousin of Emperor Shōwa.

</doc>
<doc id="11542" url="https://en.wikipedia.org/wiki?curid=11542" title="Federalism">
Federalism

Federalism is a political concept describing the practice whereby a "group" of members are bound together by agreement or covenant (Latin: "foedus", covenant) with a governing representative head. It refers to a system of government in which sovereignty is constitutionally shared between a central governing authority and constituent political units (such as states or provinces). Leading examples of such a political system, or federation, include Switzerland, Germany, the United States, Canada, Australia and India. Federalism is a system based upon democratic rules and institutions in which the power to govern is shared between national and provincial/state governments. The term "federalist" describes several political beliefs around the world depending on context.
European vs. American Federalism.
In Europe, "Federalist" is sometimes used to describe those who favor a common federal government, with distributed power at regional, national and supranational levels. Most European federalists want this development to continue within the European Union. European federalism originated in post-war Europe; one of the more important initiatives was Winston Churchill's speech in Zürich in 1946.
In the United States, federalism originally referred to belief in a stronger central government. When the U.S. Constitution was being drafted, the Federalist Party supported a stronger central government, while "Anti-Federalists" wanted a weaker central government. This is very different from the modern usage of "federalism" in Europe and the United States. The distinction stems from the fact that "federalism" is situated in the middle of the political spectrum between a confederacy and a unitary state. The U.S. Constitution was written as a reaction to the Articles of Confederation, under which the United States was a loose confederation with a weak central government.
In contrast, Europe has a greater history of unitary states than North America, thus European "federalism" argues for a weaker central government, relative to a unitary state. The modern American usage of the word is much closer to the European sense. As the power of the Federal government has increased, some people have perceived a much more unitary state than they believe the Founding Fathers intended. Most people politically advocating "federalism" in the United States argue in favor of limiting the powers of the federal government, especially the judiciary (see Federalist Society, New Federalism).
In Canada, federalism typically implies opposition to sovereigntist movements (most commonly Quebec separatism).
The governments of Argentina, Australia, Brazil, India, and Mexico, among others, are also organized along federalist principles.
Federalism may encompass as few as two or three internal divisions, as is the case in Belgium or Bosnia and Herzegovina. In general, two extremes of federalism can be distinguished: at one extreme, the strong federal state is almost completely unitary, with few powers reserved for local governments; while at the other extreme, the national government may be a federal state in name only, being a confederation in actuality.
In 1999, the Government of Canada established the Forum of Federations as an international network for exchange of best practices among federal and federalizing countries. Headquartered in Ottawa, the Forum of Federations partner governments include Australia, Brazil, Canada, Ethiopia, Germany, India, Mexico, Nigeria, and Switzerland.
Some Christian denominations are organized on federalist principles; in these churches this is known as "ecclesiastic" or "theological federalism".
Examples of federalism.
Australia.
On the 1st of January 1901 the nation-state of Australia officially came into existence as a federation. The Australian continent was colonised by the United Kingdom in 1788, which subsequently established six, eventually self-governing, colonies there. In the 1890s the governments of these colonies all held referendums on becoming a unified, self-governing "Commonwealth" within the British Empire. When all the colonies voted in favour of federation, the Federation of Australia commenced, resulting in the establishment of the Commonwealth of Australia in 1901. The model of Australian federalism adheres closely to the original model of the United States of America, although it does so through a parliamentary Westminster system rather than a presidential system.
Brazil.
In Brazil, the fall of the monarchy in 1889 by a military "coup d'état" led to the rise of the presidential system, headed by Deodoro da Fonseca. Aided by well-known jurist Ruy Barbosa, Fonseca established federalism in Brazil by decree, but this system of government would be confirmed by every Brazilian constitution since 1891, although some of them would distort some of the federalist principles. The 1937 Constitution, for example, granted the federal government the authority to appoint State Governors (called interventors) at will, thus centralizing power in the hands of President Getúlio Vargas. Brazil also uses the Fonseca system to regulate interstate trade. Brazil is one of the biggest federal governments.
The Brazilian Constitution of 1988 introduced a new component to the ideas of federalism, including municipalities as federal entities. Brazilian municipalities are now invested with some of the traditional powers usually granted to states in federalism, and although they are not allowed to have a Constitution, they are structured by an organic law.
Canada.
In Canada, the system of federalism is described by the division of powers between the federal parliament and the country's provincial governments. Under the Constitution Act (previously known as the British North America Act) of 1867, specific powers of legislation are allotted. Section 91 of the constitution gives rise to federal authority for legislation, whereas section 92 gives rise to provincial powers.
For matters not directly dealt with in the constitution, the federal government retains residual powers; however, conflict between the two levels of government, relating to which level has legislative jurisdiction over various matters, has been a longstanding and evolving issue. Areas of contest include legislation with respect to regulation of the economy, taxation, and natural resources.
India.
The Government of India (referred to as the "Union Government") was established by the Constitution of India, and is the governing authority of a "federal union" of 29 states and 7 union territories.
The government of India is based on a tiered system, in which the Constitution of India delineates the subjects on which each tier of government has executive powers. The Constitution originally provided for a two-tier system of government, the Union Government (also known as the Central Government), representing the Union of India, and the State governments. Later, a third tier was added in the form of Panchayats and Municipalities. In the current arrangement, The Seventh Schedule of the Indian Constitution delimits the subjects of each level of governmental jurisdiction, dividing them into three lists:
Asymmetric federalism.
A distinguishing aspect of Indian federalism is that unlike many other forms of federalism, it is asymmetric. Article 370 makes special provisions for the state of Jammu and Kashmir as per its Instrument of Accession. Article 371 makes special provisions for the states of Andhra Pradesh, Arunachal Pradesh, Assam, Goa, Mizoram, Manipur, Nagaland and Sikkim as per their accession or state-hood deals. Also one more aspect of Indian federalism is system of President's Rule in which the central government (through its appointed Governor) takes control of state's administration for certain months when no party can form a government in the state or there is violent disturbance in the state.
Coalition politics.
Although the Constitution does not say so, India is now a multilingual federation. India has a multi-party system,with political allegiances frequently based on linguistic, regional and caste identities, necessitating coalition politics, especially at the Union level.
South Africa.
By the definition of most political scientists, South Africa counts as a federal state in practice.
Federalism in Europe.
Several federal systems exist in Europe, such as in Switzerland, Austria, Germany, Belgium, Bosnia and Herzegovina and the European Union.
Germany and the EU present the only examples of federalism (or advanced confederalism) in the world where
Modern Germany abandoned federalism only during Nazism (1933–1945) and in the DDR ("German Democratic Republic" a.k.a. East Germany) from 1952 to 1990. Adolf Hitler viewed federalism as an obstacle to his goals. As he wrote in "Mein Kampf", "National Socialism must claim the right to impose its principles on the whole German nation, without regard to what were hitherto the confines of federal states."
Accordingly, the idea of a strong, centralized government has very negative associations in German politics, although the Progressive political movements in Germany (Liberals, Social Democrats) were advocating at the time of the Second German Empire (1871-1918) to abolish (or to reshape) the majority of German federated states of that era, as they were considered to be mostly monarchist remnances of the feudal structures of the Middle Ages.
In Britain, an Imperial Federation was once seen as ("inter alia") a method of solving the Home Rule problem in Ireland; federalism has long been proposed as a solution to the "Irish Problem", and more lately, to the "West Lothian question".
French Revolution.
During the French Revolution, especially in 1793, "federalism" had an entirely different meaning. It was a political movement to weaken the central government in Paris by devolving power to the provinces.
European Union.
Following the end of World War II, several movements began advocating a European federation, such as the Union of European Federalists or the European Movement, founded in 1948. Those organizations exercised influence in the European unification process, but never in a decisive way. In 2011 also a European political party calling for the creation of a federal Europe was established, the European Federalist Party. Hard for political parties to agree.
Although the drafts of both the Maastricht treaty and the Treaty establishing a Constitution for Europe mentioned federalism, the representatives of the member countries (all of whom would have to agree to the term) never adopted it. The strongest advocates of European federalism have been Germany, Italy, Belgium and Luxembourg while those historically most strongly opposed have been the United Kingdom, Denmark and France (with conservative presidents and governments). Since the presidency of François Mitterrand (1981-1995), the French authorities have adopted a much more pro-European Unification position, as they consider that a strong EU is presenting the best "insurance" against a unified Germany which might become too strong and thus a threat for its neighbours.
Russian Federation.
The post-Imperial nature of Russian subdivision of government changed towards a generally autonomous model which began with the establishment of the USSR (of which Russia was governed as part). It was liberalized in the aftermath of the Soviet Union, with the reforms under Boris Yeltsin preserving much of the Soviet structure while applying increasingly liberal reforms to the governance of the constituent republics and subjects (while also coming into conflict with Chechen secessionist rebels during the Chechen War). Some of the reforms under Yeltsin were scaled back by Vladimir Putin.
All of Russia's subdivisional entities are known as subjects, with some smaller entities, such as the republics enjoying more autonomy than other subjects on account of having an extant presence of a culturally non-Russian ethnic minority or, in some cases, majority.
United States.
Federalism in the United States is the evolving relationship between state governments and the federal government of the United States. American government has evolved from a system of dual federalism to one of associative federalism. In "Federalist No. 46," James Madison asserted that the states and national government "are in fact but different agents and trustees of the people, constituted with different powers." Alexander Hamilton, writing in "Federalist No. 28," suggested that both levels of government would exercise authority to the citizens' benefit: "If their he peoples rights are invaded by either, they can make use of the other as the instrument of redress." (1)
Because the states were preexisting political entities, the U.S. Constitution did not need to define or explain federalism in any one section but it often mentions the rights and responsibilities of state governments and state officials in relation to the federal government. The federal government has certain "express powers" (also called "enumerated powers") which are powers spelled out in the Constitution, including the right to levy taxes, declare war, and regulate interstate and foreign commerce. In addition, the "Necessary and Proper Clause" gives the federal government the "implied power" to pass any law "necessary and proper" for the execution of its express powers. Other powers—the "reserved powers"—are reserved to the people or the states. The power delegated to the federal government was significantly expanded by the Supreme Court decision in McCulloch v. Maryland (1819), amendments to the Constitution following the Civil War, and by some later amendments—as well as the overall claim of the Civil War, that the states were legally subject to the final dictates of the federal government.
The Federalist Party of the United States was opposed by the Democratic-Republicans, including powerful figures such as Thomas Jefferson. The Democratic-Republicans mainly believed that: the Legislature had too much power (mainly because of the Necessary and Proper Clause) and that they were unchecked; the Executive had too much power, and that there was no check on the executive; a dictator would arise; and that a bill of rights should be coupled with the constitution to prevent a dictator (then believed to eventually be the president) from exploiting or tyrannizing citizens. The federalists, on the other hand, argued that it was impossible to list all the rights, and those that were not listed could be easily overlooked because they were not in the official bill of rights. Rather, rights in specific cases were to be decided by the judicial system of courts.
After the American Civil War, the federal government increased greatly in influence on everyday life and in size relative to the state governments. Reasons included the need to regulate businesses and industries that span state borders, attempts to secure civil rights, and the provision of social services. The federal government acquired no substantial new powers until the acceptance by the Supreme Court of the Sherman Anti-Trust Act.
From 1938 until 1995, the U.S. Supreme Court did not invalidate any federal statute as exceeding Congress' power under the Commerce Clause. Most actions by the federal government can find some legal support among the express powers, such as the Commerce Clause, whose applicability has been narrowed by the Supreme Court in recent years. In 1995 the Supreme Court rejected the Gun-Free School Zones Act in the Lopez decision, and also rejected the civil remedy portion of the Violence Against Women Act of 1994 in the "United States v. Morrison" decision. Recently, the Commerce Clause was interpreted to include marijuana laws in the "Gonzales v. Raich" decision.
Dual federalism holds that the federal government and the state governments are co-equals, each sovereign.
However, since the Civil War Era, the national courts often interpret the federal government as the final judge of its own powers under dual federalism. The establishment of Native American governments (which are separate and distinct from state and federal government) exercising limited powers of sovereignty, has given rise to the concept of "bi-federalism."
Venezuela.
The Federal War ended in 1863 with the signing of the Treaty of Coche by both the centralist government of the time and the Federal Forces. The United States of Venezuela were subsequently incorporated under a "Federation of Sovereign States" upon principles borrowed from the Articles of Confederation of the United States of America. In this Federation, each State had a "President" of its own that controlled almost every issue, even the creation of "State Armies," while the Federal Army was required to obtain presidential permission to enter any given state.
However, more than 140 years later, the original system has gradually evolved into a quasi-centralist form of government. While the 1999 Constitution still defines Venezuela as a Federal Republic, it abolished the Senate, transferred competences of the States to the Federal Government and granted the President of the Republic vast powers to intervene in the States and Municipalities.
Federalism with two components.
Belgium.
Federalism in the Kingdom of Belgium is an evolving system.
Belgian federalism is a twin system which reflects both the
On one hand, this means that the Belgian political landscape, generally speaking, consists of only two components: the Dutch-speaking population represented by Dutch-language political parties, and the majority populations of Wallonia and Brussels, represented by their French-speaking parties. The Brussels region emerges as a third component. This specific dual form of federalism, with the special position of Brussels, consequently has a number of political issues—even minor ones—that are being fought out over the Dutch/French-language political division. With such issues, a final decision is possible only in the form of a compromise. This tendency gives this dual federalism model a number of traits that generally are ascribed to confederalism, and makes the future of Belgian federalism contentious.
On the other hand, Belgian federalism is federated with three components. An affirmative resolution concerning Brussels' place in the federal system passed in the parliaments of Wallonia and Brussels. These resolutions passed against the desires of Dutch-speaking parties, who are generally in favour of a federal system with two components (i.e. the Dutch and French Communities of Belgium). However, the Flemish representatives in the Parliament of the Brussels Capital-Region voted in favour of the Brussels resolution, with the exception of one party. The chairman of the Walloon Parliament stated on July 17, 2008 that, "Brussels would take an attitude". Brussels' parliament passed the resolution on July 18, 2008:
This aspect of Belgian federalism helps to explain the difficulties of partition; Brussels, with its importance, is linked to both Wallonia and Flanders and vice versa. This situation, however, does not erase the traits of a confederation in the Belgian system.
Other examples.
Current examples of two-sided federalism:
Historical examples of two-sided federalism include:
Proposed federalism.
It has been proposed in several unitary states to establish a federal system, for various reasons.
China.
China is the largest unitary state in the world by both population and land area. Although China has had long periods of central rule for centuries, it is often argued that the unitary structure of the Chinese government is far too unwieldy to effectively and equitably manage the country's affairs. On the other hand, Chinese nationalists are suspicious of decentralization as a form of secessionism and a backdoor for national disunity; still others argue that the degree of autonomy given to provincial-level officials in the People's Republic of China amounts to a "de facto" federalism.
Libya.
Shortly after the 2011 Libyan civil war, some in the eastern region of the country (Cyrenaica) began to call for the new regime to be federal, with the traditional three regions of Libya (Cyrenaica, Tripolitania, and Fezzan) being the constituent units. A group calling itself the Cyrenaican Transitional Council issued a declaration of autonomy on 6 March 2012; this move was rejected by the National Transitional Council in Tripoli.
Philippines.
The Philippines is a unitary state with some powers devolved to Local Government Units (LGUs) under the terms of the Local Government Code. There is also one autonomous region, the Autonomous Region of Muslim Mindanao. Over the years various modifications have been proposed to the Constitution of the Philippines, including possible transition to a federal system as part of a shift to a parliamentary system. In 2004, Philippine President Gloria Macapagal Arroyo established the Consultative Commission which suggested such a Charter Change but no action was taken by the Philippine Congress to amend the 1987 Constitution.
Spain.
Spain is a unitary state with a relatively 'high' level of decentralisation (i.e., a regional state). Spain is not a Federation as main taxes are taken centrally from Madrid (except for Basque Country and Navarra) and then distributed to the Autonomous Communities. Federalism is accepted by parties, such as Podemos, United Left and, more recently, Spanish Socialist Workers' Party . The Spanish Socialist party -traditionally a guaranty of centralism in recent Spanish democratic era, as confirmed in the years of centralism developed during Felipe González's government- has recently considered the idea of building a Federal Spain, in part, due to the increase of the Spanish peripheral nationalisms and the Catalan proposal of self-determination referenda for creating a Catalan State in Catalonia, either independent or within Spain.
United Kingdom.
The United Kingdom has traditionally been governed as a unitary state by the Westminster Parliament in London. Instead of adopting a federal model, the UK has relied on gradual devolution to decentralise political power. Devolution in the UK began with the Government of Ireland Act 1914 which granted home rule to Ireland as a constituent country of the former United Kingdom of Great Britain and Ireland. Following the partition of Ireland in 1921 which saw the creation of the sovereign Irish Free State (which eventually evolved into the modern day Republic of Ireland), Northern Ireland retained its devolved government through the Parliament of Northern Ireland, the only part of the UK to have such a body at this time. This body was suspended in 1972 and Northern Ireland was governed by direct rule during the period of conflict known as The Troubles.
In modern times, a process of devolution in the United Kingdom has decentralised power once again. Since the 1997 referendums in Scotland and Wales and the Good Friday Agreement in Northern Ireland, three of the four constituent countries of the UK now have some level of autonomy. Government has been devolved to the Scottish Parliament, the National Assembly for Wales and the Northern Ireland Assembly. England does not have its own parliament and English affairs continue to be decided by the Westminster Parliament. In 1998 a set of eight unelected Regional assemblies, or chambers, was created to support the English Regional Development Agencies, but these were abolished between 2008 and 2010. The Regions of England continue to be used in certain governmental administrative functions.
Critics of devolution often cite the West Lothian Question, which refers to the voting power of non-English MPs on matters affecting only England in the UK Parliament. Scottish and Welsh nationalism have been increasing in popularity, and since the Scottish independence referendum, 2014 there has been a wider debate about the UK adopting a federal system with each of the four home nations having its own, equal devolved legislatures and law-making powers.
UK federal government was proposed as early as 1912 by the Member of Parliament for Dundee, Winston Churchill, in the context of the legislation for Irish Home Rule. In a speech in Dundee on 12 September, he proposed that England should also be governed by regional parliaments, with power devolved to areas such as Lancashire, Yorkshire, the Midlands and London as part of a federal system of government.
Federalism as the anarchist and libertarian socialist mode of political organization.
Anarchists are against the State but are not against political organization or "governance"—so long as it is self-governance utilizing direct democracy. The mode of political organization preferred by anarchists, in general, is federalism or confederalism. However, the anarchist definition of federalism tends to differ from the definition of federalism assumed by pro-state political scientists. The following is a brief description of federalism from section I.5 of "An Anarchist FAQ":
Christian Church.
Federalism also finds expression in ecclesiology (the doctrine of the church). For example, presbyterian church governance resembles parliamentary republicanism (a form of "political federalism") to a large extent. In Presbyterian denominations, the local church is ruled by elected elders, some of which are ministerial. Each church then sends representatives or commissioners to presbyteries and further to a general assembly. Each greater level of assembly has ruling authority over its constituent members. In this governmental structure, each component has some level of sovereignty over itself. As in "political federalism", in presbyterian ecclesiology there is shared sovereignty.
Other ecclesiologies also have significant representational and federalistic components, including the more anarchic congregational ecclesiology, and even in more hierarchical episcopal ecclesiology.
Some Christians argue that the earliest source of political federalism (or federalism in human institutions; in contrast to theological federalism) is the ecclesiastical federalism found in the Bible. They point to the structure of the early Christian Church as described (and prescribed, as believed by many) in the New Testament. In their arguments, this is particularly demonstrated in the Council of Jerusalem, described in Acts chapter 15, where the Apostles and elders gathered together to govern the Church; the Apostles being representatives of the universal Church, and elders being such for the local church. To this day, elements of federalism can be found in almost every Christian denomination, some more than others.
Constitutional structure.
Division of powers.
In a federation, the division of power between federal and regional governments is usually outlined in the constitution. Almost every country allows some degree of regional self-government, in federations the right to self-government of the component states is constitutionally entrenched. Component states often also possess their own constitutions which they may amend as they see fit, although in the event of conflict the federal constitution usually takes precedence.
In almost all federations the central government enjoys the powers of foreign policy and national defense as exclusive federal powers. Were this not the case a federation would not be a single sovereign state, per the UN definition. Notably, the states of Germany retain the right to act on their own behalf at an international level, a condition originally granted in exchange for the Kingdom of Bavaria's agreement to join the German Empire in 1871. Beyond this the precise division of power varies from one nation to another.
The constitutions of Germany and the United States provide that all powers not specifically granted to the federal government are retained by the states. The Constitution of some countries like Canada and India, on the other hand, state that powers not explicitly granted to the provincial governments are retained by the federal government. Much like the US system, the Australian Constitution allocates to the Federal government (the Commonwealth of Australia) the power to make laws about certain specified matters which were considered too difficult for the States to manage, so that the States retain all other areas of responsibility. Under the division of powers of the European Union in the Lisbon Treaty, powers which are not either exclusively of European competence or shared between EU and state as concurrent powers are retained by the constituent states.
Where every component state of a federation possesses the same powers, we are said to find 'symmetric federalism'. Asymmetric federalism exists where states are granted different powers, or some possess greater autonomy than others do. This is often done in recognition of the existence of a distinct culture in a particular region or regions. In Spain, the Basques and Catalans, as well as the Galicians, spearheaded a historic movement to have their national specificity recognized, crystallizing in the "historical communities" such as Navarre, Galicia, Catalonia, and the Basque Country. They have more powers than the later expanded arrangement for other Spanish regions, or the Spain of the autonomous communities (called also the "coffee for everyone" arrangement), partly to deal with their separate identity and to appease peripheral nationalist leanings, partly out of respect to specific rights they had held earlier in history. However, strictly speaking Spain is not a federalism, but a decentralized administrative organization of the state.
It is common that during the historical evolution of a federation there is a gradual movement of power from the component states to the centre, as the federal government acquires additional powers, sometimes to deal with unforeseen circumstances. The acquisition of new powers by a federal government may occur through formal constitutional amendment or simply through a broadening of the interpretation of a government's existing constitutional powers given by the courts.
Usually, a federation is formed at two levels: the central government and the regions (states, provinces, territories), and little to nothing is said about second or third level administrative political entities. Brazil is an exception, because the 1988 Constitution included the municipalities as autonomous political entities making the federation tripartite, encompassing the Union, the States, and the municipalities. Each state is divided into municipalities ("municípios") with their own legislative council ("câmara de vereadores") and a mayor ("prefeito"), which are partly autonomous from both Federal and State Government. Each municipality has a "little constitution", called "organic law" ("lei orgânica"). Mexico is an intermediate case, in that municipalities are granted full-autonomy by the federal constitution and their existence as autonomous entities ("municipio libre", "free municipality") is established by the federal government and cannot be revoked by the states' constitutions. Moreover, the federal constitution determines which powers and competencies belong exclusively to the municipalities and not to the constituent states. However, municipalities do not have an elected legislative assembly.
Federations often employ the paradox of being a union of states, while still being states (or having aspects of statehood) in themselves. For example, James Madison (author of the US Constitution) wrote in Federalist Paper No. 39 that the US Constitution "is in strictness neither a national nor a federal constitution; but a composition of both. In its foundation, it is federal, not national; in the sources from which the ordinary powers of the Government are drawn, it is partly federal, and partly national..." This stems from the fact that states in the US maintain all sovereignty that they do not yield to the federation by their own consent. This was reaffirmed by the Tenth Amendment to the United States Constitution, which reserves all powers and rights that are not delegated to the Federal Government as left to the States and to the people.
Bicameralism.
The structures of most federal governments incorporate mechanisms to protect the rights of component states. One method, known as 'intrastate federalism', is to directly represent the governments of component states in federal political institutions. Where a federation has a bicameral legislature the upper house is often used to represent the component states while the lower house represents the people of the nation as a whole. A federal upper house may be based on a special scheme of apportionment, as is the case in the senates of the United States and Australia, where each state is represented by an equal number of senators irrespective of the size of its population.
Alternatively, or in addition to this practice, the members of an upper house may be indirectly elected by the government or legislature of the component states, as occurred in the United States prior to 1913, or be actual members or delegates of the state governments, as, for example, is the case in the German Bundesrat and in the Council of the European Union. The lower house of a federal legislature is usually directly elected, with apportionment in proportion to population, although states may sometimes still be guaranteed a certain minimum number of seats.
Intergovernmental Relations.
In Canada, the provincial governments represent regional interests and negotiate directly with the central government. A First Ministers conference of the prime minister and the provincial premiers is the de facto highest political forum in the land, although it is not mentioned in the constitution.
Constitutional Change.
Federations often have special procedures for amendment of the federal constitution. As well as reflecting the federal structure of the state this may guarantee that the self-governing status of the component states cannot be abolished without their consent. An amendment to the constitution of the United States must be ratified by three-quarters of either the state legislatures, or of constitutional conventions specially elected in each of the states, before it can come into effect. In referendums to amend the constitutions of Australia and Switzerland it is required that a proposal be endorsed not just by an overall majority of the electorate in the nation as a whole, but also by separate majorities in each of a majority of the states or cantons. In Australia, this latter requirement is known as a "double majority".
Some federal constitutions also provide that certain constitutional amendments cannot occur without the unanimous consent of all states or of a particular state. The US constitution provides that no state may be deprived of equal representation in the senate without its consent. In Australia, if a proposed amendment will specifically impact one or more states, then it must be endorsed in the referendum held in each of those states. Any amendment to the Canadian constitution that would modify the role of the monarchy would require unanimous consent of the provinces. The German Basic Law provides that no amendment is admissible at all that would abolish the federal system.
Federalism as a political philosophy.
The meaning of "federalism", as a political movement, and of what constitutes a 'federalist', varies with country and historical context. Movements associated with the establishment or development of federations can exhibit either centralising or decentralising trends. For example, at the time those nations were being established, factions known as "federalists" in the United States and Australia advocated the formation of strong central government. Similarly, in European Union politics, federalists mostly seek greater EU integration. In contrast, in Spain and in post-war Germany, federal movements have sought decentralisation: the transfer of power from central authorities to local units. In Canada, where Quebec separatism has been a political force for several decades, the "federalist" impulse aims to keep Quebec inside Canada.
Federalism as a concept: history.
The "Oxford English Dictionary" first records the English word "federalism" as occurring in print in 1793 with reference to French politics,
though "anti-federalism" appears as early as 1788.

</doc>
<doc id="11543" url="https://en.wikipedia.org/wiki?curid=11543" title="Firmin Abauzit">
Firmin Abauzit

Firmin Abauzit (1679–1767) was a French scholar who worked on physics, theology and philosophy, and served as librarian in Geneva (Switzerland) during his final 40 years. Abauzit is also notable for proofreading or correcting the writings of Isaac Newton and other scholars.
Biography.
Firmin Abauzit was born of Huguenot parents November 11, 1679 at Uzès, in Languedoc. His father died when he was but two years of age; and when, on the revocation of the Edict of Nantes in 1685, the authorities took steps to have him educated in the Roman Catholic faith, his mother contrived his escape.
For two years his brother and he lived as fugitives in the mountains of the Cévennes, but they at last reached Geneva, where their mother afterwards joined them on escaping from the imprisonment in which she was held from the time of their flight. Abauzit at an early age acquired great proficiency in languages, physics, and theology.
In 1698, he traveled to Germany, then to Holland, where he became acquainted with Pierre Bayle, Pierre Jurieu and Jacques Basnage. Proceeding to England, he was introduced to Sir Isaac Newton, who found in him one of the earliest defenders, against Castel of his discoveries. Newton corrected in the second edition of his "Principia" an error pointed out by Abauzit, and, when sending him the "Commercium Epistolicum," said, "You are well worthy to judge between Gottfried Leibniz and me."
The reputation of Abauzit induced William III to request him to settle in England, but he did not accept the king's offer, preferring to return to Geneva. 
There, from 1715 he rendered valuable assistance to a society that had been formed for translating the New Testament into French. He declined the offer of the chair of philosophy at the University of Geneva in 1723. He assisted in the French language New Testament in 1726. In 1727, he was granted citizenship in Geneva, and he accepted the office of honorary librarian to Geneva, the city of his adoption. It was while he was in Geneva in his later years that he authored many of his works. Here also was the city of his death past the age of 87, on March 20, 1767.
Legacy.
Abauzit was a man of great learning and of wonderful versatility. Whatever chanced to be discussed, it used to be said of Abauzit that he seemed to have made it a subject of particular study. Rousseau, who was jealously sparing of his praises, addressed to him, in his "Julie, ou la nouvelle Héloïse", a fine panegyric; and when a stranger flatteringly told Voltaire he had come to see a great man, the philosopher asked him if he had seen Abauzit. Among his acquaintances, Abauzit claimed Rousseau, Voltaire, Newton, and Bayle.
Little remains of the labours of this intellectual giant, his heirs having, it is said, destroyed the papers that came into their possession, because their own religious opinions were different. A few theological, archaeological, and astronomical articles from his pen appeared in the "Journal Helvetique" and elsewhere, and he contributed several papers to Rousseau's "Dictionnaire de musique" (1767). He wrote a work throwing doubt on the canonical authority of the Apocalypse, which called forth a reply from Dr Leonard Twells, and was published in Denis Diderot's "Encyclopédie". He also edited and made valuable additions to Jacob Spon's "Histoire de la republique de Geneve". A collection of his writings was published at Geneva in 1770 ("Oeuvres de feu M. Abauzit"), and another at London in 1773 ("Oeuvres diverses de M. Abauzit").

</doc>
<doc id="11544" url="https://en.wikipedia.org/wiki?curid=11544" title="French Foreign Legion">
French Foreign Legion

The French Foreign Legion ( (), "L.É.") is a military service branch of the French Army established in 1831, unique because it was created for foreign nationals willing to serve in the French Armed Forces.
Commanded by French officers, it is also open to French citizens, who amounted to 24% of the recruits in 2007. The Foreign Legion is today known as a unit whose training focuses not only on traditional military skills but also on its strong "esprit de corps". As its men come from different countries with different cultures, this is a way to strengthen them enough to work as a team. Although it is part of the French Military, it is the only unit of the military that does not swear allegiance to France, but to the Foreign Legion itself. Consequently, training is often described as not only physically challenging, but also very stressful psychologically. A soldier who becomes injured during a battle for France can immediately apply for French citizenship under a provision known as "Français par le sang versé" ("French by spilled blood"). As of 2008, members come from 140 countries.
Since 1831, the Legion has suffered the loss of nearly 40,000 of its own men serving the ranks and France: Loyada, Tchad, Zaïre, Lebanon, Central Africa, Gabon, Kuwait, Rwanda, Djibouti, Ex-Yugoslavia, Somalia, Republic of Congo, Ivory Coast, Afghanistan, Mali, Sahel and others. 
The Foreign Legion was primarily used to protect and expand the French colonial empire during the 19th century. The Foreign Legion was initially stationed only in Algeria, where it took part in the pacification and development of the colony. Subsequently the French Foreign Legion (FFL) was deployed in a number of conflicts, including the First Carlist War in 1835, the Crimean War in 1854, the Second Italian War of Independence in 1859, the French intervention in Mexico in 1863, the Franco-Prussian War in 1870, the Tonkin Campaign and Sino–French War in 1883, supporting growth of the French colonial empire in Sub-Saharan Africa and pacifying Algeria, the Second Franco-Dahomean War in 1892, the Second Madagascar expedition in 1895, and the Mandingo Wars in 1894.
In World War I, the Foreign Legion fought in many critical battles on the Western Front. It played a smaller role in World War II than in World War I, though having a part in the Norwegian, Syrian and North African campaigns. During the First Indochina War (1946–54), the Foreign Legion saw its numbers swell. The FFL lost a large number of men in the catastrophic Battle of Dien Bien Phu. During the Algerian War of Independence (1954–62), the Foreign Legion came close to being disbanded after some officers, men, and the highly decorated 1st Foreign Parachute Regiment (1REP) took part in the Generals' putsch. Notable operations during this period included the Suez Crisis, the Battle of Algiers and various offensives launched by General Maurice Challe including Operations Oranie and Jumelles.
In the 1960s and 1970s, the Legion had a new role as a rapid deployment force to preserve French interests – not only in its former African colonies but in other nations as well; it also returned to its roots of being a unit always ready to be sent to hot-spots all around the world. Some notable operations include: the Chadian–Libyan conflict in 1969–72 (the first time that the Legion was sent in operations after the Algerian War), 1978–79, and 1983–87; Kolwezi in what is now the Democratic Republic of the Congo in May 1978; Rwanda in 1990–94; and the Ivory Coast in 2002 to the present. In 1990, the Foreign Legion were sent to the Persian Gulf as a part of Opération Daguet. In the 1990s, the Foreign Legion helped with the evacuation of French citizens and foreigners in Rwanda, Gabon and Zaire. The Foreign Legion was also deployed in Cambodia, Somalia, Sarajevo, Bosnia and Herzegovina. In the mid- to late-1990s, the Foreign Legion was deployed in the Central African Republic, Congo-Brazzaville and in Kosovo. In the 2000s, the Foreign Legion was deployed in Operation Enduring Freedom in Afghanistan, Operation Licorne in Ivory Coast, the EUFOR Tchad/RCA in Chad, and Operation Serval in the Northern Mali conflict.
Other nations have tried to emulate the French Foreign Legion model. There have been units composed of foreign recruits in China, Israel, the Dutch Koninklijk Nederlandsch-Indische Leger (KNIL), the Rhodesian Light Infantry of the 1960s and 1970s, and Russia and Spain.
History of the French Foreign Legion since 1831.
The French Foreign Legion was created by Louis Philippe, the King of the French, on 10 March 1831 from the foreign regiments of the Kingdom of France. Recruits included soldiers from the recently disbanded Swiss and German foreign regiments of the Bourbon monarchy. The Royal Ordinance for the establishment of the new regiment specified that the foreigners recruited could only serve outside France. The French expeditionary force that had occupied Algiers in 1830 was in need of reinforcements and the Legion was accordingly transferred by sea in detachments from Toulon to Algeria.
The Foreign Legion was primarily used, as part of the "Armée d'Afrique", to protect and expand the French colonial empire during the 19th century, but it also fought in almost all French wars including the Franco-Prussian War, World War I and World War II. The Foreign Legion has remained an important part of the French Army and sea transport protected by the French Navy, surviving three Republics, the Second French Empire, two World Wars, the rise and fall of mass conscript armies, the dismantling of the French colonial empire, and the loss of the Foreign Legion's base, Algeria.
Conquest of Algeria 1830–1847 ".
Created to fight "outside mainland France", the Foreign Legion was stationed in Algeria, where it took part in the pacification and development of the colony, notably by drying the marshes in the region of Algiers. The Foreign Legion was initially divided into six "national battalions" (Swiss, Poles, Germans, Italians, Spanish, and Dutch-Belgian). Smaller national groups, such as the ten Englishmen recorded in December 1832, appear to have been placed randomly.
In late 1831, the first legionnaires landed in Algeria, the country that would be the Foreign Legion's homeland for 130 years and shape its character. The early years in Algeria were hard on the legion because it was often sent to the worst postings and received the worst assignments, and its members were generally uninterested in the new colony of the French. The Legion served alongside the Battalions of Light Infantry of Africa, formed in 1832, which was a penal military unit made up of men with prison records who still had to do their military service or soldiers with serious disciplinary problems.
The Foreign Legion's first service in Algeria came to an end after only four years, as it was needed elsewhere.
Carlist War 1835–1839.
To support Isabella's claim to the Spanish throne against her uncle, the French government decided to send the Foreign Legion to Spain. On 28 June 1835, the unit was handed over to the Spanish government. The Foreign Legion landed via sea at Tarragona on 17 August with around 1,400 who were quickly dubbed "Los Algerinos" (the Algerians) by locals because of their previous posting.
The Foreign Legion's commander immediately dissolved the national battalions to improve the "esprit de corps". Later, he also created three squadrons of lancers and an artillery battery from the existing force to increase independence and flexibility. The Foreign Legion was dissolved on 8 December 1838, when it had dropped to only 500 men. The survivors returned to France, many reenlisting in the new Foreign Legion along with many of their former Carlist enemies.
Crimean War.
On 9 June 1854, the French ship "Jean Bart" embarked four battalions of the Foreign Legion for the Crimean Peninsula. A further battalion was stationed at Gallipoli as brigade depot. Eight companies drawn from both regiments of the Foreign Legion took part in the Battle of Alma (20 September 1854). Reinforcements by sea brought the Legion contingent up to brigade strength. As the "Foreign Brigade", it served in the Siege of Sevastopol, during the winter of 1854–1855.
The lack of equipment was particularly challenging and cholera hit the Allied expeditionary force. Nevertheless, the "leather bellies" (the nickname given to the legionnaires by the Russians because of the large cartridge pouches that they wore attached to their waist-belts), performed well. On 21 June 1855, the Third Battalion, left Corsica for the Crimea.
On 8 September the final assault was launched on Sevastopol. Two days later, the Second Foreign Regiment with flags and band playing ahead, marched through the streets of Sevastopol. Although initial reservations had been expressed about whether the Legion should be used outside Africa, the Crimean experience established its suitability for service in European warfare, as well as making a cohesive single entity of what had previously been two separate foreign regiments. Total Legion casualties in the Crimea were 1,703 killed and wounded.
Italian Campaign 1859.
Like the rest of the "Army of Africa", the Foreign Legion provided detachments in the campaign of Italy. Two foreign regiments, grouped with the 2nd Regiment of Zouaves, were part of the Second Brigade of the Second Division of Mac Mahon's Corps. The Foreign Legion acquitted itself particularly well against the Austrians at the battle of Magenta (4 June 1859) and at the Battle of Solferino (24 June). Legion losses were significant and the 2nd Foreign Regiment lost Colonel Chabrière, its commanding officer. In gratitude, the city of Milan awarded, in 1909, the "commemorative medal of deliverance", which still adorns the regimental flags of the Second Regiment.
Mexican Expedition 1863–1867.
The 38,000 strong French expeditionary force dispatched to Mexico via sea between 1862 and 1863 included two battalions of the Foreign Legion, increased to six battalions by 1866. Small cavalry and artillery units were raised from legionnaires serving in Mexico. The original intention was that Foreign Legion units should remain in Mexico for up to six years to provide a core for the Imperial Mexican Army. However the Legion was withdrawn with the other French forces during February–March 1867.
It was in Mexico on 30 April 1863 that the Legion earned its legendary status. A company led by Captain Jean Danjou, numbering 62 Legionnaires and 3 Legion officers, was escorting a convoy to the besieged city of Puebla when it was attacked and besieged by two thousand Mexican loyalists, organised in two battalions of infantry and cavalry, numbering 2,200 and 800 respectively. The Legion detachment under Captain Jean Danjou, Sous-Lieutenant , Sous-Lieutenant made a stand in the "Hacienda de la Trinidad" - a farm near the village of "Camarón". When only six survivors remained, out of ammunition, a bayonet assault was launched in which three of the six were killed. The remaining three wounded men were brought before the Mexican commander Colonel Milan, who allowed them to return to the French lines as an honor guard for the body of Captain Danjou. The captain had a wooden hand, which was later returned to the Legion and is now kept in a case in the Legion Museum at Aubagne, and paraded annually on Camerone Day. It is the Foreign Legion's most precious relic.
During the Mexican Campaign, 6,654 French died. Among these losses, 1,918 of the deaths were from a single regiment of the Legion, a fact that testifies to the importance of the Legion's role in the campaign.
Franco-Prussian War 1870.
According to French law, the Foreign Legion was not to be used within Metropolitan France except in the case of a national invasion, and was consequently not a part of Napoleon III's Imperial Army that capitulated at Sedan. With the defeat of the Imperial Army, the Second French Empire fell and the Third Republic was created.
The new Third Republic was desperately short of trained soldiers following Sedan, so the Foreign Legion was ordered to provide a contingent. On 11 October 1870 two provisional battalions disembarked via sea at Toulon, the first time the Foreign Legion had been deployed in France itself. It attempted to lift the Siege of Paris by breaking through the German lines. It succeeded in retaking Orléans, but failed to break the siege. In January 1871, France capitulated but civil war soon broke out, which led to revolution and the short-lived Paris Commune. The Foreign Legion participated in the suppression of the Commune, which was crushed with great bloodshed.
Tonkin Compaign and Sino-French War 1883–1888.
The Foreign Legion's First Battalion (Lieutenant-Colonel Donnier) sailed to Tonkin in the autumn of 1883, during the period of undeclared hostilities that preceded the Sino–French War (August 1884 to April 1885), and formed part of the attack column that stormed the western gate of Son Tay on 16 December. The Second and Third Infantry Battalions ("chef de bataillon" Diguet and Lieutenant-Colonel Schoeffer) were also deployed to Tonkin shortly afterwards, and were present in all the major campaigns of the Sino-French War. Two Foreign Legion companies led the defence at the celebrated Siege of Tuyên Quang (24 November 1884 to 3 March 1885). In January 1885 the Foreign Legion's 4th Battalion ("chef de bataillon" Vitalis) was deployed to the French bridgehead at Keelung (Jilong) in Formosa (Taiwan), where it took part in the later battles of the Keelung Campaign. The battalion played an important role in Colonel Jacques Duchesne's offensive in March 1885 that captured the key Chinese positions of La Table and Fort Bamboo and disengaged Keelung.
In December 1883, during a review of the Second Legion Battalion on the eve of its departure for Tonkin to take part in the Bắc Ninh Campaign, General François de Négrier pronounced a famous "mot": "Vous, légionnaires, vous êtes soldats pour mourir, et je vous envoie où l’on meurt!" ('You, Legionnaires, you are soldiers in order to die, and I'm sending you to where one dies!')
Colonisation of Africa.
As part of the Army of Africa, the Foreign Legion contributed to the growth of the French colonial empire in Sub-Saharan Africa. Simultaneously, the Legion took part to the pacification of Algeria, plagued by various tribal rebellions and razzias.
Second Franco-Dahomean War 1892–1894.
In 1892, King Behanzin was threatening the French protectorate of Porto-Novo in modern-day Benin and France decided to intervene. A battalion, led by commandant Faurax, was formed from two companies of the First Foreign Regiment and two others from the second regiment. From Cotonou, the legionnaires marched to seize Abomey, the capital of the Kingdom of Dahomey. Two and a half months were needed to reach the city, at the cost of repeated battles against the Dahomean warriors, especially the Amazons of the King. King Behanzin surrendered and was captured by the legionnaires in January 1894.
Second Madagascar Expedition 1894–1895.
In 1895, a battalion, formed by the First and Second Foreign Regiments, was sent to the Kingdom of Madagascar, as part of an expeditionary force whose mission was to conquer the island. The foreign battalion formed the backbone of the column launched on Antananarivo, the capital of Madagascar. After a few skirmishes, the Queen Ranavalona III promptly surrendered. The Foreign Legion lost 226 men, of whom only a tenth died in actual fighting. Others, like much of the expeditionary force, died from tropical diseases. Despite the success of the expedition, the quelling of sporadic rebellions would take another eight years until 1905, when the island was completely pacified by the French under Joseph Gallieni. During that time, insurrections against the Malagasy Christians of the island, missionaries and foreigners were particularly terrible. Queen Ranavalona III was deposed in January 1897 and was exiled to Algiers in Algeria, where she died in 1917.
Mandingo War 1898.
From 1882 until his capture, Samori Ture, ruler of the Wassoulou Empire, fought the French colonial army, defeating them on several occasions, including a notable victory at Woyowayanko (2 April 1882), in the face of French heavy artillery. Nonetheless, Samori was forced to sign several treaties ceding territory to the French between 1886 and 1889. Samori began a steady retreat, but the fall of other resistance armies, particularly Babemba Traoré at Sikasso, permitted the colonial army to launch a concentrated assault against his forces. A battalion of two companies from the 2nd Foreign Regiment was created in early 1894 to pacify the Niger. The Legionnaires' victory at the fortress of Ouilla and police patrols in the region accelerated the submission of the tribes. On 29 September 1898, Samori Ture was captured by the French Commandant Gouraud and exiled to Gabon, marking the end of the Wassoulou Empire.
World War I 1914–1918.
The annexation of Alsace and Lorraine by Germany in 1871 led to numerous volunteers from the two regions enlisting in the Foreign Legion, which gave them the option of French citizenship at the end of their service
With the declaration of war on 29 July 1914, a call was made for foreigners resident in France to support their adopted country. While many would have preferred direct enlistment in the regular French Army, the only option immediately available was that of the Foreign Legion. On one day only (3 August 1914) a reported 8,000 volunteers applied to enlist in the Paris recruiting office of the Legion.
In World War I and assuming sea protecting sail from Algeria, the Foreign Legion fought in many critical battles on the Western Front, including Artois, Champagne, Somme, Aisne, and Verdun (in 1917), and also suffered heavy casualties during 1918. The Foreign Legion was also in the Dardanelles and Macedonian front, and was highly decorated for its efforts. Many young foreigners volunteered for the Foreign Legion when the war broke out in 1914. There were marked differences between the idealistic volunteers of 1914 and the hardened men of the old Legion, making assimilation difficult. Nevertheless, the old and the new men of the Foreign Legion fought and died in vicious battles on the Western front, including Belloy-en-Santerre during the Battle of the Somme, where the poet Alan Seeger, after being mortally wounded by machine-gun fire, cheered on the rest of his advancing battalion.
Interwar Period 1918–1939.
While suffering heavy casualties on the Western Front the Legion had emerged from World War I with an enhanced reputation and as one of the most highly decorated units in the French Army . In 1919, the government of Spain raised the Spanish Foreign Legion and modeled it after the French Foreign Legion. General Jean Mordacq intended to rebuild the Foreign Legion as a larger military formation, doing away with the legion's traditional role as a solely infantry formation. General Mordacq envisioned a Foreign Legion consisting not of regiments, but of divisions with cavalry, engineer, and artillery regiments in addition to the legion's infantry mainstay. In 1920, decrees ordained the establishment of regiments of cavalry and artillery. Immediately following the armistice the Foreign Legion experienced an increase of enlistments. The Foreign Legion began the process of reorganizing and redeploying to Algeria.
The Legion played a major part in the Rif War of 1920–25.
In 1932, the Foreign Legion consisted of 30,000 men, serving in 6 multi-battalion regiments:
In 1931 General Paul-Frédéric Rollet was appointed Inspector General of the Legion. He took advantage of the centennial celebrations of the Legion's foundation to reintroduce a number of ceremonial traditions dating from the 19th century. He was subsequently credited with creating much of the modern mystique of the Legion.
World War II 1939–1945.
The Foreign Legion played a smaller role in World War II in mainland Europe than in World War I, though there was involvement in many exterior theatres of operations, notably sea transport protection through sea to the Norwegian, Syria-Lebanon, and North African campaigns. The 13th Demi-Brigade, formed for service in Norway, found itself in the UK at the time of the French Armistice (June 1940), was deployed to the British 8th Army in North Africa and distinguished itself in the Battle of Bir Hakeim (1942). Reflecting the divisions of the time, part of the Foreign Legion joined the Free French movement while another part served the Vichy government. German legionnaires were incorporated into the Wehrmacht's 90th Light Infantry Division in North Africa.
The Syria–Lebanon Campaign of June 1941 saw legionnaire fighting legionnaire as the 13th Demi-Brigade of the Foreign Legion (D.B.L.E.) clashed with the 6th Foreign Infantry Regiment at Damascus. Later, a thousand of the rank-and-file of the Vichy Legion unit joined the 13th D.B.L.E. of the Free French forces as a third battalion.
Alsace-Lorraine.
Following World War II, many French speaking German former soldiers joined the Foreign Legion to pursue a military career, an option no longer possible in Germany including French German soldiers of Malgré-nous. It would have been considered problematic if the men from Alsace-Lorraine didn't speak French. These French speaking former German soldiers made up as much as 60 percent of the Legion during the war in Indochina. Contrary to popular belief however, French policy was to exclude former members of the Waffen-SS, and candidates for induction were refused if they exhibited the tell-tale blood type tattoo, or even a scar that might be masking it.
The high percentage of Germans was contrary to normal policy concerning a single dominant nationality however, and in more recent times Germans have made up a much smaller percentage of the Foreign Legion's composition.
First Indochina War 1946–1954.
During the First Indochina War (1946–54) the Foreign Legion saw its numbers swell due to the incorporation of World War II veterans. Although the Foreign Legion distinguished itself in a territory where it had served since the 1880s, it also suffered a heavy toll during this war. Constantly being deployed in operations, units of the Legion suffered particularly heavy losses in the climatic Battle of Dien Bien Phu, before the fortified valley finally fell on May 7, 1954. During the eight year war, the Legion suffered the loss of 12,000 of its own men, almost 4 legionnnaires per day for 8 years. 
While only one of several Legion units involved in Indochina, the 1st Foreign Parachute Battalion (1e BEP) particularly distinguished itself, while being annihilated twice. It was renamed the 1st Foreign Parachute Regiment (1e REP) after its third reformation.
The 1e BEP sailed to Indochina on November 12 and was then engaged in combat operations in Tonkin. On November 17, 1950; the battalion parachuted into That Khé and suffered heavy losses at Coc Xa. Reconstituted on March 1, 1951 the battalion participated in combat operations at Cho Ben, on the Black River and in Annam. On November 21, 1953; the reconstituted 1e BEP was parachuted into the Dien Bien Phu. In this battle, the unit lost 575 killed and missing. Reconstituted for the third time on May 19, 1954, the battalion left Indochina on February 8, 1955. The 1e BEP received 5 citations and the fourragère of the colors of the Médaille militaire for its service in Indochina. The 1e BEP become the 1st Foreign Parachute Regiment (1e REP) in Algeria on September 1, 1955.
Dien Bien Phu fell on May 7, 1954 at 1730. The couple of hectares comprising the battlefield today are filled with corn fields centered by a stele which commemorates the sacrifices of those who died there. While the garrison of Dien Bien Phu included French regular, North African and locally recruited (indochinese) units, the battle has become associated particularly with the paratroops of the Foreign Legion.
Algerian War 1954–1962.
The Algerian War of Independence (1954–62) was a highly traumatic conflict for France. For the Legion, it ended with the enforced abandonment of the historic barracks and command center at Sidi Bel Abbès established in 1842 and suffering the loss of 2000 of its own men, from all ranks, on average 4 legionnaires per week for eight years. 
Para Foreign Legion.
Constantly on call throughout the country, the legion was heavily engaged in fighting against the National Liberation Front and the Armée de Libération Nationale (ALN). The main activity during the period 1954-62 were part of the tasked operations of the 10th Parachute Division and 25th Parachute Division. The 1st Foreign Parachute Regiment was part of the branch hierarchy and command of the 10th Parachute Division (France) and the 2nd Foreign Parachute Regiment was part of the branch hierarchy and command of the 25th Parachute Division (France). However, it's worth noting that while both the 1st Foreign Parachute Regiment (1e REP) and the 2nd Foreign Parachute Regiment (2e REP) were part of the operations of French Parachute Divisions (10th and 25th established in 1956); the Legion 1st Foreign Parachute Regiment (1e REP) and the Legion 2nd Foreign Parachute Regiment (2e REP) are older than the French divisions. The 1e REP was the former 3 time reconstituted 1st Foreign Parachute Battalion (1e BEP) and the 2e REP was the former 2nd Foreign Parachute Battalion (2e BEP); both battalions renamed with their Legionnaires transferred from Indochina on August 1, 1954 to Algeria by November 1, 1954 in a period of 4 months and both tracing their origins to the Parachute Company of the 3rd Foreign Infantry Regiment commanded by Legion Lieutenant Jacques Morin.
Also worth noting, with the start of the War in Algeria on November 1, 1954; the two foreign participating parachute battalions back from Indochina being the 1st Foreign Parachute Battalion (1e BEP, III Formation) and the 2nd Foreign Parachute Battalion (2e BEP) were not part of any French parachute divisions yet and were not designated as regiments either until respectively September and December 1, 1955.
Main operations during the Algerian War included the and the carried by 60,000 French and Foreign Legion Paratroopers. For paratroopers of the Legion, the 1st Foreign Parachute Regiment (1e REP) and 2nd Foreign Parachute Regiment (2e REP), were the only known foreign active parachute regiments, exclusively commanded by Pierre Paul Jeanpierre for the 1e REP and the paratrooper commanders of the 2e REP. The remainder of French paratooper units of the French Armed Forces were commanded by Jacques Massu, Buchond, Marcel Bigeard, Paul Aussaresses. In relation to the Legion, other offensives in the mountains in 1959 included operations, Jumelles, Cigales and Ariege in the Aures and last in Kabylie.
The reputation of the 1st Foreign Parachute Regiment was tarnished by the general's putsch of 1961.
Generals' Putsch 1961 and reduction of Foreign Legion.
Following the independence of Algeria in 1962, the Foreign Legion was reduced in numbers but not disbanded, unlike most other units comprising the "Armée d'Afrique": Zouaves, Tirailleurs, Méharistes, Harkis, Goums, Chasseurs d'Afrique and all but one of the Spahi regiments.
The Foreign Legion faced the possibility of disbandment after the highly decorated 1st Foreign Parachute Regiment (1e REP) was readied to take part in the General's Putsch. Upon being notified that this regiment was to be disbanded and that they were to be reassigned, legionnaires of the 1e REP burned the Chinese pavilion acquired following the Siege of Tuyên Quang in 1884. The relics from the Legion's history museum, including the wooden hand of Captain Jean Danjou, subsequently accompanied the Legion to France. Also removed from Sidi Bel Abbès were the symbolic Legion remains of General ( The Father of the Legion ), Legion officer Prince Count Aage of Rosenborg, and Legionnaire Heinz Zimmermann (the last fatal casualty in Algeria).
It was at this time that the Legion acquired its parade song "Non, je ne regrette rien" ("No, I don't regret anything"), a 1960 Edith Piaf song sung by Sous-Officiers and legionnaires as they left their barracks for re-deployment following the Algiers putsch of 1961. The song has remained a part of Legion heritage since.
The 1st Foreign Parachute Regiment was disbanded on April 30, 1961. However, the 2nd Foreign Parachute Regiment remained in existence.
The effect was to retain the Foreign Legion as a professional force that could be used for military interventions outside France and not involve the politically unpopular use of French conscripts. The subsequent abolition of conscription in France in 2001 and the creation of an entirely professional army might be expected to put the legion's long-term future at risk but this has not been the case.
Post-colonial Africa.
By the mid-1960s the Legion had lost its traditional and spiritual home in Algeria and elite units had been dissolved. President de Gaulle considered disbanding it altogether but after being downsized to 8,000 men and stripped of all heavy weaponry the Legion was relocated to metropolitan France. The Legion now had a new role as a rapid intervention force to preserve French interests.
Intervention actions in Africa following the Algerian War included the Chadian–Libyan conflict in 1969–72, 1978–79, and 1983–87; Kolwezi in what is now the Democratic Republic of the Congo in May 1978; Rwanda in 1990–94; and the Ivory Coast in 2002 to the present.
1962–present.
Gulf War 1990–1991.
In September 1990, the 1st Foreign Cavalry Regiment, the 2nd Foreign Parachute Regiment, the 2nd Foreign Infantry Regiment, and the 6th Foreign Engineer Regiment were sent to the Persian Gulf as a part of Opération Daguet. The Legion force, comprising 27 different nationalities, was attached to the French 6th Light Armoured Division, whose mission was to protect the Coalition's left flank. During the Gulf War, DINOPS operated in support of the U.S. Army's 82nd Airborne Division, and provided the EOD services to the division. After the cease fire took hold they conducted a joint mine clearing operation alongside an Royal Australian Navy Clearance Diver Team Unit.
After the four-week air campaign, coalition forces launched the ground offensive. They quickly penetrated deep into Iraq, with the Legion taking the Al Salman Airport, meeting little resistance. The war ended after a hundred hours of fighting on the ground, which resulted in very light casualties for the Legion.
Composition & organization.
Prior to the end of the Algerian War the legion had not been stationed in mainland France except in wartime. Until 1962, the Foreign Legion headquarters was located in Sidi Bel Abbès, Algeria. Today, some units of the Légion are in Corsica or overseas possessions (mainly in French Guiana, guarding Guiana Space Centre), while the rest are in the south of mainland France. Current headquarters is in Aubagne, France, just outside Marseille.
Current deployments.
These are the following deployments:
Note: English names for countries or territories are in parentheses.
Recruitment process.
Basic training.
The majority of officers in the Legion are seconded from the regular French Army and are referred to as Legion officers ("Officiers de Légion"). Adjudant-chefs, Adjudants, and a limited number of both French and non-French officers () are promoted from the ranks of the Legion.
Basic training for the Foreign Legion is conducted in the 4th Foreign Regiment. This is an operational combat regiment which provides a training course of 15 weeks, before recruits are assigned to their operational units:
Traditions.
As the Foreign Legion is composed of soldiers of different nationalities and backgrounds, it needed to develop an intense Esprit de Corps, which is carried out by the development of camaraderie, specific traditions, the high sense of loyalty of its legionnaires, the quality of their training and the pride of being a soldier of an élite unit.
Code of Honour.
The "Legionnaire's Code of Honour" is the crucible vocal synchronisation and identity of the Legion and sung in French only.
Art. 1 - Légionnaire, tu es un volontaire, servant la France avec honneur et fidélité.<br>
Art. 2 - Chaque légionnaire est ton frère d'armes, quelles que soient sa nationalité, sa race ou sa religion. Tu lui manifestes toujours la solidarité étroite qui doit unir les membres d'une même famille.<br>
Art. 3 - Respectueux des traditions, attaché à tes chefs, la discipline et la camaraderie sont ta force, le courage et la loyauté tes vertus.<br>
Art. 4 - Fier de ton état de légionnaire, tu le montres dans ta tenue toujours élégante, ton comportement toujours digne mais modeste, ton casernement toujours net.<br>
Art. 5 - Soldat d'élite, tu t'entraînes avec rigueur, tu entretiens ton arme comme ton bien le plus précieux, tu as le souci constant de ta forme physique.<br>
Art. 6 - La mission est sacrée, tu l'exécutes jusqu'au bout et si besoin, en opérations, au péril de ta vie.<br>
Art. 7 - Au combat, tu agis sans passion et sans haine, tu respectes les ennemis vaincus, tu n'abandonnes jamais ni tes morts, ni tes blessés, ni tes armes.
<br>
Mottos.
"Honneur et Fidélité".
In contrast to all other French Army units, the motto embroidered on the Foreign Legion's regimental flags is not "Honneur et Patrie" (Honour and Fatherland) but "Honneur et Fidélité" (Honour and Fidelity).
"Legio Patria Nostra".
"Legio Patria Nostra" ("The Legion is our Fatherland") is the Latin motto of the Foreign Legion. The adoption of the Foreign Legion as a new "fatherland" does not imply the repudiation by the legionnaire of his original nationality. The Foreign Legion is required to obtain the agreement of any legionnaire before he is placed in any situation where he might have to serve against his country of birth.
Marching songs.
"Le Boudin".
"Le Boudin" is the marching song of the Foreign Legion.
Ranks.
All volunteers in the French Foreign Legion begin their careers as basic legionnaires with one in four eventually becoming a "sous-officier" (non-commissioned officer). On joining, a new recruit receives a monthly salary of €1,200 in addition to food and lodgings. He is also given his own new rifle, which according to the lore of the "Legion" must never be left on a battlefield. Promotion is concurrent with the ranks in the French Army.
Table note: Command insignia in the Foreign Legion use gold lace or braid indicating foot troops in the French Army. But the "Légion étrangère" service color is green (for the now-defunct colonial "Armée d'Afrique") instead of red (regular infantry).
Non-Commissioned & Warrant Officers.
"Sous-officiers" (NCOs) including warrant officers account for 25% of the current Foreign Legion's total manpower.
Commissioned Officers.
Most officers are seconded from the French Army though roughly 10% are former non-commissioned officers promoted from the ranks.
Chevrons of seniority.
The Foreign Legion still uses chevrons to indicate seniority ("chevrons d'ancienneté"). Each gold chevron, which are only worn by ordinary legionnaires and non-commissioned officers, denotes five years service in the Legion. They are worn beneath the rank insignia.
Pioneers.
The "Pionniers" (pioneers) are the combat engineers and a traditional unit of the Foreign Legion. The sapper traditionally sport large beards, wear leather aprons and gloves and hold axes. The sappers were very common in European armies during the Napoleonic Era but progressively disappeared during the 19th century. The French Army, including the Legion disbanded its regimental sapper platoons in 1870. However, in 1931 one of a number of traditions restored to mark the hundredth anniversary of the Legion's founding was the reestablishment of its bearded "Pionniers".
In the French Army, since the 18th century, every infantry regiment included a small detachment of pioneers. In addition to undertaking road building and entrenchment work, such units were tasked with using their axes and shovels to clear obstacles under enemy fire opening the way for the rest of the infantry. The danger of such missions was recognised by allowing certain privileges, such as being authorised to wear beards.
The current pioneer platoon of the Foreign Legion is provided by the Legion depot and headquarters regiment for public ceremonies. The unit has reintroduced the symbols of the Napoleonic sappers: the beard, the axe, the leather apron, the crossed-axes insignia and the leather gloves. When parades of the Foreign Legion are opened by this unit, it is to commemorate the traditional role of the sappers "opening the way" for the troops.
Cadences and marching steps.
Also notable is the marching pace of the Foreign Legion. In comparison to the 116-step-per-minute pace of other French units, the Foreign Legion has an 88-step-per-minute marching speed. It is also referred to by Legionnaires as the "crawl". This can be seen at ceremonial parades and public displays attended by the Foreign Legion, particularly while parading in Paris on 14 July (Bastille Day Military Parade). Because of the impressively slow pace, the Foreign Legion is always the last unit marching in any parade. The Foreign Legion is normally accompanied by its own band, which traditionally plays the march of any one of the regiments comprising the Foreign Legion, except that of the unit actually on parade. The regimental song of each unit and "Le Boudin" is sung by legionnaires standing at attention. Also, because the Foreign Legion must always stay together, it does not break formation into two when approaching the presidential grandstand, as other French military units do, in order to preserve the unity of the legion.
Contrary to popular belief, the adoption of the Foreign Legion's slow marching speed was not due to a need to preserve energy and fluids during long marches under the hot Algerian sun. Its exact origins are somewhat unclear, but the official explanation is that although the pace regulation does not seem to have been instituted before 1945, it hails back to the slow marching pace of the Ancien Régime, and its reintroduction was a "return to traditional roots". This was in fact, the march step of the Foreign Legion's ancestor units – the "Régiments Étrangers" or Foreign Regiments of the "Ancien Régime" French Army, the "Grande Armée"s foreign units, and the pre-1831 foreign regiments.
Uniform.
From its foundation until World War I the Foreign Legion normally wore the uniform of the French line infantry for parade with a few special distinctions. Essentially this consisted of a dark blue coat (later tunic) worn with red trousers. The field uniform was often modified under the influence of the extremes of climate and terrain in which the Foreign Legion served. Shakos were soon replaced by the light cloth kepi, which was far more suitable for North African conditions. The practice of wearing heavy "capotes" (greatcoats) on the march and "vestes" (short hip-length jackets) as working dress in barracks was followed by the Foreign Legion from its establishment.
One short lived aberration was the wearing of green uniforms in 1856 by Foreign Legion units recruited in Switzerland for service in the Crimean War. In the Crimea itself (1854–59) a hooded coat and red or blue waist sashes were adopted for winter dress, while during the Mexican Intervention (1863–65) straw hats or sombreros were sometimes substituted for the kepi. When the latter was worn it was usually covered with a white "havelock" – the predecessor of the white kepi that was to become a symbol of the Foreign Legion. Foreign Legion units serving in France during the Franco-Prussian War of 1870–71 were distinguishable only by minor details of insignia from the bulk of the French infantry. However subsequent colonial campaigns saw an increasing use of special garments for hot weather wear such as collarless "keo" blouses in Tonkin 1884–85, khaki drill jackets in Dahomey (1892) and drab covered topees worn with all-white fatigue dress in Madagascar (1895).
In the early 20th century the legionnaire wore a red kepi with blue band and piping, dark blue tunic with red collar, red cuff patches, and red trousers. The most distinctive features were the green epaulettes (replacing the red of the line) worn with red woollen fringes; plus the embroidered Foreign Legion badge of a red flaming grenade, worn on the kepi front instead of a regimental number. In the field a light khaki cover was worn over the kepi, sometimes with a protective neck curtain attached. The standard medium-blue double breasted greatcoat ("capote") of the French infantry was worn, usually buttoned back to free the legs for marching. From the 1830s the legionnaires had worn a broad blue woollen sash around the waist, like other European units of the French Army of Africa (such as the Zouaves or the Chasseurs d'Afrique), while indigenous units of the Army of Africa (spahis and tirailleurs) wore red sashes. White linen trousers tucked into short leather leggings were substituted for red serge in hot weather. This was the origin of the "Beau Geste" image.
In barracks a white bleached kepi cover was often worn together with a short dark blue jacket ("veste") or white blouse plus white trousers. The original kepi cover was khaki and due to constant washing turned white quickly. The white or khaki kepi cover was not unique to the Foreign Legion at this stage but was commonly seen amongst other French units in North Africa. It later became particularly identified with the Foreign Legion as the unit most likely to serve at remote frontier posts (other than locally recruited tirailleurs who wore fezzes or turbans). The variances of climate in North Africa led the French Army to the sensible expedient of letting local commanders decide on the appropriate "tenue de jour" (uniform of the day) according to circumstances. Thus a legionnaire might parade or walk out in blue tunic and white trousers in hot weather, blue tunic and red trousers in normal temperatures or wear the blue greatcoat with red trousers under colder conditions. The sash could be worn with greatcoat, blouse or veste but not with the tunic. Epaulettes were a detachable dress item worn only with tunic or greatcoat for parade or off duty wear.
Officers wore the same dark blue (almost black) tunics as those of their colleagues in the French line regiments, except that black replaced red as a facing colour on collar and cuffs. Gold fringed epaulettes were worn for full dress and rank was shown by the number of gold rings on both kepi and cuffs. Trousers were red with black stripes or white according to occasion or conditions. All-white or light khaki uniforms (from as early as the 1890s) were often worn in the field or for ordinary duties in barracks. Non-commissioned officers were distinguished by red or gold diagonal stripes on the lower sleeves of tunics, vestes and greatcoats. Small detachable stripes were buttoned on to the front of the white shirt-like blouse.
Prior to 1914 units in Indo-China wore white or khaki Colonial Infantry uniforms with Foreign Legion insignia, to overcome supply difficulties. This dress included a white sun helmet of a model that was also worn by Foreign Legion units serving in the outposts of Southern Algeria, though never popular with its wearers. During the initial months of World War I, Foreign Legion units serving in France wore the standard blue greatcoat and red trousers of the French line infantry, distinguished only by collar patches of the same blue as the capote, instead of red. After a short period in sky-blue the Foreign Legion adopted khaki with steel helmets, from early 1916. A mustard shade of khaki drill had been worn on active service in Morocco from 1909, replacing the classic blue and white. The latter continued to be worn in the relatively peaceful conditions of Algeria throughout World War I, although increasingly replaced by khaki drill. The pre-1914 blue and red uniforms could still be occasionally seen as garrison dress in Algeria until stocks were used up about 1919.
During the early 1920s plain khaki drill uniforms of a standard pattern became universal issue for the Foreign Legion with only the red and blue kepi (with or without a cover) and green collar braiding to distinguish the Legionnaire from other French soldiers serving in North African and Indo-China. The neck curtain ceased to be worn from about 1915, although it survived in the newly raised Foreign Legion Cavalry Regiment into the 1920s. The white blouse ("bourgeron") and trousers dating from 1882 were retained for fatigue wear until the 1930s.
At the time of the Foreign Legion's centennial in 1931, a number of traditional features were reintroduced at the initiative of the then commander Colonel Rollet. These included the blue sash and green/red epaulettes. In 1939 the white covered kepi won recognition as the official headdress of the Foreign Legion to be worn on most occasions, rather than simply as a means of reflecting heat and protecting the blue and red material underneath. The Third Foreign Infantry Regiment adopted white tunics and trousers for walking-out dress during the 1930s and all Foreign Legion officers were required to obtain full dress uniforms in the pre-war colours of black and red from 1932 to 1939.
During World War II the Foreign Legion wore a wide range of uniform styles depending on supply sources. These ranged from the heavy capotes and Adrian helmets of 1940 through to British battledress and American field uniforms from 1943 to 1945. The white kepi was stubbornly retained whenever possible.
From 1940 until 1963 the Foreign Legion maintained four Saharan Companies ("Compagnies Sahariennes") as part of the French forces used to patrol and police the desert regions to the south of Morocco and Algeria. Special uniforms were developed for these units, modeled on those of the French officered Camel Corps ("Méharistes") having prime responsibility for the Sahara. In full dress these included black or white zouave style trousers, worn with white tunics and long flowing cloaks. The Legion companies maintained their separate identity by retaining their distinctive kepis, sashes and fringed epaulettes.
The white kepis, together with the sash and epaulettes survive in the Foreign Legion's modern parade dress. Since the 1990s the modern kepi has been made wholly of white material rather than simply worn with a white cover. Officers and senior noncommissioned officers still wear their kepis in the pre-1939 colours of dark blue and red. A green tie and (for officers) a green waistcoat recall the traditional branch colour of the Foreign Legion. From 1959 a green beret (previously worn only by the legion's paratroopers) became the universal ordinary duty headdress, with the kepi reserved for parade and off duty wear. Other items of currently worn dress are the standard issue of the French Army.
Equipment.
The Foreign Legion is basically equipped with the same equipment as similar units elsewhere in the French Army. These include:
Honorary ranks.
Since 1796 the French Army had awarded honorary ranks to individuals credited with exceptional acts of courage.
In the Foreign Legion, General Paul-Frédéric Rollet introduced the practice of awarding of honorary Legion ranks to distinguished individuals, both civilian and military; men and women. Recipients of these honorary appointments had participated in an exemplary manner on active service with units of the Legion, or had rendered exceptional service to the Legion in non-combat situations.
More than 1,200 individuals have received this distinction, being granted honorary ranks ranging from "Legionnaire d'Honneur" to "Sergent-Chef de Légion d'Honneur". The majority of these awards were made to military personnel in war time, but recipients have included nurses, journalists, painters, ministers and others who are considered to have earned recognition "pour services éminent" rendered to the Foreign Legion.
Membership.
The Foreign Legion is the only unit of the French Army open to people of any nationality. Most legionnaires still come from European countries but a growing percentage comes from Latin America. Most of the Foreign Legion's commissioned officers are French with approximately 10% being former Legionnaires who have risen through the ranks.
Legionnaires were, in the past, forced to enlist under a pseudonym ("declared identity"). This disposition exists in order to allow people who want to start their lives over to enlist, and the French Foreign Legion held the belief that it was more fair to make all new recruits use declared identities. French citizens can enlist under a declared, fictitious, foreign citizenship (generally, a francophone one, often that of Belgium, Canada or Switzerland). As of 20 September 2010, new recruits may enlist under their real identities or under declared identities. Recruits who do enlist with declared identities may, after one year's service, regularise their situations under their true identities. After serving in the Foreign Legion for three years, a legionnaire may apply for French citizenship. He must be serving under his real name, must no longer have problems with the authorities, and must have served with "honour and fidelity". Furthermore, a soldier who becomes injured during a battle for France can immediately apply for French citizenship under a provision known as "Français par le sang versé" ("French by spilled blood").
While the Foreign Legion historically did not accept women in its ranks, there was one official female member, Susan Travers, an Englishwoman who joined Free French Forces during World War II and became a member of the Foreign Legion after the war, serving in Vietnam during the First Indochina War. Women were barred from service until 2000, which then-French Defence Minister Alain Richard had stated that he wanted to take the level of female recruitment in the Legion to 20% by 2020. But at this time, no woman has been known to have joined the Legion.
Membership by country.
As of 2008 members come from 140 countries. The majority of enlisted men originate from outside France, while the majority of the officer corps consists of Frenchmen. Many recruits originate from Eastern Europe and Latin America. Neil Tweedie of "The Daily Telegraph" said that Germany traditionally provided many recruits, "somewhat ironically given the Legion's bloody role in two world wars." He added that "Brits, too, have played their part, but there was embarrassment recently when it emerged that many British applicants were failing selection due to endemic unfitness."
Alsace-Lorraine.
Original nationalities of the Foreign Legion reflect the events in history at the time they join. Many former Wehrmacht personnel joined in the wake of WWII as many soldiers returning to civilian life found it hard to find reliable employment. Jean-Denis Lepage reports that "The Foreign Legion discreetly recruited from German P.O.W. camps", but adds that the number of these recruits has been subsequently exaggerated. Bernard B. Fall, who was a supporter of the French government, writing in the context of the First Indochina War, questioned the notion that the Foreign Legion was mainly German at that time, calling it:
Since, in view of the rugged Indochinese climate, older men without previous tropical experience constituted more a liability than an asset, the average age of the Foreign Legion enlistees was about 23. At the time of the battle of Dien Bien Phu, any legionnaire of that age group was at the worst, in his "Hitler Youth" shorts when the hir Reich collapsed.
The Foreign Legion accepts people enlisting under a nationality that is not their own. A proportion of the Swiss and Belgians are actually likely to be Frenchmen who wish to avoid detection. In addition many Alsatians are said to have joined the Foreign Legion when Alsace was part of the German Empire, and may have been recorded as German while considering themselves French.
Regarding recruitment conditions within the Foreign Legion, see the official page (in English) dedicated to the subject: With regard to age limits, recruits can be accepted from ages ranging from 17 ½ (with parental consent) to 40 years old.
Countries that allow post-Foreign Legion contract.
In the Commonwealth Realms, its collective provisions provide for nationals to commute between armies in training or other purposes. Moreover, this 'blanket provision' between member-states cannot exclude others for it would seem inappropriate to single out individual countries, that is, France in relation to the Legion. For example, Australia and New Zealand may allow post-Legion enlistment providing the national has commonwealth citizenship. Britain allows post-Legion enlistment. Canada allows post-Legion enlistment in its ranks with a completed five-year contract. 
In the European Union framework, post Legion enlistment is less clear. Denmark, Norway, Germany and Portugal allow post-Legion enlistment while The Netherlands has constitutional articles that forbid it. (that is: one can lose his Dutch nationality by accepting a foreign nationality or can lose his Dutch nationality by serving in the army of a foreign state that is engaged in a conflict against the Dutch Kingdom or one of its allies). The European Union twin threads seem to be recognized dual nationality status or restricting constitutional article.
The United States allows post-FFL enlistment in its National Guard, and career soldiers, up to the rank of captain only and to green card holders. Second Lieutenant Lawrence J. Franks Jr. was sentenced to four years in prison and dismissal from the U.S. Army on charges of conduct unbecoming of an officer and desertion, as he disappeared from Fort Drum, N.Y. in 2009 and reappeared in 2014. During this time, he served with distinction in the Legion under the assumed name Christopher Flaherty.
Israel allows post-Legion enlistment. The Swiss jail or fine their nationals for joining the Legion due to Switzerland's neutrality.
One of the biggest national groups in the Legion are Poles. Polish law basically allows service in a foreign army, but only after written permission from the Ministry of National Defense. Most soldiers do not actually apply for permission, but only a few have been prosecuted on this account and generally they get probation.
Emulation by other countries.
Chinese Ever Victorious Army.
The Ever Victorious Army was the name given to a Chinese imperial army in the late 19th century. The new force originally comprised about 200 mostly European mercenaries, recruited in the Shanghai area from sailors, deserters and adventurers. Many were dismissed in the summer of 1861, but the remainder became the officers of the Chinese soldiers recruited mainly in and around Sungkiang. The Chinese troops were increased to 3,000 by May 1862, all equipped with Western firearms and equipment by the British authorities in Shanghai. Throughout its four-year existence the Ever Victorious Army was mainly to operate within a thirty-mile radius of Shanghai. It was disbanded in May 1864 with 104 foreign officers and 2,288 Chinese soldiers being paid off. The bulk of the artillery and some infantry transferred to the Chinese Imperial forces. It was the first Chinese army trained in European techniques, tactics, and strategy.
Israeli Mahal.
In Israel, Mahal (, an acronym for "Mitnadvei Ḥutz LaAretz", which means "Volunteers from outside the Land f Israe") is a term designating non-Israelis serving in the Israeli military. The term originates with the (approximately) 4,000 both Jewish and non-Jewish volunteers who went to Israel to fight in the 1948 Arab–Israeli War including Aliyah Bet. The original Mahalniks were mostly World War II veterans from American and British armed forces.
Today, there is a program, Garin Tzabar, within the Israeli Ministry of Defense that administers the enlistment of non-Israeli citizens in the country's armed forces. Programs enable foreigners to join the Israel Defense Forces if they are of Jewish descent (which is defined as at least one grandparent).
Netherlands KNIL Army.
Though not named "Foreign Legion", the Dutch Koninklijk Nederlandsch-Indische Leger (KNIL), or Royal Netherlands-Indian Army (in reference to the Dutch East Indies, now Indonesia), was created in 1830, a year before the French Foreign Legion, and is therefore not an emulation but an entirely original idea and had a similar recruitment policy. It stopped being an army of foreigners around 1900 when recruitment was restricted to Dutch citizens and to the indigenous peoples of the Dutch East Indies. The KNIL was finally disbanded on 26 July 1950, seven months after the Netherlands formally recognised Indonesia as a sovereign state, and almost five years after Indonesia declared its independence.
Rhodesian Light Infantry and 7 Independent Company.
During the Rhodesian Bush War of the 1960s and 1970s, the Rhodesian Security Forces enlisted volunteers from overseas on the same pay and conditions of service as locally based regulars. The vast majority of the Rhodesian Army's foreigners joined the Rhodesian Light Infantry (RLI), a heliborne commando regiment with a glamorous international reputation; this unit became colloquially known as the "Rhodesian foreign legion" as a result, even though foreigners never made up more than about a third of its men. According to Chris Cocks, an RLI veteran, "the RLI was a mirror of the French Foreign Legion, in that recruiters paid little heed as to a man's past and asked no questions. ... And like the Foreign Legion, once in the ranks, a man's past was irrelevant." Just as French Foreign Legionnaires must speak French, the Rhodesian Army required its foreigners to be anglophone. Many of them were professional soldiers, attracted by the regiment's reputation—mostly former British soldiers, or Vietnam veterans from the United States, Australian and New Zealand forces—and these became a key part of the unit. Others, with no military experience, were often motivated to join the Rhodesian Army by anti-communism, or a desire for adventure or to escape the past.
After the Rhodesians' overseas recruiting campaign for English-speakers, started in 1974, proved successful, they began recruiting French-speakers as well, in 1977. These francophone recruits were placed in their own unit, 7 Independent Company, Rhodesia Regiment, which was commanded by French-speaking officers and operated entirely in French. The experiment was not generally considered a success by the Rhodesian commanders, however, and the company was disbanded in early 1978.
Russian "Foreign Legion".
In 2010 the service conditions of the Russian Military have been changed. The actual term "Russian Foreign Legion" is a colloquial expression without any official recognition. Under the plan, foreigners without dual citizenship are able to sign up for five-year contracts and will be eligible for Russian citizenship after serving three years. Experts say the change opens the way for Commonwealth of Independent States citizens to get fast-track Russian citizenship, and counter the effects of Russia's demographic crisis on its army recruitment.
Spanish Foreign Legion.
The Spanish Foreign Legion was created in 1920, in emulation of the French one, and had a significant role in Spain's colonial wars in Morocco and in the Spanish Civil War on the Nationalist side. The Spanish Foreign Legion recruited foreigners until 1986 but unlike its French model, the number of non-Spanish recruits never exceeded 25%, most of these from Latin America. It is now called the "Spanish Legion" and only recruits Spanish nationals.
References in popular culture.
Beyond its reputation as an elite unit often engaged in serious fighting, the recruitment practices of the French Foreign Legion have also led to a somewhat romanticised view of it being a place for disgraced or "wronged" men looking to leave behind their old lives and start new ones. This view of the legion is common in literature, and has been used for dramatic effect in many films, not the least of which are the several versions of "Beau Geste".

</doc>
<doc id="11545" url="https://en.wikipedia.org/wiki?curid=11545" title="Feedback">
Feedback

Feedback occurs when outputs of a system are routed back as inputs as part of a chain of cause-and-effect that forms a circuit or loop. The system can then be said to "feed back" into itself. The notion of cause-and-effect has to be handled carefully when applied to feedback systems:
History.
Self-regulating mechanisms have existed since antiquity, and the idea of feedback had started to enter economic theory in Britain by the eighteenth century, but it wasn't at that time recognized as a universal abstraction and so didn't have a name.
The verb phrase "to feed back", in the sense of "returning to an earlier position" in a mechanical process, was in use in the US by the 1860s, and in 1909, Nobel laureate Karl Ferdinand Braun used the term "feed-back" as a noun to refer to (undesired) "coupling" between components of an electronic circuit.
By the end of 1912, researchers using early electronic amplifiers (audions) had discovered that deliberately coupling part of the output signal back to the input circuit would boost the amplification (through regeneration), but would also cause the audion to howl or sing. This action of feeding back of the signal from output to input gave rise to the use of the term "feedback" as a distinct word by 1920.
Over the years there has been some dispute as to the best definition of feedback. According to Ashby (1956), mathematicians and theorists interested in the "principles" of feedback mechanisms prefer the definition of "circularity of action", which keeps the theory simple and consistent. For those with more "practical" aims, feedback should be a deliberate effect via some more tangible connection.
Focusing on uses in management theory, Ramaprasad (1983) defines feedback generally as "...information about the gap between the actual level and the reference level of a system parameter" that is used to "alter the gap in some way." He emphasizes that the information by itself is not feedback unless translated into action.
Types.
Positive and negative feedback.
There are two types of feedback: "positive feedback" and "negative feedback".
As an example of negative feedback, the diagram might represent a cruise control system in a car, for example, that matches a target speed such as the speed limit. The controlled system is the car; its input includes the combined torque from the engine and from the changing slope of the road (the disturbance). The car's speed (status) is measured by a speedometer. The error signal is the departure of the speed as measured by the speedometer from the target speed (set point). This measured error is interpreted by the controller to adjust the accelerator, commanding the fuel flow to the engine (the effector). The resulting change in engine torque, the feedback, combines with the torque exerted by the changing road grade to reduce the error in speed, minimizing the road disturbance.
The terms "positive" and "negative" were first applied to feedback prior to WWII. The idea of positive feedback was already current in the 1920s with the introduction of the regenerative circuit. Friis and Jensen (1924) described regeneration in a set of electronic amplifiers as a case where "the "feed-back" action is positive" in contrast to negative feed-back action, which they mention only in passing. Harold Stephen Black's classic 1934 paper first details the use of negative feedback in electronic amplifiers. According to Black:
According to Mindell (2002) confusion in the terms arose shortly after this:
Even prior to the terms being applied, James Clerk Maxwell had described several kinds of "component motions" associated with the centrifugal governors used in steam engines, distinguishing between those that lead to a continual "increase" in a disturbance or the amplitude of an oscillation, and those that lead to a "decrease" of the same.
Terminology.
The terms positive and negative feedback are defined in different ways within different disciplines.
The two definitions may cause confusion, such as when an incentive (reward) is used to boost poor performance (narrow a gap). Referring to definition 1, some authors use alternative terms, replacing "positive/negative" with "self-reinforcing/self-correcting", "reinforcing/balancing", "discrepancy-enhancing/discrepancy-reducing" or "regenerative/degenerative" respectively. And for definition 2, some authors advocate describing the action or effect as positive/negative "reinforcement" or "punishment" rather than feedback.
Yet even within a single discipline an example of feedback can be called either positive or negative, depending on how values are measured or referenced.
This confusion may arise because feedback can be used for either "informational" or "motivational" purposes, and often has both a "qualitative" and a "quantitative" component. As Connellan and Zemke (1993) put it:
Limitations of negative and positive feedback.
While simple systems can sometimes be described as one or the other type, many systems with feedback loops cannot be so easily designated as simply positive or negative, and this is especially true when multiple loops are present.
Other types of feedback.
In general, feedback systems can have many signals fed back and the feedback loop frequently contain mixtures of positive and negative feedback where positive and negative feedback can dominate at different frequencies or different points in the state space of a system.
The term bipolar feedback has been coined to refer to biological systems where positive and negative feedback systems can interact, the output of one affecting the input of another, and vice versa.
Some systems with feedback can have very complex behaviors such as chaotic behaviors in non-linear systems, while others have much more predictable behaviors, such as those that are used to make and design digital systems.
Feedback is used extensively in digital systems. For example, binary counters and similar devices employ feedback where the current state and inputs are used to calculate a new state which is then fed back and clocked back into the device to update it.
Applications.
Biology.
In biological systems such as organisms, ecosystems, or the biosphere, most parameters must stay under control within a narrow range around a certain optimal level under certain environmental conditions. The deviation of the optimal value of the controlled parameter can result from the changes in internal and external environments. A change of some of the environmental conditions may also require change of that range to change for the system to function. The value of the parameter to maintain is recorded by a reception system and conveyed to a regulation module via an information channel. An example of this is Insulin oscillations.
Biological systems contain many types of regulatory circuits, both positive and negative. As in other contexts, "positive" and "negative" do not imply that the feedback causes "good" or "bad" effects. A negative feedback loop is one that tends to slow down a process, whereas the positive feedback loop tends to accelerate it. The mirror neurons are part of a social feedback system, when an observed action is "mirrored" by the brain—like a self-performed action.
Feedback is also central to the operations of genes and gene regulatory networks. Repressor (see Lac repressor) and activator proteins are used to create genetic operons, which were identified by Francois Jacob and Jacques Monod in 1961 as "feedback loops". These feedback loops may be positive (as in the case of the coupling between a sugar molecule and the proteins that import sugar into a bacterial cell), or negative (as is often the case in metabolic consumption).
On a larger scale, feedback can have a stabilizing effect on animal populations even when profoundly affected by external changes, although time lags in feedback response can give rise to predator-prey cycles.
In zymology, feedback serves as regulation of activity of an enzyme by its direct product(s) or downstream metabolite(s) in the metabolic pathway (see Allosteric regulation).
The hypothalamic–pituitary–adrenal axis is largely controlled by positive and negative feedback, much of which is still unknown.
In psychology, the body receives a stimulus from the environment or internally that causes the release of hormones. Release of hormones then may cause more of those hormones to be released, causing a positive feedback loop. This cycle is also found in certain behaviour. For example, "shame loops" occur in people who blush easily. When they realize that they are blushing, they become even more embarrassed, which leads to further blushing, and so on.
Climate science.
The climate system is characterized by strong positive and negative feedback loops between processes that affect the state of the atmosphere, ocean, and land. A simple example is the ice-albedo positive feedback loop whereby melting snow exposes more dark ground (of lower albedo), which in turn absorbs heat and causes more snow to melt.
Control theory.
Feedback is extensively used in control theory, using a variety of methods including state space (controls), full state feedback (also known as pole placement), and so forth. Note that in the context of control theory, "feedback" is traditionally assumed to specify "negative feedback".
The most common general-purpose controller using a control-loop feedback mechanism is a proportional-integral-derivative (PID) controller. Heuristically, the terms of a PID controller can be interpreted as corresponding to time: the proportional term depends on the "present" error, the integral term on the accumulation of "past" errors, and the derivative term is a prediction of "future" error, based on current rate of change.
Mechanical engineering.
In ancient times, the float valve was used to regulate the flow of water in Greek and Roman water clocks; similar float valves are used to regulate fuel in a carburettor and also used to regulate tank water level in the flush toilet.
The Dutch inventor Cornelius Drebbel (1572-1633) built thermostats (c1620) to control the temperature of chicken incubators and chemical furnaces. In 1745, the windmill was improved by blacksmith Edmund Lee, who added a fantail to keep the face of the windmill pointing into the wind. In 1787, Thomas Mead regulated the rotation speed of a windmill by using a centrifugal pendulum to adjust the distance between the bedstone and the runner stone (i.e., to adjust the load).
The use of the centrifugal governor by James Watt in 1788 to regulate the speed of his steam engine was one factor leading to the Industrial Revolution. Steam engines also use float valves and pressure release valves as mechanical regulation devices. A mathematical analysis of Watt's governor was done by James Clerk Maxwell in 1868.
The "Great Eastern" was one of the largest steamships of its time and employed a steam powered rudder with feedback mechanism designed in 1866 by John McFarlane Gray. Joseph Farcot coined the word "servo" in 1873 to describe steam-powered steering systems. Hydraulic servos were later used to position guns. Elmer Ambrose Sperry of the Sperry Corporation designed the first autopilot in 1912. Nicolas Minorsky published a theoretical analysis of automatic ship steering in 1922 and described the PID controller.
Internal combustion engines of the late 20th century employed mechanical feedback mechanisms such as the vacuum timing advance but mechanical feedback was replaced by electronic engine management systems once small, robust and powerful single-chip microcontrollers became affordable.
Electronic engineering.
The use of feedback is widespread in the design of electronic amplifiers, oscillators, and stateful logic circuit elements such as flip-flops and counters. Electronic feedback systems are also very commonly used to control mechanical, thermal and other physical processes.
If the signal is inverted on its way round the control loop, the system is said to have "negative feedback"; otherwise, the feedback is said to be "positive". Negative feedback is often deliberately introduced to increase the stability and accuracy of a system by correcting or reducing the influence of unwanted changes. This scheme can fail if the input changes faster than the system can respond to it. When this happens, the lag in arrival of the correcting signal can result in over-correction, causing the output to oscillate or "hunt". While often an unwanted consequence of system behaviour, this effect is used deliberately in electronic oscillators.
Harry Nyquist contributed the Nyquist plot for assessing the stability of feedback systems. An easier assessment, but less general, is based upon gain margin and phase margin using Bode plots (contributed by Hendrik Bode). Design to ensure stability often involves frequency compensation, one method of compensation being pole splitting.
Electronic feedback loops are used to control the output of electronic devices, such as amplifiers. A feedback loop is created when all or some portion of the output is fed back to the input. A device is said to be operating "open loop" if no output feedback is being employed and "closed loop" if feedback is being used.
When two or more amplifiers are cross-coupled using positive feedback, complex behaviors can be created. These "multivibrators" are widely used and include:
Negative feedback.
Negative feedback occurs when the fed-back output signal has a relative phase of 180° with respect to the input signal (upside down). This situation is sometimes referred to as being "out of phase", but that term also is used to indicate other phase separations, as in "90° out of phase". Negative feedback can be used to correct output errors or to desensitize a system to unwanted fluctuations. In feedback amplifiers, this correction is generally for waveform distortion reduction or to establish a specified gain level. A general expression for the gain of a negative feedback amplifier is the asymptotic gain model.
Positive feedback.
Positive feedback occurs when the fed-back signal is in phase with the input signal. Under certain gain conditions, positive feedback reinforces the input signal to the point where the output of the device oscillates between its maximum and minimum possible states. Positive feedback may also introduce hysteresis into a circuit. This can cause the circuit to ignore small signals and respond only to large ones. It is sometimes used to eliminate noise from a digital signal. Under some circumstances, positive feedback may cause a device to latch, i.e., to reach a condition in which the output is locked to its maximum or minimum state. This fact is very widely used in digital electronics to make bistable circuits for volatile storage of information.
The loud squeals that sometimes occurs in audio systems, PA systems, and rock music are known as audio feedback. If a microphone is in front of a loudspeaker that it is connected to, sound that the microphone picks up comes out of the speaker, and is picked up by the microphone and re-amplified. If the loop gain is sufficient, howling or squealing at the maximum power of the amplifier is possible.
Oscillator.
An electronic oscillator is an electronic circuit that produces a periodic, oscillating electronic signal, often a sine wave or a square wave. Oscillators convert direct current (DC) from a power supply to an alternating current signal. They are widely used in many electronic devices. Common examples of signals generated by oscillators include signals broadcast by radio and television transmitters, clock signals that regulate computers and quartz clocks, and the sounds produced by electronic beepers and video games.
Oscillators are often characterized by the frequency of their output signal: 
Oscillators designed to produce a high-power AC output from a DC supply are usually called inverters.
There are two main types of electronic oscillator: the linear or harmonic oscillator and the nonlinear or relaxation oscillator.
Latches and flip-flops.
A latch or a flip-flop is a circuit that has two stable states and can be used to store state information. They typically constructed using feedback that crosses over between two arms of the circuit, to provide the circuit with a state. The circuit can be made to change state by signals applied to one or more control inputs and will have one or two outputs. It is the basic storage element in sequential logic. Latches and flip-flops are fundamental building blocks of digital electronics systems used in computers, communications, and many other types of systems.
Latches and flip-flops are used as data storage elements. Such data storage can be used for storage of "state", and such a circuit is described as sequential logic. When used in a finite-state machine, the output and next state depend not only on its current input, but also on its current state (and hence, previous inputs). It can also be used for counting of pulses, and for synchronizing variably-timed input signals to some reference timing signal.
Flip-flops can be either simple (transparent or opaque) or clocked (synchronous or edge-triggered). Although the term flip-flop has historically referred generically to both simple and clocked circuits, in modern usage it is common to reserve the term "flip-flop" exclusively for discussing clocked circuits; the simple ones are commonly called "latches".
Using this terminology, a latch is level-sensitive, whereas a flip-flop is edge-sensitive. That is, when a latch is enabled it becomes transparent, while a flip flop's output only changes on a single type (positive going or negative going) of clock edge.
Software.
Feedback loops provide generic mechanisms for controlling the running, maintenance, and evolution of software and computing systems. Feedback-loops are important models in the engineering of adaptive software, as they define the behaviour of the interactions among the control elements over the adaptation process, to guarantee system properties at run-time. Feedback loops and foundations of control theory have been successfully applied to computing systems. In particular, they have been applied to the development of products such as IBM's Universal Database server and IBM Tivoli. From a software perspective, the autonomic (MAPE, monitor analyze plan execute) loop proposed by researchers of IBM is another valuable contribution to the application of feedback loops to the control of dynamic properties and the design and evolution of autonomic software systems.
Video feedback.
Video feedback is the video equivalent of acoustic feedback. It involves a loop between a video camera input and a video output, e.g., a television screen or monitor. Aiming the camera at the display produces a complex video image based on the feedback.
Social sciences.
Economics and finance.
The stock market is an example of a system prone to oscillatory "hunting", governed by positive and negative feedback resulting from cognitive and emotional factors among market participants. For example,
George Soros used the word "reflexivity," to describe feedback in the financial markets and developed an investment theory based on this principle.
The conventional economic equilibrium model of supply and demand supports only ideal linear negative feedback and was heavily criticized by Paul Ormerod in his book "The Death of Economics", which, in turn, was criticized by traditional economists. This book was part of a change of perspective as economists started to recognise that chaos theory applied to nonlinear feedback systems including financial markets.

</doc>
<doc id="11547" url="https://en.wikipedia.org/wiki?curid=11547" title="Furigana">
Furigana

Furigana is most often written in hiragana, though katakana is used in certain special cases explained later in the article. In vertical text, "tategaki", the furigana is placed to the right of the line of text, while in horizontal text, "yokogaki", it is placed above the line of text, as illustrated below. 
or
These examples spell the word "kanji", which is made up of two kanji characters: 漢 ("kan", written in hiragana as かん), and 字 ("ji", written in hiragana as じ).
Appearance.
Furigana may be added by character, in which case the furigana characters that correspond to a kanji are centered over that kanji; or by word or phrase, in which case the entire furigana word is centered over several kanji characters, even if the kanji do not represent equal shares of the kana needed to write them. The latter method is more common, especially since some words in Japanese have unique pronunciations ("jukujikun") that are not related to readings of any of the characters the word is written with.
Furigana fonts are generally sized so that two kana characters fit naturally over one kanji; when more kana are required, this is resolved either by adjusting the furigana by using a condensed font (narrowing the kana), or by adjusting the kanji by intercharacter spacing (adding spaces around the kanji). In case an isolated kanji character has a long reading—for example (where reads , "tazusa")—the furigana may instead spill over into the space next to the neighboring kana characters, without condensing or changing spacing. Three-kana readings are not uncommon, particularly due to "yōon" with a long vowel, such as ; five kana are required for and six for , the longest of any characters in the Joyo kanji. Very long readings also occur for certain kanji or symbols which have a "gairaigo" reading; the word "centimeter" is generally written as "cm" (with two half-width characters, so occupying one space) and has the seven-kana reading (it can also be written as the kanji , though this is very rare); another common example is "%" (the percent sign), which has the five kana reading . These cause severe spacing problems due to length and these words being used as units (hence closely associated to the preceding figure).
When it is necessary to distinguish between native Japanese "kun'yomi" and Chinese-derived "on'yomi" pronunciations, for example in Kanji dictionaries, the Japanese pronunciations are written in hiragana, and the Chinese ones are written in katakana. However, this distinction is really only important in dictionaries and other reference works. In ordinary prose, the script chosen will usually be hiragana. The one general exception to this is "modern" Chinese place names, personal names, and (occasionally) food names—these will often be written with kanji, and katakana used for the furigana; in more casual writing these are simply written in katakana, as borrowed words. Occasionally this style is also used for loanwords from other languages (especially English). For example, the kanji 一角獣 (literally "one horn beast") might be glossed with katakana ユニコーン, "yunikōn", to show the pronunciation of the loanword "unicorn", which is unrelated to the normal reading of the kanji. Generally, though, such loanwords are just written in straight katakana.
The distinction between regular kana and the smaller character forms, which are used in regular orthography to mark such things as gemination and palatalization, is often not made in furigana: for example, the usual hiragana spelling of the word ("kyakka") is , but in furigana it might be written . This was especially common in old-fashioned movable type printing when smaller fonts were not available. Nowadays, with computer-based printing systems, this occurs less frequently.
Usage.
Furigana are most commonly used in works for children, who may not have sufficiently advanced reading skills to recognize the kanji, but can understand the word when written phonetically in hiragana. Because children learn hiragana before katakana, in books for very young children, there are hiragana furigana next to the katakana characters. It is common to use furigana on all kanji characters in works for young children. This is called in Japanese.
Many children's and shōnen manga use furigana. There are also books with a phonetic guide (mainly in hiragana but sometimes in romaji) for Japanese learners, which may be bilingual or Japanese only. These are popular with foreigners wishing to master Japanese faster and enjoy reading Japanese short stories, novels or articles.
Some websites and tools exist which provide a phonetic guide for Japanese web pages (in hiragana, romaji or kiriji); these are popular with both Japanese children and foreign Japanese learners.
In works aimed at adult Japanese speakers, furigana may be used on a word written in uncommon kanji; in the mass media, they are generally used on words containing non-Jōyō kanji.
Furigana commonly appear alongside kanji names and their romanizations on signs for railway stations, even if the pronunciation of the kanji is commonly known. Furigana also appear often on maps to show the pronunciation of unusual place names.
Prewar, youths would have been almost illiterate if it was not for furigana.
Names.
Japanese names are usually written in kanji. Because there are many possible readings for kanji names, including special name-only readings called nanori, furigana are often used to give the readings of names. On Japanese official forms, where the name is to be written, there is always an adjacent column for the name to be written in furigana. Usually katakana is preferred.
Furigana may also be used for foreign names written in kanji. Chinese and Korean names are the most common examples: Chinese names are usually pronounced with Japanese readings and the pronunciation written in hiragana, while Korean names are usually pronounced with Korean readings and the pronunciation written in katakana. Furigana may also be necessary in the rare case where names are transliterated into kanji from other languages (e.g. soccer star Ruy Ramos and politician Marutei Tsurunen.)
Language learning.
Kanji and kanji compounds are often presented with furigana in Japanese language textbooks for non-native speakers.
Furigana are also often used in foreign language textbooks for Japanese learners to indicate pronunciation. The words are written in the original foreign script, such as hangul for Korean, and furigana is used to indicate the pronunciation. According to Ministry of Education guidelines, and the opinions of educators, the use of Japanese furigana should be avoided in English teaching due to the differences in pronunciation between English and Japanese. For instance, the word "birthdate" might be glossed in furigana as 「バースデイト」, which corresponds to an imperfect pronunciation like "baasudeito".
Punning and double meaning.
Some writers use furigana to represent slang pronunciations, particularly those that would become hard to understand without the kanji to provide their meaning.
Another use is to write the kanji for something which had been previously referenced, but write furigana for () or (), meaning "that". This means that the actual word used was "that", but the kanji clarify for the reader what "that" refers to.
In karaoke it is extremely common for furigana to be placed on the song lyrics. The song lyrics are often written in kanji pronounced quite differently from the furigana. The furigana version is used for pronunciation.
Also, because the kanji represent meaning while the furigana represent sound, one can combine the two to create puns or indicate meanings of foreign words. One might write the kanji for "blue", but use katakana to write the pronunciation of the English word "blue"; this may be done, for example, in Japanese subtitles on foreign films, where it can help associate the written Japanese with the sounds actually being spoken by the actors, or it may be used in a translation of a work of fiction to enable the translator to preserve the original sound of a proper name (such as "Firebolt" in the Harry Potter series) in furigana, while simultaneously indicating its meaning with kanji. A similar practice is used in native fiction to clarify extended meanings. For example, in a work of science fiction, some astronaut could use the word , "furusato", meaning "my hometown", when referring to planet Earth. To clarify that for the reader, the word "furusato" (hometown) might be written in hiragana over the kanji for "chikyuu" (Earth).
Other Japanese reading aids.
Okurigana.
Okurigana are kana that appear inline at normal size following kanji stems, typically to complete and to inflect adjectives and verbs. In this use they may also help to disambiguate kanji with multiple readings; for example, (, "agaru") vs. (, "noboru"). Unlike furigana, the use of okurigana is a mandatory part of the written language.
Kunten.
In the written style known as "kanbun", which is the Japanese approximation of Classical Chinese, small marks called "kunten" are sometimes added as reading aids. Unlike furigana, which indicate pronunciation, "kunten" indicate Japanese grammatical structures absent from the "kanbun", as well as showing how words should be reordered to fit Japanese sentence structure.
Furikanji.
Furigana are sometimes also used to indicate meaning, rather than pronunciation. Over the foreign text, smaller sized Japanese words, in kana or kanji, corresponding to the "meaning" of the foreign words, effectively translate it in place. While rare now, some late 19th–early 20th century authors used kanji as furigana for loanwords written in katakana. This usage is called in Japanese, since "furigana implies the use of kana".

</doc>
<doc id="11551" url="https://en.wikipedia.org/wiki?curid=11551" title="Francis II, Holy Roman Emperor">
Francis II, Holy Roman Emperor

Francis II () (12 February 1768 – 2 March 1835) was the last Holy Roman Emperor, ruling from 1792 until 6 August 1806, when he dissolved the Holy Roman Empire after the decisive defeat at the hands of the First French Empire led by Napoleon at the Battle of Austerlitz. In 1804, he had founded the Austrian Empire and became Francis I ("Franz I."), the first Emperor of Austria ("Kaiser von Österreich"), ruling from 1804 to 1835, so later he was named the one and only "Doppelkaiser" (double emperor) in history.
For the two years between 1804 and 1806, Francis used the title and style "by the grace of God elected Roman Emperor, ever Augustus, hereditary Emperor of Austria" and he was called the "Emperor of both the Holy Roman Empire and Austria". He was also Apostolic King of Hungary and Bohemia as Francis I. He also served as the first president of the German Confederation following its establishment in 1815.
Francis II continued his leading role as an opponent of Napoleonic France in the Napoleonic Wars, and suffered several more defeats after Austerlitz. The proxy marriage of state of his daughter Marie Louise of Austria to Napoleon on 10 March 1810 was arguably his most severe personal defeat. After the abdication of Napoleon following the War of the Sixth Coalition, Austria participated as a leading member of the Holy Alliance at the Congress of Vienna, which was largely dominated by Francis's chancellor Klemens Wenzel, Prince von Metternich culminating in a new European map and the restoration of Francis' ancient dominions (except the Holy Roman Empire which was dissolved). Due to the establishment of the Concert of Europe, which largely resisted popular nationalist and liberal tendencies, Francis became viewed as a reactionary later in his reign.
Early life.
Francis was a son of Emperor Leopold II (1747–1792) and his wife Maria Luisa of Spain (1745–1792), daughter of Charles III of Spain. Francis was born in Florence, the capital of Tuscany, where his father reigned as Grand Duke from 1765–90. Though he had a happy childhood surrounded by his many siblings, his family knew Francis was likely to be a future Emperor (his uncle Joseph had no surviving issue from either of his two marriages), and so in 1784 the young Archduke was sent to the Imperial Court in Vienna to educate and prepare him for his future role.
Emperor Joseph II himself took charge of Francis's development. His disciplinarian regime was a stark contrast to the indulgent Florentine Court of Leopold. The Emperor wrote that Francis was "stunted in growth", "backward in bodily dexterity and deportment", and "neither more nor less than a spoiled mother's child". Joseph concluded that "...the manner in which he was treated for upwards of sixteen years could not but have confirmed him in the delusion that the preservation of his own person was the only thing of importance."
Joseph's martinet method of improving the young Francis were "fear and unpleasantness". The young Archduke was isolated, the reasoning being that this would make him more self-sufficient as it was felt by Joseph that Francis "fail to lead himself, to do his own thinking". Nonetheless, Francis greatly admired his uncle, if rather feared him. To complete his training, Francis was sent to join an army regiment in Hungary and he settled easily into the routine of military life.
After the death of Joseph II in 1790, Francis's father became Emperor. He had an early taste of power while acting as Leopold's deputy in Vienna while the incoming Emperor traversed the Empire attempting to win back those alienated by his brother's policies. The strain told on Leopold and by the winter of 1791, he became ill. He gradually worsened throughout early 1792; on the afternoon of 1 March Leopold died, at the relatively young age of 44. Francis, just past his 24th birthday, was now Emperor, much sooner than he had expected.
Emperor.
As the leader of the large multi-ethnic Habsburg Empire, Francis felt threatened by Napoleon's social and political reforms, which were being exported throughout Europe with the expansion of the first French Empire. Francis had a fraught relationship with France. His aunt Marie Antoinette, the wife of Louis XVI and Queen consort of France, had been guillotined by the revolutionaries at the beginning of his reign. Francis, on the whole, was indifferent to her fate (she was not close to his father, Leopold, and although Francis had met her, he had been too young at the time to have any memory of his aunt). Georges Danton attempted to negotiate with the Emperor for Marie Antoinette's release, but Francis was unwilling to make any concessions in return.
Later, he led Austria into the French Revolutionary Wars. He briefly commanded the Allied forces during the Flanders Campaign of 1794 before handing over command to his brother Archduke Charles. He was later defeated by Napoleon. By the Treaty of Campo Formio, he ceded the left bank of the Rhine to France in exchange for Venice and Dalmatia. He again fought against France during the Second and Third Coalition, when after meeting a crushing defeat at Austerlitz, he had to agree to the Treaty of Pressburg, weakening the Austrian Empire and reorganizing Germany under a Napoleonic imprint that would be called the Confederation of the Rhine. At this point, he believed his position as Holy Roman Emperor to be untenable, so on 6 August 1806, he abdicated the throne. He had anticipated losing the Holy Roman crown, however. Two years earlier, as a reaction to Napoleon making himself an emperor, he had raised Austria to the status of an empire. Hence, after 1806, he reigned as Francis I, Emperor of Austria.
In 1809, Francis attacked France again, hoping to take advantage of the Peninsular War embroiling Napoleon in Spain. He was again defeated, and this time forced to ally himself with Napoleon, ceding territory to the Empire, joining the Continental System, and wedding his daughter Marie-Louise to the Emperor. The Napoleonic wars drastically weakened Austria and threatened its preeminence among the states of Germany, a position that it would eventually cede to the Kingdom of Prussia.
In 1813, for the fourth and final time, Austria turned against France and joined Great Britain, Russia, Prussia and Sweden in their war against Napoleon. Austria played a major role in the final defeat of France—in recognition of this, Francis, represented by Clemens von Metternich, presided over the Congress of Vienna, helping to form the Concert of Europe and the Holy Alliance, ushering in an era of conservatism in Europe. The German Confederation, a loose association of Central European states was created by the Congress of Vienna in 1815 to organize the surviving states of the Holy Roman Empire. The Congress was a personal triumph for Francis, who hosted the assorted dignitaries in comfort, though Francis undermined his allies Tsar Alexander and Frederick William III of Prussia by negotiating a secret treaty with the restored French king Louis XVIII.
The federal Diet met at Frankfurt under Austrian presidency (in fact the Habsburg Emperor was represented by an Austrian "presidential envoy").
Domestic policy.
The violent events of the French Revolution impressed themselves deeply into the mind of Francis (as well as all other European monarchs), and he came to distrust radicalism in any form. In 1794, a "Jacobin" conspiracy was discovered in the Austrian and Hungarian armies. The leaders were put on trial, but the verdicts only skirted the perimeter of the conspiracy. Francis's brother Alexander Leopold (at that time Palatine of Hungary) wrote to the Emperor admitting "Although we have caught a lot of the culprits, we have not really got to the bottom of this business yet." Nonetheless, two officers heavily implicated in the conspiracy were hanged and gibbeted, while numerous others were sentenced to imprisonment (many of whom died from the conditions).
Francis was from his experiences suspicious and set up an extensive network of police spies and censors to monitor dissent (in this he was following his father's lead, as the Grand Duchy of Tuscany had the most effective secret police in Europe). Even his family did not escape attention. His brothers, the Archdukes Charles and Johann had their meetings and activities spied upon. Censorship was also prevalent. The author Franz Grillparzer, a Habsburg patriot, had one play suppressed solely as a "precautionary" measure. When Grillparzer met the censor responsible, he asked him what was objectionable about the work. The censor replied, "Oh, nothing at all. But I thought to myself, 'One can never tell'."
In military affairs Francis had allowed his brother, the Archduke Charles, extensive control over the army during the Napoleonic wars. Yet, distrustful of allowing any individual too much power, he otherwise maintained the separation of command functions between the Hofkriegsrat and his field commanders. In the later years of his reign he limited military spending, requiring it not exceed forty millions florins per year; because of inflation this resulted in inadequate funding, with the army's share of the budget shrinking from half in 1817 to only twenty-three percent in 1830.
Francis presented himself as an open and approachable monarch (he regularly set aside two mornings each week to meet his imperial subjects, regardless of status, by appointment in his office, even speaking to them in their own language), but his will was sovereign. In 1804, he had no compunction about announcing that through his authority as Holy Roman Emperor, he declared he was now Emperor of Austria (at the time a geographical term that had little resonance). Two years later, Francis personally wound up the moribund Holy Roman Empire of the German Nation. Both actions were of dubious constitutional legality.
Later years.
On 2 March 1835, 43 years and a day after his father's death, Francis died in Vienna of a sudden fever aged 67, in the presence of many of his family and with all the religious comforts. His funeral was magnificent, with his Viennese subjects respectfully filing past his coffin in the chapel of Hofburg Palace for three days. Francis was interred in the traditional resting place of Habsburg monarchs, the Kapuziner Imperial Crypt in Vienna's Neue Markt Square. He is buried in tomb number 57, surrounded by his four wives.
Francis left a main point in the political testament he left for his son and heir Ferdinand to, "Preserve unity in the family and regard it as one of the highest goods." In many portraits (particularly those painted by Peter Fendi) he was portrayed as the patriarch of a loving family, surrounded by his children and grandchildren.
After 1806 he used the titles: "We, Francis the First, by the grace of God Emperor of Austria; King of Jerusalem, Hungary, Bohemia, Dalmatia, Croatia, Slavonia, Galicia and Lodomeria; Archduke of Austria; Duke of Lorraine, Salzburg, Würzburg, Franconia, Styria, Carinthia and Carniola; Grand Duke of Cracow; Grand Prince of Transylvania; Margrave of Moravia; Duke of Sandomir, Masovia, Lublin, Upper and Lower Silesia, Auschwitz and Zator, Teschen and Friule; Prince of Berchtesgaden and Mergentheim; Princely Count of Habsburg, Gorizia and Gradisca and of the Tirol; and Margrave of Upper and Lower Lusatia and in Istria".
Marriages.
Francis II married four times:
Children.
From his first wife Elisabeth of Württemberg, one daughter, and his second wife Maria Teresa of the Two Sicilies, eight daughters and four sons:

</doc>
<doc id="11552" url="https://en.wikipedia.org/wiki?curid=11552" title="Frederick Abel">
Frederick Abel

Sir Frederick Augustus Abel, 1st Baronet KCB, FRS (17 July 1827 – 6 September 1902) was an English chemist.
Education.
Born in London as son of Johann Leopold Abel, Abel studied chemistry at the Royal Polytechnic Institution and in 1845 became one of the original 26 students of A. W. von Hofmann at the Royal College of Chemistry. In 1852 he was appointed lecturer in chemistry at the Royal Military Academy, Woolwich, succeeding Michael Faraday, who had held that post since 1829.
Early career.
From 1854 until 1888 Abel served as ordnance chemist at the Chemical Establishment of the Royal Arsenal at Woolwich, establishing himself as the leading British authority on explosives. Three years later was appointed chemist to the War Department and chemical referee to the government. During his tenure of this office, which lasted until 1888, he carried out a large amount of work in connection with the chemistry of explosives.
Notable work.
One of the most important of his investigations had to do with the manufacture of guncotton, and he developed a process, consisting essentially of reducing the nitrated cotton to fine pulp, which enabled it to be safely manufactured and at the same time yielded the product in a form that increased its usefulness. This work to an important extent prepared the way for the "smokeless powders" which came into general use towards the end of the 19th century; cordite, the type adopted by the British government in 1891, was invented jointly by him and Sir James Dewar. He and Dewar were unsuccessfully sued by Alfred Nobel over infringement of Nobel's patent for a similar explosive called ballistite, the case finally being resolved in the House of Lords in 1895. He also extensively researched the behaviour of black powder when ignited, with the Scottish physicist Sir Andrew Noble. At the request of the British government, he devised the Abel test, a means of determining the flash point of petroleum products. His first instrument, the open-test apparatus, was specified in an Act of Parliament in 1868 for officially specifying petroleum products. It was superseded in August 1879 by the much more reliable Abel close-test instrument. Under the leadership of Sir Frederick Abel, first, Guncotton was developed at Waltham Abbey Royal Gunpowder Mills, patented in 1865, then, the propellant Cordite, patented in 1889. In electricity Abel studied the construction of electrical fuses and other applications of electricity to warlike purposes, and his work on problems of steel manufacture won him in 1897 the Bessemer medal of the Iron and Steel Institute, of which from 1891 to 1893 he was president.
Leadership and honours.
He was president of the Institution of Electrical Engineers (then the Society of Telegraph Engineers) in 1877. He became a fellow of the Royal Society in 1860, he was a Commander of the Bath (CB) by 13 February 1879, he was knighted on 20 April 1883 and received a Royal Medal in 1887. He took an important part in the work of the Inventions Exhibition (London) in 1885, and in 1887 became organizing secretary and first director of the Imperial Institute, a position he held till his death in 1902. He was Rede Lecturer and received an honorary doctorate from Cambridge University in 1888. He was upgraded to a Knight Commander of the Bath (KCB) on 3 February 1891, created a baronet, of Cadogan Place in the Parish of Chelsea in the County of London, on 25 May 1893 and made a Knight Grand Cross of the Royal Victorian Order (GCVO) on 8 March 1901. Abel died in September 1902, aged 75, and was buried in Nunhead Cemetery, London. The baronetcy became extinct on his death.
He also wrote several important articles in the ninth edition of the Encyclopædia Britannica.

</doc>
<doc id="11554" url="https://en.wikipedia.org/wiki?curid=11554" title="Fugazi (disambiguation)">
Fugazi (disambiguation)

Fugazi may refer to:

</doc>
<doc id="11555" url="https://en.wikipedia.org/wiki?curid=11555" title="Fluorescence">
Fluorescence

Fluorescence is the emission of light by a substance that has absorbed light or other electromagnetic radiation. It is a form of luminescence. In most cases, the emitted light has a longer wavelength, and therefore lower energy, than the absorbed radiation. The most striking example of fluorescence occurs when the absorbed radiation is in the ultraviolet region of the spectrum, and thus invisible to the human eye, while the emitted light is in the visible region, which gives the fluorescent substance a distinct color that can only be seen when exposed to UV light. However, unlike phosphorescence, where the substance would continue to glow and emit light for some time after the radiation source has been turned off, fluorescent materials would cease to glow immediately upon removal of the excitation source. Hence, it is not a persistent phenomenon.
Fluorescence has many practical applications, including mineralogy, gemology, chemical sensors (fluorescence spectroscopy), fluorescent labelling, dyes, biological detectors, cosmic-ray detection, and, most commonly, fluorescent lamps. Fluorescence also occurs frequently in nature in some minerals and in various biological states in many branches of the animal kingdom.
History.
An early observation of fluorescence was described in 1560 by Bernardino de Sahagún and in 1565 by Nicolás Monardes in the infusion known as "lignum nephriticum" (Latin for "kidney wood"). It was derived from the wood of two tree species, "Pterocarpus indicus" and "Eysenhardtia polystachya". The chemical compound responsible for this fluorescence is matlaline, which is the oxidation product of one of the flavonoids found in this wood.
In 1819, Edward D. Clarke and in 1822 René Just Haüy described fluorescence in fluorites, Sir David Brewster described the phenomenon for chlorophyll in 1833 and Sir John Herschel did the same for quinine in 1845.
In his 1852 paper on the "Refrangibility" (wavelength change) of light, George Gabriel Stokes described the ability of fluorspar and uranium glass to change invisible light beyond the violet end of the visible spectrum into blue light. He named this phenomenon "fluorescence" : "I am almost inclined to coin a word, and call the appearance "fluorescence", from fluor-spar .e., fluorit, as the analogous term "opalescence" is derived from the name of a mineral." The name was derived from the mineral fluorite (calcium difluoride), some examples of which contain traces of divalent europium, which serves as the fluorescent activator to emit blue light. In a key experiment he used a prism to isolate ultraviolet radiation from sunlight and observed blue light emitted by an ethanol solution of quinine exposed by it.
Physical principles.
Photochemistry.
Fluorescence occurs when an orbital electron of a molecule, atom, or nanostructure, relaxes to its ground state by emitting a photon from an excited singlet state:
Excitation: formula_1
Fluorescence (emission): formula_2
Here formula_3 is a generic term for photon energy with h = Planck's constant and formula_4 = frequency of light. The specific frequencies of exciting and emitted light are dependent on the particular system.
S is called the ground state of the fluorophore (fluorescent molecule), and S is its first (electronically) excited singlet state.
A molecule in S can relax by various competing pathways. It can undergo "non-radiative" relaxation in which the excitation energy is dissipated as heat (vibrations) to the solvent. Excited organic molecules can also relax via conversion to a triplet state, which may subsequently relax via phosphorescence, or by a secondary non-radiative relaxation step.
Relaxation from S can also occur through interaction with a second molecule through fluorescence quenching. Molecular oxygen (O) is an extremely efficient quencher of fluorescence just because of its unusual triplet ground state.
In most cases, the emitted light has a longer wavelength, and therefore lower energy, than the absorbed radiation; this phenomenon is known as the Stokes shift. However, when the absorbed electromagnetic radiation is intense, it is possible for one electron to absorb two photons; this two-photon absorption can lead to emission of radiation having a shorter wavelength than the absorbed radiation. The emitted radiation may also be of the same wavelength as the absorbed radiation, termed "resonance fluorescence".
Molecules that are excited through light absorption or via a different process (e.g. as the product of a reaction) can transfer energy to a second 'sensitized' molecule, which is converted to its excited state and can then fluoresce.
Quantum yield.
The fluorescence quantum yield gives the efficiency of the fluorescence process. It is defined as the ratio of the number of photons emitted to the number of photons absorbed.
The maximum fluorescence quantum yield is 1.0 (100%); each photon absorbed results in a photon emitted. Compounds with quantum yields of 0.10 are still considered quite fluorescent. Another way to define the quantum yield of fluorescence, is by the rate of excited state decay:
where formula_7 is the rate constant of spontaneous emission of radiation and
is the sum of all rates of excited state decay. Other rates of excited state decay are caused by mechanisms other than photon emission and are, therefore, often called "non-radiative rates", which can include:
dynamic collisional quenching, near-field dipole-dipole interaction (or resonance energy transfer), internal conversion, and intersystem crossing. Thus, if the rate of any pathway changes, both the excited state lifetime and the fluorescence quantum yield will be affected.
Fluorescence quantum yields are measured by comparison to a standard. The quinine salt "quinine sulfate" in a sulfuric acid solution is a common fluorescence standard.
Lifetime.
The fluorescence lifetime refers to the average time the molecule stays in its excited state before emitting a photon. Fluorescence typically follows first-order kinetics:
where formula_10 is the concentration of excited state molecules at time formula_11, formula_12 is the initial concentration and formula_13 is the decay rate or the inverse of the fluorescence lifetime. This is an instance of exponential decay. Various radiative and non-radiative processes can de-populate the excited state. In such case the total decay rate is the sum over all rates:
where formula_15 is the total decay rate, formula_16 the radiative decay rate and formula_17 the non-radiative decay rate. It is similar to a first-order chemical reaction in which the first-order rate constant is the sum of all of the rates (a parallel kinetic model). If the rate of spontaneous emission, or any of the other rates are fast, the lifetime is short. For commonly used fluorescent compounds, typical excited state decay times for photon emissions with energies from the UV to near infrared are within the range of 0.5 to 20 nanoseconds. The fluorescence lifetime is an important parameter for practical applications of fluorescence such as fluorescence resonance energy transfer and Fluorescence-lifetime imaging microscopy.
Jablonski diagram.
The Jablonski diagram describes most of the relaxation mechanisms for excited state molecules. The diagram alongside shows how fluorescence occurs due to the relaxation of certain excited electrons of a molecule.
Fluorescence anisotropy.
Fluorophores are more likely to be excited by photons if the transition moment of the fluorophore is parallel to the electric vector of the photon. The polarization of the emitted light will also depend on the transition moment. The transition moment is dependent on the physical orientation of the fluorophore molecule. For fluorophores in solution this means that the intensity and polarization of the emitted light is dependent on rotational diffusion. Therefore, anisotropy measurements can be used to investigate how freely a fluorescent molecule moves in a particular environment.
Fluorescence anisotropy can be defined quantitatively as 
where formula_19 is the emitted intensity parallel to polarization of the excitation light and formula_20 is the emitted intensity perpendicular to the polarization of the excitation light.
Fluorence.
Strongly fluorescent pigments often have an unusual appearance which is often described colloquially as a "neon color." This phenomenon was termed "Farbenglut" by Hermann von Helmholtz and "fluorence" by Ralph M. Evans. It is generally thought to be related to the high brightness of the color relative to what it would be as a component of white. Fluorescence shifts energy in the incident illumination from shorter wavelengths to longer (such as blue to yellow) and thus can make the fluorescent color appear brighter (more saturated) than it could possibly be by reflection alone.
Rules.
There are several general rules that deal with fluorescence. Each of the following rules has exceptions but they are useful guidelines for understanding fluorescence (these rules do not necessarily apply to two-photon absorption).
Kasha–Vavilov rule.
The Kasha–Vavilov rule dictates that the quantum yield of luminescence is independent of the wavelength of exciting radiation. This occurs because excited molecules usually decay to the lowest vibrational level of the excited state before fluorescence emission takes place. The Kasha–Vavilov rule does not always apply and is violated severely in many simple molecules. A somewhat more reliable statement, although still with exceptions, would be that the fluorescence spectrum shows very little dependence on the wavelength of exciting radiation.
Mirror image rule.
For many fluorophores the absorption spectrum is a mirror image of the emission spectrum. This is known as the mirror image rule and is related to the Franck–Condon principle which states that electronic transitions are vertical, that is energy changes without distance changing as can be represented with a vertical line in Jablonski diagram. This means the nucleus does not move and the vibration levels of the excited state resemble the vibration levels of the ground state.
Stokes shift.
In general, emitted fluorescent light has a longer wavelength and lower energy than the absorbed light. This phenomenon, known as Stokes shift, is due to energy loss between the time a photon is absorbed and when it is emitted. The causes and magnitude of Stokes shift can be complex and are dependent on the fluorophore and its environment. However, there are some common causes. It is frequently due to non-radiative decay to the lowest vibrational energy level of the excited state. Another factor is that the emission of fluorescence frequently leaves a fluorophore in a higher vibrational level of the ground state.
Fluorescence in nature.
There are many natural compounds that exhibit fluorescence, and they have a number of applications. Some deep-sea animals, such as the greeneye, use fluorescence.
Biofluorescence vs. bioluminescence vs. biophosphorescence.
Biofluorescence.
Biofluorescence is the absorption of electromagnetic wavelengths from the visible light spectrum by fluorescent proteins in a living organism, and the reemission of that light at a lower energy level. This causes the light that is re-emitted to be a different color than the light that is absorbed. Stimulating light excites an electron, raising energy to an unstable level. This instability is unfavorable, so the energized electron is returned to a stable state almost as immediately as it becomes unstable. This return to stability corresponds with the release of excess energy in the form of fluorescent light. This emission of light is only observable when the stimulant light is still providing light to the organism/object and is typically yellow, pink, orange, red, green, or purple. Biofluorescence is often confused with the following forms of biotic light, bioluminescence and biophosphorescence.
Bioluminescence.
Bioluminescence differs from biofluorescence in that it is the natural production of light by chemical reactions within an organism, whereas biofluorescence is the absorption and reemission of light from the environment.
Biophosphorescence.
Biophosphorescence is similar to biofluorescence in its requirement of light wavelengths as a provider of excitation energy. The difference here lies in the relative stability of the energized electron. Unlike with biofluorescence, here the electron retains stability, emitting light that continues to “glow-in-the-dark” even long after the stimulating light source has been removed.
Mechanisms of biofluorescence.
Epidermal chromatophores.
Pigment cells that exhibit fluorescence are called fluorescent chromatophores, and function somatically similar to regular chromatophores. These cells are dendritic, and contain pigments called fluorosomes. These pigments contain fluorescent proteins are activated by K+ (potassium) ions, and it is their movement, aggregation, and dispersion within the fluorescent chromatophore that cause directed fluorescence patterning. Fluorescent cells are innervated the same as other chromatphores, like melanophores, pigment cells that contain melanin. Short term fluorescent patterning and signaling is controlled by the nervous system. Fluorescent chromatophores can be found in the skin (e.g. in fish) just below the epidermis, amongst other chromatophores.
Epidermal fluorescent cells in fish also respond to hormonal stimuli by the α–MSH and MCH hormones much the same as melanophores. This suggests that fluorescent cells may be have color changes throughout the day that coincide with their circadian rhythm. Fish may also be sensitive to cortisol induced stress responses to environmental stimuli, such as interaction with a predator or engaging in a mating ritual.
Phylogenetics.
Evolutionary origins.
It is suspected by some scientists that GFPs and GFP like proteins began as electron donors activated by light. These electrons were then used for reactions requiring light energy. Functions of fluorescent proteins, such as protection from the sun, conversion of light into different wavelengths, or for signaling are thought to have evolved secondarily.
The incidence of fluorescence across the tree of life is widespread, and has been studied most extensively in a phylogenetic sense in fish. The phenomenon appears to have evolved multiple times in multiple taxa such as in the anguilliformes (eels), gobioidei (gobies and cardinalfishes), and tetradontiformes (triggerfishes), along with the other taxa discussed later in the article. Fluorescence is highly genotypically and phenotypically variable even within ecosystems, in regards to the wavelengths emitted, the patterns displayed, and the intensity of the fluorescence. Generally, the species relying upon camouflage exhibit the greatest diversity in fluorescence, likely because camouflage is one of the most common uses of fluorescence.
Adaptive functions.
Currently, relatively little is known about the functional significance of fluorescence and fluorescent proteins. However, it is suspected that biofluorescence may serve important functions in signaling and communication, mating, lures, camouflage, UV protection and antioxidation, photoacclimation, dinoflagellate regulation, and in coral health.
Aquatic biofluorescence.
Water absorbs light of long wavelengths, so less light from these wavelengths reflects back to reach the eye. Therefore, warm colors from the visual light spectrum appear less vibrant at increasing depths. Water scatters light of shorter wavelengths, meaning cooler colors dominate the visual field in the photic zone. Light intensity decreases 10 fold with every 75 m of depth, so at depths of 75 m, light is 10% as intense as it is on the surface, and is only 1% as intense at 150 m as it is on the surface. Because the water filters out the wavelengths and intensity of water reaching certain depths, different proteins, because of the wavelengths and intensities of light they are capable of absorbing, are better suited to different depths. Theoretically, some fish eyes can detect light as deep as 1000 m. At these depths of the aphotic zone, the only sources of light are organisms themselves, giving off light through chemical reactions in a process called bioluminescence.
Fluorescence is simply defined as the absorption of electromagnetic radiation at one wavelength and its reemission at another, lower energy wavelength. Thus any type of fluorescence depends on the presence of external sources of light. Biologically functional fluorescence is found in the photic zone, where there is not only enough light to cause biofluorescence, but enough light for other organisms to detect it. The visual field in the photic zone is naturally blue, so colors of fluorescence can be detected as bright reds, oranges, yellows, and greens. Green is the most commonly found color in the biofluorescent spectrum, yellow the second most, orange the third, and red is the rarest. Fluorescence can occur in organisms in the aphotic zone as a byproduct of that same organism’s bioluminescence. Some biofluorescence in the aphotic zone is merely a byproduct of the organism’s tissue biochemistry and does not have a functional purpose. However, some cases of functional and adaptive significance of biofluorescence in the aphotic zone of the deep ocean is an active area of research.
Photic zone.
Fish.
Bony fishes living in shallow water, due to living in a colorful environment, generally have good color vision. Thus, in shallow-water fishes, red, orange, and green fluorescence most likely serves as a means of communication with conspecifics, especially given the great phenotypic variance of the phenomenon.
Many fish that exhibit biofluorescence, such as sharks, lizardfish, scorpionfish, wrasses, and flatfishes, also possess yellow intraocular filters. Yellow intraocular filters in the lenses and cornea of certain fishes function as long-pass filters, thus enabling the species that possess them to visualize and potentially exploit fluorescence to enhance visual contrast and patterns that are unseen to other fishes and predators that lack this visual specialization. Fishes that possess the necessary yellow intraocular filters for visualizing biofluorescence potentially exploit a light signal from members of it or a similar functional role. Biofluorescent patterning was especially prominent in cryptically patterned fishes possessing complex camouflage, and that many of these lineages also possess yellow long-pass intraocular filters that could enable visualization of such patterns.
Another adaptive use of fluorescence is to generate red light from the ambient blue light of the photic zone to aid vision. Red light can only be seen across short distances due to attenuation of red light wavelengths by water. Many fish species that fluoresce are small, group-living, or benthic/aphotic, and have conspicuous patterning. This patterning is caused by fluorescent tissue and is visible to other members of the species, however the patterning is invisible at other visual spectra. These intraspecific fluorescent patterns also coincide with intra-species signaling. The patterns present in ocular rings to indicate directionality of an individual’s gaze, and along fins to indicate directionality of an individual’s movement. Current research suspects that this red fluorescence is used for private communication between members of the same species. Due to the prominence of blue light at ocean depths, red light and light of longer wavelengths are muddled, and many predatory reef fish have little to no sensitivity for light at these wavelengths. Fish such as the fairy wrasse that have developed visual sensitivity to longer wavelengths are able to display red fluorescent signals that give a high contrast to the blue environment and are conspicuous to conspecifics in short ranges, yet are relatively invisible to other common fish that have reduced sensitivities to long wavelengths. Thus, fluorescence can be used as adaptive signaling and intra-species communication in reef fish.
Additionally, it is suggested that fluorescent tissues that surround an organism’s eyes are used to convert blue light from the photic zone or green bioluminescence in the aphotic zone into red light to aid vision.
Coral.
Fluorescence serves a wide variety of functions in coral. Fluorescent proteins in corals may contribute to photosynthesis by converting otherwise unusable wavelengths of light into ones for which the coral’s symbiotic algae are able to conduct photosynthesis. Also, the proteins may fluctuate in number as more or less light becomes available as a means of photoacclimation. Similarly, these fluorescent proteins may possess antioxidant capacities to eliminate oxygen radicals produced by photosynthesis. Finally, through modulating photosynthesis, the fluorescent proteins may also serve as a means of regulating the activity of the coral’s photosynthetic algal symbionts.
Cephalopods.
"Alloteuthis subulata" and "Loligo vulgaris", two types of nearly transparent squid, have fluorescent spots above their eyes. These spots reflect incident light, which may serve as a means of camouflage, but also for signaling to other squids for schooling purposes.
Jellyfish.
Another, well-studied example of biofluorescence in the ocean is the hydrozoan Aequorea victoria. This jellyfish lives in the photic zone off the west coast of North America and was identified as a carrier of green fluorescent protein (GFP) by Osamu Shimomura. The gene for these green fluorescent proteins has been isolated and is scientifically significant because it is widely used in genetic studies to indicate the expression of other genes.
Mantis shrimp.
Several species of mantis shrimp, which are stomatopod crustaceans, including "Lysiosquillina glabriuscula", have yellow fluorescent markings along their antennal scales and carapace (shell) that males present during threat displays to predators and other males. The display involves raising the head and thorax, spreading the striking appendages and other maxillipeds, and extending the prominent, oval antennal scales laterally, which makes the animal appear larger and accentuates its yellow fluorescent markings. Furthermore, as depth increases, mantis shrimp fluorescence accounts for a greater part of the visible light available. During mating rituals, mantis shrimp actively fluoresce, and the wavelength of this fluorescence matches the wavelengths detected by their eye pigments.
Aphotic zone.
Siphonophores.
"Siphonophorae" is an order of marine animals from the phylum Hydrozoa that are consist of a specialized medusoid and polyp zooid. Some siphonophores, including the genus Erenna that live in the aphotic zone between depths of 1600 m and 2300 m, exhibit yellow to red fluorescence in the photophores of their tentacle-like tentilla. This fluorescence occurs as a by-product of bioluminescence from these same photophores. The siphonophores exhibit the fluorescence in a flicking pattern that is used as a lure to attract prey.
Dragonfish.
The predatory deep-sea dragonfish "Malacosteus niger", the closely related "Aristostomias" genus and the species "Pachystomias microdon" are capable of harnessing the blue light emitted from their own bioluminescence to generate red biofluorescence from suborbital photophores. This red fluorescence is invisible to other animals, which allows these dragonfish extra light at dark ocean depths without attracting or signaling predators.
Terrestrial biofluorescence.
Butterflies.
Swallowtail ("Papilio") butterflies have complex systems for emitting fluorescent light. Their wings contain pigment-infused crystals that provide directed fluorescent light. These crystals function to produce fluorescent light best when they absorb radiance from sky-blue light (wavelength about 420 nm). The wavelengths of light that the butterflies see the best correspond to the absorbance of the crystals in the butterfly's wings. This likely functions to enhance the capacity for signaling.
Parrots.
Parrots have fluorescent plumage that may be used in mate signaling. A study using mate-choice experiments on budgerigars ("Melopsittacus undulates") found compelling support for fluorescent sexual signaling, with both males and females significantly preferring birds with the fluorescent experimental stimulus. This study suggests that the fluorescent plumage of parrots is not simply a by-product of pigmentation, but instead an adapted sexual signal. Considering the intricacies of the pathways that produce fluorescent pigments, there may be significant costs involved. Therefore, individuals exhibiting strong fluorescence may be honest indicators of high individual quality, since they can deal with the associated costs.
Arachnids.
Spiders fluoresce under UV light and possess a huge diversity of fluorophores. Remarkably, spiders are the only known group in which fluorescence is “taxonomically widespread, variably expressed, evolutionarily labile, and probably under selection and potentially of ecological importance for intraspecific and interspecific signaling.” A study by Andrews et al. (2007) reveals that fluorescence has evolved multiple times across spider taxa, with novel fluorophores evolving during spider diversification. In some spiders, ultraviolet cues are important for predator-prey interactions, intraspecific communication, and camouflaging with matching fluorescent flowers. Differing ecological contexts could favor inhibition or enhancement of fluorescence expression, depending upon whether fluorescence helps spiders be cryptic or makes them more conspicuous to predators. Therefore, natural selection could be acting on expression of fluorescence across spider species.
Scorpions also fluoresce.
Flowers.
The "Mirabilis jalapa" flower contains violet, fluorescent betacyanins and yellow, fluorescent betaxanthins. Under white light, parts of the flower containing only betaxanthins appear yellow, but in areas where both betaxanthins and betacyanins are present, the visible fluorescence of the flower is faded due to internal light-filtering mechanisms. Fluorescence was previously suggested to play a role in pollinator attraction, however, it was later found that the visual signal by fluorescence is negligible compared to the visual signal of light reflected by the flower.
Abiotic fluorescence.
Gemology, mineralogy and geology.
Gemstones, minerals, may have a distinctive fluorescence or may fluoresce differently under short-wave ultraviolet, long-wave ultraviolet, visible light, or X-rays.
Many types of calcite and amber will fluoresce under shortwave UV, longwave UV and visible light. Rubies, emeralds, and diamonds exhibit red fluorescence under long-wave UV, blue and sometimes green light; diamonds also emit light under X-ray radiation.
Fluorescence in minerals is caused by a wide range of activators. In some cases, the concentration of the activator must be restricted to below a certain level, to prevent quenching of the fluorescent emission. Furthermore, the mineral must be free of impurities such as iron or copper, to prevent quenching of possible fluorescence. Divalent manganese, in concentrations of up to several percent, is responsible for the red or orange fluorescence of calcite, the green fluorescence of willemite, the yellow fluorescence of esperite, and the orange fluorescence of wollastonite and clinohedrite. Hexavalent uranium, in the form of the uranyl cation, fluoresces at all concentrations in a yellow green, and is the cause of fluorescence of minerals such as autunite or andersonite, and, at low concentration, is the cause of the fluorescence of such materials as some samples of hyalite opal. Trivalent chromium at low concentration is the source of the red fluorescence of ruby. Divalent europium is the source of the blue fluorescence, when seen in the mineral fluorite. Trivalent lanthanides such as terbium and dysprosium are the principal activators of the creamy yellow fluorescence exhibited by the yttrofluorite variety of the mineral fluorite, and contribute to the orange fluorescence of zircon. Powellite (calcium molybdate) and scheelite (calcium tungstate) fluoresce intrinsically in yellow and blue, respectively. When present together in solid solution, energy is transferred from the higher-energy tungsten to the lower-energy molybdenum, such that fairly low levels of molybdenum are sufficient to cause a yellow emission for scheelite, instead of blue. Low-iron sphalerite (zinc sulfide), fluoresces and phosphoresces in a range of colors, influenced by the presence of various trace impurities.
Crude oil (petroleum) fluoresces in a range of colors, from dull-brown for heavy oils and tars through to bright-yellowish and bluish-white for very light oils and condensates. This phenomenon is used in oil exploration drilling to identify very small amounts of oil in drill cuttings and core samples.
Organic liquids.
Organic solutions such anthracene or stilbene, dissolved in benzene or toluene, fluoresce with ultraviolet or gamma ray irradiation. The decay times of this fluorescence are of the order of nanoseconds, since the duration of the light depends on the lifetime of the excited states of the fluorescent material, in this case anthracene or stilbene.
Atmosphere.
Fluorescence is observed in the atmosphere when the air is under energetic electron bombardment. In cases such as the natural aurora, high-altitude nuclear explosions, and rocket-borne electron gun experiments, the molecules and ions formed have a fluorescent response to light.
Applications of fluorescence.
Lighting.
The common fluorescent lamp relies on fluorescence. Inside the glass tube is a partial vacuum and a small amount of mercury. An electric discharge in the tube causes the mercury atoms to emit ultraviolet light. The tube is lined with a coating of a fluorescent material, called the "phosphor", which absorbs the ultraviolet and re-emits visible light. Fluorescent lighting is more energy-efficient than incandescent lighting elements. However, the uneven spectrum of traditional fluorescent lamps may cause certain colors to appear different than when illuminated by incandescent light or daylight. The mercury vapor emission spectrum is dominated by a short-wave UV line at 254 nm (which provides most of the energy to the phosphors), accompanied by visible light emission at 436 nm (blue), 546 nm (green) and 579 nm (yellow-orange). These three lines can be observed superimposed on the white continuum using a hand spectroscope, for light emitted by the usual white fluorescent tubes. These same visible lines, accompanied by the emission lines of trivalent europium and trivalent terbium, and further accompanied by the emission continuum of divalent europium in the blue region, comprise the more discontinuous light emission of the modern trichromatic phosphor systems used in many compact fluorescent lamp and traditional lamps where better color rendition is a goal.
Fluorescent lights were first available to the public at the 1939 New York World's Fair. Improvements since then have largely been better phosphors, longer life, and more consistent internal discharge, and easier-to-use shapes (such as compact fluorescent lamps). Some high-intensity discharge (HID) lamps couple their even-greater electrical efficiency with phosphor enhancement for better color rendition.
White light-emitting diodes (LEDs) became available in the mid-1990s as LED lamps, in which blue light emitted from the semiconductor strikes phosphors deposited on the tiny chip. The combination of the blue light that continues through the phosphor and the green to red fluorescence from the phosphors produces a net emission of white light.
Glow sticks sometimes utilize fluorescent materials to absorb light from the chemiluminescent reaction and emit light of a different color.
Analytical chemistry.
Many analytical procedures involve the use of a fluorometer, usually with a single exciting wavelength and single detection wavelength. Because of the sensitivity that the method affords, fluorescent molecule concentrations as low as 1 part per trillion can be measured.
Fluorescence in several wavelengths can be detected by an array detector, to detect compounds from HPLC flow. Also, TLC plates can be visualized if the compounds or a coloring reagent is fluorescent. Fluorescence is most effective when there is a larger ratio of atoms at lower energy levels in a Boltzmann distribution. There is, then, a higher probability of excitement and release of photons by lower-energy atoms, making analysis more efficient.
Spectroscopy.
Usually the setup of a fluorescence assay involves a light source, which may emit many different wavelengths of light. In general, a single wavelength is required for proper analysis, so, in order to selectively filter the light, it is passed through an excitation monochromator, and then that chosen wavelength is passed through the sample cell. After absorption and re-emission of the energy, many wavelengths may emerge due to Stokes shift and various electron transitions. To separate and analyze them, the fluorescent radiation is passed through an emission monochromator, and observed selectively by a detector.
Biochemistry and medicine.
Fluorescence in the life sciences is used generally as a non-destructive way of tracking or analysis of biological molecules by means of the fluorescent emission at a specific frequency where there is no background from the excitation light, as relatively few cellular components are naturally fluorescent (called intrinsic or autofluorescence).
In fact, a protein or other component can be "labelled" with an extrinsic fluorophore, a fluorescent dye that can be a small molecule, protein, or quantum dot, finding a large use in many biological applications.
The quantification of a dye is done with a spectrofluorometer and finds additional applications in:
Forensics.
Fingerprints can be visualized with fluorescent compounds such as ninhydrin. Blood and other substances are sometimes detected by fluorescent reagents, like fluorescein. Fibers, and other materials that may be encountered in forensics or with a relationship to various collectibles, are sometimes fluorescent.
Mechanical engineering.
Fluorescent penetrant inspection is used to find cracks and other defects on the surface of a part. Dye tracing, using fluorescent dyes, is used to find leaks in liquid and gas plumbing systems.
Signage.
Fluorescent colors are frequently used in signage, particularly road signs. Fluorescent colors are generally recognizable at longer ranges than their non-fluorescent counterparts, with fluorescent orange being particularly noticeable. This property has led to its frequent use in safety signs and labels.
Optical brighteners.
Fluorescent compounds are often used to enhance the appearance of fabric and paper, causing a "whitening" effect. A white surface treated with an optical brightener can emit more visible light than that which shines on it, making it appear brighter. The blue light emitted by the brightener compensates for the diminishing blue of the treated material and changes the hue away from yellow or brown and toward white. Optical brighteners are used in laundry detergents, high brightness paper, cosmetics, high-visibility clothing and more.

</doc>
<doc id="11556" url="https://en.wikipedia.org/wiki?curid=11556" title="Fundamental theorem of arithmetic">
Fundamental theorem of arithmetic

In number theory, the fundamental theorem of arithmetic, also called the unique factorization theorem or the unique-prime-factorization theorem, states that every integer greater than 1 either is prime itself or is the product of prime numbers, and that this product is unique, up to the order of the factors. For example,
1200 = 2 × 3 × 5 = 3 × 2 × 2 × 2 × 2 × 5 × 5 = 5 × 2 × 3 × 2 × 5 × 2 × 2 = etc.
The theorem is stating two things: first, that 1200 "can" be represented as a product of primes, and second, no matter how this is done, there will always be four 2s, one 3, two 5s, and no other primes in the product.
The requirement that the factors be prime is necessary: factorizations containing composite numbers may not be unique (e.g. 12 = 2 × 6 = 3 × 4).
This theorem is one of the main reasons why 1 is not considered a prime number: if 1 were prime, the factorization would not be unique, as, for example, 
History.
Book VII, propositions 30 and 32 of Euclid's Elements is essentially the statement and proof of the fundamental theorem.
Proposition 30 is referred to as Euclid's lemma. And it is the key in the proof of the fundamental theorem of arithmetic.
Proposition 31 is derived from proposition 30.
Proposition 32 is derived from proposition 31.
Article 16 of Gauss' "Disquisitiones Arithmeticae" is an early modern statement and proof employing modular arithmetic.
Applications.
Canonical representation of a positive integer.
Every positive integer "n" > 1 can be represented in exactly one way as a product of prime powers:
where "p" < "p" < ... < "p" are primes and the α are positive integers. This representation is commonly extended to all positive integers, including one, by the convention that the empty product is equal to 1 (the empty product corresponds to "k" = 0).
This representation is called the canonical representation of "n", or the standard form of "n".
Note that factors "p" = 1 may be inserted without changing the value of "n" (e.g. 1000 = 2×3×5).<br>In fact, any positive integer can be uniquely represented as an infinite product taken over all the positive prime numbers,
where a finite number of the "n" are positive integers, and the rest are zero. Allowing negative exponents provides a canonical form for positive rational numbers.
Arithmetic operations.
The canonical representation, when it is known, is convenient for easily computing products, gcd, and lcm:
However, as Integer factorization of large integers is much harder than computing their product, gcd or lcm, these formulas have, in practice, a limited usage.
Arithmetical functions.
Many arithmetical functions are defined using the canonical representation. In particular, the values of additive and multiplicative functions are determined by their values on the powers of prime numbers.
Proof.
The proof uses Euclid's lemma ("Elements" VII, 30): if a prime "p" divides the product of two natural numbers "a" and "b", then either "p" divides "a" or "p" divides "b" (or both).
Existence.
We need to show that every integer greater than 1 is a product of primes.
By induction: assume it is true for all numbers between 1 and "n". If "n" is prime, there is nothing more to prove (a prime is a trivial product of primes, a "product" with only one factor). Otherwise, there are integers "a" and "b", where "n" = "ab" and 1 < "a" ≤ "b" < "n".
By the induction hypothesis,
"a" = "p""p"..."p"
and
"b" = "q""q"..."q" are products of primes. But then
"n" = "ab" = "p""p"..."p""q""q"..."q" is a product of primes.
Uniqueness.
Assume that "s" > 1 is the product of prime numbers in two different ways:
We must show "m" = "n" and that the "q" are a rearrangement of the "p".
By Euclid's lemma, "p" must divide one of the "q"; relabeling the "q" if necessary, say that "p" divides "q". But "q" is prime, so its only divisors are itself and 1. Therefore, "p" = "q", so that
Reasoning the same way, "p" must equal one of the remaining "q". Relabeling again if necessary, say "p" = "q". Then
This can be done for each of the "m" "p"'s, showing that "m" ≤ "n" and every "p" is a "q". Applying the same argument with the formula_9's and formula_10's reversed shows "n" ≤ "m" (hence "m" = "n") and every "q" is a "p".
Elementary proof of uniqueness.
The fundamental theorem of arithmetic can also be proved without using Euclid's lemma, as follows:
Assume that "s" > 1 is the smallest positive integer which is the product of prime numbers in two different ways. If "s" were prime then it would factor uniquely as itself, so there must be at least two primes in each factorization of "s":
If any "p" = "q" then, by cancellation, "s"/"p" = "s"/"q" would be another positive integer, different from s, which is greater than 1 and also has two distinct factorizations. But "s"/"p" is smaller than "s", meaning "s" would not actually be the smallest such integer. Therefore every "p" must be distinct from every "q".
Without loss of generality, take "p" < "q" (if this is not already the case, switch the "p" and "q" designations.) Consider
and note that 1 < "q" ≤ "t" < "s". Therefore "t" must have a unique prime factorization. By rearrangement we see,
Here "u" = (("p" ... "p") - ("q" ... "q")) is positive, for if it were negative or zero then so would be its product with "p", but that product equals "t" which is positive. So "u" is either 1 or factors into primes. In either case, "t" = "p""u" yields a prime factorization of "t", which we know to be unique, so "p" appears in the prime factorization of "t".
If ("q" - "p") equaled 1 then the prime factorization of "t" would be all "q"'s, which would preclude "p" from appearing. Thus ("q" - "p") is not 1, but is positive, so it factors into primes: ("q" - "p") = ("r" ... "r"). This yields a prime factorization of
which we know is unique. Now, "p" appears in the prime factorization of "t", and it is not equal to any "q", so it must be one of the "r"'s. That means "p" is a factor of ("q" - "p"), so there exists a positive integer "k" such that "p""k" = ("q" - "p"), and therefore
But that means "q" has a proper factorization, so it is not a prime number. This contradiction shows that "s" does not actually have two different prime factorizations. As a result, there is no smallest positive integer with multiple prime factorizations, hence all positive integers greater than 1 factor uniquely into primes.
Generalizations.
The first generalization of the theorem is found in Gauss's second monograph (1832) on biquadratic reciprocity. This paper introduced what is now called the ring of Gaussian integers, the set of all complex numbers "a" + "bi" where "a" and "b" are integers. It is now denoted by formula_16 He showed that this ring has the four units ±1 and ±"i", that the non-zero, non-unit numbers fall into two classes, primes and composites, and that (except for order), the composites have unique factorization as a product of primes.
Similarly, in 1844 while working on cubic reciprocity, Eisenstein introduced the ring formula_17, where formula_18   formula_19 is a cube root of unity. This is the ring of Eisenstein integers, and he proved it has the six units formula_20 and that it has unique factorization.
However, it was also discovered that unique factorization does not always hold. An example is given by formula_21. In this ring one has
Examples like this caused the notion of "prime" to be modified. In formula_21 it can be proven that if any of the factors above can be represented as a product, e.g. 2 = "ab", then one of "a" or "b" must be a unit. This is the traditional definition of "prime". It can also be proven that none of these factors obeys Euclid's lemma; e.g.
2 divides neither (1 + √−5) nor (1 − √−5) even though it divides their product 6. In algebraic number theory 2 is called irreducible in formula_21 (only divisible by itself or a unit) but not prime in formula_21 (if it divides a product it must divide one of the factors). The mention of formula_21 is required because 2 is prime and irreducible in formula_16 Using these definitions it can be proven that in any ring a prime must be irreducible. Euclid's classical lemma can be rephrased as "in the ring of integers formula_28 every irreducible is prime". This is also true in formula_28 and formula_30 but not in formula_31
The rings in which factorization into irreducibles is essentially unique are called unique factorization domains. Important examples are polynomial rings over the integers or over a field, Euclidean domains and principal ideal domains.
In 1843 Kummer introduced the concept of ideal number, which was developed further by Dedekind (1876) into the modern theory of ideals, special subsets of rings. Multiplication is defined for ideals, and the rings in which they have unique factorization are called Dedekind domains.
There is a version of unique factorization for ordinals, though it requires some additional conditions to ensure uniqueness.
References.
The "Disquisitiones Arithmeticae" has been translated from Latin into English and German. The German edition includes all of his papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.
The two monographs Gauss published on biquadratic reciprocity have consecutively numbered sections: the first contains §§ 1–23 and the second §§ 24–76. Footnotes referencing these are of the form "Gauss, BQ, § "n"". Footnotes referencing the "Disquisitiones Arithmeticae" are of the form "Gauss, DA, Art. "n"".
These are in Gauss's "Werke", Vol II, pp. 65–92 and 93–148; German translations are pp. 511–533 and 534–586 of the German edition of the "Disquisitiones".

</doc>
<doc id="11558" url="https://en.wikipedia.org/wiki?curid=11558" title="Flamenco">
Flamenco

flamenco () is an artform native to the Spanish regions of Andalusia, Extremadura and Murcia. It includes "cante" (singing), "toque" (guitar playing), "baile" (dance) and "jaleo" (vocalizations and "palmas" (handclapping) and "pitos" (finger snapping)). 
First mentioned in literature in 1774, the genre originates in Andalusian music and dance styles. Flamenco is strongly associated with the gitanos (Romani people of Spain) - however, unlike Romani music of eastern Europe, the style is distinctively Andalusian and the fusion of the various cultures of southern Spain is clearly perceptible in Flamenco music. Although there are many theories on its influences and origins, the most widespread highlights a Morisco heritage, the cultural melting pot that was Andalusia at the time (Andalusians, Moors, Castilian settlers, Romanis and Jews) fostering its development over time. Flamenco music, as a theatrical representation of Andalusian musical tradition, was first recorded in the late 18th century but the genre underwent a dramatic development in the late 19th century.
In recent years, flamenco has become popular all over the world and is taught in many non-Hispanic countries, especially United States and Japan. In Japan, there are more flamenco academies than there are in Spain. On November 16, 2010, UNESCO declared flamenco one of the Masterpieces of the Oral and Intangible Heritage of Humanity.
Etymology.
There are many suggestions for the origin of the word "flamenco" as a musical term (summarized below) but no solid evidence for any of them. The word was not recorded as a musical and dance term until the late 18th century.
The Spanish word "flamenco" could have been a derivative of "fire" or "flame", as it is connected to the 'Cante' and the dance's strong, passionate nature. The word "flamenco" may have come to be used for certain behaviour in general, which could possibly have come to be applied to the Gitano players and performers.
Another theory, proposed by Andalusian historian Blas Infante in his 1933 book "Orígenes de lo Flamenco y Secreto del Cante Jondo" suggests that the word "flamenco" comes from the Hispano-Arabic term "fellah mengu", meaning "expelled peasant"; Infante argued that this term referred to the ethnic Andalusians of the Islamic faith, the Moriscos, who in order to avoid forced exile and religious persecution, joined with the Roma newcomers.
"Palos".
"Palos" (formerly known as "cantes") are flamenco styles, classified by criteria such as rhythmic pattern, mode, chord progression, stanzaic form and geographic origin. There are over 50 different "palos" although some are rarely performed; only about a dozen of these palos are commonly played. Some are sung unaccompanied while others usually have guitar or other accompaniment. Some forms are danced while others are not. Some are reserved for men and others for women while some may be performed by either, though these traditional distinctions are breaking down: the "Farruca", for example, once a male dance, is now commonly performed by women too.
"Palos" traditionally fall into three classes: the most serious is known as "cante jondo" (or "cante grande"), while lighter, frivolous forms are called "cante chico". Forms that do not fit either category are classed as "cante intermedio". "Cante jondo" has clear traces of Arabic and Spanish folk melodies, as well as vestiges of Byzantine, Christian and Jewish religious music.
These are the most known "Palos":
Music.
There are many great guitartists who have dedicated their professional expertise and been a part of the Flamenco scene, such as Paco Pena, Paco De Lucia, Ramon Montoya, Pepe Romero, Pepe Martinez and The Romeros to name a few. They are the backbone of helping to create the ambiance to this much loved tradition of Spanish song and dance.
Structure.
A typical flamenco recital with voice and guitar accompaniment, comprises a series of pieces (not exactly “songs”) in different palos. Each song of a set of verses (called "copla", "tercio", or "letras"), which are punctuated by guitar interludes called "falsetas". The guitarist also provides a short introduction which sets the tonality, compás and tempo of the cante. In some palos, these falsetas are also played with certain structures too; for example, the typical sevillanas is played in an AAB pattern, where A and B are the same falseta with only a slight difference in the ending.
Harmony.
Flamenco uses the Flamenco mode (which can also be described as the modern Phrygian mode ("modo frigio"), or a harmonic version of that scale with a major 3rd degree), in addition to the major and minor scales commonly used in modern Western music. The Phrygian mode occurs in "palos" such as soleá, most bulerías, siguiriyas, tangos and tientos.
A typical chord sequence, usually called the "Andalusian cadence" may be viewed as in a modified Phrygian: in E the sequence is Am–G–F–E. According to Manolo Sanlúcar "E" is here the tonic, F has the harmonic function of dominant while Am and G assume the functions of subdominant and mediant respectively.
Guitarists tend to use only two basic inversions or "chord shapes" for the tonic chord (music), the open 1st inversion E and the open 3rd inversion A, though they often transpose these by using a capo. Modern guitarists such as Ramón Montoya, have introduced other positions: Montoya himself started to use other chords for the tonic in the modern Dorian sections of several "palos"; F sharp for "tarantas", B for "granaínas" and A flat for the "minera". Montoya also created a new "palo" as a solo for guitar, the "rondeña" in C sharp with "scordatura". Later guitarists have further extended the repertoire of tonalities, chord positions and "scordatura".
There are also "palos" in major mode; most cantiñas and alegrías, guajiras, some "bulerías" and "tonás", and the "cabales" (a major type of "siguiriyas"). The minor mode is restricted to the "Farruca", the "milongas" (among "cantes de ida y vuelta"), and some styles of "tangos, bulerías", etc. In general traditional palos in major and minor mode are limited harmonically to two-chord (tonic–dominant) or three-chord (tonic–subdominant–dominant) progressions. (Rossy 1998:92) However modern guitarists have introduced chord substitution, transition chords, and even modulation.
"Fandangos" and derivative "palos" such as "malagueñas", "tarantas" and "cartageneras) are bimodal": guitar introductions are in Phrygian mode while the singing develops in major mode, modulating to Phrygian at the end of the stanza. (Rossy 1998:92)
Melody.
Dionisio Preciado, quoted by Sabas de Hoces established the following characteristics for the melodies of flamenco singing:
Musicologist Hipólito Rossy adds the following characteristics (Rossy 1997: 97):
Compás.
Compás is the Spanish word for metre or time signature (in classical music theory). It also refers to the rhythmic cycle, or layout, of a "palo".
The compás is fundamental to flamenco. Compás is most often translated as rhythm but it demands far more precise interpretation than any other Western style of music. If there is no guitarist available, the compás is rendered through hand clapping ("palmas") or by hitting a table with the knuckles. The guitarist uses techniques like strumming ("rasgueado") or tapping the soundboard ("golpe"). Changes of chords emphasize the most important downbeats.
Flamenco uses three basic counts or measures: Binary, Ternary and a form of a twelve-beat cycle that is unique to flamenco. There are also free-form styles including, among others, the tonás, saetas, malagueñas, tarantos, and some types of fandangos.
There are three types of 12-beat rhythms, which vary in their layouts, or use of accentuations: soleá, seguiriya and bulería.
The Bulerías is the emblematic palo of flamenco: today its 12-beat cycle is most often played with accents on the 3rd, 6th, 8th, 10th and 12th beats. The accompanying "palmas" are played in groups of 6 beats, giving rise to a multitude of counter-rhythms and percussive voices within the 12 beat compás.
Forms of flamenco expression.
Toque (guitar).
The origins, history and importance of the flamenco guitar is covered in the main Wikipedia entry for the Flamenco guitar
Cante (song).
The origins, history and importance of the cante is covered in the main Wikipedia entry for the cante flamenco.
Baile (dance).
"El baile flamenco" is known for its emotional intensity, proud carriage, expressive use of the arms and rhythmic stamping of the feet (similar to tap dance). As with any dance form, many different styles of flamenco have developed.
In the twentieth century, flamenco danced informally at gitano (Roma) weddings and celebrations in Spain was considered the most "authentic" form of flamenco. There is less virtuoso technique in gitano flamenco, but the music and steps are fundamentally the same. The arms are noticeably different from classical flamenco, curving around the head and body rather than extending, often with a bent elbow.
"Flamenco puro" is considered the form of performance flamenco closest to its gitano influences. In this style, the dance is always performed solo, and is improvised rather than choreographed. Some purists frown on castanets (even though they can be seen in many early 20th century photos of flamenco dancers).
"Classical flamenco" is the style most frequently performed by Spanish flamenco dance companies, tending to exhibit more clearly the characteristics derived from the Seguidilla, a traditional Spanish dance. It is danced largely in a proud and upright way. For women, the back is often held in a marked back bend. Unlike the more gitano influenced styles, there is little movement of the hips, the body is tightly held and the arms are long, like a ballet dancer. In fact many of the dancers in these companies have trained in ballet as well as flamenco. Flamenco has both influenced and been influenced by ballet, as evidenced by the fusion of the two created by 'La Argentinita' in the early part of the twentieth century and later, by Joaquín Cortés.
In the 1950s Jose Greco was one of most famous male Flamenco dancers, performing on stage worldwide and on television including the Ed Sullivan Show, and reviving the art almost singlehandedly.
Modern flamenco is a highly technical dance style requiring years of study. The emphasis for both male and female performers is on lightning-fast footwork performed with absolute precision. In addition, the dancer may have to dance while using props such as castanets, shawls and fans.
"Flamenco nuevo" is a recent style in flamenco, characterized by pared-down costumes (the men often dance bare-chested, and the women in plain jersey dresses). Props such as castanets, fans and shawls are rarely used. Dances are choreographed and include influences from other dance styles.
The flamenco most foreigners are familiar with is a style that was developed as a spectacle for tourists. To add variety, group dances are included and even solos are more likely to be choreographed. The frilly, voluminous spotted dresses are derived from a style of dress worn for the Sevillanas at the annual Feria in Seville.
In traditional flamenco, young people are not considered to have the emotional maturity to adequately convey the "duende" (soul) of the genre. Therefore, unlike other dance forms, where dancers turn professional early to take advantage of youth and strength, many flamenco dancers do not hit their peak until their thirties and will continue to perform into their fifties and beyond.

</doc>
<doc id="11561" url="https://en.wikipedia.org/wiki?curid=11561" title="Father Christmas">
Father Christmas

Father Christmas is the traditional English name for the personification of Christmas. Although now known as a Christmas gift-bringer, and normally considered to be synonymous with the US and international figure of Santa Claus, he was originally part of an unrelated and much older English folkloric tradition. The recognisably modern figure of the English Father Christmas developed in the late Victorian period, but Christmas had been personified for centuries before then.
English personifications of Christmas were first recorded the 15th century, with Father Christmas himself first appearing in the mid 17th century in the aftermath of the English Civil War. The Puritan-controlled English government had legislated to abolish Christmas, considering it papist, and had outlawed its traditional customs. Royalist political pamphleteers, linking the old traditions with their cause, adopted Old Father Christmas as the symbol of 'the good old days' of feasting and good cheer. Following the Restoration in 1660, Father Christmas's profile declined. His character was maintained during the late 18th and into the 19th century by the Christmas folk plays later known as mummers plays.
Until Victorian times, Father Christmas was concerned with adult feasting and merry-making. He had no particular connection with children, nor with the giving of presents, nocturnal visits, stockings or chimneys. But as later Victorian Christmases developed into child-centric family festivals, Father Christmas became a bringer of gifts. The popular American myth of Santa Claus arrived in England in the 1850s and Father Christmas started to take on Santa's attributes. By the 1880s the new customs had become established, with the nocturnal visitor sometimes being known as Santa Claus and sometimes as Father Christmas. He was often illustrated wearing a long red hooded gown trimmed with white fur.
Any residual distinctions between Father Christmas and Santa Claus largely faded away in the early years of the 20th century, and modern dictionaries consider the terms Father Christmas and Santa Claus to be synonymous.
Early midwinter celebrations.
The custom of merrymaking and feasting at Christmastide first appears in the historical record during the High Middle Ages (c 1000–1300). This almost certainly represented a continuation of pre-Christian midwinter celebrations in Britain of which - as the historian Ronald Hutton has pointed out - "we have no details at all". Personifications came later, and when they did they reflected the existing custom.
15th century - the first English personifications of Christmas.
The first known English personification of Christmas was associated with merry-making, singing and drinking. A carol attributed to Richard Smart, Rector of Plymtree from 1435 to 1477, has 'Sir Christemas' announcing the news of Christ's birth and encouraging his listeners to drink: "Buvez bien par toute la compagnie, / Make good cheer and be right merry, / And sing with us now joyfully: Nowell, nowell."
Many late medieval Christmas customs incorporated both sacred and secular themes. In Norwich in January 1443, at a traditional battle between the flesh and the spirit (represented by Christmas and Lent), John Gladman, crowned and disguised as 'King of Christmas', rode behind a pageant of the months "disguysed as the seson requird" on a horse decorated with tinfoil.
16th century - feasting, entertainment and music.
In most areas of England the archaic word 'Yule' had been replaced by 'Christmas' by the 11th century, but in some regions 'Yule' survived as the normal dialect term . The City of York maintained an annual St Thomas's Day celebration of "The Riding of Yule and his Wife" which involved a figure representing Yule who carried bread and a leg of lamb. In 1572 the riding was suppressed on the orders of the Archbishop, who complained of the "undecent and uncomely disguising" which drew multitudes of people from divine service.
Such personifications, illustrating the medieval fondness for pageantry and symbolism, extended throughout the Tudor and Stuart periods with Lord of Misrule characters, sometimes called 'Captain Christmas', 'Prince Christmas' or 'The Christmas Lord', presiding over feasting and entertainment in grand houses, university colleges and Inns of Court."
In his allegorical play "Summer's Last Will and Testament", written in about 1592, Thomas Nashe introduces for comic effect a miserly Christmas character who refuses to keep the feast. He is reminded by Summer of the traditional role that he ought to be playing: "Christmas, how chance thou com’st not as the rest, / Accompanied with some music, or some song? / A merry carol would have graced thee well; / Thy ancestors have used it heretofore."
17th century - religion and politics.
Puritan criticisms.
Early 17th century writers used the techniques of personification and allegory as a means of defending Christmas from attacks by radical Protestants.
Responding to a perceived decline in the levels of Christmas hospitality provided by the gentry, Ben Jonson in "Christmas his Masque" (1616) dressed his Old Christmas in out of date fashions: "attir'd in round Hose, long Stockings, a close Doublet, a high crownd Hat with a Broach, a long thin beard, a Truncheon, little Ruffes, white shoes, his Scarffes, and Garters tyed crosse." Surrounded by guards, Christmas asserts his rightful place in the Protestant Church and protests against attempts to exclude him: "Why Gentlemen, doe you know what you doe? ha! would you ha'kept me out? Christmas, old Christmas? Christmas of London, and Captaine Christmas? ... they would not let me in: I must come another time! a good jeast, as if I could come more then once a yeare; why, I am no dangerous person, and so I told my friends, o'the Guard. I am old Gregorie Christmas still, and though I come out of Popes-head-alley as good a Protestant, as any i'my Parish".
The stage directions to "The Springs Glorie", a 1638 court masque by Thomas Nabbes, state that "Christmas is personated by an old reverend Gentleman in a furr'd gown and cappe &c." Shrovetide and Christmas dispute precedence, and Shrovetide issues a challenge: "I say Christmas you are past date, you are out of the Almanack. Resigne, resigne". To which Christmas responds: "Resigne to thee! I that am the King of good cheere and feasting, though I come but once a yeare to raigne over bak't, boyled, roast and plum-porridge, will have being in despight of thy lard-ship."
This sort of character was to feature repeatedly over the next 250 years in pictures, stage plays and folk dramas. Initially known as 'Sir Christmas' or 'Lord Christmas', he later became increasingly referred to as 'Father Christmas'.
Puritan revolution - enter 'Father Christmas'.
The rise of puritanism led to accusations of popery in connection with pre-reformation Christmas traditions. When the Puritans took control of government in the mid-1640s they made concerted efforts to abolish Christmas and to outlaw its traditional customs. For 15 years from around 1644, before and during the Interregnum of 1649-1660, the celebration of Christmas in England was forbidden. The suppression was given greater legal weight from June 1647 when parliament passed an "Ordinance for Abolishing of Festivals" which formally abolished Christmas in its entirely, along with the other traditional church festivals of Easter and Whitsun.
It was in this context that Royalist pamphleteers linked the old traditions of Christmas with the cause of King and Church, while radical puritans argued for the suppression of Christmas both in its religious and its secular aspects. In the hands of Royalist pamphlet writers, Old Father Christmas served as the symbol and spokesman of 'the good old days' of feasting and good cheer, and it became popular for Christmastide's defenders to present him as lamenting past times.
"The Arraignment, Conviction and Imprisoning of Christmas" (January 1646) describes a discussion between a town crier and a Royalist gentlewoman enquiring after Old Father Christmas who is 'is gone from hence'. Its anonymous author, a parliamentarian, presents Father Christmas in a negative light, concentrating on his allegedly popish attributes: "For age, this hoarie headed man was of great yeares, and as white as snow ; he entred the Romish Kallender time out of mind; is old ... ; he was full and fat as any dumb Docter of them all. He looked under the consecrated Laune sleeves as big as Bul-beefe ... but, since the catholike liquor is taken from him, he is much wasted, so that he hath looked very thin and ill of late ... But yet some other markes that you may know him by, is that the wanton Women dote after him; he helped them to so many new Gownes, Hatts, and Hankerches, and other fine knacks, of which he hath a pack on his back, in which is good store of all sorts, besides the fine knacks that he got out of their husbands’ pockets for household provisions for him. He got Prentises, Servants, and Schollars many play dayes, and therefore was well beloved by them also, and made all merry with Bagpipes, Fiddles, and other musicks, Giggs, Dances, and Mummings".
The character of 'Christmas' (also called 'father Christmas') speaks in a pamphlet of 1652, immediately after the English Civil War, published anonymously by the satirical Royalist poet John Taylor: "The Vindication of Christmas or, His Twelve Yeares' Observations upon the Times". A frontispiece illustrates an old, bearded Christmas in a brimmed hat, a long open robe and undersleeves. Christmas laments the pitiful quandary he has fallen into since he came into "this headlesse countrey". "I was in good hope that so long a misery would have made them glad to bid a merry Christmas welcome. But welcome or not welcome, I am come...". He concludes with a verse: "Lets dance and sing, and make good chear, / For Christmas comes but once a year".
In 1658 Josiah King published "The Examination and Tryall of Old Father Christmas" (the earliest citation for the specific term 'Father Christmas' recognised by the Oxford English Dictionary). King portrays Father Christmas as a white-haired old man who is on trial for his life based on evidence laid against him by the Commonwealth. Father Christmas's counsel mounts the defence: "Me thinks my Lord, the very Clouds blush, to see this old Gentleman thus egregiously abused. if at any time any have abused themselves by immoderate eating, and drinking or otherwise spoil the creatures, it is none of this old mans fault; neither ought he to suffer for it; for example the Sun and the Moon are by the heathens worship’d are they therefore bad because idolized? so if any abuse this old man, they are bad for abusing him, not he bad, for being abused". The jury acquits.
Restoration.
Following the Restoration in 1660, most traditional Christmas celebrations were revived, although as these were no longer contentious the historic documentary sources become fewer.
In 1678 Josiah King reprinted his 1658 pamphlet with additional material. In this version, the restored Father Christmas is looking better: " look't so smug and pleasant, his cherry cheeks appeared through his thin milk white locks, like lushing Roses vail'd with snow white Tiffany ... the true Emblem of Joy and Innocence".
18th century - a low profile.
As interest in Christmas customs waned, Father Christmas's profile declined. He still continued to be regarded as Christmas's presiding spirit, although his occasional earlier associations with the Lord of Misrule died out with the disappearance of the Lord of Misrule himself. The historian Ronald Hutton notes that "after a taste of genuine misrule during the Interregnum nobody in the ruling elite seems to have had any stomach for simulating it". Hutton also found that "patterns of entertainment at late Stuart Christmases are remarkably timeless n nothing very much seems to have altered during the next century either". The diaries of 18th and early 19th century clergy take little note of any Christmas traditions.
In "The Country Squire", a play of 1732, Old Christmas is depicted as someone who is rarely-found: a generous squire. The character Scabbard remarks that "Men are grown so ... stingy, now-a-days, that there is scarce One, in ten Parishes, makes any House-keeping. ... Squire Christmas ... keeps a good House, or else I do not know of One besides". When invited to spend Christmas with the squire, he comments "I will ... else I shall forget Christmas, for aught I see". Similar opinions were expressed in "Round About Our Coal Fire ... with some curious Memories of Old Father Christmas; Shewing what Hospitality was in former Times, and how little there remains of it at present" (1734, reprinted with Father Christmas subtitle 1796).
David Garrick's popular 1774 Drury Lane production "A Christmas Tale" included a personified Christmas character who announced "Behold a personage well known to fame; / Once lov'd and honour'd — Christmas is my name! /.../ I, English hearts rejoic'd in days of yore; / for new strange modes, imported by the score, / You will not sure turn Christmas out of door!"
Early records of folk plays.
By the late 18th century Father Christmas had become a stock character in the Christmas folk plays later known as mummers plays. During the following century they became probably the most widespread of all calendar customs. Hundreds of villages had their own their mummers who performed traditional plays around the neighbourhood, especially at the big houses. Father Christmas appears as a character in plays of the Southern England type, featuring in 46 of the surviving 18th and 19th century texts. His ritual opening speech is characterised by variants of a couplet closely reminiscent of John Taylor's "But welcome or not welcome, I am come..." from 1652.
The oldest extant speech is from Truro, Cornwall in the late 1780s:
19th century - revival.
During the Victorian period Christmas customs enjoyed a significant revival, including the figure of Father Christmas himself as the emblem of 'good cheer'. His physical appearance at this time became more variable, and he was by no means always portrayed as the old and bearded figure imagined by 17th century writers.
'Merry England' view of Christmas.
In his poem "Marmion" of 1808 Walter Scott wrote
Scott's phrase Merry England has been adopted by historians to describe the romantic notion that there was a golden age of the English past, allegedly since lost, that was characterised by universal hospitality and charity. The notion had a profound influence on the way that popular customs were seen, and most of the 19th century writers who bemoaned the state of contemporary Christmases were, at least to some extent, yearning for the mythical Merry England version.
Thomas Hervey’s "The Book of Christmas" (1836), illustrated by Robert Seymour, exemplifies this view. In Hervey's personification of the lost charitable festival, "Old Father Christmas, at the head of his numerous and uproarious family, might ride his goat through the streets of the city and the lanes of the village, but he dismounted to sit for some few moments by each man's hearth; while some one or another of his merry sons would break away, to visit the remote farm-houses or show their laughing faces at many a poor man's door". Seymour's illustration shows Old Christmas dressed in a fur gown, crowned with a holly wreath, and riding a yule goat.
In an extended allegory, Hervey imagines his contemporary Old Father Christmas as a white-bearded magician dressed in a long robe and crowned with holly. His children are identified as Roast Beef (Sir Loin) and his faithful squire or bottle-holder Plum Pudding; the slender figure of Wassail with her fount of perpetual youth; a 'tricksy spirit' who bears the bowl and is on the best of terms with the Turkey; Mumming; Misrule, with a feather in his cap; the Lord of Twelfth Night under a state-canopy of cake and wearing his ancient crown; Saint Distaff looking like an old maid ("she used to be a sad romp; but her merriest days we fear are over"); Carol singing; the Waits; and the twin-faced Janus.
Hervey ends by lamenting the lost "uproarious merriment" of Christmas, and calls on his readers "who know anything of the 'old, old, very old, gray-bearded gentleman' or his family to aid us in our search after them; and with their good help we will endeavor to restore them to some portion of their ancient honors in England".
Father Christmas or Old Christmas, represented as a jolly-faced bearded man often surrounded by plentiful food and drink, started to appear regularly in illustrated magazines of the 1840s. He was dressed in a variety of costumes and usually had holly on his head, as in these illustrations from the Illustrated London News:
Charles Dickens's 1843 novel "A Christmas Carol" was highly influential, and has been credited both with reviving interest in Christmas in England and with shaping the themes attached to it. A famous image from the novel is John Leech's illustration of the 'Ghost of Christmas Present'. Although not explicitly named Father Christmas, the character wears a holly wreath, is shown sitting among food, drink and wassail bowl, and is dressed in the traditional loose furred gown - but in green rather than the red that later become ubiquitous.
Later 19th century mumming.
Old Father Christmas continued to make his annual appearance in Christmas folk plays throughout the 19th century, his appearance varying considerably according to local custom. Sometimes, as in as Hervey's book of 1836, he was portrayed (below left) as a hunchback.
One unusual portrayal (below centre) was described several times by William Sandys between 1830 and 1852, all in essentially the same terms: "Father Christmas is represented as a grotesque old man, with a large mask and comic wig, and a huge club in his hand." This representation is considered by the folklore scholar Peter Millington to be the result of the southern Father Christmas replacing the northern Beelzebub character in a hybrid play. A spectator to a Worcestershire version of the "St George" play in 1856 noted that "Beelzebub was identical with Old Father Christmas".
A mummers play mentioned in "The Book of Days" (1864) opened with "Old Father Christmas, bearing, as emblematic devices, the holly bough, wassail-bowl, &c". A corresponding illustration (below right) shows the character wearing not only a holly wreath but also a gown with a hood.
In a Hampshire folk play of 1860 Father Christmas is portrayed as a disabled soldier: " wore breeches and stockings, carried a begging-box, and conveyed himself upon two sticks; his arms were striped with chevrons like a noncommissioned officer".
In the latter part of the 19th century and the early years of the next the folk play tradition in England rapidly faded, and the plays almost died out after the First World War taking their ability to influence the character of Father Christmas with them.
Father Christmas as gift-giver.
In pre-Victorian personifications, Father Christmas had been concerned essentially with adult feasting and games. He had no particular connection with children, nor with the giving of presents. But as Victorian Christmases developed into family festivals centred mainly on children, Father Christmas started to be associated with the giving of gifts.
The Cornish Quaker diarist Barclay Fox relates a family party given on 26 December 1842 that featured "the venerable effigies of Father Christmas with scarlet coat & cocked hat, stuck all over with presents for the guests, by his side the old year, a most dismal & haggard old beldame in a night cap and spectacles, then 1843 he new yea, a promising baby asleep in a cradle".
Santa Claus crosses the Atlantic.
The figure of Santa Claus had originated in the USA, drawing at least partly upon Dutch St Nicolas traditions. In 1821, an illustrated poem entitled "A New-Year’s Present, to the Little Ones from Five to Twelve" had been published in New York. The poem described 'Old Santeclaus' on a reindeer sleigh, bringing presents for good children and a "long, black birchen rod" for use on the bad ones. In 1823 came the famous poem "A Visit from St. Nicholas", usually attributed to the New York writer Clement Clarke Moore, which developed the character further. Moore's poem became immensely popular and Santa Claus customs, initially localized in the Dutch American areas, were becoming general in the United States by the middle of the century.
The January 1848 edition of "Howitt's Journal of Literature and Popular Progress", published in London, carried an illustrated article entitled "New Year's Eve in Different Nations". This noted that one of the chief features of the American New Year's Eve was a custom carried over from the Dutch, namely the arrival of Santa Claus with gifts for the children. Santa Claus is "no other than the Pelz Nickel of Germany ... the good Saint Nicholas of Russia ... He arrives in Germany about a fortnight before Christmas, but as may be supposed from all the visits he has to pay there, and the length of his voyage, he does not arrive in America, until this eve".
From 1851 advertisements began appearing in UK newspapers for a new transatlantic passenger service to and from New York aboard the Eagle Line's ship "Santa Claus", and returning visitors and emigrants to the UK on this and other vessels will have been familiar with the American figure. There were some early adoptions in the UK. A Scottish reference has Santa Claus leaving presents on New Year's Eve 1852, with children "hanging their stockings up on each side of the fire-place, in their sleeping apartments, at night, and waiting patiently till morning, to see what Santa Claus puts into them during their slumbers". In Ireland in 1853, on the other hand, presents were being left on Christmas Eve according to a character in a newspaper short story who says "... tomorrow will be Christmas. What will Santa Claus bring us?" A poem published in Belfast in 1858 includes the lines "The children sleep; they dream of him, the fairy, / Kind Santa Claus, who with a right good will / Comes down the chimney with a footstep airy ..."
"A Visit from St. Nicholas" was published in England in December 1853 in "Notes and Queries". An explanatory note states that the St Nicholas figure is known as Santa Claus in New York State and as Krishkinkle in Pennsylvania.
1854 marked the first English publication of "Carl Krinkin; or, The Christmas Stocking" by the popular American author Susan Warner. The novel was published three times in London in 1854-5, and there were several later editions. Characters in the book include both Santa Claus (complete with sleigh, stocking and chimney), leaving presents on Christmas Eve and - separately - Old Father Christmas. The Stocking of the title tells of how in England, "a great many years ago", it saw Father Christmas enter with his traditional refrain "Oh! here come I, old father Christmas, welcome or not ..." He wore a crown of yew and ivy, and he carried a long staff topped with holly-berries. His dress "was a long brown robe which fell down about his feet, and on it were sewed little spots of white cloth to represent snow".
Merger with Santa Claus.
As the US-inspired customs became popular in England, Father Christmas started to take on Santa's attributes. His costume became more standardised, and although depictions often still showed him carrying holly, the holly crown became rarer and was often replaced with a hood. It still remained common, though, for Father Christmas and Santa Claus to be distinguished, and as late as the 1890s there were still examples of the old-style Father Christmas appearing without any of the new American features.
Appearances in public.
The blurring of public roles occurred quite rapidly. In an 1854 newspaper description of the public Boxing Day festivities in Luton, Bedfordshire, a gift-giving Father Christmas/Santa Claus figure was already being described as 'familiar': "On the right-hand side was Father Christmas's bower, formed of evergreens, and in front was the proverbial Yule log, glistening in the snow ... He wore a great furry white coat and cap, and a long white beard and hair spoke to his hoar antiquity. Behind his bower he had a large selection of fancy articles which formed the gifts he distributed to holders of prize tickets from time to time during the day ... Father Christmas bore in his hand a small Christmas tree laden with bright little gifts and bon-bons, and altogether he looked like the familiar Santa Claus or Father Christmas of the picture book". Discussing the shops of Regent Street in London, another writer noted in December of that year that "you may fancy yourself in the abode of Father Christmas or St. Nicholas himself".
During the 1860s and 70s Father Christmas became a popular subject on Christmas cards, where he was shown in many different costumes. Sometimes he gave presents and sometimes received them.
An illustrated article of 1866 explained the concept of "The Cave of Mystery". In an imagined children's party this took the form of a recess in the library which evoked "dim visions of the cave of Aladdin" and was "well filled ... with all that delights the eye, pleases the ear, or tickles the fancy of children". The young guests "tremblingly await the decision of the improvised Father Christmas, with his flowing grey beard, long robe, and slender staff".
From the 1870s onwards, Christmas shopping had begun to evolve as a separate seasonal activity, and by the late 19th century it had become an important part of the English Christmas. The purchasing of toys, especially from the new department stores, became strongly associated with the season. The first retail Christmas Grotto was set up in JP Robert's store in Stratford, London in December 1888, and shopping arenas for children - often called 'Christmas Bazaars' - spread rapidly during the 1890s and 1900s, helping to assimilate Father Christmas/Santa Claus into society. 
Sometimes the two characters continued to be presented as separate, as in a procession at the Olympia Exhibition of 1888 in which both Father Christmas and Santa Claus took part, with Little Red Riding Hood and other children's characters in between. At other times the characters were conflated: in 1885 Mr Williamson's London Bazaar in Sunderland was reported to be a "Temple of juvenile delectation and delight. In the well-lighted window is a representation of Father Christmas, with the printed intimation that 'Santa Claus is arranging within.' "
Even after the appearance of the store grotto, it was still not firmly established who should hand out gifts at parties. A writer in the "Illustrated London News" of December 1888 suggested that a Sibyl should dispense gifts from 'snow cave', but a little over a year later she had changed her recommendation to a 'magic cave' - a mysterious tent extemporised with sheets and fairy lamps - inhabited by a gypsy who should call the children "from the group gathered together in delightful half-terror, to enter one by one to receive hei present". This was said to be "Less trouble than decking the tree, and having the advantage of novelty".
The same writer suggested that, alternatively, the hostess could "have Father Christmas arrive, towards the end of the evening, with a sack of toys on his back. He must have a white head and a long white beard, of course. Wig and beard can be cheaply hired from a theatrical theatrical costumier, or may be improvised from tow in case of need. He should wear a greatcoat down to his heels, liberally sprinkled with flour as though he had just come from that land of ice where Father Christmas is supposed to reside." "
As secret nocturnal visitor.
The nocturnal visitor aspect of the American myth took much longer to become naturalised. From the 1840s it had been accepted readily enough that presents were left for children by unseen hands overnight on Christmas Eve, but the receptacle was a matter of debate, as was the nature of the visitor. Dutch tradition had St Nicholas leaving presents in shoes laid out on 6 December, while in France shoes were filled by Père Noël. The older shoe custom and the newer America stocking custom trickled only slowly into Britain, with writers and illustrators remaining uncertain for many years. Although the stocking eventually triumphed, the shoe custom had still not been forgotten by 1901 when an illustration entitled "Did you see Santa Claus, Mother?" was accompanied by the verse "Her Christmas dreams / Have all come true; / Stocking o'erflows / and likewise shoe."
Before Santa Claus and the stocking became ubiquitous, one English tradition had been for fairies to visit on Christmas Eve to leave gifts in shoes set out in front of the fireplace.
Aspects of the American Santa Claus myth were sometimes adopted in isolation and applied to Father Christmas. In a short fantasy piece, the editor of the "Cheltenham Chronicle" in 1867 dreamt of being seized by the collar by Father Christmas, "rising up like a Geni of the Arabian Nights ... and moving rapidly through the "aether"". Hovering over the roof of a house, Father Christmas cries 'Open Sesame' to have the roof roll back to disclose the scene within.
It was not until the 1870s that the tradition of a nocturnal Santa Claus began to be adopted by ordinary people. A poem "The Baby's Stocking" that was syndicated to local newspapers in 1871 took it for granted that readers would be familiar with the custom, and would understand the joke that the stocking might be missed as "Santa Claus wouldn't be looking for anything half so small". On the other hand, when "The Preston Guardian" published its poem "Santa Claus and the Children" in 1877 it felt the need to include a long preface explaining exactly who Santa Claus was.
Folklorists and antiquarians were not, it seems, familiar with the new local customs and Ronald Hutton notes that in 1879 the newly formed Folk-Lore Society, ignorant of American practices, was still "excitedly trying to discover the source of the new belief".
In January 1879 the antiquarian Edwin Lees wrote to "Notes and Queries" seeking information about an observance he had he had been told about by 'a country person': "On Christmas Eve, when the inmates of a house in the country retire to bed, all those desirous of a present place a stocking outside the door of their bedroom, with the expectation that some mythical being called Santiclaus will fill the stocking or place something within it before the morning. This is of course well known, and the master of the house does in reality place a Christmas gift secretly in each stocking; but the giggling girls in the morning, when bringing down their presents, affect to say that Santiclaus visited and filled the stockings in the night. From what region of the earth or air this benevolent Santiclaus takes flight I have not been able to ascertain ..." Lees received several responses, linking 'Santiclaus' with the continental traditions of St Nicholas and 'Petit Jesus' (Christkind), but no-one mentioned Father Christmas and no-one was correctly able to identify the American source.
By the 1880s the American myth had become firmly established in the popular English imagination, the nocturnal visitor sometimes being known as Santa Claus and sometimes as Father Christmas (often complete with a hooded robe). An 1881 poem imagined a child awaiting a visit from Santa Claus and asking "Will he come like Father Christmas, / Robed in green and beard all white? / Will he come amid the darkness? / Will he come at all tonight?" The French writer Max O'Rell, who evidently thought the custom was established in the England of 1883, explained that Father Christmas "descend par la cheminée, pour remplir de bonbons et de joux les bas que les enfants ont suspendus au pied du lit." 'comes down the chimney, to fill with sweets and games the stockings that the children have hung from the foot of the bed'. And in her poem "Agnes: A Fairy Tale" (1891), Lilian M Bennett treats the two names as interchangeable: "Old Santa Claus is exceedingly kind, / but he won't come to Wide-awakes, you will find... / Father Christmas won't come if he can hear / You're awake. So to bed my bairnies dear." The commercial availability from 1895 of Tom Smith & Co's "Santa Claus Surprise Stockings" indicates how deeply the American myth had penetrated English society by the end of the century.
Representations of the developing character at this period were sometimes labelled 'Santa Claus' and sometimes 'Father Christmas', with a tendency for the latter still to include allusions to old-style associations with charity and with food and drink, as in several of these Punch illustrations:
20th century.
Any residual distinctions between Father Christmas and Santa Claus largely faded away in the early years of the new century, and it was reported in 1915 that "The majority of children to-day ... do not know of any difference between our old Father Christmas and the comparatively new Santa Claus, as, by both wearing the same garb, they have effected a happy compromise".
It took many years for authors and illustrators to agree that Father Christmas's costume should be portrayed as red - although that was always the most common colour - and he could sometimes be found in a gown of brown, green, blue or white. Mass media approval of the red costume came following a Coca-Cola advertising campaign that was launched in 1931.
Father Christmas's common form for much of the 20th century was described by his entry in the "Oxford English Dictionary". He is "the personification of Christmas as a benevolent old man with a flowing white beard, wearing a red sleeved gown and hood trimmed with white fur, and carrying a sack of Christmas presents". One of the OED's sources is a 1919 cartoon in "Punch", reproduced here. The caption reads:
In 1951 an editorial in "The Times" opined that while most adults may be under the impression that he Englis Father Christmas is home-bred, and is "a good insular John Bull old gentleman", many children, "led away ... by the false romanticism of sledges and reindeer", post letters to Norway addressed simply to Father Christmas or, "giving him a foreign veneer, Santa Claus".
Differences between the English and US representations were discussed in "The Illustrated London News" of 1985. The classic illustration by the US artist Thomas Nast was held to be "the authorised version of how Santa Claus should look - in America, that is." In Britain, people were said to stick to the older Father Christmas, with a long robe, large concealing beard, and boots similar to Wellingtons.
Father Christmas appeared in many 20th century English-language works of fiction, including J. R. R. Tolkien's "Father Christmas Letters", a series of private letters to his children written between 1920 and 1942 and first published in 1976. Other 20th century publications include C. S. Lewis's "The Lion, the Witch and the Wardrobe" (1950), Raymond Briggs's "Father Christmas" (1973), Debbie Macomber's "There's Something About Christmas" (2005), Robin Jones Gunn's "Father Christmas Series" (2007), Catherine Spencer's "A Christmas to Remember" (2007), and Richard Paul Evans's "The Gift" (2007). The character was also celebrated in popular song, including "I Believe in Father Christmas" by Greg Lake (1974) and "Father Christmas" by The Kinks (1977).
Modern dictionaries consider the terms Father Christmas and Santa Claus to be synonymous. The respective characters are now to all intents and purposes indistinguishable, although some people are still said to prefer the term 'Father Christmas' over 'Santa', nearly 150 years after Santa's arrival in England. According to "Brewer's Dictionary of Phrase and Fable" (19th edn, 2012), Father Christmas is considered to be " British rather than a US name for Santa Claus, associating him specifically with Christmas. The name carries a somewhat socially superior cachet and is thus preferred by certain advertisers."

</doc>
<doc id="11563" url="https://en.wikipedia.org/wiki?curid=11563" title="Federal jurisdiction (United States)">
Federal jurisdiction (United States)

The United States of America is a federal republic governed by the U.S. Constitution containing fifty states and a federal district which elect the President and Vice President, and having other territories and possessions in its national jurisdiction. This government is variously known as the Union, the United States, or the federal government. Federal jurisdiction refers to the legal scope of the government's powers. Under the Constitution and various treaties, the legal jurisdiction of the United States includes territories and territorial waters.
Legislative Branch.
One aspect of federal jurisdiction is the extent of legislative power. Under the Constitution, Congress has power to legislate only in the areas that are delegated to it. Under clause 17 however, Congress has power to "exercise exclusive Legislation in all cases whatsoever" over the federal district (Washington, D.C.) and other territory ceded to the federal government by the states, such as for military installations. 
Federal jurisdiction in this sense is important in criminal law because federal law does not supersede state criminal law. Congress has enacted the Assimilative Crimes Act (), which provides that any act that would have been a crime under the laws of the state in which a federal enclave is situated is also a federal crime. As most such enclaves are occupied by the military, military law is especially concerned with these enclaves, especially the issue of establishing who has jurisdiction and what type of jurisdiction. In such areas, the federal government may have proprietary jurisdiction (rights as landowner), concurrent jurisdiction (with federal and state law applicable), or exclusive jurisdiction over the land where an act was committed. Courts-martial involving military members subject to the Uniform Code of Military Justice apply regardless of location.
Article Four of the United States Constitution also states that the Congress has the power to enact laws "respecting the Territory or other Property belonging to the United States." Federal jurisdiction exists over any territory thus subject to laws enacted by the Congress.
Judicial branch.
The American legal system includes both state courts and federal courts. State courts hear cases involving state law, and such federal laws as are not restricted to hearing in federal courts. Federal courts may only hear cases where federal jurisdiction can be established. Specifically, the court must have both subject-matter jurisdiction over the matter of the claim and personal jurisdiction over the parties.
The Federal Courts are courts of limited jurisdiction, meaning that they only exercise powers granted to them by the Constitution and Federal Laws. There are several forms of subject-matter jurisdiction, but the two most commonly appealed to are federal-question jurisdiction and diversity jurisdiction. Federal question jurisdiction is available when the plaintiff raises a claim that arises under the laws, treaties, or Constitution of the United States, as opposed to claims arising under state law. By the "Well-Pleaded Complaint" rule, federal question jurisdiction is not available if the federal issue arises only as a defense to a state-law claim. Diversity jurisdiction, on the other hand, is available regarding state-law claims if every plaintiff is from a different state from every defendant (the requirement for so-called complete or total diversity) and the amount in controversy exceeds $75,000.
If a Federal Court has subject matter jurisdiction over one or more of the claims in a case, it has discretion to exercise ancillary jurisdiction over other state law claims. 
The Supreme Court has "cautioned that ... Court must take great care to 'resist the temptation' to express preferences about ertain types of case in the form of jurisdictional rules. Judges must strain to remove the influence of the merits from their jurisdictional rules. The law of jurisdiction must remain apart from the world upon which it operates".
Generally, when a case has successfully overcome the hurdles of standing, Case or Controversy and State Action, it will be heard by a trial court. The non-governmental party may raise claims or defenses relating to alleged constitutional violation(s) by the government. If the non-governmental party loses, the constitutional issue may form part of the appeal. Eventually, a petition for certiorari may be sent to the Supreme Court. If the Supreme Court grants certiorari and accepts the case, it will receive written briefs from each side (and any amici curiae or friends of the court—usually interested third parties with some expertise to bear on the subject) and schedule oral arguments. The Justices will closely question both parties. When the Court renders its decision, it will generally do so in a single majority opinion and one or more dissenting opinions. Each opinion sets forth the facts, prior decisions, and legal reasoning behind the position taken. The majority opinion constitutes binding precedent on all lower courts; when faced with very similar facts, they are bound to apply the same reasoning or face reversal of their decision by a higher court.

</doc>
<doc id="11564" url="https://en.wikipedia.org/wiki?curid=11564" title="Fossil Record">
Fossil Record

Fossil Record is a biannual peer-reviewed scientific journal covering palaeontology. It was established in 1998 as the Mitteilungen aus dem Museum für Naturkunde in Berlin, Geowissenschaftliche Reihe and originally published on behalf of the Museum für Naturkunde by Wiley-VCH; since 2014 it has been published by Copernicus Publications. The editors-in-chief are Martin Aberhan, Dieter Korn, and Florian Witzmann (Museum für Naturkunde).
Abstracting and indexing.
The journal is abstracted and indexed in the Science Citation Index Expanded, BIOSIS Previews, The Zoological Record, and Scopus. According to the "Journal Citation Reports", the journal has a 2013 impact factor of 0.913.

</doc>
<doc id="11569" url="https://en.wikipedia.org/wiki?curid=11569" title="Frequency modulation synthesis">
Frequency modulation synthesis

In audio and music, frequency modulation synthesis (or FM synthesis) is a form of audio synthesis where the timbre of a simple waveform (such as a square, triangle, or sawtooth) is changed by modulating its frequency with a modulator frequency that is also in the audio range, resulting in a more complex waveform and a different-sounding tone that can also be described as "gritty" if it is a thick and dark timbre. The frequency of an oscillator is altered or distorted, "in accordance with the amplitude of a modulating signal." 
FM synthesis can create both harmonic and inharmonic sounds. For synthesizing harmonic sounds, the modulating signal must have a harmonic relationship to the original carrier signal. As the amount of frequency modulation increases, the sound grows progressively more complex. Through the use of modulators with frequencies that are non-integer multiples of the carrier signal (i.e. non harmonic), atonal and tonal bell-like and percussive sounds can easily be created.
FM synthesis using analog oscillators may result in pitch instability. However, FM synthesis can also be implemented digitally, the latter proving to be more 'reliable' and is currently seen as standard practice. Digital FM synthesis (using the more frequency-stable phase modulation variant) was the basis of several commercial musical instruments beginning as early as 1977. The Synclavier I, manufactured by New England Digital Corporation beginning in 1977, included a 32-voice digital FM synthesizer. Yamaha's groundbreaking DX7 brought FM to the forefront of synthesis in the mid-1980s.
History.
The technique of the digital implementation of frequency modulation, which was developed by John Chowning (, cited in ) at Stanford University in 1967-68, was patented in 1975 and later licensed to Yamaha.
The implementation commercialized by Yamaha (US Patent 4018121 Apr 1977 or U.S. Patent 4,018,121) is actually based on phase modulation, but the results end up being equivalent mathematically as both are essentially a special case of QAM, with phase modulation simply making the implementation resilient against undesirable drift in frequency of carrier waves due to self-modulation or due to DC bias in the modulating wave.
As noted earlier, FM synthesis was the basis of some of the early generations of digital synthesizers, most notable being those from New England Digital Corporation and Yamaha. Yamaha's popular DX7 synthesizer was ubiquitous throughout the 1980s. Several other models by Yamaha provided variations and evolutions of FM synthesis during that decade.
Yamaha had patented its hardware implementation of FM in the 1980s, allowing it and New England Digital Corporation (under license from Yamaha) to nearly monopolize the market for that technology until the mid-1990s. Casio developed a related form of synthesis called phase distortion synthesis, used in its CZ range of synthesizers. It had a similar (but slightly differently derived) sound quality to the DX series. Don Buchla implemented FM on his instruments in the mid-1960s, prior to Yamaha's patent. His 158, 258 and 259 dual oscillator modules had a specific FM control voltage input, and the model 208 (Music Easel) had a modulation oscillator hard-wired to allow FM as well as AM of the primary oscillator. These early applications used analog oscillators, and this capability was also followed by other modular synthesizers and portable synthesizers including Minimoog and ARP Odyssey.
With the expiration of the Stanford University FM patent in 1995, digital FM synthesis can now be implemented freely by other manufacturers. The FM synthesis patent brought Stanford $20 million before it expired, making it (in 1994) "the second most lucrative licensing agreement in Stanford's history". FM today is mostly found in software-based synths such as FM8 by Native Instruments or Sytrus by Image-Line, but it has also been incorporated into the synthesis repertoire of some modern digital synthesizers, usually coexisting as an option alongside other methods of synthesis such as subtractive, sample-based synthesis, additive synthesis, and other techniques. The degree of complexity of the FM in such hardware synths may vary from simple 2-operator FM, to the highly flexible 6-operator engines of the Korg Kronos and Alesis Fusion, to creation of FM in extensively modular engines such as those in the latest synthesisers by Kurzweil Music Systems.
New hardware synths specifically marketed for their FM capabilities have not been seen since the Yamaha SY99 and FS1R, and even those marketed their highly powerful FM abilities as counterparts to sample-based synthesis and formant synthesis respectively. However, well-developed FM synthesis options are a feature of Nord Lead synths manufactured by Clavia, the Alesis Fusion range, the Korg Oasys and Kronos and the Modor NF-1. Various other synthesizers offer limited FM abilities to supplement their main engines.
Spectral analysis.
The spectrum generated by FM synthesis with one modulator is expressed as follows:
For modulation signal formula_1, the carrier signal is
If we were to ignore the constant phase terms on the carrier formula_3 and the modulator formula_4, finally we would get the following expression, as seen on and :
where formula_6 are angular frequencies (formula_7) of carrier and modulator, formula_8 is frequency modulation index, and amplitudes formula_9  is  formula_10-th , respectively.

</doc>
<doc id="11572" url="https://en.wikipedia.org/wiki?curid=11572" title="Font (disambiguation)">
Font (disambiguation)

Font may mean:

</doc>
<doc id="11574" url="https://en.wikipedia.org/wiki?curid=11574" title="Friedrich Bessel">
Friedrich Bessel

Friedrich Wilhelm Bessel (; 22 July 1784 – 17 March 1846) was a German astronomer, mathematician, physicist and geodesist. He was the first astronomer who determined reliable values for the distance from the sun to another star by the method of parallax. A special type of mathematical functions were named Bessel functions after Bessel's death, though they had originally been discovered by Daniel Bernoulli.
Life and Family.
Bessel was born in Minden, administrative center of Minden-Ravensberg, as second son of a civil servant. He is born into a large family in Germany. At the age of 14 Bessel was apprenticed to the import-export concern Kulenkamp at Bremen. The business's reliance on cargo ships led him to turn his mathematical skills to problems in navigation. This in turn led to an interest in astronomy as a way of determining longitude.
Bessel came to the attention of a major figure of German astronomy at the time, Heinrich Wilhelm Olbers, by producing a refinement on the orbital calculations for Halley's Comet in 1804, using old observation data taken from Thomas Harriot and Nathaniel Torporley in 1607.
Two years later Bessel left Kulenkamp and became Johann Hieronymus Schröter's assistant at Lilienthal Observatory near Bremen. There he worked on James Bradley's stellar observations to produce precise positions for some 3,222 stars.
In January 1810, at the age of 25, Bessel was appointed director of the newly founded Königsberg Observatory by King Frederick William III of Prussia. On the recommendation of fellow mathematician and physicist Carl Gauss he was awarded an honorary doctor degree from the University of Göttingen in March 1811.
In 1842 Bessel took part in the annual meeting of the British Association for the Advancement of Science in Manchester, accompanied by the geophysicist Georg Adolf Erman and the mathematician Carl Gustav Jacob Jacobi.
Bessel married Johanna, the daughter of the chemist and pharmacist Karl Gottfried Hagen who was the uncle of the physician and biologist Hermann August Hagen and the hydraulic engineer Gotthilf Hagen, the latter also Bessel's student and assistant from 1816 to 1818. The physicist Franz Ernst Neumann, Bessel's close companion and colleague, was married to Johanna Hagen's sister Florentine. Neumann introduced Bessel's exacting methods of measurement and data reduction into his mathematico-physical seminar, which he co-directed with Carl Gustav Jacob Jacobi at Königsberg. These exacting methods had a lasting impact upon the work of Neumann's students and upon the Prussian conception of precision in measurement.
Bessel had two sons and three daughters. His eldest daughter, Marie, married Georg Adolf Erman, member of the scholar family Erman. One of their sons was the renowned egyptologist Adolf Erman.
After several months of illness Bessel died in March 1846 at his observatory from retroperitoneal fibrosis.
Work.
While the observatory was still in construction Bessel elaborated the "Fundamenta Astronomiae" based on Bradley's observations. As a preliminary result he produced tables of atmospheric refraction that won him the Lalande Prize from the French Academy of Sciences in 1811. The Königsberg Observatory began operation in 1813.
Starting in 1819, Bessel determined the position of over 50,000 stars using a meridian circle from Reichenbach, assisted by some of his qualified students. The most prominent of them was Friedrich Wilhelm Argelander.
With this work done, Bessel was able to achieve the feat for which he is best remembered today: he is credited with being the first to use parallax in calculating the distance to a star. Astronomers had believed for some time that parallax would provide the first accurate measurement of interstellar distances—in fact, in the 1830s there was a fierce competition between astronomers to be the first to measure a stellar parallax accurately. In 1838 Bessel won the race, announcing that 61 Cygni had a parallax of 0.314 arcseconds; which, given the diameter of the Earth's orbit, indicated that the star is 10.3 ly away. Given the current measurement of 11.4 ly, Bessel's figure had an error of 9.6%. Nearly at the same time Friedrich Georg Wilhelm Struve and Thomas Henderson measured the parallaxes of Vega and Alpha Centauri.
As well as helping determine the parallax of 61 Cygni, Bessel's precise measurements using a new meridian circle from "Adolf Repsold" allowed him to notice deviations in the motions of Sirius and Procyon, which he deduced must be caused by the gravitational attraction of unseen companions.
His announcement of Sirius's "dark companion" in 1844 was the first correct claim of a previously unobserved companion by positional measurement, and eventually led to the discovery of Sirius B.
In 1824, Bessel developed a new method for calculation the circumstances of eclipses using the so-called Besselian elements. His method simplified the calculation to such an extent, without sacrificing accuracy, that it is still in use today.
Bessel's work in 1840 contributed in some degree to the discovery of Neptune in 1846 at Berlin Observatory, several months after Bessel's death. On Bessel's proposal (1825) the Prussian Academy of Sciences started the edition of the "Berliner Akademische Sternkarten" ("Berlin Academic Star Charts") as an international project. One unpublished new chart enabled Johann Gottfried Galle to find Neptune near the position calculated by LeVerrier in 1846.
In the second decade of the 19th century while studying the dynamics of 'many-body' gravitational systems, Bessel developed what are now known as Bessel functions. Critical for the solution of certain differential equations, these functions are used throughout both classical and quantum physics. 
Bessel is responsible for the correction to the formula for the sample variance estimator named in his honour. This is the use of the factor "n-1" in the denominator of the formula, rather than just "n". This occurs when the "sample mean" rather than the "population mean" is used to centre the data and since the sample mean is a linear combination of the data the residual to the sample mean overcounts the number of degrees of freedom by the number of constraint equations — in this case one.
An additional field of work was geodesy.
Bessel published a method for solving the main 
geodesic problem.
He was responsible for the survey of East Prussia which joined the Prussian and Russian triangulation networks
and he obtained an estimate of increased accuracy for the figure of the Earth,
nowadays referred to as the Bessel ellipsoid.
Despite lacking a university education, Bessel was a major figure in astronomy during his lifetime. He was elected as member of the French Academy of Sciences in 1812, the Prussian Academy of Sciences in 1815, foreign member of the Royal Swedish Academy of Sciences in 1823, and fellow of the Royal Society in 1828. In 1832, he was elected a Foreign Honorary Member of the American Academy of Arts and Sciences. Bessel won the Gold Medal of the Royal Astronomical Society twice in 1829 and 1841.
The largest crater in the Moon's Mare Serenitatis and the asteroid 1552 Bessel were named in his honour.

</doc>
<doc id="11577" url="https://en.wikipedia.org/wiki?curid=11577" title="FSB">
FSB

FSB may refer to:

</doc>
<doc id="11579" url="https://en.wikipedia.org/wiki?curid=11579" title="Fermi paradox">
Fermi paradox

The Fermi paradox or Fermi's paradox, named after Enrico Fermi, is the apparent contradiction between high estimates of the probability of the existence of extraterrestrial civilizations, such as in the Drake equation, and the lack of evidence for such civilizations. The basic points of the argument, made by physicists Enrico Fermi (1901–1954) and Michael H. Hart (born 1932), are:
According to this line of thinking, the Earth should have already been visited by extraterrestrial aliens. In an informal conversation, Fermi noted no convincing evidence of this, nor any signs of alien intelligence anywhere in the observable universe, leading him to ask, "Where is everybody?" There have been many attempts to explain the Fermi paradox, primarily suggesting either that intelligent extraterrestrial life is extremely rare, or proposing reasons that such civilizations have not contacted or visited Earth.
Basis.
The Fermi paradox is a conflict between arguments of scale and probability that seem to favor intelligent life being common in the universe, and a total lack of evidence of intelligent life having ever arisen anywhere other than on the Earth.
The first aspect of the Fermi paradox is a function of the scale or the large numbers involved: there are an estimated 200–400 billion stars in the Milky Way (2–4 ×10) and 70 sextillion (7×10) in the observable universe. Even if intelligent life occurs on only a minuscule percentage of planets around these stars, there might still be a great number of extant civilizations, and if the percentage were high enough it would produce a significant number of extant civilizations in the Milky Way. This creates the assumption that Earth is merely a typical planet.
The second aspect of the Fermi paradox is the argument of probability: given intelligent life's ability to overcome scarcity, and its tendency to colonize new habitats, it seems possible that at least some civilizations would be technologically advanced, seek out new resources in space, and colonize their own star system and, subsequently, surrounding star systems. Since there is no conclusive evidence on Earth or elsewhere in the known universe of other intelligent life after 13.8 billion years of the universe's history, we have a conflict requiring a resolution. Some examples of possible resolutions are that intelligent life is rarer than we think, that our assumptions about the general development or behavior of intelligent species are flawed, or, more radically, that our current scientific understanding of the nature of the universe itself is quite incomplete.
The Fermi paradox can be asked in two ways. The first is, "Why are no aliens or their artifacts found here on Earth, or in the Solar System?" If interstellar travel is possible, even the "slow" kind nearly within the reach of Earth technology, then it would only take from 5 million to 50 million years to colonize the galaxy. This is relatively brief on a geological scale, let alone a cosmological one. Since there are many stars older than the Sun, and since intelligent life might have evolved earlier elsewhere, the question then becomes why the galaxy has not been colonized already. Even if colonization is impractical or undesirable to all alien civilizations, large-scale "exploration" of the galaxy could be possible by probes. These might leave detectable artifacts in the solar system, such as old probes or evidence of mining activity, but none of these have been observed.
The second form of the question is "Why do we see no signs of intelligence elsewhere in the universe?" This version does not assume interstellar travel, but includes other galaxies as well. For distant galaxies, travel times may well explain the lack of alien visits to Earth, but a sufficiently advanced civilization could potentially be observable over a significant fraction of the size of the observable universe. Even if such civilizations are rare, the scale argument indicates they should exist somewhere at some point during the history of the universe, and since they could be detected from far away over a considerable period of time, many more potential sites for their origin are within range of our observation. It is unknown whether the paradox is stronger for our galaxy or for the universe as a whole.
Name.
In 1950, while working at Los Alamos National Laboratory, Fermi had a casual conversation while walking to lunch with colleagues Emil Konopinski, Edward Teller and Herbert York. The men discussed a recent spate of UFO reports and an Alan Dunn cartoon facetiously blaming the disappearance of municipal trashcans on marauding aliens. The conversation shifted to other subjects, until during lunch Fermi suddenly exclaimed, "Where are they?" (alternatively, "Where is everybody?"). Teller remembers, "The result of his question was general laughter because of the strange fact that in spite of Fermi's question coming from the clear blue, everybody around the table seemed to understand at once that he was talking about extraterrestrial life." Herbert York recalls that Fermi followed up on his comment with a series of calculations on the probability of Earth-like planets, the probability of life, the likely rise and duration of high technology, etc., and concluded that we ought to have been visited long ago and many times over.
Although Fermi's name is most commonly associated with the paradox, he was not the first to ask the question. An earlier implicit mention was by Konstantin Tsiolkovsky in an unpublished manuscript from 1933. He noted "people deny the presence of intelligent beings on the planets of the universe" because "(i) if such beings exist they would have visited Earth, and (ii) if such civilisations existed then they would have given us some sign of their existence." This was not a paradox for others, who took this to imply the absence of ETs, but it was for him, since he himself was a strong believer in extraterrestrial life and the possibility of space travel. Therefore, he speculated that mankind is not yet ready for higher beings to contact us. That Tsiolkovsky himself may not have been the first to discover the paradox is suggested by his above-mentioned reference to other people's reasons for denying the existence of Extraterrestrial Civilisations (ETCs).
Michael H. Hart published in 1975 a detailed examination of the paradox, which has since become a theoretical reference point for much of the research into what is now sometimes known as the Fermi-Hart paradox.
Other common names for "Fermi's question" ("Where are they?") include: the "Great Silence", and "silentium universi" (Latin for "silence of the universe").
Drake equation.
The theories and principles in the Drake equation are closely related to the Fermi paradox. The equation was formulated by Frank Drake in 1961 in an attempt to find a systematic means to evaluate the numerous probabilities involved in the existence of alien life. The speculative equation considers the rate of star formation in the galaxy; the fraction of stars with planets and the number per star that are habitable; the fraction of those planets which develop life; the fraction that develop "intelligent" life; the fraction that have detectable, technological intelligent life; and finally the length of time such communicable civilizations are detectable. The fundamental problem is that the last four terms are completely unknown, rendering statistical estimates impossible.
The Drake equation has been used by both optimists and pessimists, with wildly differing results. Carl Sagan, using optimistic numbers, suggested as many as one million communicating civilizations in the Milky Way in 1966, though he later suggested that the actual number could be far smaller. Frank Tipler and John D. Barrow used pessimistic numbers and concluded that the average number of civilizations in a galaxy is much less than one.
Empirical projects.
There are two parts of the Fermi paradox that rely on empirical evidence - that there are many potential sites for life, and that we see no evidence of life. The first point, that many suitable planets exist, was an assumption in Fermi's time but since has largely been settled by investigation into exoplanets.
The second part of the paradox, that we see no evidence of extraterrestrial life, is also an active field of scientific research. This includes both efforts to find any indication of life, and efforts specifically directed to finding intelligent life. These searches have been made since 1960, and several are ongoing.
Mainstream astronomy and SETI.
Although astronomers do not usually search for extraterrestrials, they might observe some phenomenon that cannot be explained without positing an intelligent civilization as the source. This has been suspected several times. For example, pulsars, when first discovered, were called little green men (LGM) because of the precise repetition of their pulses. In all cases, explanations with no need for intelligent life have been found for such observations, but the possibility of discovery remains. Proposed examples include asteroid mining that would change the appearance of debris disks around stars, or spectral lines from nuclear waste disposal in stars. An ongoing example is the unusual transit light curves of star KIC 8462852, where natural interpretations are not fully convincing. Although most likely a natural explanation will emerge, some scientists are investigating the remote possibility that it could be a sign of alien technology.
Electromagnetic emissions.
Radio technology and the ability to construct a radio telescope are presumed to be a natural advance for technological species, theoretically creating effects that might be detected over interstellar distances. The careful searching for non-natural radio emissions from space may lead to the detection of alien civilizations. Sensitive alien observers of the Solar System, for example, would note unusually intense radio waves for a G2 star due to Earth's television and telecommunication broadcasts. In the absence of an apparent natural cause, alien observers might infer the existence of a terrestrial civilization. It should be noted however that the most sensitive radio telescopes currently available on Earth would not be able to detect non-directional radio signals even at a fraction of a light-year, so it is questionable whether any such signals could be detected by an extraterrestrial civilization. Such signals could be either "accidental" by-products of a civilization, or deliberate attempts to communicate, such as the Arecibo message. A number of astronomers and observatories have attempted and are attempting to detect such evidence, mostly through the SETI organization. Several decades of SETI analysis have not revealed any unusually bright or meaningfully repetitive radio emissions, although there have been several candidate signals.
Electromagnetic emissions and information panspermia.
The strategy of decoding of electromagnetic emission has to be influenced by the concept of "information panspermia" coined in and which Webb (2015) attributed as Solution 23 of Fermi Paradox. It is shown that the human genome and hence the terrestrial life possess low Kolmogorov complexity and so the corresponding bit strings can be transmitted by Arecibo-type antenna to Galactic distances. Then the electromagnetic signals have to be analyzed on the subject of bit strings as traveling extraterrestrial life streams at von Neumann automata network.
Direct planetary observation.
Exoplanet detection and classification is a very active sub-discipline in astronomy, and the first possibly terrestrial planet discovered within a star's habitable zone was found in 2007. New refinements in exoplanet detection methods, and use of existing methods from space (such as the Kepler Mission, launched in 2009) are starting to detect and characterize Earth-size planets, and determine if they are within the habitable zones of their stars. Such observational refinements may allow us to better gauge how common potentially habitable worlds are.
Conjectures about interstellar probes.
Self-replicating probes could exhaustively explore a galaxy the size of the Milky Way in as little as half a million years. If even a single civilization in the Milky Way attempted this, such probes could spread throughout the entire galaxy. Another speculation for contact with an alien probe — one that would be trying to find human beings — is an alien Bracewell probe. Such hypothetical device would be an autonomous space probe whose purpose is to seek out and communicate with alien civilizations (as opposed to Von Neumann probes, which are usually described as purely exploratory). These were proposed as an alternative to carrying a slow speed-of-light dialogue between vastly distant neighbors. Rather than contending with the long delays a radio dialogue would suffer, a probe housing an artificial intelligence would seek out an alien civilization to carry on a close-range communication with the discovered civilization. The findings of such a probe would still have to be transmitted to the home civilization at light speed, but an information-gathering dialogue could be conducted in real time.
Attempts to find alien probes.
Direct exploration of the Solar System has yielded no evidence indicating a visit by aliens or their probes. Detailed exploration of areas of the Solar System where resources would be plentiful may yet produce evidence of alien exploration, though the entirety of the Solar System is vast and difficult to investigate. Attempts to signal, attract, or activate hypothetical Bracewell probes in Earth's vicinity have not succeeded.
Conjectures about stellar-scale artifacts.
In 1959, Freeman Dyson observed that every developing human civilization constantly increases its energy consumption, and, he conjectured, a civilization might try to harness a large part of the energy produced by a star. He proposed that a Dyson sphere could be a possible means: a shell or cloud of objects enclosing a star to absorb and utilize as much radiant energy as possible. Such a feat of astroengineering would drastically alter the observed spectrum of the star involved, changing it at least partly from the normal emission lines of a natural stellar atmosphere to those of black body radiation, probably with a peak in the infrared. Dyson speculated that advanced alien civilizations might be detected by examining the spectra of stars and searching for such an altered spectrum.
There have been some attempts to find evidence of the existence of Dyson spheres that would alter the spectra of their core stars. Direct observation of thousands of galaxies has shown no explicit evidence of artificial construction or modifications. In October 2015, there was some speculation that a pattern of light from star KIC 8462852, observed by the Kepler Space Telescope, could have been a result of Dyson sphere construction.
Hypothetical explanations for the paradox.
Extraterrestrial life is rare or non-existent.
Those who think that intelligent extraterrestrial life is (nearly) impossible argue that the conditions needed for the evolution of life — or at least the evolution of biological complexity — are rare or even unique to Earth. Under this assumption with some advocates, called the rare Earth hypothesis, a rejection of the mediocrity principle, complex multicellular life is regarded as exceedingly unusual.
The Rare Earth hypothesis argues that the evolution of biological complexity requires a host of fortuitous circumstances, such as a galactic habitable zone, a central star and planetary system having the requisite character, the circumstellar habitable zone, a right sized terrestrial planet, the advantage of a gas giant guardian like Jupiter and a large natural satellite, conditions needed to ensure the planet has a magnetosphere and plate tectonics, the chemistry of the lithosphere, atmosphere, and oceans, the role of "evolutionary pumps" such as massive glaciation and rare bolide impacts, and whatever led to the appearance of the eukaryote cell, sexual reproduction and the Cambrian explosion of animal, plant, and fungi phyla.
No other intelligent species have arisen.
It is possible that even if complex life is common, intelligence (and consequently civilizations) are not.
While there are remote sensing techniques which could perhaps detect life-bearing planets without relying on the signs of technology, none of them has any ability to tell if any detected life is intelligent. This is sometimes referred to as the "algae vs. alumnae" problem.
Intelligent alien species lack advanced technology.
It may be that while alien species with intelligence exist, they are primitive or have not reached the level of technological advancement necessary to communicate. Along with non-intelligent life, such civilizations would be also very difficult for humans to detect. 
To skeptics, the fact that in the history of life on the Earth only one species has developed a civilization to the point of being capable of spaceflight and radio technology, lends more credence to the idea that technologically advanced civilizations are rare in the universe.
It is the nature of intelligent life to destroy itself.
This is the argument that technological civilizations may usually or invariably destroy themselves before or shortly after developing radio or spaceflight technology. Possible means of annihilation are many, including nuclear war, biological warfare, accidental environmental contamination, or poorly designed artificial intelligence. This general theme is explored both in fiction and in scientific hypothesizing. Indeed, there are probabilistic arguments which suggest that human extinction may occur sooner rather than later. In 1966, Sagan and Shklovskii speculated that technological civilizations will either tend to destroy themselves within a century of developing interstellar communicative capability or master their self-destructive tendencies and survive for billion-year timescales. Self-annihilation may also be viewed in terms of thermodynamics: insofar as life is an ordered system that can sustain itself against the tendency to disorder, the "external transmission" or interstellar communicative phase may be the point at which the system becomes unstable and self-destructs.
It is the nature of intelligent life to destroy others.
Another hypothesis is that an intelligent species beyond a certain point of technological capability will destroy other intelligent species as they appear. The idea that something, or someone, might be destroying intelligent life in the universe has been explored in the scientific literature. A species might undertake such extermination out of expansionist motives, paranoia, or aggression. In 1981, cosmologist Edward Harrison argued that such behavior would be an act of prudence: an intelligent species that has overcome its own self-destructive tendencies might view any other species bent on galactic expansion as a threat. It has also been suggested that a successful alien species would be a superpredator, as are humans.
Periodic extinction by natural events.
New life would commonly die out due to runaway heating or cooling on their fledgling planets. On Earth, there have been numerous major extinction events that destroyed the majority of complex species alive at the time; the extinction of the dinosaurs is the best known example. These are thought to have been caused by events such as impact from a large meteorite, massive volcanic eruptions, or astronomical events such as gamma-ray bursts. It may be the case that such extinction events are common throughout the universe and periodically destroy intelligent life, or at least its civilizations, before the species is able to develop the technology to communicate with other species.
Inflation hypothesis and the youngness argument.
Cosmologist Alan Guth proposed a multi-verse solution to the Fermi paradox. This hypothesis uses the synchronous gauge probability distribution, that young universes exceedingly outnumber older ones (by a factor of e for every second of age). Therefore, averaged over all universes, universes with civilizations will almost always have just one, the first to develop. However, Guth notes "Perhaps this argument explains why SETI has not found any signals from alien civilizations, but I find it more plausible that it is merely a symptom that the synchronous gauge probability distribution is not the right one."
Intelligent civilizations are too far apart in space or time.
It may be that non-colonizing technologically capable alien civilizations exist, but that they are simply too far apart for meaningful two-way communication. If two civilizations are separated by several thousand light-years, it is possible that one or both cultures may become extinct before meaningful dialogue can be established. Human searches may be able to detect their existence, but communication will remain impossible because of distance. It has been suggested that this problem might be ameliorated somewhat if contact/communication is made through a Bracewell probe. In this case at least one partner in the exchange may obtain meaningful information. Alternatively, a civilization may simply broadcast its knowledge, and leave it to the receiver to make what they may of it. This is similar to the transmission of information from ancient civilizations to the present, and humanity has undertaken similar activities like the Arecibo message, which could transfer information about Earth's intelligent species, even if it never yields a response or does not yield a response in time for humanity to receive it. It is also possible that archaeological evidence of past civilizations may be detected through deep space observations — especially if they left behind large artifacts such as Dyson spheres.
A related speculation by Sagan and Newman suggests that if other civilizations exist, and are transmitting and exploring, their signals and probes simply have not arrived yet. However, critics have noted that this is unlikely, since it requires that humanity's advancement has occurred at a very special point in time, while the Milky Way is in transition from empty to full. This is a tiny fraction of the lifespan of a galaxy under ordinary assumptions and calculations resulting from them, so the likelihood that we are in the midst of this transition is considered low in the paradox.
It is too expensive to spread physically throughout the galaxy.
Many speculations about the ability of an alien culture to colonize other star systems are based on the idea that interstellar travel is technologically feasible. While the current understanding of physics rules out the possibility of faster-than-light travel, it appears that there are no major theoretical barriers to the construction of "slow" interstellar ships, even though the engineering required is considerably beyond our present capabilities. This idea underlies the concept of the Von Neumann probe and the Bracewell probe as a potential evidence of extraterrestrial intelligence.
It is possible, however, that present scientific knowledge cannot properly gauge the feasibility and costs of such interstellar colonization. Theoretical barriers may not yet be understood, and the cost of materials and energy for such ventures may be so high as to make it unlikely that any civilization could afford to attempt it. Even if interstellar travel and colonization are possible, they may be difficult, leading to a colonization model based on percolation theory. Colonization efforts may not occur as an unstoppable rush, but rather as an uneven tendency to "percolate" outwards, within an eventual slowing and termination of the effort given the enormous costs involved and the fact that colonies will inevitably develop a culture and civilization of their own. Colonization may thus occur in "clusters," with large areas remaining uncolonized at any one time.
Human beings have not existed long enough.
Humanity's ability to detect intelligent extraterrestrial life has existed for only a very brief period—from 1937 onwards, if the invention of the radio telescope is taken as the dividing line—and "Homo sapiens" is a geologically recent species. The whole period of modern human existence to date is a very brief period on a cosmological scale, and radio transmissions have only been propagated since 1895. Thus, it remains possible that human beings have neither existed long enough nor made themselves sufficiently detectable to be found by extraterrestrial intelligence.
Humans are not listening properly.
There are some assumptions that underlie the SETI programs that may cause searchers to miss signals that are present. Extraterrestrials might, for example, transmit signals that have a very high or low data rate, or employ unconventional (in our terms) data compression, frequencies, or modulations. Signals might be sent from non-main sequence star systems that we search with lower priority; current programs assume that most alien life will be orbiting Sun-like stars.
The greatest challenge is the sheer size of the radio search needed to look for signals (effectively spanning the entire visible universe), the limited amount of resources committed to SETI, and the sensitivity of modern instruments. SETI estimates, for instance, that with a radio telescope as sensitive as the Arecibo Observatory, Earth's television and radio broadcasts would only be detectable at distances up to 0.3 light-years, less than 1/10 the distance to the nearest star. A signal is much easier to detect if the signal energy is limited to either a narrow range of frequencies, or directed at a specific part of the sky. Such signals could be detected at ranges of hundreds to tens of thousands of light-years distance. However, this means that detectors must be listening to an appropriate range of frequencies, and be in that region of space to which the beam is being sent. Many SETI searches assume that extraterrestrial civilizations will be broadcasting a deliberate signal, like the Arecibo message, in order to be found.
Thus to detect alien civilizations through their radio emissions, Earth observers either need more sensitive instruments or must hope for fortunate circumstances: that the broadband radio emissions of alien radio technology are much stronger than our own; that one of SETI's programs is listening to the correct frequencies from the right regions of space; or that aliens are deliberately sending focused transmissions in our general direction.
Civilizations broadcast detectable radio signals only for a brief period of time.
It may be that alien civilizations are detectable through their radio emissions for only a short time, reducing the likelihood of spotting them. There are two possibilities in this regard: civilizations outgrow radio through technological advance or, conversely, resource depletion cuts short the time in which a species broadcasts. These will potentially remain visible even after broadcast emission are replaced by less observable technology.
More hypothetically, advanced alien civilizations evolve beyond broadcasting at all in the electromagnetic spectrum and communicate by principles of physics not yet understood by humans. Some scientists have hypothesized that advanced civilizations may send neutrino signals. If such signals exist, they could be detectable by neutrino detectors that are now under construction for other goals.
They tend to isolate themselves.
It has been suggested that some advanced beings may divest themselves of physical form, create massive artificial virtual environments, transfer themselves into these environments through mind uploading, and exist totally within virtual worlds, ignoring the external physical universe.
It may also be that intelligent alien life develop an "increasing disinterest" in their outside world. Possibly any sufficiently advanced society will develop highly engaging media and entertainment well before the capacity for advanced space travel, and that the rate of appeal of these social contrivances is destined, because of their inherent reduced complexity, to overtake any desire for complex, expensive endeavors such as space exploration and communication. Once any sufficiently advanced civilization becomes able to master its environment, and most of its physical needs are met through technology, various "social and entertainment technologies", including virtual reality, are postulated to become the primary drivers and motivations of that civilization.
They are too alien.
Another possibility is that human theoreticians have underestimated how much alien life might differ from that on Earth. Aliens may be psychologically unwilling to attempt to communicate with human beings. Perhaps human mathematics is parochial to Earth and not shared by other life, though others argue this can only apply to abstract math since the math associated with physics must be similar (in results, if not in methods.)
Physiology might also cause a communication barrier. Carl Sagan speculated that an alien species might have a thought process orders of magnitude slower (or faster) than humans. A message broadcast by that species might well seem like random background noise to humans, and therefore go undetected.
Another thought is that technological civilizations invariably experience a technological singularity and attain a post-biological character. Hypothetical civilizations of this sort may have advanced drastically enough to render communication impossible.
Everyone is listening, no one is transmitting.
Alien civilizations might be technically capable of contacting Earth, but are only listening instead of transmitting. If all, or even most, civilizations act the same way, the galaxy could be full of civilizations eager for contact, but everyone is listening and no one is transmitting. This is the so-called "SETI Paradox".
The only civilization we know, the Earth, does not explicitly transmit, except for a few small efforts. Even these efforts, and certainly any attempt to expand them, are controversial. It is not even clear we would respond to a detected signal — the official policy within the SETI community is that " response to a signal or other evidence of extraterrestrial intelligence should be sent until appropriate international consultations have taken place." However, given the possible impact of any reply it may be very difficult to obtain any consensus on "Who speaks for Earth?" and "What should we say?"
Earth is deliberately not contacted.
The zoo hypothesis states that intelligent extraterrestrial life exists and does not contact life on Earth to allow for its natural evolution and development. This hypothesis may break down under the uniformity of motive flaw: all it takes is a single culture or civilization to decide to act contrary to the imperative within our range of detection for it to be abrogated, and the probability of such a violation increases with the number of civilizations.
Analysis of the inter-arrival times between civilizations in the galaxy based on common astrobiological assumptions suggests that since the initial civilization would have such a commanding lead over the later arrivals, it may have established what we call "zoo hypothesis" as a galactic/universal norm and the resultant "paradox" by a cultural founder effect with or without the continued activity of the founder.
Earth is purposely isolated (planetarium hypothesis).
A related idea to the zoo hypothesis is that, beyond a certain distance, the perceived universe is a simulated reality. The planetarium hypothesis speculates that beings may have created this simulation so that the universe appears to be empty of other life.
It is dangerous to communicate.
An alien civilization might feel it is too dangerous to communicate, either for us or for them. After all, when very different civilizations have met on Earth, the results have often been disastrous for one side or the other, and the same may well apply to interstellar contact. Even contact at a safe distance could lead to infection by computer code or even ideas themselves. Perhaps prudent civilizations actively hide not only from Earth but from everyone, out of fear of other civilizations.
Perhaps the Fermi paradox itself — or the alien equivalent of it — is the reason for any civilization to avoid contact with other civilizations, even if no other obstacles existed. From any one civilization's point of view, it would be unlikely for them to be the first ones to make first contact. Therefore, according to this reasoning, it is likely that previous civilizations faced fatal problems with first contact and doing so should be avoided. So perhaps every civilization keeps quiet because of the possibility that there is a real reason for others to do so.
They are here undetected.
It is possible that a civilization advanced enough to travel between the stars could visit or observe our world while remaining undetected.
They are here unacknowledged.
A significant fraction of the population believes that at least some UFOs (Unidentified Flying Objects) are spacecraft piloted by aliens. While most of these are unrecognized or mistaken interpretations of mundane phenomena, there are those that remain puzzling even after investigation. The consensus scientific view is that although they may be unexplained, they do not rise to the level of convincing evidence.
Similarly, it is theoretically possible that SETI groups are not reporting positive detections, or governments have been blocking signals or suppressing publication. This response might be attributed to security or economic interests from the potential use of advanced extraterrestrial technology. It has been suggested that the detection of an extraterrestrial radio signal or technology could well be the most highly secret information that exists. Claims that this has already happened are common in the popular press, but the scientists involved report the opposite experience — the press becomes informed and interested in a potential detection even before a signal can be confirmed. Another problem with such a conspiracy theory is the diverse number of organisations and governments involved in science activities that might chance upon detections, of which SETI forms only a small part.

</doc>
<doc id="11582" url="https://en.wikipedia.org/wiki?curid=11582" title="Fundamentalism">
Fundamentalism

Fundamentalism usually has a religious connotation that indicates unwavering attachment to a set of irreducible beliefs. However, fundamentalism has come to apply to a tendency among certain groups—mainly, though not exclusively, in religion—that is characterized by a markedly strict literalism as applied to certain specific scriptures, dogmas, or ideologies, and a strong sense of the importance of maintaining ingroup and outgroup distinctions, leading to an emphasis on purity and the desire to return to a previous ideal from which advocates believe members have strayed. Rejection of diversity of opinion as applied to these established "fundamentals" and their accepted interpretation within the group is often the result of this tendency.
Depending upon the context, fundamentalism can be a pejorative rather than neutral characterization, similar to the ways that calling political perspectives "right-wing" or "left-wing" can, for some, have negative connotations.
Christian.
Christian fundamentalism has been defined by George Marsden as the demand for a strict adherence to certain theological doctrines, in reaction against Modernist theology. The term was originally coined by its supporters to describe what they claimed were five specific classic theological beliefs of Christianity, and that developed into a Christian fundamentalist movement within the Protestant community of the United States in the early part of the 20th century. Fundamentalism as a movement arose in the United States, starting among conservative Presbyterian theologians at Princeton Theological Seminary in the late 19th century. It soon spread to conservatives among the Baptists and other denominations around 1910 to 1920. The movement's purpose was to reaffirm key theological tenets and defend them against the challenges of liberal theology and higher criticism.
The term "fundamentalism" has roots in the Niagara Bible Conference (1878–1897), which defined those tenets it considered "fundamental" to Christian belief. The term was popularized by "The Fundamentals", a collection of twelve books on five subjects published in 1910 and funded by the brothers Milton and Lyman Stewart. These essays came to represent a "Fundamentalist-Modernist Controversy" that appeared late in the 19th century within some Protestant denominations in the United States, and continued in earnest through the 1920s. The first formulation of American fundamentalist beliefs traces to the Niagara Bible Conference and, in 1910, to the General Assembly of the Presbyterian Church, which distilled these into what became known as the "five fundamentals":
It did "not" (yet) become associated with tenets such as Young Earth creationism.
By the late 1910s, theological conservatives rallying around the five fundamentals came to be known as "fundamentalists". They reject the existence of commonalities with theologically related religious traditions, such as the grouping of Christianity, Islam, and Judaism into one Abrahamic family of religions. In contrast, Evangelical groups (such as the Billy Graham Evangelistic Association), while they typically agree on the theology "fundamentals" as expressed in "The Fundamentals", are often willing to participate in events with religious groups who do not hold to the essential doctrines.
Jewish.
Jewish fundamentalism has been used to characterize militant religious Zionism, and both Ashkenazi and Sephardic versions of Haredi Judaism.
Ian S Lustik has characterized Jewish fundamentalism as "an ultranationalist, eschatologically based, irredentist ideology."
Islamic.
The Shia and Sunni religious conflicts since the 7th century created an opening for radical ideologues, such as Ali Shariati (1933–77), to merge social revolution with Islamic fundamentalism, as exemplified by the Iranian Revolution in 1979. Islamic fundamentalism has appeared in many countries; the Wahhabi version is promoted worldwide and financed by Saudi Arabia, Qatar and Pakistan.
The Iran hostage crisis of 1979–80 marked a major turning point in the use of the term "fundamentalism". The media, in an attempt to explain the ideology of Ayatollah Khomeini and the Iranian Revolution to a Western audience described it as a "fundamentalist version of Islam" by way of analogy to the Christian fundamentalist movement in the U.S. Thus was born the term "Islamic fundamentalist", which became a common use of the term in following years.
Hindu.
Scholars identify several politically active Hindu movements (including the RSS, BJP and VHP) as part of the "Hindu fundamentalist family."
A recent phenomenon in India has been the rise of Hindu fundamentalism, which has led to political mobilization against Muslims.
Buddhist.
Buddhist fundamentalism has also targeted other religious and ethnic groups, such as that in Myanmar. As a Buddhist dominated nation, Myanmar has seen recent tensions between Muslim minorities and the Buddhist majority, especially during the 2013 Burma anti-Muslim riots, alleged to have been instigated by hardliner groups such as the 969 Movement.
There are historic and contemporary examples of Buddhist fundamentalism in each of the three main branches of Buddhism: Theravada, Mahayana, and Vajrayana. In Japan, a prominent example has been the practice of shakubuku among some members of the Nichiren sect—a method of proselytizing involving strident condemnation of other sects as deficient or evil. Similarly, some members of the New Kadampa Tradition of Tibetan Buddhism and the Western Shugden Society have appropriated the controversial and fiercely sectarian protector deity Dorje Shugden as a symbol of maintaining the purity of the Gelugpa sect from contamination by teachings of other sects, condemning the Dalai Lama's eclectic approach (see Dorje Shugden controversy).
Non-religious.
"Fundamentalist" has been used pejoratively to refer to philosophies perceived as literal-minded or carrying a pretense of being the sole source of objective truth, regardless of whether it is usually called a religion. For instance, the Archbishop of Wales has criticized "atheistic fundamentalism" broadly and said "Any kind of fundamentalism, be it Biblical, atheistic or Islamic, is dangerous". He also said, "the new fundamentalism of our age ... leads to the language of expulsion and exclusivity, of extremism and polarisation, and the claim that, because God is on our side, he is not on yours."
In "The New Inquisition", Robert Anton Wilson lampoons the members of skeptical organizations such as the Committee for the Scientific Investigation of Claims of the Paranormal as fundamentalist materialists, alleging that they dogmatically dismiss any evidence that conflicts with materialism as hallucination or fraud.
In France, the imposition of restrictions on the wearing of headscarves in state-run schools has been labeled "secular fundamentalism". In the United States, private or cultural intolerance of women wearing the hijab (Islamic headcovering) and political activism by Muslims also has been labeled "secular fundamentalism" by some Muslims in the U.S.
The term "fundamentalism" is sometimes applied to signify a counter-cultural fidelity to a principle or set of principles, as in the pejorative term "market fundamentalism", used to imply exaggerated religious-like faith in the ability of unfettered "laissez-faire" or free market economic views or policies to solve economic and social problems. According to economist John Quiggin, the standard features of "economic fundamentalist rhetoric" are "dogmatic" assertions and the claim that anyone who holds contrary views is not a real economist. Retired professor in religious studies Roderick Hindery lists positive qualities attributed to political, economic, or other forms of cultural fundamentalism, including "vitality, enthusiasm, willingness to back up words with actions, and the avoidance of facile compromise," as well as negative aspects, such as psychological attitudes, occasionally elitist and pessimistic perspectives, and, in some cases, literalism.
Atheist.
In December 2007, the Anglican Archbishop of Wales Barry Morgan criticized what he referred to as "atheistic fundamentalism", claiming that it advocated that religion has no substance and "that faith has no value and is superstitious nonsense." He claimed it led to situations such as councils calling Christmas "Winterval", schools refusing to put on nativity plays and crosses removed from chapels. Others have countered that some of these attacks on Christmas are urban legends, not all schools do nativity plays because they choose to perform other traditional plays like A Christmas Carol or The Snow Queen and, because of rising tensions between various religions, opening up public spaces to alternate displays rather than the Nativity scene is an attempt to keep government religion-neutral.
Criticism.
Sociologist of religion Tex Sample asserts that it is a mistake to refer to a Muslim, Jewish, or Christian fundamentalist. Rather, a fundamentalist's fundamentalism is their primary concern, over and above other denominational or faith considerations.
A criticism by Elliot N. Dorff:
In order to carry out the fundamentalist program in practice, one would need a perfect understanding of the ancient language of the original text, if indeed the true text can be discerned from among variants. Furthermore, human beings are the ones who transmit this understanding between generations. Even if one wanted to follow the literal word of God, the need for people first to understand that word necessitates human interpretation. Through that process human fallibility is inextricably mixed into the very meaning of the divine word. As a result, it is impossible to follow the indisputable word of God; one can only achieve a human understanding of God's will.
Howard Thurman was interviewed in the late 1970s for a BBC feature on religion. He told the interviewer:
Influential criticisms of fundamentalism include James Barr's books on Christian fundamentalism and Bassam Tibi's analysis of Islamic fundamentalism.
Political usage of the term "fundamentalism" has also been criticized. "Fundamentalism" has been used by political groups to attack their opponents, using the term flexibly depending on their political interests. According to Judith Nagata, a professor of Asia Research Institute in the National University of Singapore, "The Afghan "mujahiddin", locked in combat with the Soviet enemy in the 1980s, could be praised as 'freedom fighters' by their American backers at the time, while the present Taliban, viewed, among other things, as protectors of American enemy Osama bin Laden, are unequivocally 'fundamentalist'."
A study at the University of Edinburgh found that of its six measured dimensions of religiosity, "lower intelligence is most associated with higher levels of fundamentalism."
Controversy.
The Associated Press' "AP Stylebook" recommends that the term fundamentalist not be used for any group that does not apply the term to itself. Many scholars have adopted a similar position. Other scholars, however, use the term in the broader descriptive sense to refer to various groups in various religious traditions including those groups that would object to being classified as fundamentalists, such as in "The Fundamentalism Project".

</doc>
<doc id="11585" url="https://en.wikipedia.org/wiki?curid=11585" title="Show Me Love (film)">
Show Me Love (film)

Show Me Love is the English distribution name, for the 1998 Swedish film Fucking Åmål (), directed by Lukas Moodysson.
The film follows the lives of two seemingly disparate teenage girls who begin a tentative romantic relationship. It first premiered outside Sweden at the 1998 Cannes Film Festival under its original title. According to Moodysson, the problem with the original title started when the film was Sweden's candidate for the Academy Awards, though eventually it was not chosen as a nominee. The Hollywood industry magazine "Variety" refused to run an advertisement for "Fucking Åmål". Thus American distributor Strand Releasing asked for a new title. Moodysson took the new title from the song at the end of the film, by Robyn. Distributors in other native English-speaking countries then followed suit.
For writer Moodysson, it was his directorial debut in a full-length film. Starring in the lead roles were Rebecka Liljeberg, as Agnes, and Alexandra Dahlström, as Elin. The film received an overwhelmingly positive reception and won four Guldbagge Awards (Sweden's official film awards) at the 1999 ceremony. Its international awards include the Teddy award at the 1999 Berlin International Film Festival.
The Swedish title refers to the small town of Åmål in western Sweden. Only a few scenes were filmed in Åmål, and these were not included in the final version. The main shooting took place in the nearby town of Trollhättan, the location of Film i Väst's (producing company) studios.
Plot.
Two girls, Agnes and Elin, attend school in the small town of Åmål in Sweden. Elin is outgoing and popular but finds her life unsatisfying and dull. Agnes, by contrast, has no real friends and is constantly depressed. Agnes is in love with Elin but cannot find any way to express it.
Agnes' parents worry about their daughter's reclusive life and try to be reassuring. Her mother decides, against Agnes' will, to throw a 16th birthday party for her. Agnes is afraid no one will come. Viktoria, a girl in a wheelchair, shows up and Agnes shouts at her in front of her parents, telling her they are friends only because no one else will talk to them. Agnes, overcome with anger and depression, goes to her room and cries into her pillow shouting that she wishes she was dead, while her father tries to soothe her. Viktoria leaves and Agnes' family eats the food made for the party. 
Elin arrives at Agnes' house, mainly as an excuse to avoid going to another party, where there will be a boy (Johan, played by Mathias Rust) she wants to avoid. Elin's older sister, Jessica, who comes with her, dares her to kiss Agnes, who is rumoured to be a lesbian. Elin fulfills the dare and then runs out with Jessica, only to soon feel guilty for having humiliated Agnes.
After becoming drunk at the other party, Elin gets sick and throws up. Johan tries to help her and ends up professing his love to her. Elin leaves Johan and the party, only to return to Agnes' house to apologize for how she acted earlier. And in doing so, Elin stops Agnes from attempting to commit suicide. She even manages to persuade Agnes to return with her to the other party. On the way, Elin shares her real feelings about being trapped in Åmål. She asks Agnes about being a lesbian and believes that their problems could be solved by leaving Åmål and going to Stockholm. On impulse, Elin persuades Agnes to hitchhike to Stockholm, a five-hour car journey. They find a driver who agrees to take them, believing them to be sisters who are visiting their grandmother. While sitting in the back seat have their first real kiss. The driver sees them and, shocked at the behaviour of the two 'sisters', orders them to leave the car.
Elin discovers that she is attracted to Agnes but is afraid to admit it. She proceeds to ignore Agnes and refuses to talk to her. Elin's sister Jessica sees that she is in love and pushes her to figure out who it is. To cover the fact that she is in love with Agnes, Elin lies, pretending to be in love with Johan, and loses her virginity during a short-lived relationship with him. Elin eventually admits her feelings, when, after a climactic scene in a school bathroom, they are forced to 'out' their relationship to the school. 
The film ends with Elin and Agnes sitting in Elin's bedroom drinking chocolate milk. Elin explains that she often adds too much chocolate until her milk is nearly black. She must fill another glass with milk and mix it and that her sister Jessica often gets mad that she finishes the chocolate. Elin has the last word saying "It makes a lot of chocolate milk. But that doesn't matter."
Title.
The original title of the film, "Fucking Åmål", refers to the girls' feelings about their small town: In a key scene one of the girls shouts in desperation "varför måste vi bo i fucking jävla kuk-Åmål?" (which roughly translates to "why do we have to live in fucking bloody cock-Åmål?"). The title, however, caused problems in other countries. Alternative, generic names were chosen by local distributors: 
Reception.
Political controversy.
Even before the film was completed, it created controversy in the town of Åmål. Local politicians campaigned to get the title changed because they argued that it would show the town in an unfair way and even undermine it as an economic centre. Further pressure was brought on the makers of the film, the Film i Väst studio, who are partly financed by Swedish local authorities, including Åmål. 
However, the local complaints had no effect on the content or release of the film. Since the release, the town of Åmål has tried to embrace the publicity generated, despite the fact that the town's name is missing from the English title. In the early 2000s the town founded the pop music "Fucking Åmål Festival."
Critical and commercial response.
"Fucking Åmål" received the highest audience figures for a Swedish film in 1998-9, with a total audience of 867,576 and a total audience for the whole of Europe of 2,100,000. 
However, some reports outside Sweden incorrectly stated that in Sweden the film had even outgrossed the Hollywood film "Titanic". In fact, "Titanic" had over twice as many viewers as "Show Me Love" in Sweden in 1998. Based on 39 reviews collected by the film review aggregator Rotten Tomatoes, 90% of critics gave "Show Me Love" a positive review. It is among the top ten of the BFI list of the 50 films you should see by the age of 14.
Soundtrack.
The film's soundtrack was released through Columbia Records and consists of songs in English and Swedish language. Swedish band Broder Daniel, who contributed three English language songs to "Fucking Åmål", saw a spike in popularity after the film's release. The band also released an EP titled "Fucking Åmål".

</doc>
<doc id="11586" url="https://en.wikipedia.org/wiki?curid=11586" title="Full disclosure (computer security)">
Full disclosure (computer security)

In the field of computer security, independent researchers often discover flaws in software that can be abused to cause unintended behaviour, these flaws are called vulnerabilities. The process by which the analysis of these vulnerabilities is shared with third parties is the subject of much debate, and is referred to as the researcher’s "disclosure policy". Full disclosure is the practice of publishing analysis of software vulnerabilities as early as possible, making the data accessible to everyone without restriction. The primary purpose of widely disseminating information about vulnerabilities is so that potential victims are as knowledgeable as those who attack them.
In his essay on the topic, Bruce Schneier stated "Full disclosure -- the practice of making the details of security vulnerabilities public -- is a damned good idea. Public scrutiny is the only reliable way to improve security, while secrecy only makes us less secure". Leonard Rose, co-creator of an electronic mailing list that has superseded bugtraq to become the de facto forum for disseminating advisories, explains "We don't believe in security by obscurity, and as far as we know, full disclosure is the only way to ensure that everyone, not just the insiders, have access to the information we need." 
The vulnerability disclosure debate.
The controversy around the public disclosure of sensitive information isn't new. The issue of full disclosure was first raised in the context of locksmithing, in a 19th-century controversy regarding whether weaknesses in lock systems should be kept secret in the locksmithing community, or revealed to the public. Today, there are three major disclosure policies under which most others can be categorized: Non Disclosure, Coordinated Disclosure, and Full Disclosure.
The major stakeholders in vulnerability research have their disclosure policies shaped by various motivations, it is not uncommon to observe campaigning, marketing or lobbying for their preferred policy to be adopted and chastising those who dissent. Many prominent security researchers favor full disclosure, whereas most vendors prefer coordinated disclosure. Non disclosure is generally favoured by commercial exploit vendors and blackhat hackers.
Coordinated disclosure.
Proponents of coordinated disclosure believe that software vendors have the right to control vulnerability information concerning their products. The primary tenet of coordinated disclosure is that nobody should be informed about a vulnerability until the software vendor gives their permission. While there are often exceptions or variations of this policy, distribution must initially be limited and vendors are given privileged access to nonpublic research. Advocates for coordinated disclosure often prefer the weighted but less-descriptive term “responsible disclosure” coined by Microsoft Security Manager Scott Culp in his essay “It's Time to End Information Anarchy” (referring to full disclosure). Microsoft later asked for the term to be phased out in favour of “coordinated disclosure”.
Although the reasoning varies, many practitioners argue that end-users cannot benefit from access to vulnerability information without guidance or patches from the vendor, so the risks of sharing research with malicious actors is too great for too little benefit. As Microsoft explain, "oordinated disclosur serves everyone's best interests by ensuring that customers receive comprehensive, high-quality updates for security vulnerabilities but are not exposed to malicious attacks while the update is being developed."
Full disclosure.
Full disclosure is the policy of publishing information on vulnerabilities without restriction as early as possible, making the information accessible to the general public without restriction. In general, proponents of full disclosure believe that the benefits of freely available vulnerability research outweigh the risks, whereas opponents prefer to limit the distribution. 
The free availability of vulnerability information allows users and administrators to understand and react to vulnerabilities in their systems, and allows customers to pressure vendors to fix vulnerabilities that vendors may otherwise feel no incentive to solve. There are some fundamental problems with coordinated disclosure that full disclosure can resolve.
Discovery of a specific flaw or vulnerability is not a mutually exclusive event, multiple researchers with differing motivations can and do discover the same flaws independently.
There is no standard way to make vulnerability information available to the public, researchers often use mailing lists dedicated to the topic, academic papers or industry conferences.
Non disclosure.
Non disclosure is the principle that no vulnerability information should be shared, or should only be shared under non-disclosure agreement (either contractually or informally).
Common proponents of non-disclosure include commercial exploit vendors, researchers who intend to exploit the flaws they find, and vendors who believe that any vulnerability information whatsoever assists attackers.
Debate.
Arguments against coordinated disclosure.
Researchers in favour of coordinated disclosure believe that users cannot make use of advanced knowledge of vulnerabilities without guidance from the vendor, and that the majority is best served by limiting distribution of vulnerability information. Advocates argue that low-skilled attackers can use this information to perform sophisticated attacks that would otherwise be beyond their ability, and the potential benefit does not outweigh the potential harm caused by malevolent actors. Only when the vendor has prepared guidance that even the most unsophisticated users can digest should the information be made public.
This argument presupposes that vulnerability discovery is a mutually exclusive event, that only one person can discover a vulnerability. There are many examples of vulnerabilities being discovered simultaneously, often being exploited in secrecy before discovery by other researchers. While there may exist users who cannot benefit from vulnerability information, full disclosure advocates believe this demonstrates a contempt for the intelligence of end users. While it's true that some users cannot benefit from vulnerability information, if they're concerned with the security of their networks they are in a position to hire an expert to assist them as you would hire a mechanic to help with a car.
Arguments against non disclosure.
Non disclosure is typically used when a researcher intends to use knowledge of a vulnerability to attack computer systems operated by their enemies, or to trade knowledge of a vulnerability to a third party for profit, who will typically use it to attack their enemies.
Researchers practicing non disclosure are generally not concerned with improving security or protecting networks. However, some proponents argue that they simply do not want to assist vendors, and claim no intent to harm others.
While full and coordinated disclosure advocates declare similar goals and motivations, simply disagreeing on how best to achieve them, non disclosure is entirely incompatible.

</doc>
<doc id="11587" url="https://en.wikipedia.org/wiki?curid=11587" title="Feminist theology">
Feminist theology

Feminist theology is a movement found in several religions, including Buddhism, Christianity, Judaism, and New Thought, to reconsider the traditions, practices, scriptures, and theologies of those religions from a feminist perspective. Some of the goals of feminist theology include increasing the role of women among the clergy and religious authorities, reinterpreting male-dominated imagery and language about God, determining women's place in relation to career and motherhood, and studying images of women in the religion's sacred texts and matriarchal religion.
Methodology.
Feminist theology attempts to consider every aspect of religious practice and thought. Some of the questions feminist theologians ask are:
Development of theology.
According to Grenz and Olson in their review of Feminist Theology, "it was developed in three distinct steps. They begin with a critique of the past” such that they review the ways women have been oppressed; “they seek alternative biblical and extrabiblical traditions that support” the ideals Feminists are trying to advance; and finally “feminists set forth their own unique method of theology, which includes the revisioning of Christian categories.” Grenz and Olson also mention, however, while all feminists agree there is a flaw in the system, there is disagreement over how far outside of the Bible and the Christian tradition women are willing to go to seek support for their ideals.
It has frequently been said that feminist theology draws on women's experience as a basic source of content as well as a criterion of truth.
There has been a tendency to treat this principle of "experience" as unique to feminist theology (or, perhaps to liberation theologies) and to see it as distant from "objective" source of truth of classical theologies. This seems to be a misunderstanding of the experimental base of all theological reflection. What have been called the objective sources of theology; Scripture and tradition, are themselves codified collective human experience.
Prehistoric religion and archaeology.
The primacy of a monotheistic or near-monotheistic "Great Goddess" is advocated by some modern matriarchists as a female version of, preceding, or analogue to, the Abrahamic God associated with the historical rise of monotheism in the Mediterranean Axis Age.
Mother Nature (sometimes known as "Mother Earth") is a common representation of nature that focuses on the life-giving and nurturing features of nature by embodying it in the form of the mother. Images of women representing mother earth, and mother nature, are timeless. In prehistoric times, goddesses were worshipped for their association with fertility, fecundity, and agricultural bounty. Priestesses held dominion over aspects of Incan, Assyrian, Babylonian, Slavonic, Roman, Greek, Indian, and Iroquoian religions in the millennia prior to the inception of Patriarchal religion.
Gender and God.
Others who practice feminist spirituality may instead adhere to a feminist re-interpretation of Western monotheistic traditions. In those cases, the notion of God as having a male gender is rejected, and God is not referred to using male pronouns. Feminist spirituality may also object to images of God that they perceive as authoritarian, parental, or disciplinarian, instead emphasizing "maternal" attributes such as nurturing, acceptance, and creativity.
Carol P. Christ is the author of the widely reprinted essay "Why Women Need the Goddess,", which argues in favor of the concept of there having been an ancient religion of a supreme goddess. This essay was presented as the keynote address to an audience of over 500 at the "Great Goddess Re-emerging" conference at the University of Santa Cruz in the spring of 1978, and was first published in "Heresies: The Great Goddess Issue" (1978), pgs. 8-13. Carol P. Christ also co-edited the classic feminist religion anthologies "Weaving the Visions: New Patterns in Feminist Spirituality" (1989) and "Womanspirit Rising" (1979/1989); the latter included her essay "Why Women Need the Goddess".
New Thought movement.
New Thought as a movement had no single origin, but was rather propelled along by a number of spiritual thinkers and philosophers and emerged through a variety of religious denominations and churches, particularly the Unity Church, Religious Science, and Church of Divine Science. It was a feminist movement in that most of its teachers and students were women; notable among the founders of the movement were Emma Curtis Hopkins, known as the "teacher of teachers" Myrtle Fillmore, Malinda Cramer, and Nona L. Brooks; with its churches and community centers mostly led by women, from the 1880s to today.
Within specific religions.
Judaism.
Jewish feminism is a movement that seeks to make the religious, legal, and social status of Jewish women equal to that of Jewish men. Feminist movements, with varying approaches and successes, have opened up within all major branches of Judaism.
Various versions of feminist theology exist within the Jewish community.
Some of these theologies promote the idea that it is important to have a feminine characterisation of God within the siddur (Jewish prayerbook) and service.
In 1976, Rita Gross published the article "Female God Language in a Jewish Context" (Davka Magazine 17), which Jewish scholar and feminist Judith Plaskow considers "probably the first article to deal theoretically with the issue of female God-language in a Jewish context".  Gross was Jewish herself at this time.
Reconstructionist Rabbi Rebecca Alpert ("Reform Judaism", Winter 1991) comments:
In 1990 Rabbi Margaret Wenig wrote the sermon, "God is a Woman and She is Growing Older," which as of 2011 has been published ten times (three times in German) and preached by rabbis from Australia to California.
Rabbi Paula Reimers ("Feminism, Judaism, and God the Mother", "Conservative Judaism" 46 (1993)) comments:
Ahuva Zache affirms that using both masculine and feminine language for God can be a positive thing, but reminds her Reform Jewish readership that God is beyond gender ("Is God male, female, both or neither? How should we phrase our prayers in response to God’s gender?", in the Union for Reform Judaism's iTorah, ):
These views are highly controversial even within liberal Jewish movements. Orthodox Jews and many Conservative Jews
hold that it is wrong to use English female pronouns for God, viewing such usage as an intrusion of modern feminist ideology into Jewish tradition. Liberal prayerbooks tend increasingly to also avoid male-specific words and pronouns, seeking that all references to God in translations be made in gender-neutral language. For example, the UK Liberal movement's "Siddur Lev Chadash" (1995) does so, as does the UK Reform Movement's "Forms of Prayer" (2008). In Mishkan T'filah, the American Reform Jewish prayer book released in 2007, references to God as “He” have been removed, and whenever Jewish patriarchs are named (Abraham, Isaac, and Jacob), so also are the matriarchs (Sarah, Rebecca, Rachel, and Leah.) In 2015 the Reform Jewish High Holy Days prayer book Mishkan HaNefesh was released; it is intended as a companion to Mishkan T'filah. It includes a version of the High Holy Days prayer Avinu Malkeinu that refers to God as both "Loving Father" and "Compassionate Mother." Other notable changes are replacing a line from the Reform movement’s earlier prayerbook, "Gates of Repentance," that mentioned the joy of a bride and groom specifically, with the line "rejoicing with couples under the chuppah edding canop", and adding a third, non-gendered option to the way worshippers are called to the Torah, offering “mibeit,” Hebrew for “from the house of,” in addition to the traditional “son of” or “daughter of.”
In 2003 "The Female Face of God in Auschwitz: A Jewish Feminist Theology of the Holocaust", the first full-length feminist theology of the Holocaust, written by Melissa Raphael, was published. Judith Plaskow’s "Standing Again at Sinai: Judaism from a Feminist Perspective" (1991), and Rachel Adler’s "Engendering Judaism: An Inclusive Theology and Ethics" (1999) are the only two full-length Jewish feminist works to focus entirely on theology in general (rather than specific aspects such as Holocaust theology.) Thus, "Standing Again at Sinai: Judaism from a Feminist Perspective" (1991) is the first book of Jewish feminist theology ever written.
Christianity.
Christian feminism is an aspect of feminist theology which seeks to advance and understand the equality of men and women morally, socially, spiritually, and in leadership from a Christian perspective. Christian feminists argue that contributions by women in that direction are necessary for a complete understanding of Christianity. Christian feminists believe that God does not discriminate on the basis of biologically determined characteristics such as sex and race. Their major issues include the ordination of women, male dominance in Christian marriage, recognition of equal spiritual and moral abilities, reproductive rights, and the search for a feminine or gender-transcendent divine. Christian feminists often draw on the teachings of other religions and ideologies in addition to biblical evidence.
Two authors whose works are vital to an understanding of feminist theology are Mary Daly and Rosemary Radford Ruether.
Mary Daly grew up an Irish Catholic and all of her education was received through Catholic schools. She has three doctorate degrees. One from St. Mary’s College in sacred theology, and two from University of Fribourg, Switzerland in theology and philosophy. From 1966 till the end of her career she taught at Boston College. While in her early works Daly expressed a desire to reform Christianity from the inside, she would later come to the same point as several other feminists, that Christianity is not able to enact the necessary changes as it is. (Prologue Daly). “On November 14, 1971, when she was invited to be the first woman to preach at Harvard Memorial Chapel. She used the opportunity to denounce Christianity as irredeemable for women and to call for women (and men) to make an exodus from the Church. Almost all the women who attended this service walked out with her, as well as a few men.” Her works include: "The Church and the Second Sex" (1968), "Beyond God the Father" (1973), "Gyn/ecology: The Metaethics of Radical Feminism" (1978), "Pure Lust: Elemental Feminist Philosophy" (1984), "Webster’s First Intergalactic Wickedary of the English Language" (1987), and "Outercourse: The Be-Dazzling Voyage" (1992). According to Ford’s The Modern Theologians, “Mary Daly has done more than anyone to clarify the problems women have concerning the central core symbolism of Christianity, and its effects on their self-understanding and their relationship to God.”
Rosemary Radford Ruether grew up Roman Catholic and attended Catholic schools through her sophomore year of high school. She was a classics major at Scripps College, worked for the Delta Ministry in 1965 and taught at Howard University School of Religion from 1966 to 1976. She has also “been responsible for the production of some twenty-two books…and at least five hundred articles.” “Rosemary Ruether has written on the question of Christian credibility, with particular attention to ecclesiology and its engagement with church-world conflicts; Jewish-Christian relations…; politics and religion in America; and Feminism".
The term Christian egalitarianism is sometimes preferred by those advocating gender equality and equity among Christians who do not wish to associate themselves with the feminist movement.
Women apologists have become more visible in Christian academia. Their defense of the faith is differentiated by a more personal, cultural and listening approach "driven by love".
See also: Unity Church, Christian Science, Christian theological praxis and Postmodern Christianity.
Islam.
Islamic feminism is a form of feminism concerned with the role of women in Islam. It aims for the full equality of all Muslims, regardless of gender, in public and private life. Islamic feminists advocate women's rights, gender equality, and social justice grounded in an Islamic framework. Although rooted in Islam, the movement's pioneers have also utilised secular and European or non-Muslim feminist discourses and recognise the role of Islamic feminism as part of an integrated global feminist movement. Advocates of the movement seek to highlight the deeply rooted teachings of equality in the Quran and encourage a questioning of the patriarchal interpretation of Islamic teaching through the Quran (holy book), "hadith" (sayings of Muhammad) and "sharia" (law) towards the creation of a more equal and just society. Muslim majority countries have produced more than seven female heads of state, including Benazir Bhutto of Pakistan, Mame Madior Boye of Senegal, Tansu Çiller of Turkey, and Megawati Sukarnoputri of Indonesia. Bangladesh was the first country in the world to have consecutive, elected, female heads of state: Khaleda Zia and Sheikh Hasina.
Sikhism.
In Sikhism women are equal to men, see the verse from the Sikh scripture the Guru Granth Sahib
"From woman, man is born;
within woman, man is conceived; to woman he is engaged and married.
Woman becomes his friend; through woman, the future generations come.
When his woman dies, he seeks another woman; to woman he is bound.
So why call her bad? From her, kings are born.
From woman, woman is born; without woman, there would be no one at all."
— Guru Nanak
Hinduism.
Within Ancient Hinduism, women have been held in equal honour as men. Manusmriti for example states: "The society that provides respect and dignity to women flourishes with nobility and prosperity. And a society that does not put women on such a high pedestal has to face miseries and failures regardless of how so much noble deeds they perform otherwise." Manusmrithi Chapter 3 Verse 56.
Within the Vedas the Hindu holy texts, women were given the highest possible respect and equality. The Vedic period was glorified by this tradition. Many rishis were women. Indeed, several of them authored many of the slokas in the Vedas. For instance, in the Rigveda there is a list of women rishis. Some of them are: Ghosha, Godha, Gargi, Vishwawra, Apala, Upanishad, Brahmjaya, Aditi, Indrani, Sarma, Romsha, Maitreyi, Kathyayini, Urvashi, Lopamudra, Yami, Shashwati, Sri, Laksha and many others. In the Vedic period women were free to enter into brahmacharya just like men, and attain salvation.
During Hindu marriage ceremonies the following slokas are uttered by the grooms but, these days, their import little understood or ever attempted to understand.
"O bride! I accept your hand to enhance our joint good fortune. I pray to you to accept me as your husband and live with me until our old age. …" "Rigveda Samhita Part -4, sukta 85, sloka 9702"
"O bride! May you be like the empress of your mother-in-law, father-in-law, sisters-in-law and brothers-in-law (sisters and brothers of the groom). May your writ run in your house." "Rigveda Samhita Part -4, sukta 85, sloka 9712"
This beautifully lyrical sloka from the Atharvaveda clearly states that the woman leads and the man follows: ""The Sun God follows the first illuminated and enlightened goddess Usha (dawn) in the same manner as men emulate and follow women." Athravaveda Samhita, Part 2, Kanda 27, sukta 107, sloka 5705."
Women were considered to be the embodiment of great virtue and wisdom.
Thus we have: "O bride! May the knowledge of the Vedas be in front of you and behind you, in your centre and in your ends. May you conduct your life after attaining the knowledge of the Vedas. May you be benevolent, the harbinger of good fortune and health and live in great dignity and indeed illuminate your husband's home." "Atharva Veda 14-1-64."
Women were allowed full freedom of worship. "The wife should do agnihotra (yagna), sandhya (puja) and all other daily religious rituals. If, for some reason, her husband is not present, the woman alone has full rights to do yagna". Rigveda Samhita, part 1, sukta 79, sloka 872.
Moving on towards the Monotheistic era of Hinduism when such ideals such as Shaivism and Vaishnavism, a specific deity for feministic worship was bought about under the Shaktism branch. From a Hinduism point of view women are equal in all measures to men in comparison.
Neopaganism.
Some currents of Neopaganism, in particular Wicca, have a ditheistic concept of a single goddess and a single god, who in hieros gamos represent a united whole. Polytheistic reconstructionists focus on reconstructing polytheistic religions, including the various goddesses and figures associated with indigenous cultures.
The term "thealogy" is sometimes used in the context of the Neopagan Goddess movement, a pun on theology and "thea" θεά "goddess" intended to suggest a feminist approach to theism.
The Goddess movement is a loose grouping of social and religious phenomena that grew out of second-wave feminism, predominantly in North America, Western Europe, Australia, and New Zealand in the 1970s, and the metaphysical community as well. Spurred by the perception that women were not treated equitably in many religions, some women turned to a Female Deity as more in tune with their spiritual needs. Education in the Arts became a vehicle for the study of humanitarian philosophers like David Hume at that time. A unifying theme of this diverse movement is the femaleness of Deity (as opposed and contrasted to a patriarchal God).
Goddess beliefs take many forms: some people in the Goddess movement recognize multiple goddesses; some also include gods; others honour what they refer to as "the Goddess," which is not necessarily seen as monotheistic, but is often understood to be an inclusive, encompassing term incorporating many goddesses in many different cultures. The term "the Goddess" may also be understood to include a multiplicity of ways to view deity personified as female, or as a metaphor, or as a process. (Christ 1997, 2003) The term "The Goddess" may also refer to the concept of The One Divine Power, or the traditionally worshipped "Great Goddess" of ancient times.
In the latter part of the 20th century, feminism was influential in the rise of Neopaganism in the United States, and particularly the Dianic tradition. Some feminists find the worship of a goddess, rather than a god, to be consonant with their views. Others are polytheists, and worship a number of goddesses. The collective set of beliefs associated with this is sometimes known as thealogy and sometimes referred to as the Goddess movement. See also Dianic Wicca.
Buddhism.
Buddhist feminism seeks to advance and understand the equality of men and women morally, socially, spiritually, and in leadership from a Buddhist perspective and within Buddhism.

</doc>
<doc id="11589" url="https://en.wikipedia.org/wiki?curid=11589" title="FSK">
FSK

FSK can have alternative meanings:

</doc>
<doc id="11591" url="https://en.wikipedia.org/wiki?curid=11591" title="List of fictional guidebooks">
List of fictional guidebooks

Some fictional universes feature useful guidebooks which assist the hero and friends through difficult situations.
Features of a great fictional guidebook: Such books are ideally compact enough to carry on even the most strenuous adventures, yet detailed enough to contain exactly the information the reader needs at that particular point in the plot.
Many guidebooks are electronic in nature; some can access relevant information through a wireless connection.
Real guidebooks to fictional matters.
A few guides to fictional places have also been published. "The Dictionary of Imaginary Places", by Alberto Manguel and Gianni Guadalupi (Macmillan, 1980; Expanded Edition, HBJ, 1987), is a comprehensive survey of fictional places mentioned in fantasy and other literature. The 1996 book "Paris out of hand", by Karen Elizabeth Gordon, Barbara Hodgson, and Nick Bantock, is a guide to a fictionalized version of Paris. There are guidebooks to the fictional countries of "Molvanîa: The Land that Dentistry Forgot" (2003), "Phaic Tăn: Sunstroke on a Shoestring" (2004) and "San Sombrèro: A Land of Carnivals, Cocktails and Coups" (2006), written by Tom Gleisner, Santo Cilauro, and Rob Sitch.
"The Tough Guide to Fantasyland" by Diana Wynne Jones (Vista Books, 1996; Firebird Books, revised and updated 2006) is real book about high fantasy fiction cast as a tourist guidebook. It may be considered fantasy, or parody or criticism of fantasy, or a reference book. The U.S. Library of Congress calls it a dictionary (LCSH). The Internet Speculative Fiction Database calls it non-fiction, as did the administrators of some genre awards.

</doc>
<doc id="11592" url="https://en.wikipedia.org/wiki?curid=11592" title="Freeware">
Freeware

Freeware is proprietary software that is available for use at no monetary cost. In other words, freeware may be used without payment but may usually not be modified, re-distributed or reverse-engineered without the author's permission. Two historic examples of freeware include Skype and Adobe Acrobat Reader.
Freeware, although itself free of charge, may be intended to benefit its owner, e.g. by encouraging sales of a more capable version ("Freemium" or Shareware business model). The source code of freeware is typically not available, unlike free software and open source software which are often distributed free of charge.
History.
The term "freeware" was coined in 1982 by Andrew Fluegelman when he wanted to sell a communications program named PC-Talk that he had created but for which he did not wish to use commercial distribution channels. Fluegelman actually distributed PC-Talk via a process now referred to as shareware, no longer called freeware. 
The term "freeware" was used often in the 1980s and 1990s for programs released without source code.
Definitions.
Software license.
Software classified as freeware may be used without payment and is typically either fully functional for an unlimited time, or has limited functionality, with a more capable version available commercially or as shareware. In contrast to what the FSF calls free software, the author usually restricts the rights of the user to use, copy, distribute, modify, make derivative works, or reverse-engineer the software. The software license may impose various additional restrictions on the type of use, e.g. only for personal use, private use, individual use, non-profit use, non-commercial use, academic use, educational use, use in charity or humanitarian organizations, non-military use, use by public authorities or various other combinations of these type of restrictions. For instance, the license may be "free for private, non-commercial use". The software license may also impose various other restrictions, such as restricted use over a network, restricted use on a server, restricted use in a combination with some types of other software or with some hardware devices, prohibited distribution over the Internet other than linking to author's website, restricted distribution without author's consent, restricted number of copies, etc. Restrictions may be required by the licence, or enforced by the software (e.g., not usable over a network).
Relation to other forms of software licensing.
The US Department of Defense (DoD) defines "open source software" (i.e., free software or free and open source software), as distinct from "freeware" or "shareware"; it is software where "the Government does not have access to the original source code". The "free" in "freeware" refers to the price of the software, which is typically proprietary and distributed without source code. By contrast, the "free" in "free software" refers to freedoms granted users under the software license (for example, to run the program for any purpose, modify and redistribute the program to others), and such software may be sold at a price.
According to the Free Software Foundation (FSF), "freeware" is a loosely defined category and it has no clear accepted definition, although FSF asks that free software (libre; unrestricted and with source code available) should not be called freeware.
In contrast the Oxford English Dictionary simply characterizes freeware as being "available free of charge (sometimes with the suggestion that users should make a donation to the provider)".
Some freeware products are released alongside paid versions that either have more features or less restrictive licensing terms. This approach is known as freemium ("free" + "premium"), since the free version is intended as a promotion for the premium version. The two often share a code base, using a compiler flag to determine which is produced. For example, BBEdit has a BBEdit Lite edition which has less features. XnView is available free of charge for personal use but must be licensed for commercial use. The free version may be advertising supported, as was the case with the DivX.
Ad-supported software and free registerware also bear resemblances to freeware. Ad-supported software do not ask money for license but display advertisement to either compensate for development costs or as a mean of income. Registerware forces the user to subscribe with the publisher before being able to use the product. While commercial products may require registration to ensure licensed use, free registerware do not.
Restrictions.
Freeware cannot economically rely on commercial promotion. In May 2015 advertising freeware on Google AdWords was restricted to "authoritative source". Thus web sites and blogs are the primary resource for information on which freeware is available, useful, and is not malware. However, there are also many computer magazines or newspapers that provide ratings for freeware and include compact discs or other storage media containing freeware. Freeware is also often bundled with other products such as digital cameras or scanners.
Freeware has been criticized as "unsustainable" because it requires a single entity to be responsible for updating and enhancing the product, which is then given away without charge. Other freeware projects are simply released as one-off programs with no promise or expectation of further development. These may include source code, as does free software, so that users can make any required or desired changes themselves, but this code remains subject to the license of the compiled executable and does not constitute free software.

</doc>
<doc id="11593" url="https://en.wikipedia.org/wiki?curid=11593" title="Flat Earth">
Flat Earth

The flat Earth model is an archaic conception of the Earth's shape as a plane or disk. Many ancient cultures subscribed to a flat Earth cosmography, including Greece until the classical period, the Bronze Age and Iron Age civilizations of the Near East until the Hellenistic period, India until the Gupta period (early centuries AD) and China until the 17th century. That paradigm was also typically held in the aboriginal cultures of the Americas, and the notion of a flat Earth domed by the firmament in the shape of an inverted bowl was common in pre-scientific societies.
The idea of a spherical Earth appeared in Greek philosophy with Pythagoras (6th century BC), although most Pre-Socratics retained the flat Earth model. Aristotle provided evidence for the spherical shape of the Earth on empirical grounds by around 330 BC. Knowledge of the spherical Earth gradually began to spread beyond the Hellenistic world from then on.
Modern flat Earth theories, such as those espoused by modern flat Earth societies are considered pseudoscience by academics.
Historical development.
Ancient Near East.
In early Egyptian and Mesopotamian thought the world was portrayed as a flat disk floating in the ocean. A similar model is found in the Homeric account of the 8th century BC in which "Okeanos, the personified body of water surrounding the circular surface of the Earth, is the begetter of all life and possibly of all gods." The Israelites likely had a similar cosmology, with the earth as a flat disc floating on water beneath an arced firmament separating it from the heavens.
The Pyramid Texts and Coffin Texts reveal that the ancient Egyptians believed Nun (the Ocean) was a circular body surrounding "nbwt" (a term meaning "dry lands" or "Islands"), and therefore believed in a similar Ancient Near Eastern circular earth cosmography surrounded by water.
Ancient Mediterranean.
Poets.
Both Homer and Hesiod described a flat disc cosmography on the Shield of Achilles.
This poetic tradition of an earth-encircling ("gaiaokhos") sea (Oceanus) and a flat disc also appears in Stasinus of Cyprus, Mimnermus, Aeschylus, and Apollonius Rhodius.
Homer's description of the flat disc cosmography on the shield of Achilles with the encircling ocean is repeated far later in Quintus Smyrnaeus' Posthomerica (4th century AD), which continues the narration of the Trojan War.
Philosophers.
Several pre-Socratic philosophers believed that the world was flat: Thales (c. 550 BC) according to several sources,
and Leucippus (c. 440 BC) and Democritus (c. 460 – 370 BC) according to Aristotle.
Thales thought the earth floated in water like a log. It has been argued, however, that Thales actually believed in a round Earth. Anaximander (c. 550 BC) believed the Earth was a short cylinder with a flat, circular top that remained stable because it was the same distance from all things. Anaximenes of Miletus believed that "the earth is flat and rides on air; in the same way the sun and the moon and the other heavenly bodies, which are all fiery, ride the air because of their flatness." Xenophanes of Colophon (c. 500 BC) thought that the Earth was flat, with its upper side touching the air, and the lower side extending without limit.
Belief in a flat Earth continued into the 5th century BC. Anaxagoras (c. 450 BC) agreed that the Earth was flat, and his pupil Archelaus believed that the flat Earth was depressed in the middle like a saucer, to allow for the fact that the Sun does not rise and set at the same time for everyone.
Historians.
Hecataeus of Miletus believed the earth was flat and surrounded by water. Herodotus in his "Histories" ridiculed the belief that water encircled the world, yet most classicists agree he still believed the earth was flat because of his descriptions of literal "ends" or "edges" of the earth.
Ancient India.
Ancient Hindu, Jain, and Buddhist cosmology held that the Earth is a disc consisting of four continents grouped around a central mountain (Mount Meru) like the petals of a flower. An outer ocean surrounds these continents. This view of traditional Buddhist and Jain cosmology depicts the cosmos as a vast, oceanic disk (of the magnitude of a small planetary system), bounded by mountains, in which the continents are set as small islands.
Norse and Germanic.
The ancient Norse and Germanic peoples believed in a flat Earth cosmography with the Earth surrounded by an ocean, with the axis mundi, a world tree (Yggdrasil), or pillar (Irminsul) in the centre. The Norse believed that in the world-encircling ocean sat a snake called Jormungandr. In the Norse creation account preserved in Gylfaginning (VIII) it is stated that during the creation of the earth, an impassable sea was placed around the earth like a ring:
The late Norse Konungs skuggsjá, on the other hand, states that:
Ancient China.
In ancient China, the prevailing belief was that the Earth was flat and square, while the heavens were round, an assumption virtually unquestioned until the introduction of European astronomy in the 17th century. The English sinologist Cullen emphasizes the point that there was no concept of a round Earth in ancient Chinese astronomy:
Chinese thought on the form of the earth remained almost unchanged from early times until the first contacts with modern science through the medium of Jesuit missionaries in the seventeenth century. While the heavens were variously described as being like an umbrella covering the earth (the Kai Tian theory), or like a sphere surrounding it (the Hun Tian theory), or as being without substance while the heavenly bodies float freely (the Hsüan yeh theory), the earth was at all times flat, although perhaps bulging up slightly.
The model of an egg was often used by Chinese astronomers such as Zhang Heng (78–139 AD) to describe the heavens as spherical:
This analogy with a curved egg led some modern historians, notably Joseph Needham, to conjecture that Chinese astronomers were, after all, aware of the Earth's sphericity. The egg reference, however, was rather meant to clarify the relative position of the flat earth to the heavens:
In a passage of Zhang Heng's cosmogony not translated by Needham, Zhang himself says: "Heaven takes its body from the Yang, so it is round and in motion. Earth takes its body from the Yin, so it is flat and quiescent". The point of the egg analogy is simply to stress that the earth is completely enclosed by heaven, rather than merely covered from above as the Kai Tian describes. Chinese astronomers, many of them brilliant men by any standards, continued to think in flat-earth terms until the seventeenth century; this surprising fact might be the starting-point for a re-examination of the apparent facility with which the idea of a spherical earth found acceptance in fifth-century BC Greece.
Further examples cited by Needham supposed to demonstrate dissenting voices from the ancient Chinese consensus actually refer without exception to the Earth being square, not to it being flat. Accordingly, the 13th-century scholar Li Ye, who argued that the movements of the round heaven would be hindered by a square Earth, did not advocate a spherical Earth, but rather that its edge should be rounded off so as to be circular.
As noted in the book "Huainanzi", in the 2nd century BC Chinese astronomers effectively inverted Eratosthenes' calculation of the curvature of the Earth to calculate the height of the sun above the earth. By assuming the earth was flat, they arrived at a distance of 100,000 "li" (approximately 200,000 km), which is a value far short of the correct distance of 150 million km.
Declining support for the flat Earth.
Ancient Mediterranean.
In "The Histories", written in the mid-5th century BC, Herodotus cast doubt on a report of the sun observed shining from the north. He stated that the phenomenon was observed during a circumnavigation of Africa undertaken by Phoenician explorers employed by Egyptian pharaoh Necho II c. 610–595 BC (, 4.42) who claimed to have had the sun on their right when circumnavigating in a clockwise direction. To modern historians aware of a spherical Earth, these details confirm the truth of the Phoenicians’ report.
After the Greek philosophers Pythagoras, in the 6th century BC, and Parmenides, in the 5th, recognized that the Earth is spherical, the spherical view spread rapidly in the Greek world. Around 330 BC, Aristotle maintained on the basis of physical theory and observational evidence that the Earth was spherical, and reported on an estimate on the circumference. The Earth's circumference was first determined around 240 BC by Eratosthenes. By the second century CE, Ptolemy had derived his maps from a globe and developed the system of latitude, longitude, and climes. His Almagest was written in Greek and only translated into Latin in the 11th century from Arabic translations.
Lucretius (1st. c. BC) opposed the concept of a spherical Earth, because he considered that an infinite universe had no center towards which heavy bodies would tend. Thus, he thought the idea of animals walking around topsy-turvy under the Earth was absurd. By the 1st century AD, Pliny the Elder was in a position to claim that everyone agrees on the spherical shape of Earth, though disputes continued regarding the nature of the antipodes, and how it is possible to keep the ocean in a curved shape. Pliny also considered the possibility of an imperfect sphere, "...shaped like a pinecone."
In late antiquity such widely read encyclopedists as Macrobius (5th century) and Martianus Capella (5th century) discussed the circumference of the sphere of the Earth, its central position in the universe, the difference of the seasons in northern and southern hemispheres, and many other geographical details. In his commentary on Cicero's "Dream of Scipio", Macrobius described the Earth as a globe of insignificant size in comparison to the remainder of the cosmos.
Early Christian Church.
During the early Church period, the spherical view continued to be widely held, with some notable exceptions.
Lactantius, Christian writer and advisor to the first Christian Roman Emperor, Constantine, ridiculed the notion of the Antipodes, inhabited by people "whose footsteps are higher than their heads". After presenting some arguments he attributes to advocates for a spherical heaven and Earth, he writes:
The influential theologian and philosopher Saint Augustine, one of the four Great Church Fathers of the Western Church, similarly objected to the "fable" of an inhabited Antipodes:
The view generally accepted by scholars of Augustine's work is that he shared the common view of his contemporaries that the Earth is spherical, in line with his endorsement of science in "De Genesi ad litteram". That view was challenged by noted Augustine scholar Leo Ferrari, who concluded that 
Ferrari's interpretation was questioned by the historian of science, Phillip Nothaft, who considers that in his scriptural commentaries Augustine was not endorsing any particular cosmological model.
Diodorus of Tarsus, a leading figure in the School of Antioch and mentor of John Chrysostom, may have argued for a flat Earth; however, Diodorus' opinion on the matter is known only from a later criticism. Chrysostom, one of the four Great Church Fathers of the Eastern Church and Archbishop of Constantinople, explicitly espoused the idea, based on scripture, that the Earth floats miraculously on the water beneath the firmament. Athanasius the Great, Church Father and Patriarch of Alexandria, expressed a similar view in "Against the Heathen".
"Christian Topography" (547) by the Alexandrian monk Cosmas Indicopleustes, who had travelled as far as Sri Lanka and the source of the Blue Nile, is now widely considered the most valuable geographical document of the early medieval age, although it received relatively little attention from contemporaries. In it, the author repeatedly expounds the doctrine that the universe consists of only two places, the Earth below the firmament and heaven above it. Carefully drawing on arguments from scripture, he describes the Earth as a rectangle, 400 day's journey long by 200 wide, surrounded by four oceans and enclosed by four massive walls which support the firmament. The spherical Earth theory is contemptuously dismissed as "pagan".
Severian, Bishop of Gabala (d. 408), wrote that the Earth is flat and the sun does not pass under it in the night, but "travels through the northern parts as if hidden by a wall". Basil of Caesarea (329–379) argued that the matter was theologically irrelevant.
Early Middle Ages.
Early medieval Christian writers in the early Middle Ages felt little urge to assume flatness of the earth, though they had fuzzy impressions of the writings of Ptolemy, Aristotle, and relied more on Pliny.
With the end of Roman civilization, Western Europe entered the Middle Ages with great difficulties that affected the continent's intellectual production. Most scientific treatises of classical antiquity (in Greek) were unavailable, leaving only simplified summaries and compilations. Still, many textbooks of the Early Middle Ages supported the sphericity of the Earth. For example: some early medieval manuscripts of Macrobius include maps of the Earth, including the antipodes, zonal maps showing the Ptolemaic climates derived from the concept of a spherical Earth and a diagram showing the Earth (labeled as "globus terrae", the sphere of the Earth) at the center of the hierarchically ordered planetary spheres. Further examples of such medieval diagrams can be found in medieval manuscripts of the Dream of Scipio. In the Carolingian era, scholars discussed Macrobius's view of the antipodes. One of them, the Irish monk Dungal, asserted that the tropical gap between our habitable region and the other habitable region to the south was smaller than Macrobius had believed.
Europe's view of the shape of the Earth in Late Antiquity and the Early Middle Ages may be best expressed by the writings of early Christian scholars:
A possible non-literary but graphic indication that people in the Middle Ages believed that the Earth (or perhaps the world) was a sphere is the use of the "orb" (globus cruciger) in the regalia of many kingdoms and of the Holy Roman Empire. It is attested from the time of the Christian late-Roman emperor Theodosius II (423) throughout the Middle Ages; the "Reichsapfel" was used in 1191 at the coronation of emperor Henry VI. However the word 'orbis' means 'circle' and there is no record of a globe as a representation of the Earth since ancient times in the west till that of Martin Behaim in 1492. Additionally it could well be a representation of the entire 'world' or cosmos.
A recent study of medieval concepts of the sphericity of the Earth noted that "since the eighth century, no cosmographer worthy of note has called into question the sphericity of the Earth." However, the work of these intellectuals may not have had significant influence on public opinion, and it is difficult to tell what the wider population may have thought of the shape of the Earth, if they considered the question at all.
High and Late Middle Ages.
By the 11th century Europe had learned of Islamic astronomy. The Renaissance of the 12th century from about 1070 started an intellectual revitalization of Europe with strong philosophical and scientific roots, and increased interest in natural philosophy.
Hermannus Contractus (1013–1054) was among the earliest Christian scholars to estimate the circumference of Earth with Eratosthenes' method. Thomas Aquinas (1225–1274), the most important and widely taught theologian of the Middle Ages, believed in a spherical Earth; and he even took for granted his readers also knew the Earth is round. Lectures in the medieval universities commonly advanced evidence in favor of the idea that the Earth was a sphere. Also, "On the Sphere of the World", the most influential astronomy textbook of the 13th century and required reading by students in all Western European universities, described the world as a sphere. Thomas Aquinas, in his Summa Theologica, wrote, "The physicist proves the earth to be round by one means, the astronomer by another: for the latter proves this by means of mathematics, e.g. by the shapes of eclipses, or something of the sort; while the former proves it by means of physics, e.g. by the movement of heavy bodies towards the center, and so forth."
The shape of the Earth was not only discussed in scholarly works written in Latin; it was also treated in works written in vernacular languages or dialects and intended for wider audiences. The Norwegian book Konungs Skuggsjá, from around 1250, states clearly that the Earth is round—and that there is night on the opposite side of the Earth when there is daytime in Norway. The author also discusses the existence of antipodes—and he notes that (if they exist) they see the Sun in the north of the middle of the day, and that they experience seasons opposite those of people in the Northern Hemisphere.
However Tattersall shows that in many vernacular works in 12th- and 13th-century French texts the Earth was considered "round like a table" rather than "round like an apple". "In virtually all the examples quoted...from epics and from non-'historical' romances (that is, works of a less learned character) the actual form of words used suggests strongly a circle rather than a sphere, though notes that even in these works the language is ambiguous.
As late as 1674, Robert Hooke could argue "To one who has been conversant only with illiterate persons, or such as understand not the principles of Astronomy and Geometry...who can scarce imagine the Earth is globous, but...imagine it to be a round plain covered with the Sky as with a Hemisphere", suggesting that the opinion was not uncommon even then.
Portuguese exploration of Africa and Asia, Columbus's voyage to the Americas (1492) and finally Ferdinand Magellan's circumnavigation of the Earth (1519–21) provided the final, practical proofs for the global shape of the Earth.
Islamic world.
The Abbasid Caliphate saw a great flowering of astronomy and mathematics in the 9th century CE. in which Muslim scholars translated Ptolemy's work, which become the Almagest, and extended and updated his work based on spherical ideas, and these have generally been respected since. However, after the decline of the Golden Age in the 13th century more traditional views were increasingly heard.
The Quran mentions that the world was "laid out". To this a classic Sunni commentary, the Tafsir al-Kabir (al-Razi) written in the late 12th century says "If it is said: Do the words “And the earth We spread out” indicate that it is flat? We would respond: Yes, because the earth, even though it is round, is an enormous sphere, and each little part of this enormous sphere, when it is looked at, appears to be flat. As that is the case, this will dispel what they mentioned of confusion. The evidence for that is the verse in which Allah says (interpretation of the meaning): “And the mountains as pegs” . He called them awtaad (pegs) even though these mountains may have large flat surfaces. And the same is true in this case."
A later classic Sunni commentary, the Tafsir al-Jalalayn written in the early 16th century says "As for His words sutihat, ‘laid out flat’, this on a literal reading suggests that the earth is flat, which is the opinion of most of the scholars of the eveale Law, and not a sphere as astronomers (ahl al-hay’a) have it, even if this atte does not contradict any of the pillars of the Law." Other translations render "made flat" as "spread out".
Ming China.
As late as 1595, an early Jesuit missionary to China, Matteo Ricci, recorded that the Chinese say: "The earth is flat and square, and the sky is a round canopy; they did not succeed in conceiving the possibility of the antipodes." The universal belief in a flat Earth is confirmed by a contemporary Chinese encyclopedia from 1609 illustrating a flat Earth extending over the horizontal diametral plane of a spherical heaven.
In the 17th century, the idea of a spherical Earth spread in China due to the influence of the Jesuits, who held high positions as astronomers at the imperial court.
Myth of the flat Earth.
Beginning in the 19th century, a historical myth arose which held that the predominant cosmological doctrine during the Middle Ages was that the Earth was flat. An early proponent of this myth was the American writer, Washington Irving, who maintained that Christopher Columbus had to overcome the opposition of churchmen to gain sponsorship for his voyage of exploration. Later significant advocates of this view were John William Draper and Andrew Dickson White, who used it as a major element in their advocacy of the thesis that there was a long lasting and essential conflict between science and religion. Subsequent historical research has demonstrated two flaws in this approach. First, studies of medieval science have shown that the preponderance of scholars in the Middle Ages, including those read by Christopher Columbus, maintained that the Earth was spherical. Second, studies of the relations between science and religion over the course of time have demonstrated that the model of an essential conflict is a vast oversimplication, which ignores the positive elements of the relations between them.
Modern Flat-Earthers.
In the modern era, belief in a flat Earth has been expressed by isolated individuals and groups, but no scientists of note. 
English writer Samuel Rowbotham (1816–1885), writing under the pseudonym "Parallax," produced a pamphlet called "Zetetic Astronomy" in 1849 arguing for a flat Earth and published results of many experiments that tested the curvatures of water over a long drainage ditch, followed by another called "The inconsistency of Modern Astronomy and its Opposition to the Scripture". One of his supporters, John Hampden, lost a bet to Alfred Russel Wallace in the famous Bedford Level Experiment, which attempted to prove it. In 1877 Hampden produced a book called "A New Manual of Biblical Cosmography". Rowbotham also produced studies that purported to show that the effects of ships disappearing below the horizon could be explained by the laws of perspective in relation to the human eye. In 1883 he founded Zetetic Societies in England and New York, to which he shipped a thousand copies of "Zetetic Astronomy".
William Carpenter, a printer originally from Greenwich, England, was a supporter of Rowbotham and published "Theoretical Astronomy Examined and Exposed – Proving the Earth not a Globe" in eight parts from 1864 under the name "Common Sense". He later emigrated to Baltimore where he published "A hundred proofs the Earth is not a Globe" in 1885. He said:
John Jasper, the black ex-slave preacher said to have preached to more people than any Southern clergyman of his generation, echoed his friend Carpenter's sentiments in his most famous sermon "Der Sun do move and the Earth Am Square", preached over 250 times always by invitation.
In Brockport, New York, in 1887, M.C. Flanders argued the case of a flat Earth for three nights against two scientific gentlemen defending sphericity. Five townsmen chosen as judges voted unanimously for a flat Earth at the end. The case was reported in the "Brockport Democrat".
"Professor" Joseph W. Holden of Maine, a former justice of the peace, gave numerous lectures in New England and lectured on flat Earth theory at the Columbian Exposition in Chicago. His fame stretched to North Carolina where the Statesville "Semi-weekly Landmark" recorded at his death in 1900: 'We hold to the doctrine that the earth is flat ourselves and we regret exceedingly to learn that one of our members is dead'.
After Rowbotham's death, Lady Elizabeth Blount created the Universal Zetetic Society in 1893 in England and created a journal called "Earth not a Globe Review," which sold for twopence, as well as one called "Earth," which only lasted from 1901 to 1904. She held that the Bible was the unquestionable authority on the natural world and argued that one could not be a Christian and believe the Earth is a globe. Well-known members included E. W. Bullinger of the Trinitarian Bible Society, Edward Haughton, senior moderator in natural science in Trinity College, Dublin and an archbishop. She repeated Rowbotham's experiments, generating some interesting counter-experiments, but interest declined after the First World War. The movement gave rise to several books that argued for a flat, stationary earth, including "Terra Firma" by David Wardlaw Scott.
In 1898, during his solo circumnavigation of the world, Joshua Slocum encountered a group of flat-Earthers in Durban. Three Boers, one of them a clergyman, presented Slocum with a pamphlet in which they set out to prove that the world was flat. Paul Kruger, President of the Transvaal Republic, advanced the same view: "You don't mean "round" the world, it is impossible! You mean "in" the world. Impossible!"
Wilbur Glenn Voliva, who in 1906 took over the Christian Catholic Church, a Pentecostal sect that established a utopian community at Zion, Illinois, preached flat Earth doctrine from 1915 onwards and used a photograph of a twelve-mile stretch of the shoreline at Lake Winnebago, Wisconsin taken three feet above the waterline to prove his point. When the airship "Italia" disappeared on an expedition to the North Pole in 1928 he warned the world's press that it had sailed over the edge of the world. He offered a $5,000 award for proving the Earth is not flat, under his own conditions. Teaching a globular Earth was banned in the Zion schools and the message was transmitted on his WCBD radio station.
Mohammed Yusuf, founder of the Nigerian militant Islamist group Boko Haram, stated his belief in a flat Earth.
In January 2016, rapper B.o.B tweeted that "A lot of people are turned off by the phrase 'flat earth' ... but there's no way u can see all the evidence and not know... grow up", and accused NASA of hiding the truth. Astrophysicist Neil deGrasse Tyson replied to B.o.B.'s arguments, commenting that "Being five centuries regressed in your reasoning doesn't mean we all can't still like your music."
Flat Earth Society.
In 1956, Samuel Shenton set up the "International Flat Earth Research Society" (IFERS), better known as the Flat Earth Society from Dover, UK, as a direct descendant of the Universal Zetetic Society. This was just before the Soviet Union launched the first artificial satellite, Sputnik; he responded, "Would sailing round the Isle of Wight prove that it were spherical? It is just the same for those satellites."
His primary aim was to reach children before they were convinced about a spherical Earth. Despite plenty of publicity, the space race eroded Shenton's support in Britain until 1967 when he started to become famous due to the Apollo program. His postbag was full but his health suffered as his operation remained essentially a one-man show until he died in 1971.
In 1972 Shenton's role was taken over by Charles K. Johnson, a correspondent from California, USA. He incorporated the IFERS and steadily built up the membership to about 3,000. He spent years examining the studies of flat and round Earth theories and proposed evidence of a conspiracy against flat-Earth: "The idea of a spinning globe is only a conspiracy of error that Moses, Columbus, and FDR all fought..." His article was published in the magazine "Science Digest", 1980. It goes on to state, "If it is a sphere, the surface of a large body of water must be curved. The Johnsons have checked the surfaces of Lake Tahoe and the Salton Sea without detecting any curvature."
The Society declined in the 1990s following a fire at its headquarters in California and the death of Johnson in 2001. It was revived as a website in 2004 by Daniel Shenton (no relation to Samuel Shenton). He believes that no one has provided proof that the world is not flat.
Cultural references.
The term "flat-Earther" is often used in a derogatory sense to mean anyone who holds ridiculously antiquated views. The first use of the term "flat-earther" recorded by the "Oxford English Dictionary" is in 1934 in "Punch": "Without being a bigoted flat-earther, he c. Mercato perceived the nuisance..of fiddling about with globes..in order to discover the South Seas." The term "flat-earth-man" was recorded in 1908: "Fewer votes than one would have thought possible for any human candidate, were he even a flat-earth-man."
Scientific satire.
In a satirical piece published 1996, Albert A. Bartlett uses arithmetic to show that sustainable growth on Earth is impossible in a spherical Earth since its resources are necessarily finite. He explains that only a model of a flat Earth, stretching infinitely in the two horizontal dimensions and also in the vertical downward direction, would be able to accommodate the needs of a permanently growing population.
Referring to Julian Simon's book "The Ultimate Resource", Bartlett suggests "So, let us think of the 'We’re going to grow the limits!' people as the 'New Flat Earth Society.'" The satiric nature of the piece is also made clear by a comparison to Bartlett's other publications, which mainly advocate the necessity of curbing population growth.

</doc>
<doc id="11600" url="https://en.wikipedia.org/wiki?curid=11600" title="Persian language">
Persian language

Persian ( or ; "" ) is the predominant modern descendant of Old Persian, a southwestern Iranian language within the Indo-Iranian branch of the Indo-European languages. It is primarily spoken in Iran, Afghanistan (officially known as "Dari" since 1958 for political reasons), and Tajikistan (officially known as "Tajiki" since the Soviet era for political reasons), and some other regions which historically came under Persian influence. The Persian language is classified as a continuation of Middle Persian, the official religious and literary language of Sassanid Persia, itself a continuation of Old Persian, the language of the Achaemenid Persian Empire. Persian is a pluricentric language and its grammar is similar to that of many contemporary European languages. Persian is so-called due to its origin from the capital of the Achaemenid Empire, Persis (Modern day Pars/Fars province), hence the name Persian (Parsi/Farsi). A Persian-speaking person may be referred to as "Persophone".
There are approximately 110 million Persian speakers worldwide, with the language holding official status in Iran, Afghanistan, and Tajikistan. For centuries, Persian has also been a prestigious cultural language in other regions of Western Asia, Central Asia, and South Asia by the various empires based in the regions.
Persian has had a considerable (mainly lexical) influence on neighboring languages, particularly the Turkic languages in Central Asia, Caucasus, and Anatolia, neighboring Iranian languages, as well as Armenian, Georgian, and Indo-Aryan languages, especially Urdu. It also exerted some influence on Arabic, particularly Bahrani Arabic, while borrowing much vocabulary from it after the Muslim conquest of Persia.
With a long history of literature in the form of Middle Persian before Islam, Persian was the first language in Muslim civilization to break through Arabic's monopoly on writing, and the writing of poetry in Persian was established as a court tradition in many eastern courts. Some of the famous works of Persian literature are the "Shahnameh" ('Book of Kings') of Ferdowsi, works of Rumi, Rubaiyat of Omar Khayyam, Divan ('miscellany') of Hafiz and the two miscellanea of prose and verse by Sa'di of Shiraz, the "Golestān" (lit., 'flower garden') and the "Būstān" (also meaning "garden;" lit., 'a place of fragrance').
Classification.
Persian belongs to the Western branch of the Iranian family of Indo-European languages, which also includes Kurdish, Gilaki, Mazandarani, Talyshi, and Baluchi. The language is in the Southwestern Iranian group, along with the Larestani, Kumzari, and Luri languages.
Etymology.
Persian language name in Persian.
In Persian, the language is known by several names:
Persian language name in English.
"Persian", the historically more widely used name of the language in English, is an anglicized form derived from Latin * < Latin < Greek "Persia", a Hellenized form of Old Persian . According to the "Oxford English Dictionary", the term "Persian" as a language name is first attested in English in the mid-16th century. Native Iranian Persian speakers call it "Fārsi". "Farsi" is the Arabicized form of "Pārsi", subsequent to Muslim conquest of Persia, due to a lack of the phoneme /p/ in Standard Arabic (i.e., the /p/ was replaced with an /f/). The origin of the name "Farsi" and the place of origin of the language which is "Fars Province" is the Arabicized form of "Pārs". In English, this language has historically been known as "Persian", though "Farsi" has also gained some currency. According to the Oxford English Dictionary, the term "Farsi" was first used in English in 1926, while "Parsi" dates to 1790. "Farsi" is encountered in some linguistic literature as a name for the language, used both by Iranian and by foreign authors.
In South Asia the word "Farsi" refers to the language while "Parsi" describes the people of Persian origin, particularly Zoroastrians.
The Academy of Persian Language and Literature has declared that the name "Persian" is more appropriate, as it has the longer tradition in western languages and better expresses the role of the language as a mark of cultural and national continuity. Some Persian language scholars such as Ehsan Yarshater, editor of "Encyclopædia Iranica", and University of Arizona professor Kamran Talattof, have also rejected the usage of "Farsi" in their articles.
The international language-encoding standard ISO 639-1 uses the code "fa", as its coding system is mostly based on the local names. The more detailed standard ISO 639-3 uses the name "Persian" (code "fas") for the dialect continuum spoken across Iran and Afghanistan. This consists of the individual languages Dari (Afghan Persian) and Iranian Persian.
Currently, VOA, BBC, DW, and RFE/RL use "Persian Service" for their broadcasts in the language. RFE/RL also includes a Tajik service, and an Afghan (Dari) service. This is also the case for the American Association of Teachers of Persian, The Centre for Promotion of Persian Language and Literature, and many of the leading scholars of Persian language.
History.
Persian is an Iranian language belonging to the Indo-Iranian branch of the Indo-European family of languages. In general, Iranian languages are known from three periods, usually referred to as Old, Middle, and New (Modern) periods. These correspond to three eras in Iranian history; Old era being the period from sometime before Achaemenids, the Achaemenid era and sometime after Achaemenids (that is to 400–300 BC), Middle era being the next period most officially Sassanid era and sometime in post-Sassanid era, and the New era being the period afterwards down to present day.
According to available documents, the Persian language is "the only Iranian language" for which close philological relationships between all of its three stages are established and so that Old, Middle, and New Persian represent one and the same language of Persian, that is New Persian is a direct descendant of Middle and Old Persian.
The known history of the Persian language can be divided into the following three distinct periods:
Old Persian.
As a written language, Old Persian is attested in royal Achaemenid inscriptions. It is an Iranian language and as such, like its modern-day variant, a branch of the Indo-European language family. The oldest known text written in Old Persian is from the Behistun Inscriptions. Examples of Old Persian have been found in what is now present-day Iran, Romania (Gherla), Armenia, Bahrain, Iraq, Turkey and Egypt. Old Persian is one of the oldest Indo-European languages which is attested in original texts.
Xenophon, a Greek general serving in some of the Persian expeditions, describes many aspects of Armenian village life and hospitality in around 401 BC, which is at a time when Old Persian was the only form of Persian used. He relates that the Armenian people spoke a language that to his ear sounded like this language, the language of the Persians.
Middle Persian.
The complex conjugation and declension of Old Persian yielded to the structure of Middle Persian in which the dual number disappeared, leaving only singular and plural, as did gender. Middle Persian developed the ezāfe construction, expressed through ī, to indicate some of the relations between words that have been lost with the simplification of the earlier grammatical system.
Although the "middle period" of the Iranian languages formally begins with the fall of the Achaemenid Empire, the transition from Old to Middle Persian had probably already begun before the 4th century. However, Middle Persian is not actually attested until 600 years later when it appears in Sassanid era (224–651) inscriptions, so any form of the language before this date cannot be described with any degree of certainty. Moreover, as a literary language, Middle Persian is not attested until much later, to the 6th or 7th century. And from the 8th century onward, Middle Persian gradually began yielding to New Persian, with the middle-period form only continuing in the texts of Zoroastrian tradition.
The native name of Middle Persian was "Parsig" or "Parsik", after the name of the ethnic group of the southwest, that is, "of "Pars"", Old Persian "Parsa", New Persian "Fars". This is the origin of the name "Farsi" as it is today used to signify New Persian. Following the collapse of the Sassanid state, "Parsik" came to be applied exclusively to (either Middle or New) Persian that was written in Arabic script. From about the 9th century onwards, as Middle Persian was on the threshold of becoming New Persian, the older form of the language came to be erroneously called "Pahlavi", which was actually but one of the "writing systems" used to render both Middle Persian as well as various other Middle Iranian languages. That writing system had previously been adopted by the Sassanids (who were Persians, i.e. from the southwest) from the preceding Arsacids (who were Parthians, i.e. from the northeast). While Rouzbeh (Abdullah Ibn al-Muqaffa, 8th century) still distinguished between "Pahlavi" (i.e. Parthian) and "Persian" (in Arabic text: al-Farisiah) (i.e. Middle Persian), this distinction is not evident in Arab commentaries written after that date.
Gernot Windfuhr considers new Persian as an evolution of the Old Persian language and the Middle Persian language but also states that none of the known Middle Persian dialects is the direct predecessor of Modern Persian. Ludwig Paul states: "The language of the Shahnameh should be seen as one instance of continuous historical development from Middle to New Persian."
New Persian.
The history of New Persian itself spans more than 1,000–1,200 years. The development of the language in its last period is often divided into three stages dubbed early, classical, and contemporary. Native speakers of the language can in fact understand early texts in Persian with minimal adjustment, because the morphology and, to a lesser extent, the lexicon of the language have remained relatively stable for the greater part of a millennium.
Early New Persian.
New Persian developed from the 8th century on as an independent literary language.
Upon the decline of the Caliphate at Baghdad in the 9th century began the re-establishment of Persian national life and Persians laid the foundations for a renaissance in the realm of letters. New Persian was born in Bactria through the adaptation of the spoken form of Sassanian Middle Persian court language called Dari. The cradle of the Persian literary renaissance lay in the east of Greater Iran, in the Greater Khorasan and Transoxiana regions close to the river Amu Darya.
The mastery of the newer speech having now been transformed from Middle into New Persian was already complete during three princely
dynasties of Iranian origin Tahirid (820–872), Saffarid (860–903) and Samanid (874–999), and could develop only in range and power of expression.
Abbas of Merv is mentioned as being the earliest minstrel to chant verse in the newer Persian tongue and after him the poems of Hanzala Badghisi were among the most famous between the Persian-speakers of the time.
The first poems of the Persian language, a language historically called Dari, have emerged in Afghanistan. The first significant Persian poet was Rudaki. He flourished in the 10th century, when the Sāmānids were at the height of their power. His reputation as a court poet and as an accomplished musician and singer has survived, although little of his poetry has been preserved. Among his lost works is versified fables collected in Kalilah va Dimnah.
The language spread geographically from the 11th century on and was the medium through which among others, Central Asian Turks became familiar with Islam and urban culture. New Persian was widely used as a trans-regional lingua franca, a task for which it was particularly suitable due to its relatively simple morphological structure and this situation persisted until at least 19th century. In the late Middle Ages, new Islamic literary languages were created on the Persian model: Ottoman, Chaghatay and Urdu, which are regarded as "structural daughter languages" of Persian.
Classical Persian.
The Islamic conquest of Persia marks the beginning of the new history of Persian language and literature. This period produced world class Persian language poets and the language served, for a long span of time, as the lingua franca of major parts of the Islamic world and South Asia. It was also the official and cultural language of many Islamic dynasties, including Samanids, Buyids, Tahirids, Ziyarids, the Mughal Empire, Timurids, Ghaznavid, Seljuq, Khwarezmids, Sultanate of Rum, Shirvanshah,
Safavid, Afsharids, Zand, Qajar, Ottomans and also many Mughal successor states such as the Nizams etc. For example, Persian was the only oriental language known and used by Marco Polo at the Court of Kublai Khan and in his journeys through China. The heavy influence of Persian on other languages can still be witnessed across the Islamic world, especially, and it is still appreciated as a literary and prestigious language among the educated elite, especially in fields of music (for example Qawwali) and art (Persian literature). After the Arab invasion of Persia, Persian began to adopt many words from Arabic and as time went by, a few words were even taken from Turko-Mongol languages under the Mongol Empire and Turco-Persian society.
Use in Asia Minor.
Despite of Asia Minor (or Anatolia) having been ruled at various times prior to the Middle Ages by various Persian-speaking dynasties originating in Iran, the language lost its traditional foothold there with the demise of the Sassanian Empire. Centuries later however, the practise and usage of Persian in the region would be strongly revived. A branch of the Seljuks, the Sultanate of Rum, took Persian language, art and letters to Anatolia. They adopted Persian language as the official language of the empire. The Ottomans, which can "roughly" be seen as their eventual successors, took this tradition over. Persian was the official court language of the empire, and for some time, the official language of the empire. The educated and noble class of the Ottoman Empire all spoke Persian, such as sultan Selim I, despite being Safavid Iran's archrival and a staunch opposer of Shia Islam. It was a major literary language in the empire. Some of the noted earlier Persian works during the Ottoman rule are Idris Bidlisi's "Hasht Bihisht", which begun in 1502 and covered the reign of the first eight Ottoman rulers, and the "Salim-Namah", a glorification of Selim I. After a period of several centuries, Ottoman Turkish (which was highly Persianised itself) had developed towards a fully accepted language of literature, which was even able to satisfy the demands of a scientific presentation. However, the number of Persian and Arabic loanwords contained in those works increased at times up to 88%.
Use in South Asia.
The Persian language influenced the formation of many modern languages in West Asia, Europe, Central Asia, and South Asia. Following the Turko-Persian Ghaznavid conquest of South Asia, Persian was firstly introduced in the region by Turkic Central Asians. The basis in general for the introduction of Persian language into the subcontinent was set, from its earliest days, by various Persianized Central Asian Turkic and Afghan dynasties. For five centuries prior to the British colonization, Persian was widely used as a second language in the Indian subcontinent, due to the admiration the Mughals (who were of Turco-Mongol origin) had for the foreign language. It took prominence as the language of culture and education in several Muslim courts on the subcontinent and became the sole "official language" under the Mughal emperors.
Beginning in 1843, though, English and Hindustani gradually replaced Persian in importance on the subcontinent. Evidence of Persian's historical influence there can be seen in the extent of its influence on certain languages of the Indian subcontinent. Words borrowed from Persian are still quite commonly used in certain Indo-Aryan languages, especially Urdu, also historically known as Hindustani. There is also a small population of Zoroastrian Iranis in India, who migrated around 16th-18th century to escape religious execution from the Qajar Empire when execution of non-Muslims was on its high and speak a Dari-dialect.
Contemporary Persian.
Since the nineteenth century, Russian, French and English and many other languages have contributed to the technical vocabulary of Persian. The Iranian National Academy of Persian Language and Literature is responsible for evaluating these new words in order to initiate and advise their Persian equivalents. The language itself has greatly developed during the centuries.
Varieties.
There are three modern varieties of standard Persian:
All these three varieties are based on the classic Persian literature and its literary tradition. There are also several local dialects from Iran, Afghanistan and Tajikistan which slightly differ from the standard Persian. Hazaragi (in Central Afghanistan and Pakistan), Herati (in Western Afghanistan), Darwazi (in Afghanistan and Tajikistan), and Tehrani (in Iran, the basis of standard Iranian Persian) are examples of these dialects. Persian-speaking peoples of Iran, Afghanistan, and Tajikistan can understand one another with a relatively high degree of mutual intelligibility.
The following are some languages closely related to Persian, or in some cases are considered dialects:
Phonology.
Iranian Persian has six vowels and twenty-three consonants.
Vowels.
Historically, Persian has distinguished length: Early New Persian possessed a series of five long vowels (, , , and ) along with three short vowels , and . At some point prior to the sixteenth century within the general area that is today encompassed by modern Iran, and merged into , and and merged into . Thus, the older contrasts such as شیر "shēr" "lion" vs. شیر "shīr" "milk", and رود "rūd" "river" vs رود "rōd" "bow-string" were lost. However, there are exceptions to this rule, and in some words "ē" and "ō" are preserved or merged into the diphthongs and (which are descendants of the diphthongs and in Early New Persian), instead of merging into and . Examples of this exception can be found in words such as روشن (bright).
However, in the eastern varieties, the archaic distinction of and (respectively known as یای مجهول "Yā-ye majhūl" and یای معروف "Yā-ye ma'rūf") is still preserved, as well as the distinction of and (known as واو مجهول "Wāw-e majhūl" and واو معروف "Wāw-e ma'rūf"). On the other hand, in standard Tajik, the length distinction has disappeared and merged with , and with . Therefore, contemporary Afghan Dari dialects are the closest one can get to the vowel inventory of Early New Persian.
According to most studies on the subject (e.g. Samareh 1977, Pisowicz 1985, Najafi 2001), the three vowels which are traditionally considered long (, , ) are currently distinguished from their short counterparts (, , ) by position of articulation, rather than by length. However, there are studies (e.g. Hayes 1979, Windfuhr 1979) which consider vowel length to be the active feature of this system, i.e. /ɒ/, /i/, and /u/ are phonologically long or bimoraic whereas /æ/, /e/, and /o/ are phonologically short or monomoraic.
There are also some studies which consider quality and quantity to be both active in the Iranian system (e.g. Toosarvandani 2004). This view offers a synthetic analysis which includes both quality and quantity, often suggesting that modern Persian vowels are in a transition state between the quantitative system of classical Persian and a hypothetical future Persian which will eliminate all traces of quantity, and retain quality as the only active feature.
The length distinction is nevertheless strictly observed by careful reciters of classic-style poetry, for all varieties (including the Tajik).
Grammar.
Syntax.
Normal declarative sentences are structured as "(S) (PP) (O) V". This means sentences can comprise optional subjects, prepositional phrases, and objects, followed by a required verb. If the object is specific, then the object is followed by the word "rā" and precedes prepositional phrases: "(S) (O + "rā") (PP) V".
Vocabulary.
Native word formation.
Persian makes extensive use of word building and combining affixes, stems, nouns and adjectives. Persian frequently uses derivational agglutination to form new words from nouns, adjectives, and verbal stems. New words are extensively formed by compounding – two existing words combining into a new one, as is common in German.
Influences.
While having a lesser influence on Arabic and other languages of Mesopotamia and its core vocabulary being of Middle Persian origin, New Persian contains a considerable amount of Arabic lexical items, which were Persianized and often took a different meaning and usage than the Arabic original. Persian loanwords of Arabic origin especially include Islamic terms. The Arabic vocabulary in other Iranian, Turkic and Indic languages are generally understood to have been copied from New Persian, not from Arabic itself.
John R. Perry, in his article "Lexical Areas and Semantic Fields of Arabic", estimates that about 24 percent of an everyday vocabulary of 20,000 words in current Persian, and more than 25 percent of the vocabulary of classical and modern Persian literature, are of Arabic origin. The text frequency of these loan words is generally lower and varies by style and topic area. It may approach 25 percent of a text in literature. Among the Arabic loan words, relatively few (14 percent) are from the semantic domain of material culture, while a larger number are from domains of intellectual and spiritual life. Most of the Arabic words used in Persian are either synonyms of native terms or could be glossed in Persian.
The inclusion of Mongolian and Turkic elements in the Persian language should also be mentioned, not only because of the political role a succession of Turkic dynasties played in Iranian history, but also because of the immense prestige Persian language and literature enjoyed in the wider (non-Arab) Islamic world, which was often ruled by sultans and emirs with a Turkic background. The Turkish and Mongolian vocabulary in Persian is minor in comparison to that of Arabic and these words were mainly confined to military, pastoral terms and political sector (titles, administration, etc.). New military and political titles were coined based partially on Middle Persian (e.g. "arteš" for "army", instead of the Uzbek "qoʻshin"; "sarlaškar"; "daryābān"; etc.) in the 20th century.
Persian has likewise influenced the vocabularies of other languages, especially other Indo-European languages such as Armenian, Urdu, and (to a lesser extent) Hindi; the latter two through conquests of Persianized Central Asian Turkic and Afghan invaders; Turkic languages such as Ottoman Turkish, Chagatai, Tatar, Turkish, Turkmen, Azeri, Uzbek, and Karachay-Balkar; Caucasian languages such as Georgian, and to a lesser extent, Avar and Lezgin; Afro-Asiatic languages like Assyrian (List of loanwords in Assyrian Neo-Aramaic) and Arabic; and even Dravidian languages indirectly especially Telugu and Brahui; as well as Austronesian languages such as Indonesian and Malay. Persian has also had a significant lexical influence, via Turkish, on Serbian, Croatian, Bosnian, and Serbo-Croatian, particularly as spoken in Bosnia and Herzegovina.
Use of occasional foreign synonyms instead of Persian words can be a common practice in everyday communications as an alternative expression. In some instances in addition to the Persian vocabulary, the equivalent synonyms from multiple foreign languages can be used. For example, in Iranian colloquial Persian (not in Afghanistan or Tajikistan), the phrase "thank you" may be expressed using the French word "merci" (stressed however on the first syllable), the hybrid Persian-Arabic phrase "motešakker am" ("motešakker" being "merciful" in Arabic, commonly pronounced "motčakker" in Persian, and the verb "am" meaning "I am" in Persian), or by the pure Persian phrase "sepās-gozār am".
Orthography.
The vast majority of modern Iranian Persian and Dari text is written with the Arabic script. Tajik, which is considered by some linguists to be a Persian dialect influenced by Russian and the Turkic languages of Central Asia, is written with the Cyrillic script in Tajikistan (see Tajik alphabet).
Persian alphabet.
Modern Iranian Persian and Afghan Persian are written using a modified variant of the Arabic alphabet, which uses different pronunciation and additional letters not found in Arabic. Tajik Persian, as used in Tajikistan, is typically written in a modified version of the Cyrillic alphabet. There also exist several romanization systems for Persian. After the conversion of Persia to Islam (see Islamic conquest of Iran), it took approximately 150 years before Persians adopted the Arabic script in place of the older alphabet. Previously, two different scripts were used, Pahlavi, used for Middle Persian, and the Avestan alphabet (in Persian, Dīndapirak or Din Dabire—literally: religion script), used for religious purposes, primarily for the Avestan language but sometimes for Middle Persian.
In modern Persian script, vowels that are referred to as short vowels ("a, e, o") are usually not written; only the long vowels ("'ā, ī, ū") are represented in the text, so words distinguished from each other only by short vowels are ambiguous in writing: "kerm" "worm", "karam" "generosity", "kerem" "cream", and "krom" "chrome" are all spelled "krm" () in Persian. The reader must determine the word from context. The Arabic system of vocalization marks known as "harakat" is also used in Persian, although some of the symbols have different pronunciations. For example, an Arabic "damma" is pronounced , while in Iranian Persian it is pronounced . This system is not used in mainstream Persian literature; it is primarily used for teaching and in some (but not all) dictionaries.
There are several letters generally only used in Arabic loanwords. These letters are pronounced the same as similar Persian letters. For example, there are four functionally identical letters for (), three letters for (), two letters for (), two letters for ().
On the other hand, there are four letters that don't exist in Arabic .
Additions.
The Persian alphabet adds four letters to the Arabic alphabet:
The "že" is pronounced with the same sound as the "s" in "measure" and "fusion", or the "z" in "azure". 
For Arabic speakers, it is similar to the way Lebanese or Syrians pronounce the Arabic letter "jīm" (ج).
For French speakers, it is the sound of the letter "j" or "g" when it's followed by an "e" or "i".
The letters "pe", "če" and "gaf" are similar to the English "p", "ch" and "hard" "g".
Variations.
The Persian alphabet also modifies some letters from the Arabic alphabet. For example, "alef with hamza below" (  ) changes to "alef" (  ); words using various hamzas get spelled with yet another kind of hamza (so that becomes ) even though the latter is also correct in Arabic; and "teh marbuta" (  ) changes to "heh" (  ) or "teh" (  ).
The letters different in shape are:
Latin alphabet.
The International Organization for Standardization has published a standard for simplified transliteration of Persian into Latin, ISO 233-3, titled "Information and documentation – Transliteration of Arabic characters into Latin characters – Part 3: Persian language – Simplified transliteration" but the transliteration scheme is not in widespread use.
Another Latin alphabet, based on the Uniform Turkic alphabet, was used in Tajikistan in the 1920s and 1930s. The alphabet was phased out in favor of Cyrillic in the late 1930s.
Fingilish is Persian using ISO basic Latin alphabet. It is most commonly used in chat, emails and SMS applications. The orthography is not standardized, and varies among writers and even media (for example, typing 'aa' for the phoneme is easier on computer keyboards than on cellphone keyboards, resulting in smaller usage of the combination on cellphones).
Tajik alphabet.
The Cyrillic alphabet was introduced for writing the Tajik language under the Tajik Soviet Socialist Republic in the late 1930s, replacing the Latin alphabet that had been used since the Bolshevik revolution and the Persian script that had been used earlier. After 1939, materials published in Persian in the Persian script were banned from the country.
Examples.
The following text is from Article 1 of the Universal Declaration of Human Rights.

</doc>
<doc id="11601" url="https://en.wikipedia.org/wiki?curid=11601" title="Farsi (disambiguation)">
Farsi (disambiguation)

Farsi is the indigenous name for the Persian language.
Farsi may also refer to:

</doc>
<doc id="11603" url="https://en.wikipedia.org/wiki?curid=11603" title="Frances Abington">
Frances Abington

Frances "Fanny" Abington (1737 – 4 March 1815) was a British actress, known not only for her acting, but her sense of fashion.
Biography.
She was born Frances Barton or Frances "Fanny" Barton, the daughter of a private soldier, and began her career as a flower girl and a street singer. She was also rumored that she would recite Shakespeare in Taverns at the age of 12 and for a short period of time was a prostitute to help her family in the hard times. Later she became a servant to a French milliner. She learned about costume and acquired a knowledge of French which afterwards stood her in good stead. Her early nickname, Nosegay Fan, came from her time as a flower girl. Her first appearance on the stage was at Haymarket in 1755 as Miranda in Mrs Centlivre's play, "Busybody".
In 1755, on the recommendation of Samuel Foote, she became a member of the Drury Lane company, where she was overshadowed by Hannah Pritchard and Kitty Clive. Her first success was in Ireland as Lady Townley (in "The Provok'd Husband" by Vanbrugh and Cibber), and it was only after five years, on the pressing invitation of David Garrick, that she returned to Drury Lane. In 1759, after an unhappy marriage to her music teacher James Abington, a royal trumpeter, she is mentioned in the bills as "Mrs Abington" and so she just kept his last name.She remained at the Drury Lane for eighteen years, being the first to play more than thirty important characters, notably Lady Teazle (1777). 
In April 1772, when James Northcote saw her Miss Notable in Cibber's "The Lady's Last Stake", he remarked to his brother 
Her Shakespearean heroines – Beatrice, Portia, Desdemona and Ophelia – were no less successful than her comic characters – Miss Hoyden, Biddy Tipkin, Lucy Lockit and Miss Prue.Mrs. Abington’s Kitty in "High Life Below Stairs" put her in the foremost rank of comic actresses, making the mob cap she wore in the role the reigning fashion“. This cap was soon referred to as the “Abington Cap” and frequently seen on stage as well as in hat shops across Ireland and England. Adoring fans donned copies of this cap and it became an essential part of the well-appointed woman’s wardrobe. 
The actress soon became known for her avant-garde fashion and she even came up with a way of making the female figure appear taller. She began to wear this tall-hat called a ziggurat complete with long flowing feathers and began to follow the French custom of putting red powder on her hair (Richards).
It was as the last character in Congreve's "Love for Love" that Sir Joshua Reynolds painted the best-known of his half-dozen or more portraits of her ("illustration, left"). In 1782 she left Drury Lane for Covent Garden. After an absence from the stage from 1790 until 1797, she reappeared, quitting it finally in 1799. Her ambition, personal wit and cleverness won her a distinguished position in society, in spite of her humble origin.

</doc>

<doc id="2767" url="https://en.wikipedia.org/wiki?curid=2767" title="ACE inhibitor">
ACE inhibitor

An angiotensin-converting-enzyme inhibitor (ACE inhibitor) is a pharmaceutical drug used primarily for the treatment of hypertension (elevated blood pressure) and congestive heart failure.
This group of drugs cause relaxation of blood vessels, as well as a decreased blood volume, which leads to lower blood pressure and decreased oxygen demand from the heart. They inhibit the angiotensin-converting enzyme, an important component of the renin-angiotensin-aldosterone system.
Frequently prescribed ACE inhibitors include perindopril, captopril, enalapril, lisinopril, and ramipril.
Medical use.
ACE inhibitors were initially approved for the treatment of hypertension and can be used alone or in combination with other antihypertensive medications. Later, they were found useful for other cardiovascular and kidney diseases including:
In treating heart disease, ACE inhibitors are usually used with other medications. A typical treatment plan often includes an ACE inhibitor, a beta blocker, a long-acting nitrate, and a calcium channel blocker in combinations that are adjusted to the individual patient's needs.
ACE inhibitors have also been used in chronic kidney failure and kidney involvement in systemic sclerosis (hardening of tissues, as scleroderma renal crisis)
Mechanism of action.
ACE inhibitors reduce the activity of the renin-angiotensin-aldosterone system (RAAS) as the primary etiologic (causal) event in the development of hypertension in people with diabetes mellitus, as part of the insulin-resistance syndrome or as a manifestation of renal disease.
Renin-angiotensin-aldosterone system.
One mechanism for maintaining the blood pressure is the release of renin, an enzyme, from cells in the kidney (to be specific, the juxtaglomerular apparatus). This proteolytically cleaves and activates another circulating protein, angiotensin. This system is activated in response to a fall in blood pressure (hypotension) and markers of problems with the salt-water balance of the body, such as decreased sodium concentration in the distal tubules of the kidney, decreased blood volume, and stimulation of the kidney by the sympathetic nervous system. In such situations, the kidneys release renin, which acts as an enzyme and cuts off all but the first ten amino acid residues of angiotensinogen (a protein made in the liver, and which circulates in the blood). These ten residues are then known as angiotensin I. ACE then removes a further two residues, converting angiotensin I into angiotensin II. Angiotensin II is found in the pulmonary circulation and in the endothelium of many blood vessels. The system increases blood pressure by increasing the amount of salt and water the body retains, although angiotensin is also very good at causing the blood vessels to tighten (a potent vasoconstrictor).
Effects.
ACE inhibitors block the conversion of angiotensin I (AI) to angiotensin II (AII). They thereby lower arteriolar resistance and increase venous capacity; decrease cardiac output, cardiac index, stroke work, and volume; lower resistance in blood vessels in the kidneys; and lead to increased natriuresis (excretion of sodium in the urine).
Renin increases in concentration in the blood as a result of negative feedback of conversion of AI to AII. AI increases for the same reason; AII and aldosterone decrease. Bradykinin increases because of less inactivation by ACE.
Under normal conditions, angiotensin II has these effects:
With ACE inhibitor use, the production of AII is decreased, leading to decreased blood pressure.
Epidemiological and clinical studies have shown ACE inhibitors reduce the progress of diabetic nephropathy independently from their blood pressure-lowering effect. This action of ACE inhibitors is used in the prevention of diabetic renal failure.
ACE inhibitors have been shown to be effective for indications other than hypertension even in patients with normal blood pressure. The use of a maximum dose of ACE inhibitors in such patients (including for prevention of diabetic nephropathy, congestive heart failure, and prophylaxis of cardiovascular events) is justified, because it improves clinical outcomes independently of the blood pressure-lowering effect of ACE inhibitors. Such therapy, of course, requires careful and gradual titration of the dose to prevent the effects of rapidly decreasing blood pressure (dizziness, fainting, etc.).
ACE inhibitors have also been shown to cause a central enhancement of parasympathetic nervous system activity in healthy volunteers and patients with heart failure. This action may reduce the prevalence of malignant cardiac arrhythmias, and the reduction in sudden death reported in large clinical trials.
ACE Inhibitors also reduce plasma norepinephrine levels, and its resulting vasoconstriction effects, in heart failure patients, thus breaking the vicious circles of sympathetic and renin angiotensin system activation, which sustains the downward spiral in cardiac function in congestive heart failure
The ACE inhibitor enalapril has also been shown to reduce cardiac cachexia in patients with chronic heart failure. Cachexia is a poor prognostic sign in patients with chronic heart failure.
ACE inhibitors are under early investigation for the treatment of frailty and muscle wasting (sarcopenia) in elderly patients without heart failure.
Adverse effects.
Common adverse drug reactions include: hypotension, cough, hyperkalemia, headache, dizziness, fatigue, nausea, and renal impairment. ACE inhibitors might increase inflammation-related pain, perhaps mediated by the buildup of bradykinin that accompanies ACE inhibition.
The main adverse effects of ACE inhibition can be understood from their pharmacological action. The other reported adverse effects are hepatotoxicity and effect on the fetus.
Renal impairment is a significant potential adverse effect of all ACE inhibitors, that directly follows from their mechanism of action. Patients starting on an ACE inhibitor usually have a modest reduction in glomerular filtration rate (GFR) that stabilizes after several days. However, the decrease may be significant in conditions of decreased renal perfusion, such as renal artery stenosis, heart failure, polycystic kidney disease, or volume depletion. In these patients, maintenance of GFR depends on angiotensin-II-dependent efferent vasomotor tone. Therefore, renal function should be closely monitored over the first few days after initiation of treatment with ACE inhibitor in patients with decreased renal perfusion. A moderate reduction in renal function, no greater than 30% rise in serum creatinine, that is stabilized after a week of treatment, is deemed acceptable as part of the therapeutic effect, providing the residual renal function is sufficient. This is especially a problem if the patient is concomitantly taking an NSAID and a diuretic. When the three drugs are taken together, the risk of developing renal failure is significantly increased.
Hyperkalemia is another possible complication of treatment with an ACE inhibitor due to its effect on aldosterone. Suppression of angiotensin II leads to a decrease in aldosterone levels. Since aldosterone is responsible for increasing the excretion of potassium, ACE inhibitors can cause retention of potassium. Some people, however, can continue to lose potassium while on an ACE inhibitor. Hyperkalemia may decrease the velocity of impulse conduction in the nerves and muscles, including cardiac tissues. This leads to cardiac dysfunction and neuromuscular consequences, such as muscle weakness, paresthesia, nausea, diarrhea, and others. Close monitoring of potassium levels is required in patients receiving treatment with ACE inhibitors who are at risk of hyperkalemia.
Another possible adverse effect specific for ACE inhibitors, but not for other RAAS blockers, is an increase in bradykinin level. Elevated bradykinin level due to ACE inhibition can be a cause of dry cough, angioedema and/or rash, hypotension, and inflammation-related pain.
A persistent dry cough is a relatively common adverse effect believed to be associated with the increases in bradykinin levels produced by ACE inhibitors, although the role of bradykinin in producing these symptoms has been disputed. Patients who experience this cough are often switched to angiotensin II receptor antagonists.
Some patients develop angioedema due to increased bradykinin levels. A genetic predisposition may exist toward this adverse effect in patients who degrade bradykinin more slowly than average.
Rash and taste disturbances, infrequent with most ACE inhibitors, are more prevalent in captopril, and this is attributed to its sulfhydryl moiety. This has led to decreased use of captopril in clinical setting, although it is still used in scintigraphy of the kidney.
A severe rare allergic reaction can affect the bowel wall and secondarily cause abdominal pain.
Adverse Hematologic Effects.
Hematologic effects, such as neutropenia, agranulocytosis and other blood dyscrasias have occurred during therapy with ACE inhibitors, especially in patients with additional risk factors (see Warnings). Patients should be advised to report symptoms such as sore throat or fever to their physician.
In pregnant women, ACE inhibitors taken during all the trimesters have been reported to cause congenital malformations, stillbirths, and neonatal deaths. Commonly reported fetal abnormalities include hypotension, renal dysplasia, anuria/oliguria, oligohydramnios, intrauterine growth retardation, pulmonary hypoplasia, patent ductus arteriosus, and incomplete ossification of the skull. Overall, about half of newborns exposed to ACE inhibitors are adversely affected.
Overdose.
Symptoms and Treatment: There are few reports of ACE inhibitor overdose in the literature. The most likely manifestations are hypotension, which may be severe, hyperkalemia, hyponatremia and renal impairment with metabolic acidosis. Treatment should be mainly symptomatic and supportive, with volume expansion using normal saline to correct hypotension and improve renal function, and gastric lavage followed by activated charcoal and a cathartic to prevent further absorption of the drug. Captopril, enalapril, lisinopril and perindopril are known to be removable by hemodialysis.
Contraindications and precautions.
The ACE inhibitors are contraindicated in patients with:
ACE inhibitors should be used with caution in patients with:
ACE inhibitors are ADEC pregnancy category D, and should be avoided in women who are likely to become pregnant. In the U.S., ACE inhibitors must be labeled with a boxed warning concerning the risk of birth defects when taken during the second and third trimester. Their use in the first trimester is also associated with a risk of major congenital malformations, particularly affecting the cardiovascular and central nervous systems.
A combination of ACE inhibitor with other drugs may increase effects of these drugs, but also the risk of adverse effects. The commonly reported adverse effects of drug combination with ACE are acute renal failure, hypotension, and hyperkalemia. The drugs interacting with ACE inhibitor should be prescribed with caution. Special attention should be given to combinations of ACE inhibitor with other RAAS blockers, diuretics (especially potassium-sparing diuretics), NSAIDs, anticoagulants, cyclosporine, DPP-4 inhibitors, and potassium supplements.
Potassium supplementation should be used with caution and under medical supervision owing to the hyperkalemic effect of ACE inhibitors.
Examples.
ACE inhibitors are easily identifiable by their common suffix, '-pril'. ACE inhibitors can be divided into three groups based on their molecular structure:
Dicarboxylate-containing agents.
This is the largest group, including:
Comparative information.
All ACE inhibitors have similar antihypertensive efficacy when equivalent doses are administered. The main differences lie with captopril, the first ACE inhibitor. Captopril has a shorter duration of action and an increased incidence of adverse effects. It is also the only ACE inhibitor capable of passing through the blood–brain barrier, although the significance of this characteristic has not been shown to have any positive clinical effects.
In a large clinical study, one of the agents in the ACE inhibitor class, ramipril (Altace), demonstrated an ability to reduce the mortality rates of patients suffering from a myocardial infarction, and to slow the subsequent development of heart failure. This finding was made after it was discovered that regular use of ramipril reduced mortality rates even in test subjects not having suffered from hypertension.
Some believe ramipril's additional benefits may be shared by some or all drugs in the ACE-inhibitor class. However, ramipril currently remains the only ACE inhibitor for which such effects are actually evidence-based.
A meta-analysis confirmed that ACE inhibitors are effective and certainly the first-line choice in hypertension treatment. This meta-analysis was based on 20 trials and a cohort of 158,998 patients, of whom 91% were hypertensive. ACE inhibitors were used as the active treatment in seven trials (n=76,615) and angiotensin receptor blocker (ARB) in 13 trials (n=82,383).
ACE inhibitors were associated with a statistically significant 10% mortality reduction: (HR 0.90; 95% CI, 0.84-0.97; P=0.004). In contrast, no significant mortality reduction was observed with ARB treatment (HR 0.99; 95% CI, 0.94-1.04; P=0.683). Analysis of mortality reduction by different ACE inhibitors showed that perindopril-based regimens are associated with a statistically significant 13% all-cause mortality reduction.
Taking into account the broad spectrum of the hypertensive population, one might expect that an effective treatment with ACE inhibitors, in particular with perindopril, would result in an important gain of lives saved.
ACE inhibitor equivalent doses in hypertension.
The ACE inhibitors have different strengths with different starting dosages. Dosage should be adjusted according to the clinical response.
Angiotensin II receptor antagonists.
ACE inhibitors possess many common characteristics with another class of cardiovascular drugs, angiotensin II receptor antagonists, which are often used when patients are intolerant of the adverse effects produced by ACE inhibitors. ACE inhibitors do not completely prevent the formation of angiotensin II, as blockage is dose-dependent, so angiotensin II receptor antagonists may be useful because they act to prevent the action of angiotensin II at the AT receptor, leaving AT receptor unblocked; the latter may have consequences needing further study.
Use in combination.
The combination therapy of angiotensin II receptor antagonists with ACE inhibitors may be superior to either agent alone. This combination may increase levels of bradykinin while blocking the generation of angiotensin II and its activity at the AT receptor. This 'dual blockade' may be more effective than using an ACE inhibitor alone, because angiotensin II can be generated via non-ACE-dependent pathways. Preliminary studies suggest this combination of pharmacologic agents may be advantageous in the treatment of essential hypertension, chronic heart failure, and nephropathy. However, the more recent ONTARGET study showed no benefit of combining the agents and more adverse events. While statistically significant results have been obtained for its role in treating hypertension, clinical significance may be lacking. There are warnings about the combination of ACE inhibitors with ARBs.
Patients with heart failure may benefit from the combination in terms of reducing morbidity and ventricular remodeling.
The most compelling evidence for the treatment of nephropathy has been found: This combination therapy partially reversed the proteinuria and also exhibited a renoprotective effect in patients afflicted with diabetic nephropathy, and pediatric IgA nephropathy.
History.
The first step in the development of ACE inhibitors was the discovery of ACE in plasma by Leonard T. Skeggs and his colleagues in 1956. Brazilian scientist Sérgio Henrique Ferreira reported a bradykinin-potentiating factor (BPF) present in the venom of "Bothrops jararaca", a South American pit viper, in 1965. Ferreira then went to John Vane's laboratory as a postdoctoral fellow with his already-isolated BPF. The conversion of the inactive angiotensin I to the potent angiotensin II was thought to take place in the plasma. However, in 1967, Kevin K. F. Ng and John R. Vane showed plasma ACE is too slow to account for the conversion of angiotensin I to angiotensin II "in vivo". Subsequent investigation showed rapid conversion occurs during its passage through the pulmonary circulation.
Bradykinin is rapidly inactivated in the circulating blood, and it disappears completely in a single pass through the pulmonary circulation. Angiotensin I also disappears in the pulmonary circulation because of its conversion to angiotensin II. Furthermore, angiotensin II passes through the lungs without any loss. The inactivation of bradykinin and the conversion of angiotensin I to angiotensin II in the lungs was thought to be caused by the same enzyme. In 1970, Ng and Vane, using BPF provided by Ferreira, showed the conversion is inhibited during its passage through the pulmonary circulation.
BPFs are members of a family of peptides whose potentiating action is linked to inhibition of bradykinin by ACE. Molecular analysis of BPF yielded a nonapeptide BPF teprotide (SQ 20,881), which showed the greatest ACE inhibition potency and hypotensive effect "in vivo". Teprotide had limited clinical value as a result of its peptide nature and lack of activity when given orally. In the early 1970s, knowledge of the structure-activity relationship required for inhibition of ACE was growing. David Cushman, Miguel Ondetti and colleagues used peptide analogues to study the structure of ACE, using carboxypeptidase A as a model. Their discoveries led to the development of captopril, the first orally-active ACE inhibitor, in 1975.
Captopril was approved by the United States Food and Drug Administration in 1981. The first nonsulfhydryl-containing ACE inhibitor, enalapril, was marketed two years later. At least 12 other ACE inhibitors have since been marketed.
In 1991, Japanese scientists created the first milk-based ACE inhibitor, in the form of a fermented milk drink, using specific cultures to liberate the tripeptide isoleucine-proline-proline (IPP) from the dairy protein. Valine-proline-proline (VPP) is also liberated in this process—another milk tripeptide with a very similar chemical structure to IPP. Together, these peptides are now often referred to as lactotripeptides. In 1996, the first human study confirmed the blood pressure-lowering effect of IPP in fermented milk. Although twice the amount of VPP is needed to achieve the same ACE-inhibiting activity as the originally discovered IPP, VPP also is assumed to add to the total blood pressure lowering effect.
Since the first lactotripeptides discovery, more than 20 human clinical trials have been conducted in many different countries.

</doc>
<doc id="2769" url="https://en.wikipedia.org/wiki?curid=2769" title="Antianginal">
Antianginal

An antianginal is any drug used in the treatment of "angina pectoris", a symptom of ischaemic heart disease.
Types.
Stable Angina.
Pain due to atherosclerosis causing incomplete coronary artery occlusion. Pain onset with strenuous activity or emotional strain due to increased myocardial oxygen demand.
Unstable Angina.
Pain due to atherosclerotic plaque rupture and subsequent embolization causing incomplete coronary arterial occlusion.
Variant (Prinzmetal's) Angina.
Pain due to transient vasospasm causing coronary artery vasoconstriction.
Examples.
Drugs used are nitrates, beta blockers, or calcium channel blockers.
Nitrates.
Nitrates cause vasodilation of the venous capacitance vessels by stimulating the endothelium-derived relaxing factor (EDRF). Used to relieve both exertional and vasospastic angina by allowing venous pooling, reducing the pressure in the ventricles and so reducing wall tension and oxygen requirements in the heart. Short-acting nitrates are used to abort angina attacks that have occurred, while longer-acting nitrates are used in the prophylactic management of the condition.
Agents include nitroglycerin (glyceryl trinitrate) or pentaerythritol tetranitrate, isosorbide dinitrate and isosorbide mononitrate.
Beta blockers.
Beta blockers are used in the prophylaxis of exertional angina by reducing the myocardial oxygen demand below the level that would provoke an angina attack.
They are contraindicated in variant angina and can precipitate heart failure. They are also contraindicated in severe asthmatics due to bronchoconstriction, and should be used cautiously in diabetics as they can cause hypoglycemia
Agents include either cardioselectives such as acebutolol or metoprolol, or non-cardioselectives such as oxprenolol or sotalol.
Calcium channel blockers.
Calcium ion (Ca) antagonists (Calcium channel blockers) are used in the treatment of chronic stable angina, and most effectively in the treatment of variant angina (directly preventing coronary artery vasospasm). They are not used in the treatment of unstable angina . 
In vitro, they dilate the coronary and peripheral arteries and have negative inotropic and chronotropic effects - decreasing afterload, improving myocardial efficiency, reducing heart rate and improving coronary blood flow.
"In vivo", the vasodilation and hypotension trigger the baroreceptor reflex. Therefore the net effect is the interplay of direct and reflex actions.
Examples include Class I agents ("e.g.", verapamil), Class II agents ("e.g.", amlodipine, nifedipine), or the Class III agent diltiazem.
Nifedipine is more a potent vasodilator and more effective in angina. It is in the class of dihydropyridines and does not affect refrectory period on SA node conduction.

</doc>
<doc id="2770" url="https://en.wikipedia.org/wiki?curid=2770" title="Anatomical Therapeutic Chemical Classification System">
Anatomical Therapeutic Chemical Classification System

The Anatomical Therapeutic Chemical (ATC) Classification System is used for the classification of active ingredients of drugs according to the organ or system on which they act and their therapeutic, pharmacological and chemical properties. It is controlled by the World Health Organization Collaborating Centre for Drug Statistics Methodology (WHOCC), and was first published in 1976.
This pharmaceutical coding system divides drugs into different groups according to the organ or system on which they act and/or their therapeutic and chemical characteristics. Each bottom-level ATC code stands for a pharmaceutically used substance, or a combination of substances, in a single indication (or use). This means that one drug can have more than one code: acetylsalicylic acid (aspirin), for example, has as a drug for local oral treatment, as a platelet inhibitor, and as an analgesic and antipyretic. On the other hand, several different brands share the same code if they have the same active substance and indications.
Classification.
In this system, drugs are classified into groups at 5 different levels:
First level.
The first level of the code indicates the anatomical main group and consists of one letter. There are 14 main groups:
"Example": C Cardiovascular system
Second level.
The second level of the code indicates the therapeutic main group and consists of two digits.
"Example": C03 Diuretics
Third level.
The third level of the code indicates the therapeutic/pharmacological subgroup and consists of one letter.
"Example": C03C High-ceiling diuretics
Fourth level.
The fourth level of the code indicates the chemical/therapeutic/pharmacological subgroup and consists of one letter.
"Example": C03CA Sulfonamides
Fifth level.
The fifth level of the code indicates the chemical substance and consists of two digits.
"Example": C03CA01 Furosemide
ATCvet.
The "Anatomical Therapeutic Chemical Classification System for veterinary medicinal products" (ATCvet) is used to classify veterinary drugs. ATCvet codes can be created by placing the letter Q in front of the ATC code of most human medications. For example, furosemide for veterinary use has the code QC03CA01.
Some codes are used exclusively for veterinary drugs, such as "QI Immunologicals", "QJ51 Antibacterials for intramammary use" or "QN05AX90 amperozide".
Defined daily dose.
The ATC system also includes defined daily doses (DDDs) for many drugs. This is a measurement of drug consumption based on the usual daily dose for a given drug. According to the definition, "he DDD is the assumed average maintenance dose per day for a drug used for its main indication in adults."
National adaptations.
National issues of the ATC classification, such as the German "Anatomisch-therapeutisch-chemische Klassifikation mit Tagesdosen", may include additional codes and DDDs not present in the WHO version.
Updates to ATC.
ATC follows guidelines in creating new codes for newly approved drugs. In order to create a new ATC code, an application has to be sent to ATC. New ATC codes are published twice annually. A formal release of new ATC edition occurs once a year.

</doc>
<doc id="2778" url="https://en.wikipedia.org/wiki?curid=2778" title="Parallel ATA">
Parallel ATA

Parallel ATA (PATA), originally ', is an interface standard for the connection of storage devices such as hard disk drives, floppy disk drives, and optical disc drives in computers. The standard is maintained by the X3/INCITS committee. It uses the underlying ' (ATA) and Packet Interface (ATAPI) standards.
The Parallel ATA standard is the result of a long history of incremental technical development, which began with the original AT Attachment interface, developed for use in early PC AT equipment. The ATA interface itself evolved in several stages from Western Digital's original Integrated Drive Electronics (IDE) interface. As a result, many near-synonyms for ATA/ATAPI and its previous incarnations are still in common informal use, in particular Extended IDE (EIDE) and Ultra ATA (UATA). After the introduction of Serial ATA (SATA) in 2003, the original ATA was renamed to Parallel ATA, or PATA for short.
Parallel ATA cables have a maximum allowable length of only . Because of this limit, the technology normally appears as an internal computer storage interface. For many years, ATA provided the most common and the least expensive interface for this application. It has largely been replaced by SATA in newer systems.
History and terminology.
The PATA standard was originally conceived as the "PC/AT Attachment" because its primary feature was a direct connection to the 16-bit ISA bus introduced with the IBM PC/AT. The "AT" in "IBM PC/AT" refers to "Advanced Technology", but the ATA specifications simply use the name "AT Attachment", to avoid possible trademark issues with IBM.
IDE and ATA-1.
The first version of what is now called the ATA/ATAPI interface was developed by Western Digital under the name "Integrated Drive Electronics" (IDE). Together with Control Data Corporation (who manufactured the hard drive part) and Compaq Computer (into whose systems these drives would initially go), they developed the connector, the signaling protocols and so on, with the goal of remaining software compatible with the existing ST-506 hard drive interface. The first such drives appeared in Compaq PCs in 1986.
The term "Integrated Drive Electronics" refers not just to the connector and interface definition, but also to the fact that the drive controller is integrated into the drive, as opposed to a separate controller on or connected to the motherboard. The interface cards used to connect a parallel ATA drive to, for example, a PCI slot are not drive controllers: they are merely bridges between the host bus and the ATA interface. Since the original ATA interface is essentially just a 16-bit ISA bus in disguise, the bridge was especially simple in case of an ATA connector being located on an ISA interface card. The integrated controller presented the drive to the host computer as an array of 512-byte blocks with a relatively simple command interface. This relieved the mainboard and interface cards in the host computer of the chores of stepping the disk head arm, moving the head arm in and out, and so on, as had to be done with earlier ST-506 and ESDI hard drives. All of these low-level details of the mechanical operation of the drive were now handled by the controller on the drive itself. This also eliminated the need to design a single controller that could handle many different types of drives, since the controller could be unique for the drive. The host need only ask for a particular sector, or block, to be read or written, and either accept the data from the drive or send the data to it.
The interface used by these drives was standardized in 1994 as ANSI standard X3.221-1994, "AT Attachment Interface for Disk Drives". After later versions of the standard were developed, this became known as "ATA-1".
A short-lived, seldom-used implementation of ATA was created for the IBM XT and similar machines that used the 8-bit version of the ISA bus. It has been referred to as "XT-IDE", "XTA" or "XT Attachment".
Second ATA interface.
When PC motherboard makers started to include onboard ATA interfaces in place of the earlier ISA plug-in cards, there was usually only one ATA connector on the board, which could support up to two hard drives. At the time, in combination with the floppy drive, this was sufficient for most people. When the CD-ROM was developed, many computers would have been unable to accept these drives if they had been ATA devices, due to already having two hard drives installed. Adding the CD-ROM drive would have required removal of one of the drives.
SCSI was available as a CD-ROM expansion option at the time, but devices with SCSI were more expensive than ATA devices due to the need for a smart interface that is capable of bus arbitration. SCSI typically added to the cost of a storage device, in addition to the cost of a SCSI host adapter.
The less expensive solution was the addition of a dedicated CD-ROM interface, which was typically included as an expansion option on a sound card. PC motherboards initially did not come with support for more than simple beeps from internal speakers; thus, sound cards (such as the Sound Blaster Pro) were available for use with games, operating system and software event sounds, or to listen to audio CDs. Also, sound cards commonly included a gameport joystick/gamepad port along with interfaces to control a CD-ROM and transmit CD audio to the system.
Initially, the second drive interface was not well defined. It was first introduced with interfaces specific to certain CD-ROM drives such as Mitsumi, Sony or Panasonic drives, and it was common to find early sound cards with two or three separate connectors each designed to match a certain brand of CD-ROM drive. This evolved into the standard ATA interface for ease of cross-compatibility, though the sound card ATA interface still usually supported only a single CD-ROM and not hard drives.
This second ATA interface on the sound card eventually evolved into the second motherboard ATA interface which was long included as a standard component in all PCs.
Called the "primary" and "secondary" ATA interfaces, they were assigned to base addresses 0x1F0 and 0x170 on ISA bus systems.
EIDE and ATA-2.
In 1994, about the same time that the ATA-1 standard was adopted, Western Digital introduced drives under a newer name, Enhanced IDE (EIDE). These included most of the features of the forthcoming ATA-2 specification and several additional enhancements. Other manufacturers introduced their own variations of ATA-1 such as "Fast ATA" and "Fast ATA-2".
The new version of the ANSI standard, "AT Attachment Interface with Extensions ATA-2" (X3.279-1996), was approved in 1996. It included most of the features of the manufacturer-specific variants.
ATA-2 also was the first to note that devices other than hard drives could be attached to the interface:
ATAPI.
As mentioned in the previous sections, ATA was originally designed for, and worked only with hard disk drives and devices that could emulate them. The introduction of ATAPI (ATA Packet Interface) by a group called the Small Form Factor committee (SFF) allowed ATA to be used for a variety of other devices that require functions beyond those necessary for hard disk drives. For example, any removable media device needs a "media eject" command, and a way for the host to determine whether the media is present, and these were not provided in the ATA protocol.
The Small Form Factor committee approached this problem by defining ATAPI, the "ATA Packet Interface". ATAPI is actually a protocol allowing the ATA interface to carry SCSI commands and responses; therefore, all ATAPI devices are actually "speaking SCSI" other than at the electrical interface. In fact, some early ATAPI devices were simply SCSI devices with an ATA/ATAPI to SCSI protocol converter added on. The SCSI commands and responses are embedded in "packets" (hence "ATA Packet Interface") for transmission on the ATA cable. This allows any device class for which a SCSI command set has been defined to be interfaced via ATA/ATAPI.
ATAPI devices are also "speaking ATA", as the ATA physical interface and protocol are still being used to send the packets. On the other hand, ATA hard drives and solid state drives do not use ATAPI.
ATAPI devices include CD-ROM and DVD-ROM drives, tape drives, and large-capacity floppy drives such as the Zip drive and SuperDisk drive.
The SCSI commands and responses used by each class of ATAPI device (CD-ROM, tape, etc.) are described in other documents or specifications specific to those device classes
and are not within ATA/ATAPI or the T13 committee's purview. One commonly used set is defined in the MMC SCSI command set.
ATAPI was adopted as part of ATA in INCITS 317-1998, "AT Attachment with Packet Interface Extension (ATA/ATAPI-4)".
UDMA and ATA-4.
The ATA/ATAPI-4 standard also introduced several "Ultra DMA" transfer modes. These initially supported speeds from 16 MByte/s to 33 MByte/second. In later versions, faster Ultra DMA modes were added, requiring new 80-wire cables to reduce crosstalk. The latest versions of Parallel ATA support up to 133 MByte/s.
Ultra ATA.
Ultra ATA, abbreviated UATA, is a designation that has been primarily used by Western Digital for different speed enhancements to the ATA/ATAPI standards. For example, in 2000 Western Digital published a document describing "Ultra ATA/100", which brought performance improvements for the then-current ATA/ATAPI-5 standard by improving maximum speed of the Parallel ATA interface from 66 to 100 MB/s. Most of Western Digital's changes, along with others, were included in the ATA/ATAPI-6 standard (2002).
Current terminology.
The terms "integrated drive electronics" (IDE), "enhanced IDE" and "EIDE" have come to be used interchangeably with ATA (now Parallel ATA, or PATA).
In addition, there have been several generations of "EIDE" drives marketed, compliant with various versions of the ATA specification. An early "EIDE" drive might be compatible with ATA-2, while a later one with ATA-6.
Nevertheless, a request for an "IDE" or "EIDE" drive from a computer parts vendor will almost always yield a drive that will work with most Parallel ATA interfaces.
Another common usage is to refer to the specification version by the fastest mode supported. For example, ATA-4 supported Ultra DMA modes 0 through 2, the latter providing a maximum transfer rate of 33 megabytes per second. ATA-4 drives are thus sometimes called "UDMA-33" drives, and sometimes "ATA-33" drives. Similarly, ATA-6 introduced a maximum transfer speed of 100 megabytes per second, and some drives complying to this version of the standard are marketed as "PATA/100" drives.
x86 BIOS size limitations.
Initially, the size of an ATA drive was stored in the system x86 BIOS using a type number (1 through 45) that predefined the C/H/S parameters and also often the landing zone, in which the drive heads are parked while not in use. Later, a "user definable" format called C/H/S or cylinders, heads, sectors was made available. These numbers were important for the earlier ST-506 interface, but were generally meaningless for ATA—the CHS parameters for later ATA large drives often specified impossibly high numbers of heads or sectors that did not actually define the internal physical layout of the drive at all. From the start, and up to ATA-2, every user had to specify explicitly how large every attached drive was. From ATA-2 on, an "identify drive" command was implemented that can be sent and which will return all drive parameters.
Owing to a lack of foresight by motherboard manufacturers, the system BIOS was often hobbled by artificial C/H/S size limitations due to the manufacturer assuming certain values would never exceed a particular numerical maximum.
The first of these BIOS limits occurred when ATA drives reached sizes in excess of 504 megabytes, because some motherboard BIOSes would not allow C/H/S values above 1024 cylinders, 16 heads, and 63 sectors. Multiplied by 512 bytes per sector, this totals bytes which, divided by bytes per megabyte, equals 504 megabytes.
The second of these BIOS limitations occurred at 1024 cylinders, 256 heads, and 63 sectors, and a bug in MS-DOS and MS-Windows 95 limited the number of heads to 255. This totals to bytes, commonly referred to as the 8.4 gigabyte barrier. This is again a limit imposed by x86 BIOSes, and not a limit imposed by the ATA interface.
It was eventually determined that these size limitations could be overridden with a tiny program loaded at startup from a hard drive's boot sector. Some hard drive manufacturers, such as Western Digital, started including these override utilities with new large hard drives to help overcome these problems. However, if the computer was booted in some other manner without loading the special utility, the invalid BIOS settings would be used and the drive could either be inaccessible or appear to the operating system to be damaged.
Later, an extension to the x86 BIOS disk services called the "Enhanced Disk Drive" (EDD) was made available, which makes it possible to address drives as large as 2 sectors.
Interface size limitations.
The first drive interface used 22-bit addressing mode which resulted in a maximum drive capacity of two gigabytes. Later, the first formalized ATA specification used a 28-bit addressing mode through LBA28, allowing for the addressing of 2 () sectors (blocks) of 512 bytes each, resulting in a maximum capacity of 128 GiB (137 GB).
ATA-6 introduced 48-bit addressing, increasing the limit to 128 PiB (144 PB). As a consequence, any ATA drive of capacity larger than about 137 GB must be an ATA-6 or later drive. Connecting such a drive to a host with an ATA-5 or earlier interface will limit the usable capacity to the maximum of the interface.
Some operating systems, including Windows XP pre-SP 1, and Windows 2000 pre-SP 3, disable LBA48 by default, requiring the user to take extra steps to use the entire capacity of an ATA drive larger than about 137 gigabytes.
Older operating systems, such as Windows 98, do not support 48-bit LBA at all. However, members of the third-party group MSFN have modified the Windows 98 disk drivers to add unofficial support for 48-bit LBA to Windows 95 OSR2, Windows 98, Windows 98 SE and Windows ME.
Some 16-bit and 32-bit operating systems supporting LBA48 may still not support disks larger than 2 TiB due to using 32-bit arithmetics only; a limitation also applying to many boot sectors.
Primacy and obsolescence.
Parallel ATA (then simply called ATA or IDE) became the primary storage device interface for PCs soon after 
its introduction. In some systems, a third and fourth motherboard interface was provided, allowing up to eight ATA devices to be attached to the motherboard. Often, these additional connectors were implemented by inexpensive RAID controllers.
Soon after the introduction of Serial ATA (SATA) in 2003, use of Parallel ATA declined. 
The first motherboards with built-in SATA interfaces usually had only a single PATA connector 
(for up to two PATA devices), along with multiple SATA connectors.
As of 2007, some PC chipsets, for example the Intel ICH10, had removed support for PATA. Motherboard vendors still wishing to offer Parallel ATA with those chipsets must include an additional interface chip. In more recent computers, the Parallel ATA interface is rarely used even if present, as four or more Serial ATA connectors are usually provided on the motherboard and SATA devices of all types are common.
With Western Digital's withdrawal from the market, hard disk drives with the PATA interface will no longer be in production after December 2013 for other than specialty applications.
Parallel ATA interface.
Parallel ATA cables transfer data 16 bits at a time. The traditional cable uses 40-pin connectors attached to a ribbon cable. Each cable has two or three connectors, one of which plugs into an adapter interfacing with the rest of the computer system. The remaining connector(s) plug into storage devices, most commonly hard disk drives or optical drives.
ATA's cables have had 40 wires for most of its history (44 conductors for the smaller form-factor version used for 2.5" drives—the extra four for power), but an 80-wire version appeared with the introduction of the "Ultra DMA/33" ("UDMA") mode. All of the additional wires in the new cable are ground wires, interleaved with the previously defined wires to reduce the effects of capacitive coupling between neighboring signal wires, reducing crosstalk. Capacitive coupling is more of a problem at higher transfer rates, and this change was necessary to enable the 66 megabytes per second (MB/s) transfer rate of "UDMA4" to work reliably. The faster "UDMA5" and "UDMA6" modes also require 80-conductor cables.
Though the number of wires doubled, the number of connector pins and the pinout remain the same as 40-conductor cables, and the external appearance of the connectors is identical. Internally, the connectors are different; the connectors for the 80-wire cable connect a larger number of ground wires to the ground pins, while the connectors for the 40-wire cable connect ground wires to ground pins one-for-one. 80-wire cables usually come with three differently colored connectors (blue, black, and gray for controller, master drive, and slave drive respectively) as opposed to uniformly colored 40-wire cable's connectors (commonly all gray). The gray connector on 80-conductor cables has pin 28 CSEL not connected, making it the slave position for drives configured cable select.
Round parallel ATA cables (as opposed to ribbon cables) were eventually made available for 'case modders' for cosmetic reasons, as well as claims of improved computer cooling and were easier to handle; however, only ribbon cables are supported by the ATA specifications.
In the ATA standard, pin 20 is defined as (mechanical) key and is not used. This socket on the female connector is often obstructed, requiring pin 20 to be omitted from the male cable or drive connector, making it impossible to plug it in the wrong way round; a male connector with pin 20 present cannot be used. However, some flash memory drives can use pin 20 as VCC_in to power the drive without requiring a special power cable; this feature can only be used if the equipment supports this use of pin 20.
Pin 28 of the gray (slave/middle) connector of an 80-conductor cable is not attached to any conductor of the cable. It is attached normally on the black (master drive end) and blue (motherboard end) connectors.
Pin 34 is connected to ground inside the blue connector of an 80-conductor cable but not attached to any conductor of the cable. It is attached normally on the gray and black connectors.
Differences between connectors on 80-conductor cables.
The image on the right shows PATA connectors after removal of strain relief, cover, and cable. Pin one is at bottom left of the connectors, pin 2 is top left, etc., except that the lower image of the blue connector shows the view from the opposite side, and pin one is at top right. 
The connector is an insulation-displacement connector—in other words, each contact comprises a pair of points which together pierce the insulation of the ribbon cable with such precision that they make a connection to the desired conductor without harming the insulation on the neighboring wires. The center row of contacts are all connected to the common ground bus and attached to the odd numbered conductors of the cable. The top row of contacts are the even-numbered sockets of the connector (mating with the even-numbered pins of the receptacle) and attach to every other even-numbered conductor of the cable. The bottom row of contacts are the odd-numbered sockets of the connector (mating with the odd-numbered pins of the receptacle) and attach to the remaining even-numbered conductors of the cable.
Note the connections to the common ground bus from sockets 2 (top left), 19 (center bottom row), 22, 24, 26, 30, and 40 on all connectors. Also note (enlarged detail, bottom, looking from the opposite side of the connector) that socket 34 of the blue connector does not contact any conductor but unlike socket 34 of the other two connectors, it does connect to the common ground bus. On the gray connector, note that socket 28 is completely missing, so that pin 28 of the drive attached to the gray connector will be open. On the black connector, sockets 28 and 34 are completely normal, so that pins 28 and 34 of the drive attached to the black connector will be connected to the cable. Pin 28 of the black drive reaches pin 28 of the host receptacle but not pin 28 of the gray drive, while pin 34 of the black drive reaches pin 34 of the gray drive but not pin 34 of the host. Instead, pin 34 of the host is grounded.
The standard dictates color-coded connectors for easy identification by both installer and cable maker. All three connectors are different from one another. The blue (host) connector has the socket for pin 34 connected to ground inside the connector but not attached to any conductor of the cable. Since the old 40 conductor cables do not ground pin 34, the presence of a ground connection indicates that an 80 conductor cable is installed. The wire for pin 34 is attached normally on the other types and is not grounded. Installing the cable backwards (with the black connector on the system board, the blue connector on the remote device and the gray connector on the center device) will ground pin 34 of the remote device and connect host pin 34 through to pin 34 of the center device. The gray center connector omits the connection to pin 28 but connects pin 34 normally, while the black end connector connects both pins 28 and 34 normally.
Multiple devices on a cable.
If two devices are attached to a single cable, one must be designated as "device 0" (commonly referred to as "master") and the other as "device 1" ("slave"). This distinction is necessary to allow both drives to share the cable without conflict. The "master" drive is the drive that usually appears "first" to the computer's BIOS and/or operating system. On old BIOSes (Intel 486 era and older), the drives are often referred to by the BIOS as "C" for the master and "D" for the slave following the way DOS would refer to the active primary partitions on each.
The mode that a drive must use is often set by a jumper setting on the drive itself, which must be manually set to "master" or "slave". If there is a single device on a cable, it should be configured as "master". However, some hard drives have a special setting called "single" for this configuration (Western Digital, in particular). Also, depending on the hardware and software available, a single drive on a cable will often work reliably even though configured as the "slave" drive (most often seen where an optical drive is the only device on the secondary ATA interface).
Cable select.
A drive mode called "cable select" was described as optional in ATA-1 and has come into fairly widespread use with ATA-5 and later. A drive set to "cable select" automatically configures itself as master or slave, according to its position on the cable. Cable select is controlled by pin 28. The host adapter grounds this pin; if a device sees that the pin is grounded, it becomes the master device; if it sees that pin 28 is open, the device becomes the slave device.
This setting is usually chosen by a jumper setting on the drive called "cable select", usually marked "CS", which is separate from the "master" or "slave" setting.
Note that if two drives are configured as "master" and "slave" manually, this configuration does not need to correspond to their position on the cable. Pin 28 is only used to let the drives know their position on the cable; it is not used by the host when communicating with the drives.
With the 40-wire cable, it was very common to implement cable select by simply cutting the pin 28 wire between the two device connectors; putting the slave device at the end of the cable, and the master on the middle connector. This arrangement eventually was standardized in later versions. If there is just one device on the cable, this results in an unused stub of cable, which is undesirable for physical convenience and electrical reasons. The stub causes signal reflections, particularly at higher transfer rates.
Starting with the 80-wire cable defined for use in ATAPI5/UDMA4, the master device goes at the end of the cable—the black connector—and the slave device goes on the middle connector—the gray one—and the blue connector goes onto the motherboard. So, if there is only one (master) device on the cable, there is no cable stub to cause reflections. Also, cable select is now implemented in the slave device connector, usually simply by omitting the contact from the connector body.
Master and slave clarification.
Although they are in extremely common use, the terms "master" and "slave" do not actually appear in current versions of the ATA specifications. The two devices are simply referred to as "device 0" and "device 1", respectively, in ATA-2 and later.
It is a common myth that the controller on the master drive assumes control over the slave drive, or that the master drive may claim priority of communication over the other device on the same ATA interface. In fact, the drivers in the host operating system perform the necessary arbitration and serialization, and each drive's onboard controller operates independently of the other.
Serialized, overlapped, and queued operations.
The parallel ATA protocols up through ATA-3 require that once a command has been given on an ATA interface, it must complete before any subsequent command may be given. Operations on the devices must be serialized—with only one operation in progress at a time—with respect to the ATA host interface. A useful mental model is that the host ATA interface is busy with the first request for its entire duration, and therefore can not be told about another request until the first one is complete. The function of serializing requests to the interface is usually performed by a device driver in the host operating system.
The ATA-4 and subsequent versions of the specification have included an "overlapped feature set" and a "queued feature set" as optional features, both being given the name "Tagged Command Queuing", a reference to a set of features from SCSI which the ATA version attempts to emulate. However, support for these is extremely rare in actual parallel ATA products and device drivers because these feature sets were implemented in such a way as to maintain software compatibility with its heritage as originally an extension of the ISA bus. This implementation resulted in excessive CPU utilization which largely negated the advantages of command queuing. By contrast, overlapped and queued operations have been common in other storage buses, in particular, SCSI's version of tagged command queuing had no need to be software compatible with ISA's APIs, allowing it to attain high performance with low overhead on buses which supported first party DMA like PCI. This has long been seen as a major advantage of SCSI.
The Serial ATA standard has supported native command queueing since its first release, but it is an optional feature for both host adapters and target devices. Many less expensive PC motherboards do not support NCQ. Many SATA/II hard drives sold today support NCQ, while no removable (CD/DVD) drives do because the ATAPI command set used to control them prohibits queued operations.
Two devices on one cable—speed impact.
There are many debates about how much a slow device can impact the performance of a faster device on the same cable. There is an effect, but the debate is confused by the blurring of two quite different causes, called here "Lowest speed" and "One operation at a time".
"Lowest speed".
It is a common misconception that, if two devices of different speed capabilities are on the same cable, both devices' data transfers will be constrained to the speed of the slower device.
For all modern ATA host adapters, this is not true, as modern ATA host adapters support "independent device timing". This allows each device on the cable to transfer data at its own best speed. Even with older adapters without independent timing, this effect applies only to the data transfer phase of a read or write operation. This is usually the shortest part of a complete read or write operation.
"One operation at a time".
This is caused by the omission of both overlapped and queued feature sets from most parallel ATA products. Only one device on a cable can perform a read or write operation at one time, therefore, a fast device on the same cable as a slow device under heavy use will find it has to wait for the slow device to complete its task first.
However, most modern devices will report write operations as complete once the data is stored in its onboard cache memory, before the data is written to the (slow) magnetic storage. This allows commands to be sent to the other device on the cable, reducing the impact of the "one operation at a time" limit.
The impact of this on a system's performance depends on the application. For example, when copying data from an optical drive to a hard drive (such as during software installation), this effect probably will not matter: Such jobs are necessarily limited by the speed of the optical drive no matter where it is. But if the hard drive in question is also expected to provide good throughput for other tasks at the same time, it probably should not be on the same cable as the optical drive.
HDD passwords and security.
The disk lock is a built-in security feature in the disk. It is part of the ATA specification, and thus not specific to any brand or device. The disk lock can be enabled and disabled by sending special ATA commands to the drive. If a disk is locked, it will refuse all access until it is unlocked.
A disk always has two passwords: A User password and a Master password. Most disks support a Master Password Revision Code. Reportedly, some disks can report if the Master password has been changed, or if it still is the factory default. The revision code is word 92 in the IDENTIFY response. Reportedly, on some disks, a value of 0xFFFE means the Master password is unchanged. The standard does not distinguish this value.
A disk can be locked in two modes: High security mode or Maximum security mode. Bit 8 in word 128 of the IDENTIFY response shows which mode the disk is in: 0 = High, 1 = Maximum.
In High security mode, the disk can be unlocked with either the User or Master password, using the "SECURITY UNLOCK DEVICE" ATA command. There is an attempt limit, normally set to 5, after which the disk must be power cycled or hard-reset before unlocking can be attempted again. Also in High security mode, the SECURITY ERASE UNIT command can be used with either the User or Master password.
In Maximum security mode, the disk can be unlocked only with the User password. If the User password is not available, the only remaining way to get at least the bare hardware back to a usable state is to issue the SECURITY ERASE PREPARE command, immediately followed by SECURITY ERASE UNIT. In Maximum security mode, the SECURITY ERASE UNIT command requires the Master password and will completely erase all data on the disk. The operation is slow. It may take half an hour or more, depending on the size of the disk. (Word 89 in the IDENTIFY response indicates how long the operation will take.) 
While the ATA disk lock is intended to be impossible to defeat without a valid password, there are workarounds to unlock a drive. Many data recovery companies offer unlocking services, so while the disk lock will deter a casual attacker, it is not secure against a qualified adversary.
External parallel ATA devices.
It is extremely uncommon to find external PATA devices that directly use the interface for connection to a computer. PATA is primarily restricted to devices installed internally, due to the short data cable specification. A device connected externally needs additional cable length to form a U-shaped bend so that the external device may be placed alongside, or on top of the computer case, and the standard cable length is too short to permit this.
For ease of reach from motherboard to device, the connectors tend to be positioned towards the front edge of motherboards, for connection to devices protruding from the front of the computer case. This front-edge position makes extension out the back to an external device even more difficult. Ribbon cables are poorly shielded, and the standard relies upon the cabling to be installed inside a shielded computer case to meet RF emissions limits.
All external PATA devices, such as external hard drives, use some other interface technology to bridge the distance between the external device and the computer. USB is the most common external interface, followed by Firewire. A bridge chip inside the external devices converts from the USB interface to PATA, and typically only supports a single external device without cable select or master/slave.
Compact Flash interface.
Compact Flash in its "IDE mode" is essentially just a miniaturized ATA interface, intended for use on devices that use flash memory storage. No interfacing chips or circuitry are required, other than to directly adapt the smaller CF socket onto the larger ATA connector.
The ATA connector specification does not include pins for supplying power to a CF device, so power is inserted into the connector from a separate source. The exception to this is when the CF device is connected to a 44-pin ATA bus designed for 2.5-inch hard disk drives, commonly found in notebook computers, as this bus implementation must provide power to a standard hard disk drive.
CF devices can be designated as master or slave on an ATA interface, though since most CF devices offer only a single socket, it is not necessary to offer this selection to end users. Although CF can be hot-pluggable with additional design methods, by default when wired directly to an ATA interface, it is not intended to be hot-pluggable.
ATA standards versions, transfer rates, and features.
The following table shows the names of the versions of the ATA standards and the transfer modes and rates supported by each. Note that the transfer rate for each mode (for example, 66.7 MB/s for UDMA4, commonly called "Ultra-DMA 66", defined by ATA-5) gives its maximum theoretical transfer rate on the cable. This is simply two bytes multiplied by the effective clock rate, and presumes that every clock cycle is used to transfer end-user data. In practice, of course, protocol overhead reduces this value.
Congestion on the host bus to which the ATA adapter is attached may also limit the maximum burst transfer rate. For example, the maximum data transfer rate for conventional PCI bus is 133 MB/s, and this is shared among all active devices on the bus.
In addition, no ATA hard drives existed in 2005 that were capable of measured sustained transfer rates of above 80 MB/s. Furthermore, sustained transfer rate tests do not give realistic throughput expectations for most workloads: They use I/O loads specifically designed to encounter almost no delays from seek time or rotational latency. Hard drive performance under most workloads is limited first and second by those two factors; the transfer rate on the bus is a distant third in importance. Therefore, transfer speed limits above 66 MB/s really affect performance only when the hard drive can satisfy all I/O requests by reading from its internal cache—a very unusual situation, especially considering that such data is usually already buffered by the operating system.
, mechanical hard disk drives can transfer data at up to 157 MB/s, which is beyond the capabilities of the PATA/133 specification. High-performance solid state drives can transfer data at up to 308 MB/s.
Only the Ultra DMA modes use CRC to detect errors in data transfer between the controller and drive. This is a 16-bit CRC, and it is used for data blocks only. Transmission of command and status blocks do not use the fast signaling methods that would necessitate CRC. For comparison, in Serial ATA, 32-bit CRC is used for both commands and data.
Related standards, features, and proposals.
ATAPI Removable Media Device (ARMD).
ATAPI devices with removable media, other than CD and DVD drives, are classified as ARMD (ATAPI Removable Media Device) and can appear as either a super-floppy (non-partitioned media) or a hard drive (partitioned media) to the operating system. These can be supported as bootable devices by a BIOS complying with the ATAPI Removable Media Device BIOS Specification, originally developed by Compaq Computer Corporation and Phoenix Technologies. It specifies provisions in the BIOS of a personal computer to allow the computer to be bootstrapped from devices such as Zip drives, Jaz drives, SuperDisk (LS-120) drives, and similar devices.
These devices have removable media like floppy disk drives, but capacities more commensurate with hard drives, and programming requirements unlike either. Due to limitations in the floppy controller interface most of these devices were ATAPI devices, connected to one of the host computer's ATA interfaces, similarly to a hard drive or CD-ROM device. However, existing BIOS standards did not support these devices. An ARMD-compliant BIOS allows these devices to be booted from and used under the operating system without requiring device-specific code in the OS.
A BIOS implementing ARMD allows the user to include ARMD devices in the boot search order. Usually an ARMD device is configured earlier in the boot order than the hard drive. Similarly to a floppy drive, if bootable media is present in the ARMD drive, the BIOS will boot from it; if not, the BIOS will continue in the search order, usually with the hard drive last.
There are two variants of ARMD, ARMD-FDD and ARMD-HDD. Originally ARMD caused the devices to appear as a sort of very large floppy drive, either the primary floppy drive device 00h or the secondary device 01h. Some operating systems required code changes to support floppy disks with capacities far larger than any standard floppy disk drive. Also, standard-floppy disk drive emulation proved to be unsuitable for certain high-capacity floppy disk drives such as Iomega Zip drives. Later the ARMD-HDD, ARMD-"Hard disk device", variant was developed to address these issues. Under ARMD-HDD, an ARMD device appears to the BIOS and the operating system as a hard drive.
ATA over Ethernet.
In August 2004, Sam Hopkins and Brantley Coile of Coraid specified a lightweight ATA over Ethernet protocol to carry ATA commands over Ethernet instead of directly connecting them to a PATA host adapter. This permitted the established block protocol to be reused in storage area network (SAN) applications.

</doc>
<doc id="2779" url="https://en.wikipedia.org/wiki?curid=2779" title="Atari 2600">
Atari 2600

The Atari 2600, (or Atari VCS before 1982) is a home video game console released on September 11, 1977 by Atari, Inc. It is credited with popularizing the use of microprocessor-based hardware and ROM cartridges containing game code, a format first used with the Fairchild Channel F video game console in 1976. This format contrasts with the older model of having non-microprocessor dedicated hardware, which could only play the games which were physically built into the unit.
The console was originally sold as the Atari VCS, an abbreviation for Video Computer System. Following the release of the Atari 5200 in 1982, the VCS was renamed to the "Atari 2600", after the unit's Atari part number, CX2600. The 2600 was typically bundled with two joystick controllers, a conjoined pair of paddle controllers, and a game cartridge, initially "Combat", and later "Pac-Man".
History.
Ted Dabney and Nolan Bushnell developed the Atari gaming system in the 1970s. Originally operating under the name "Syzygy", Bushnell and Dabney changed the name of their company to "Atari" in 1972. In 1973, Atari Inc. had purchased an engineering think tank called Cyan Engineering to research next-generation video game systems, and had been working on a prototype known as "Stella" (named after one of the engineers' bicycles) for some time. Unlike prior generations of machines that use custom logic to play a small number of games, its core is a complete CPU, the famous MOS Technology 6502 in a cost-reduced version known as the 6507. It was combined with a RAM-and-I/O chip, the MOS Technology 6532, and a display and sound chip known as the Television Interface Adaptor (TIA). The first two versions of the machine contain a fourth chip, a standard CMOS logic buffer IC, making Stella cost-effective. Some later versions of the console eliminated the buffer chip. 
Programs for small computers of the time were generally stored on cassette tapes, floppy disks, or paper tape. By the early 1970s, Hewlett-Packard manufactured desktop computers costing thousands of dollars such as the HP 9830, which packaged Read Only Memory (ROM) into removable cartridges to add special programming features, and these were being considered for use in games. At first, the design was not going to be cartridge-based, but after seeing a "fake" cartridge system on another machine, they realized they could place the games on cartridges essentially for the price of the connector and packaging.
In 1976, Fairchild Semiconductor released their own CPU-based system, the Video Entertainment System. Stella was still not ready for production, but it was clear that it needed to be before there were a number of "me too" products filling up the market, which had happened after they released "Pong". Atari Inc. didn't have the cash flow to complete the system quickly, given that sales of their "Pong" systems were cooling. Nolan Bushnell eventually turned to Warner Communications, and sold the company to them in 1976 for US$28 million on the promise that Stella would be produced as soon as possible.
Key to the eventual success of the machine was the hiring of Jay Miner, a chip designer who managed to squeeze an entire wire wrap of equipment making up the TIA into a single chip. Once that was completed and debugged, the system was ready for shipping.
Launch and success.
The unit was originally priced at US$199 ($ adjusted for inflation), and shipped with two joysticks and a "Combat" cartridge (eight additional games were available at launch and sold separately). In a move to compete directly with the Channel F, Atari Inc. named the machine the Video Computer System (or VCS for short), as the Channel F was at that point known as the VES, for "Video Entertainment System". The VCS was also rebadged as the Sears Video Arcade and sold through Sears, Roebuck and Company stores. Another break-through for gaming systems was Atari's invention of a computer-controlled opponent, rather than the usual two-player or asymmetric challenges of the past.
When Fairchild learned of Atari Inc.'s naming, they quickly changed the name of their system to become the Channel F. However, both systems were now in the midst of a vicious round of price-cutting: "Pong" clones that had been made obsolete by these newer and more powerful machines were sold off to discounters for ever-lower prices. Soon many of the clone companies were out of business, and both Fairchild and Atari Inc. were selling to a public that was completely burnt out on Pong. In 1977, Atari Inc. sold 250,000 Video Computer Systems.
For the first year of production, the Video Computer System was manufactured in Sunnyvale, California. The consoles manufactured there had thick plastic molding around the sides and bottom. These added weight to the console, and because all six switches were on the front, these consoles were nicknamed "Heavy Sixers". After this first year, production moved to Hong Kong, and the consoles manufactured there had thinner plastic molding. In 1978, only 550,000 units from a production run of 800,000 were sold, requiring further financial support from Warner to cover losses. This led directly to the disagreements that caused Atari Inc. founder Nolan Bushnell to leave the company in 1978. Despite Bushnell's retirement in 1978, Warren Robinett’s invention of the first graphical adventure game, "Adventure", was developed the same year and changed the fundamentals of gaming as it unlocked a game with a “virtual space bigger than the screen."
Once the public realized it was possible to play video games other than "Pong", and programmers learned how to push its hardware's capabilities, the VCS gained popularity. By this point, Fairchild had given up, thinking video games were a passing fad, thereby handing the entire quickly growing market to Atari Inc. By 1979, the VCS was the best-selling Christmas gift (and console), due to its exclusive content, and 1 million units were sold that year.
Atari Inc. then licensed the smash arcade hit "Space Invaders" by Taito, which greatly increased the unit's popularity when it was released in January 1980, doubling sales to over 2 million units. The VCS and its cartridges were the main factor behind Atari Inc. grossing more than $2 billion in 1980. Sales then doubled again for the next two years; by 1982, the console had sold 10 million units, while its best-selling game "Pac-Man" sold 7 million copies. The console also sold 450,000 units in West Germany by 1984. By 1982 the 2600 console cost Atari about $40 to make and was sold for an average of $125. The company spent $4.50 to $6 to manufacture each cartridge and $1 to $2 for advertising, and sold it for $18.95 wholesale.
In 1980, the VCS was given a minor revision in which the left and right difficulty switches were moved to the back of the console, leaving four switches on the front. Other than this, these four-switch consoles looked nearly identical to the earlier six-switch models. In 1982, another version of the four-switch console was released without woodgrain. They were nicknamed "Darth Vader" consoles due to their all-black appearance. These were also the first consoles to be officially called "Atari 2600", as the Atari 5200 was released the same year.
During this period, Atari Inc. expanded the 2600 family with two other compatible consoles. Despite the faux-wood panels and what would now appear to be primitive graphics, the game console became widely popular for the time. Later however, they designed the Atari 2700, a wireless version of the console that was never released because of a design flaw. The company also built a sleeker version of the machine dubbed the Atari 2800 to sell directly to the Japanese market in early 1983, but it suffered from competition with the newly released Nintendo Famicom.
In a survey mentioned by Jeff Rovin it is reported that more stores reported breakdowns of the Atari 2600 system than any other, and that Atari repair centers seemed to have the most trouble with consoles manufactured in 1980. In one case it is stated that a system was repaired five times before static electricity from a carpet was discovered as having caused the problem. The controllers were also a source of breakage because of the way they could be gripped by a player holding it with their fist, allowing players to get carried away and over control, which was less likely with other systems released at the time, such as the Magnavox Odyssey², which has controllers that are nearly half its size.
Sears Tele-Games 2600s.
Atari Inc. also continued their OEM relationship with Sears under the latter's Tele-Games brand label, which started in 1975 with the original "Pong". Sears released several versions of the 2600 as the Sears Video Arcade series from 1977 to 1983. These include the Rev. A "Heavy Sixer" model in 1977, the Rev. B "4 switch" model in 1980, and the US version of the Atari 2800 branded as the Sears Video Arcade II in 1983.
Sears also released their own versions of Atari Inc.'s games under the Tele-Games brand — often with different titles — which included the Tele-Games branded variations of text and picture labels. Three games were also produced by Atari Inc. for Sears as exclusive releases under the Tele-Games brand: "Steeplechase", "Stellar Track", and "Submarine Commander".
Sears's Tele-Games brand was unrelated to the company Telegames, which also produced cartridges for the Atari 2600 — mostly re-issues of M Network games.
Decline and remodel.
During the 1970s, Atari Inc. continued to grow until it had one of the largest R&D divisions in Silicon Valley. However, it spent much of its R&D budget on projects that seemed out of place at a video game (or even home computer) company; many of these projects never saw the light of day. Meanwhile, several attempts to bring out newer consoles failed for one reason or another, although Atari Inc.'s home computer system (the Atari 8-bit family) sold reasonably well, Warner was pleased as it seemed to have no end to the sales of the 2600, and Atari Inc. was responsible for over half of the company's income.
The programmers of many of Atari Inc.'s biggest hits grew disgruntled with the company for not crediting game developers and many left the company and formed their own independent software companies. The most prominent and longest-lasting of these third-party developers was Activision, founded in 1980, whose titles quickly became more popular than those of Atari Inc. itself. Atari Inc. attempted to block third-party development for the 2600 in court but failed, and soon other publishers, such as Imagic and Coleco, entered the market. Atari Inc. suffered from an image problem when a company named Mystique produced a number of pornographic games for the 2600. The most notorious of these, "Custer's Revenge", was protested by women's and Native American groups because it depicted General George Armstrong Custer raping a bound Native American woman. Atari Inc. sued Mystique in court over the release of the game.
Atari Inc. continued to acquire licenses for the 2600, the most prominent of which included "Pac-Man" and "E.T." Public disappointment with these two titles and the market saturation of poor third-party titles are cited as major contributors to the video game crash of 1983. Suddenly, Atari Inc.'s growth meant it was losing massive amounts of money during the crash, at one point about $10,000 a day. Warner quickly grew tired of supporting Atari Inc., and started looking for buyers in 1984.
By mid-1984 most software development for the 2600 had stopped except by Atari and Activision, with third-party developers emphasizing ColecoVision games. Although not formally discontinued, the 2600 was de-emphasized for two years after Warner's 1984 sale of Atari Inc.'s Consumer Division to Commodore Business Machines founder Jack Tramiel, who wanted to concentrate on home computers. He ended all development of console games, including a 2600 "Garfield" game and an Atari 5200 port of "Super Pac-Man". Due to a large library and a low price point, the 2600 and the 2600jr, continued to sell into the late 1980s and was not discontinued until 1992. The 2600 ended up outdoing all other hardware that Atari released, in attempt to replicate its success.
Atari 2800.
The Atari 2800 is the Japanese version of the Atari 2600, released in October 1983. It was the first release of a 2600 designed specifically for the Japanese market, despite companies like Epoch distributing the 2600 in Japan previously. In fact, Atari's name was inspired by the Japanese game 'Go'.
The 2800 never captured a large market in Japan. It was released a short time after Nintendo's Family Computer, which became the dominant console in the Japanese video game market of the time.
Codenamed "Cindy", and designed by Atari engineer Joe Tilly, the Atari 2800 had four controller ports instead of the standard two on the Atari 2600's. The controllers are an all-in one design using a combination of an 8-direction digital joystick and a 270-degree paddle, designed by John Amber.
The 2800's case design departed from the standard 2600 format, using a wedge shape with non-protruding switches.
Around 30 specially branded games were released for the 2800. Their boxes are in Japanese and have a silver/red color scheme similar to the packaging of Atari's 2600 branded games of the time. The ROM cartridges themselves had identical labels as their 2600 branded counterparts.
Sears liked the design of the Atari 2800 so much, they opted to sell a version under their Tele-Games label. It was released in the US in 1983 as the Sears Video Arcade II, and was packaged with 2 controllers and "Space Invaders".
The Atari 2800's case style was used as the basis for the Atari 7800's case style by Barney Huang.
Atari 2600 Jr..
In 1986, a new version of the 2600 was released. The newly redesigned version of the 2600, unofficially referred to as the 2600 Jr., features a smaller cost-reduced form factor with a modernized Atari 7800-like appearance. The redesigned 2600 was advertised as a budget gaming system (under US$50) that has the ability to run a large collection of classic games.
The Atari 2600 continued to sell in North America and Europe until 1991, and in Asia until the early 1990s. Its final Atari-licensed release is "KLAX" in 1990. In 2007, the Atari 2600 was inducted into the Toy Hall of Fame, with 40 million units sold in its lifetime, and the youngest toy to be inducted. In Brazil, the console became extremely popular in the mid-1980s. The Atari 2600 was officially retired by Atari Corp. on January 1, 1992, making it, at the time, the longest-lived home video game console (14 years, 4 months) in video game history. It was later surpassed by the Sega Master System, a console which never formally ended production in Brazil.
The Atari 2600 was also, at the time, the best-selling American-made console, selling 30 million units. This record would later be broken by the Xbox 360 which sold 84 million units.
The system was promoted on a United Kingdom TV ad in 1989 in the run-up to Christmas, in which it claimed "The fun is back!". The advertising campaign used its price of under £50 as a selling point. The advert was a re-dubbed version of the early original campaign in the United States. Also, the 2600 Jr. was originally to be packaged with a Pro-Line joystick (the same one used on the Atari 7800), but when it was released, it instead included the original CX-40 Joystick. Later European versions of the 2600 Jr. included a joypad, which was also featured with the European 7800.
Design.
Hardware.
The CPU was the MOS Technology 6507, a stripped-down version of the 6502, running at 1.19 MHz in the 2600. The 6507 included fewer memory-address pins—13 instead of 16—and no external interrupts to fit into a smaller 28-pin package. Smaller packaging was, and still is, an important factor in overall system cost, and since memory was very expensive at the time, the 6507's small 8 kB of maximum external memory space was not going to be used up anyway. In fact, memory was so expensive they could not imagine using up even 4 kB, and when Atari got a deal on 24-pin connectors for the cartridge socket, they took it, despite this limiting the games to 4 kB. Atari established their system design in order to be compatible with the cathode-ray tube television sets in the late 1970s and early 1980s. Later games get around this limitation with bank switching. The maximum supported cartridge size is 32 kilobytes.
The console has only 128 bytes of RAM for run-time data that includes the call stack and the state of the game world. There is no frame buffer, as the necessary RAM would have been too expensive. Instead the video device has two bitmapped sprites, two 1-pixel "missile" sprites, a 1-pixel "ball," and a 40-pixel "playfield" that is drawn by writing a bit pattern for each line into a register just before the television scans that line. As each line is scanned, a game must identify the non-sprite objects that overlaps the next line, assemble the appropriate bit patterns to draw for those objects, and write the pattern into the register. In a telling reveal of its Pong heritage, by default, the right side of the screen is a mirrored duplicate of the left; to control it separately, the software may modify the patterns as the scan line is drawn. After the controller scans the last active line, a more leisurely vertical blanking interval begins, during which the game can process inputs and update the positions & states of objects in the game world. Any mistake in timing produces visual artifacts, a problem that programmers call "racing the beam" and which users tend to call "flickering".
The video hardware gives the 2600 a reputation as one of the most complex game consoles in the world to program, but those programmers who sufficiently understand it realize that such direct control over the video picture is also a source of flexibility. One advantage the 2600 has over more powerful contemporary competitors such as the ColecoVision is that the 2600 has no protection against altering settings in mid-line. For example, although each sprite nominally has only one color, it is possible to color the rows differently by changing the sprite's color as it is drawn. If the two hardware sprites are not enough for a game, a developer may share one sprite among several objects (as with the ghosts in "Pac-Man") or draw software sprites, which is only a little more difficult than drawing a fixed playfield. The "Pitfall!" screenshot below (section: "Games") demonstrates some of these tricks: the player is a multicolor sprite, one sprite is multiplexed for the logs and the scorpion, and the swinging vine is drawn by shifting the position of the "ball" on each scan line. Despite the hardware limitations, many Atari 2600 games have a lot of action on the screen, creating an engaging experience. Furthermore, the Atari 2600 was one of the first consoles to introduce video game cartridges instead of having hardwired games built into it, allowing for the play of multiple different games rather than the usual one built in.
The Atari originally shipped with two types of controllers, a joystick as well as a pair of paddle controllers. Later, new controllers were added to the game system including a driving controller, a trak-ball controller, and finally keypad controllers. Additionally, the 2600 supports several types of input devices as well as third-party peripherals. Many of these peripherals are interchangeable with the MSX and other Japanese systems; and, in some cases, it is possible to use the Atari joysticks with the Commodore 64, Commodore 128, Amiga, Sega Master System, and Mega Drive/Genesis, though functionality may be somewhat limited. Also, although Master System and Mega Drive/Genesis controllers work on the Atari 2600, only the "B" button can be used in most games. Another adapter is the Starpath Supercharger, an add-on created by Starpath to expand the game capabilities of the Atari 2600. The Supercharger's interface adds an extra 6 kB to the Atari 2600's 128 bytes of RAM, allowing for larger games with higher-resolution graphics. A cord coming out of the side of the cartridge plugs into the earphone jack of any standard cassette player. Games for the Supercharger are stored on standard audio cassettes.
Graphics.
The Atari 2600 uses different color palettes depending on the television signal format used. With the NTSC format, a 128-color palette is available, while in PAL, only 104 colors are available. Additionally, the SECAM palette consists of only 8 colors.
Games.
In 1977, nine games were released on cartridge to accompany the launch of the machine, including Outlaw, Space War and Breakout. During the console's lifetime, Atari Inc and Atari Corp. published many titles: these games included "Adventure" (often credited as starting the action-adventure game genre—its creator, Warren Robinett, also introduced the first widely known Easter egg to the gaming world—"Breakout", and "Yars' Revenge". The console's popularity attracted many third-party developers, which led to popular titles such as Activision's "Pitfall!" and Imagic's "Atlantis". However, two Atari published titles, "E.T. the Extra-Terrestrial" and "Pac-Man", are frequently blamed for contributing to the video game crash of 1983.
Legacy.
The Atari 2600 was wildly successful, and during much of the 1980s, "Atari" was a synonym for this model in mainstream media and, by extension, for video games in general.
The Atari 2600 was inducted into the National Toy Hall of Fame at The Strong in Rochester, New York in 2007. In 2009, the Atari 2600 was named the second greatest video game console of all time by IGN, who cited its remarkable role as the console behind both the first video game boom and the video game crash of 1983, and called it "the console that our entire industry is built upon."
Atari 2000.
The Atari 2000 (model number CX-2000) was a prototype version of the Atari 2600 that was intended to be released as a cheaper alternative for children in 1982. Although identical in specification to the original 2600, the 2000 included built-in controllers and an innovative case design. The 2000 was originally intended to be black, but it was later recolored blue to appeal more to children. While Atari never officially stated the reason for not releasing the 2000, experts have cited the poor quality and durability of its built-in joysticks and the greater in-house popularity of the competing 2600 Jr. design as the most likely reasons.
Atari 3200.
Atari started work on a replacement to the 2600, called the Atari 3200, with codenames including Super Stella, Sylvia, and PAM (a note attached reads "Super Stella: Multipurpose"). The system was to have compatibility with Atari 2600 cartridges, and was rumored to be based on a 10-bit processor, although design documents shows it was to actually be based around the 6502 8-bit CPU. It was still unfinished when preliminary game programmers discovered that it was difficult to program. The project was cancelled, and Atari went with the second "System X", also titled PAM, that would later become the Atari 5200. Atari also cloned the Atari 3200 into the Sears Super Arcade II, but this was never released.
Clones and reissues.
The console and its old and new games are very popular with collectors because of its significant impact on video game and consumer electronics history and also due to its nostalgic value for many people, along with a number of games that are still considered highly playable. In addition, modern Atari 2600 clones remain on the market. One example is the Atari Classics 10-in-1 TV Game, manufactured by Jakks Pacific, which emulates the 2600 console, and includes converted versions of 10 games into a single Atari-brand-lookalike joystick with composite-video outputs for connecting directly to modern televisions or VCRs. Another is the TV Boy, which includes 127 games in an enlarged joypad.
The Atari Flashback 2 console, released in 2005, contains 40 games (with four additional programs unlockable by a cheat code). The console implements the original 2600 architecture and can be modified to play original 2600 cartridges by adding a cartridge port, and is also compatible with original 2600 controllers.
In music.
Many games for the Atari 2600 have detailed and easily identifiable music, and its distinctive sound makes it ideal for use in modern lo-fi and industrial music. In 2002, Dallas musician and visual artist Paul Slocum developed a cartridge called Synthcart for the Atari 2600, which allows the user to turn an Atari 2600 into a two-voice synthesizer and drum machine. Adapters have also been developed by amateurs enabling the Atari 2600's use with MIDI devices. A number of bands, such as 8 Bit Weapon, Black Moth Super Rainbow and The Squigs, as well as Slocum's own band Tree Wave, use Synthcart to make modern music on the Atari 2600. Some effects units like the MXR Blue Box are often cited for their ability to produce an Atari-like sound. Phonte from the hip-hop group Little Brother, along with fellow lyricist Eccentric, formed a mock group named Unheralded Symmetrics, and recorded a tribute to the system, entitled "Atari 2600".

</doc>
<doc id="2780" url="https://en.wikipedia.org/wiki?curid=2780" title="Atari 5200">
Atari 5200

The Atari 5200 SuperSystem, commonly known as the Atari 5200, is a home video game console that was introduced in 1982 by Atari Inc. as a higher-end complementary console for the popular Atari 2600. The 5200 was created to compete with the Intellivision, but wound up more directly competing with the ColecoVision shortly after its release.
The 5200 was based on Atari Inc.'s existing 400/800 computers and the internal hardware was almost identical, although software was not directly compatible between the two systems. The 5200's controllers have an analog joystick and a numeric keypad along with start, pause and reset buttons. The 360-degree non-centering joystick was touted as offering more control than the eight-way joystick controller offered with the Atari 2600.
Hardware.
Much of the technology in the Atari 8-bit family of home computer systems was originally developed as a second-generation games console intended to replace the 2600. However, as the system was reaching completion, the personal computer revolution was starting with the release of machines like the Commodore PET, TRS-80 and Apple II. These machines had less advanced hardware than the 5200, but sold for much higher prices with associated higher profit margins. Atari's management decided to enter this market, and the technology was repackaged into the Atari 400 and 800. The chipset used in the these machines was created with the mindset that the 2600 would likely be obsolete by the 1980 time frame. What was surprising, however, was that the entry into this new market of competition helped to quickly cut off the sales of the 2600.
Atari decided to re-enter the games market with a design that closely matched their original 1978 specifications. In its prototype stage, the Atari 5200 was originally called the "Atari Video System X - Advanced Video Computer System", and was codenamed "Pam" after a female employee at Atari Inc. It is also rumored that PAM actually stood for "Personal Arcade Machine", as the majority of games for the system ended up being arcade conversions. Actual working "Atari Video System X" machines, whose hardware is 100% identical to the Atari 5200 do exist, but are extremely rare.
The initial 1982 release of the system featured four controller ports, where nearly all other systems of the day had only one or two ports. The 5200 also featured a new style controller with an analog joystick, numeric keypad, two fire buttons on each side of the controller and game function keys for Start, Pause, and Reset. The 5200 also featured the innovation of the first automatic TV switchbox, allowing it to automatically switch from regular TV viewing to the game system signal when the system was activated. Previous RF adapters required the user to slide a switch on the adapter by hand. This unique RF box was also where the power supply connected in a unique dual power/television signal setup similar to the RCA Studio II's. A single cable coming out of the 5200 plugged into the switch box and was used for both electricity and the television signal.
The 1983 revision of the Atari 5200 has two controller ports instead of four, and a change back to the more conventional separate power supply and standard non-autoswitching RF switch. It also has changes in the cartridge port address lines to allow for the Atari 2600 adapter released that year. While the adapter was only made to work on the two-port version, modifications can be made to the four-port to make it line-compatible. In fact, towards the end of the four-port model's production run, there were a limited number of consoles produced which included these modifications. These consoles can be identified by an asterisk in their serial number.
Controllers.
The controller prototypes used in the electrical development lab used a yoke and gimbal mechanism that came from an RC airplane controller kit. This simple design gave smooth linear control and was highly reliable. The design of the analog joystick, which used a weak rubber boot rather than springs to provide centering, proved to be ungainly and unreliable. They quickly became the Achilles' heel of the system because of their combination of an overly complex mechanical design with a very low-cost internal flex circuit system. Another major flaw of the controllers was that the design did not translate into a linear acceleration from the center through the arc of the stick travel. The controllers did, however, include a pause button, a unique feature at the time. Various third-party replacement joysticks were also released, including those made by Wico.
Atari Inc. released the Pro-Line Trak-Ball controller for the system, which was used primarily for gaming titles such as "Centipede" and "Missile Command". A paddle controller and an updated self-centering version of the original controller were also in development, but never made it to market.
Games shipped with plastic card overlays that snapped in over the keypad. The card would indicate which game functions, such as changing the view or vehicle speed, were assigned to each key.
The primary controller was ranked the 10th worst video game controller by IGN editor Craig Harris.
Internal differences between the 5200 and the 400/800.
Although the Atari 5200's internal design was extensively based on that of the 400/800 home computers, the differences were sufficient that games designed for one would not run directly on the other. John J. Anderson of "Creative Computing" alluded to the incompatibility being intentional, caused by fierce rivalries between Atari's computer and console divisions.
One of the most obvious differences was the 5200's lack of a keyboard. However, there were several others:
Atari Corp.'s later XE Games System revisited the idea of a console based on the 400/800 hardware. However, as this was essentially just a 65XE computer with a detachable keyboard, it was (unlike the 5200) able to run most of the home computer titles directly.
Market performance.
The Atari 5200 did not fare well commercially, compared to its predecessor, the Atari 2600. While it touted superior graphics to the 2600 and Mattel's Intellivision, the system was initially incompatible with the 2600's expansive library of games, and some market analysts have speculated that this hurt its sales, especially since an Atari 2600 cartridge adapter had been released for the Intellivision II. (A revised 2-port model was released in 1983, along with a game adapter that allowed gamers to play all 2600 games.) This lack of new games was due in part to a lack of funding, with Atari continuing to develop most of its games for the saturated 2600 market.
Many of the 5200's games appeared simply as updated versions of 2600 titles, which failed to excite consumers. Its pack-in game, "Super Breakout", was particularly criticized for not doing enough to demonstrate the system's capabilities, and this gave the ColecoVision a significant advantage when its pack-in, "Donkey Kong", delivered a more authentic arcade experience than any previous game cartridge. In its list of the top 25 game consoles of all time, IGN claimed that the main reason for the 5200's market failure was the technological superiority of its competitor, while other sources maintain that the two consoles are roughly equivalent in power.
At one point following the 5200's release, Atari had planned a smaller, cost-reduced version of the Atari 5200, which would have removed the controller storage bin. Code-named the "Atari 5100" (a.k.a. "Atari 5200 Jr."), only a few fully working prototype 5100s were made before the project was canceled.
On May 21, 1984, during a press conference at which the Atari 7800 was introduced, company executives revealed that the 5200 had been discontinued after just two years on the market. Total sales of the 5200 were reportedly in excess of 1 million units.
Games.
There were a total of 69 games officially released for the system. "Super Breakout", "Galaxian" and "Space Invaders" were the system's launch titles. A port of "Asteroids" was advertised as a launch title, but was never released. "Gremlins", released in 1986, was the last game officially released for the system.
Reception.
The 5200 received much criticism for the "sloppy" design of its non-centering analog controllers and its high asking price.

</doc>
<doc id="2781" url="https://en.wikipedia.org/wiki?curid=2781" title="Atari 7800">
Atari 7800

The Atari 7800 ProSystem, or simply the Atari 7800, is a home video game console officially released by Atari Corporation in 1986. It had simple digital joysticks and was almost fully backward-compatible with the Atari 2600, the first console to have backward compatibility without the use of additional modules. It was considered affordable at a price of US$140.
The 1986 launch is sometimes referred to as a "re-release" or "relaunch" because the Atari 7800 had originally been announced on May 21, 1984, to replace Atari Inc.'s Atari 5200, but a general release was shelved due to the sale of the company. A few units were released to test markets in June 1984 though. However, by 1987 the Nintendo Entertainment System was already dominating the home console market, and the 7800 could not gain a significant foothold.
In 2009, IGN chose the 7800 to be their 17th best video game console of all time. They justified this relatively low ranking (though higher than every other Atari console save the 2600) with the summary statement: "Its delayed release, its cancelled peripherals, and a lack of financial backing from the company's new owners all combined to ensure that Atari 7800 would never see any success beyond being a sexier way of playing Atari 2600 titles."
History.
The Atari 7800 ProSystem was the first game system from Atari Inc. designed by an outside company, General Computer Corporation (GCC). The system was designed in 1983-84 with an intended mass market rollout in June 1984, but was canceled shortly thereafter due to the sale of the company to Tramel Technology Ltd on July 2, 1984. The project was originally called the Atari 3600, though was later renamed the Atari 7800.
Atari had been facing mounting pressure in the form of competition from the ColecoVision, which boasted graphics that more closely mirrored arcade games of the time than Atari’s 2600 system. At the same time, the Atari 5200 (the original intended successor to the Atari 2600) had been widely criticized for not being able to play Atari 2600 games without an adapter.
GCC, which had a background in creating arcade games, designed their new system with a graphical architecture similar to arcade machines of the time. The 7800 allows a large number of moving objects (75 to 100) that far exceeds previous consoles. Powering the system is a slightly custom 6502 processor, the Atari SALLY (sometimes described as a "6502C"), running at 1.79 MHz.
In contrast to the Atari 5200, the Atari 7800 can play almost all Atari 2600 games out of the box, without the need for an adapter. In addition, it features a return to a digital controller.
To address the concerns of parents that home computers were a better investment than consoles, the system was designed to be upgraded to a full-fledged home computer. A keyboard was developed, and the keyboard had an expansion port (which was the SIO port from Atari's 8-bit computer line, though the 7800 could not run Atari computer programs) that allowed for the addition of peripherals such as disk drives and printers.
To further enhance the gaming experience, GCC had also designed a "high score cartridge", a battery-backed RAM cartridge designed for storing game scores. On the side of the 7800 was an expansion port, reportedly for a planned connection with a laserdisc player.
Launch.
The 7800 was initially released in southern California in June 1984, following an announcement on May 21, 1984 at the Summer Consumer Electronics Show. 13 games were announced for the system's launch, including "Ms. Pac-Man", "Pole Position II", "Centipede", "Joust", "Dig Dug", "Desert Falcon", "", "Galaga", "Xevious", "Food Fight", "Ballblazer", "Rescue on Fractalus!", and "Track & Field". Atari was a sponsor of the 1984 Summer Olympics and planned to push the 7800 aggressively in time for Christmas that year. 
On July 2, 1984, Warner Communications sold Atari's Consumer Division to Jack Tramiel. All projects were halted during an initial evaluation period. Modern publications have often incorrectly asserted that Jack Tramiel mothballed the Atari 7800 feeling video games were a past fad and subsequently asserted that he dusted off the Atari 7800 once the NES became successful. The reality was that a contractual issue arose in that GCC had not been paid for their development of the 7800. Warner and Tramiel battled back and forth over who was accountable, with Tramiel believing that the 7800 should have been covered as part of his acquisition deal. In May 1985, Jack relented and paid GCC the overdue payment. This led to additional negotiations regarding the initial launch titles that GCC had developed and then an effort to find someone to lead their new video game division, which was completed in November 1985.
The original production run of the Atari 7800 languished on warehouse shelves until it was re-introduced in January 1986 after strong 2600 sales the previous Christmas. The console was released nationwide in May 1986.
Atari's launch of the 7800 under Tramiel was far more subdued than Warner had planned for the system in 1984 with a marketing budget of just $300,000. Additionally, the keyboard and high score cartridge were canceled, the expansion port was removed from later production runs of the system and, in lieu of new titles, the system was launched with titles intended for the 7800's debut in 1984.
By the end of 1986, Computer Entertainer claimed the Atari 7800 had sold 100,000 consoles in the United States, less than the Sega Master System's 125,000 and the Nintendo Entertainment System's 1.1 million. According to Atari, due to manufacturing problems, they only managed to produce and sell 100,000 units by 1986, including units that had been in a warehouse since 1984. A common complaint in 1986 was a lack of games, including a gap of months between new releases ("Galaga"s release in August was followed by "Xevious" in November). By the end of 1986, the 7800 had 10 games, compared to Sega's 20 and Nintendo's 36; nine of the NES games were third-party, whereas the 7800 and Master System had no third-party games. A reason cited for the lack of third-party interest in the 7800 was its small 100,000 install base and low market penetration.
Marketplace challenges.
Atari's lineup for the 7800 emphasized high-quality versions of popular arcade games like "Joust" and "Asteroids". This had been a primary reason for the success of the Atari 2600 VCS against systems like the Intellivision.
During the Atari 7800’s life cycle, Atari found themselves struggling to get developers to create 7800 versions of then-popular arcade titles because of a controversial policy employed by Nintendo. When Nintendo revived the industry, they signed up software development companies to create Nintendo Entertainment System games under a strict license agreement which imposed serious restrictions on what they were allowed to do. One of the key clauses was that companies who made Nintendo games were not allowed to make that game on a competing system for a period of two years. Because of the market success of the Nintendo Entertainment System, companies chose to develop for it first and were thus barred from developing the same games on competing systems for two years. The software libraries of the Atari 7800 and Sega Master System suffered tremendously as a result.
Eleven titles were developed and sold by three third-party companies under their own labels for the 7800 (Absolute Entertainment, Activision, and Froggo) with the rest published by Atari themselves. However, most Atari development was contracted out.
Some NES titles were developed by companies who had licensed their title from a different arcade manufacturer. While the creator of the NES version would be restricted from making a competitive version of an NES game, the original arcade copyright holder was not precluded from licensing out rights for a home version of an arcade game to multiple systems. Through this loophole, Atari 7800 conversions of "Mario Bros.", "Double Dragon", "Commando", "Rampage", "Xenophobe", "Ikari Warriors", and "Kung-Fu Master" were licensed and developed.
Discontinuation.
The Atari 7800 remained officially active in the United States between 1986 and 1991 and in Europe between 1989 and 1991. On January 1, 1992, Atari Corp. formally announced that production of the Atari 7800, the Atari 2600, the Atari 8-bit computer line, and the Atari XE Game System would cease. (It has since been discovered that Atari Corp. continued to develop games such as "Toki" for the Atari 7800 until all development was shut down in May 1993.) By the time of the cancellation, Nintendo's NES dominated the North American market, controlling 80% while Atari Corp. controlled just 12%.
Despite trailing the Nintendo Entertainment System in terms of number of units sold, the 7800 was a profitable enterprise for Atari Corp., benefiting largely from Atari’s name and the system's 2600 compatibility. Profits were strong owing to low investment in game development and marketing. Nonetheless, the 7800 failed to help Atari regain its dominance in the video game industry.
Technical specifications.
Graphics.
The graphics are generated by a custom graphics chip called MARIA, which uses an approach to graphics commonly used in arcade game system boards at the time. It was very different from other second and third generation consoles. Instead of a limited number of hardware sprites, MARIA allows for a much larger number of sprites described in a list of display lists. Each display list contains sprite entries with pointers to graphics data, color information, and horizontal positioning. The same display list is used for multiple rasters with the pointers being automatically adjusted. However, managing and displaying a large number of sprites required much more CPU time (both directly and indirectly since the MARIA would halt the CPU when drawing sprites) than consoles with hardware sprites and backgrounds.
MARIA has a number of different graphics modes which are either 160 pixels wide or 320 pixels wide. While the 320 pixel modes theoretically enable the 7800 to create games at higher resolution than the 256 pixel wide graphics found in the Nintendo Entertainment System and Sega Master System, the intense processing demands of MARIA typically meant that programmers created their games using the lower 160 pixel modes.
The 7800 features a broad (for its time) palette of 256 colors. Depending on various parameters, each individual sprite can use from 1 to 12 colors, with 3 colors (plus a 4th "transparency" color) being the most common. In this format, the sprite is referenced to one of 8 palettes, where each palette holds 3 assignable colors. There is also an assignable background color, which will be visible wherever another object has not covered it up. In total the system can utilize 25 colors on a scanline at one time.
The graphics resolution, color palette assignments, and background color can be adjusted in between scanlines. This technique is documented in the original 1983 "Atari 3600 Software Guide". Games often used this feature to render high resolution text in one area of the screen, while displaying more colorful graphics with less resolution in the gameplay area. Demos also exist which use this feature to place all 256 colors on the screen at the same time.
The MARIA’s approach had advantages and disadvantages when it came to generating graphics in software during the lifespan of the 7800. It excelled at moving around large numbers of sprites on a static screen without the screen flickering that plagued other 8-bit systems. Its flexible design enabled it to play games which used display list manipulation to generate a pseudo 3D appearance such as "Ballblazer" (1987) and "F-18 Hornet" (1988). While side-scrolling games in the vein of "Super Mario Bros." are possible on the system (1990's "Scrapyard Dog" is the best example), it is significantly harder to develop such a title than on a tile-based system such as the Nintendo Entertainment System.
Sound.
A common criticism of the 7800 regards its use of the TIA to provide 2-channel sound effects and music, resulting in sound quality that is virtually identical to the Atari 2600 VCS from 1977. While the inclusion of 2600 hardware is required to maintain compatibility with the older system, this drove up production costs and reduced available space on the 7800’s motherboard. As such, the 7800 does not include additional hardware for generating sound as it does with graphics and the sound hardware is considered the weakest part of the system.
To compensate for this, GCC’s engineers allowed games to include a POKEY audio chip in the cartridge which substantially improved the audio quality. To ensure software developers had an economical means of producing better sound than TIA, GCC had originally planned to make a low-cost, high performance sound chip, GUMBY, which could also be placed in 7800 cartridges to enhance its sound capabilities further. This project was cancelled when Atari was sold to Jack Tramiel.
Despite having the capability to support sound chips in cartridges, almost no 7800 cartridges feature POKEY hardware for enhanced sound. "Ballblazer", released in 1987, uses the POKEY to generate all music and sound effects. Similarly, "Commando", released in 1989, uses a POKEY to generate in-game music while the TIA generates the game's sound effects for a total of 6 channels of sound.
Lockout features.
Following the debate over "Custer's Revenge", an Atari 2600 VCS title with adult themes, Atari had concerns over similar adult titles finding their way onto the 7800 and displaying adult graphics on the significantly improved graphics of the MARIA chip. To combat this, they included a digital signature protection method which prevented unauthorized 7800 games from being played on the system.
When a cartridge was inserted into the system, the 7800 BIOS included code which would generate a digital signature of the cartridge ROM and compare it to the signature stored on the cartridge. If a correct signature was located on the cartridge, the 7800 would operate in 7800 mode, granting the game access to MARIA and other features. If a signature was not located, the 7800 remained in 2600 mode and MARIA was unavailable. All 7800 games released in North America had to be digitally signed by Atari. This digital signature code is not present in PAL 7800s, which use various heuristics to detect 2600 cartridges, due to export restrictions. The signing utility was found and released by Classic Gaming Expo in 2001.
Backward compatibility.
The Atari 7800 differs from the 2600 in several key areas. It features a full Atari SALLY 6502 processor whereas the 2600 VCS has a stripped-down 6507 processor running at a slower speed. It has additional RAM (Random Access Memory) and the ability to access more cartridge data at one time than the 2600. The most substantial difference, however, is a graphics architecture which differs markedly from either the Atari 2600 VCS or Atari’s 8-bit line of computers.
The 7800's compatibility with the Atari 2600 is made possible by including many of the same chips used in the Atari 2600. When operating in “2600” mode to play Atari 2600 titles, the 7800 uses a Television Interface Adapter (TIA) chip to generate graphics and sound. The processor is slowed to 1.19 MHz, enabling the 7800 to mirror the performance of the 2600's stripped-down 6507 processor. RAM is limited to 128 bytes found in the RIOT and game data is accessed in 4K blocks.
When in “7800” mode (signified by the appearance of the full-screen Atari logo), the graphics are generated entirely by the MARIA graphics processing unit, all system RAM is available and game data is accessed in larger 48K blocks. The system’s SALLY 6502 runs at its normal 1.79 MHz instead of the reduced speed of 2600 mode. The 2600 chips are used in 7800 mode to generate sound as well as switch and controller interfaces.
The Atari 7800 does not support backward compatibility for Atari 5200 games or accessories.
System revisions.
Prototypes:
Production:
Peripherals.
The Atari 7800 came bundled with the Atari Proline Joystick, a two button controller with a joystick for movement. In response to criticism over ergonomic issues in the 7800’s Pro-Line controllers, Atari later released joypad controllers with European 7800s, which were similar in style to controllers found on Nintendo and Sega Systems. The Joypad was not available in the United States.
Unlike the NES or Sega Master System, there were few add-on peripherals for the 7800, though its backwards compatibility feature allowed it to be compatible with most Atari 2600 peripherals.
The most notable exception was the XG-1 lightgun, which came bundled with the Atari XE Game System. The XG-1 was fully compatible with the 7800 and was sold separately for other Atari systems. Atari released four 7800 light gun games: "Alien Brigade", "Crossbow", "Meltdown", and "Barnyard Blaster".
Canceled peripherals.
Due to the acquisition of the Atari Consumer Division by Jack Tramiel in 1984, a number of planned peripherals for the system were canceled.
Software library.
While the 7800 can actually play hundreds of titles due to its compatibility with the Atari 2600, there was limited third party support for the 7800 and fewer than 100 titles were specifically designed for it.
Unreleased games.
As with most game consoles, there were many more games in development for the 7800 than were actually released. However, very few prototypes have been located, due to Tramiel Atari’s reluctance to make them in the first place. Atari 7800 prototypes tend to be highly coveted by collectors, often fetching hundreds of dollars when sold. Some collectors are unwilling to share the rare items publicly as doing so is assumed to decrease the value of their prototype.
Nonetheless, some unreleased Atari 7800 games, as well as early versions of released games have been released to the public. A few have been manufactured and sold.
These include
Engineering Notes list "Tempest" as a game that was between 15–20% completed for the Atari 7800; no code to date has been found. The Atari Museum located and posted unreleased box art and notes for a 7800 version of "Crystal Castles", but no code to date has been found for that game, either. Atari's earlier 7800 games listing showed "Millipede" as one of the games in the line up; however, it does not appear that it was ever started or worked on.
Source code release.
The source code for 13 games, as well as the OS and development tools (for the Atari ST computer system) were discovered in a dumpster behind the Atari building in Sunnyvale, California. Commented assembly language source code was made available for "Centipede", "Commando", "Crossbow", "Desert Falcon", "Dig Dug", "Food Fight", "Galaga", "Hat Trick", "Joust", "Ms. Pac-Man", "Super Stunt Cycle", "Robotron: 2084" and "Xevious" game titles.
Emulation and homebrew.
When emulators of 1980s video game consoles began to appear on home computers in the late 1990s, the Atari 7800 was one of the last to be emulated. The lack of awareness of the system, the lack of understanding of the hardware, and fears about the digital signature lockout initially caused concerns. Since that time, however, the 7800 has been emulated successfully and is now common on emulation sites. One such program is ProSystem, written in C/C++ for the Microsoft Windows operating system. It uses the Windows API and DirectX to display what it emulates in both PAL and NTSC.
The digital signature long prevented homebrew games from being developed until the original encryption generating software was discovered. When the original digital signature generating software was turned over to the Atari community, development of new Atari 7800 titles began. In addition, the Atari community has slowly uncovered the original 7800 development tools and released them into the public domain. New tools, documentation, source code and utilities for development have since been created which has sponsored additional homebrew development. Several new commercial Atari 7800 titles such as Beef Drop, B*nQ, Pac Man Collection, Combat 1990, Santa Simon, and Space War have been created and released.
System compatible hardware has also been produced for the system. Among these was the Cuttle Cart II, a device that allowed the Atari 7800 to read MMC cards containing binary files of Atari 7800 programs. The Cuttle Cart II has enabled more people to play the entire 2600 and 7800 library on an original system as well as binaries of unreleased games and new homebrew titles. The Cuttle Cart II was a success by homebrew standards, selling out both production runs and commanding high prices on eBay.
A more recent development is the Atari 7800 expansion module developed by Legacy Engineering with a high scores save feature (with compatible games), additional RAM capabilities, as well as vastly improved sound capabilities using the POKEY and YM2151 sound chips. The Expansion module is designed as a pass-through device that sits on top of the console and requires no system modding.
Atari Flashback.
In 2004, Atari (now owned by Infogrames) released the first Atari Flashback console. This system resembled a miniature Atari 7800 and joysticks and had 20 built in games (five 7800 and fifteen 2600 titles). While the unit sold well, it was controversial among Atari fans. Atari had given the engineering firm, Legacy Engineering, extremely limited development timelines. The firm was forced to build the Flashback using NES-On-A-Chip hardware instead of recreating the Atari 7800 hardware. As a result, the Flashback has been criticized for failing to properly replicate the actual Atari gaming experience.
Legacy Engineering was later commissioned to create another 7800 project that was subsequently cancelled after prototypes were made.

</doc>
<doc id="2782" url="https://en.wikipedia.org/wiki?curid=2782" title="Atari Jaguar">
Atari Jaguar

The Atari Jaguar is a fifth generation home video game console that was developed by Atari Corporation. The console was the sixth and last programmable console to be developed under the Atari brand, originally released in North America in November 1993. Marketed by Atari as the first 64-bit video game console, the Jaguar was designed to compete with the 16-bit Sega Genesis and Super Nintendo Entertainment System and the 32-bit 3DO Interactive Multiplayer platform.
Development on the Atari Jaguar started in the early 90s, and was designed by Flare Technology, who were tasked by Atari to create two consoles; the Atari Panther, which would compete with the Sega Genesis and the Super Nintendo, and a successor, the Jaguar, which would surpass the capabilities of any other console on the market at the time. With development of the Jaguar running ahead of schedule, the Panther was cancelled, and the release of the Jaguar was pushed forward. It was originally released to test markets in New York City and San Francisco in November 1993, and to the general public in 1994, with "Cybermorph" as the pack-in launch game.
Upon release, it was criticized for its complex controller design, failure to distinguish itself from its 16-bit competitors, and low quality game library. The console's multi-chip architecture made game development for the console difficult, and underwhelming sales further contributed to the console's lack of third party support. This, in addition to the lack of internal development at Atari, led to a limited games library, comprising only 67 licensed titles.
Atari attempted to extend the lifespan of the Jaguar by releasing a CD-ROM add-on known as the Atari Jaguar CD and marketing the Jaguar as the low-cost next generation console, with a price tag over $100 less than any of its competitors. With the release of the Sega Saturn and Sony's PlayStation in 1995, sales of the Jaguar continued to fall, ultimately selling no more than 250,000 units before it was eventually discontinued in 1996. The Jaguar was deemed a commercial failure, and prompted Atari to leave the home video game console market. After Hasbro Interactive bought out Atari in the late 1990s, the patents to the Jaguar were released into the public domain, with the console being declared an open platform. Since then, the Jaguar has gained a cult following, with a developer base that produces homebrew games for the console.
History.
Development.
The Jaguar was developed by the members of Flare Technology, a company formed by Martin Brennan and John Mathieson. The team had claimed that they could not only make a console superior to the Sega Genesis or the Super Nintendo Entertainment System, but they could also be cost-effective. Impressed by their work on the Konix Multisystem, Atari persuaded them to close Flare and form a new company called Flare II, with Atari providing the funding. Flare II initially set to work designing two consoles for Atari Corp. One was a 32-bit architecture (codenamed "Panther"), and the other was a 64-bit system (codenamed "Jaguar"); however, work on the Jaguar design progressed faster than expected, so Atari Corp. canceled the Panther project to focus on the more promising Jaguar.
Launch.
The Jaguar was introduced in 1993 at a price of $249.99, under a $500 million manufacturing deal with IBM. The system was initially marketed only in New York City and San Francisco, under the slogan "Do the Math", claiming superiority over competing 16-bit and 32-bit systems. A US-wide release followed in early 1994.
The Atari Jaguar struggled to attain a substantial user base. In 1993, Atari reported that they had shipped 17,000 units as part of the system's initial test market. By the end of 1994, Atari reported that they had sold approximately 100,000 systems and had reduced the price to improve the competitive nature of the console. By the end of 1995, Sony and Sega had entered the marketplace with competing consoles and Atari's sales declined rapidly. In Atari's 1995 annual report, they noted:
"Jaguar sales were substantially below Atari's expectations, and Atari's business and financial results were materially adversely affected in 1995 as Atari continued to invest heavily in Jaguar game development, entered into arrangements to publish certain licensed titles and reduced the retail price for its Jaguar console unit. Atari attributes the poor performance of Jaguar to a number of factors including (i) extensive delays in development of software for the Jaguar which resulted in reduced orders due to consumer concern as to when titles for the platform would be released and how many titles would ultimately be available, and (ii) the introduction of competing products by Sega and Sony in May 1995 and September 1995, respectively."
Lack of titles was attributable to two main factors: the Jaguar's questionable long-term prospects among third-party game-publishers and the problematic nature of developing games for the Jaguar. Atari had one opportunity to convince third-party developers, vital for the diversity of Jaguar's game library, with a solid retail-performance, but as things played out, post-holiday sales figures questioned the viability of Atari's business; Atari failed to attract many third-party developers already committed to other game platforms. In addition, the Jaguar's underlying hardware was crippled by a flaw in the CPU's memory controller, which prevented code execution out of system RAM. Less severe, but still annoying defects included a buggy UART. The memory controller flaw could have been mitigated by a mature code-development environment, to unburden the programmer from having to micromanage small chunks of code. Jaguar's development tools left much to the programmer's own implementation, as documentation was incomplete. Writing game-code was often an endurance exercise in the tedious assembler.
In a July 1995 interview with "Next Generation", then-CEO Sam Tramiel declared that the Jaguar was as powerful, if not more powerful, than the Sega Saturn, and slightly weaker than the PlayStation.
Decline.
By the end of 1995, Atari's revenues declined by more than half, from US$38.7 million in 1994 to $14.6 million in 1995. In late 1995, Atari Corp. ran early-morning infomercial advertisements with enthusiastic salesmen touting the powerful game system. The infomercials ran most of the year, but did not significantly sell the remaining stock of Jaguar systems. In its 10-K405 SEC Filing, filed April 12, 1996, Atari informed their stockholders of the truly dire nature of the Jaguar business: Atari had already suffered an ill-fated crash in the mid-1980s as a result of the oversaturation of the video game market by third-party developers.
Production of the Jaguar ceased after Atari Corp. merged with JT Storage in a reverse takeover. In a last-ditch effort to revive the Jaguar, Atari Corp. tried to play down the other two consoles by proclaiming the Jaguar was the only "64-bit" system. This claim is questioned by some, because the CPU (68000) and GPU executed a 32-bit instruction-set, but sent control signals to the 64-bit graphics co-processors (or "graphics accelerators"). Atari Corp.'s reasoning that the 32-bit "Tom" and "Jerry" chips work in tandem to add up to a 64-bit system was ridiculed in a mini-editorial by "Electronic Gaming Monthly", which commented that "If Sega did the math for the Sega Saturn the way Atari did the math for their 64-bit Jaguar system, the Sega Saturn would be a 112-bit monster of a machine." Design specs for the console allude to the GPU or DSP being capable of acting as a CPU, leaving the Motorola 68000 to read controller inputs. In practice, however, many developers used the Motorola 68000 to drive gameplay logic.
Technical specifications.
From the Jaguar Software Reference manual, page 1:
Jaguar is a custom chip set primarily intended to be the heart of a very high-performance games/leisure computer. It may also be used as a graphics accelerator in more complex systems, and applied to workstation and business uses. As well as a general purpose CPU, Jaguar contains four processing units. These are the Object Processor, Graphics Processor, Blitter, and Digital Sound Processor. Jaguar provides these blocks with a 64-bit data path to external memory devices, and is capable of a very high data transfer rate into external dynamic RAM.
COJAG Arcade Games.
Atari Games licensed the Atari Jaguar's chipset for use in its arcade games. The system, named COJAG (for "Coin-Op Jaguar"), replaced the 68000 with a 68020 or MIPS R3000-based CPU (depending on the board version), and added a hard drive and more RAM. It ran the lightgun games "Area 51" and "Maximum Force", which were released by Atari as dedicated cabinets or as the Area 51/Maximum Force combo machine. Other games ("3 On 3 Basketball"; "Fishin' Frenzy"; "Freeze"; "Vicious Circle") were developed but never released.
Atari Jaguar Duo.
The Atari Jaguar Duo was a proposed console similar to the Sega CDX. It was an attempt by Atari to combine the Atari Jaguar and Atari Jaguar CD to make a new console. It was never completed and was thus never released. After cancelling the console, Atari was bought by Hasbro and ceased all console development.
Peripherals.
Prior to the launch of the console in November 1993, Atari had announced a variety of peripherals and add-ons for the Jaguar to be released over the console's lifespan. This included a CD-ROM-based add-on console, a dial-up internet link with support for online gaming, a virtual reality headset, and an MPEG-2 video card, among other things. However, due to the poor sales and eventual commercial failure of the Jaguar, most of the peripherals in development were scrapped. The only peripherals and add-ons released by Atari for the Jaguar were a redesigned controller, an adapter for four-players, a CD console add-on and a link cable for Local area network (LAN) gaming.
The redesigned second controller for the Jaguar, named the "ProController" by Atari, added three more face buttons, two triggers, and had a flat interface. The controller was created in response to the criticism of the original controller that the console came with. Sold independently, however, it was never bundled with the system after its release. A peripheral that allowed 4 controllers to be plugged into the console was also released. Dubbed the "Team Tap", it was released independently and as a bundle with "White Men Can't Jump". However, the Team Tap was only compatible with "White Men Can't Jump" and "NBA Jam Tournament Edition". Eight player gameplay with the Team Tap peripheral is also possible if a second Team Tap is plugged into the second controller port on the console. Local area network multiplayer gameplay was achieved through the use of the Jaglink Interface, which allowed two Jaguar consoles to be linked together through a modular extension and a UTP phone cable. The Jaglink was compatible with three games: "AirCars", "BattleSphere" and "Doom".
In 1994 at the CES, Atari announced that it partnered up with Phylon, Inc. to create the Jaguar Voice/Data Communicator. The unit was delayed and eventually in 1995 mass production was canceled all together, but not before an estimated 100 or so were made. The JVM as it became known, utilized a 19.9kbit/s dial up modem and had the ability to answer incoming phone calls and store up to 18 phone numbers. Players were required to directly dial each other for online game play. The only Jaguar game that supports the JVM is Ultra Vortek, the modem is initialized in the Ultra Vortek start up screen by entering 911 on the key pad.
Jaguar CD.
The Atari Jaguar CD is an add-on to the Jaguar that made use of CD-ROMs to distribute games. Developed and marketed in response to Sony's PlayStation and Sega's Saturn console, it was released in September 1995, two years after the Jaguar's launch. Twelve games were released for the system during its manufacturing lifetime, with many more being made after, by homebrew developers. Each copy of the Jaguar CD console also came with a Virtual Light Machine, which displayed light patterns corresponding to music, if the user inserts an Audio CD into the console. It was developed by Jeff Minter, who had created the program after experimenting with graphics during the development of "Tempest 2000". The program was deemed a spiritual successor to the Atari Video Music, a system which served a similar purpose, released in 1976.
An additional accessory for the Jaguar CD, which allowed Jaguar CD games to save persistent data such as preferences and saved games, was also released. Known as the Memory Track, it was a cartridge that contained a 128 K EEPROM, and was to be inserted into the cartridge slot on the Jaguar CD while the user played a Jaguar CD game. The program manager for the Memory Track is accessed by pushing the option button while the system is starting, and exited by pushing the * and # keys simultaneously. There were plans to make a second model of the Jaguar console that combined both the Jaguar and the Jaguar CD into one unit, a la the TurboDuo. Originally codenamed the Jaguar III, and later the Jaguar Duo, the proposed model was developed to feasibly compete with the PlayStation and Sega Saturn, however, the idea was scrapped after the discontinuation of the Jaguar.
Jaguar VR.
A virtual reality headset compatible with the console, tentatively titled the Jaguar VR, was unveiled by Atari at the 1995 Winter Consumer Electronics Show. The development of the peripheral was a response to Nintendo's virtual reality console, the Virtual Boy, which had been announced the previous year. The headset was developed in cooperation with Virtuality, who had previously created many virtual reality arcade systems, and was already developing a similar headset for practical purposes, named Project Elysium, for IBM. The peripheral was targeted for a commercial release before Christmas 1995. However, the project was eventually cancelled, and Atari severed ties with Virtuality afterwards. After Atari's merger with JTS in 1996, all prototypes of the headset were allegedly destroyed. However, two working units, one low-resolution prototype with red and grey-colored graphics, and one high-resolution prototype with blue and grey-colored graphics, have since been recovered, and are regularly showcased at retrogaming-themed conventions and festivals. Only one game was developed for the Jaguar VR prototype; a 3D-rendered version of the 1980 arcade game "Missile Command", entitled "Missile Command 3D", though, a demo of Virtuality's "Zone Hunter" was also created for Jaguar VR demonstrations.
Unlicensed peripherals.
An unofficial expansion peripheral for the Atari Jaguar dubbed the "Catbox" was released by the Rockford, Illinois company ICD. It was originally slated to be released early in the Jaguar's life, in the second quarter of 1994, but was not actually released until mid-1995. The ICD CatBox plugs directly into the AV/DSP connectors located in the rear of the Jaguar console and provides three main functions. These are audio, video, and communications. It features six output formats, three for audio (line level stereo, RGB monitor, headphone jack with volume control) and three for video (composite, S-Video, and RGB analog component video) making the Jaguar compatible with multiple high quality monitor systems and multiple monitors at the same time. It is capable of communications methods known as CatNet and RS-232 as well as DSP pass through, allowing the user to connect two or more Jaguars together for multi player games either directly or with modems. The ICD CatBox features a polished stainless steel casing and red LEDs in the jaguar's eyes on the logo that indicate communications activity. An IBM AT type null modem cable may be used to connect two Jaguars together. The CatBox is also compatible with Atari's Jaglink Interface peripheral.
An adaptor for the Jaguar that allows for WebTV access was revealed in 1998, one prototype is known to exist.
Reception.
In 2006 IGN editor Craig Harris rated the Jaguar controller as the worst ever, criticizing the complexity of the "phone keypad". A version that has six action buttons, the Pro Controller, is suggested for certain games. Reviewing the Jaguar just a few weeks prior to its launch, "GamePro" gave it a "thumbs sideways". They praised the power of the hardware but criticized the controller, and were dubious of how the software lineup would turn out, commenting that Atari's failure to secure support from key third party publishers such as Capcom was a bad sign. They concluded that "Like the 3DO, the Jaguar is a risky investment - just not quite as expensive." Jaguar did earn praise with titles such as "Tempest 2000", "Doom", and "Wolfenstein 3D". The most successful title during the Jaguar's first year was "Alien vs. Predator". Both it and "Tempest 2000" were named among the system's defining titles by "GamePro" in 2007. With such a small library of games to challenge the incumbent 16-bit game consoles, Jaguar's appeal never grew beyond a small gaming audience. Digital Spy commented: "Like many failed hardware ventures, it still maintains something of a cult following but can only be considered a misstep for Atari."
Legacy.
After the Atari Corporation properties were bought out by Hasbro Interactive in the late 1990s, Hasbro released the rights to the Jaguar, declaring the console an open platform and opening the doors for homebrew development. A few developers, including Telegames and Songbird Productions, have not only released previously unfinished materials from the Jaguar's past, but also several brand new titles to satisfy the system's cult following.
In the United Kingdom in 2001, a deal was struck between Telegames and retailer Game to bring the Jaguar to Game's retail outlets. The machine was initially sold for £29.99 brand new and software prices ranged between £9.99 for more common games such as "Doom" and "Ruiner Pinball", and £39.99 for more sought-after releases such as "Defender 2000" and "Checkered Flag". The machine had a presence in the stores until 2007 when remaining consoles were sold off for £9.99 and games were sold for as low as 97p.
This deal was seen as a move to remain competitive with Game's rival at the time, Gamestation, who were well known for stocking retro formats.
Imagin Systems, a manufacturer of dental imaging equipment, has since purchased the molding plates for the Jaguar's casing as with minor modification they were found to be the right size for housing their HotRod camera. The game cartridge molds were reused to create an optional memory expansion card.
In December 2014, the molds for the console and cartridges were purchased from Imagin Systems by Mike Kennedy, owner of the "GameGavel" video game auction website and "Retro Magazine", a Kickstarter funded print and digital retro video game magazine, to manufacture shells for a brand new, Kickstarter funded, cartridge-based video game console, called the "Retro VGS" (Retro Video Game System). The purchase of the molds from Imagin Systems was far cheaper than designing and manufacturing entirely new molds, and Kennedy described their acquisition as "the entire reason he Retro VG is possible".
The Jaguar continues to have a very small and dedicated game development circle.

</doc>
<doc id="2783" url="https://en.wikipedia.org/wiki?curid=2783" title="Atari Lynx">
Atari Lynx

The Atari Lynx is an 8 bit handheld game console that was released by Atari Corporation in October 1989 in North America, and in Europe and Japan in 1990. The Lynx holds the distinction of being the world's first handheld electronic game with a color LCD. The system is also notable for its forward-looking features, advanced graphics, and ambidextrous layout. As part of the fourth generation of gaming, the Lynx competed with Nintendo's Game Boy (released just 2 months earlier), the Sega Game Gear and NEC's TurboExpress, both released the following year.
As with many classic consoles, there is a modern retrogaming community, creating and selling games for the system.
Features.
The Atari Lynx's innovative features include being the first color handheld, with a backlit display, a switchable right-handed/left-handed (upside down) configuration, and the ability to network with up to 17 other units via its "Comlynx" system (though most games would network eight or fewer players). Comlynx was originally developed to run over infrared links (and was codenamed RedEye). This was changed to a cable-based networking system before the final release.
The Lynx was cited as the "first gaming console with hardware support for zooming and distortion of sprites". Featuring a 4096 color palette and integrated math and graphics co-processors (including a blitter unit), its pseudo-3D color graphics display was said to be the key defining feature in the system's competition against Nintendo's monochromatic Game Boy. The fast pseudo-3D graphics features were made possible on a minimal hardware system by codesigner Dave Needle having "invented the technique for planar expansion/shrinking capability" and using stretched, textured, triangles instead of full polygons. These particular features were achieved over a year prior to the launch of the Super Nintendo Entertainment System, whose stock hardware features the comparable Mode 7 but which can't scale sprites.
History.
The Lynx was the second handheld game system to be released with the Atari name. The first was Atari Inc.'s handheld electronic game "Touch Me". Atari Inc. had previously worked on several other handheld projects including the "Breakout", "Space Invaders", and the Atari Cosmos portable/tabletop console. However, those projects were shut down during development, some just short of their intended commercial release.
The Lynx system was originally developed by Epyx as the Handy Game. In 1986, two former Amiga designers, R. J. Mical and Dave Needle, had been asked by former manager at Amiga, David Morse, if they could come up with a design for a portable gaming system. Morse now worked at Epyx, a game software company that had a recent string of hit games. Morse's son had asked him if he could make a portable gaming system, prompting the lunch with Mical and Needle to discuss the idea. Morse convinced Mical and Needle to develop the idea and they were hired by Epyx to be a part of the design team. Planning and design of the console began in 1986 and was completed in 1987. Epyx first showed the Handy system at the Winter Consumer Electronics Show (CES) in January 1989. Facing financial difficulties, Epyx sought out partners. Atari Corp. and Epyx eventually agreed that Atari Corp. would handle production and marketing, while Epyx would handle software development.
The Handy was designed to run games from the cartridge format, and the game data must be copied from ROM to RAM before it can be used. Thus, less RAM is available and the games initially load relatively slowly. There are trace remnants of a cassette tape interface physically capable of being programmed to read a tape. Lynx developers have noted that "there is still reference of the tape and some hardware addresses" and an updated vintage Epyx manual describes the bare existence of what could be utilized for tape support. A 2009 retrospective interview clarifies that although some early reports claimed that games were loaded from tape, Mical says there was no truth in them: "We did think about hard disk a little".
Atari Corp. changed the internal speaker and removed the thumb-stick on the control pad before releasing it as the Lynx, initially retailing in the US at . Atari Corp. then showed the Lynx to the press at the Summer 1989 CES as the "Portable Color Entertainment System", which was changed to "Lynx" when actual consoles were distributed to resellers.
The Lynx started off successfully. Atari reported that they had sold 90% of the 50,000 units it shipped in its launch month in the U.S. with a limited launch in New York. US sales in 1990 were approximately 500,000 units according to the Associated Press In late 1991, it was reported that Atari sales estimates were about 800,000, which Atari claimed was within their expected projections. Lifetime sales by 1995 amounted to fewer than 7 million units when combined with the Game Gear. In comparison, the Game Boy sold 16 million units by 1995. In issue 129 of Retro Gamer magazine a special article was published to celebrate the 25th anniversary of the console which included interviews with numerous ex-Atari and ex-Epyx staff where lifetime Lynx sales figures were confirmed as being in the region of 3 million.
As with the actual console units, the game cartridges themselves evolved over the first year of the console's release. The first generation of cartridges were flat, and were designed to be stackable for ease of storage. However, this design proved to be very difficult to remove from the console and was replaced by a second design. This style, called "tabbed" or "ridged", used the same basic design as the original cartridges with the addition of two small tabs on the cartridge's underside to aid in removal. The original flat style cartridges could be stacked on top of the newer cartridges, but the newer cartridges could not be easily stacked on each other, nor were they stored easily. Thus a third style, the "curved lip" style was produced, and all official and third-party cartridges during the console's lifespan were released (or re-released) using this style.
In May 1991, Sega launched its Game Gear portable gaming handheld. Also a color handheld, in comparison to the Lynx it had a higher cost and shorter battery life (3–4 hours as opposed to 4-5 for the Lynx), but it was slightly smaller and was backed up by significantly more games. In North America the Game Gear took second place, and while in Europe sales of the Lynx were initially quite strong on the back of the popular Atari ST, it still could not compete with the software library of the Game Gear and was eventually pushed into third place. Retailers such as Game and Toys R Us continued to sell the Lynx well into the mid-90s on the back of the Atari Jaguar launch, helped by magazines such as Ultimate Future Games who continued to cover the Lynx alongside the new generation of 32-bit and 64-bit consoles.
During 1990, the Lynx had moderate sales. In July 1991, Atari Corp. introduced the Lynx II with a new marketing campaign, new packaging, slightly improved hardware, better battery life and a new sleeker look. The new system (referred to within Atari Corp. as the "Lynx II") featured rubber hand grips and a clearer backlit color screen with a power save option (which turned off the LCD panel's backlighting). It also replaced the monaural headphone jack of the original Lynx with one wired for stereo. The new packaging made the Lynx available without any accessories, dropping the price to $99. Although sales improved, Nintendo still dominated the handheld market.
In 1995, Atari Corp. shifted its focus away from the Lynx. As Nintendo's Super Nintendo and Sega's Sega Genesis filled retailers' shelves, Atari Corp. refocused its efforts on its Jaguar console and it's CD add-on. A handful of games were released during this time, including "Battlezone 2000". In 1996, Atari shut down its internal game development.
Telegames released a number of games in the second half of the 1990s, including a port of "Raiden" and a platformer called "Fat Bobby" in 1997, as well as an action sports game called "Hyperdrome" in 1999. At the end of the 1990s, Hasbro, the owners of the Atari properties at the time, released the rights to develop for the system to the public domain. Since then a number of independent developers released games into the new decade, like "Championship Rally", "CyberVirus", and "Alpine Games". Some of the late 90s/early 2000s games were under development by other companies at one time, but rights to the game programs and all of the existing code was bought and finished by other developers.
In 2008 Atari was honored at the 59th Annual Technology & Engineering Emmy Awards for pioneering the development of handheld games with its Lynx game unit.
On October 24, 2009, North American company Super Fighter Team released "Zaku", a horizontal shooter for the Lynx developed by PenguiNet. It was the first new game for the system since the 1990s whose game card has an authentic "curved lip" plastic shell instead of a custom bare circuit board.
Reception.
The game system was reviewed in 1990 in "Dragon", giving the Lynx 5 out of 5 stars. The review states that the Lynx "throws the into the prehistoric age"; and praises the built-in object scaling capabilities, the multiplayer feature of the ComLynx cable, and the strong set of launch games.

</doc>
<doc id="2784" url="https://en.wikipedia.org/wiki?curid=2784" title="Ahimsa">
Ahimsa

Ahimsa (; IAST: , Pāli: ) is a term meaning 'not to injure' and 'compassion'. The word is derived from the Sanskrit root "hiṃs" – to strike; "hiṃsā" is injury or harm, "a-hiṃsā" is the opposite of this, i.e. cause no injury, do no harm. Ahimsa is also referred to as nonviolence, and it applies to all living beings - including all animals - according to many Indian religions.
Ahimsa is one of the cardinal virtues and an important tenet of 3 major religions (Jainism, Hinduism, and Buddhism). Ahimsa is a multidimensional concept, inspired by the premise that all living beings have the spark of the divine spiritual energy; therefore, to hurt another being is to hurt oneself. Ahimsa has also been related to the notion that any violence has karmic consequences. While ancient scholars of Hinduism pioneered and over time perfected the principles of Ahimsa, the concept reached an extraordinary status in the ethical philosophy of Jainism. Most popularly, Mahatma Gandhi strongly believed in the principle of "ahimsa".
Ahimsa's precept of 'cause no injury' includes one's deeds, words, and thoughts. Classical literature of Hinduism such as Mahabharata and Ramayana, as well as modern scholars debate principles of Ahimsa when one is faced with war and situations requiring self-defense. The historic literature from India and modern discussions have contributed to theories of Just War, and theories of appropriate self-defense.
Etymology.
The word "Ahimsa" - sometimes spelled as "Ahinsa" - is derived from the Sanskrit root "hiṃs" – to strike; "hiṃsā" is injury or harm, "a-hiṃsā" is the opposite of this, i.e. "non harming" or "nonviolence".
There is a debate on the origins of the word "Ahimsa", and how its meaning evolved. Mayrhofer as well as Dumot suggest the root word may be "han" which means kill, which leads to the interpretation that "ahimsa" means "do not kill". Schmidt as well as Bodewitz explain the proper root word is "hiṃs" and the Sanskrit verb "hinasti", which leads to the interpretation "ahimsa" means "do not injure", or "do not hurt". Wackernagel-Debrunner concur with the latter explanation.
Ancient texts use ahimsa to mean non-injury, a broader concept than non-violence. Non-injury implies not killing others, as well as not hurting others mentally or verbally; it includes avoiding all violent means - including physical violence - anything that injures others. In classical Sanskrit literature of Hinduism, another word "Adrohi" is sometimes used instead of "Ahimsa", as one of the cardinal virtues necessary for moral life. One example is in Baudhayana Dharmasutra 2.6.23: वाङ्-मनः-कर्म-दण्डैर् भूतानाम् अद्रोही (One who does not injure others with words, thoughts or acts is named "Adrohi").
Hinduism.
Ancient Vedic Texts.
Ahimsa as an ethical concept evolved in Vedic texts. The oldest scripts, along with discussing ritual animal sacrifices, indirectly mention Ahimsa, but do not emphasize it. Over time, the Hindu scripts revise ritual practices and the concept of Ahimsa is increasingly refined and emphasized, ultimately Ahimsa becomes the concept that describes the highest virtue by the late Vedic era (about 500 BC). For example, hymn 10.22.13 in the Rig Veda uses the words Satya (truthfulness) and Ahimsa in a prayer to deity Indra; later, the Yajur Veda dated to be between 1000 BC and 600 BC, states, "may all beings look at me with a friendly eye, may I do likewise, and may we look at each other with the eyes of a friend".
The term "Ahimsa" appears in the text Taittiriya Shakha of the Yajurveda (TS 5.2.8.7), where it refers to non-injury to the sacrificer himself. It occurs several times in the "Shatapatha Brahmana" in the sense of "non-injury". The Ahimsa doctrine is a late Vedic era development in Brahmanical culture. The earliest reference to the idea of non-violence to animals ("pashu-Ahimsa"), apparently in a moral sense, is in the Kapisthala Katha Samhita of the Yajurveda (KapS 31.11), which may have been written in about the 8th century BCE.
Bowker states the word appears but is uncommon in the principal Upanishads. Kaneda gives examples of the word "Ahimsa" in these Upanishads. Other scholars suggest "Ahimsa" as an ethical concept that started evolving in the Vedas, became an increasingly central concept in Upanishads.
The Chāndogya Upaniṣad, dated to the 8th or 7th century BCE, one of the oldest Upanishads, has the earliest evidence for the use of the word "Ahimsa" in the sense familiar in Hinduism (a code of conduct). It bars violence against "all creatures" ("sarvabhuta") and the practitioner of Ahimsa is said to escape from the cycle of metempsychosis (CU 8.15.1). A few scholars are of the opinion that this might have been a concession to the growing influence of Jainism, in Vedic Hinduism.
Chāndogya Upaniṣad also names Ahimsa, along with Satyavacanam (truthfulness), Arjavam (sincerity), Danam (charity), Tapo (penance/meditation), as one of five essential virtues (CU 3.17.4).
The Sandilya Upanishad lists ten forbearances: Ahimsa, Satya, Asteya, Brahmacharya, Daya, Arjava, Kshama, Dhriti, Mitahara and Saucha. According to Kaneda, the term Ahimsa is an important spiritual doctrine shared by Hinduism, Buddhism and Jainism. It literally means 'non-injury' and 'non-killing'. It implies the total avoidance of harming of any kind of living creatures not only by deeds, but also by words and in thoughts.
The Epics.
The Mahabharata, one of the epics of Hinduism, has multiple mentions of the phrase "Ahimsa Paramo Dharma" (अहिंसा परमॊ धर्मः), which literally means: non-violence is the highest moral virtue. For example, Mahaprasthanika Parva has the verse:
<poem>
अहिंसा परमॊ धर्मस तथाहिंसा परॊ दमः।
अहिंसा परमं दानम अहिंसा परमस तपः।
अहिंसा परमॊ यज्ञस तथाहिस्मा परं बलम।
अहिंसा परमं मित्रम अहिंसा परमं सुखम।
अहिंसा परमं सत्यम अहिंसा परमं शरुतम॥
</poem>
The above passage from Mahabharata emphasizes the cardinal importance of Ahimsa in Hinduism, and literally means: Ahimsa is the highest virtue, Ahimsa is the highest self-control, Ahimsa is the greatest gift, Ahimsa is the best suffering, Ahimsa is the highest sacrifice, Ahimsa is the finest strength, Ahimsa is the greatest friend, Ahimsa is the greatest happiness, Ahimsa is the highest truth, and Ahimsa is the greatest teaching. Some other examples where the phrase "Ahimsa Paramo Dharma" are discussed include Adi Parva, Vana Parva and Anushasana Parva. The Bhagavad Gita, among other things, discusses the doubts and questions about appropriate response when one faces systematic violence or war. These verses develop the concepts of lawful violence in self-defense and the theories of just war. However, there is no consensus on this interpretation. Gandhi, for example, considers this debate about non-violence and lawful violence as a mere metaphor for the internal war within each human being, when he or she faces moral questions.
Self-defense, criminal law, and war.
The classical texts of Hinduism devote numerous chapters discussing what people who practice the virtue of Ahimsa, can and must do when they are faced with war, violent threat or need to sentence someone convicted of a crime. These discussions have led to theories of just war, theories of reasonable self-defense and theories of proportionate punishment. Arthashastra discusses, among other things, why and what constitutes proportionate response and punishment.
The precepts of Ahimsa under Hinduism require that war must be avoided, with sincere and truthful dialogue. Force must be the last resort. If war becomes necessary, its cause must be just, its purpose virtuous, its objective to restrain the wicked, its aim peace, its method lawful. War can only be started and stopped by a legitimate authority. Weapons used must be proportionate to the opponent and the aim of war, not indiscriminate tools of destruction. All strategies and weapons used in the war must be to defeat the opponent, not designed to cause misery to the opponent; for example, use of arrows is allowed, but use of arrows smeared with painful poison is not allowed. Warriors must use judgment in the battlefield. Cruelty to the opponent during war is forbidden. Wounded, unarmed opponent warriors must not be attacked or killed, they must be brought to your realm and given medical treatment. Children, women and civilians must not be injured. While the war is in progress, sincere dialogue for peace must continue.
In matters of self-defense, different interpretations of ancient Hindu texts have been offered. For example, Tähtinen suggests self-defense is appropriate, criminals are not protected by the rule of Ahimsa, and Hindu scriptures support the use of violence against an armed attacker. Ahimsa is not meant to imply pacifism.
Alternate theories of self-defense, inspired by Ahimsa, build principles similar to theories of just war. Aikido, pioneered in Japan, illustrates one such principles of self-defense. Morihei Ueshiba, the founder of Aikido, described his inspiration as Ahimsa. According to this interpretation of Ahimsa in self-defense, one must not assume that the world is free of aggression. One must presume that some people will, out of ignorance, error or fear, attack other persons or intrude into their space, physically or verbally. The aim of self-defense, suggested Ueshiba, must be to neutralize the aggression of the attacker, and avoid the conflict. The best defense is one where the victim is protected, as well as the attacker is respected and not injured if possible. Under Ahimsa and Aikido, there are no enemies, and appropriate self-defense focuses on neutralizing the immaturity, assumptions and aggressive strivings of the attacker.
Tähtinen concludes that Hindus have no misgivings about death penalty; their position is that evil-doers who deserve death should be killed, and that a king in particular is obliged to punish criminals and should not hesitate to kill them, even if they happen to be his own brothers and sons.
Other scholars conclude that the scriptures of Hinduism suggest sentences for any crime must be fair, proportional and not cruel.
There is no universal consensus on pacifism among Hindu scholars of modern times. The conflict between pacifistic interpretations of Ahimsa and the theories of just war prescribed by the Gita has been resolved by some scholars such as Mohandas Karamchand Gandhi, as being an allegory, wherein the battlefield is the soul and Arjuna, the war is within each human being, where man's higher impulses struggle against his own evil impulses.
Non-human life.
The Hindu precept of 'cause no injury' applies to animals and all life forms. This precept isn’t found in the oldest verses of Vedas, but increasingly becomes one of the central ideas between 500 BC and 400 AD. In the oldest texts, numerous ritual sacrifices of animals, including cows and horses, are highlighted and hardly any mention is made of Ahimsa to non-human life.
Hindu scriptures, dated to between 5th century and 1st century BC, while discussing human diet, initially suggest ‘‘kosher’’ meat may be eaten, evolving it with the suggestion that only meat obtained through ritual sacrifice can be eaten, then that one should eat no meat because it hurts animals, with verses describing the noble life as one that lives on flowers, roots and fruits alone.
Later texts of Hinduism declare Ahimsa one of the primary virtues, declare any killing or harming any life as against ‘‘dharma’’ (moral life). Finally, the discussion in Upanishads and Hindu Epics shifts to whether a human being can ever live his or her life without harming animal and plant life in some way; which and when plants or animal meat may be eaten, whether violence against animals causes human beings to become less compassionate, and if and how one may exert least harm to non-human life consistent with ahimsa precept, given the constraints of life and human needs. The Mahabharata permits hunting by warriors, but opposes it in the case of hermits who must be strictly non-violent. Sushruta Samhita, a Hindu text written in the 3rd or 4th century, in Chapter XLVI suggests proper diet as a means of treating certain illnesses, and recommends various fishes and meats for different ailments and for pregnant women, and the Charaka Samhita describes meat as superior to all other kinds of food for convalescents.
Across the texts of Hinduism, there is a profusion of ideas about the virtue of Ahimsa when applied to non-human life, but without a universal consensus. Alsdorf claims the debate and disagreements between supporters of vegetarian lifestyle and meat eaters was significant. Even suggested exceptions – ritual slaughter and hunting – were challenged by advocates of Ahimsa. In the Mahabharata both sides present various arguments to substantiate their viewpoints. Moreover, a hunter defends his profession in a long discourse.
Many of the arguments proposed in favor of non-violence to animals refer to the bliss one feels, the rewards it entails before or after death, the danger and harm it prevents, as well as to the karmic consequences of violence.
The ancient Hindu texts discuss Ahimsa and non-animal life. They discourage wanton destruction of nature including of wild and cultivated plants. Hermits (sannyasins) were urged to live on a fruitarian diet so as to avoid the destruction of plants. Scholars claim the principles of ecological non-violence is innate in the Hindu tradition, and its conceptual fountain has been Ahimsa as their cardinal virtue.
The classical literature of Hinduism exists in many Indian languages. For example, "Tirukkuṛaḷ" written between 200 BC and 400 AD, and sometimes called the Tamil Veda, is one of the most cherished classics on Hinduism written in a South Indian language. Tirukkuṛaḷ dedicates Chapter 32 and 33 of Book 1 to the virtue of Ahimsa. "Tirukkuṛaḷ" suggests that Ahimsa applies to all life forms.
Modern times.
In the 19th and 20th centuries, prominent figures of Indian spirituality such as Swami Vivekananda, Ramana Maharshi, Swami Sivananda, A. C. Bhaktivedanta Swami and in the present time Vijaypal Baghel emphasized the importance of Ahimsa.
Mohandas Karamchand Gandhi promoted the principle of Ahimsa, very successful by applying it to all spheres of life, particularly to politics (Swaraj). His non-violent resistance movement satyagraha had an immense impact on India, impressed public opinion in Western countries, and influenced the leaders of various civil and political rights movements such as the American civil rights movement's Martin Luther King, Jr. and James Bevel. In Gandhi’s thought, Ahimsa precludes not only the act of inflicting a physical injury, but also mental states like evil thoughts and hatred, unkind behavior such as harsh words, dishonesty and lying, all of which he saw as manifestations of violence incompatible with Ahimsa. Gandhi believed Ahimsa to be a creative energy force, encompassing all interactions leading one's self to find satya, "Divine Truth". Sri Aurobindo criticized the Gandhian concept of Ahimsa as unrealistic and not universally applicable; he adopted a pragmatic non-pacifist position, saying that the justification of violence depends on the specific circumstances of the given situation. Sri Aurobindo also indicated that Gandhi's Ahimsa led to partition of India as it blocked the forceful action that the Indian people were engaged in during the 1920s and 30s, which caused delay in independence, allowing other forces to take root, including those who wanted India divided.
Gandhi stated that he viewed "Ahimsa is in Hinduism, it is in Christianity as well as in Islam." He added, "Nonviolence is common to all religions, but it has found the highest expression and application in Hinduism (I do not regard Jainism or Buddhism as separate from Hinduism)." When questioned whether violence and non-violence is both taught in Quran, he stated, "I have heard it from many Muslim friends that the Koran teaches the use of non-violence. (...The) argument about non-violence in the Holy Koran is an interpolation, not necessary for my thesis."
A historical and philosophical study of Ahimsa was instrumental in the shaping of Albert Schweitzer's principle of "reverence for life". Schweitzer praised Indian philosophical and religious traditions for ethics of Ahimsa as, "the laying down of the commandment not to kill and not to damage is one of the greatest events in the spiritual history of mankind", but suggested that "not-killing and not-harming" is not always practically possible as in self-defense, nor ethical as in chronic starving during a famine case.
Yoga.
Ahimsa is imperative for practitioners of Patañjali’s eight limb Raja yoga system. It is included in the first limb and is the first of five Yamas (self restraints) which, together with the second limb, make up the code of ethical conduct in Yoga philosophy. Ahimsa is also one of the ten "Yamas" in Hatha Yoga according to verse 1.1.17 of its classic manual "Hatha Yoga Pradipika".
Jainism.
In Jainism, the understanding and implementation of "Ahimsā" is more radical, scrupulous, and comprehensive than in any other religion. Killing any living being out of passions is considered "hiṃsā" (to injure) and abstaining from such an act is "ahimsā" (noninjury). The vow of ahimsā is considered the foremost among the 'five vows of Jainism'. Other vows like truth (satya) are meant for safeguarding the vow of ahimsā. In the practice of Ahimsa, the requirements are less strict for the lay persons (sravakas) who have undertaken "anuvrata" (Smaller Vows) than for the Jain monastics who are bound by the Mahavrata "Great Vows". The statement "" is often found inscribed on the walls of the Jain temples. Like in Hinduism, the aim is to prevent the accumulation of harmful karma. When Mahavira revived and reorganized the Jain faith in the 6th or 5th century BCE, Ahimsa was already an established, strictly observed rule. Rishabhanatha (Ādinātha), the first Jain Tirthankara, whom modern Western historians consider to be a historical figure, followed by Parshvanatha (Pārśvanātha) the twenty-third Tirthankara lived in about the 8th century BCE. He founded the community to which Mahavira’s parents belonged. Ahimsa was already part of the "Fourfold Restraint" ("Caujjama"), the vows taken by Parshva’s followers. In the times of Mahavira and in the following centuries, Jains were at odds with both Buddhists and followers of the Vedic religion or Hindus, whom they accused of negligence and inconsistency in the implementation of Ahimsa. According to the Jain tradition either lacto vegetarianism or veganism is mandatory.
The Jain concept of Ahimsa is characterized by several aspects. It does not make any exception for ritual sacrificers and professional warrior-hunters. Killing of animals for food is absolutely ruled out. Jains also make considerable efforts not to injure plants in everyday life as far as possible. Though they admit that plants must be destroyed for the sake of food, they accept such violence only inasmuch as it is indispensable for human survival, and there are special instructions for preventing unnecessary violence against plants. Jains go out of their way so as not to hurt even small insects and other minuscule animals. For example, Jains often do not go out at night, when they are more likely to step upon an insect. In their view, injury caused by carelessness is like injury caused by deliberate action. Eating honey is strictly outlawed, as it would amount to violence against the bees. Some Jains abstain from farming because it inevitably entails unintentional killing or injuring of many small animals, such as worms and insects, but agriculture is not forbidden in general and there are Jain farmers.
Theoretically, all life forms are said to deserve full protection from all kinds of injury, Jains recognize a hierarchy of life. Mobile beings are given higher protection than immobile ones. For the mobile beings, they distinguish between one-sensed, two-sensed, three-sensed, four-sensed and five-sensed ones; a one-sensed animal has touch as its only sensory modality. The more senses a being has, the more they care about non-injuring it. Among the five-sensed beings, the precept of non-injury and non-violence to the rational ones (humans) is strongest in Jain Ahimsa.
Jains agree with Hindus that violence in self-defense can be justified, and they agree that a soldier who kills enemies in combat is performing a legitimate duty. Jain communities accepted the use of military power for their defense, there were Jain monarchs, military commanders, and soldiers.
Buddhism.
In Buddhist texts "Ahimsa" (or its Pāli cognate ) is part of the Five Precepts (), the first of which has been to abstain from killing. However, this precept has been variously interpreted. In some Buddhist traditions, such as the Theravada tradition, vegetarianism is not mandatory. In these traditions, monks may eat meat and fish on condition that the animal was not killed specifically for them. For some monks, specifically monks of some Mahayana traditions, the eating of meat is strictly forbidden. Laypeople are also encouraged to eat vegetarian.
War.
Violent ways of punishing criminals and prisoners of war was not explicitly condemned in Buddhism, but peaceful ways of conflict resolution and punishment with the least amount of injury were encouraged. The early texts condemn the mental states that lead to violent behavior.
Nonviolence is an overriding theme within the Pali Canon. While the early texts condemn killing in the strongest terms, and portray the ideal king as a pacifist, such a king is nonetheless flanked by an army. It seems that the Buddha's teaching on nonviolence was not interpreted or put into practice in an uncompromisingly pacifist or anti-military-service way by early Buddhists. The early texts assume war to be a fact of life, and well-skilled warriors are viewed as necessary for defensive warfare. In Pali texts, injunctions to abstain from violence and involvement with military affairs are directed at members of the sangha; later Mahayana texts, which often generalize monastic norms to laity, require this of lay people as well.
The early texts do not contain just-war ideology as such. Some argue that a sutta in the "Gamani Samyuttam" rules out all military service. In this passage, a soldier asks the Buddha if it is true that, as he has been told, soldiers slain in battle are reborn in a heavenly realm. The Buddha reluctantly replies that if he is killed in battle while his mind is seized with the intention to kill, he will undergo an unpleasant rebirth. In the early texts, a person's mental state at the time of death is generally viewed as having a great impact on the next birth.
Some Buddhists point to other early texts as justifying defensive war. One example is the "Kosala Samyutta", in which King Pasenadi, a righteous king favored by the Buddha, learns of an impending attack on his kingdom. He arms himself in defense, and leads his army into battle to protect his kingdom from attack. He lost this battle but won the war. King Pasenadi eventually defeated King Ajatasattu and captured him alive. He thought that, although this King of Magadha has transgressed against his kingdom, he had not transgressed against him personally, and Ajatasattu was still his nephew. He released Ajatasattu and did not harm him. Upon his return, the Buddha said (among other things) that Pasenadi "is a friend of virtue, acquainted with virtue, intimate with virtue", while the opposite is said of the aggressor, King Ajatasattu.
According to Theravada commentaries, there are five requisite factors that must all be fulfilled for an act to be both an act of killing and to be karmically negative. These are: (1) the presence of a living being, human or animal; (2) the knowledge that the being is a living being; (3) the intent to kill; (4) the act of killing by some means; and (5) the resulting death. Some Buddhists have argued on this basis that the act of killing is complicated, and its ethicization is predicated upon intent. Some have argued that in defensive postures, for example, the primary intention of a soldier is not to kill, but to defend against aggression, and the act of killing in that situation would have minimal negative karmic repercussions.
According to Dr. Babasaheb Ambedkar, there is circumstantial evidence encouraging Ahimsa, from the Buddha's doctrine, "Love all, so that you may not wish to kill any." Gautama Buddha distinguished between a principle and a rule. He did not make Ahimsa a matter of rule, but suggested it as a matter of principle. This gives Buddhists freedom to act.
Laws.
The emperors of Sui dynasty, Tang dynasty and early Song dynasty banned killing in Lunar calendar 1st, 5th, and 9th month. Empress Wu Tse-Tien banned killing for more than half a year in 692. Some also banned fishing for some time each year.
There were bans after death of emperors, Buddhist and Taoist prayers, and natural disasters such as after a drought in 1926 summer Shanghai and an 8 days ban from August 12, 1959 after the August 7 flood (), the last big flood before the 88 Taiwan Flood.
People avoid killing during some festivals, like the Taoist Ghost Festival, the Nine Emperor Gods Festival, the Vegetarian Festival and many others.

</doc>
<doc id="2785" url="https://en.wikipedia.org/wiki?curid=2785" title="Annals of Mathematics">
Annals of Mathematics

The Annals of Mathematics is a bimonthly mathematical journal published by Princeton University and the Institute for Advanced Study.
Although its ISO 4 abbreviation is "Ann. Math.", Mathematical Reviews and many other mathematical publications abbreviate it as "Ann. of Math." instead.
History.
The journal was established as "The Analyst" in 1874 and with Joel E. Hendricks as the founding editor-in-chief. It was "intended to afford a medium for the presentation and analysis of any and all questions of interest or importance in pure and applied Mathematics, embracing especially all new and interesting discoveries in theoretical and practical astronomy, mechanical philosophy, and engineering". It was published in Des Moines, Iowa, and was the earliest American mathematics journal to be published continuously for more than a year or two. This incarnation of the journal ceased publication after its tenth year, in 1883, giving as an explanation Hendricks' declining health, but Hendricks made arrangements to have it taken over by new management, and it was continued from March 1884 as the "Annals of Mathematics". The new incarnation of the journal was edited by Ormond Stone (University of Virginia). It moved to Harvard in 1899 before reaching its current home in Princeton in 1911.
An important period for the journal was 1928–1958 with Solomon Lefschetz as editor. During this time, it became an increasingly well-known and respected journal. Its rise, in turn, stimulated American mathematics. Norman Steenrod characterized Lefschetz' impact as editor as follows: "The importance to American mathematicians of a first-class journal is that it sets high standards for them to aim at. In this somewhat indirect manner, Lefschetz profoundly affected the development of mathematics in the United States."
Princeton University continued to publish the annals on its own until 1933, when the Institute for Advanced Study took joint editorial control. Since 1998 it has been available in an electronic edition, alongside its regular print edition. The electronic edition was available without charge, as an open access journal, but since 2008 this is no longer the case. Issues from before 2003 were transferred to the non-free JSTOR archive, and articles are not freely available until 5 years after publication.
Editors.
The current editors of the "Annals of Mathematics" are David Gabai, Charles Fefferman, Nicholas M. Katz, Sergiu Klainerman, and Gang Tian (all from Princeton University).
Abstracting and indexing.
The journal is abstracted and indexed in the Science Citation Index, Current Contents/Physical, Chemical & Earth Sciences, and Scopus. According to the "Journal Citation Reports", the journal has a 2012 impact factor of 3.027, ranking it third out of 296 journals in the category "Mathematics".

</doc>
<doc id="2786" url="https://en.wikipedia.org/wiki?curid=2786" title="Andrei Sakharov">
Andrei Sakharov

Andrei Dmitrievich Sakharov (; May 21, 1921December 14, 1989) was a Russian nuclear physicist, Soviet dissident and human rights activist.
He became renowned as the designer of the Soviet Union's Third Idea, a codename for Soviet development of thermonuclear weapons. Sakharov later became an advocate of civil liberties and civil reforms in the Soviet Union, for which he faced state persecution; these efforts earned him the Nobel Peace Prize in 1975. The Sakharov Prize, which is awarded annually by the European Parliament for people and organizations dedicated to human rights and freedoms, is named in his honour.
Biography.
Sakharov was born in Moscow on May 21, 1921. His father was Dmitri Ivanovich Sakharov, a private school physics teacher and an amateur pianist. His father later taught at the Second Moscow State University. Andrei's grandfather Ivan had been a prominent lawyer in the Russian Empire who had displayed respect for social awareness and humanitarian principles (including advocating the abolition of capital punishment) that would later influence his grandson. Sakharov's mother was Yekaterina Alekseyevna Sakharova, a great-granddaughter of the prominent military commander Alexey Semenovich Sofiano (who was of Greek ancestry). Sakharov's parents and paternal grandmother, Maria Petrovna, largely shaped his personality. Although Sakharov's paternal great-grandfather had been a priest in the Russian Orthodox Church, and his pious mother had him baptised, Sakharov was an atheist in later life. However, he did believe that a "guiding principle" governed the universe and human life.
Education and career.
Sakharov entered Moscow State University in 1938. Following evacuation in 1941 during the Great Patriotic War (World War II), he graduated in Aşgabat, in today's Turkmenistan. He was then assigned to laboratory work in Ulyanovsk. In 1943, he married Klavdia Alekseyevna Vikhireva, with whom he raised two daughters and a son before she died in 1969. He returned to Moscow in 1945 to study at the Theoretical Department of FIAN (the Physical Institute of the Soviet Academy of Sciences). He received his Ph.D. in 1947.
Development of thermonuclear devices.
After the end of World War II, he researched cosmic rays. In mid-1948 he participated in the Soviet atomic bomb project under Igor Kurchatov and Igor Tamm. The first Soviet atomic device was tested on August 29, 1949. After moving to Sarov in 1950, Sakharov played a key role in the development of the first megaton-range Soviet hydrogen bomb using a design known as "Sakharov's Third Idea" in Russia and the Teller-Ulam design in the United States. Before his "Third Idea", Sakharov tried a "layer cake" of alternating layers of fission and fusion fuel. The results were disappointing, yielding no more than a typical fission bomb. However the design was seen to be worth pursuing because deuterium is abundant and uranium is scarce, and he had no idea how powerful the US design was. One of the Bikini atomic experiments changed that, because the magnitude of the explosion became public knowledge when there was a dispute between Japan and the US over the contamination of a large area of ocean. Sakharov was surprised by the size of the explosion and realized that the Americans had harnessed the power of a separate fission explosion to compress the fusion fuel. Sakharov realised that in order to cause the explosion of one side of the fuel to symmetrically compress the fusion fuel, a mirror could be used to reflect the radiation. The details had not been officially declassified in Russia when Sakharov was writing his memoirs, but in the Teller-Ulam design, soft X-rays emitted by the fission bomb were focused onto a cylinder of lithium deuteride to compress it symmetrically. This is called radiation implosion. The Teller-Ulam design also had a secondary fission device inside the fusion cylinder to assist with the compression of the fusion fuel and generate neutrons to convert some of the lithium to tritium, producing a mixture of deuterium and tritium. Sakarov's idea was first tested as RDS-37 in 1955. A larger variation of the same design which Sakharov worked on was the 50 Mt Tsar Bomba of October 1961, which was the most powerful nuclear device ever detonated.
Sakharov saw "striking parallels" between his fate and those of J. Robert Oppenheimer and Edward Teller in the USA. Sakharov believed that in this "tragic confrontation of two outstanding people", both deserved respect, because "each of them was certain he had right on his side and was morally obligated to go to the end in the name of truth." While Sakharov strongly disagreed with Teller over nuclear testing in the atmosphere and the Strategic Defense Initiative, he believed that American academics had been unfair to Teller's resolve to get the H-bomb for the United States since "all steps by the Americans of a temporary or permanent rejection of developing thermonuclear weapons would have been seen either as a clever feint, or as the manifestation of stupidity. In both cases, the reaction would have been the same – avoid the trap and immediately take advantage of the enemy's stupidity."
Sakharov never felt that by creating nuclear weapons he had "known sin", in Oppenheimer's expression. He later wrote: "After more than forty years, we have had no third world war, and the balance of nuclear terror ... may have helped to prevent one. But I am not at all sure of this; back then, in those long-gone years, the question didn't even arise. What most troubles me now is the instability of the balance, the extreme peril of the current situation, the appalling waste of the arms race ... Each of us has a responsibility to think about this in global terms, with tolerance, trust, and candor, free from ideological dogmatism, parochial interests, or national egotism."
Support for peaceful use of nuclear technology.
In 1950 he proposed an idea for a controlled nuclear fusion reactor, the tokamak, which is still the basis for the majority of work in the area. Sakharov, in association with Igor Tamm, proposed confining extremely hot ionized plasma by torus shaped magnetic fields for controlling thermonuclear fusion that led to the development of the tokamak device.
Efforts to improve nuclear reactor technology.
In 1951 he invented and tested the first explosively pumped flux compression generators, compressing magnetic fields by explosives. He called these devices MC or MK (for "magnetocumulative") generators. The radial MK-1 produced a pulsed magnetic field of 25 megagauss (2500 teslas). The resulting helical MK-2 generated 1000 million amperes in 1953.
Sakharov then tested a MK-driven "plasma cannon" where a small aluminum ring was vaporized by huge eddy currents into a stable, self-confined toroidal plasmoid and was accelerated to 100 km/s. Sakharov later suggested replacing the copper coil in MK generators with a large superconductor solenoid to magnetically compress and focus underground nuclear explosions into a shaped charge effect. He theorized this could focus 10 protons per second on a 1 mm surface.
Research and physics.
After 1965 Sakharov returned to fundamental science and began working on particle physics and cosmology.
He tried to explain the baryon asymmetry of the universe, being the first scientist to introduce two universes called "sheets", linked by the Big Bang. Sakharov achieved there a complete CPT symmetry since the second sheet is enantiomorph (P-symmetry), has an opposite arrow of time (T-symmetry) and is mainly populated by antimatter (C-symmetry) because of an opposite CP-violation. In this model the two universes do not interact, except via local matter accumulation whose density and pressure become high enough to connect the two sheets through a bridge without spacetime between them, but with geodesics continuity beyond the radius limit allowing an exchange of matter. Sakharov called such singularities a "collapse" and an "anticollapse", which are an alternative to the couple black hole and white hole in the wormhole theory. Sakharov also proposed the idea of induced gravity as an alternative theory of quantum gravity.
Turn to activism.
Since the late 1950s Sakharov had become concerned about the moral and political implications of his work. Politically active during the 1960s, Sakharov was against nuclear proliferation. Pushing for the end of atmospheric tests, he played a role in the 1963 Partial Test Ban Treaty, signed in Moscow.
The major turn in Sakharov's political evolution came in 1967, when anti-ballistic missile defense became a key issue in US–Soviet relations. In a secret detailed letter to the Soviet leadership of July 21, 1967, Sakharov explained the need to "take the Americans at their word" and accept their proposal for a "bilateral rejection by the USA and the Soviet Union of the development of antiballistic missile defense", because otherwise an arms race in this new technology would increase the likelihood of nuclear war. He also asked permission to publish his manuscript (which accompanied the letter) in a newspaper to explain the dangers posed by this kind of defense. The government ignored his letter and refused to let him initiate a public discussion of ABMs in the Soviet press.
In May 1968 he completed an essay, "Reflections on Progress, Peaceful Coexistence, and Intellectual Freedom", where the anti-ballistic missile defense is described as a major threat of world nuclear war. After this essay was circulated in "samizdat" and then published outside the Soviet Union (initially on July 6, 1968, in the Dutch newspaper "Het Parool" through intermediary of the Dutch academic and writer Karel van het Reve, followed by "The New York Times"), Sakharov was banned from conducting any military-related research and returned to FIAN to study fundamental theoretical physics. In 1970 he, along with Valery Chalidze and Andrei Tverdokhlebov, was one of the founders of the Committee on Human Rights in the USSR and came under increasing pressure from the government. He married a fellow human rights activist, Yelena Bonner, in 1972.
Attacked by Soviet establishment, 1972 onwards.
In 1972 Sakharov became the target of sustained pressure and intimidation, from his fellow scientists in the USSR Academy of Sciences, the Soviet press and direct threats of physical assault. Dissident activists, including the writer Solzhenitsyn, sprang to his defence. In 1973 and 1974, the Soviet media campaign continued, targeting both Sakharov and Aleksandr Solzhenitsyn. While Sakharov disagreed with Solzhenitsyn's vision of Russian revival, he deeply respected him for his courage. Only a few individuals in the Soviet Union dared to defend 'traitors' like Sakharov and Solzhenitsyn, and those who had dared were inevitably punished.
Sakharov later described that it took "years" for him to "understand how much substitution, deceit, and lack of correspondence with reality there was" in the Soviet ideals. "At first I thought, despite everything that I saw with my own eyes, that the Soviet State was a breakthrough into the future, a kind of prototype for all countries". Then he came, in his words, to "the theory of symmetry: all governments and regimes to a first approximation are bad, all peoples are oppressed, and all are threatened by common dangers."
After that he realized that there is not much "symmetry between a cancer cell and a normal one. Yet our state is similar to a cancer cell – with its messianism and expansionism, its totalitarian suppression of dissent, the authoritarian structure of power, with a total absence of public control in the most important decisions in domestic and foreign policy, a closed society that does not inform its citizens of anything substantial, closed to the outside world, without freedom of travel or the exchange of information." Sakharov's ideas on social development led him to put forward the principle of human rights as a new basis of all politics. In his works he declared that "the principle 'what is not prohibited is allowed' should be understood literally", defying the unwritten ideological rules imposed by the Communist ruling elite on the society in spite of the seemingly democratic (1936) USSR Constitution.
In 1973, Sakharov was nominated for the Nobel Peace Prize and in 1974 was awarded the Prix mondial Cino Del Duca. He was awarded the Nobel Peace Prize in 1975, although he was not allowed to leave the Soviet Union to collect it. His wife read his speech at the ceremony in Oslo, Norway. The Norwegian Nobel Committee called him "a spokesman for the conscience of mankind". In the words of the Nobel Committee's citation: "In a convincing manner Sakharov has emphasised that Man's inviolable rights provide the only safe foundation for genuine and enduring international cooperation."
In no way did Sakharov consider himself a prophet or the like: "I am no volunteer priest of the idea, but simply a man with an unusual fate. I am against all kinds of self-immolation (for myself and for others, including the people closest to me)." In a letter written from exile, he cheered up a fellow physicist and human rights activist with the words: "Fortunately, the future is unpredictable and also – because of quantum effects – uncertain." For Sakharov the indeterminacy of the future supported his belief that he could, and should, take personal responsibility for it.
Internal exile.
Sakharov was arrested on January 22, 1980, following his public protests against the Soviet intervention in Afghanistan in 1979, and was sent to internal exile in the city of Gorky, now Nizhny Novgorod, a city that was off limits to foreigners.
Between 1980 and 1986, Sakharov was kept under tight Soviet police surveillance. In his memoirs he mentions that their apartment in Gorky was repeatedly subjected to searches and heists. Sakharov was named the 1980 Humanist of the Year by the American Humanist Association.
In May 1984, Sakharov's wife, Yelena Bonner, was detained and Sakharov began a hunger strike, demanding permission for his wife to travel to the United States for heart surgery. He was forcibly hospitalized and force-fed. He was held in isolation for four months. In August 1984 Yelena Bonner was sentenced by a court to five years of exile in Gorky.
In April 1985, Sakharov started a new hunger strike for his wife to travel abroad for medical treatment. He again was taken to a hospital and force-fed. He remained in the hospital until October 1985 when his wife was allowed to travel to the United States. She had heart surgery in the United States and returned to Gorky in June 1986.
In December 1985, the European Parliament established the Sakharov Prize for Freedom of Thought, to be given annually for outstanding contributions to human rights.
On December 19, 1986, Mikhail Gorbachev, who had initiated the policies of perestroika and glasnost, called Sakharov to tell him that he and his wife could return to Moscow.
Political leader.
In 1988, Sakharov was given the International Humanist Award by the International Humanist and Ethical Union. He helped to initiate the first independent legal political organizations and became prominent in the Soviet Union's growing political opposition. In March 1989, Sakharov was elected to the new parliament, the All-Union Congress of People's Deputies and co-led the democratic opposition, the Inter-Regional Deputies Group.
Death.
Soon after 21:00 on December 14, 1989, Sakharov went to his study to take a nap before preparing an important speech he was to deliver the next day in the Congress. His wife went to wake him at 23:00 as he had requested but she found Sakharov dead on the floor. According to the notes of Yakov Rapoport, a senior pathologist present at the autopsy, it is most likely that Sakharov died of an arrhythmia consequent to dilated cardiomyopathy at the age of 68. He was interred in the Vostryakovskoye Cemetery in Moscow.
Influence.
Memorial prizes.
The Sakharov Prize for Freedom of Thought was established in 1988 by the European Parliament in his honour, and is the highest tribute to human rights endeavours awarded by the European Union. It is awarded annually by the parliament to "those who carry the spirit of Soviet dissident Andrei Sakharov"; to "Laureates who, like Sakharov, dedicate their lives to peaceful struggle for human rights."
An Andrei Sakharov prize has also been awarded by the American Physical Society every second year since 2006 "to recognize outstanding leadership and/or achievements of scientists in upholding human rights".
The Andrei Sakharov Prize For Writer's Civic Courage was established in October 1990.
In 2004, with the approval of Elena Bonner, an annual Sakharov Prize for journalism was established for reporters and commentators in Russia. Funded by former Soviet dissident Pyotr Vins, now a businessman in the USA, the prize is administered by the Glasnost Defence Foundation in Moscow. The prize "for journalism as an act of conscience" has been won over the years by famous journalists such as Anna Politkovskaya and young reporters and editors working far from Russia's media capital, Moscow. The 2015 winner was Yelena Kostyuchenko.
Andrei Sakharov Archives and Human Rights Center.
The Andrei Sakharov Archives and Human Rights Center, established at Brandeis University in 1993, are now housed at Harvard University.
The documents from that archive were published by the Yale University Press in 2005. These documents are available online.
Most of documents of the archive are letters from the head of the KGB to the Central Committee about activities of Soviet dissidents and recommendations about the interpretation in newspapers. The letters cover the period from 1968 to 1991 (Brezhnev stagnation). The documents characterize not only Sakharov's activity, but that of other dissidents, as well as that of highest-position apparatchiks and the KGB. No Russian equivalent of the KGB archive is available.
In 1980, Sakharov was stripped of all Soviet awards for "anti-Soviet activities". Later, during glasnost, he declined the return of his awards and, consequently, Mikhail Gorbachev did not sign the necessary decree.

</doc>
<doc id="2787" url="https://en.wikipedia.org/wiki?curid=2787" title="Astrobiology">
Astrobiology

Astrobiology is the study of the origin, evolution, distribution, and future of life in the universe: extraterrestrial life and life on Earth. This interdisciplinary field encompasses the search for habitable environments in the Solar System and habitable planets outside the Solar System, the search for evidence of prebiotic chemistry, laboratory and field research into the origins and early evolution of life on Earth, and studies of the potential for life to adapt to challenges on Earth and in outer space. Astrobiology addresses the question of whether life exists beyond Earth, and how humans can detect it if it does (the term exobiology is similar but more specific—it covers the search for life beyond Earth, and the effects of extraterrestrial environments on living things).
Astrobiology makes use of physics, chemistry, astronomy, biology, molecular biology, ecology, planetary science, geography, and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from the biosphere on Earth. The origin and early evolution of life is an inseparable part of the discipline of astrobiology. Astrobiology concerns itself with interpretation of existing scientific data; given more detailed and reliable data from other parts of the universe, the roots of astrobiology itself—physics, chemistry and biology—may have their theoretical bases challenged. Although speculation is entertained to give context, astrobiology concerns itself primarily with hypotheses that fit firmly into existing scientific theories.
The chemistry of life may have begun shortly after the Big Bang, 13.8 billion years ago, during a habitable epoch when the Universe was only 10–17 million years old. According to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe. According to research published in August 2015, very large galaxies may be more favorable to the creation and development of habitable planets than smaller galaxies, like the Milky Way galaxy. Nonetheless, Earth is the only place in the universe known to harbor life. Estimates of habitable zones around other stars, along with the discovery of hundreds of extrasolar planets and new insights into the extreme habitats here on Earth, suggest that there may be many more habitable places in the universe than considered possible until very recently.
Current studies on the planet Mars by the "Curiosity" and "Opportunity" rovers are now searching for evidence of ancient life as well as plains related to ancient rivers or lakes that may have been habitable. The search for evidence of habitability, taphonomy (related to fossils), and organic molecules on the planet Mars is now a primary NASA objective on Mars.
Overview.
"Astrobiology" is etymologically derived from the Greek , "astron", "constellation, star"; , "bios", "life"; and , "-logia", "study". The synonyms of astrobiology are diverse; however, the synonyms were structured in relation to the most important sciences implied in its development: astronomy and biology. A close synonym is "exobiology" from the Greek , "external"; Βίος, "bios", "life"; and λογία, -logia, "study". The term exobiology was coined by molecular biologist Joshua Lederberg. Exobiology is considered to have a narrow scope limited to search of life external to Earth, whereas subject area of astrobiology is wider and investigates the link between life and the universe, which includes the search for extraterrestrial life, but also includes the study of life on Earth, its origin, evolution and limits. Exobiology as a term tends to be replaced by astrobiology.
Another term used in the past is xenobiology, ("biology of the foreigners") a word used in 1954 by science fiction writer Robert Heinlein in his work The Star Beast. The term "xenobiology" is now used in a more specialized sense, to mean "biology based on foreign chemistry", whether of extraterrestrial or terrestrial (possibly synthetic) origin. Since alternate chemistry analogs to some life-processes have been created in the laboratory, xenobiology is now considered as an extant subject.
While it is an emerging and developing field, the question of whether life exists elsewhere in the universe is a verifiable hypothesis and thus a valid line of scientific inquiry. Though once considered outside the mainstream of scientific inquiry, astrobiology has become a formalized field of study. Planetary scientist David Grinspoon calls astrobiology a field of natural philosophy, grounding speculation on the unknown, in known scientific theory. NASA's interest in exobiology first began with the development of the U.S. Space Program. In 1959, NASA funded its first exobiology project, and in 1960, NASA founded an Exobiology Program, which is now one of four main elements of NASA's current Astrobiology Program. In 1971, NASA funded the Search for Extra-Terrestrial Intelligence (SETI) to search radio frequencies of the electromagnetic spectrum for interstellar communications transmitted by extraterrestrial life outside the Solar System. NASA's Viking missions to Mars, launched in 1976, included three biology experiments designed to look for metabolism of present life on Mars.
Advancements in the fields of astrobiology, observational astronomy and discovery of large varieties of extremophiles with extraordinary capability to thrive in the harshest environments on Earth, have led to speculation that life may possibly be thriving on many of the extraterrestrial bodies in the universe. A particular focus of current astrobiology research is the search for life on Mars due to its proximity to Earth and geological history. There is a growing body of evidence to suggest that Mars has previously had a considerable amount of water on its surface, water being considered an essential precursor to the development of carbon-based life.
Missions specifically designed to search for current life on Mars were the Viking program and Beagle 2 probes. The Viking results were inconclusive, and Beagle 2 failed minutes after landing. A future mission with a strong astrobiology role would have been the Jupiter Icy Moons Orbiter, designed to study the frozen moons of Jupiter—some of which may have liquid water—had it not been cancelled. In late 2008, the Phoenix lander probed the environment for past and present planetary habitability of microbial life on Mars, and to research the history of water there.
In November 2011, NASA launched the Mars Science Laboratory mission carrying the "Curiosity" rover, which landed on Mars at Gale Crater in August 2012. The "Curiosity" rover is currently probing the environment for past and present planetary habitability of microbial life on Mars. On 9 December 2013, NASA reported that, based on evidence from "Curiosity" studying Aeolis Palus, Gale Crater contained an ancient freshwater lake which could have been a hospitable environment for microbial life.
The European Space Agency is currently collaborating with the Russian Federal Space Agency (Roscosmos) and developing the ExoMars astrobiology rover, which is to be launched in 2018. While NASA is developing the Mars 2020 astrobiology rover and sample cacher for a later return to Earth.
Methodology.
Planetary habitability.
When looking for life on other planets like Earth, some simplifying assumptions are useful to reduce the size of the task of the astrobiologist. One is the informed assumption that the vast majority of life forms in our galaxy are based on carbon chemistries, as are all life forms on Earth. Carbon is well known for the unusually wide variety of molecules that can be formed around it. Carbon is the fourth most abundant element in the universe and the energy required to make or break a bond is just at an appropriate level for building molecules which are not only stable, but also reactive. The fact that carbon atoms bond readily to other carbon atoms allows for the building of arbitrarily long and complex molecules.
The presence of liquid water is an assumed requirement, as it is a common molecule and provides an excellent environment for the formation of complicated carbon-based molecules that could eventually lead to the emergence of life. Some researchers posit environments of ammonia, or more likely, water-ammonia mixtures as possible solvents for hypothetical types of biochemistry.
A third assumption is to focus on planets orbiting Sun-like stars for increased probabilities of planetary habitability. Very large stars have relatively short lifetimes, meaning that life might not have time to emerge on planets orbiting them. Very small stars provide so little heat and warmth that only planets in very close orbits around them would not be frozen solid, and in such close orbits these planets would be tidally "locked" to the star. The long lifetimes of red dwarfs could allow the development of habitable environments on planets with thick atmospheres. This is significant, as red dwarfs are extremely common. (See Habitability of red dwarf systems).
Since Earth is the only planet known to harbor life, there is no evident way to know if any of the simplifying assumptions are correct.
Communication attempts.
Research on communication with extraterrestrial intelligence (CETI) focuses on composing and deciphering messages that could theoretically be understood by another technological civilization. Communication attempts by humans have included broadcasting mathematical languages, pictorial systems such as the Arecibo message and computational approaches to detecting and deciphering 'natural' language communication. The SETI program, for example, uses both radio telescopes and optical telescopes to search for deliberate signals from an extraterrestrial intelligence.
While some high-profile scientists, such as Carl Sagan, have advocated the transmission of messages, scientist Stephen Hawking has warned against it, suggesting that aliens might simply raid Earth for its resources and then move on.
Elements of astrobiology.
Astronomy.
Most astronomy-related astrobiology research falls into the category of extrasolar planet (exoplanet) detection, the hypothesis being that if life arose on Earth, then it could also arise on other planets with similar characteristics. To that end, a number of instruments designed to detect Earth-sized exoplanets have been considered, most notably NASA's Terrestrial Planet Finder (TPF) and ESA's Darwin programs, both of which have been cancelled. NASA launched the Kepler mission in March 2009, and the French Space Agency launched the COROT space mission in 2006. There are also several less ambitious ground-based efforts underway.
The goal of these missions is not only to detect Earth-sized planets, but also to directly detect light from the planet so that it may be studied spectroscopically. By examining planetary spectra, it would be possible to determine the basic composition of an extrasolar planet's atmosphere and/or surface. Given this knowledge, it may be possible to assess the likelihood of life being found on that planet. A NASA research group, the Virtual Planet Laboratory, is using computer modeling to generate a wide variety of virtual planets to see what they would look like if viewed by TPF or Darwin. It is hoped that once these missions come online, their spectra can be cross-checked with these virtual planetary spectra for features that might indicate the presence of life.
An estimate for the number of planets with intelligent "communicative" extraterrestrial life can be gleaned from the Drake equation, essentially an equation expressing the probability of intelligent life as the product of factors such as the fraction of planets that might be habitable and the fraction of planets on which life might arise:
where:
However, whilst the rationale behind the equation is sound, it is unlikely that the equation will be constrained to reasonable error limits any time soon. The first term, "N", number of stars, is generally constrained within a few orders of magnitude. The second and third terms, "f", stars with planets and "f", planets with habitable conditions, are being evaluated for the star's neighborhood. The problem with the formula is that it is not usable to generate or support hypotheses because it contains factors that can never be verified. Drake originally formulated the equation merely as an agenda for discussion at the Green Bank conference, but some applications of the formula had been taken literally and related to simplistic or pseudoscientific arguments. Another associated topic is the Fermi paradox, which suggests that if intelligent life is common in the universe, then there should be obvious signs of it.
Another active research area in astrobiology is planetary system formation. It has been suggested that the peculiarities of the Solar System (for example, the presence of Jupiter as a protective shield) may have greatly increased the probability of intelligent life arising on our planet.
Biology.
Biology cannot state that a process or phenomenon, by being mathematically possible, has to exist forcibly in an extraterrestrial body. Biologists specify what is speculative and what is not.
Until the 1970s, life was thought to be entirely dependent on energy from the Sun. Plants on Earth's surface capture energy from sunlight to photosynthesize sugars from carbon dioxide and water, releasing oxygen in the process that is then consumed by oxygen-respiring organisms, passing their energy up the food chain. Even life in the ocean depths, where sunlight cannot reach, was thought to obtain its nourishment either from consuming organic detritus rained down from the surface waters or from eating animals that did. The world's ability to support life was thought to depend on its access to sunlight. However, in 1977, during an exploratory dive to the Galapagos Rift in the deep-sea exploration submersible "Alvin", scientists discovered colonies of giant tube worms, clams, crustaceans, mussels, and other assorted creatures clustered around undersea volcanic features known as black smokers. These creatures thrive despite having no access to sunlight, and it was soon discovered that they comprise an entirely independent ecosystem. Instead of plants, the basis for this food chain is a form of bacterium that derives its energy from oxidization of reactive chemicals, such as hydrogen or hydrogen sulfide, that bubble up from the Earth's interior. This chemosynthesis revolutionized the study of biology and astrobiology by revealing that life need not be sun-dependent; it only requires water and an energy gradient in order to exist.
Extremophiles, organisms able to survive in extreme environments, are a core research element for astrobiologists. Such organisms include biota which are able to survive several kilometers below the ocean's surface near hydrothermal vents and microbes that thrive in highly acidic environments. It is now known that extremophiles thrive in ice, boiling water, acid, alkali, the water core of nuclear reactors, salt crystals, toxic waste and in a range of other extreme habitats that were previously thought to be inhospitable for life. It opened up a new avenue in astrobiology by massively expanding the number of possible extraterrestrial habitats. Characterization of these organisms, their environments and their evolutionary pathways, is considered a crucial component to understanding how life might evolve elsewhere in the universe. For example, some organisms able to withstand exposure to the vacuum and radiation of outer space include the lichen fungi "Rhizocarpon geographicum" and "Xanthoria elegans", the bacterium "Bacillus safensis", "Deinococcus radiodurans", "Bacillus subtilis", yeast "Saccharomyces cerevisiae", seeds from "Arabidopsis thaliana" ('mouse-ear cress'), as well as the invertebrate animal Tardigrade.
Jupiter's moon, Europa, and Saturn's moon, Enceladus, are now considered the most likely locations for extant extraterrestrial life in the Solar System.
The origin of life, known as abiogenesis, distinct from the evolution of life, is another ongoing field of research. Oparin and Haldane postulated that the conditions on the early Earth were conducive to the formation of organic compounds from inorganic elements and thus to the formation of many of the chemicals common to all forms of life we see today. The study of this process, known as prebiotic chemistry, has made some progress, but it is still unclear whether or not life could have formed in such a manner on Earth. The alternative hypothesis of panspermia is that the first elements of life may have formed on another planet with even more favorable conditions (or even in interstellar space, asteroids, etc.) and then have been carried over to Earth — the panspermia hypothesis.
The cosmic dust permeating the universe contains complex organic matter ("amorphous organic solids with a mixed aromatic-aliphatic structure") that could be created naturally, and rapidly, by stars. Further, a scientist suggested that these compounds may have been related to the development of life on Earth and said that, "If this is the case, life on Earth may have had an easier time getting started as these organics can serve as basic ingredients for life." In September 2012, NASA scientists reported that polycyclic aromatic hydrocarbons (PAHs), subjected to interstellar medium conditions, are transformed through hydrogenation, oxygenation and hydroxylation, to more complex organics - "a step along the path toward amino acids and nucleotides, the raw materials of proteins and DNA, respectively".
More than 20% of the carbon in the universe may be associated with PAHs, possible starting materials for the formation of life. PAHs seem to have been formed shortly after the Big Bang, are widespread throughout the universe, and are associated with new stars and exoplanets.
Astroecology.
Astroecology concerns the interactions of life with space environments and resources, in planets, asteroids and comets. On a larger scale, astroecology concerns resources for life about stars in the galaxy through the cosmological future. Astroecology attempts to quantify future life in space, addressing this area of astrobiology.
Experimental astroecology investigates resources in planetary soils, using actual space materials in meteorites. The results suggest that Martian and carbonaceous chondrite materials can support bacteria, algae and plant (asparagus, potato) cultures, with high soil fertilities. The results support that life could have survived in early aqueous asteroids and on similar materials imported to Earth by dust, comets and meteorites, and that such asteroid materials can be used as soil for future space colonies.
On the largest scale, cosmoecology concerns life in the universe over cosmological times. The main sources of energy may be red giant stars and white and red dwarf stars, sustaining life for 10 years. Astroecologists suggest that their mathematical models may quantify the potential amounts of future life in space, allowing a comparable expansion in biodiversity, potentially leading to diverse intelligent life forms.
Astrogeology.
Astrogeology is a planetary science discipline concerned with the geology of the celestial bodies such as the planets and their moons, asteroids, comets, and meteorites. The information gathered by this discipline allows the measure of a planet's or a natural satellite's potential to develop and sustain life, or planetary habitability.
An additional discipline of astrogeology is geochemistry, which involves study of the chemical composition of the Earth and other planets, chemical processes and reactions that govern the composition of rocks and soils, the cycles of matter and energy and their interaction with the hydrosphere and the atmosphere of the planet. Specializations include cosmochemistry, biochemistry and organic geochemistry.
The fossil record provides the oldest known evidence for life on Earth. By examining the fossil evidence, paleontologists are able to better understand the types of organisms that arose on the early Earth. Some regions on Earth, such as the Pilbara in Western Australia and the McMurdo Dry Valleys of Antarctica, are also considered to be geological analogs to regions of Mars, and as such, might be able to provide clues on how to search for past life on Mars.
The various organic functional groups, composed of hydrogen, oxygen, nitrogen, phosphorus, sulfur, and a host of metals, such as iron, magnesium, and zinc, provide the enormous diversity of chemical reactions necessarily catalyzed by a living organism. Silicon, in contrast, interacts with only a few other atoms, and the large silicon molecules are monotonous compared with the combinatorial universe of organic macromolecules. Indeed, it seems likely that the basic building blocks of life anywhere will be similar those on Earth, in the generality if not in the detail. Although terrestrial life and life that might arise independently of Earth are expected to use many similar, if not identical, building blocks, they also are expected to have some biochemical qualities that are unique. If life has had a comparable impact elsewhere in the Solar System, the relative abundances of chemicals key for its survival - whatever they may be - could betray its presence. Whatever extraterrestrial life may be, its tendency to chemically alter its environment might just give it away.
Life in the Solar System.
People have long speculated about the possibility of life in settings other than Earth, however, speculation on the nature of life elsewhere often has paid little heed to constraints imposed by the nature of biochemistry. The likelihood that life throughout the universe is probably carbon-based is suggested by the fact that carbon is one of the most abundant of the higher elements. Only two of the natural atoms, carbon and silicon, are known to serve as the backbones of molecules sufficiently large to carry biological information. As the structural basis for life, one of carbon's important features is that unlike silicon, it can readily engage in the formation of chemical bonds with many other atoms, thereby allowing for the chemical versatility required to conduct the reactions of biological metabolism and propagation.
Thought on where in the Solar System life might occur, was limited historically by the understanding that life relies ultimately on light and warmth from the Sun and, therefore, is restricted to the surfaces of planets. The three most likely candidates for life in the Solar System are the planet Mars, the Jovian moon Europa, and Saturn's moon Titan. More recently, Saturn's moon Enceladus may be considered a likely candidate as well.
Mars, Enceladus and Europa are considered likely candidates in the search for life primarily because they may have liquid water, a molecule essential for life as we know it for its use as a solvent in cells. Water on Mars is found in its polar ice caps, and newly carved gullies recently observed on Mars suggest that liquid water may exist, at least transiently, on the planet's surface. At the Martian low temperatures and low pressure, liquid water is likely to be highly saline. As for Europa, liquid water likely exists beneath the moon's icy outer crust. This water may be warmed to a liquid state by volcanic vents on the ocean floor, but the primary source of heat is probably tidal heating. On 11 December 2013, NASA reported the detection of "clay-like minerals" (specifically, phyllosilicates), often associated with organic materials, on the icy crust of Europa. The presence of the minerals may have been the result of a collision with an asteroid or comet according to the scientists.
Another planetary body that could potentially sustain extraterrestrial life is Saturn's largest moon, Titan. Titan has been described as having conditions similar to those of early Earth. On its surface, scientists have discovered the first liquid lakes outside Earth, but they seem to be composed of ethane and/or methane, not water. Some scientists think it possible that these liquid hydrocarbons might take the place of water in living cells different from those on Earth. After Cassini data was studied, it was reported on March 2008 that Titan may also have an underground ocean composed of liquid water and ammonia. Additionally, Saturn's moon Enceladus may have an ocean below its icy surface and, according to NASA scientists in May 2011, "is emerging as the most habitable spot beyond Earth in the Solar System for life as we know it".
Measuring the ratio of hydrogen and methane levels on Mars may help determine the likelihood of life on Mars. According to the scientists, "...low H/CH ratios (less than approximately 40) indicate that life is likely present and active." Other scientists have recently reported methods of detecting hydrogen and methane in extraterrestrial atmospheres.
Complex organic compounds of life, including uracil, cytosine and thymine, have been formed in a laboratory under outer space conditions, using starting chemicals such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe.
Rare Earth hypothesis.
The Rare Earth hypothesis postulates that multicellular life forms found on Earth may actually be more of a rarity than scientists assume. It provides a possible answer to the Fermi paradox which suggests, "If extraterrestrial aliens are common, why aren't they obvious?" It is apparently in opposition to the principle of mediocrity, assumed by famed astronomers Frank Drake, Carl Sagan, and others. The Principle of Mediocrity suggests that life on Earth is not exceptional, but rather that life is more than likely to be found on innumerable other worlds.
The anthropic principle states that fundamental laws of the universe work specifically in a way that life would be possible. The anthropic principle supports the Rare Earth Hypothesis by arguing the overall elements that are needed to support life on Earth are so fine-tuned that it is nearly impossible for another just like it to exist by random chance (note that these terms are used by scientists in a different way from the vernacular conception of them).
Research.
The systematic search for possible life outside Earth is a valid multidisciplinary scientific endeavor. However, hypotheses and predictions as to its existence and origin vary widely, and at the present, the development of hypotheses firmly grounded on science may be considered astrobiology's most concrete practical application. It has been proposed that viruses are likely to be encountered on other life-bearing planets.
Research outcomes.
, no evidence of extraterrestrial life has been identified. Examination of the Allan Hills 84001 meteorite, which was recovered in Antarctica in 1984 and originated from Mars, is thought by David McKay, as well as few other scientists, to contain microfossils of extraterrestrial origin; this interpretation is controversial.
Yamato 000593 is the second largest meteorite from Mars, and was found on Earth in 2000. At a microscopic level, spheres are found in the meteorite that are rich in carbon compared to surrounding areas that lack such spheres. The carbon-rich spheres may have been formed by biotic activity according to some NASA scientists.
On 5 March 2011, Richard B. Hoover, a scientist with the Marshall Space Flight Center, speculated on the finding of alleged microfossils similar to cyanobacteria in CI1 carbonaceous meteorites. However, NASA formally distanced itself from Hoover's claim. According to American astrophysicist Neil deGrasse Tyson: "At the moment, life on Earth is the only known life in the universe, but there are compelling arguments to suggest we are not alone."
On 17 March 2013, researchers reported that microbial life forms thrive in the Mariana Trench, the deepest spot on the Earth. Other researchers reported related studies that microbes thrive inside rocks up to 1900 feet below the sea floor under 8500 feet of ocean off the coast of the northwestern United States. According to one of the researchers, "You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are." These finds expand the potential habitability of certain niches of other planets.
In 2004, the spectral signature of methane () was detected in the Martian atmosphere by both Earth-based telescopes as well as by the Mars Express orbiter. Because of solar radiation and cosmic radiation, methane is predicted to disappear from the Martian atmosphere within several years, so the gas must be actively replenished in order to maintain the present concentration. The "Curiosity" rover will perform precision measurements of oxygen and carbon isotope ratios in carbon dioxide (CO) and methane (CH) in the atmosphere of Mars in order to distinguish between a geochemical and a biological origin.
It is possible that some exoplanets may have moons with solid surfaces or liquid oceans that are hospitable. Most of the planets so far discovered outside the Solar System are hot gas giants thought to be inhospitable to life, so it is not yet known whether the Solar System, with a warm, rocky, metal-rich inner planet such as Earth, is of an aberrant composition. Improved detection methods and increased observing time will undoubtedly discover more planetary systems, and possibly some more like ours. For example, NASA's Kepler Mission seeks to discover Earth-sized planets around other stars by measuring minute changes in the star's light curve as the planet passes between the star and the spacecraft. Progress in infrared astronomy and submillimeter astronomy has revealed the constituents of other star systems.
Efforts to answer questions such as the abundance of potentially habitable planets in habitable zones and chemical precursors have had much success. Numerous extrasolar planets have been detected using the wobble method and transit method, showing that planets around other stars are more numerous than previously postulated. The first Earth-sized extrasolar planet to be discovered within its star's habitable zone is Gliese 581 c.
Missions.
Research into the environmental limits of life and the workings of extreme ecosystems is ongoing, enabling researchers to better predict what planetary environments might be most likely to harbor life. Missions such as the Phoenix lander, Mars Science Laboratory, ExoMars, Mars 2020 rover to Mars, and the "Cassini" probe to Saturn's moons aim to further explore the possibilities of life on other planets in the Solar System.
Viking program.
The two Viking landers each carried four types of biological experiments to the surface of Mars in the late 1970s. These were the only Mars landers to carry out experiments to look specifically for metabolism by current microbial life on Mars. The landers used a robotic arm to collect soil samples into sealed test containers on the craft. The two landers were identical, so the same tests were carried out at two places on Mars' surface; Viking 1 near the equator and Viking 2 further north. The result was inconclusive, and is still disputed by some scientists.
Beagle 2.
"Beagle 2" was an unsuccessful British Mars lander that formed part of the European Space Agency's 2003 Mars Express mission. Its primary purpose was to search for signs of life on Mars, past or present. Although it landed safely, it was unable to correctly deploy its solar panels and telecom antenna.
EXPOSE.
EXPOSE is a multi-user facility mounted in 2008 outside the International Space Station dedicated to astrobiology. EXPOSE was developed by the European Space Agency (ESA) for long-term spaceflights that allows to expose organic chemicals and biological samples to outer space in low Earth orbit.
Mars Science Laboratory.
The Mars Science Laboratory (MSL) mission landed a rover that is currently in operation on Mars. It was launched 26 November 2011, and landed at Gale Crater on 6 August 2012. Mission objectives are to help assess Mars' habitability and in doing so, determine whether Mars is or has ever been able to support life, collect data for a future human mission, study Martian geology, its climate, and further assess the role that water, an essential ingredient for life as we know it, played in forming minerals on Mars.
ExoMars.
ExoMars is a robotic mission to Mars to search for possible biosignatures of Martian life, past or present. This astrobiological mission is currently under development by the European Space Agency (ESA) in partnership with the Russian Federal Space Agency (Roscosmos); it is planned for a 2018 launch.
Mars 2020.
The 'Mars 2020' rover mission is a concept under development by NASA with a possible launch in 2020. It is intended to investigate environments on Mars relevant to astrobiology, investigate its surface geological processes and history, including the assessment of its past habitability and potential for preservation of biosignatures and biomolecules within accessible geological materials. The Science Definition Team is proposing the rover collect and package at least 31 samples of rock cores and soil for a later mission to bring back for more definitive analysis in laboratories on Earth. The rover could make measurements and technology demonstrations to help designers of a human expedition understand any hazards posed by Martian dust and demonstrate how to collect carbon dioxide (CO), which could be a resource for making molecular oxygen (O) and rocket fuel.
Proposed concepts.
Red Dragon.
Red Dragon is a proposed concept for a low-cost Mars lander mission that would utilize the SpaceX Falcon Heavy launch vehicle, and a modified Dragon capsule to enter the Martian atmosphere. The lander's primary mission would be a technology demonstration, and to search for evidence of life on Mars (biosignatures), past or present. The concept had been scheduled to be propose for funding on 2012/2013 as a NASA Discovery mission, for launch in 2018.
Icebreaker Life.
"Icebreaker Life" is a lander mission that is being proposed for NASA's Discovery Program for the 2018 launch opportunity. If selected and funded, the stationary lander would be a near copy of the successful 2008 "Phoenix" and it would carry an upgraded astrobiology scientific payload, including a 1-meter-long core drill to sample ice-cemented ground in the northern plains to conduct a search for organic molecules and evidence of current or past life on Mars. One of the key goals of the "Icebreaker Life" mission is to test the hypothesis that the ice-rich ground in the polar regions has significant concentrations of organics due to protection by the ice from oxidants and radiation.
Journey to Enceladus and Titan.
Journey to Enceladus and Titan (JET) is an orbiter astrobiology mission concept to assess the habitability potential of Saturn's moons Enceladus and Titan.
Enceladus Life Finder.
Enceladus Life Finder (ELF) is a proposed astrobiology mission concept for a space probe intended to assess the habitability of the internal aquatic ocean of Enceladus, Saturn's sixth-largest moon.
Life Investigation For Enceladus.
Life Investigation For Enceladus (LIFE) is a proposed astrobiology sample-return mission concept for Enceladus. The spacecraft would enter into Saturn orbit and enable multiple flybys through Enceladus' icy plumes to collect icy plume particles and volatiles and return them to Earth on a capsule. The spacecraft may sample Enceladus' plumes, the E ring of Saturn, and the Titan upper atmosphere.
Europa Multiple-Flyby Mission.
Europa Multiple-Flyby Mission is a mission planned by NASA for a 2025 launch that will conduct detailed reconnaissance of Jupiter's moon Europa and will investigate whether the icy moon could harbor conditions suitable for life. It will also aid in the selection of future landing sites.

</doc>
<doc id="2790" url="https://en.wikipedia.org/wiki?curid=2790" title="Air show">
Air show

An air show, (also airshow, Air Fair, or Air Tattoo) is a public event at which aviators display their flying skills and the capabilities of their aircraft to spectators, usually by means of aerobatics. Air shows without aerobatic displays, having only aircraft displayed parked on the ground, are called "static air shows".
Outline.
Some air shows are held as a business venture or as a trade event where aircraft, avionics and other services are promoted to potential customers. Many air shows are held in support of local, national or military charities. Military air firms often organise air shows at military airfields as a public relations exercise to thank the local community, promote military careers and raise the profile of the military.
Air show "seasons" vary around the world. The United States enjoys a long season that generally runs from March to November, covering the spring, summer, and fall seasons. Other countries often have much shorter seasons. The European season usually starts in late April or Early May and is usually over by mid October. The Middle East, Australia and New Zealand hold their events between January and March. However, for many acts, the "off-season" does not mean a period of inactivity; they use this time for maintenance and practice.
The type of displays seen at an event are constrained by a number of factors, including the weather and visibility. Most aviation authorities now publish rules and guidance on minimum display heights and criteria for differing conditions. In addition to the weather, pilots and organizers must also consider local airspace restrictions. Most exhibitors will plan "full," "rolling" and "flat" display for varying weather and airspace conditions.
The types of shows vary greatly. Some are large scale military events with large flying displays and ground exhibitions while others held at small local airstrips can often feature just one or two hours of flying with just a few stalls on the ground. Air Displays can be held during day or night with the latter becoming increasingly popular. Shows don't always take place over airfields; some have been held over the grounds of stately homes or castles and over the sea at coastal resorts.
Attractions.
Before the Second World War, air shows were associated with long distance air races, often lasting many days and covering thousands of miles. While the Reno Air Races keep this tradition alive, most air shows today primarily feature a series of aerial demos of short duration.
Most air shows feature warbirds, aerobatics, and demonstrations of modern military aircraft, and many air shows offer a variety of other aeronautical attractions as well, such as wing-walking, radio-controlled aircraft, water/slurry drops from firefighting aircraft, simulated helicopter rescues and sky diving.
Specialist aerobatic aircraft have powerful piston engines, light weight and big control surfaces, making them capable of very high roll rates and accelerations. A skilled pilot will be able to climb vertically, perform very tight turns, tumble his aircraft end-over-end and perform manoeuvres during loops.
Solo military jet demos, also known as tactical demo, feature one aircraft, usually a strike fighter or an advanced trainer. The demonstration focuses on the capabilities of modern aircraft used in combat operations. The display will usually demonstrate the aircraft's very short (and often very loud) takeoff rolls, fast speeds, slow approach speeds, as well as their ability to quickly make tight turns, to climb quickly, and their ability to be precisely controlled at a large range of speeds. Manoeuvres include aileron rolls, barrel rolls, hesitation rolls, Cuban-8s, tight turns, high-alpha flight, a high-speed pass, double Immelmans, and touch-and-gos. Tactical demos may include simulated bomb drops, sometimes with pyrotechnics on the ground for effect. Aircraft with special characteristics that give them unique capabilities will often display those in their demos; For example, Russian fighters with Thrust vectoring may be used to perform Pugachev's Cobra or the Kulbit, among other difficult manoeuvers that cannot be performed by other aircraft. Similarly, an F-22 pilot may hover his jet in the air with the nose pointed straight up, a Harrier or Osprey pilot may perform a vertical landing or vertical takeoff, and so on.
Safety.
Air shows may present some risk to spectators and aviators. Accidents have occurred, sometimes with a large loss of life, such as the 1988 disaster at Ramstein Air Base in Germany and the 2002 air show crash at Lviv, Ukraine. Because of these accidents, the various aviation authorities around the world have created set rules and guidance for those running and participating in air displays. Air displays are often monitored by aviation authorities to ensure safe procedures.
In the United Kingdom, local authorities will first need to approve any application for an event to which the public is admitted. No approval, no event. The first priority must be to arrange insurance cover and details can be obtained from your local authority. An added complication is a whole new raft of legislation concerning Health & Safety in particular Corporate Manslaughter, which can involve the event organiser being charged with a criminal offence if any of the insurances and risk assessments are not fully completed well in advance of the event. If this very basic step isn't completed then any further activity should be halted until it is.
Rules govern the distance from the crowds that aircraft must fly. These vary according to the rating of the pilot/crew, the type of aircraft and the way the aircraft is being flown. For instance, slower lighter aircraft are usually allowed closer and lower to the crowd than larger, faster types. Also, a fighter jet flying straight and level will be able to do so closer to the crowd and lower than if it were performing a roll or a loop.
Pilots can get authorizations for differing types of displays (i.e. limbo flying, basic aerobatics to unlimited aerobatics) and to differing minimum base heights above the ground. To gain such authorizations, the pilots will have to demonstrate to an examiner that they can perform to those limits without endangering themselves, ground crew or spectators.
Despite display rules and guidances, accidents have continued to happen. However, air show accidents are rare and where there is proper supervision air shows have impressive safety records. Each year, organisations such as International Council of Air Shows and European Airshow Council meet and discuss various subjects including air show safety where accidents are discussed and lessons learnt.

</doc>
<doc id="2792" url="https://en.wikipedia.org/wiki?curid=2792" title="Anthropic principle">
Anthropic principle

The anthropic principle () is the philosophical consideration that observations of the universe must be compatible with the conscious and sapient life that observes it. Some proponents of the anthropic principle reason that it explains why the universe has the age and the fundamental physical constants necessary to accommodate conscious life. As a result, they believe it is unremarkable that the universe's fundamental constants happen to fall within the narrow range thought to be compatible with life.
The strong anthropic principle (SAP) as explained by John D. Barrow and Frank Tipler states that this is all the case because the universe is compelled to eventually have conscious and sapient life emerge within it. Some critics of the SAP argue in favor of a weak anthropic principle (WAP) similar to the one defined by Brandon Carter, which states that the universe's ostensible fine tuning is the result of selection bias: i.e., only in a universe capable of eventually supporting life will there be living beings capable of observing and reflecting upon fine tuning. Most often such arguments draw upon some notion of the multiverse for there to be a statistical population of universes to select from and from which selection bias (our observance of "only" this universe, compatible with life) could occur.
Definition and basis.
The principle was formulated as a response to a series of observations that the laws of nature and parameters of the universe take on values that are consistent with conditions for life as we know it rather than a set of values that would not be consistent with life on Earth. The anthropic principle states that this is a necessity, because if life were impossible, no living entity would be there to observe it, and thus would not be known. That is, it must be possible to observe "some" universe, and hence, the laws and constants of any such universe must accommodate that possibility.
The term "anthropic" in "anthropic principle" has been argued to be a misnomer. While singling out our kind of carbon-based life, none of the finely tuned phenomena require human life or some kind of carbon chauvinism. Any form of life or any form of heavy atom, stone, star or galaxy would do; nothing specifically human or anthropic is involved.
The anthropic principle has given rise to some confusion and controversy, partly because the phrase has been applied to several distinct ideas. All versions of the principle have been accused of discouraging the search for a deeper physical understanding of the universe. The anthropic principle is often criticized for lacking falsifiability and therefore critics of the anthropic principle may point out that the anthropic principle is a non-scientific concept, even though the weak anthropic principle, ""conditions that are observed in the universe must allow the observer to exist"," is "easy" to support in mathematics and philosophy, i.e. it is a tautology or truism. However, building a substantive argument based on a tautological foundation is problematic. Stronger variants of the anthropic principle are not tautologies and thus make claims considered controversial by some and that are contingent upon empirical verification.
Anthropic coincidences.
In 1961, Robert Dicke noted that the age of the universe, as seen by living observers, cannot be random. Instead, biological factors constrain the universe to be more or less in a "golden age," neither too young nor too old. If the universe were one tenth as old as its present age, there would not have been sufficient time to build up appreciable levels of
metallicity (levels of elements besides hydrogen and helium) especially carbon, by nucleosynthesis. Small rocky planets did not yet exist. If the universe were 10 times older than it actually is, most stars would be too old to remain on the main sequence and would have turned into white dwarfs, aside from the dimmest red dwarfs, and stable planetary systems would have already come to an end. Thus, Dicke explained the coincidence between large dimensionless numbers constructed from the constants of physics and the age of the universe, a coincidence which had inspired Dirac's varying-G theory.
Dicke later reasoned that the density of matter in the universe must be almost exactly the critical density needed to prevent the Big Crunch (the "Dicke coincidences" argument). The most recent measurements may suggest that the observed density of baryonic matter, and some theoretical predictions of the amount of dark matter account for about 30% of this critical density, with the rest contributed by a cosmological constant. Steven Weinberg gave an anthropic explanation for this fact: he noted that the cosmological constant has a remarkably low value, some 120 orders of magnitude smaller than the value particle physics predicts (this has been described as the "worst prediction in physics"). However, if the cosmological constant were only one order of magnitude larger than its observed value, the universe would suffer catastrophic inflation, which would preclude the formation of stars, and hence life.
The observed values of the dimensionless physical constants (such as the fine-structure constant) governing the four fundamental interactions are balanced as if fine-tuned to permit the formation of commonly found matter and subsequently the emergence of life. A slight increase in the strong interaction would bind the dineutron and the diproton, and nuclear fusion would have converted all hydrogen in the early universe to helium. Water, as well as sufficiently long-lived stable stars, both essential for the emergence of life as we know it, would not exist. More generally, small changes in the relative strengths of the four fundamental interactions can greatly affect the universe's age, structure, and capacity for life.
Origin.
The phrase "anthropic principle" first appeared in Brandon Carter's contribution to a 1973 Kraków symposium honouring Copernicus's 500th birthday. Carter, a theoretical astrophysicist, articulated the Anthropic Principle in reaction to the Copernican Principle, which states that humans do not occupy a privileged position in the Universe. As Carter said: "Although our situation is not necessarily "central", it is inevitably privileged to some extent." Specifically, Carter disagreed with using the Copernican principle to justify the Perfect Cosmological Principle, which states that all large regions "and times" in the universe must be statistically identical. The latter principle underlay the steady-state theory, which had recently been falsified by the 1965 discovery of the cosmic microwave background radiation. This discovery was unequivocal evidence that the universe has changed radically over time (for example, via the Big Bang).
Carter defined two forms of the anthropic principle, a "weak" one which referred only to anthropic selection of privileged spacetime locations in the universe, and a more controversial "strong" form which addressed the values of the fundamental constants of physics.
Roger Penrose explained the weak form as follows:
One reason this is plausible is that there are many other places and times in which we can imagine finding ourselves. But when applying the strong principle, we only have one universe, with one set of fundamental parameters, so what exactly is the point being made? Carter offers two possibilities: First, we can use our own existence to make "predictions" about the parameters. But second, "as a last resort", we can convert these predictions into "explanations" by assuming that there "is" more than one universe, in fact a large and possibly infinite collection of universes, something that is now called the multiverse ("world ensemble" was Carter's term), in which the parameters (and perhaps the laws of physics) vary across universes. The strong principle then becomes an example of a selection effect, exactly analogous to the weak principle. Postulating a multiverse is certainly a radical step, but taking it could provide at least a partial answer to a question which had seemed to be out of the reach of normal science: "why do the fundamental laws of physics take the particular form we observe and not another?"
Since Carter's 1973 paper, the term "anthropic principle" has been extended to cover a number of ideas which differ in important ways from those he espoused. Particular confusion was caused in 1986 by the book "The Anthropic Cosmological Principle" by John D. Barrow and Frank Tipler, published that year which distinguished between "weak" and "strong" anthropic principle in a way very different from Carter's, as discussed in the next section.
Carter was not the first to invoke some form of the anthropic principle. In fact, the evolutionary biologist Alfred Russel Wallace anticipated the anthropic principle as long ago as 1904: "Such a vast and complex universe as that which we know exists around us, may have been absolutely required ... in order to produce a world that should be precisely adapted in every detail for the orderly development of life culminating in man." In 1957, Robert Dicke wrote: "The age of the Universe 'now' is not random but conditioned by biological factors ... hanges in the values of the fundamental constants of physic would preclude the existence of man to consider the problem."
Variants.
Weak anthropic principle (WAP) (Carter): "we must be prepared to take account of the fact that our location in the universe is "necessarily" privileged to the extent of being compatible with our existence as observers." Note that for Carter, "location" refers to our location in time as well as space.
Strong anthropic principle (SAP) (Carter): "the universe (and hence the fundamental parameters on which it depends) must be such as to admit the creation of observers within it at some stage. To paraphrase Descartes, "cogito ergo mundus talis est"."<br>The Latin tag ("I think, therefore the world is such s it i") makes it clear that "must" indicates a deduction from the fact of our existence; the statement is thus a truism.
In their 1986 book, "The Anthropic Cosmological Principle", John Barrow and Frank Tipler depart from Carter and define the WAP and SAP as follows:
Weak anthropic principle (WAP) (Barrow and Tipler): "The observed values of all physical and cosmological quantities are not equally probable but they take on values restricted by the requirement that there exist sites where carbon-based life can evolve and by the requirements that the universe be old enough for it to have already done so."<br>Unlike Carter they restrict the principle to carbon-based life, rather than just "observers." A more important difference is that they apply the WAP to the fundamental physical constants, such as the fine structure constant, the number of spacetime dimensions, and the cosmological constant — topics that fall under Carter's SAP.
Strong anthropic principle (SAP) (Barrow and Tipler): "The Universe must have those properties which allow life to develop within it at some stage in its history."<br>This looks very similar to Carter's SAP, but unlike the case with Carter's SAP, the "must" is an imperative, as shown by the following three possible elaborations of the SAP, each proposed by Barrow and Tipler:
Modified anthropic principle (MAP) (Schmidhuber): The 'problem' of existence is only relevant to a species capable of formulating the question. Prior to "Homo sapiens" intellectual evolution to the point where the nature of the observed universe - and humans' place within same - spawned deep inquiry into its origins, the 'problem' simply did not exist.
The philosophers John Leslie and Nick Bostrom reject the Barrow and Tipler SAP as a fundamental misreading of Carter. For Bostrom, Carter's anthropic principle just warns us to make allowance for anthropic bias, that is, the bias created by anthropic selection effects (which Bostrom calls "observation" selection effects) — the necessity for observers to exist in order to get a result. He writes:
Strong self-sampling assumption (SSSA) (Bostrom): "Each observer-moment should reason as if it were randomly selected from the class of all observer-moments in its reference class."<br> Analysing an observer's experience into a sequence of "observer-moments" helps avoid certain paradoxes; but the main ambiguity is the selection of the appropriate "reference class": for Carter's WAP this might correspond to all real or potential observer-moments in our universe; for the SAP, to all in the multiverse. Bostrom's mathematical development shows that choosing either too broad or too narrow a reference class leads to counter-intuitive results, but he is not able to prescribe an ideal choice.
According to Jürgen Schmidhuber, the anthropic principle essentially just says that the conditional probability of finding yourself in a universe compatible with your existence is always 1. It does not allow for any additional nontrivial predictions such as "gravity won't change tomorrow." To gain more predictive power, additional assumptions on the prior distribution of alternative universes are necessary.
Playwright and novelist Michael Frayn describes a form of the Strong Anthropic Principle in his 2006 book "The Human Touch", which explores what he characterises as "the central oddity of the Universe":
Character of anthropic reasoning.
Carter chose to focus on a tautological aspect of his ideas, which has resulted in much confusion. In fact, anthropic reasoning interests scientists because of something that is only implicit in the above formal definitions, namely that we should give serious consideration to there being other universes with different values of the "fundamental parameters" — that is, the dimensionless physical constants and initial conditions for the Big Bang. Carter and others have argued that life as we know it would not be possible in most such universes. In other words, the universe we are in is fine tuned to permit life. Collins & Hawking (1973) characterized Carter's then-unpublished big idea as the postulate that "there is not one universe but a whole infinite ensemble of universes with all possible initial conditions". If this is granted, the anthropic principle provides a plausible explanation for the fine tuning of our universe: the "typical" universe is not fine-tuned, but given enough universes, a small fraction thereof will be capable of supporting intelligent life. Ours must be one of these, and so the observed fine tuning should be no cause for wonder.
Although philosophers have discussed related concepts for centuries, in the early 1970s the only genuine physical theory yielding a multiverse of sorts was the many-worlds interpretation of quantum mechanics. This would allow variation in initial conditions, but not in the truly fundamental constants. Since that time a number of mechanisms for producing a multiverse have been suggested: see the review by Max Tegmark. An important development in the 1980s was the combination of inflation theory with the hypothesis that some parameters are determined by symmetry breaking in the early universe, which allows parameters previously thought of as "fundamental constants" to vary over very large distances, thus eroding the distinction between Carter's weak and strong principles. At the beginning of the 21st century, the string landscape emerged as a mechanism for varying essentially all the constants, including the number of spatial dimensions.
The anthropic idea that fundamental parameters are selected from a multitude of different possibilities (each actual in some universe or other) contrasts with the traditional hope of physicists for a theory of everything having no free parameters: as Einstein said, "What really interests me is whether God had any choice in the creation of the world." In 2002, proponents of the leading candidate for a "theory of everything", string theory, proclaimed "the end of the anthropic principle" since there would be no free parameters to select. Ironically, string theory now seems to offer no hope of predicting fundamental parameters, and now some who advocate it invoke the anthropic principle as well (see below).
The modern form of a design argument is put forth by Intelligent design. Proponents of intelligent design often cite the fine-tuning observations that (in part) preceded the formulation of the anthropic principle by Carter as a proof of an intelligent designer. Opponents of intelligent design are not limited to those who hypothesize that other universes exist; they may also argue, anti-anthropically, that the universe is less fine-tuned than often claimed, or that accepting fine tuning as a brute fact is less astonishing than the idea of an intelligent creator. Furthermore, even accepting fine tuning, Sober (2005) and Ikeda and Jefferys, argue that the Anthropic Principle as conventionally stated actually undermines intelligent design; see fine-tuned universe.
Paul Davies's book "The Goldilocks Enigma" (2006) reviews the current state of the fine tuning debate in detail, and concludes by enumerating the following responses to that debate:
Omitted here is Lee Smolin's model of cosmological natural selection, also known as "fecund universes," which proposes that universes have "offspring" which are more plentiful if they resemble our universe. Also see Gardner (2005).
Clearly each of these hypotheses resolve some aspects of the puzzle, while leaving others unanswered. Followers of Carter would admit only option 3 as an anthropic explanation, whereas 3 through 6 are covered by different versions of Barrow and Tipler's SAP (which would also include 7 if it is considered a variant of 4, as in Tipler 1994).
The anthropic principle, at least as Carter conceived it, can be applied on scales much smaller than the whole universe. For example, Carter (1983) inverted the usual line of reasoning and pointed out that when interpreting the evolutionary record, one must take into account cosmological and astrophysical considerations. With this in mind, Carter concluded that given the best estimates of the age of the universe, the evolutionary chain culminating in "Homo sapiens" probably admits only one or two low probability links. Antonio Feoli and Salvatore Rampone dispute this conclusion, arguing instead that the estimated size of our universe and the number of planets in it allows for a higher bound, so that there is no need to invoke intelligent design to explain evolution.
Observational evidence.
No possible observational evidence bears on Carter's WAP, as it is merely advice to the scientist and asserts nothing debatable. The obvious test of Barrow's SAP, which says that the universe is "required" to support life, is to find evidence of life in universes other than ours. Any other universe is, by most definitions, unobservable (otherwise it would be included in "our" portion of "this" universe). Thus, in principle Barrow's SAP cannot be falsified by observing a universe in which an observer cannot exist.
Philosopher John Leslie states that the Carter SAP (with multiverse) predicts the following:
Hogan has emphasised that it would be very strange if all fundamental constants were strictly determined, since this would leave us with no ready explanation for apparent fine tuning. In fact we might have to resort to something akin to Barrow and Tipler's SAP: there would be no option for such a universe "not" to support life.
Probabilistic predictions of parameter values can be made given:
The probability of observing value "X" is then proportional to "N"("X") "P"("X"). A generic feature of an analysis of this nature is that the expected values of the fundamental physical constants should not be "over-tuned," i.e. if there is some perfectly tuned predicted value (e.g. zero), the observed value need be no closer to that predicted value than what is required to make life possible. The small but finite value of the cosmological constant can be regarded as a successful prediction in this sense.
One thing that would "not" count as evidence for the Anthropic Principle is evidence that the Earth or the solar system occupied a privileged position in the universe, in violation of the Copernican principle (for possible counterevidence to this principle, see Copernican principle), unless there was some reason to think that that position was a necessary condition for our existence as observers.
Applications of the principle.
The nucleosynthesis of carbon-12.
Fred Hoyle may have invoked anthropic reasoning to predict an astrophysical phenomenon. He is said to have reasoned from the prevalence on Earth of life forms whose chemistry was based on carbon-12 atoms, that there must be an undiscovered resonance in the carbon-12 nucleus facilitating its synthesis in stellar interiors via the triple-alpha process. He then calculated the energy of this undiscovered resonance to be 7.6 million electron-volts. Willie Fowler's research group soon found this resonance, and its measured energy was close to Hoyle's prediction.
However, a recently released paper argues that Hoyle did not use anthropic reasoning to make this prediction.
Cosmic inflation.
Don Page criticized the entire theory of cosmic inflation as follows. He emphasized that initial conditions which made possible a thermodynamic arrow of time in a universe with a Big Bang origin, must include the assumption that at the initial singularity, the entropy of the universe was low and therefore extremely improbable. Paul Davies rebutted this criticism by invoking an inflationary version of the anthropic principle. While Davies accepted the premise that the initial state of the visible universe (which filled a microscopic amount of space before inflating) had to possess a very low entropy value — due to random quantum fluctuations — to account for the observed thermodynamic arrow of time, he deemed this fact an advantage for the theory. That the tiny patch of space from which our observable universe grew had to be extremely orderly, to allow the post-inflation universe to have an arrow of time, makes it unnecessary to adopt any "ad hoc" hypotheses about the initial entropy state, hypotheses other Big Bang theories require.
String theory.
String theory predicts a large number of possible universes, called the "backgrounds" or "vacua." The set of these vacua is often called the "multiverse" or "anthropic landscape" or "string landscape." Leonard Susskind has argued that the existence of a large number of vacua puts anthropic reasoning on firm ground: only universes whose properties are such as to allow observers to exist are observed, while a possibly much larger set of universes lacking such properties go unnoticed.
Steven Weinberg believes the Anthropic Principle may be appropriated by cosmologists committed to nontheism, and refers to that Principle as a "turning point" in modern science because applying it to the string landscape "...may explain how the constants of nature that we observe can take values suitable for life without being fine-tuned by a benevolent creator." Others, most notably David Gross but also Lubos Motl, Peter Woit, and Lee Smolin, argue that this is not predictive. Max Tegmark, Mario Livio, and Martin Rees argue that only some aspects of a physical theory need be observable and/or testable for the theory to be accepted, and that many well-accepted theories are far from completely testable at present.
Jürgen Schmidhuber (2000–2002) points out that Ray Solomonoff's theory of universal inductive inference and its extensions already provide a framework for maximizing our confidence in any theory, given a limited sequence of physical observations, and some prior distribution on the set of possible explanations of the universe.
Spacetime.
There are two kinds of dimensions, spatial (bidirectional) and temporal (unidirectional). Let the number of spatial dimensions be "N" and the number of temporal dimensions be "T". That "N" = 3 and "T" = 1, setting aside the compactified dimensions invoked by string theory and undetectable to date, can be explained by appealing to the physical consequences of letting "N" differ from 3 and "T" differ from 1. The argument is often of an anthropic character and possibly the first of its kind, albeit before the complete concept came into vogue. Immanuel Kant argued that 3-dimensional space was a consequence of the inverse square law of universal gravitation. While Kant's argument is historically important, John D. Barrow says that it "...gets the punch-line back to front: it is the three-dimensionality of space that explains why we see inverse-square force laws in Nature, not vice-versa." (Barrow 2002: 204). This is because the law of gravitation (or any other inverse-square law) follows from the concept of flux and the proportional relationship of flux density and the strength of field. If "N" = 3, then 3-dimensional solid objects have surface areas proportional to the square of their size in any selected spatial dimension. In particular, a sphere of radius "r" has area of 4π"r" ². More generally, in a space of "N" dimensions, the strength of the gravitational attraction between two bodies separated by a distance of "r" would be inversely proportional to "r".
In 1920, Paul Ehrenfest showed that if there is only one time dimension and greater than three spatial dimensions, the orbit of a planet about its Sun cannot remain stable. The same is true of a star's orbit around the center of its galaxy. Ehrenfest also showed that if there are an even number of spatial dimensions, then the different parts of a wave impulse will travel at different speeds. If there are formula_1 spatial dimensions, where "k" is a whole number, then wave impulses become distorted. In 1922, Hermann Weyl showed that Maxwell's theory of electromagnetism works only with three dimensions of space and one of time. Finally, Tangherlini showed in 1963 that when there are more than three spatial dimensions, electron orbitals around nuclei cannot be stable; electrons would either fall into the nucleus or disperse.
Max Tegmark expands on the preceding argument in the following anthropic manner. If "T" differs from 1, the behavior of physical systems could not be predicted reliably from knowledge of the relevant partial differential equations. In such a universe, intelligent life capable of manipulating technology could not emerge. Moreover, if "T" > 1, Tegmark maintains that protons and electrons would be unstable and could decay into particles having greater mass than themselves. (This is not a problem if the particles have a sufficiently low temperature.)
"The Anthropic Cosmological Principle".
A thorough extant study of the anthropic principle is the book "The Anthropic Cosmological Principle" by John D. Barrow, a cosmologist, and Frank J. Tipler, a cosmologist and mathematical physicist. This book sets out in detail the many known anthropic coincidences and constraints, including many found by its authors. While the book is primarily a work of theoretical astrophysics, it also touches on quantum physics, chemistry, and earth science. An entire chapter argues that "Homo sapiens" is, with high probability, the only intelligent species in the Milky Way.
The book begins with an extensive review of many topics in the history of ideas the authors deem relevant to the anthropic principle, because the authors believe that principle has important antecedents in the notions of teleology and intelligent design. They discuss the writings of Fichte, Hegel, Bergson, and Alfred North Whitehead, and the Omega Point cosmology of Teilhard de Chardin. Barrow and Tipler carefully distinguish teleological reasoning from "eutaxiological" reasoning; the former asserts that order must have a consequent purpose; the latter asserts more modestly that order must have a planned cause. They attribute this important but nearly always overlooked distinction to an obscure 1883 book by L. E. Hicks.
Seeing little sense in a principle requiring intelligent life to emerge while remaining indifferent to the possibility of its eventual extinction, Barrow and Tipler propose the final anthropic principle (FAP): Intelligent information-processing must come into existence in the universe, and, once it comes into existence, it will never die out.
Barrow and Tipler submit that the FAP is both a valid physical statement and "closely connected with moral values." FAP places strong constraints on the structure of the universe, constraints developed further in Tipler's "The Physics of Immortality". One such constraint is that the universe must end in a big crunch, which seems unlikely in view of the tentative conclusions drawn since 1998 about dark energy, based on observations of very distant supernovas.
In his review of Barrow and Tipler, Martin Gardner ridiculed the FAP by quoting the last two sentences of their book as defining a Completely Ridiculous Anthropic Principle (CRAP):
Criticisms.
Carter has frequently regretted his own choice of the word "anthropic," because it conveys the misleading impression that the principle involves humans specifically, rather than intelligent observers in general. Others have criticised the word "principle" as being too grandiose to describe straightforward applications of selection effects.
A common criticism of Carter's SAP is that it is an easy deus ex machina which discourages searches for physical explanations. To quote Penrose again: "it tends to be invoked by theorists whenever they do not have a good enough theory to explain the observed facts."
Carter's SAP and Barrow and Tipler's WAP have been dismissed as truisms or trivial tautologies, that is, statements true solely by virtue of their logical form (the conclusion is identical to the premise) and not because a substantive claim is made and supported by observation of reality. As such, they are criticized as an elaborate way of saying "if things were different, they would be different," which is a valid statement, but does not make a claim of some factual alternative over another.
Critics of the Barrow and Tipler SAP claim that it is neither testable nor falsifiable, and thus is not a scientific statement but rather a philosophical one. The same criticism has been leveled against the hypothesis of a multiverse, although some argue that it does make falsifiable predictions. A modified version of this criticism is that we understand so little about the emergence of life, especially intelligent life, that it is effectively impossible to calculate the number of observers in each universe. Also, the prior distribution of universes as a function of the fundamental constants is easily modified to get any desired result.
Many criticisms focus on versions of the strong anthropic principle, such as Barrow and Tipler's "anthropic cosmological principle", which are teleological notions that tend to describe the existence of life as a "necessary prerequisite" for the observable constants of physics. Similarly, Stephen Jay Gould, Michael Shermer, and others claim that the stronger versions of the anthropic principle seem to reverse known causes and effects. Gould compared the claim that the universe is fine-tuned for the benefit of our kind of life to saying that sausages were made long and narrow so that they could fit into modern hotdog buns, or saying that ships had been invented to house barnacles. These critics cite the vast physical, fossil, genetic, and other biological evidence consistent with life having been fine-tuned through natural selection to adapt to the physical and geophysical environment in which life exists. Life appears to have adapted to the universe, and not vice versa.
Some applications of the anthropic principle have been criticized as an argument by lack of imagination, for tacitly assuming that carbon compounds and water are the only possible chemistry of life (sometimes called "carbon chauvinism", see also alternative biochemistry). The range of fundamental physical constants consistent with the evolution of carbon-based life may also be wider than those who advocate a fine tuned universe have argued. For instance, Harnik et al. propose a weakless universe in which the weak nuclear force is eliminated. They show that this has no significant effect on the other fundamental interactions, provided some adjustments are made in how those interactions work. However, if some of the fine-tuned details of our universe were violated, that would rule out complex structures of any kind — stars, planets, galaxies, etc.
Lee Smolin has offered a theory designed to improve on the lack of imagination that anthropic principles have been accused of. He puts forth his fecund universes theory, which assumes universes have "offspring" through the creation of black holes whose offspring universes have values of physical constants that depend on those of the mother universe.
Some versions of the anthropic principle are only interesting if the range of physical constants that allow certain kinds of life are unlikely in a landscape of possible universes. But Lee Smolin assumes that conditions for carbon based life are similar to conditions for black hole creation, which would change the a priori distribution of universes such that universes containing life would be likely. In Smolin vs. Susskind: The Anthropic Principle the string theorist Leonard Susskind disagrees about some assumptions in Lee Smolin's theory, while Smolin defends his theory.
The philosophers of cosmology John Earman, Ernan McMullin, and Jesús Mosterín contend that "in its weak version, the anthropic principle is a mere tautology, which does not allow us to explain anything or to predict anything that we did not already know. In its strong version, it is a gratuitous speculation". A further criticism by Mosterín concerns the flawed "anthropic" inference from the assumption of an infinity of worlds to the existence of one like ours:

</doc>
<doc id="2795" url="https://en.wikipedia.org/wiki?curid=2795" title="Australian Army">
Australian Army

The Australian Army is Australia's military land force. It is part of the Australian Defence Force (ADF) along with the Royal Australian Navy and the Royal Australian Air Force. While the Chief of the Defence Force (CDF) commands the ADF, the Army is commanded by the Chief of Army (CA). The CA is therefore subordinate to the CDF, but is also directly responsible to the Minister for Defence. Although Australian soldiers have been involved in a number of minor and major conflicts throughout its history, only in World War II has Australian territory come under direct attack.
History.
The history of the Australian Army can be divided into two periods:
During its history the Australian Army has fought in a number of major wars, including: Second Boer War (1899–1902), First World War (1914–18), the Second World War (1939–45), Korea War (1950–53), Malayan Emergency (1950–60), Indonesia-Malaysia Confrontation (1962–66), Vietnam War (1962–73), and more recently in Afghanistan (2001 – present) and Iraq (2003–2009). Since 1947 the Australian Army has also been involved in many peacekeeping operations, usually under the auspices of the United Nations, however the non United Nations sponsored Multinational Force and Observers in the Sinai is a notable exception. Australia's largest peacekeeping deployment began in 1999 in East Timor, while other ongoing operations include peacekeeping on Bougainville, in the Sinai, and in the Solomon Islands. Humanitarian relief after 2004 Indian Ocean earthquake in Aceh Province, Indonesia, Operation Sumatra Assist, ended on 24 March 2005.
Current organisation.
The 1st Division comprises a deployable headquarters, while 2nd Division under the command of Forces Command is the main home-defence formation, containing Army Reserve units. 2nd Division's headquarters only performs administrative functions. The Australian Army has not deployed a divisional-sized formation since 1945 and does not expect to do so in the future.
1st Division.
1st Division carries out high-level training activities and deploys to command large-scale ground operations. It does not have any combat units permanently assigned.
Forces Command.
Forces Command controls for administrative purposes all non-special-forces assets of the Australian Army. It is neither an operational nor a deployable command.
Additionally, Forces Command includes the following training establishments:
Special Forces.
Special Operations Command comprises a command formation of equal status to the other commands in the ADF. It is a brigade-sized formation responsible for all of Australia's special-forces assets.
Planned restructuring.
Under a restructuring program known as Plan Beersheba announced in late 2011, the 1st, 3rd and 7th Brigades will be re-formed as combined-arms multi-role manoeuvre brigades with the 2nd Battalion, Royal Australian Regiment (part of the 3rd Brigade) forming the core of a future amphibious force The force will be known as an Amphibious Ready Element and will utilise the former Royal Navy 16,000-tonne auxiliary Bay class landing ship RFA "Largs Bay" (L3006), bought for $100 million to become HMAS "Choules".
Colours, standards and guidons.
Infantry, and some other combat units of the Australian Army carry flags called the Queen's Colour and the Regimental Colour, known as "the Colours". Armoured units carry Standards and Guidons – flags smaller than Colours and traditionally carried by Cavalry, Lancer, Light Horse and Mounted Infantry units. The 1st Armoured Regiment is the only unit in the Australian Army to carry a Standard, in the tradition of heavy armoured units. Artillery units' guns are considered to be their Colours, and on parade are provided with the same respect. Non-combat units (combat service support corps) do not have Colours, as Colours are battle flags and so are only available to combat units. As a substitute, many have Standards or Banners. Units awarded battle honours have them emblazoned on their Colours, Standards and Guidons. They are a link to the unit's past and a memorial to the fallen. Artillery do not have Battle Honours – their single Honour is "Ubique" which means "Everywhere" – although they can receive Honour Titles.
The Army is the guardian of the National Flag and as such, unlike the Royal Australian Air Force, does not have a flag or Colours. The Army, instead, has a banner, known as the Army Banner. To commemorate the centenary of the Army, the Governor General Sir William Deane, presented the Army with a new Banner at a parade in front of the Australian War Memorial on 10 March 2001. The Banner was presented to the Regimental Sergeant Major of the Army (RSM-A), Warrant Officer Peter Rosemond.
The Army Banner bears the Australian Coat of Arms on the obverse, with the dates "1901–2001" in gold in the upper hoist. The reverse bears the "rising sun" badge of the Australian Army, flanked by seven campaign honours on small gold-edged scrolls: South Africa, World War I, World War II, Korea, Malaya-Borneo, South Vietnam, and Peacekeeping. The banner is trimmed with gold fringe, has gold and crimson cords and tassels, and is mounted on a pike with the usual British royal crest finial.
Personnel.
Strength.
In the 2014–15 financial year the Army had an average strength of 43,667 personnel: 29,366 permanent (regular) and 14,301 active reservists (part-time). In addition, there are another 12,496 members of the Standby Reserve. The regular Army is targeted to expand to 30,464 (regular) and 15,250 (part-time) personnel by 2015–16. Personnel numbers have trended upwards since a peak in 2010–11 with an actual strength of 29,366 full-time personnel. Army Reserve numbers are 14,301, which does not include Standby Reserves. This gives the Army a combined strength of 43,667 active personnel for the year 2014-15.
Rank and insignia.
The ranks of the Australian Army are based on the ranks of the British Army, and carry mostly the same actual insignia. For officers the ranks are identical except for the shoulder title "Australia". The Non-Commissioned Officer insignia are the same up until Warrant Officer, where they are stylised for Australia (for example, using the Australian, rather than the British coat of arms).
The ranks of the Australian Army are as follows:
Bases.
The Army's operational headquarters, Forces Command, is located at Victoria Barracks in Sydney. The Australian Army's three regular brigades are based at Robertson Barracks near Darwin, Lavarack Barracks in Townsville and Gallipoli Barracks in Brisbane. The Deployable Joint Force Headquarters is also located at Gallipoli Barracks.
Other important Army bases include the Army Aviation Centre near Oakey, Queensland, Holsworthy Barracks near Sydney, Lone Pine Barracks in Singleton, New South Wales and Woodside Barracks near Adelaide, South Australia. The SASR is based at Campbell Barracks Swanbourne, a suburb of Perth, Western Australia.
Puckapunyal north of Melbourne houses the Australian Army's Combined Arms Training Centre, Land Warfare Development Centre, and three of the five principal Combat Arms schools. Further barracks include Steele Barracks in Sydney, Keswick Barracks in Adelaide, and Irwin Barracks at Karrakatta in Perth. Dozens of Australian Army Reserve depots are located across Australia.
Australian Army Journal.
Since 1948, the Australian Army has published its own journal titled the "Australian Army Journal". Covering a broad range of topics including essays, book reviews and editorials, with submissions from serving members as well as professional authors, the journal's stated goal is to provide "...the primary forum for Army's professional discourse... nd to facilitat... debate within the Australian Army ...nd rais ...the quality and intellectual rigor of that debate by adhering to a strict and demanding standard of quality". In 1976, the journal was placed on hiatus; however, publishing began again in 1999 and since then the journal has been published largely on a quarterly basis, with only minimal interruptions.
Future Procurement.
This list includes equipment currently on order or a requirement which has been identified:

</doc>
<doc id="2799" url="https://en.wikipedia.org/wiki?curid=2799" title="American Registry for Internet Numbers">
American Registry for Internet Numbers

The American Registry for Internet Numbers (ARIN) is the Regional Internet Registry (RIR) for Canada, the United States, and many Caribbean and North Atlantic islands. ARIN manages the distribution of Internet number resources, including IPv4 and IPv6 address space and AS numbers. ARIN opened its doors for business on December 22, 1997 after incorporating on April 18, 1997. ARIN is a nonprofit corporation with headquarters in Chantilly, Virginia, USA.
ARIN is one of five Regional Internet Registries (RIRs) in the world. Like the other RIRs, ARIN:
Services.
ARIN provides services related to the technical coordination and management of Internet number resources. The nature of these services is described in ARIN's mission statement:
These services are grouped in three areas: Registration, Organization, and Policy Development.
Registration services.
Registration services pertain to the technical coordination and inventory management of Internet number resources. Services include:
For information on requesting Internet number resources from ARIN, see https://www.arin.net/resources/index.html. This section includes the request templates, specific distribution policies, and guidelines for requesting and managing Internet number resources.
Organization services.
Organization services pertain to interaction between stakeholders, ARIN members, and ARIN. Services include:
Policy development services.
Policy development services facilitate the development of policy for the technical coordination and management of Internet number resources.
All ARIN policies are set by the community. Everyone is encouraged to participate in the policy development process at public policy meetings and on the Public Policy Mailing List. The ARIN Board of Trustees ratifies policies only after:
The community develops policies by following a formal Policy Development Process as outlined at https://www.arin.net/policy/pdp.html. The Number Resource Policy Manual, ARIN’s complete set of current policies, is available at https://www.arin.net/policy/nrpm.html.
Membership is not required to participate in ARIN’s policy development process or to apply for Internet number resources.
Services include:
Organizational structure.
ARIN consists of the Internet community within its region, its members, a 7-member Board of Trustees, a 15-member Advisory Council, and a professional staff of about 50. The Board of Trustees and Advisory Council are elected by ARIN members for three-year terms.
Board of trustees.
The ARIN membership elects the Board of Trustees (BoT), which has ultimate responsibility for the business affairs and financial health of ARIN, and manages ARIN's operations in a manner consistent with the guidance received from the Advisory Council and the goals set by the registry's members. The BoT is responsible for determining the disposition of all revenues received to ensure all services are provided in an equitable manner. The BoT ratifies proposals generated from the membership and submitted through the Advisory Council. Executive decisions are carried out following approval by the BoT. The BoT consists of 7 members consisting of a President and CEO, a Chairman, a Treasurer, and others.
Advisory council.
In addition to the BoT, ARIN has an advisory council that advises ARIN and the BoT on IP address allocation policy and related matters. Adhering to the procedures in the Internet Resource Policy Evaluation Process, the advisory council forwards consensus-based policy proposals to the BoT for ratification. The advisory council consists of 15 elected members consisting of a Chair, Vice Chair, and others.
History.
The organization was formed in December 1997 to "provide IP registration services as an independent, nonprofit corporation." Until this time, IP address registration (outside of RIPE and APNIC regions) was done in accordance with policies set by the IETF by Network Solutions corporation as part of the InterNIC project. The National Science Foundation approved the plan for the creation of the not-for-profit organization to "give the users of IP numbers (mostly Internet service providers, corporations and other large institutions) a voice in the policies by which they are managed and allocated within the North American region.". As part of the transition, Network Solutions corporation transitioned these tasks as well as initial staff and computer infrastructure to ARIN.
The initial Board of Trustees consisted of Scott Bradner, John Curran, Kim Hubbard, Don Telage, Randy Bush, Raymundo Vega Aguilar, and Jon Postel (IANA) as an ex-officio member.
The first president of ARIN was Kim Hubbard, from 1997 until 2000. Kim was succeeded by Raymond "Ray" Plzak until the end of 2008. Trustee John Curran was acting President until July 1 of 2009 when he assumed the CEO role permanently.
Until late 2002 it served Mexico, Central America, South America and all of the Caribbean. LACNIC now handles parts of the Caribbean, Mexico, Central America, and South America. Also, Sub-Saharan Africa was part of its region until April 2005, when AfriNIC was officially recognized by ICANN as the fifth Regional Internet Registry.
On 24 September 2015 ARIN has declared exhaustion of the ARIN IPv4 addresses pool.
Service Region.
The countries in the ARIN service region are:
Former service regions.
ARIN formerly covered Angola, Botswana, Burundi, Republic of Congo, Democratic Republic of Congo, Malawi, Mozambique, Namibia, Rwanda, South Africa, Swaziland, Tanzania, Zambia, and Zimbabwe until AfriNIC was formed.
ARIN formerly covered Argentina, Aruba, Belize, Bolivia, Brazil, Chile, Colombia, Costa Rica, Cuba, Dominican Republic, Dutch West Indies, Ecuador, El Salvador, Falkland Islands (UK), French Guiana, Guatemala, Guyana, Haiti, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, South Georgia and the South Sandwich Islands, Suriname, Trinidad and Tobago, Uruguay, and Venezuela until LACNIC was formed.

</doc>
<doc id="2800" url="https://en.wikipedia.org/wiki?curid=2800" title="Asimov (disambiguation)">
Asimov (disambiguation)

Asimov usually refers to Isaac Asimov, the science fiction writer.
Asimov may also refer to:

</doc>
<doc id="2802" url="https://en.wikipedia.org/wiki?curid=2802" title="Akihabara">
Akihabara

Akihabara gained the nickname shortly after World War II for being a major shopping center for household electronic goods and the post-war black market. Nowadays, Akihabara is considered by many to be an otaku cultural center and a shopping district for video games, anime, manga, and computer goods. Icons from popular anime and manga are displayed prominently on the shops in the area, and numerous maid cafés are found throughout the district.
Geography.
The main area of Akihabara is located on a street just west of Akihabara Station, where most of the major shops are situated. Most of the electronics shops are just west of the station, and the anime and manga shops and the cosplay cafés are north of them.
History.
The area that is now Akihabara was once near a city gate of Edo and served as a passage between the city and northwestern Japan. This made the region a home to many craftsmen and tradesmen, as well as some low class samurai. One of Tokyo's frequent fires destroyed the area in 1869, and the people decided to replace the buildings of the area with a shrine called Chinkasha (now known as ), meaning fire extinguisher shrine, in an attempt to prevent the spread of future fires. The locals nicknamed the shrine Akiba after the deity that could control fire, and the area around it became known as Akibagahara and later Akihabara. After Akihabara Station was built in 1888, the shrine was moved to the Taitō ward where it still resides up to the present day.
Since its opening in 1890, Akihabara Station became a major freight transit point, which allowed a vegetable and fruit market to spring up in the district. Then, in the 1920s, the station saw a large volume of passengers after opening for public transport, and after World War II, the black market thrived in the absence of a strong government. This disconnection of Akihabara from government authority has allowed the district to grow as a market city and given rise to an excellent atmosphere for entrepreneurship. In the 1930s, this climate turned Akihabara into a future-oriented market region specializing in household electronics, such as washing machines, refrigerators, televisions, and stereos, earning Akihabara the nickname "Electric Town".
As household electronics began to lose their futuristic appeal in about the 1980s, the shops of Akihabara shifted their focus to home computers at a time when they were only used by specialists and hobbyists. This new specialization brought in a new type of consumer, computer nerds or "otaku". The market in Akihabara naturally latched onto their new customer base that was focused on anime, manga, and video games. The connection between Akihabara and otaku has survived and grown to the point that the region is now known worldwide as a center for otaku culture, and some otaku even consider Akihabara to be a sacred place.
Akihabara massacre.
On Sunday, June 8, 2008 at 12:33 JST, a man drove into a crowd with a truck, then stabbed at least 12 people using a dagger. Seven died and ten were injured. Tokyo Metropolitan Police Department arrested , 25, on suspicion of attempted murder, later being re-arrested weeks later on suspicion of murder. Kato was eventually sentenced to death by the Tokyo District Court in 2011, and the sentence was upheld on appeal in 2012.
"Otaku" culture.
The influence of "otaku" culture has shaped Akihabara's businesses and buildings to reflect the interests of "otaku" and gained the district worldwide fame for its distinctive imagery. Akihabara tries to create an atmosphere as close as possible to the game and anime worlds of customers' interest. The streets of Akihabara are covered with anime and manga icons, and cosplayers line the sidewalks handing out advertisements, especially for maid cafés. The idol group AKB48, one of Japan's highest selling contemporary musical acts, runs its own theater in Akihabara, from which the group's name is derived.
Release events, special events, and conventions in Akihabara give anime and manga fans frequent opportunities to meet the creators of the works they follow so closely and strengthen the connection between the region and "otaku" culture. The design of many of the buildings serves to create the sort of atmosphere that draws in "otaku". Architects design the stores of Akihabara to be more opaque and closed to reflect the general desire of many "otaku" to live in their anime worlds rather than display their interests to the world at large.
Since "otaku" are primarily male, and because of the nature of the medium, Akihabara contains some depictions of sexualized female characters. The abundance of cosplay and maid cafés also puts young women in a position of taking requests from the male customers they serve.
Akihabara's role as a free market has also allowed a large amount of amateur work to find a passionate audience in the otaku who frequent the area. "Doujinshi" (amateur manga) has been growing in Akihabara since the 1970s when publishers began to drop manga that were not ready for large markets.

</doc>
<doc id="2807" url="https://en.wikipedia.org/wiki?curid=2807" title="Active Directory">
Active Directory

Active Directory (AD) is a directory service that Microsoft developed for Windows domain networks. It is included in most Windows Server operating systems as a set of processes and services. Initially, Active Directory was only in charge of centralized domain management. Starting with Windows Server 2008, however, Active Directory became an umbrella title for a broad range of directory-based identity-related services.
A server running Active Directory Domain Services (AD DS) is called a domain controller. It authenticates and authorizes all users and computers in a Windows domain type network—assigning and enforcing security policies for all computers and installing or updating software. For example, when a user logs into a computer that is part of a Windows domain, Active Directory checks the submitted password and determines whether the user is a system administrator or normal user.
Active Directory uses Lightweight Directory Access Protocol (LDAP) versions 2 and 3, Microsoft's version of Kerberos, and DNS.
History.
Active Directory, like many information-technology efforts, originated out of a democratization of design using Request for Comments or RFCs. The Internet Engineering Task Force (IETF), which oversees the RFC process, has accepted numerous RFCs initiated by widespread participants. Active Directory incorporates decades of communication technologies into the overarching Active Directory concept then makes improvements upon them. For example, LDAP underpins Active Directory. Also X.500 directories and the Organizational Unit preceded the Active Directory concept that makes use of those methods. The LDAP concept began to emerge even before the founding of Microsoft in April 1975, with RFCs as early as 1971. RFCs contributing to LDAP include RFC 1823 (on the LDAP API, August 1995), RFC 2307, RFC 3062, and RFC 4533.
Microsoft previewed Active Directory in 1999, released it first with Windows 2000 Server edition, and revised it to extend functionality and improve administration in Windows Server 2003. Additional improvements came with subsequent versions of Windows Server. In Windows Server 2008, additional services were added to Active Directory, such as Active Directory Federation Services. The part of the directory in charge of management of domains, which was previously a core part of the operating system, was renamed Active Directory Domain Services (ADDS) and became a server role like others. "Active Directory" became the umbrella title of a broader range of directory-based services. According to Bryon Hynes, everything related to identity was brought under Active Directory's banner.
Active Directory Services.
Domain Services.
Active Directory Domain Services (AD DS) is the cornerstone of every Windows domain network. It stores information about members of the domain, including devices and users, verifies their credentials and defines their access rights. The server (or the cluster of servers) running this service is called a domain controller. A domain controller is contacted when a user logs into a device, access another device across the network or runs a line-of-business Metro-style app sideloaded into a device.
Other Active Directory services (excluding LDS, as described below) as well as most of Microsoft server technologies rely on or use Domain Services; examples include Group Policy, Encrypting File System, BitLocker, Domain Name Services, Remote Desktop Services, Exchange Server and SharePoint Server.
Lightweight Directory Services.
Active Directory Lightweight Directory Services ("AD LDS"), formerly known as "Active Directory Application Mode" (ADAM), is a light-weight implementation of AD DS. AD LDS runs as a service on Windows Server. AD LDS shares the code base with AD DS and provides the same functionality, including an identical API, but does not require the creation of domains or domain controllers. It provides a "Data Store" for storage of directory data and a "Directory Service" with an LDAP "Directory Service Interface". Unlike AD DS, however, multiple AD LDS instances can run on the same server.
Certificate Services.
Active Directory Certificate Services (AD CS) establishes an on-premises public key infrastructure. It can create, validate and revoke public key certificates for internal uses of an organization. These certificates can be used to encrypt files (when used with Encrypting File System), emails (per S/MIME standard), network traffic (when used by virtual private networks, Transport Layer Security protocol or IPSec protocol).
AD CS predates Windows Server 2008, but its name was simply Certificate Services.
AD CS requires an AD DS infrastructure.
Federation Services.
Active Directory Federation Services (AD FS) is a single sign-on service. With an AD FS infrastructure in place, users may use several web-based service (e.g. internet forum, blog, online shopping, webmail) or network resources using only one set of credentials stored at a central location, as opposed to having to be granted a dedicated set of credentials for each service. AD FS's purpose is an extension of that of AD DS: The latter enables users to authenticate with and use the devices that are part of the same network, using one set of credentials. The former enables them use this same set in a different network.
As the name suggests, AD FS works based on the concept of federated identity.
AD FS requires an AD DS infrastructure, although its federation partner may not.
Rights Management Services.
Active Directory Rights Management Services (AD RMS, known as Rights Management Services or RMS before Windows Server 2008) is a server software for information rights management shipped with Windows Server. It uses encryption and a form of selective functionality denial for limiting access to documents such as corporate e-mails, Microsoft Word documents, and web pages, and the operations authorized users can perform on them.
Logical structure.
As a directory service, an Active Directory instance consists of a database and corresponding executable code responsible for servicing requests and maintaining the database. The executable part, known as Directory System Agent, is a collection of Windows services and processes that run on Windows 2000 and later. Objects in Active Directory databases can be accessed via LDAP, ADSI (a component object model interface), messaging API and Security Accounts Manager services.
Objects.
Active Directory structures are arrangements of information about objects. The objects fall into two broad categories: resources (e.g., printers) and security principals (user or computer accounts and groups). Security principals are assigned unique security identifiers (SIDs).
Each object represents a single entity—whether a user, a computer, a printer, or a group—and its attributes. Certain objects can contain other objects. An object is uniquely identified by its name and has a set of attributes—the characteristics and information that the object represents— defined by a schema, which also determines the kinds of objects that can be stored in Active Directory.
The schema object lets administrators extend or modify the schema when necessary. However, because each schema object is integral to the definition of Active Directory objects, deactivating or changing these objects can fundamentally change or disrupt a deployment. Schema changes automatically propagate throughout the system. Once created, an object can only be deactivated—not deleted. Changing the schema usually requires planning.
Forests, trees, and domains.
The Active Directory framework that holds the objects can be viewed at a number of levels. The forest, tree, and domain are the logical divisions in an Active Directory network.
Within a deployment, objects are grouped into domains. The objects for a single domain are stored in a single database (which can be replicated). Domains are identified by their DNS name structure, the namespace.
A domain is defined as a logical group of network objects (computers, users, devices) that share the same Active Directory database.
A tree is a collection of one or more domains and domain trees in a contiguous namespace, linked in a transitive trust hierarchy.
At the top of the structure is the "forest." A forest is a collection of trees that share a common global catalog, directory schema, logical structure, and directory configuration. The forest represents the security boundary within which users, computers, groups, and other objects are accessible.
Organizational units.
The objects held within a domain can be grouped into Organizational Units (OUs). OUs can provide hierarchy to a domain, ease its administration, and can resemble the organization's structure in managerial or geographical terms. OUs can contain other OUs—domains are containers in this sense. Microsoft recommends using OUs rather than domains for structure and to simplify the implementation of policies and administration. The OU is the recommended level at which to apply group policies, which are Active Directory objects formally named Group Policy Objects (GPOs), although policies can also be applied to domains or sites (see below). The OU is the level at which administrative powers are commonly delegated, but delegation can be performed on individual objects or attributes as well.
Organizational units do not each have a separate namespace; e.g. user accounts with an identical username (sAMAccountName) in separate OUs within a domain are not allowed, such as "fred.staff-ou.domain" and "fred.student-ou.domain", where "staff-ou" and "student-ou" are the OUs. This is because sAMAccountName, a user object attribute, must be unique within the domain. However, two users in different OUs can have the same Common Name (CN), the name under which they are stored in the directory itself.
In general the reason for this lack of allowance for duplicate names through hierarchical directory placement, is that Microsoft primarily relies on the principles of NetBIOS, which is a flat-file method of network object management that for Microsoft software, goes all the way back to Windows NT 3.1 and MS-DOS LAN Manager. Allowing for duplication of object names in the directory, or completely removing the use of NetBIOS names, would prevent backward compatibility with legacy software and equipment. However, disallowing duplicate object names in this way is a violation of the LDAP RFCs on which Active Directory is supposedly based.
As the number of users in a domain increases, conventions such as "first initial, middle initial, last name" (Western order) or the reverse (Eastern order) fail for common family names like "Li (李)", "Smith" or "Garcia". Workarounds include adding a digit to the end of the username. Alternatives include creating a separate ID system of unique employee/student id numbers to use as account names in place of actual user's names, and allowing users to nominate their preferred word sequence within an acceptable use policy.
Because duplicate usernames cannot exist within a domain, account name generation poses a significant challenge for large organizations that cannot be easily subdivided into separate domains, such as students in a public school system or university who must be able to use any computer across the network.
Shadow groups.
In Microsoft's Active Directory, OUs do not confer access permissions, and objects placed within OUs are not automatically assigned access privileges based on their containing OU. This is a design limitation specific to Active Directory. Other competing directories such as Novell NDS are able to assign access privileges through object placement within an OU.
Active Directory requires a separate step for an administrator to assign an object in an OU as a member of a group also within that OU. Relying on OU location alone to determine access permissions is unreliable, because the object may not have been assigned to the group object for that OU.
A common workaround for an Active Directory administrator is to write a custom PowerShell or Visual Basic script to automatically create and maintain a "user group" for each OU in their directory. The scripts are run periodically to update the group to match the OU's account membership, but are unable to instantly update the security groups anytime the directory changes, as occurs in competing directories where security is directly implemented into the directory itself. Such groups are known as "Shadow Groups". Once created, these shadow groups are selectable in place of the OU in the administrative tools.
Microsoft refers to shadow groups in the Server 2008 Reference documentation, but does not explain how to create them. There are no built-in server methods or console snap-ins for managing shadow groups.
The division of an organization's information infrastructure into a hierarchy of one or more domains and top-level OUs is a key decision. Common models are by business unit, by geographical location, by IT Service, or by object type and hybrids of these. OUs should be structured primarily to facilitate administrative delegation, and secondarily, to facilitate group policy application. Although OUs form an administrative boundary, the only true security boundary is the forest itself and an administrator of any domain in the forest must be trusted across all domains in the forest.
Partitions.
The Active Directory database is organized in "partitions", each holding specific object types and following a specific replication pattern. Microsoft often refers to these partitions as 'naming contexts'. The 'Schema' partition contains the definition of object classes and attributes within the Forest. The 'Configuration' partition contains information on the physical structure and configuration of the forest (such as the site topology). Both replicate to all domains in the Forest. The 'Domain' partition holds all objects created in that domain and replicates only within its domain.
Physical structure.
"Sites" are physical (rather than logical) groupings defined by one or more IP subnets. AD also holds the definitions of connections, distinguishing low-speed (e.g., WAN, VPN) from high-speed (e.g., LAN) links. Site definitions are independent of the domain and OU structure and are common across the forest. Sites are used to control network traffic generated by replication and also to refer clients to the nearest domain controllers (DCs). Microsoft Exchange Server 2007 uses the site topology for mail routing. Policies can also be defined at the site level.
Physically, the Active Directory information is held on one or more peer domain controllers, replacing the NT PDC/BDC model. Each DC has a copy of the Active Directory. Servers joined to Active Directory that are not domain controllers are called Member Servers. A subset of objects in the domain partition replicate to domain controllers that are configured as global catalogs. Global catalog (GC) servers provide a global listing of all objects in the Forest.
Global Catalog servers replicate to themselves all objects from all domains and hence, provide a global listing of objects in the forest. However, to minimize replication traffic and keep the GC's database small, only selected attributes of each object are replicated. This is called the partial attribute set (PAS). The PAS can be modified by modifying the schema and marking attributes for replication to the GC. Earlier versions of Windows used NetBIOS to communicate. Active Directory is fully integrated with DNS and requires TCP/IP—DNS. To be fully functional, the DNS server must support SRV resource records, also known as service records.
Replication.
Active Directory synchronizes changes using "multi-master replication". Replication by default is 'pull' rather than 'push', meaning that replicas pull changes from the server where the change was effected. The "Knowledge Consistency Checker" (KCC) creates a replication topology of "site links" using the defined "sites" to manage traffic. Intrasite replication is frequent and automatic as a result of change notification, which triggers peers to begin a pull replication cycle. Intersite replication intervals are typically less frequent and do not use change notification by default, although this is configurable and can be made identical to intrasite replication.
Each link can have a 'cost' (e.g., DS3, T1, ISDN etc.) and the KCC alters the site link topology accordingly. Replication may occur transitively through several site links on same-protocol "site link bridges", if the cost is low, although KCC automatically costs a direct site-to-site link lower than transitive connections. Site-to-site replication can be configured to occur between a "bridgehead server" in each site, which then replicates the changes to other DCs within the site. Replication for Active Directory zones is automatically configured when DNS is activated in the domain based by site.
Replication of Active Directory uses Remote Procedure Calls (RPC) over IP (RPC/IP). Between Sites SMTP can be used for replication, but only for changes in the Schema, Configuration, or Partial Attribute Set (Global Catalog) GCs. SMTP cannot be used for replicating the default Domain partition.
Implementation.
In general, a network utilizing Active Directory has more than one licensed Windows server computer. Backup and restore of Active Directory is possible for a network with a single domain controller, but Microsoft recommends more than one domain controller to provide automatic failover protection of the directory. Domain controllers are also ideally single-purpose for directory operations only, and should not run any other software or role.
Certain Microsoft products such as SQL Server and Exchange can interfere with the operation of a domain controller, necessitating isolation of these products on additional Windows servers. Combining them can make configuration or troubleshooting of either the domain controller or the other installed software more difficult. A business intending to implement Active Directory is therefore recommended to purchase a number of Windows server licenses, to provide for at least two separate domain controllers, and optionally, additional domain controllers for performance or redundancy, a separate file server, a separate Exchange server, a separate SQL Server, and so forth to support the various server roles.
Physical hardware costs for the many separate servers can be reduced through the use of virtualization, although for proper failover protection, Microsoft recommends not running multiple virtualized domain controllers on the same physical hardware.
Database.
The Active-Directory database, the "directory store", in Windows 2000 Server uses the JET Blue-based Extensible Storage Engine (ESE98) and is limited to 16 terabytes and 2 billion objects (but only 1 billion security principals) in each domain controller's database. Microsoft has created NTDS databases with more than 2 billion objects. (NT4's Security Account Manager could support no more than 40,000 objects). Called NTDS.DIT, it has two main tables: the "data table" and the "link table". Windows Server 2003 added a third main table for security descriptor single instancing.
Programs may access the features of Active Directory via the COM interfaces provided by "Active Directory Service Interfaces".
Single server operations.
Flexible Single Master Operations Roles (FSMO, pronounced "fizz-mo") operations are also known as operations master roles. Although domain controllers allow simultaneous updates in multiple places, certain operations are supported only on a single server. These operations are performed using the roles listed below:
Trusting.
To allow users in one domain to access resources in another, Active Directory uses trusts.
Trusts inside a forest are automatically created when domains are created. The forest sets the default boundaries of trust, and implicit, transitive trust is automatic for all domains within a forest.
Terminology.
Forest trusts.
Windows Server 2003 introduced the "forest root trust". This trust can be used to connect Windows Server 2003 forests if they are operating at the 2003 forest functional level. Authentication across this type of trust is Kerberos-based (as opposed to NTLM).
Forest trusts are transitive for all the domains within the trusted forests. However, forest trusts are "not" transitive between forests.
Example: Suppose that a two-way transitive forest trust exists between the forest root domains in Forest A and Forest B, and another two-way transitive forest trust exists between the forest root domains in Forest B and Forest C. Such a configuration lets users in Forest B access resources in any domain in either Forest A or Forest C, and users in Forest A or C can access resources in any domain in Forest B. However, it does "not" let users in Forest A access resources in Forest C, or vice versa. To let users in Forest A and Forest C share resources, a two-way transitive trust must exist between both forests.
Management solutions.
Microsoft Active Directory management tools include:
These management tools may not provide enough functionality for efficient workflow in large environments. Some third-party solutions extend the administration and management capabilities. They provide essential features for a more convenient administration processes, such as automation, reports, integration with other services, etc.
Unix integration.
Varying levels of interoperability with Active Directory can be achieved on most Unix-like operating systems (including Unix, Linux, Mac OS X or Java and Unix-based programs) through standards-compliant LDAP clients, but these systems usually do not interpret many attributes associated with Windows components, such as Group Policy and support for one-way trusts.
Third parties offer Active Directory integration for Unix-like platforms, including:
The schema additions shipped with Windows Server 2003 R2 include attributes that map closely enough to RFC 2307 to be generally usable. The reference implementation of RFC 2307, nss_ldap and pam_ldap provided by PADL.com, support these attributes directly. The default schema for group membership complies with RFC 2307bis (proposed). Windows Server 2003 R2 includes a Microsoft Management Console snap-in that creates and edits the attributes.
An alternate option is to use another directory service as non-Windows clients authenticate to this while Windows Clients authenticate to AD. Non-Windows clients include 389 Directory Server (formerly Fedora Directory Server, FDS), ViewDS Identity Solutions - ViewDS v7.2 XML Enabled Directory and Sun Microsystems Sun Java System Directory Server. The latter two both being able to perform two-way synchronization with AD and thus provide a "deflected" integration.
Another option is to use OpenLDAP with its "translucent" overlay, which can extend entries in any remote LDAP server with additional attributes stored in a local database. Clients pointed at the local database see entries containing both the remote and local attributes, while the remote database remains completely untouched.
Administration (querying, modifying, and monitoring) of Active Directory can be achieved via many scripting languages, including PowerShell, VBScript, JScript/JavaScript, Perl, Python, and Ruby. Using free AD administration tools can help to simplify AD management tasks.

</doc>
<doc id="2809" url="https://en.wikipedia.org/wiki?curid=2809" title="Arian (disambiguation)">
Arian (disambiguation)

Arian may refer to:

</doc>
<doc id="2810" url="https://en.wikipedia.org/wiki?curid=2810" title="Aldona of Lithuania">
Aldona of Lithuania

Aldona (baptized "Ona" or "Anna"; her pagan name, Aldona, is known only from the writings of Maciej Stryjkowski; c. 1309 – 26 May 1339) was Queen consort of Poland (1333–1339), and a princess of the Grand Duchy of Lithuania. She was the daughter of Gediminas, Grand Duke of Lithuania.
Biography.
Aldona married Casimir III of Poland, when he was 15 or 16 years old. The bride was probably of about the same age. The marriage took place on 30 April or 16 October 1325 and was a purely political maneuver to strengthen the first Polish–Lithuanian coalition against the Teutonic Knights. Casimir was seeking allies in the dispute over Pomerania with the Order. Gediminas had just undertaken an unsuccessful attempt to Christianize Lithuania. This coalition was a prelude to the Union of Krewo in 1385, and the Union of Lublin in 1569, which resulted in the creation of a new state, the Polish–Lithuanian Commonwealth. The details of the agreement are not known; however, it is known that Gediminas released all Polish captives, numbered at around 25,000, who returned to Poland. The importance of the marriage was attested by the fact that Władysław abandoned his earlier plans to marry his son to Jutta of Bohemia. The alliance was put into effect when joint Polish-Lithuanian forces organized an attack against the Margraviate of Brandenburg in 1326. However, the coalition was not strong and collapsed c. 1330. Yet, there is no evidence of fighting between Poland and Lithuania while Aldona was alive. Aldona died suddenly at the end of May 1339, and was buried in Kraków.
Aldona was remembered for her piety and devotion to music. She was accompanied by court musicians wherever she went. It was even suggested by Jan Długosz that the cymbals which were played in procession before her represented a pagan Lithuanian tradition. Her husband Casimir is known for his romantic affairs: after Aldona's death he married three more times. Aldona had two daughters:

</doc>
<doc id="2812" url="https://en.wikipedia.org/wiki?curid=2812" title="Aron Nimzowitsch">
Aron Nimzowitsch

Aron Nimzowitsch (, , "Aron Isayevich Nimtsovich"; born Aron Niemzowitsch; 7 November 1886 – 16 March 1935) was a Russian-born, Danish leading chess master and a very influential chess writer. He was the foremost figure amongst the "hypermoderns".
Life.
Born in part of the Russian Empire, the Jewish German-speaking Nimzowitsch came from a wealthy family, where he learned chess from his father, who was a merchant. In 1904, he travelled to Berlin to study philosophy, but set aside his studies soon and began a career as a professional chess player that same year. He won his first international tournament at Munich 1906. Then, he tied for first with Alexander Alekhine at St. Petersburg 1913/14 (the eighth All-Russian Masters' Tournament).
During the 1917 Russian Revolution, Nimzowitsch was in the Baltic war zone. He escaped being drafted into one of the armies by feigning madness, insisting that a fly was on his head. He then escaped to Berlin, and gave his first name as Arnold, possibly to avoid anti-Semitic persecution.
Nimzowitsch eventually moved to Copenhagen in 1922, which coincided with his rise to the world chess elite, where he lived for the rest of his life in one small rented room. In Copenhagen, he twice won the Nordic Chess Championship, in 1924 and 1934. He obtained Danish citizenship and lived in Denmark until his death in 1935. Although he had long suffered from heart trouble, his early death was unexpected; taken ill suddenly at the end of 1934, he lay bedridden for three months before dying of pneumonia. He is buried in Bispebjerg Cemetery in Copenhagen.
Chess career.
The height of Nimzowitsch's career was the late 1920s and early 1930s. Chessmetrics places him as the third best player in the world from 1927 to 1931, behind Alexander Alekhine and José Capablanca. His most notable successes were first-place finishes at Copenhagen 1923, Marienbad 1925, Dresden 1926, Hanover 1926, the Carlsbad 1929 chess tournament, and second place behind Alekhine at the San Remo 1930 chess tournament. Nimzowitsch never developed a knack for match play, though; his best match success was a draw with Alekhine, but the match consisted of only two games and took place in 1914, thirteen years before Alekhine became world champion.
Nimzowitsch never beat Capablanca, but fared better against Alekhine. He even beat Alekhine with the black pieces, in their short 1914 match at St. Petersburg. One of Nimzowitsch's most famous games is his celebrated immortal zugzwang game against Sämisch at Copenhagen 1923. Another game on this theme is his win over Paul Johner at Dresden 1926. When in form, Nimzowitsch was very dangerous with the black pieces, scoring many fine wins over top players.
Legacy.
Nimzowitsch is considered one of the most important players and writers in chess history. His works influenced numerous other players, including Savielly Tartakower, Milan Vidmar, Richard Réti, Akiba Rubinstein, Bent Larsen and Tigran Petrosian, and his influence is still felt today.
He wrote three books on chess strategy: "Mein System (My System)", 1925, "Die Praxis meines Systems (The Practice of My System)", 1929, commonly known as "Chess Praxis", and "Die Blockade" ("The Blockade"), 1925, though much in the latter book is generally held to be a rehash of material already presented in "Mein System". "Mein System" is considered to be one of the most influential chess books of all time. It sets out Nimzowitsch's most important ideas, while his second most influential work, "Chess Praxis", elaborates upon these ideas, adds a few new ones, and has immense value as a stimulating collection of Nimzowitsch's own games accompanied by his idiosyncratic, hyperbolic commentary which is often as entertaining as instructive.
Nimzowitsch's chess theories, when first propounded flew in the face of widely held orthodoxies enunciated by the dominant theorist of the era, Siegbert Tarrasch, and his disciples. Tarrasch's rigid generalizations drew on the earlier work of Wilhelm Steinitz, and were upheld by Tarrasch's sharp tongue when dismissing the opinions of doubters. While the greatest players of the time, among them Alekhine, Emanuel Lasker and Capablanca, clearly did not allow their play to be hobbled by blind adherence to general concepts that the center had to be controlled by pawns, that development had to happen in support of this control, that rooks always belong on open files, that wing openings were unsound—core ideas of Tarrasch's chess philosophy as popularly understood—beginners were taught to think of these generalizations as unalterable principles.
Nimzowitsch supplemented many of the earlier simplistic assumptions about chess strategy by enunciating in his turn a further number of general concepts of defensive play aimed at achieving one's own goals by preventing realization of the opponent's plans. Notable in his "system" were concepts such as overprotection of pieces and pawns under attack, control of the center by pieces instead of pawns, blockading of opposing pieces (notably the passed pawns) and prophylaxis. He was also a leading exponent of the fianchetto development of bishops. Perhaps most importantly, he formulated the terminology still in use for various complex chess strategies. Others had used these ideas in practice, but he was the first to present them systematically as a lexicon of themes accompanied by extensive taxonomical observations.
Grandmaster (GM) Raymond Keene writes that Nimzowitsch "was one of the world's leading grandmasters for a period extending over a quarter of a century, and for some of that time he was the obvious challenger for the world championship. ... e was als a great and profound chess thinker second only to Steinitz, and his works – "Die Blockade", "My System" and "Chess Praxis" – established his reputation as one of the father figures of modern chess." GM Robert Byrne called him "perhaps the most brilliant theoretician and teacher in the history of the game." GM Jan Hein Donner called Nimzowitsch "a man who was too much of an artist to be able to prove he was right and who was regarded as something of a madman in his time. He would be understood only long after his death."
Many chess openings and variations are named after Nimzowitsch, the most famous being the Nimzo-Indian Defence (1.d4 Nf6 2.c4 e6 3.Nc3 Bb4) and the less often played Nimzowitsch Defence (1.e4 Nc6). Nimzowitsch biographer GM Raymond Keene and others have referred to 1.Nf3 followed by 2.b3 as the Nimzowitsch–Larsen Attack. Keene wrote a book about the opening with that title. These openings all exemplify Nimzowitsch's ideas about controlling the center with pieces instead of pawns. He was also vital in the development of two important systems in the French Defence, the (in some places called the Nimzowitsch Variation; its moves are 1.e4 e6 2.d4 d5 3.Nc3 Bb4) and the (1.e4 e6 2.d4 d5 3.e5). He also pioneered two provocative variations of the Sicilian Defence: the , 1.e4 c5 2.Nf3 Nf6, which invites 3.e5 Nd5 (similar to Alekhine's Defence) and 1.e4 c5 2.Nf3 Nc6 3.d4 cxd4 4.Nxd4 d5?! (the latter regarded as dubious today). International Master John L. Watson has dubbed the line 1.c4 Nf6 2.Nc3 e6 3.Nf3 Bb4 the "Nimzo-English", employing this designation in Chapter 11 of his recent book "Mastering the Chess Openings, Volume 3".
Personality.
There are many entertaining anecdotes regarding Nimzowitsch—some less savory than others. An article by Hans Kmoch and Fred Reinfeld entitled "Unconventional Surrender" on page 55 of the February 1950 Chess Review tells of the "... example of Nimzowitsch, who ... once missed first prize in a tournament in Berlin by losing to Sämisch, and when it became clear he was going to lose the game, Nimzowitsch stood up on the table and shouted, 'Gegen diesen Idioten muss ich verlieren!' ('That I should lose to this idiot!')".
Nimzowitsch was annoyed by his opponents' smoking. A popular, but probably apocryphal, story is that once when an opponent laid an unlit cigar on the table, he complained to the tournament arbiters, "He is threatening to smoke, and as an old player you must know that the threat is stronger than the execution."
Nimzowitsch had lengthy and somewhat bitter dogmatic conflicts with Tarrasch over whose ideas constituted 'proper' chess.
Nimzowitsch's vanity and faith in his ideas of overprotection provoked Hans Kmoch to write a parody about him in February 1928 in the "Wiener Schachzeitung". This consisted of a mock game against the fictional player "Systemsson", supposedly played and annotated by Nimzowitsch himself. The annotations gleefully exaggerate the idea of overprotection, as well as asserting the true genius of the wondrous idea. Kmoch was in fact a great admirer of Nimzowitsch, and the subject of the parody himself was amused at the effort.
Kmoch also wrote an article about his nine years with Nimzowitsch:
Nimzowitsch's colleague Tartakower observed of him, "He pretends to be crazy in order to drive us all crazy."

</doc>
<doc id="2813" url="https://en.wikipedia.org/wiki?curid=2813" title="Aragonese language">
Aragonese language

Aragonese (; "aragonés" in Aragonese) is a Romance language spoken today in several local varieties by between 10,000 and 30,000 people throughout the valleys of the Pyrenees in Aragon, Spain, mainly in the comarcas of Somontano de Barbastro, Jacetania, Alto Gállego, Sobrarbe, and Ribagorza. It is the only modern language that survived from medieval Navarro-Aragonese in a form distinctly different from Spanish.
While informally known as "fabla" ("talk" or "speech"), Aragonese is also commonly referred to by the names of its numerous local dialects, such as "cheso" (from Valle de Hecho) or "patués" (from the valley of Benasque).
History.
Aragonese, one of many Latin dialects developed in areas of the Ebro basin, can be traced back to the High Middle Ages. It spread throughout the Pyrenees to areas where languages similar to Basque are supposed to have been spoken before. The original Kingdom of Aragon (formed by the counties of Aragon, Sobrarbe and Ribagorza) was progressively expanded from the mountain ranges towards the South, pushing the Moors farther south in the "Reconquista", thereby spreading the Aragonese language.
The dynastic union of the Catalan Counties and the Kingdom of Aragon, which formed the Crown of Aragon in the twelfth century, did not result in a merger of the languages of the two territories; Catalan continued to be spoken in the east and Navarro-Aragonese in the west, although with blurred boundaries because of dialectal continuity. The Aragonese "Reconquista" in the south ended with the kingdom of Murcia, which was ceded by James I of Aragon to the Kingdom of Castile as a dowry for an Aragonese princess.
The most prominent proponent of the Aragonese language was Johan Ferrandez d'Heredia, founder of the lineage and Grand Master of the Order of the Hospital of St. John of Jerusalem based in Rhodes. He wrote an extensive catalog of works in Aragonese and also several works translated from Greek into Aragonese, the first in medieval Europe.
The spread of Castilian (the language today known as "Spanish"), the Castilian origin of the Trastámara dynasty, and a strong similarity between Castilian and Aragonese meant that further recession was to follow. One of the key moments in the history of Aragonese was when a king of Castilian origin was appointed in the fifteenth century: Ferdinand I of Aragon, also known as Ferdinand of Antequera.
The union of the crowns of Aragon and Castile and the progressive suspension of all capacity of self-rule from the sixteenth century meant that Aragonese, while still widely spoken, was limited to a rural and colloquial use, as the nobility chose Castillian as their language. 
In modern times, Aragonese was regarded as a mere group of rural dialects of Spanish, while the spread of compulsory schooling further undermined its position; the language was frowned upon: for example, pupils were punished in schools for using it.
The Spanish transition to democracy in 1978 heralded the debut of literary works and studies concerning the Aragonese language.
Modern Aragonese.
Today, Aragonese is still the native language within a core area; the Aragonese mountain ranges of the Pyrenees, in the "comarcas" of Somontano, Jacetania, Sobrarbe, and Ribagorza.
The major cities and towns in which Aragonese speakers can still be found are as follows: Huesca, Graus, Monzón, Barbastro, Bielsa, Chistén, Fonz, Echo, Estadilla, Benasque, Campo, Sabiñánigo, Jaca, Plan, Ansó, Ayerbe, Broto, and El Grado.
Aragonese is also learned as a second language by other inhabitants of the country in such areas as Huesca, Zaragoza, Ejea de los Caballeros, and Teruel. According to recent polls they only make up around 10,000 active speakers and about 30,000 passive speakers.
In 2009, the Languages Act of Aragon gave recognition of "native language, original and historic" of Aragon. There are now a number of linguistic rights, such as the use of Aragonese in the public administrations of Aragon.
Phonology.
Phonological characteristics.
Aragonese has many historical traits that join it to Catalan rather than to Spanish. Some of these are conservative features that are also shared with Astur-Leonese and Portuguese, where Spanish innovated in ways that did not spread to nearby languages.
Orthography.
In 2010, the Academia de l'Aragonés, formed in 2006, established a single orthographic standard in order to modernize medieval orthography and to make it more etymological. This new orthography is used by the .
Previously, Aragonese had two orthographic standards:
In the sixteenth century, Aragonese Moriscos wrote some aljamiado texts (Romance texts in Arabic writing), probably because of their inability to write in Arabic; the language in these texts shows a mixture of Aragonese and Castilian traits, and they can be considered among the last written examples of the Aragonese formerly spoken in Central and Southern Aragon.
Grammar.
Aragonese grammar is similar to the grammar of other Iberian Romance languages, such as Spanish and Catalan.
Article.
Definite article.
The definite article in Aragonese has undergone certain changes that have become characteristics of dialectal differentiation. The definite articles in Old Aragonese were similar to their present-day Spanish equivalents. The most widespread articles in Aragonese are similar to those found in Galician and Portuguese, as they lack the initial "l":
The second article, auxiliary, after a vowel, is used with an "r", whose pronunciation is .
Lexicology.
Examining the Aragonese lexicon shows the origin of Aragonese words from different languages that have influenced it.
The influence of other Romance languages on Aragonese is evident, especially from neighboring languages. Catalan and Occitan influenced Medieval Aragonese, and the Catalan influence continued, under the Crown of Aragon, in the territory where the languages are in contact (Ribagorça), a fact that explains the main characteristics of Eastern Aragonese. Since the 15th century, the Romance language which has influenced Aragonese the most is Spanish, having been adopted in almost all of Aragon as the first language and reducing Aragonese to the northern region around the Pyrenees.
Another Romance language with certain influence is French, the only official language in the neighboring country. Italian loans have come in through other languages such as Catalan, while words from Portuguese have come in through Spanish.
Germanic words came through the conquest of the region by Germanic peoples in the 5th century AD.
Aragonese also has loans from Arabic and Mozarabic due to the Umayyad conquest of Hispania in the 8th century, and in turn, Arabic brought words from other languages, such as Persian and Sanskrit.
English, with its international importance, has introduced a lot of new words into the language.
Gender.
Words that derive from the second declension or assimilated to the second declension are usually masculine:
Words derived from the first declension are usually feminine:
There are neutral plurals assimilated to the first declension that become feminine-gender singular: 
Words that end in "-or" are feminine:
The names of fruit trees usually end in "-era", a suffix derived from Latin -ARIA and they are usually feminine:
The genders of river names vary according to the river:
Pronouns.
Aragonese preserves the system of clitic pronouns derived from the Latin forms "inde" and "ibi", as "en'/"ne" and "".
This feature is shared with other Romance languages (cf., Catalan "en" and "hi", Occitan "ne" and "i", French "en" and "y", and Italian "ne" and "ci"), thus making Aragonese different from other Ibero-Romance languages, which lack such clitics (e.g., Spanish, Asturian, and Portuguese).
"En/ne" is used for:
"" is used for:
Dialects.
There are about 25–30 dialectal variants of Aragonese, the majority of which are in the province of Huesca, where natural isoglosses have developed around valley enclaves. Ribagorçan, is one such variant: a transitional eastern Aragonese dialect between Gascon Occitan, Catalan, and Spanish.
There is a proposal to classify the language varieties into four main dialects:
For certain linguists, these groups are complex dialects formed by various varieties. For others, these four groups are Aragonese dialects and Hecho Aragonese and Chistau Valley Aragonese are comarcal varieties.
Literature.
Medieval Ages.
At no point in its history did the Aragonese language acquire the prestige literature developed in other Romance languages from the Iberian Peninsula.
Not until the 12th - 13th centuries did Aragonese begin to be used in written documents. From this period are featured "Liber Regum"' (a book of general history), "Razón feita d'amor", "Libre dels tres reys d'orient" and "Vida de Santa María Egipcíaca".
Early modern period literature.
Spanish was from 1500 the first language of culture in Aragon: a lot of Aragonese stood out with writings in the Spanish language, to the point that in the 17th century the Argensola brothers went to Castile to teach Spanish.
Aragonese became a familiar and village language and each century acquired popular traces. The 16th was obscure: there is no document in Aragonese, just in Aljamia. In the 17th century certain texts appeared that used the language to characterized popular characters.
In a literary contest held in Huesca in 1650, there were three poems submitted in Aragonese, respectively, by Matías Pradas, Isabel de Rodas and "Fileno, montañés".
The first "pastoradas" come from the 16th and the 17th century.
Contemporary literature.
The 19th and 20th centuries have seen a renaissance of the Aragonese literature; however, due to the lack of a standard language, authors write about local topics, each using his own variety of the language. In 1844, the novel "Vida de Pedro Saputo", by Braulio Foz, appeared in Almudévar Aragonese. In the 20th century the costumbrist comedies written by Domingo Miral gained importance, as well as the poetry of Veremundo Méndez Coarasa, both in Hecho Aragonese; in Graus Aragonese, one can highlight Cleto Torrodellas' verses and Tonón de Baldomera's popular writings; in Somontano Aragonese, there are Pedro Arnal Cavero's costumbrist narrations, as well as Juana Coscujuela' novel, "A Lueca, historia d'una moceta d'o Semontano".

</doc>
<doc id="2815" url="https://en.wikipedia.org/wiki?curid=2815" title="Advanced Mobile Phone System">
Advanced Mobile Phone System

Advanced Mobile Phone System (AMPS) is an analog mobile cell phone system standard developed by Bell Labs, and officially introduced in the Americas on October 13, 1983, Israel in 1986, Australia in 1987, and Pakistan in 1990. It was the primary analog mobile phone system in North America (and other locales) through the 1980s and into the 2000s. As of February 18, 2008, carriers in the United States were no longer required to support AMPS and companies such as AT&T and Verizon have discontinued this service permanently. AMPS was discontinued in Australia in September 2000 and in Pakistan by October 2004.
History.
The first cellular network efforts began at Bell Labs (which first proposed the idea of a cellular system in 1947 and continued to petition the FCC for channels through the 1950s and 1960s) and with research conducted at Motorola. 
In 1960, John F. Mitchell,
an electrical engineer who had graduated from the Illinois Institute of Technology, became Motorola's chief engineer for its mobile-communication products. Mitchell oversaw the development and marketing of the first pager to use transistors.
Motorola had long produced mobile telephones for automobiles, but these large and heavy models consumed too much power to allow their use without the automobile's engine running. Mitchell's team, which included the gifted Dr. Martin Cooper, developed portable cellular telephony, and Mitchell was among the Motorola employees granted a patent for this work in 1973; the first call on the prototype connected, reportedly, to a wrong number.
While Motorola was developing a cellular phone, from 1968-1983 Bell Labs worked out a system called Advanced Mobile Phone System (AMPS), which became the first cellular network standard in the U.S. Motorola and others designed and built the cellular phones for this and other cellular systems.
Martin Cooper, a former general manager for the systems division at Motorola, led a team that produced the DynaTAC8000x, the first commercially available cellular phone small enough to be easily carried, and made the first phone call from it, and later introduced the so-called Bag Phone.
In 1992 the first smartphone, called IBM Simon, used AMPS. Frank Canova led its design at IBM and it was demonstrated that year at the COMDEX computer-industry trade-show. A refined version of the product was marketed to consumers in 1994 by BellSouth under the name Simon Personal Communicator. The Simon was the first device that can be properly referred to as a "smartphone", even though that term was not yet coined.
Technology.
AMPS is a first-generation cellular technology that uses separate frequencies, or "channels", for each conversation (see Frequency-division multiple access (FDMA)). It therefore required considerable bandwidth for a large number of users. In general terms, AMPS was very similar to the older "0G" Improved Mobile Telephone Service, but used considerably more computing power in order to select frequencies, hand off conversations to PSTN lines, and handle billing and call setup.
What really separated AMPS from older systems is the "back end" call setup functionality. In AMPS, the cell centers could flexibly assign channels to handsets based on signal strength, allowing the same frequency to be re-used in various locations without interference. This allowed a larger number of phones to be supported over a geographical area. AMPS pioneers coined the term "cellular" because of its use of small hexagonal "cells" within a system.
AMPS suffered from many weaknesses compared to today's digital technologies. As an analog standard, it was susceptible to static and noise, and there was no protection from 'eavesdropping' using a scanner.
Cloning.
In the 1990s an epidemic of "cloning" cost the cellular carriers millions of dollars. An eavesdropper with specialized equipment could intercept a handset's ESN (Electronic Serial Number) and MDN or CTN (Mobile Directory Number or Cellular Telephone Number). The Electronic Serial Number, a 12-digit number sent by the handset to the cellular system for billing purposes, uniquely identified that phone on the network. The system then allowed or disallowed calls and or features based on its customer file. A person intercepting an ESN/MDN pair could clone the combination onto a different phone and use it in other areas for making calls without paying.
Cellular phone cloning became possible with off-the-shelf technology in the 1990s. Would-be cloners required three key items :
The radio, when tuned to the proper frequency, would receive the signal transmitted by the cell phone to be cloned, containing the phone's ESN/MDN pair. This signal would feed into the sound-card audio-input of the PC, and Banpaia would decode the ESN/MDN pair from this signal and display it on the screen. The hacker could then copy that data into the Oki 900 phone and reboot it, after which the phone network could not distinguish the Oki from the original phone whose signal had been received. This gave the cloner, through the Oki phone, the ability to use the mobile-phone service of the legitimate subscriber whose phone was cloned - just as if that phone had been physically stolen, except that the subscriber retained his or her phone, unaware that the phone had been cloned—at least until that subscriber received his or her next bill.
The problem became so large that some carriers required the use of a PIN before making calls. Eventually, the cellular companies initiated a system called RF Fingerprinting, whereby it could determine subtle differences in the signal of one phone from another and shut down some cloned phones. Some legitimate customers had problems with this though if they made certain changes to their own phone, such as replacing the battery and/or antenna. The Oki 900, the ultimate tool of cell-phone hackers, could listen in to AMPS phone-calls right out-of-the-box with no hardware modifications.
Standards.
AMPS was originally standardized by American National Standards Institute (ANSI) as EIA/TIA/IS-3. EIA/TIA/IS-3 was superseded by EIA/TIA-553 and TIA interim standard with digital technologies, the cost of wireless service is so low that the problem of cloning has virtually disappeared.
Frequency bands.
AMPS cellular service operated in the 850 MHz Cellular band. For each market area, the United States Federal Communications Commission (FCC) allowed two licensees (networks) known as "A" and "B" carriers. Each carrier within a market used a specified "block" of frequencies consisting of 21 control channels and 395 voice channels. Originally, the B (wireline) side license was usually owned by the local phone company, and the A (non-wireline) license was given to wireless telephone providers.
At the inception of cellular in 1983, the FCC had granted each carrier within a market 333 channel pairs (666 channels total). By the late 1980s, the cellular industry's subscriber base had grown into the millions across America and it became necessary to add channels for additional capacity. In 1989, the FCC granted carriers an expansion from the previous 666 channels to the final 832 (416 pairs per carrier). The additional frequencies were from the band held in reserve for future (inevitable) expansion. These frequencies were immediately adjacent to the existing cellular band. These bands had previously been allocated to UHF TV channels 70–83.
Each duplex channel was composed of 2 frequencies. 416 of these were in the 824–849 MHz range for transmissions from mobile stations to the base stations, paired with 416 frequencies in the 869–894 MHz range for transmissions from base stations to the mobile stations. Each cell site used a different subset of these channels than its neighbors to avoid interference. This significantly reduced the number of channels available at each site in real-world systems. Each AMPS channel had a one way bandwidth of 30 kHz, for a total of 60 kHz for each duplex channel.
Laws were passed in the US which prohibited the FCC type acceptance and sale of any receiver which could tune the frequency ranges occupied by analog AMPS cellular services. Though the service is no longer offered, these laws remain in force.
Digital AMPS.
Later, many AMPS networks were partially converted to D-AMPS, often referred to as TDMA (though TDMA is a generic term that applies to many 2G cellular systems). D-AMPS, commercial deployed since 1993, was a digital, 2G standard used mainly by AT&T Mobility and U.S. Cellular in the United States, Rogers Wireless in Canada, Telcel in Mexico, Telecom Italia Mobile (TIM) in Brazil, VimpelCom in Russia, Movilnet in Venezuela, and Cellcom in Israel. In most areas, D-AMPS is no longer offered and has been replaced by more advanced digital wireless networks.
Successor technologies.
AMPS and D-AMPS have now been phased out in favor of either CDMA2000 or GSM, which allow for higher capacity data transfers for services such as WAP, Multimedia Messaging System (MMS), and wireless Internet access. There are some phones capable of supporting AMPS, D-AMPS and GSM all in one phone (using the GAIT standard).
Analog AMPS being replaced by digital.
In 2002, the FCC decided to no longer require A and B carriers to support AMPS service as of February 18, 2008. All AMPS carriers have converted to a digital standard such as CDMA2000 or GSM. Digital technologies such as GSM and CDMA2000 support multiple voice calls on the same channel and offer enhanced features such as two-way text messaging and data services.
Unlike in the United States, the Canadian Radio-television and Telecommunications Commission (CRTC) and Industry Canada have not set any requirement for maintaining AMPS service in Canada. Rogers Wireless has dismantled their AMPS (along with IS-136) network; the networks were shut down May 31, 2007. Bell Mobility and Telus Mobility, who operated AMPS networks in Canada, announced that they would observe the same timetable as outlined by the FCC in the United States, and as a result would not begin to dismantle their AMPS networks until after February 2008.
OnStar relied heavily on North American AMPS service for its subscribers because, when the system was developed, AMPS offered the most comprehensive wireless coverage in the US. In 2006, ADT asked the FCC to extend the AMPS deadline due to many of their alarm systems still using analog technology to communicate with the control centers. Cellular companies who own an A or B license (such as Verizon and Alltel) were required to provide analog service until February 18, 2008. After that point, however, most cellular companies were eager to shut down AMPS and use the remaining channels for digital services. OnStar transitioned to digital service with the help of data transport technology developed by Airbiquity, but warned customers who could not be upgraded to digital service that their service would permanently expire on January 1, 2008.

</doc>
<doc id="2819" url="https://en.wikipedia.org/wiki?curid=2819" title="Aerodynamics">
Aerodynamics

Aerodynamics, from Greek ἀήρ "aer" (air) + δυναμική (dynamics), is a branch of fluid dynamics concerned with studying the motion of air, particularly when it interacts with a solid object, such as an airplane wing. Aerodynamics is a sub-field of fluid dynamics and gas dynamics, and many aspects of aerodynamics theory are common to these fields. The term "aerodynamics" is often used synonymously with gas dynamics, with the difference being that "gas dynamics" applies to the study of the motion of all gases, not limited to air.
Formal aerodynamics study in the modern sense began in the eighteenth century, although observations of fundamental concepts such as aerodynamic drag have been recorded much earlier. Most of the early efforts in aerodynamics worked towards achieving heavier-than-air flight, which was first demonstrated by Wilbur and Orville Wright in 1903. Since then, the use of aerodynamics through mathematical analysis, empirical approximations, wind tunnel experimentation, and computer simulations has formed the scientific basis for ongoing developments in heavier-than-air flight and a number of other technologies. Recent work in aerodynamics has focused on issues related to compressible flow, turbulence, and boundary layers, and has become increasingly computational in nature.
History.
Modern aerodynamics only dates back to the seventeenth century, but aerodynamic forces have been harnessed by humans for thousands of years in sailboats and windmills, and images and stories of flight appear throughout recorded history, such as the Ancient Greek legend of Icarus and Daedalus. Fundamental concepts of continuum, drag, and pressure gradients, appear in the work of Aristotle and Archimedes.
In 1726, Sir Isaac Newton became the first person to develop a theory of air resistance, making him one of the first aerodynamicists. Dutch-Swiss mathematician Daniel Bernoulli followed in 1738 with "Hydrodynamica", in which he described a fundamental relationship between pressure, density, and flow velocity for incompressible flow known today as Bernoulli's principle, which provides one method for calculating aerodynamic lift. In 1757, Leonhard Euler published the more general Euler equations, which could be applied to both compressible and incompressible flows. The Euler equations were extended to incorporate the effects of viscosity in the first half of the 1800s, resulting in the Navier-Stokes equations. The Navier-Stokes equations are the most general governing equations of fluid flow and are difficult to solve.
In 1799, Sir George Cayley became the first person to identify the four aerodynamic forces of flight (weight, lift, drag, and thrust), as well as the relationships between them, outlining the work towards achieving heavier-than-air flight for the next century. In 1871, Francis Herbert Wenham constructed the first wind tunnel, allowing precise measurements of aerodynamic forces. Drag theories were developed by Jean le Rond d'Alembert, Gustav Kirchhoff, and Lord Rayleigh. In 1889, Charles Renard, a French aeronautical engineer, became the first person to reasonably predict the power needed for sustained flight. Otto Lilienthal, the first person to become highly successful with glider flights, was also the first to propose thin, curved airfoils that would produce high lift and low drag. Building on these developments as well as research carried out in their own wind tunnel, the Wright brothers flew the first powered airplane on December 17, 1903.
During the time of the first flights, Frederick W. Lanchester, Martin Wilhelm Kutta, and Nikolai Zhukovsky independently created theories that connected circulation of a fluid flow to lift. Kutta and Zhukovsky went on to develop a two-dimensional wing theory. Expanding upon the work of Lanchester, Ludwig Prandtl is credited with developing the mathematics behind thin-airfoil and lifting-line theories as well as work with boundary layers.
As aircraft speed increased, designers began to encounter challenges associated with air compressibility at speeds near or greater than the speed of sound. The differences in air flows under these conditions led to problems in aircraft control, increased drag due to shock waves, and structural dangers due to aeroelastic flutter. The ratio of the flow speed to the speed of sound was named the Mach number after Ernst Mach, who was one of the first to investigate the properties of supersonic flow. William John Macquorn Rankine and Pierre Henri Hugoniot independently developed the theory for flow properties before and after a shock wave, while Jakob Ackeret led the initial work on calculating the lift and drag of supersonic airfoils. Theodore von Kármán and Hugh Latimer Dryden introduced the term transonic to describe flow speeds around Mach 1 where drag increases rapidly. This rapid increase in drag led aerodynamicists and aviators to disagree on whether supersonic flight was achievable until the sound barrier was broken for the first time in 1947 using the Bell X-1 aircraft.
By the time the sound barrier was broken, much of the subsonic and low supersonic aerodynamics knowledge had matured. The Cold War fueled an ever evolving line of high performance aircraft. Computational fluid dynamics began as an effort to solve for flow properties around complex objects and has rapidly grown to the point where entire aircraft can be designed using a computer, with wind-tunnel tests followed by flight tests to confirm the computer predictions. Knowledge of supersonic and hypersonic aerodynamics has also matured since the 1960s, and the goals of aerodynamicists have shifted from understanding the behavior of fluid flow to understanding how to engineer a vehicle to interact appropriately with the fluid flow. Designing aircraft for supersonic and hypersonic conditions, as well as the desire to improve the aerodynamic efficiency of current aircraft and propulsion systems, continues to fuel new research in aerodynamics, while work continues to be done on important problems in basic aerodynamic theory related to flow turbulence and the existence and uniqueness of analytical solutions to the Navier-Stokes equations.
Fundamental concepts.
Understanding the motion of air around an object (often called a flow field) enables the calculation of forces and moments acting on the object. In many aerodynamics problems, the forces of interest are the fundamental forces of flight: lift, drag, thrust, and weight. Of these, lift and drag are aerodynamic forces, i.e. forces due to air flow over a solid body. Calculation of these quantities is often founded upon the assumption that the flow field behaves as a continuum. Continuum flow fields are characterized by properties such as flow velocity, pressure, density and temperature, which may be functions of spatial position and time. These properties may be directly or indirectly measured in aerodynamics experiments, or calculated from equations for the conservation of mass, momentum, and energy in air flows. Density, flow velocity, and an additional property, viscosity, are used to classify flow fields.
Flow classification.
Flow velocity is used to classify flows according to speed regime. Subsonic flows are flow fields in which air velocity throughout the entire flow is below the local speed of sound. Transonic flows include both regions of subsonic flow and regions in which the flow speed is greater than the speed of sound. Supersonic flows are defined to be flows in which the flow speed is greater than the speed of sound everywhere. A fourth classification, hypersonic flow, refers to flows where the flow speed is much greater than the speed of sound. Aerodynamicists disagree on the precise definition of hypersonic flow.
Compressibility refers to whether or not the flow in a problem can have a varying density. Subsonic flows are often assumed to be incompressible, i.e. the density is assumed to be constant. Transonic and supersonic flows are compressible, and neglecting to account for the changes in density in these flow fields when performing calculations will yield inaccurate results.
Viscosity is associated with the frictional forces in a flow. In some flow fields, viscous effects are very small, and solutions may neglect to account for viscous effects. These approximations are called inviscid flows. Flows for which viscosity is not neglected are called viscous flows. Finally, aerodynamic problems may also be classified by the flow environment. External aerodynamics is the study of flow around solid objects of various shapes (e.g. around an airplane wing), while internal aerodynamics is the study of flow through passages in solid objects (e.g. through a jet engine).
Continuum assumption.
Unlike liquids and solids, gases are composed of discrete molecules which occupy only a small fraction of the volume filled by the gas. On a molecular level, flow fields are made up of many individual collisions between gas molecules and between gas molecules and solid surfaces. In most aerodynamics applications, however, this discrete molecular nature of gases is ignored, and the flow field is assumed to behave as a continuum. This assumption allows fluid properties such as density and flow velocity to be defined anywhere within the flow.
Validity of the continuum assumption is dependent on the density of the gas and the application in question. For the continuum assumption to be valid, the mean free path length must be much smaller than the length scale of the application in question. For example, many aerodynamics applications deal with aircraft flying in atmospheric conditions, where the mean free path length is on the order of micrometers. In these cases, the length scale of the aircraft ranges from a few meters to a few tens of meters, which is much larger than the mean free path length. For these applications, the continuum assumption holds. The continuum assumption is less valid for extremely low-density flows, such as those encountered by vehicles at very high altitudes (e.g. 300,000 ft/90 km) or satellites in Low Earth orbit. In these cases, statistical mechanics is a more valid method of solving the problem than continuous aerodynamics. The Knudsen number can be used to guide the choice between statistical mechanics and the continuous formulation of aerodynamics.
Conservation laws.
Aerodynamic problems are typically solved using fluid dynamics conservation laws as applied to a fluid continuum. Three conservation principles are used: 
The ideal gas law or another equation of state is often used in conjunction with these equations to form a determined system to solve for the unknown variables.
Branches of aerodynamics.
Aerodynamic problems are classified by the flow environment or properties of the flow, including flow speed, compressibility, and viscosity. "External" aerodynamics is the study of flow around solid objects of various shapes. Evaluating the lift and drag on an airplane or the shock waves that form in front of the nose of a rocket are examples of external aerodynamics. "Internal" aerodynamics is the study of flow through passages in solid objects. For instance, internal aerodynamics encompasses the study of the airflow through a jet engine or through an air conditioning pipe.
Aerodynamic problems can also be classified according to whether the flow speed is below, near or above the speed of sound. A problem is called subsonic if all the speeds in the problem are less than the speed of sound, transonic if speeds both below and above the speed of sound are present (normally when the characteristic speed is approximately the speed of sound), supersonic when the characteristic flow speed is greater than the speed of sound, and hypersonic when the flow speed is much greater than the speed of sound. Aerodynamicists disagree over the precise definition of hypersonic flow; a rough definition considers flows with Mach numbers above 5 to be hypersonic.
The influence of viscosity in the flow dictates a third classification. Some problems may encounter only very small viscous effects on the solution, in which case viscosity can be considered to be negligible. The approximations to these problems are called inviscid flows. Flows for which viscosity cannot be neglected are called viscous flows.
Incompressible aerodynamics.
An incompressible flow is a flow in which density is constant in both time and space. Although all real fluids are compressible, a flow problem is often considered incompressible if the effect of the density changes in the problem on the outputs of interest is small. This is more likely to be true when the flow speeds are significantly lower than the speed of sound. Effects of compressibility are more significant at speeds close to or above the speed of sound. The Mach number is used to evaluate whether the incompressibility can be assumed or the flow must be solved as compressible.
Subsonic flow.
Subsonic (or low-speed) aerodynamics studies fluid motion in flows which are much lower than the speed of sound everywhere in the flow. There are several branches of subsonic flow but one special case arises when the flow is inviscid, incompressible and irrotational. This case is called potential flow and allows the differential equations used to be a simplified version of the governing equations of fluid dynamics, thus making available to the aerodynamicist a range of quick and easy solutions.
In solving a subsonic problem, one decision to be made by the aerodynamicist is whether to incorporate the effects of compressibility. Compressibility is a description of the amount of change of density in the problem. When the effects of compressibility on the solution are small, the aerodynamicist may choose to assume that density is constant. The problem is then an incompressible low-speed aerodynamics problem. When the density is allowed to vary, the problem is called a compressible problem. In air, compressibility effects are usually ignored when the Mach number in the flow does not exceed 0.3 (about 335 feet (102 m) per second or 228 miles (366 km) per hour at 60 °F (16 °C)). Above 0.3, the problem should be solved by using compressible aerodynamics.
Compressible aerodynamics.
According to the theory of aerodynamics, a flow is considered to be compressible if its change in density with respect to pressure is non-zero along a streamline. This means that - unlike incompressible flow - changes in density must be considered. In general, this is the case where the Mach number in part or all of the flow exceeds 0.3. The Mach .3 value is rather arbitrary, but it is used because gas flows with a Mach number below that value demonstrate changes in density with respect to the change in pressure of less than 5%. Furthermore, that maximum 5% density change occurs at the stagnation point of an object immersed in the gas flow and the density changes around the rest of the object will be significantly lower. Transonic, supersonic, and hypersonic flows are all compressible.
Transonic flow.
The term Transonic refers to a range of flow velocities just below and above the local speed of sound (generally taken as Mach 0.8–1.2). It is defined as the range of speeds between the critical Mach number, when some parts of the airflow over an aircraft become supersonic, and a higher speed, typically near Mach 1.2, when all of the airflow is supersonic. Between these speeds, some of the airflow is supersonic, and some is not.
Supersonic flow.
Supersonic aerodynamic problems are those involving flow speeds greater than the speed of sound. Calculating the lift on the Concorde during cruise can be an example of a supersonic aerodynamic problem.
Supersonic flow behaves very differently from subsonic flow. Fluids react to differences in pressure; pressure changes are how a fluid is "told" to respond to its environment. Therefore, since sound is in fact an infinitesimal pressure difference propagating through a fluid, the speed of sound in that fluid can be considered the fastest speed that "information" can travel in the flow. This difference most obviously manifests itself in the case of a fluid striking an object. In front of that object, the fluid builds up a stagnation pressure as impact with the object brings the moving fluid to rest. In fluid traveling at subsonic speed, this pressure disturbance can propagate upstream, changing the flow pattern ahead of the object and giving the impression that the fluid "knows" the object is there and is avoiding it. However, in a supersonic flow, the pressure disturbance cannot propagate upstream. Thus, when the fluid finally does strike the object, it is forced to change its properties -- temperature, density, pressure, and Mach number—in an extremely violent and irreversible fashion called a shock wave. The presence of shock waves, along with the compressibility effects of high-flow velocity (see Reynolds number) fluids, is the central difference between supersonic and subsonic aerodynamics problems.
Hypersonic flow.
In aerodynamics, hypersonic speeds are speeds that are highly supersonic. In the 1970s, the term generally came to refer to speeds of Mach 5 (5 times the speed of sound) and above. The hypersonic regime is a subset of the supersonic regime. Hypersonic flow is characterized by high temperature flow behind a shock wave, viscous interaction, and chemical dissociation of gas.
Associated terminology.
The incompressible and compressible flow regimes produce many associated phenomena, such as boundary layers and turbulence.
Boundary layers.
The concept of a boundary layer is important in many aerodynamic problems. The viscosity and fluid friction in the air is approximated as being significant only in this thin layer. This principle makes aerodynamics much more tractable mathematically.
Turbulence.
In aerodynamics, turbulence is characterized by chaotic, stochastic property changes in the flow. This includes low momentum diffusion, high momentum convection, and rapid variation of pressure and flow velocity in space and time. Flow that is not turbulent is called laminar flow.
Aerodynamics in other fields.
Aerodynamics is important in a number of applications other than aerospace engineering. It is a significant factor in any type of vehicle design, including automobiles. It is important in the prediction of forces and moments in sailing. It is used in the design of mechanical components such as hard drive heads. Structural engineers also use aerodynamics, and particularly aeroelasticity, to calculate wind loads in the design of large buildings and bridges. Urban aerodynamics seeks to help town planners and designers improve comfort in outdoor spaces, create urban microclimates and reduce the effects of urban pollution. The field of environmental aerodynamics studies the ways atmospheric circulation and flight mechanics affect ecosystems. The aerodynamics of internal passages is important in heating/ventilation, gas piping, and in automotive engines where detailed flow patterns strongly affect the performance of the engine.
People who do wind turbine design use aerodynamics.
A few aerodynamic equations are used as part of numerical weather prediction.
Further reading.
General aerodynamics
Subsonic aerodynamics
Transonic aerodynamics
Supersonic aerodynamics
Hypersonic aerodynamics
History of aerodynamics
Aerodynamics related to engineering
"Ground vehicles"
"Fixed-wing aircraft"
"Helicopters"
"Missiles"
"Model aircraft"
Related branches of aerodynamics
"Aerothermodynamics"
"Aeroelasticity"
"Boundary layers"
"Turbulence"

</doc>
<doc id="2820" url="https://en.wikipedia.org/wiki?curid=2820" title="Andreas Schlüter">
Andreas Schlüter

Andreas Schlüter (20 May 1664 – May 1714) was a German baroque sculptor and architect associated with the Petrine Baroque style of architecture and decoration.
Biography.
Andreas Schlüter was born in Hamburg His early life is obscure as at least three different persons of that name are documented. The records of St. Michaelis Church, Hamburg show that an Andreas Schlüter, son of sculptor Gerhart Schlüter, had been baptized there on 22 May 1664. Documents from Danzig (Gdańsk) reported that an Andreas Schlüter "(senior)" had worked 1640-1652 in Danzig's Jopengasse lane (today's ulica Piwna). Possibly born in 1640, an "Andres Schliter" is recorded as apprentice on 9 May 1656 by the mason's guild. Other sources state 1659 as year of birth.
He probably did spend several years abroad as Journeyman. His first work, in 1675, may have been epitaphs of the Dukes Sambor and Mestwin in the dome of Pelplin monastery.
Schlüter's first known work was the decoration of the facade of the St. Johannis Chapel, or Danzig Royal Chapel, in 1681. He later created statues for King John III Sobieski's Wilanów Palace in Warsaw and sepulchral sculptures in Żółkiew (Zhovkva). In 1689, he moved to Warsaw and made the pediment reliefs and sculptural work of Krasiński Palace.
Schlüter was invited to Berlin in 1694 by Eberhard von Danckelmann to work as court sculptor at the armory ("Zeughaus") for Elector Frederick III. His sculpted decorations are a masterpiece of baroque expression and pathos. While the more visible reliefs on the outside had to praise fighting, the statues of dying warriors in the interior denounced war and gave an indication of his pacifist religious beliefs (he is said to have been a Mennonite). Travelling through Italy in 1696, he studied the work of masters like Michelangelo Buonarroti and Gian Lorenzo Bernini.
Schlüter also worked as an architect and built many state buildings in Berlin in his role as "Hofbaumeister" (Court Architect), which he lost when one tower showed signs of a weak fundament. He also served as director of the Akademie der Künste from 1702 to 1704, after which he began concentrating on sculpting again, as "Hofbildhauer" (Court Sculptor). His most important equestrian sculpture is that of the "Great Elector", Frederick William of Brandenburg, cast in 1708 and placed at "Lange Brücke" near the Berlin City Palace, now situated in the honor court before Charlottenburg Palace.
The Berlin City Palace, and many of his works, were partially destroyed by bombing in World War II and by the subsequent Communist regime. A similar fate probably befell the Amber Room, made between 1701 and 1709, Schlüter's most famous work of architecture.
In 1713 Schlüter's fame brought him to work for Tsar Peter the Great in Saint Petersburg, where he died of an illness after creating several designs. Together with Johann Friedrich Braunstein, he designed the Grand Palace and Monplaisir Palace in Peterhof Palace Complex. Also the city's oldest building, Kikin's Palace, and the reliefs at the Summer Palace are attributed to him.

</doc>
<doc id="2822" url="https://en.wikipedia.org/wiki?curid=2822" title="Ash">
Ash

Ash or ashes are the solid remains of fires. Specifically, it refers to all non-aqueous, non-gaseous residues that remains after something is burned. In analytical chemistry, in order to analyse the mineral and metal content of chemical samples, ash is the non-gaseous, non-liquid residue after a complete 100% combustion.
Ashes as the end product of incomplete combustion will be mostly mineral, but usually still contain an amount of combustible organic or other oxidizable residues. The most well-known type of ash is wood ash, as a product of wood combustion in campfires, fireplaces, etc. The darker the wood ashes, the higher the content of remaining charcoal will be due to incomplete combustion.
Like soap, ash is also a disinfecting agent (alkaline). WHO recommended ash or sand as alternative to soap when soap is not available.

</doc>
<doc id="2823" url="https://en.wikipedia.org/wiki?curid=2823" title="Antiderivative">
Antiderivative

In calculus, an antiderivative, primitive function, primitive integral or indefinite integral
of a function is a differentiable function whose derivative is equal to the original function . This can be stated symbolically as ′ . The process of solving for antiderivatives is called antidifferentiation (or indefinite integration) and its opposite operation is called differentiation, which is the process of finding a derivative.
Antiderivatives are related to definite integrals through the fundamental theorem of calculus: the definite integral of a function over an interval is equal to the difference between the values of an antiderivative evaluated at the endpoints of the interval.
The discrete equivalent of the notion of antiderivative is antidifference.
Example.
The function "F"("x") = "x"/3 is an antiderivative of "f"("x") = "x". As the derivative of a constant is zero, "x" will have an infinite number of antiderivatives, such as "x"/3, "x"/3 + 1, "x"/3 - 2, etc. Thus, all the antiderivatives of "x" can be obtained by changing the value of C in "F"("x") = "x"/3 + "C"; where "C" is an arbitrary constant known as the constant of integration. Essentially, the graphs of antiderivatives of a given function are vertical translations of each other; each graph's vertical location depending upon the value of "C".
In physics, the integration of acceleration yields velocity plus a constant. The constant is the initial velocity term that would be lost upon taking the derivative of velocity because the derivative of a constant term is zero. This same pattern applies to further integrations and derivatives of motion (position, velocity, acceleration, and so on).
Uses and properties.
Antiderivatives are important because they can be used to compute definite integrals, using the fundamental theorem of calculus: if "F" is an antiderivative of the integrable function "f" and "f" is continuous over the interval then:
Because of this, each of the infinitely many antiderivatives of a given function "f" is sometimes called the "general integral" or "indefinite integral" of "f" and is written using the integral symbol with no bounds:
If "F" is an antiderivative of "f", and the function "f" is defined on some interval, then every other antiderivative "G" of "f" differs from "F" by a constant: there exists a number "C" such that "G"("x") = "F"("x") + "C" for all "x". "C" is called the arbitrary constant of integration. If the domain of "F" is a disjoint union of two or more intervals, then a different constant of integration may be chosen for each of the intervals. For instance
is the most general antiderivative of formula_4 on its natural domain formula_5
Every continuous function "f" has an antiderivative, and one antiderivative "F" is given by the definite integral of "f" with variable upper boundary:
Varying the lower boundary produces other antiderivatives (but not necessarily all possible antiderivatives). This is another formulation of the fundamental theorem of calculus.
There are many functions whose antiderivatives, even though they exist, cannot be expressed in terms of elementary functions (like polynomials, exponential functions, logarithms, trigonometric functions, inverse trigonometric functions and their combinations). Examples of these are 
"From left to right, the first four are the error function, the Fresnel function, the trigonometric integral, and the logarithmic integral function."
See also Differential Galois theory for a more detailed discussion.
Techniques of integration.
Finding antiderivatives of elementary functions is often considerably harder than finding their derivatives. For some elementary functions, it is impossible to find an antiderivative in terms of other elementary functions. See the articles on elementary functions and nonelementary integral for further information.
There are various methods available:
Computer algebra systems can be used to automate some or all of the work involved in the symbolic techniques above, which is particularly useful when the algebraic manipulations involved are very complex or lengthy. Integrals which have already been derived can be looked up in a table of integrals.
Antiderivatives of non-continuous functions.
Non-continuous functions can have antiderivatives. While there are still open questions in this area, it is known that:
Assuming that the domains of the functions are open intervals:
on the closed interval 'a", "b'. Then "g" must have either a maximum or minimum "c" in the open interval ("a", "b") and so 

</doc>
<doc id="2824" url="https://en.wikipedia.org/wiki?curid=2824" title="Alphabet song">
Alphabet song

An alphabet song is any of various songs used to teach children an alphabet. Alphabet songs typically follow the alphabetic principle (though the phonics method offers variants). In languages such as English with morphophonemic variation (e.g. "cake" is , not ), an alphabet song usually chooses a particular pronunciation for each letter in the alphabet and also typically for some words in the song.
The A.B.C. (Verse 1).
"The A.B.C." or "A.B.Cs" is one of the best-known English language alphabet songs, and perhaps the one most frequently referred to as "the alphabet song", especially in the United States.
The song was first copyrighted in 1835 by the Boston-based music publisher Charles Bradlee, and given the title "The A.B.C., a German air with variations for the flute with an easy accompaniment for the piano forte". The musical arrangement was attributed to Louis Le Maire (sometimes Lemaire), an 18th-century composer. This was "Entered according to act of Congress, in the year 1835, by C. Bradlee, in the clerk's office of the District Court of Massachusetts", according to the Newberry Library, which also says, "The theme is that used by Mozart for his piano variations, Ah, vous dirai-je, maman." This tune is the same as the tune for "Twinkle, Twinkle, Little Star" and "Baa, Baa, Black Sheep".
Lyrics: "(each line represents two measures, or eight beats)"
Zed for Zee.
In the United States, Z is pronounced "zee"; in most other English-speaking countries (such as Canada, UK and Australia) it is pronounced "zed". Generally, the absent "zee"-rhyme is not missed, although some children use a "zee" pronunciation in the rhyme which they would not use elsewhere. Variants of the song exist to accommodate the "zed" pronunciation. One variation shortens the second line and lengthens the last, to form a near-rhyme between N and zed:
Alternate Zed Version:
Another alternate Zed version:
Dutch Version.
Note that the third line is lengthened and the fourth line is shortened, to compensate for the Dutch pronunciations.
Phonics songs.
Because the English language has 40 sounds and only 26 letters, children and beginning readers also need to learn the different sounds (phonemes) associated with each letter. Many songs have been written to teach phonemic awareness and they are usually referred to as alphabet songs.
Acrostic songs.
There are also songs that go through the alphabet, making some of the letters stand for something in the process. An example was recorded in 1948, by Buddy Kaye, Fred Wise, Sidney Lippman, and later Perry Como, called "A, You're Adorable" (also known as "The Alphabet Love Song"):
A newer example of this is from the award winning musical, Matilda. 'School Song' is an acrostic that spells out the alphabet phonetically, which is made more abundant on the second pass through the chorus as the letters are more emphasized.
Backwards song (Verse 2).
The group Wee Sing released an alphabet song with the letters in reverse order. It is called ZYXs. It goes as follows:
Another version ends with "Now I know my ZYXs, let's all go and walk to Texas."
The Canadian children's TV series "The Big Comfy Couch" used a version of the song in the episode "Backwards" (Season 4, episode 1.) 
Comedian Soupy Sales released a song in 1966 called "Backwards Alphabet" which contained the reverse alphabet in lyrical style. The original version of the song was performed by actress Judi Rolin with The Smothers Brothers in the 1966 teleplay adaptation of "Alice Through the Looking Glass".
In the opening scene of the 1992 episode of "Martin", Martin sings the song in the dark radio station in season 1's "Dead Men Don't Flush".

</doc>
<doc id="2826" url="https://en.wikipedia.org/wiki?curid=2826" title="Antigonid dynasty">
Antigonid dynasty

The Antigonid dynasty (; ) was a dynasty of Hellenistic kings descended from Alexander the Great's general Antigonus I Monophthalmus ("the One-eyed").
History.
Succeeding the Antipatrid dynasty in much of Macedonia, Antigonus ruled mostly over Asia Minor and northern Syria. His attempts to take control of the whole of Alexander's empire led to his defeat and death at the Battle of Ipsus in 301 BC. Antigonus's son Demetrius I Poliorcetes survived the battle, and managed to seize control of Macedon itself a few years later, but eventually lost his throne, dying as a prisoner of Seleucus I Nicator. After a period of confusion, Demetrius's son Antigonus II Gonatas was able to establish the family's control over the old Kingdom of Macedon, as well as over most of the Greek city-states, by 276 BC.
Legacy.
It was one of four dynasties established by Alexander's successors, the others being the Seleucid dynasty, Ptolemaic dynasty and Attalid dynasty. The last scion of the dynasty, Perseus of Macedon, who reigned between 179-168 BC, proved unable to stop the advancing Roman legions and Macedon's defeat at the Battle of Pydna signaled the end of the dynasty.
Dynasty.
The ruling members of the Antigonid dynasty were:
The Greek rebel against Rome and last King of Macedonia, Andriscus, claimed to be the son of Perseus.

</doc>
<doc id="2827" url="https://en.wikipedia.org/wiki?curid=2827" title="Abingdon">
Abingdon

Abingdon may refer to the following places:
In Australia :
In Britain:
In Canada:
In the United States:
In the Galapagos Islands:

</doc>
<doc id="2830" url="https://en.wikipedia.org/wiki?curid=2830" title="Abjuration">
Abjuration

Abjuration is the solemn repudiation, abandonment, or renunciation by or upon oath, often the renunciation of citizenship or some other right or privilege. (It comes from the Latin "abjurare", "to forswear").
Abjuration of the realm.
Abjuration of the realm was a type of abjuration in ancient English law. The person taking the oath swore to leave the country directly and promptly, never to return to the kingdom unless by permission of the sovereign. This was often taken by fugitives who had taken sanctuary:
English Commonwealth.
Near the start of the English Civil War, on 18 August 1643 Parliament passed "An Ordinance for Explanation of a former Ordinance for Sequestration of Delinquents Estates with some Enlargements." The enlargements included an oath which became known as the "Oath of Abjuration":
In 1656-7, it was reissued in what was for Catholics an even more objectionable form. Everyone was to be "adjudged a Papist" who refused this oath, and the consequent penalties began with the confiscation of two thirds of the recusant's goods, and went on to deprive him of almost every civic right.
The Catholic Encyclopaedia make the point that the oath and the penalties were so severe that it stopped the efforts of the Gallicanizing party among the English Catholics, who had been ready to offer forms of submission similar to the old oath of Allegiance, which was condemned anew about this time by Pope Innocent X.
Great Britain and Ireland.
In England (and after 1707 Great Britain) the Oath of Abjuration denied the royal title of James II's heirs (i.e. the direct Catholic descendent of the House of Stuart exiled after the Glorious Revolution in 1688). In England, an Oath of Abjuration was taken by Members of Parliament, clergy, and laymen, pledging to support the current British monarch and repudiated the right of the Stuarts and other claimants to the throne. This oath was imposed under William III, George I and George III. It was superseded by the oath of allegiance. In Ireland the oath was imposed of state office holders, teachers and lawyers, and on clergy of the established church in from 1703, the following year it was on all Irish voters and from 1709 it could be demanded of any adult male by a magistrate.
The Netherlands.
Another famous abjuration was brought about by the Plakkaat van Verlatinghe of July 26, 1581, the formal declaration of independence of the Low Countries from the Spanish king, Philip II. This oath was the climax of the Eighty Years' War (Dutch Revolt).

</doc>
<doc id="2833" url="https://en.wikipedia.org/wiki?curid=2833" title="Abitibi">
Abitibi

Abitibi may refer to:

</doc>
<doc id="2834" url="https://en.wikipedia.org/wiki?curid=2834" title="A Vindication of the Rights of Woman">
A Vindication of the Rights of Woman

A Vindication of the Rights of Woman: with Strictures on Political and Moral Subjects (1792), written by the 18th-century British feminist Mary Wollstonecraft, is one of the earliest works of feminist philosophy. In it, Wollstonecraft responds to those educational and political theorists of the 18th century who did not believe women should have an education. She argues that women ought to have an education commensurate with their position in society, claiming that women are essential to the nation because they educate its children and because they could be "companions" to their husbands, rather than mere wives. Instead of viewing women as ornaments to society or property to be traded in marriage, Wollstonecraft maintains that they are human beings deserving of the same fundamental rights as men.
Wollstonecraft was prompted to write the "Rights of Woman" after reading Charles Maurice de Talleyrand-Périgord's 1791 report to the French National Assembly, which stated that women should only receive a domestic education; she used her commentary on this specific event to launch a broad attack against sexual double standards and to indict men for encouraging women to indulge in excessive emotion. Wollstonecraft wrote the "Rights of Woman" hurriedly to respond directly to ongoing events; she intended to write a more thoughtful second volume but died before completing it.
While Wollstonecraft does call for equality between the sexes in particular areas of life, such as morality, she does not explicitly state that men and women are equal. Her ambiguous statements regarding the equality of the sexes have since made it difficult to classify Wollstonecraft as a modern feminist, particularly since the word and the concept were unavailable to her. Although it is commonly assumed now that the "Rights of Woman" was unfavourably received, this is a modern misconception based on the belief that Wollstonecraft was as reviled during her lifetime as she became after the publication of William Godwin's "Memoirs of the Author of A Vindication of the Rights of Woman" (1798). The "Rights of Woman" was actually well received when it was first published in 1792. One biographer has called it "perhaps the most original book of ollstonecraft' century".
Historical context.
"A Vindication of the Rights of Woman" was written against the tumultuous background of the French Revolution and the debates that it spawned in Britain. In a lively and sometimes vicious pamphlet war, now referred to as the "Revolution Controversy", British political commentators addressed topics ranging from representative government to human rights to the separation of church and state, many of these issues having been raised in France first. Wollstonecraft first entered this fray in 1790 with "A Vindication of the Rights of Men", a response to Edmund Burke's "Reflections on the Revolution in France" (1790). In his "Reflections", Burke criticised the view of many British thinkers and writers who had welcomed the early stages of the French revolution. While they saw the revolution as analogous to Britain's own Glorious Revolution in 1688, which had restricted the powers of the monarchy, Burke argued that the appropriate historical analogy was the English Civil War (1642–1651) in which Charles I had been executed in 1649. He viewed the French revolution as the violent overthrow of a legitimate government. In "Reflections" he argues that citizens do not have the right to revolt against their government because civilisation is the result of social and political consensus; its traditions cannot be continually challenged—the result would be anarchy. One of the key arguments of Wollstonecraft's "Rights of Men", published just six weeks after Burke's "Reflections", is that rights cannot be based on tradition; rights, she argues, should be conferred because they are reasonable and just, regardless of their basis in tradition.
When Charles Maurice de Talleyrand-Périgord presented his "Rapport sur l'instruction publique" (1791) to the National Assembly in France, Wollstonecraft was galvanised to respond. In his recommendations for a national system of education, Talleyrand had written:
Let us bring up women, not to aspire to advantages which the Constitution denies them, but to know and appreciate those which it guarantees them . . . Men are destined to live on the stage of the world. A public education suits them: it early places before their eyes all the scenes of life: only the proportions are different. The paternal home is better for the education of women; they have less need to learn to deal with the interests of others, than to accustom themselves to a calm and secluded life.
Wollstonecraft dedicated the "Rights of Woman" to Talleyrand: "Having read with great pleasure a pamphlet which you have lately published, I dedicate this volume to you; to induce you to reconsider the subject, and maturely weigh what I have advanced respecting the rights of woman and national education." At the end of 1791, French feminist Olympe de Gouges had published her "Declaration of the Rights of Woman and the Female Citizen", and the question of women's rights became central to political debates in both France and Britain.
The "Rights of Woman" is an extension of Wollstonecraft's arguments in the "Rights of Men". In the "Rights of Men", as the title suggests, she is concerned with the rights of particular men (18th-century British men) while in the "Rights of Woman", she is concerned with the rights afforded to "woman", an abstract category. She does not isolate her argument to 18th-century women or British women. The first chapter of the "Rights of Woman" addresses the issue of natural rights and asks who has those inalienable rights and on what grounds. She answers that since natural rights are given by God, for one segment of society to deny them to another segment is a sin. "The Rights of Woman" thus engages not only specific events in France and in Britain but also larger questions being raised by political philosophers such as John Locke and Jean-Jacques Rousseau.
Themes of writings.
Wollstonecraft did not employ the formal argumentation or logical prose style common to 18th-century philosophical writing when composing her own works. The "Rights of Woman" is a long essay that introduces all of its major topics in the opening chapters and then repeatedly returns to them, each time from a different point of view. It also adopts a hybrid tone that combines rational argument with the fervent rhetoric of sensibility.
In the 18th century, "sensibility" was a physical phenomenon that came to be attached to a specific set of moral beliefs. Physicians and anatomists believed that the more sensitive people's nerves, the more emotionally affected they would be by their surroundings. Since women were thought to have keener nerves than men, it was also believed that women were more emotional than men. The emotional excess associated with sensibility also theoretically produced an ethic of compassion: those with sensibility could easily sympathise with people in pain. Thus historians have credited the discourse of sensibility and those who promoted it with the increased humanitarian efforts, such as the movement to abolish the slave trade. But sensibility also paralysed those who had too much of it; as scholar G. J. Barker-Benfield explains, "an innate refinement of nerves was also identifiable with greater suffering, with weakness, and a susceptibility to disorder".
By the time Wollstonecraft was writing the "Rights of Woman", sensibility had already been under sustained attack for a number of years. Sensibility, which had initially promised to draw individuals together through sympathy, was now viewed as "profoundly separatist"; novels, plays, and poems that employed the language of sensibility asserted individual rights, sexual freedom, and unconventional familial relationships based only upon feeling. Furthermore, as Janet Todd, another scholar of sensibility, argues, "to many in Britain the cult of sensibility seemed to have feminized the nation, given women undue prominence, and emasculated men."
Rational education.
One of Wollstonecraft's central arguments in the "Rights of Woman" is that women should be educated rationally to give them the opportunity to contribute to society. In the 18th century, it was often assumed by both educational philosophers and conduct book writers, who wrote what one might think of as early self-help books, that women were incapable of rational or abstract thought. Women, it was believed, were too susceptible to sensibility and too fragile to be able to think clearly. Wollstonecraft, along with other female reformers such as Catharine Macaulay and Hester Chapone, maintained that women were indeed capable of rational thought and deserved to be educated. She argued this point in her own conduct book, "Thoughts on the Education of Daughters" (1787), in her children's book, "Original Stories from Real Life" (1788), as well as in the "Rights of Woman".
Stating in her preface that "my main argument is built on this simple principle, that if oma be not prepared by education to become the companion of man, she will stop the progress of knowledge and virtue; for truth must be common to all", Wollstonecraft contends that society will degenerate without educated women, particularly because mothers are the primary educators of young children. She attributes the problem of uneducated women to men and "a false system of education, gathered from the books written on this subject by men who onside females rather as women than human creatures". Women are capable of rationality; it only appears that they are not, because men have refused to educate them and encouraged them to be frivolous (Wollstonecraft describes silly women as "spaniels" and "toys"). While stressing it is of the same kind, she entertains the notion that women might not be able to attain the same degree of knowledge that men do.
Wollstonecraft attacks conduct book writers such as James Fordyce and John Gregory as well as educational philosophers such as Jean-Jacques Rousseau who argue that a woman does not need a rational education. (Rousseau famously argues in "" (1762) that women should be educated for the pleasure of men; Wollstonecraft, infuriated by this argument, attacks not only it but also Rousseau himself.) Intent on illustrating the limitations that contemporary educational theory placed upon women, Wollstonecraft writes, "taught from their infancy that beauty is woman's sceptre, the mind shapes itself to the body, and, roaming round its gilt cage, only seeks to adorn its prison", implying that without this damaging ideology, which encourages young women to focus their attention on beauty and outward accomplishments, they could achieve much more. Wives could be the rational "companions" of their husbands and even pursue careers should they so choose: "women might certainly study the art of healing, and be physicians as well as nurses. And midwifery, decency seems to allot to them . . . they might, also, study politics . . . Business of various kinds, they might likewise pursue."
For Wollstonecraft, "the most perfect education" is "an exercise of the understanding as is best calculated to strengthen the body and form the heart. Or, in other words, to enable the individual to attach such habits of virtue as will render it independent." In addition to her broad philosophical arguments, Wollstonecraft lays out a specific plan for national education to counter Talleyrand's. In Chapter 12, "On National Education," she proposes that children be sent to day schools as well as given some education at home "to inspire a love of home and domestic pleasures," and that such schools be free for children "five to nine years of age." She also maintains that schooling should be co-educational, contending that men and women, whose marriages are "the cement of society," should be "educated after the same model."
Feminism writings.
It is debatable to what extent the "Rights of Woman" is a feminist text; because the definitions of "feminist" vary, different scholars have come to different conclusions. Wollstonecraft would never have referred to her text as feminist because the words "feminist" and "feminism" were not coined until the 1890s. Moreover, there was no feminist movement to speak of during Wollstonecraft's lifetime. In the introduction to her seminal work on Wollstonecraft's thought, Barbara Taylor writes:
Describing ollstonecraft's philosoph as feminist is problematic, and I do it only after much consideration. The label is of course anachronistic . . . Treating Wollstonecraft's thought as an anticipation of nineteenth and twentieth-century feminist argument has meant sacrificing or distorting some of its key elements. Leading examples of this . . . have been the widespread neglect of her religious beliefs, and the misrepresentation of her as a bourgeois liberal, which together have resulted in the displacement of a religiously inspired utopian radicalism by a secular, class-partisan reformism as alien to Wollstonecraft's political project as her dream of a divinely promised age of universal happiness is to our own. Even more important however has been the imposition on Wollstonecraft of a heroic-individualist brand of politics utterly at odds with her own ethically driven case for women's emancipation. Wollstonecraft's leading ambition for women was that they should attain virtue, and it was to this end that she sought their liberation.
In the "Rights of Woman", Wollstonecraft does not make the claim for gender equality using the same arguments or the same language that late 19th- and 20th century feminists later would. For instance, rather than unequivocally stating that men and women are equal, Wollstonecraft contends that men and women are equal in the eyes of God, which means that they are both subject to the same moral law. For Wollstonecraft, men and women are equal in the most important areas of life. While such an idea may not seem revolutionary to 21st-century readers, its implications were revolutionary during the 18th century. For example, it implied that both men and women—not just women—should be modest and respect the sanctity of marriage. Wollstonecraft's argument exposed the sexual double standard of the late 18th century and demanded that men adhere to the same virtues demanded of women.
However, Wollstonecraft's arguments for equality stand in contrast to her statements respecting the superiority of masculine strength and valour. Wollstonecraft famously and ambiguously states:
Let it not be concluded, that I wish to invert the order of things; I have already granted, that, from the constitution of their bodies, men seem to be designed by Providence to attain a greater degree of virtue. I speak collectively of the whole sex; but I see not the shadow of a reason to conclude that their virtues should differ in respect to their nature. In fact, how can they, if virtue has only one eternal standard? I must therefore, if I reason consequentially, as strenuously maintain that they have the same simple direction, as that there is a God.
Moreover, Wollstonecraft calls on men, rather than women, to initiate the social and political changes she outlines in the "Rights of Woman". Because women are uneducated, they cannot alter their own situation—men must come to their aid. Wollstonecraft writes at the end of her chapter "Of the Pernicious Effects Which Arise from the Unnatural Distinctions Established in Society":
I then would fain convince reasonable men of the importance of some of my remarks; and prevail on them to weigh dispassionately the whole tenor of my observations. – I appeal to their understandings; and, as a fellow-creature, claim, in the name of my sex, some interest in their hearts. I entreat them to assist to emancipate their companion, to make her a help meet for them! Would men but generously snap our chains, and be content with rational fellowship instead of slavish obedience, they would find us more observant daughters, more affectionate sisters, more faithful wives, more reasonable mothers – in a word, better citizens.
It is Wollstonecraft's last novel, "" (1798), the fictionalised sequel to the "Rights of Woman", that is usually considered her most radical feminist work.
Sensibility.
One of Wollstonecraft's most scathing criticisms in the "Rights of Woman" is against false and excessive sensibility, particularly in women. She argues that women who succumb to sensibility are "blown about by every momentary gust of feeling"; because these women are "the prey of their senses", they cannot think rationally. In fact, not only do they do harm to themselves but they also do harm to all of civilisation: these are not women who can refine civilisation – these are women who will destroy it. But reason and feeling are not independent for Wollstonecraft; rather, she believes that they should inform each other. For Wollstonecraft, as for the important 18th-century philosopher David Hume, the passions underpin all reason. This was a theme that she would return to throughout her career, but particularly in her novels ' (1788) and '.
As part of her argument that women should not be overly influenced by their feelings, Wollstonecraft emphasises that they should not be constrained by or made slaves to their bodies or their sexual feelings. This particular argument has led many modern feminists to suggest that Wollstonecraft intentionally avoids granting women any sexual desire. Cora Kaplan argues that the "negative and prescriptive assault on female sexuality" is a "leitmotif" of the "Rights of Woman". For example, Wollstonecraft advises her readers to "calmly let passion subside into friendship" in the ideal companionate marriage (that is, in the ideal of a love-based marriage that was developing at the time). It would be better, she writes, when "two virtuous young people marry . . . if some circumstances checked their passion". According to Wollstonecraft, "love and friendship cannot subsist in the same bosom". As Mary Poovey explains, "Wollstonecraft betrays her fear that female desire might in fact court man's lascivious and degrading attentions, that the subordinate position women have been given might even be deserved. Until women can transcend their fleshly desires and fleshly forms, they will be hostage to the body." If women are not interested in sexuality, they cannot be dominated by men. Wollstonecraft worries that women are consumed with "romantic wavering", that is, they are interested only in satisfying their lusts. Because the "Rights of Woman" eliminates sexuality from a woman's life, Kaplan contends, it "expresses a violent antagonism to the sexual" while at the same time "exaggeratn the importance of the sensual in the everyday life of women". Wollstonecraft was so determined to wipe sexuality from her picture of the ideal woman that she ended up foregrounding it by insisting upon its absence. But as Kaplan and others have remarked, Wollstonecraft may have been forced to make this sacrifice: "it is important to remember that the notion of woman as politically enabled and independent a fatally linked uring the eighteenth centur to the unrestrained and vicious exercise of her sexuality."
Republicanism.
Claudia Johnson, a prominent Wollstonecraft scholar, has called the "Rights of Woman" "a republican manifesto". Johnson contends that Wollstonecraft is hearkening back to the Commonwealth tradition of the 17th century and attempting to reestablish a republican ethos. In Wollstonecraft's version, there would be strong, but separate, masculine and feminine roles for citizens. According to Johnson, Wollstonecraft "denounces the collapse of proper sexual distinction as the leading feature of her age, and as the grievous consequence of sentimentality itself. The problem undermining society in her view is feminized men". If men feel free to adopt both the masculine position and the sentimental feminine position, she argues, women have no position open to them in society. Johnson therefore sees Wollstonecraft as a critic, in both the "Rights of Men" and the "Rights of Woman", of the "masculinization of sensitivity" in such works as Edmund Burke's "Reflections on the Revolution in France".
In the "Rights of Woman" Wollstonecraft adheres to a version of republicanism that includes a belief in the eventual overthrow of all titles, including the monarchy. She also briefly suggests that all men and women should be represented in government. But the bulk of her "political criticism," as Chris Jones, a Wollstonecraft scholar, explains, "is couched predominantly in terms of morality". Her definition of virtue focuses on the individual's happiness rather than, for example, the good of the entire society. This is reflected in her explanation of natural rights. Because rights ultimately proceed from God, Wollstonecraft maintains that there are duties, tied to those rights, incumbent upon each and every person. For Wollstonecraft, the individual is taught republicanism and benevolence within the family; domestic relations and familial ties are crucial to her understanding of social cohesion and patriotism.
Class.
In many ways the "Rights of Woman" is inflected by a bourgeois view of the world, as is its direct predecessor the "Rights of Men". Wollstonecraft addresses her text to the middle class, which she calls the "most natural state". She also frequently praises modesty and industry, virtues which, at the time, were associated with the middle class. From her position as a middle-class writer arguing for a middle-class ethos, Wollstonecraft also attacks the wealthy, criticising them using the same arguments she employs against women. She points out the "false-refinement, immorality, and vanity" of the rich, calling them "weak, artificial beings, raised above the common wants and affections of their race, in a premature unnatural manner h undermine the very foundation of virtue, and spread corruption through the whole mass of society".
But Wollstonecraft's criticisms of the wealthy do not necessarily reflect a concomitant sympathy for the poor. For her, the poor are fortunate because they will never be trapped by the snares of wealth: "Happy is it when people have the cares of life to struggle with; for these struggles prevent their becoming a prey to enervating vices, merely from idleness!" Moreover, she contends that charity has only negative consequences because, as Jones puts it, she "sees it as sustaining an unequal society while giving the appearance of virtue to the rich".
In her national plan for education, she retains class distinctions (with an exception for the intelligent), suggesting that: "After the age of nine, girls and boys, intended for domestic employments, or mechanical trades, ought to be removed to other schools, and receive instruction, in some measure appropriated to the destination of each individual . . . The young people of superior abilities, or fortune, might now be taught, in another school, the dead and living languages, the elements of science, and continue the study of history and politics, on a more extensive scale, which would not exclude polite literature."
Rhetoric and style.
In attempting to navigate the cultural expectations of female writers and the generic conventions of political and philosophical discourse, Wollstonecraft, as she does throughout her "oeuvre", constructs a unique blend of masculine and feminine styles in the "Rights of Woman". She utilises the language of philosophy, referring to her work as a "treatise" with "arguments" and "principles". However, Wollstonecraft also uses a personal tone, employing "I" and "you", dashes and exclamation marks, and autobiographical references to create a distinctly feminine voice in the text. The "Rights of Woman" further hybridizes its genre by weaving together elements of the conduct book, the short essay, and the novel, genres often associated with women, while at the same time claiming that these genres could be used to discuss philosophical topics such as rights.
Although Wollstonecraft argues against excessive sensibility, the rhetoric of the "Rights of Woman" is at times heated and attempts to provoke the reader. Many of the most emotional comments in the book are directed at Rousseau. For example, after excerpting a long passage from "" (1762), Wollstonecraft pithily states, "I shall make no other comments on this ingenious passage, than just to observe, that it is the philosophy of lasciviousness." A mere page later, after indicting Rousseau's plan for female education, she writes "I must relieve myself by drawing another picture." These terse exclamations are meant to draw the reader to her side of the argument (it is assumed that the reader will agree with them). While she claims to write in a plain style so that her ideas will reach the broadest possible audience, she actually combines the plain, rational language of the political treatise with the poetic, passionate language of sensibility to demonstrate that one can combine rationality and sensibility in the same self. Wollstonecraft defends her positions not only with reasoned argument but also with ardent rhetoric.
In her efforts to vividly describe the condition of women within society, Wollstonecraft employs several different analogies. She often compares women to slaves, arguing that their ignorance and powerlessness places them in that position. But at the same time, she also compares them to "capricious tyrants" who use cunning and deceit to manipulate the men around them. At one point, she reasons that a woman can become either a slave or tyrant, which she describes as two sides of the same coin. Wollstonecraft also compares women to soldiers; like military men, they are valued only for their appearance. And like the rich, women's "softness" has "debased mankind".
Revision.
Wollstonecraft was forced to write the "Rights of Woman" hurriedly to respond to Talleyrand and ongoing events. Upon completing the work, she wrote to her friend William Roscoe: "I am dissatisfied with myself for not having done justice to the subject. – Do not suspect me of false modesty – I mean to say that had I allowed myself more time I could have written a better book, in every sense of the word . . . I intend to finish the next volume before I begin to print, for it is not pleasant to have the Devil coming for the conclusion of a sheet fore it is written." When Wollstonecraft revised the "Rights of Woman" for the second edition, she took the opportunity not only to fix small spelling and grammar mistakes but also to bolster the feminist claims of her argument. She changed some of her statements regarding female and male difference to reflect a greater equality between the sexes.
Wollstonecraft never wrote the second part to the "Rights of Woman," although William Godwin published her "Hints", which were "chiefly designed to have been incorporated in the second part of the "Vindication of the Rights of Woman", in the posthumous collection of her works. However, she did begin writing the novel ", which most scholars consider a fictionalised sequel to the "Rights of Woman". It was unfinished at her death and also included in the "Posthumous Works" published by Godwin.
Reception and legacy.
When it was first published in 1792, the "Rights of Woman" was reviewed favourably by the "Analytical Review", the "General Magazine", the "Literary Magazine", "New York Magazine", and the "Monthly Review", although the assumption persists even today that "Rights of Woman" received hostile reviews. It was almost immediately released in a second edition in 1792, several American editions appeared, and it was translated into French. Taylor writes that "it was an immediate success". Moreover, other writers such as Mary Hays and Mary Robinson specifically alluded to Wollstonecraft's text in their own works. Hays cited the "Rights of Woman" in her novel "Memoirs of Emma Courtney" (1796) and modelled her female characters after Wollstonecraft's ideal woman. Although female conservatives such as Hannah More excoriated Wollstonecraft personally, they actually shared many of the same values. As the scholar Anne Mellor has shown, both More and Wollstonecraft wanted a society founded on "Christian virtues of rational benevolence, honesty, personal virtue, the fulfillment of social duty, thrift, sobriety, and hard work". During the early 1790s, many writers within British society were engaged in an intense debate regarding the position of women in society. For example, the respected poet and essayist Anna Laetitia Barbauld and Wollstonecraft sparred back and forth; Barbauld published several poems responding to Wollstonecraft's work and Wollstonecraft commented on them in footnotes to the "Rights of Woman". The work also provoked outright hostility. The bluestocking Elizabeth Carter was unimpressed with the work. Thomas Taylor, the Neoplatonist translator who had been a landlord to the Wollstonecraft family in the late 1770s, swiftly wrote a satire called "A Vindication of the Rights of Brutes": if women have rights, why not animals too?
After Wollstonecraft died in 1797, her husband William Godwin published his "Memoirs of the Author of A Vindication of the Rights of Woman" (1798). He revealed much about her private life that had previously not been known to the public: her illegitimate child, her love affairs, and her attempts at suicide. While Godwin believed he was portraying his wife with love, sincerity, and compassion, contemporary readers were shocked by Wollstonecraft's unorthodox lifestyle and she became a reviled figure. Richard Polwhele targeted her in particular in his anonymous long poem "The Unsex'd Females" (1798), a defensive reaction to women's literary self-assertion: Hannah More is Christ to Wollstonecraft's Satan. His poem was "well known" among the responses "A Vindication". One reviewer comments this "ingenious poem" with its "playful sallies of sarcastic wit" against "our modern ladies," though others found it "a tedious, lifeless piece of writing." Critical responses largely fell along clear-cut political lines.
Wollstonecraft's ideas became associated with her life story and women writers felt that it was dangerous to mention her in their texts. Hays, who had previously been a close friend and an outspoken advocate for Wollstonecraft and her "Rights of Woman", for example, did not include her in the collection of "Illustrious and Celebrated Women" she published in 1803. Maria Edgeworth specifically distances herself from Wollstonecraft in her novel "Belinda" (1802); she caricatures Wollstonecraft as a radical feminist in the character of Harriet Freke. But, like Jane Austen, she does not reject Wollstonecraft's ideas. Both Edgeworth and Austen argue that women are crucial to the development of the nation; moreover, they portray women as rational beings who should choose companionate marriage.
The negative views towards Wollstonecraft persisted for over a century. The "Rights of Woman" was not reprinted until the middle of the 19th century and it still retained an aura of ill-repute. George Eliot wrote "there is in some quarters a vague prejudice against the "Rights of Woman" as in some way or other a reprehensible book, but readers who go to it with this impression will be surprised to find it eminently serious, severely moral, and withal rather heavy".
The suffragist (i.e. moderate reformer, as opposed to suffragette) Millicent Garrett Fawcett wrote the introduction to the centenary edition of the "Rights of Woman", cleansing the memory of Wollstonecraft and claiming her as the foremother of the struggle for the vote. While the "Rights of Woman" may have paved the way for feminist arguments, 20th century feminists have tended to use Wollstonecraft's life story, rather than her texts, for inspiration; her unorthodox lifestyle convinced them to try new "experiments in living", as Virginia Woolf termed it in her famous essay on Wollstonecraft. However, there is some evidence that the "Rights of Woman" may be influencing current feminists. Ayaan Hirsi Ali, a feminist who is critical of Islam's dictates regarding women, cites the "Rights of Woman" in her autobiography "Infidel", writing that she was "inspired by Mary Wollstonecraft, the pioneering feminist thinker who told women they had the same ability to reason as men did and deserved the same rights".

</doc>
<doc id="2835" url="https://en.wikipedia.org/wiki?curid=2835" title="Afghan Hound">
Afghan Hound

The Afghan Hound is a hound that is distinguished by its thick, fine, silky coat and its tail with a ring curl at the end. The breed acquired its unique features in the cold mountains of Afghanistan. Its local name is Tāžī Spay () or Sag-e shekâri (Dari Persian: سگ تازی). Other alternate names for this breed are "Kuchi Hound", "Tāzī", "Balkh Hound", "Baluchi Hound", "Barutzy Hound", "Shalgar Hound", "Kabul Hound", "Galanday Hound", or sometimes incorrectly "African Hound".
History.
The Afghan Hound has been identified as a basal breed that predates the emergence of the modern breeds in the 19th Century.
Today's modern purebred breed of Afghan Hound descends from dogs brought to Great Britain in the 1920s which King Amanullah of the Afghan Royal Family gave away as gifts. Some had been kept as hunting dogs, others as guardians.
Although the breed is demonstrably ancient, verifiable written or visual records that tie today's Afghan Hound breed to specific Afghan owners or places are absent. There is much speculation about the breeds origin and possible connections with the ancient world among fanciers and in non-scientific breed books and breed websites. Connections with other types and breeds from the same area may provide clues to the history. A name for a desert coursing Afghan hound, Tazi (sag-e-tazi), suggests a shared ancestry with the very similar Tasy breed from the Caspian Sea area of Russia and Turkmenistan.Other types or breeds of similar appearance are the Taigan from the mountainous Tian Shan region on the Chinese border of Afghanistan, and the Barakzay, or Kurram Valley Hound. 
There are at least 13 types known in Afghanistan, and some are being developed (through breeding and recordkeeping) into modern purebred breeds. As the lives of the peoples with whom these dogs developed change in the modern world, often these landrace types of dogs lose their use and disappear; there may have been many more types of longhaired sighthound in the past.
Once out of Afghanistan, the history of the Afghan Hound breed becomes an important part of the history of the very earliest dog shows and The Kennel Club (UK). Various sighthounds were brought to England in the 1800s by army officers returning from British India (which at the time included), Afghanistan, and Persia, and were exhibited at dog shows, which were then just becoming popular, under various names, such as Barukzy hounds. They were also called "Persian Greyhounds" by the English, in reference to their own indigenous sighthound.
One dog in particular, "Zardin", was brought in 1907 from India by Captain Bariff, and became the early ideal of breed type for what was still called the Persian Greyhound. Zardin was the basis of the writing of the first breed standard in 1912, but breeding of the dogs was stopped by World War I.
Out of the longhaired sighthound types known in Afghanistan, two main strains make up the modern Afghan Hound breed. The first were a group of hounds brought to Scotland from Baluchistan by Major and Mrs. G. Bell-Murray and Miss Jean C. Manson in 1920, and are called the "Bell-Murray strain".
These dogs were of the lowland or steppe type, also called kalagh, and are less heavily coated. The second strain was a group of dogs from a kennel in Kabul owned by Mrs. Mary Amps, which she shipped to England in 1925. She and her husband came to Kabul after the Afghan war in 1919, and the foundation sire of her kennel (named Ghazni) in Kabul was a dog that closely resembled Zardin. Her "Ghazni strain" were the more heavily coated mountain type. Most of the Afghans in the United States were developed from the Ghazni strain from England. The first Afghans in Australia were imported from the United States in 1934, also of the Ghazni strain. The French breed club was formed in 1939 (FALAPA). The mountain and steppe strains became mixed into the modern Afghan Hound breed, and a new standard was written in 1948, which is still used today.
The spectacular beauty of Afghan Hound dogs caused them to become highly desirable showdogs and pets, and they are recognised by all of the major kennel clubs in the English-speaking world. One of the Amps Ghazni, "Sirdar", won BIS at Crufts in 1928 and 1930. An Afghan hound was featured on the cover of Life Magazine, November 26, 1945. "Afghan Hounds were the most popular in Australia in the 1970s…and won most of the major shows". An Afghan Hound won BIS (Best in Show) at the 1996 World Dog Show in Budapest. Afghan hounds were BIS at the Westminster Kennel Club Dog Show in 1957 and again in 1983. That win also marked the most recent win at Westminster for breeder-owner-handler, Chris Terrell.
The Afghan Hound breed is no longer used for hunting, although it can be seen in the sport of lure coursing.
Descriptions.
The Afghan Hound is tall, standing in height 61–74 cm (24–29 inches) and weighing 20–27 kg (45–60 pounds). The coat may be any colour, but white markings, particularly on the head, are discouraged; many individuals have a black facial mask. A specimen may have facial hair that looks like a Fu Manchu moustache. The moustache is called "mandarins." Some Afghan Hounds are almost white, but parti-colour hounds (white with islands of red or black) are not acceptable and may indicate impure breeding. The long, fine-textured coat requires considerable care and grooming. The long topknot and the shorter-haired saddle on the back of the dog are distinctive features of the Afghan Hound coat. The high hipbones and unique small ring on the end of the tail are also characteristics of the breed.
The temperament of the typical Afghan Hound can be aloof and dignified, but happy and clownish when it's playing. This breed, as is the case with many sighthounds, has a high prey drive and may not get along with small animals. The Afghan Hound can be a successful competitor in dog agility trials as well as an intuitive therapy dog and companion. Genomic studies have pointed to the Afghan Hound as one of the oldest of dog breeds.
The breed has a reputation among some dog trainers of having a relatively slow "obedience intelligence" as defined by author Stanley Coren in "The Intelligence of Dogs".
Although seldom used today for hunting in Europe and America where they are popular, Afghan hounds are frequent participants in lure coursing events and are also popular in the sport of conformation showing.
Variants.
The Khalag Tazi is a variety of the Afghan. It was introduced to Europe in 1920 when an Indian Army officer, Major G Bell-Murray, brought some animals back from Afghanistan. "Tazi" is a current and ancient name for hunting dogs of the sighthound type in the Middle East. It has been used to denote the Saluki, Afghan, Taigan, Persian Greyhound, greyhound types of hound.
Health.
Lifespan.
Afghan Hounds in UK surveys had a median lifespan of about 12 years. which is similar to other breeds of their size. In the 2004 UK Kennel Club survey, the most common causes of death were cancer (31%), old age (20%), cardiac (10.5%), and urologic (5%). Those that die of old age had an average lifespan of 13 to 14 1/2 years.
Health concerns.
Major health issues are allergies, cancer, and hip dysplasia. Sensitivity to anesthesia is an issue the Afghan hound shares with the rest of the sighthound group, as sighthounds have relatively low levels of body fat. Afghan hounds are also among the dog breeds most likely to develop chylothorax, a rare condition which causes the thoracic ducts to leak, allowing large quantities of chyle fluid to enter the dog's chest cavity. This condition commonly results in a lung torsion (in which the dog's lung twists within the chest cavity, requiring emergency surgery), due to the breed's typically deep, "barrel"-shaped chest. If not corrected through surgery, chylothorax can ultimately cause fibrosing pleuritis, or a hardening of the organs, due to scar tissue forming around the organs to protect them from the chyle fluid. Chylothorax is not necessarily, but often, fatal.
In popular culture.
Because of its distinctive appearance, the Afghan hound has been represented in animated feature films and TV shows, including Universal Pictures' "Balto" (Sylvie), Disney's ' (Ruby), an Afghan hound also appeared on "101 Dalmatians" as well as in "102 Dalmatians" as one of the dogs in Cruella De Vil's party and the television series What-a-Mess (Prince Amir of Kinjan; based on children's books by Frank Muir) and, as Prissy in the 1961 Disney animated film "One Hundred and One Dalmatians" and '. Brainy Barker from "Krypto the Superdog" claims to be an Afghan Hound in the episode "Meet the Dog Stars", although her design actually resembles that of a Saluki instead of an Afghan.
Afghan hounds have also been featured in television advertisements and in fashion magazines. The Afghan hound is represented in books as well, including being featured in a series of mystery novels by Nina Wright (Abra), and a talking Afghan Hound in David Rothman's "The Solomon Scandals" (2008, Twilight Times Books). In the novel "Between the Acts", Virginia Woolf uses an Afghan hound (named Sohrab) to represent aspects of one of the book's human characters.
On August 3, 2005, Korean scientist Hwang Woo-Suk announced that his team of researchers had become the first team to successfully clone a dog, an Afghan Hound named Snuppy. In 2006 Hwang Woo-Suk was dismissed from his university position for fabricating data in his research. Snuppy, nonetheless, was a genuine clone, and thus the first cloned dog in history.
The Afghan Hound features prominently in the avant-garde music video of popular French band M83's, "Set in Stone (M83 Remix)".

</doc>
<doc id="2836" url="https://en.wikipedia.org/wiki?curid=2836" title="Azawakh">
Azawakh

The Azawakh is a sighthound dog breed from Africa.
Description.
Appearance.
Morphology is very similar to that of the Middle Eastern and South Indian sight hounds, all swift, high-bred coursing hounds, although there are several obvious differences. For example, a short, flat back combined with long legs place the hips higher than the withers. The Azawakh is almond eyed and thin. It moves with a distinctly feline gait and can be found in a variety of colors as well as varying degrees of refinement, though format is basically constant.
Height and weight.
The standards call for a hound from ; its height is . The coat is very short and almost absent on the belly. Its bone structure shows clearly through the skin and musculature. Its muscles are "dry", meaning that they are quite flat, unlike the Greyhound and Whippet. In this respect it is similar in type to the Saluki.
Colors.
In Africa, Azawakh are found in a variety of colors such as red, blue fawn (that is, with a lilac cast), grizzle, and, rarely, blue and black. The Azawakh in its native land also comes with various white markings including Irish marked (white collar) and particolour (mostly white). Because of this wide color variation in the native population, the American standard used by the AKC and UKC allows any color combination found in Africa. In the United States, the FCI standard is modified to have no color restrictions at a minimum and there is a strong sentiment that the FCI standard should be heavily edited or replaced.
Colors permitted by the FCI breed standard are clear sand to dark fawn/brown, red and brindle (with or without a dark mask), with white bib, tail tip, and white on all feet (which can be tips of toes to high stockings). Currently, white stockings that go above the elbow joint are considered disqualifying features in France, as is a white collar or half collar (Irish marked).
Movement.
The Azawakh's light, supple, lissome gait is a notable breed characteristic, as is an upright double suspension gallop.
Health.
Azawakhs are an incredibly sound coursing hound. Serious coursing injuries are rare. The dogs heal very quickly from injury.
Azawakh have no known incidence of hip dysplasia. There is a small occurrence of adult-onset idiopathic epilepsy in the breed. Wobbler disease, or cervical vertebral instability, does rarely occur. Some breeders believe this is largely a developmental problem where puppies grow too quickly due to a high-protein Western diet.
Reproduction.
Like the Basenji and Tibetan Mastiff, the Azawakh often has a single annual estrus. Unassisted birth of healthy puppies is normal. Litter sizes are usually from four to six puppies, but litters as small as one and as large as ten occur.
Care.
Azawakh need a fairly high level of exercise and should have regular runs off lead in large enclosed areas to run off steam. The dogs are very social and emotional. They need a master that provides firm but fair leadership. Azawakh thrive on companionship of other Azawakh.
Temperament.
Unlike other sighthounds, the primary function of the Azawakh in its native land is that of protector. It develops an intense bond with its owner, yet can perform independently from its master. With those they accept, Azawakh are gentle and extremely affectionate. With strangers many are reserved and prefer not to be touched, but are not inherently aggressive. Although raised to protect livestock, they do not have innate aggression toward canines or humans unless they are threatened. 
Azawakh have high energy and tremendous endurance. They are excellent training companions for runners and are nearly impervious to heat. They will happily run in weather over 100 degrees Fahrenheit that would kill a Greyhound.
Many Azawakh dislike rain and cold weather.
Azawakh are pack oriented and form complex social hierarchies. They have tremendous memories and are able to recognize each other after long periods of separation. They can often be found sleeping on top of each other for warmth and companionship.
Alberto Rossi: "To raise an Azawakh is like building a very fragile construction, which takes a lot of sensibility and can be destroyed from one minute to the next. But every minute it lasts, it fills you with great happiness." Every time I´m sitting in a chair or sofa at least one of my dogs tries to take a seat on my lap. The same happens to those of my guests which they love. In these moments they seem to be the image of calmness, gentleness, and trust. But one should not be deceived about this. In the deepest place of their soul resides something wild and native, and they will remind us about it with the first occasion and we should not forget, even for a moment, not to treat them like a normal dog."
History.
Bred by the Tuareg, Fula and various other nomads of the Sahara and sub-Saharan Sahel in the countries of Mali, Niger, Burkina Faso, and southern Algeria, the breed is used there as a guard dog and to hunt gazelle and hare at speeds up to 40 miles per hour. The austerity of the Sahel environment has ensured that only the most fit dogs survive and has accentuated the breed's ruggedness and independence. Unlike some other sighthounds, the Azawakh is more of a pack hunter and they bump down the quarry with hindquarters when it has been tired out. In role of a guard dog, if an Azawakh senses danger it will bark to alert the other members of the pack, and they will gather together as a pack under the lead of the alpha dog, then chase off or attack the predator. The Sloughi, by comparison, is more of an independent lone hunter and has a high hunting instinct.
They are relatively uncommon in Europe and North America but there is a growing band of devotees. Azawakhs have a range of temperaments from lap dog to quite fierce. Lifelong socialization and firm but gentle handling are critical. Well socialised and trained, they can be good with other dogs, cats, children, and strangers. Azawakh may be registered with the FCI in the USA via the Federación Canófila de Puerto Rico (FCPR). European FCI clubs and the AKC recognize the FCPR as an acceptable registry. The AKC currently recognizes Azawakh as a Foundation Stock Service breed and they are eligible to participate in AKC-sanctioned Companion & Performance events. The breed will enter the AKC Miscellaneous Class on June 30, 2011. The American Azawakh Association (AAA). is the AKC Parent Club for the Azawakh. Azawakh may be registered with the UKC and ARBA. The breed is not yet registered by CKC. Azawakh are eligible for ASFA and AKC lure coursing and NOFCA open field coursing events.
Origin.
Genetic, blood protein and archaeological studies, as well as direct observation in the field, offer a glimpse into the origin of the contemporary Azawakh breed. It originated from the pariah dogs of sub-Saharan Africa—also called "bush dogs" or "basenji"—and is also closely related to the Sloughi of the Maghreb. Despite morphological similarities, mitochondrial DNA evidence shows that it is only very distantly related to other sight hounds. Azawakh have a rare glucose isomerase allele (GPI) that occurs only in foxes, jackals, Italian wolves, Sloughi dogs and a handful of other quite unrelated rare dogs found mostly in Japan. The presence of the GPI suggests an ancient differentiation of the Azawakh from other dog populations near the base of the dog family tree divergence from wolves or perhaps a uniquely African cross-breeding with local African canids such as jackals. Petroglyph rock art dating from 8,000 to 10,000 years ago during the Green Sahara (also known as the Holocene and Neolithic Subpluvial) shows cursorial dogs in conjunction with hunters. Archaeologists have found dog bones buried in Holocene settlements in the Sahara. At the close of the Holocene Wet Phase in the 4th millennium BCE, the Sahara returned to desert and created a formidable physical barrier to travel. Together, this evidence suggests that the Azawakh population has a unique genetic heritage that has been largely isolated from other dog populations for millennia.
In the common era the Sahel dogs are almost totally isolated from northern dogs by the Sahara, but the ties to the pariah dogs to the south are extremely close. Azawakh are virtually indistinguishable from the Sahel pariah dog population from which they are drawn. In addition to a basic physical structure, the Azawakh share a number of unique traits with the pariah dogs:
Throughout the Sahel, very elegant puppies can be found among rustic siblings. The Sahel nomads do not have the same breed concepts as in the West and, unlike the Bedouin of the North, do not recognize a strict separation of "al hor" (noble) from "kelb" (mongrel) dogs. The nomads act as an extra level of selection on top of the intense natural selection pressure of the Sahel environment. The approach to selection is diametrically opposed to Western breeding, and presents the advantage of maintaining a large reservoir of genetic variability and resilience.
The peoples of the Sahel control dam lines and cull puppies heavily at birth according to locally held aesthetic criteria that are not yet fully understood. In the Sahel, color is not a selection criterion. The alpha male dog from the local population is usually the sire. Females are usually culled unless the family projects a need for more dogs in the future.

</doc>
<doc id="2838" url="https://en.wikipedia.org/wiki?curid=2838" title="Acrylic paint">
Acrylic paint

Acrylic paint is a fast-drying paint containing pigment suspension in acrylic polymer emulsion. Acrylic paints are water-soluble, but become water-resistant when dry. Depending on how much the paint is diluted with water, or modified with acrylic gels, media, or pastes, the finished acrylic painting can resemble a watercolor or an oil painting, or have its own unique characteristics not attainable with other media.
History.
As early as 1934, the first usable acrylic resin dispersion was developed by German chemical company BASF, which was patented by Rohm and Haas. The synthetic paint was first used in the 1940s, combining some of the properties of oil and watercolor. Between 1946 and 1949, Leonard Bocour and Sam Golden invented a solution acrylic paint under the brand Magna paint. These were mineral spirit-based paints. Acrylics were made commercially available in the 1950s. Following that development, Golden came up with a waterborne acrylic paint called "Aquatec". Otto Rohm invented acrylic resin, which was quickly transformed into acrylic paint. In 1953, the year that Rohm and Haas developed the first acrylic emulsions, Jose L. Gutierrez produced "Politec Acrylic Artists' Colors" in Mexico, and Henry Levinson of Cincinnati-based Permanent Pigments Co. produced Liquitex colors. These two product lines were the very first acrylic emulsion artists' paints. Water-based acrylic paints were subsequently sold as latex house paints, as latex is the technical term for a suspension of polymer microparticles in water. Interior latex house paints tend to be a combination of binder (sometimes acrylic, vinyl, pva, and others), filler, pigment, and water. Exterior latex house paints may also be a co-polymer blend, but the best exterior water-based paints are 100% acrylic, due to elasticity and other factors, but vinyl costs half of what 100% acrylic resins cost, and PVA (polyvinyl acetate) is even cheaper, so paint companies make many different combinations of them to match the market.
Soon after the water-based acrylic binders were introduced as house paints, artists and companies alike began to explore the potential of the new binders. Water-soluble artists' acrylic paints were sold commercially by Liquitex beginning in the 1950s, with modern high-viscosity paints becoming available in the early '60s. In 1963, Rowney (now part of Daler-Rowney since 1983) was the first manufacturer to introduce artist’s acrylic paints in Europe, under the brand name "Cryla".
Techniques.
Acrylic artists' paints may be thinned with water and used as washes in the manner of watercolor paints, but the washes are not re-hydratable once dry. For this reason, acrylics do not lend themselves to the color lifting techniques of gum arabic based watercolor paints.
Acrylic paints with gloss or matte finishes are common, although a satin (semi-matte) sheen is most common. Some brands exhibit a range of finishes (e.g. heavy-body paints from Golden, Liquitex, Winsor & Newton and Daler-Rowney); Politec acrylics are fully matte. As with oils, pigment amounts and particle size or shape can affect the paint sheen. Matting agents can also be added during manufacture to dull the finish. If desired, the artist can mix different media with their paints and use topcoats or varnishes to alter or unify sheen.
When dry, acrylic paint is generally non-removable from a solid surface if it adheres to the surface. Water or mild solvents do not re-solubilize it, although isopropyl alcohol can lift some fresh paint films off. Toluene and acetone can remove paint films, but they do not lift paint stains very well and are not selective. The use of a solvent to remove paint may result in removal of all of the paint layers (acrylic gesso, et cetera). Oils and warm, soapy water can remove acrylic paint from skin.
Only a proper, artist-grade acrylic gesso should be used to prime canvas in preparation for painting with acrylic paints. However, acrylic paint can be applied to a raw canvas if so desired without any negative effect or chemical reaction (as would be the case with oil paint). It is important to avoid adding non-stable or non-archival elements to the gesso upon application. However, the viscosity of acrylic can be successfully reduced by using suitable extenders that maintain the integrity of the paint film. There are retarders to slow drying and extend workability time, and flow releases to increase color-blending ability.
Painters and acrylic.
Before the 19th century, artists mixed their own paints, which allowed them to achieve the desired color and thickness, and to control the use of fillers, if any. While suitable media and raw pigments are available for the individual production of acrylic paint, hand mixing may not be practical because of the fast drying time and other technical issues.
Acrylic painters can modify the appearance, hardness, flexibility, texture, and other characteristics of the paint surface by using acrylic media or simply by adding water. Watercolor and oil painters also use various media, but the range of acrylic media is much greater. Acrylics have the ability to bond to many different surfaces, and media can be used to modify their binding characteristics. Acrylics can be used on paper, canvas and a range of other materials, however their use on engineered woods such as medium-density fiberboard can be problematic because of the porous nature of those surfaces. In these cases it is recommended that the surface first be sealed with an appropriate sealer. Acrylics can be applied in thin layers or washes to create effects that resemble watercolors and other water-based media. They can also be used to build thick layers of paint—gel and molding paste media are sometimes used to create paintings with relief features that are, quite literally, sculptural. Acrylic paints are also used in hobbies such as train, car, house, and human models. People who make such models use acrylic paint to build facial features on dolls, or raised details on other types of models. Wet acrylic paint is easily removed from paint brushes and skin with water, whereas oil paints require the use of a hydrocarbon.
Acrylic paints are the most common paints used in grattage, a surrealist technique that became popular with the advent of acrylic paint. Acrylics are used for this purpose because they easily scrape or peel from a surface.
Grades.
Commercial acrylic paints come in two grades:
Differences between acrylic and oil paint.
The vehicle and binder of oil paints is linseed oil or another drying oil, whereas acrylic paint has water as the vehicle for an emulsion (suspension) of acrylic polymer, which serves as the binder. Thus, oil paint is said to be "oil-based", whereas acrylic paint is "water-based" (or sometimes "water-borne").
The main practical difference between most acrylics and oil paints is the inherent drying time. Oils allow for more time to blend colors and apply even glazes over underpaintings. This slow-drying aspect of oil can be seen as an advantage for certain techniques, but it impedes an artist trying to work quickly. The fast evaporation of water from regular acrylic paint films can be slowed with the use of acrylic retarders. Retarders are generally glycol or glycerin-based additives. The addition of a retarder slows the evaporation rate of the water.
Oil paints may require the use of solvents such as mineral spirits or turpentine to thin the paint and clean up. These solvents generally have some level of toxicity and are often found objectionable. Relatively recently, water-miscible oil paints have been developed for artists' use. Oil paint films can become increasingly yellow and brittle with time; they lose much of their flexibility in a few decades. Additionally, the rules of "fat over lean" must be employed to ensure the paint films are durable.
Oil paint has a higher pigment load than acrylic paint. As linseed oil contains a smaller molecule than acrylic paint, oil paint is able to absorb substantially more pigment. Oil provides a refractive index that is less clear than acrylic dispersions, which imparts a unique "look and feel" to the resultant paint film. Not all the pigments of oil paints are available in acrylics.
Due to acrylic paint's more flexible nature and more consistent drying time between layers, an artist does not have to follow the same rules of oil painting, where more medium must be applied to each layer to avoid cracking. It usually takes 15-20 minutes for one to two layers of acrylic paint to dry. Although canvas needs to be properly primed before painting with oil to prevent it from eventually rotting the canvas, acrylic can be safely applied straight to the canvas. The rapid drying of acrylic paint tends to discourage blending of color and use of wet-in-wet technique as in oil painting. Even though acrylic retarders can slow drying time to several hours, it remains a relatively fast-drying medium and adding too much acrylic retarder can prevent the paint from ever drying properly.
Meanwhile, acrylic paint is very elastic, which prevents cracking from occurring. Acrylic paint's binder is acrylic polymer emulsion – as this binder dries, the paint remains flexible.
Another difference between oil and acrylic paints is the versatility offered by acrylic paints. Acrylics are very useful in mixed media, allowing the use of pastel (oil & chalk), charcoal and pen (among others) on top of the dried acrylic painted surface. Mixing other bodies into the acrylic is possible—sand, rice, and even pasta may be incorporated in the artwork. Mixing artist or student grade acrylic paint with household acrylic emulsions is possible, allowing the use of premixed tints straight from the tube or tin, and thereby presenting the painter with a vast color range at their disposal. This versatility is also illustrated by the variety of additional artistic uses for acrylics. Specialized acrylics have been manufactured and used for linoblock printing (acrylic block printing ink has been produced by Derivan since the early 1980s), face painting, airbrushing, watercolor-like techniques, and fabric screen printing.

</doc>
<doc id="2839" url="https://en.wikipedia.org/wiki?curid=2839" title="Angular momentum">
Angular momentum

In physics, angular momentum (less often moment of momentum or rotational momentum) is a physical quantity corresponding to the amount of rotational motion of an object, taking into account how fast a distribution of mass rotates about some axis. It is the rotational analog of linear momentum. For example, a conker twirling around on a short chord has a lower angular momentum compared to twirling a large heavy sledgehammer at high speed. For a conker of a given mass, increasing the length of chord and angular speed of twirling increases the angular momentum of the conker, and for a fixed angular speed and length, a heavier conker has a larger angular momentum than the lighter conker. In principle, the conker and sledgehammer could have the same angular momentum, despite the differences in their masses and sizes. 
Symbolically, angular momentum it is denoted L, J, or S, each used in different contexts. The definition of angular momentum for a point particle is a pseudovector, L = r×p, the cross product of the particle's position vector r (relative to some origin) and its momentum vector p = "m"v. This definition can be applied to each point in continua like solids or fluids, or physical fields. Unlike momentum, angular momentum does depend on where the origin is chosen, since the particle's position is measured from it. The angular momentum of an object can also be connected to the angular velocity ω of the object (how fast it rotates about an axis) via the moment of inertia "I" (which depends on the shape and distribution of mass about the axis of rotation). However, while ω always points in the direction of the rotation axis, the angular momentum L may point in a "different" direction depending on how the mass is distributed.
Angular momentum is additive; the total angular momentum of a system is the (pseudo)vector sum of the angular momenta. For continua or fields one uses integration. The total angular momentum of anything can always be split into the sum of two main components: "orbital" angular momentum about an axis outside the object, plus "spin" angular momentum through the centre of mass of the object.
Angular momentum is important because it is connected to the symmetry of rotation, and is a conserved quantity – the angular momentum of a system remains constant unless acted on by an external torque. Torque can be defined as the rate of change of angular momentum, analogous to force. The conservation of angular momentum helps explain many observed phenomena, for example the increase in rotational speed of a spinning figure skater as the skater's arms are contracted, the high rotational rates of neutron stars, the falling cat problem, and precession of tops and gyros. Applications include the gyrocompass, control moment gyroscope, inertial guidance systems, reaction wheels, flying discs or Frisbees and Earth's rotation to name a few. In general, conservation does limit the possible motion of a system, but does not uniquely determine what the exact motion is.
In quantum mechanics, angular momentum is an operator with quantized eigenvalues. Angular momentum is subject to the Heisenberg uncertainty principle, meaning only one component can be measured with definite precision, the other two cannot. Also, the "spin" of elementary particles does not correspond to literal spinning motion.
Angular momentum in classical mechanics.
Definition.
Scalar — angular momentum in two dimensions.
Angular momentum is a vector quantity (more precisely, a pseudovector) that represents the product of a body's rotational inertia and rotational velocity about a particular axis. In the simple case of revolution of a particle in a circle about a center of rotation, the particle remaining always in the same plane and having always the same distance from the center, it is sufficient to discard the vector nature of angular momentum, and treat it as a scalar. Angular momentum can be considered a rotational analog of linear momentum. Thus, where linear momentum is proportional to mass formula_1 and linear speed formula_2,
angular momentum is proportional to moment of inertia formula_4 and angular speed formula_5,
Unlike mass, which depends only on amount of matter, moment of inertia is also dependent on the position of the axis of rotation and the shape of the matter. Unlike linear speed, which occurs in a straight line, angular speed occurs about a center of rotation.
Because formula_7 for a single particle and formula_8 for circular motion, angular momentum can be expanded, formula_9 and reduced to,
the product of the radius of rotation formula_11 and the linear momentum of the particle formula_12, where formula_2 in this case is the equivalent linear (tangential) speed at the radius (formula_14).
This simple analysis can also apply to non-circular motion if only the component of the motion which is perpendicular to the radius vector is considered. In that case,
where formula_16 is the perpendicular component of the motion. Expanding, formula_17 rearranging, formula_18 and reducing, angular momentum can also be expressed,
where formula_20 is the length of the "moment arm", a line dropped perpendicularly from the origin onto the path of the particle. It is this definition, to which the term "moment of momentum" refers.
Vector — angular momentum in three dimensions.
To completely define angular momentum in three dimensions, it is required to know the angle swept out in unit time, the direction of the axis of rotation, and the sense (right- or left-handed) of the rotation, as well as the mass involved. By retaining this vector nature of angular momentum, the general nature of the equations is also retained, and can describe any sort of three-dimensional motion about the center of rotation – circular, linear, or otherwise. In vector notation, the angular momentum of a particle in motion about the origin of coordinates is defined as:
This can be expanded, formula_28 reduced, formula_29
and by the rules of vector algebra rearranged to the form,
which is the cross product of the position vector formula_24 and the linear momentum formula_32 of the particle. By the definition of the cross product, the formula_33 vector is perpendicular to both formula_24 and formula_35. It is directed along the axis of rotation as indicated by the right-hand rule – so that the rotation is seen as counter-clockwise from the head of the vector. Conversely, the formula_33 vector defines the plane in which formula_24 and formula_35 lie.
By defining a unit vector formula_39 in the direction of the axis of rotation, a scalar angular speed formula_5 results, where
The two-dimensional scalar equations of the previous section can thus be given direction:
and formula_45 for circular motion, where all of the motion is perpendicular to the radius formula_11.
Discussion.
Angular momentum can be described as the rotational analog of linear momentum. Like linear momentum it involves elements of mass and displacement. Unlike linear momentum it also involves elements of position and shape.
Many problems in physics involve matter in motion about some certain point in space, be it in actual rotation about it, or simply moving past it, where it is desired to know what effect the moving matter has on the point — can it exert energy upon it or perform work about it? Energy, the ability to do work, can be stored in matter by setting it in motion — a combination of its inertia and its displacement. Inertia is measured by its mass, and displacement by its velocity. Their product,
is the matter's momentum. Referring this momentum to a central point introduces a complication: the momentum is not applied to the point directly. For instance, a particle of matter at the outer edge of a wheel is, in effect, at the end of a lever of the same length as the wheel's radius, its momentum turning the lever about the center point. This imaginary lever is known as the "moment arm". It has the effect of multiplying the momentum's effort in proportion to its length, an effect known as a "moment". Hence, the particle's momentum referred to a particular point,
is the "angular momentum", sometimes called, as here, the "moment of momentum" of the particle versus that particular center point. The equation formula_49 combines a moment (a mass formula_1 turning moment arm formula_11) with a linear (straight-line equivalent) speed formula_2. Linear speed referred to the central point is simply the product of the distance formula_11 and the angular speed formula_5 versus the point: formula_55 another moment. Hence, angular momentum contains a double moment: formula_56 Simplifying slightly, formula_57 the quantity formula_58 is the particle's moment of inertia, sometimes called the second moment of mass. It is a measure of rotational inertia.
Because rotational inertia is a part of angular momentum, it necessarily includes all of the complications of moment of inertia, which is calculated by multiplying elementary bits of the mass by the squares of their distances from the center of rotation. Therefore, the total moment of inertia, and the angular momentum, is a complex function of the configuration of the matter about the center of rotation and the orientation of the rotation for the various bits.
For a rigid body, for instance a wheel or an asteroid, the orientation of rotation is simply the position of the rotation axis versus the matter of the body. It may or may not pass through the center of mass, or it may lie completely outside of the body. For the same body, angular momentum may take a different value for every possible axis about which rotation may take place. It reaches a minimum when the axis passes through the center of mass.
For a collection of objects revolving about a center, for instance all of the bodies of the Solar System, the orientations may be somewhat organized, as is the Solar System, with most of the bodies' axes lying close to the system's axis. Their orientations may also be completely random.
In brief, the more mass and the farther it is from the center of rotation (the longer the moment arm), the greater the moment of inertia, and therefore the greater the angular momentum for a given angular velocity. In many cases the moment of inertia, and hence the angular momentum, can be simplified by,
Similarly, for a point mass formula_1 the moment of inertia is defined as,
and for any collection of particles formula_65 as the sum,
Angular momentum's dependence on position and shape is reflected in its units versus linear momentum: kg·m/s, N·m·s or J·s for angular momentum versus kg·m/s or N·s for linear momentum. Angular momentum's units can be interpreted as torque·seconds, work·seconds, or energy·seconds. An object with angular momentum of can be reduced to zero rotation (all of the energy can be transferred out of it) by an angular impulse of or equivalently, by torque or work of for one second, or energy of for one second.
The plane perpendicular to the axis of angular momentum and passing through the center of mass is sometimes called the "invariable plane", because the direction of the axis remains fixed if only the interactions of the bodies within the system, free from outside influences, are considered. One such plane is the invariable plane of the Solar System.
Angular momentum and torque.
Newton's Second Law of Motion can be expressed mathematically,
or Force = mass × acceleration. The rotational equivalent is
or torque = moment of inertia × angular acceleration. Because angular acceleration is the time derivative of angular velocity, this is equivalent to formula_69 Rearranging into a form suitable for integration, formula_70 and formula_71 and integrating with respect to time,
Therefore, a torque acting over time is equivalent to a change in angular momentum, known as "angular impulse" by analogy with impulse defined as the change in translational momentum. The constant can be interpreted as the initial angular momentum of the body, before the torque began to act. In particular, if torque formula_73 then angular momentum formula_74 That is, if no torque acts upon a body, then its angular momentum remains constant. Conversely,
or Angular momentum = moment of inertia × angular velocity, and its time derivative is
Because moment of inertia is constant, formula_77 is zero, and formula_78 which, as above, reduces to
Therefore, the time rate of change of angular momentum is equivalent to torque. If angular momentum is constant, formula_80 and no torque is applied.
Conservation of angular momentum.
Conservation follows mathematically from isotropy, or continuous directional symmetry of space, that is, no direction in space is any different from any other direction. See Noether's theorem.
A rotational analog of Newton's Third Law of Motion might be written, "In a closed system, no torque can be exerted on any matter without the exertion on some other matter of an equal and opposite torque." Hence, "angular momentum can be exchanged between objects in a closed system, but total angular momentum before and after an exchange remains constant (is conserved)."
Similarly, a rotational analogy of Newton's Second law of Motion might be, "A change in angular momentum is proportional to the applied torque and occurs about the same axis as that torque." Since a torque applied over time is equivalent to a change in angular momentum, then if torque is zero, angular momentum is constant. As above, a system with constant angular momentum is a closed system. Therefore, "requiring the system to be closed is equivalent to requiring that no external influence, in the form of a torque, acts upon it."
A rotational analog of Newton's First Law of Motion might be written, "A body continues in a state of rest or of uniform rotation unless compelled by a torque to change its state." Thus "with no external influence to act upon it, the original angular momentum of the system is conserved".
The conservation of angular momentum is used in analyzing "central force motion". If the net force on some body is directed always toward some point, the "center", then there is no torque on the body with respect to the center, as all of the force is directed along the radius vector, and none is perpendicular to the radius. Mathematically, torque formula_81 because in this case formula_24 and formula_83 are parallel vectors. Therefore, the angular momentum of the body about the center is constant. This is the case with gravitational attraction in the orbits of planets and satellites, where the gravitational force is always directed toward the primary body and orbiting bodies conserve angular momentum by exchanging distance and velocity as they move about the primary. Central force motion is also used in the analysis of the Bohr model of the atom.
For a planet, angular momentum is distributed between the spin of the planet and its revolution in its orbit, and these are often exchanged by various mechanisms. The conservation of angular momentum in the Earth–Moon system results in the transfer of angular momentum from Earth to Moon, due to tidal torque the Moon exerts on the Earth. This in turn results in the slowing down of the rotation rate of Earth, at about 65.7 nanoseconds per day, and in gradual increase of the radius of Moon's orbit, at about 3.82 centimeters per year.
The conservation of angular momentum explains the angular acceleration of an ice skater as she brings her arms and legs close to the vertical axis of rotation. By bringing part of the mass of her body closer to the axis she decreases her body's moment of inertia. Because angular momentum is the product of moment of inertia and angular velocity, if the angular momentum remains constant (is conserved), then the angular velocity (rotational speed) of the skater must increase.
The same phenomenon results in extremely fast spin of compact stars (like white dwarfs, neutron stars and black holes) when they are formed out of much larger and slower rotating stars. Decrease in the size of an object "n" times results in increase of its angular velocity by the factor of "n".
Conservation is not always full explanation for the dynamics of a system but a key constraint. For example, a spinning top is subject to a gravitational torque making it lean over and change the angular momentum about the nutation axis, but neglecting friction at the point of spinning contact, it has a conserved angular momentum about its spinning axis, and another about its precession axis. Also, in any planetary system, the planets, star(s), comets, and asteroids can all move in numerous complicated ways, but only so that the angular momentum of the system is conserved.
Angular momentum in orbital mechanics.
In astrodynamics and celestial mechanics, a "massless" (or "per unit mass") angular momentum is defined
called "specific angular momentum". Note that formula_85 Mass is often unimportant in orbital mechanics calculations, because motion is defined by gravity. The primary body of the system is often so much larger than any bodies in motion about it that the smaller bodies have a negligible gravitational effect on it; it is, in effect, stationary. All bodies are apparently attracted by its gravity in the same way, regardless of mass, and therefore all move approximately the same way under the same conditions.
Solid bodies.
For a continuous mass distribution with density function "ρ"(r), a differential volume element "dV" with position vector r within the mass has a mass element "dm" = "ρ"(r)"dV". Therefore, the infinitesimal angular momentum of this element is:
and integrating this differential over the volume of the entire mass gives its total angular momentum:
Collection of particles.
Center of mass.
It is convenient to develop the equation of angular momentum for a collection of particles in motion about an arbitrary origin by resolving their motion into components about their own center of mass and about the origin. Given,
The total mass of the particles is simply their sum,
The position vector of the center of mass is defined by,
By inspection,
The total angular momentum of the collection of particles is the sum of the angular momentum of each particle,
Expanding formula_90,
Expanding formula_92,
It can be shown that (see sidebar),
therefore the second and third terms vanish,
The first term can be rearranged,
and total angular momentum for the collection of particles is finally,
The first term is the angular momentum of the center of mass relative to the origin. Similar to Single particle, below, it is the angular momentum of one particle of mass "M" at the center of mass moving with velocity V. The second term is the angular momentum of the particles moving relative to the center of mass, similar to Fixed center of mass, below. The result is general — the motion of the particles is not restricted to rotation or revolution about the origin or center of mass. The particles need not be individual masses, but can be elements of a continuous distribution, such as a solid body.
Rearranging equation () by vector identities, multiplying both terms by "one", and grouping appropriately,
gives the total angular momentum of the system of particles in terms of moment of inertia formula_4 and angular velocity formula_114,
Simplifications.
Single particle.
In the case of a single particle moving about the arbitrary origin,
Fixed center of mass.
For the case of the center of mass fixed in space with respect to the origin,
Angular momentum (modern definition).
In modern (20th century) theoretical physics, angular momentum (not including any intrinsic angular momentum – see below) is described using a different formalism, instead of a classical pseudovector. In this formalism, angular momentum is the 2-form Noether charge associated with rotational invariance. As a result, angular momentum is not conserved for general curved spacetimes, unless it happens to be asymptotically rotationally invariant.
In classical mechanics, the angular momentum of a particle can be reinterpreted as a plane element:
in which the exterior product ∧ replaces the cross product × (these products have similar characteristics but are nonequivalent). This has the advantage of a clearer geometric interpretation as a plane element, defined from the x and p vectors, and the expression is true in any number of dimensions (two or higher). In Cartesian coordinates:
or more compactly in index notation:
The angular velocity can also be defined as an antisymmetric second order tensor, with components "ω". The relation between the two antisymmetric tensors is given by the moment of inertia which must now be a fourth order tensor:
Again, this equation in L and ω as tensors is true in any number of dimensions. This equation also appears in the geometric algebra formalism, in which L and ω are bivectors, and the moment of inertia is a mapping between them.
In relativistic mechanics, the relativistic angular momentum of a particle is expressed as an antisymmetric tensor of second order:
in the language of four-vectors, namely the four position "X" and the four momentum "P", and absorbs the above L together with the motion of the centre of mass of the particle.
In each of the above cases, for a system of particles, the total angular momentum is just the sum of the individual particle angular momenta, and the centre of mass is for the system.
Angular momentum in quantum mechanics.
Angular momentum in quantum mechanics differs in many profound respects from angular momentum in classical mechanics. In relativistic quantum mechanics, it differs even more, in which the above relativistic definition becomes a tensorial operator.
Spin, orbital, and total angular momentum.
The classical definition of angular momentum as formula_131 can be carried over to quantum mechanics, by reinterpreting r as the quantum position operator and p as the quantum momentum operator. L is then an operator, specifically called the "orbital angular momentum operator".
However, in quantum physics, there is another type of angular momentum, called "spin angular momentum", represented by the spin operator S. Almost all elementary particles have spin. Spin is often depicted as a particle literally spinning around an axis, but this is a misleading and inaccurate picture: spin is an intrinsic property of a particle, unrelated to any sort of motion in space and fundamentally different from orbital angular momentum. All elementary particles have a characteristic spin, for example electrons always have "spin 1/2" (this actually means "spin ħ/2") while photons always have "spin 1" (this actually means "spin ħ").
Finally, there is total angular momentum J, which combines both the spin and orbital angular momentum of all particles and fields. (For one particle, J = L + S.) Conservation of angular momentum applies to J, but not to L or S; for example, the spin–orbit interaction allows angular momentum to transfer back and forth between L and S, with the total remaining constant.
Quantization.
In quantum mechanics, angular momentum is quantized – that is, it cannot vary continuously, but only in "quantum leaps" between certain allowed values. For any system, the following restrictions on measurement results apply, where formula_132 is the reduced Planck constant and formula_133 is any direction vector such as x, y, or z:
The reduced Planck constant formula_132 is tiny by everyday standards, about 10 J s, and therefore this quantization does not noticeably affect the angular momentum of macroscopic objects. However, it is very important in the microscopic world. For example, the structure of electron shells and subshells in chemistry is significantly affected by the quantization of angular momentum.
Quantization of angular momentum was first postulated by Niels Bohr in his Bohr model of the atom and was later predicted by Erwin Schrödinger in his Schrödinger equation.
Uncertainty.
In the definition formula_131, six operators are involved: The position operators formula_136, formula_137, formula_138, and the momentum operators formula_139, formula_140, formula_141. However, the Heisenberg uncertainty principle tells us that it is not possible for all six of these quantities to be known simultaneously with arbitrary precision. Therefore, there are limits to what can be known or measured about a particle's angular momentum. It turns out that the best that one can do is to simultaneously measure both the angular momentum vector's magnitude and its component along one axis.
The uncertainty is closely related to the fact that different components of an angular momentum operator do not commute, for example formula_142. (For the precise commutation relations, see angular momentum operator.)
Total angular momentum as generator of rotations.
As mentioned above, orbital angular momentum L is defined as in classical mechanics: formula_131, but "total" angular momentum J is defined in a different, more basic way: J is defined as the "generator of rotations". More specifically, J is defined so that the operator
is the rotation operator that takes any system and rotates it by angle formula_145 about the axis formula_146. (The "exp" in the formula refers to operator exponential)
The relationship between the angular momentum operator and the rotation operators is the same as the relationship between lie algebras and lie groups in mathematics. The close relationship between angular momentum and rotations is reflected in Noether's theorem that proves that angular momentum is conserved whenever the laws of physics are rotationally invariant.
Angular momentum in electrodynamics.
When describing the motion of a charged particle in an electromagnetic field, the canonical momentum P (derived from the Lagrangian for this system) is not gauge invariant. As a consequence, the canonical angular momentum L = r × P is not gauge invariant either. Instead, the momentum that is physical, the so-called "kinetic momentum" (used throughout this article), is (in SI units)
where "e" is the electric charge of the particle and A the magnetic vector potential of the electromagnetic field. The gauge-invariant angular momentum, that is "kinetic angular momentum", is given by
The interplay with quantum mechanics is discussed further in the article on canonical commutation relations.
Angular momentum in optics.
In "classical Maxwell electrodynamics" the Pointing vector
is a linear momentum density of electromagnetic field
The angular momentum density vector formula_150 is given by a vector product
as in classical mechanics:
formula_151
The above identities are valid " locally ", i.e. in each space point formula_152 in a given moment formula_153.
History.
Newton, in the "Principia", hinted at angular momentum in his examples of the First Law of Motion,
He did not further investigate angular momentum directly in the "Principia",
However, his geometric proof of the Law of Areas is an outstanding example of Newton's genius, and indirectly proves angular momentum conservation in the case of a central force.
The Law of Areas.
Newton's derivation.
As a planet orbits the Sun, the line between the Sun and the planet sweeps out equal areas in equal intervals of time. This had been known since Kepler expounded his Second Law of Planetary Motion. Newton derived a unique geometric proof, and went on to show that the attractive force of the Sun's gravity was the cause of all of Kepler's laws.
During the first interval of time, an object is in motion from point A to point B. Undisturbed, it would continue to point c during the second interval. When the object arrives at B, it receives an impulse directed toward point S. The impulse gives it a small added velocity toward S, such that if this were its only velocity, it would move from B to V during the second interval. By the rules of velocity composition, these two velocities add, and point C is found by construction of parallelogram BcCV. Thus the object's path is deflected by the impulse so that it arrives at point C at the end of the second interval. Because the triangles SBc and SBC have the same base SB and the same height Bc or VC, they have the same area. By symmetry, triangle SBc also has the same area as triangle SAB, therefore the object has swept out equal areas SAB and SBC in equal times.
At point C, the object receives another impulse toward S, again deflecting its path during the third interval from d to D. Thus it continues to E and beyond, the triangles SAB, SBc, SBC, SCd, SCD, SDe, SDE all having the same area. Allowing the time intervals to become ever smaller, the path ABCDE approaches indefinitely close to a continuous curve.
Note that because this derivation is geometric, and no specific force is applied, it proves a more general law than Kepler's Second Law of Planetary Motion. It shows that the Law of Areas applies to any central force, attractive or repulsive, continuous or non-continuous, or zero.
Conservation of angular momentum in the Law of Areas.
The proportionality of angular momentum to the area swept out by a moving object can be understood by realizing that the bases of the triangles, that is, the lines from S to the object, are equivalent to the radius, and that the heights of the triangles are proportional to the perpendicular component of velocity. Hence, if the area swept per unit time is constant, then by the triangular area formula , the product and therefore the product are constant: if and the base length are decreased, and height must increase proportionally. Mass is constant, therefore angular momentum is conserved by this exchange of distance and velocity.
In the case of triangle SBC, area is equal to (SB)(VC). Wherever C is eventually located due to the impulse applied at B, the product (SB)(VC), and therefore remain constant. Similarly so for each of the triangles.
After Newton.
Leonhard Euler, Daniel Bernoulli, and Patrick d'Arcy all understood angular momentum in terms of conservation of areal velocity, a result of their analysis of Kepler's Second Law of planetary motion. It is unlikely that they realized the implications for ordinary rotating matter.
In 1736 Euler, like Newton, touched on some of the equations of angular momentum in his "Mechanica" without further developing them.
Bernoulli wrote in a 1744 letter of a "moment of rotational motion", possibly the first conception of angular momentum as we now understand it.
In 1799, Pierre-Simon Laplace first realized that a fixed plane was associated with rotation — his "invariable plane".
Louis Poinsot in 1803 began representing rotations as a line segment perpendicular to the rotation, and elaborated on the "conservation of moments".
In 1852 Léon Foucault used a gyroscope in an experiment to display the Earth's rotation.
William J. M. Rankine's 1858 "Manual of Applied Mechanics" defined angular momentum in the modern sense for the first time:
In an 1872 edition of the same book, Rankine stated that "The term "angular momentum" was introduced by Mr. Hayward," probably referring to R.B. Hayward's article "On a Direct Method of estimating Velocities, Accelerations, and all similar Quantities with respect to Axes moveable in any manner in Space with Applications," which was introduced in 1856, and published in 1864. Rankine was mistaken, as numerous publications feature the term starting in the late 18th to early 19th centuries. However, Hayward's article apparently was the first use of the term and the concept seen by much of the English-speaking world. Before this, angular momentum was typically referred to as "momentum of rotation" in English.

</doc>
<doc id="2840" url="https://en.wikipedia.org/wiki?curid=2840" title="Plum pudding model">
Plum pudding model

The plum pudding model is an obsolete scientific model of the atom proposed by J. J. Thomson in 1904. It was devised shortly after the discovery of the electron but before the discovery of the atomic nucleus.
In this model, the atom is composed of electrons (which Thomson still called "corpuscles", though G. J. Stoney had proposed that atoms of electricity be called "electrons", in 1894) surrounded by a soup of positive charge to balance the electrons' negative charges, like negatively charged "plums" surrounded by positively charged "pudding". The electrons (as we know them today) were thought to be positioned throughout the atom, but with many structures possible for positioning multiple electrons, particularly rotating rings of electrons (see below). Instead of a soup, the atom was also sometimes said to have had a "cloud" of positive charge. 
With this model, Thomson abandoned his earlier "nebular atom" hypothesis in which the atom was composed of immaterial vortices. Now, at least part of the atom was to be composed of Thomson's particulate negative "corpuscles", although the rest of the positively charged part of the atom remained somewhat nebulous and ill-defined.
The 1904 Thomson model was disproved by the 1909 gold foil experiment of Hans Geiger and Ernest Marsden. This was interpreted by Ernest Rutherford in 1911
Thomson's model was compared (though not by Thomson) to a British dessert called plum pudding, hence the name. Thomson's paper was published in the March 1904 edition of the "Philosophical Magazine", the leading British science journal of the day. In Thomson's view:
... the atoms of the elements consist of a number of negatively electrified corpuscles enclosed in a sphere of uniform positive electrification, ...
In this model, the electrons were free to rotate within the blob or cloud of positive substance. These orbits were stabilized in the model by the fact that when an electron moved farther from the centre of the positive cloud, it felt a larger net positive inward force, because there was more material of opposite charge, inside its orbit (see Gauss's law). In Thomson's model, electrons were free to rotate in rings which were further stabilized by interactions between the electrons, and spectra were to be accounted for by energy differences of different ring orbits. Thomson attempted to make his model account for some of the major spectral lines known for some elements, but was not notably successful at this. Still, Thomson's model (along with a similar Saturnian ring model for atomic electrons, also put forward in 1904 by Nagaoka after James Clerk Maxwell's model of Saturn's rings), were earlier harbingers of the later and more successful solar-system-like Bohr model of the atom.
Related scientific problems.
The plum pudding model with a single electron was used in part by the physicist Arthur Erich Haas in 1910 to estimate the numerical value of Planck's constant and the Bohr radius of hydrogen atoms. Haas' work estimated these values to within an order of magnitude and preceded the work of Niels Bohr by three years. Of note, the Bohr model itself only provides substantially-reasonable predictions for atomic and ionic systems having a single effective electron.
A particularly useful mathematics problem related to the plum pudding model is the optimal distribution of equal point charges on a unit sphere called the Thomson problem. The Thomson problem is a natural consequence of the plum pudding model in the absence of its uniform positive background charge.
The classical electrostatic treatment of electrons confined to spherical quantum dots is also similar to their treatment in the plum pudding model. In this classical problem, the quantum dot is modeled as a simple dielectric sphere (in place of a uniform, positively-charged sphere as in the plum pudding model) in which free, or excess, electrons reside. The electrostatic N-electron configurations are found to be exceptionally close to solutions found in the Thomson problem with electrons residing at the same radius within the dielectric sphere. Notably, the plotted distribution of geometry-dependent energetics has been shown to bear a remarkable resemblance to the distribution of anticipated electron orbitals in natural atoms as arranged on the periodic table of elements. Of great interest, solutions of the Thomson problem exhibit this corresponding energy distribution by comparing the energy of each N-electron solution with the energy of its neighbouring (N-1)-electron solution with one charge at the origin. However, when treated within a dielectric sphere model, the features of the distribution are much more pronounced and provide greater fidelity with respect to electron orbital arrangements in real atoms.

</doc>
<doc id="2844" url="https://en.wikipedia.org/wiki?curid=2844" title="Atomic theory">
Atomic theory

In chemistry and physics, atomic theory is a scientific theory of the nature of matter, which states that matter is composed of discrete units called atoms. It began as a philosophical concept in ancient Greece and entered the scientific mainstream in the early 19th century when discoveries in the field of chemistry showed that matter did indeed behave as if it were made up of atoms.
The word "atom" comes from the Ancient Greek adjective "atomos", meaning "uncuttable". 19th century chemists began using the term in connection with the growing number of irreducible chemical elements. While seemingly apropos, around the turn of the 20th century, through various experiments with electromagnetism and radioactivity, physicists discovered that the so-called "uncuttable atom" was actually a conglomerate of various subatomic particles (chiefly, electrons, protons and neutrons) which can exist separately from each other. In fact, in certain extreme environments, such as neutron stars, extreme temperature and pressure prevents atoms from existing at all. Since atoms were found to be divisible, physicists later invented the term "elementary particles" to describe the "uncuttable", though not indestructible, parts of an atom. The field of science which studies subatomic particles is particle physics, and it is in this field that physicists hope to discover the true fundamental nature of matter.
History.
Philosophical atomism.
The idea that matter is made up of discrete units is a very old one, appearing in many ancient cultures such as Greece and India. However, these ideas were founded in philosophical and theological reasoning rather than evidence and experimentation. Because of this, they could not convince everybody, so atomism was but one of a number of competing theories on the nature of matter. It was not until the 19th century that the idea was embraced and refined by scientists, as the blossoming science of chemistry produced discoveries that could easily be explained using the concept of atoms.
Dalton.
Near the end of the 18th century, two laws about chemical reactions emerged without referring to the notion of an atomic theory. The first was the law of conservation of mass, formulated by Antoine Lavoisier in 1789, which states that the total mass in a chemical reaction remains constant (that is, the reactants have the same mass as the products). The second was the law of definite proportions. First proven by the French chemist Joseph Louis Proust in 1799, this law states that if a compound is broken down into its constituent elements, then the masses of the constituents will always have the same proportions, regardless of the quantity or source of the original substance.
John Dalton studied and expanded upon this previous work and developed the law of multiple proportions: if two elements can be combined to form a number of possible compounds, then the ratios of the masses of the second element which combine with a fixed mass of the first element will be ratios of small whole numbers. For example: Proust had studied tin oxides and found that their masses were either 88.1% tin and 11.9% oxygen or 78.7% tin and 21.3% oxygen (these were tin(II) oxide and tin dioxide respectively). Dalton noted from these percentages that 100g of tin will combine either with 13.5g or 27g of oxygen; 13.5 and 27 form a ratio of 1:2. Dalton found that an atomic theory of matter could elegantly explain this common pattern in chemistry. In the case of Proust's tin oxides, one tin atom will combine with either one or two oxygen atoms.
Dalton also believed atomic theory could explain why water absorbed different gases in different proportions - for example, he found that water absorbed carbon dioxide far better than it absorbed nitrogen. Dalton hypothesized this was due to the differences in mass and complexity of the gases' respective particles. Indeed, carbon dioxide molecules (CO) are heavier and larger than nitrogen molecules (N).
Dalton proposed that each chemical element is composed of atoms of a single, unique type, and though they cannot be altered or destroyed by chemical means, they can combine to form more complex structures (chemical compounds). This marked the first truly scientific theory of the atom, since Dalton reached his conclusions by experimentation and examination of the results in an empirical fashion.
In 1803 Dalton orally presented his first list of relative atomic weights for a number of substances. This paper was published in 1805, but he did not discuss there exactly how he obtained these figures. The method was first revealed in 1807 by his acquaintance Thomas Thomson, in the third edition of Thomson's textbook, "A System of Chemistry". Finally, Dalton published a full account in his own textbook, "A New System of Chemical Philosophy", 1808 and 1810.
Dalton estimated the atomic weights according to the mass ratios in which they combined, with the hydrogen atom taken as unity. However, Dalton did not conceive that with some elements atoms exist in molecules—e.g. pure oxygen exists as O. He also mistakenly believed that the simplest compound between any two elements is always one atom of each (so he thought water was HO, not HO). This, in addition to the crudity of his equipment, flawed his results. For instance, in 1803 he believed that oxygen atoms were 5.5 times heavier than hydrogen atoms, because in water he measured 5.5 grams of oxygen for every 1 gram of hydrogen and believed the formula for water was HO. Adopting better data, in 1806 he concluded that the atomic weight of oxygen must actually be 7 rather than 5.5, and he retained this weight for the rest of his life. Others at this time had already concluded that the oxygen atom must weigh 8 relative to hydrogen equals 1, if one assumes Dalton's formula for the water molecule (HO), or 16 if one assumes the modern water formula (HO).
Avogadro.
The flaw in Dalton's theory was corrected in principle in 1811 by Amedeo Avogadro. Avogadro had proposed that equal volumes of any two gases, at equal temperature and pressure, contain equal numbers of molecules (in other words, the mass of a gas's particles does not affect the volume that it occupies). Avogadro's law allowed him to deduce the diatomic nature of numerous gases by studying the volumes at which they reacted. For instance: since two liters of hydrogen will react with just one liter of oxygen to produce two liters of water vapor (at constant pressure and temperature), it meant a single oxygen molecule splits in two in order to form two particles of water. Thus, Avogadro was able to offer more accurate estimates of the atomic mass of oxygen and various other elements, and made a clear distinction between molecules and atoms.
Brownian Motion.
In 1827, the British botanist Robert Brown observed that dust particles inside pollen grains floating in water constantly jiggled about for no apparent reason. In 1905, Albert Einstein theorized that this Brownian motion was caused by the water molecules continuously knocking the grains about, and developed a hypothetical mathematical model to describe it. This model was validated experimentally in 1908 by French physicist Jean Perrin, thus providing additional validation for particle theory (and by extension atomic theory).
Discovery of subatomic particles.
Atoms were thought to be the smallest possible division of matter until 1897 when J.J. Thomson discovered the electron through his work on cathode rays.
A Crookes tube is a sealed glass container in which two electrodes are separated by a vacuum. When a voltage is applied across the electrodes, cathode rays are generated, creating a glowing patch where they strike the glass at the opposite end of the tube. Through experimentation, Thomson discovered that the rays could be deflected by an electric field (in addition to magnetic fields, which was already known). He concluded that these rays, rather than being a form of light, were composed of very light negatively charged particles he called "corpuscles" (they would later be renamed electrons by other scientists). He measured the mass-to-charge ratio and discovered it was 1800 times smaller than that of hydrogen, the smallest atom. These corpuscles were a particle unlike any other previously known.
Thomson suggested that atoms were divisible, and that the corpuscles were their building blocks. To explain the overall neutral charge of the atom, he proposed that the corpuscles were distributed in a uniform sea of positive charge; this was the plum pudding model as the electrons were embedded in the positive charge like plums in a plum pudding (although in Thomson's model they were not stationary).
Discovery of the nucleus.
Thomson's plum pudding model was disproved in 1909 by one of his former students, Ernest Rutherford, who discovered that most of the mass and positive charge of an atom is concentrated in a very small fraction of its volume, which he assumed to be at the very center.
In the Geiger–Marsden experiment, Hans Geiger and Ernest Marsden (colleagues of Rutherford working at his behest) shot alpha particles at thin sheets of metal and measured their deflection through the use of a fluorescent screen. Given the very small mass of the electrons, the high momentum of the alpha particles, and the low concentration of the positive charge of the plum pudding model, the experimenters expected all the alpha particles to pass through the metal foil without significant deflection. To their astonishment, a small fraction of the alpha particles experienced heavy deflection. Rutherford concluded that the positive charge of the atom must be concentrated in a very tiny volume to produce an electric field sufficiently intense to deflect the alpha particles so strongly.
This led Rutherford to propose a planetary model in which a cloud of electrons surrounded a small, compact nucleus of positive charge. Only such a concentration of charge could produce the electric field strong enough to cause the heavy deflection.
First steps toward a quantum physical model of the atom.
The planetary model of the atom had two significant shortcomings. The first is that, unlike planets orbiting a sun, electrons are charged particles. An accelerating electric charge is known to emit electromagnetic waves according to the Larmor formula in classical electromagnetism. An orbiting charge should steadily lose energy and spiral toward the nucleus, colliding with it in a small fraction of a second. The second problem was that the planetary model could not explain the highly peaked emission and absorption spectra of atoms that were observed.
Quantum theory revolutionized physics at the beginning of the 20th century, when Max Planck and Albert Einstein postulated that light energy is emitted or absorbed in discrete amounts known as quanta (singular, "quantum"). In 1913, Niels Bohr incorporated this idea into his Bohr model of the atom, in which an electron could only orbit the nucleus in particular circular orbits with fixed angular momentum and energy, its distance from the nucleus (i.e., their radii) being proportional to its energy. Under this model an electron could not spiral into the nucleus because it could not lose energy in a continuous manner; instead, it could only make instantaneous "quantum leaps" between the fixed energy levels. When this occurred, light was emitted or absorbed at a frequency proportional to the change in energy (hence the absorption and emission of light in discrete spectra).
Bohr's model was not perfect. It could only predict the spectral lines of hydrogen; it couldn't predict those of multielectron atoms. Worse still, as spectrographic technology improved, additional spectral lines in hydrogen were observed which Bohr's model couldn't explain. In 1916, Arnold Sommerfeld added elliptical orbits to the Bohr model to explain the extra emission lines, but this made the model very difficult to use, and it still couldn't explain more complex atoms.
Discovery of isotopes.
While experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one element at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for these elements.
That same year, J.J. Thomson conducted an experiment in which he channeled a stream of neon ions through magnetic and electric fields, striking a photographic plate at the other end. He observed two glowing patches on the plate, which suggested two different deflection trajectories. Thomson concluded this was because some of the neon ions had a different mass. The nature of this differing mass would later be explained by the discovery of neutrons in 1932.
Discovery of nuclear particles.
In 1917 Rutherford bombarded nitrogen gas with alpha particles and observed hydrogen nuclei being emitted from the gas (Rutherford recognized these, because he had previously obtained them bombarding hydrogen with alpha particles, and observing hydrogen nuclei in the products). Rutherford concluded that the hydrogen nuclei emerged from the nuclei of the nitrogen atoms themselves (in effect, he had split a nitrogen).
From his own work and the work of his students Bohr and Henry Moseley, Rutherford knew that the positive charge of any atom could always be equated to that of an integer number of hydrogen nuclei. This, coupled with the atomic mass of many elements being roughly equivalent to an integer number of hydrogen atoms - then assumed to be the lightest particles - led him to conclude that hydrogen nuclei were singular particles and a basic constituent of all atomic nuclei. He named such particles protons. Further experimentation by Rutherford found that the nuclear mass of most atoms exceeded that of the protons it possessed; he speculated that this surplus mass was composed of hitherto unknown neutrally charged particles, which were tentatively dubbed "neutrons".
In 1928, Walter Bothe observed that beryllium emitted a highly penetrating, electrically neutral radiation when bombarded with alpha particles. It was later discovered that this radiation could knock hydrogen atoms out of paraffin wax. Initially it was thought to be high-energy gamma radiation, since gamma radiation had a similar effect on electrons in metals, but James Chadwick found that the ionization effect was too strong for it to be due to electromagnetic radiation, so long as energy and momentum were conserved in the interaction. In 1932, Chadwick exposed various elements, such as hydrogen and nitrogen, to the mysterious "beryllium radiation", and by measuring the energies of the recoiling charged particles, he deduced that the radiation was actually composed of electrically neutral particles which could not be massless like the gamma ray, but instead were required to have a mass similar to that of a proton. Chadwick now claimed these particles as Rutherford's neutrons. For his discovery of the neutron, Chadwick received the Nobel Prize in 1935.
Quantum physical models of the atom.
In 1924, Louis de Broglie proposed that all moving particles—particularly subatomic particles such as electrons—exhibit a degree of wave-like behavior. Erwin Schrödinger, fascinated by this idea, explored whether or not the movement of an electron in an atom could be better explained as a wave rather than as a particle. Schrödinger's equation, published in 1926, describes an electron as a wavefunction instead of as a point particle. This approach elegantly predicted many of the spectral phenomena that Bohr's model failed to explain. Although this concept was mathematically convenient, it was difficult to visualize, and faced opposition. One of its critics, Max Born, proposed instead that Schrödinger's wavefunction described not the electron but rather all its possible states, and thus could be used to calculate the probability of finding an electron at any given location around the nucleus. This reconciled the two opposing theories of particle versus wave electrons and the idea of wave–particle duality was introduced. This theory stated that the electron may exhibit the properties of both a wave and a particle. For example, it can be refracted like a wave, and has mass like a particle.
A consequence of describing electrons as waveforms is that it is mathematically impossible to simultaneously derive the position and momentum of an electron. This became known as the Heisenberg uncertainty principle after the theoretical physicist Werner Heisenberg, who first described it and published it in 1927. This invalidated Bohr's model, with its neat, clearly defined circular orbits. The modern model of the atom describes the positions of electrons in an atom in terms of probabilities. An electron can potentially be found at any distance from the nucleus, but, depending on its energy level, exists more frequently in certain regions around the nucleus than others; this pattern is referred to as its atomic orbital. The orbitals come in a variety of shapes-sphere, dumbbell, torus, etc.-with the nucleus in the middle.

</doc>
<doc id="2846" url="https://en.wikipedia.org/wiki?curid=2846" title="Ai">
Ai

AI, A.I., Ai, or ai may refer to:

</doc>
<doc id="2847" url="https://en.wikipedia.org/wiki?curid=2847" title="Aung San Suu Kyi">
Aung San Suu Kyi

Aung San Suu Kyi, (, , ; born 19 June 1945) is a Burmese Social Democratic stateswoman, politician and president of the National League for Democracy (NLD) in Myanmar. In the 1990 general election, the NLD won 59% of the national votes and 81% (392 of 485) of the seats in Parliament. She had, however, already been detained under house arrest before the elections. She remained under house arrest in Burma for almost 15 of the 21 years from 20 July 1989 until her most recent release on 13 November 2010, becoming one of the world's most prominent political prisoners.
Suu Kyi received the Rafto Prize and the Sakharov Prize for Freedom of Thought in 1990 and the Nobel Peace Prize in 1991. In 1992, she was awarded the Jawaharlal Nehru Award for International Understanding by the government of India and the International Simón Bolívar Prize from the government of Venezuela. In 2012, the Government of Pakistan awarded her the Shaheed Benazir Bhutto Award For Democracy. In 2007, the Government of Canada made her an honorary citizen of that country, the fourth person ever to receive the honour. In 2011, she was awarded the Wallenberg Medal.
On 19 September 2012, Aung San Suu Kyi was also presented with the Congressional Gold Medal, which is, along with the Presidential Medal of Freedom, the highest civilian honour in the United States.
On 1 April 2012, her party, the National League for Democracy, announced that she was elected to the Pyithu Hluttaw, the lower house of the Burmese parliament, representing the constituency of Kawhmu; her party also won 43 of the 45 vacant seats in the lower house. The election results were confirmed by the official electoral commission the following day.
On 6 June 2013, Suu Kyi announced on the World Economic Forum's website that she wants to run for the presidency in Myanmar's 2015 elections. Suu Kyi is prohibited, however, from becoming president within the current constitution due to having married a non-Burmese person; this cannot be amended without the approval of at least one military legislator.
In the 2015 Myanmar general election, the NLD, Suu Kyi's party, won a sweeping victory, taking 86 percent of the seats in the Assembly of the Union (235 in the House of Representatives and 135 in the House of Nationalities)—well more than the 67 percent supermajority needed to ensure that its preferred candidates will be elected president and first vice president in the Presidential Electoral College.
Name.
"Aung San Suu Kyi", like other Burmese names, includes no family name, but is only a personal name, in her case derived from three relatives: "Aung San" from her father, "Suu" from her paternal grandmother, and "Kyi" from her mother Khin Kyi.
The Burmese refer to her as Daw Aung San Suu Kyi. "Daw", literally meaning "aunt", is not part of her name but is a Burmese honorific for any older and revered woman, akin to "Madame". Burmese sometimes address her as Daw Suu or Amay Suu ("Mother Suu").
Personal life.
Aung San Suu Kyi was born on 19 June 1945 in Rangoon (now often called Yangon). Her father, Aung San, founded the modern Burmese army and negotiated Burma's independence from the British Empire in 1947; he was assassinated by his rivals in the same year. She grew up with her mother, Khin Kyi, and two brothers, Aung San Lin and Aung San Oo, in Rangoon. Aung San Lin died at the age of eight, when he drowned in an ornamental lake on the grounds of the house. Her elder brother emigrated to San Diego, California, becoming a United States citizen. After Aung San Lin's death, the family moved to a house by Inya Lake where Suu Kyi met people of various backgrounds, political views and religions. She was educated in Methodist English High School (now Basic Education High School No. 1 Dagon) for much of her childhood in Burma, where she was noted as having a talent for learning languages. Currently, she speaks 4 languages: Burmese, English, French and Japanese. She is a Theravada Buddhist.
Suu Kyi's mother, Khin Kyi, gained prominence as a political figure in the newly formed Burmese government. She was appointed Burmese ambassador to India and Nepal in 1960, and Aung San Suu Kyi followed her there. She studied in the Convent of Jesus and Mary School in New Delhi, and graduated from Lady Shri Ram College in New Delhi with a degree in politics in 1964. Suu Kyi continued her education at St Hugh's College, Oxford, obtaining a B.A degree in Philosophy, Politics and Economics in 1967 and M.A degree in Politics in 1968. After graduating, she lived in New York City with a family friend Ma Than E, who was once a popular Burmese pop singer. She worked at the United Nations for three years, primarily on budget matters, writing daily to her future husband, Dr. Michael Aris. On 1 January 1972, Aung San Suu Kyi married Aris, a scholar of Tibetan culture, living abroad in Bhutan. The following year she gave birth to their first son, Alexander Aris, in London; their second son, Kim, was born in 1977. Between 1985 and 1987, Suu Kyi was working toward an M.Phil degree in Burmese literature as a research student at SOAS, the School of Oriental and African Studies, University of London. She was elected as an Honorary Fellow of SOAS in 1990. For two years, she was a Fellow at the Indian Institute of Advanced Studies (IIAS) in Shimla, India. She also worked for the government of the Union of Burma.
In 1988, Suu Kyi returned to Burma, at first to tend for her ailing mother but later to lead the pro-democracy movement. Aris' visit in Christmas 1995 turned out to be the last time that he and Suu Kyi met, as Suu Kyi remained in Burma and the Burmese dictatorship denied him any further entry visas. Aris was diagnosed with prostate cancer in 1997 which was later found to be terminal. Despite appeals from prominent figures and organizations, including the United States, UN Secretary General Kofi Annan and Pope John Paul II, the Burmese government would not grant Aris a visa, saying that they did not have the facilities to care for him, and instead urged Aung San Suu Kyi to leave the country to visit him. She was at that time temporarily free from house arrest but was unwilling to depart, fearing that she would be refused re-entry if she left, as she did not trust the military junta's assurance that she could return.
Aris died on his 53rd birthday on 27 March 1999. Since 1989, when his wife was first placed under house arrest, he had seen her only five times, the last of which was for Christmas in 1995. She was also separated from her children, who live in the United Kingdom, but starting in 2011, they have visited her in Burma.
On 2 May 2008, after Cyclone Nargis hit Burma, Suu Kyi lost the roof of her house and lived in virtual darkness after losing electricity in her dilapidated lakeside residence. She used candles at night as she was not provided any generator set. Plans to renovate and repair the house were announced in August 2009. Suu Kyi was released from house arrest on 13 November 2010.
Political career.
Political beginning.
Coincidentally, when Aung San Suu Kyi returned to Burma in 1988, the long-time military leader of Burma and head of the ruling party, General Ne Win, stepped down. Mass demonstrations for democracy followed that event on 8 August 1988 (8–8–88, a day seen as auspicious), which were violently suppressed in what came to be known as the 8888 Uprising. On 26 August 1988, she addressed half a million people at a mass rally in front of the Shwedagon Pagoda in the capital, calling for a democratic government. However, in September, a new military junta took power.
Influenced by both Mahatma Gandhi's philosophy of non-violence and more specifically by Buddhist concepts, Aung San Suu Kyi entered politics to work for democratization, helped found the National League for Democracy on 27 September 1988, but was put under house arrest on 20 July 1989. Offered freedom if she left the country, she refused. Despite her philosophy of non-violence, a group of ex-military commanders and senior politicians who joined NLD during the crisis believed that she was too confrontational and left NLD. However, she retained enormous popularity and support among NLD youths with whom she spent most of her time.
During her time under house arrest, Suu Kyi devoted herself to Buddhist meditation practices and to studying Buddhist thought. This deeper interest in Buddhism is reflected in her writings as more emphasis is put on love and compassion. There also emerged more discussion on the compatibility of democracy and Buddhism and the ability of gaining freedom from an authoritarian government through Buddhism.
During the crisis, the previous democratically elected Prime Minister of Burma, U Nu initiated to form an interim government and invited opposition leaders to join him. Indian Prime Minister Rajiv Gandhi had signaled his readiness to recognize the interim government. However, Aung San Suu Kyi categorically rejected U Nu's plan by saying "the future of the opposition would be decided by masses of the people". Ex-Brigadier General Aung Gyi, another influential politician at the time of the 8888 crisis, followed the suit and rejected the plan after Suu Kyi's refusal. Aung Gyi later accused several NLD members of being communists and resigned from the party.
1990 general election.
In 1990, the military junta called a general election, in which the National League for Democracy (NLD) received 59% of the votes, guaranteeing NLD 80% of the parliament seats. Some claim that Aung San Suu Kyi would have assumed the office of Prime Minister; in fact, however, as she was not permitted, she did not stand as a candidate in the elections (although being a MP is not a strict prerequisite for becoming PM in most parliamentary systems). Instead, the results were nullified and the military refused to hand over power, resulting in an international outcry. Aung San Suu Kyi was placed under house arrest at her home on University Avenue () in Rangoon, during which time she was awarded the Sakharov Prize for Freedom of Thought in 1990, and the Nobel Peace Prize the year after. Her sons Alexander and Kim accepted the Nobel Peace Prize on her behalf. Aung San Suu Kyi used the Nobel Peace Prize's 1.3 million USD prize money to establish a health and education trust for the Burmese people. Around this time, Suu Kyi chose non-violence as an expedient political tactic, stating in 2007, "I do not hold to non-violence for moral reasons, but for political and practical reasons."
1996 attack.
On 9 November 1996, the motorcade that Aung San Suu Kyi was traveling in with other National League for Democracy leaders Tin Oo and Kyi Maung, was attacked in Yangon. About 200 men swooped down on the motorcade, wielding metal chains, metal batons, stones and other weapons. The car that Aung San Suu Kyi was in had its rear window smashed, and the car with Tin Oo and Kyi Maung had its rear window and two backdoor windows shattered. It is believed the offenders were members of the Union Solidarity and Development Association (USDA) who were allegedly paid 500 kyats (@ USD $0.50) each to participate. The NLD lodged an official complaint with the police, and according to reports the government launched an investigation, but no action was taken. (Amnesty International 120297)
House arrest.
Aung San Suu Kyi was placed under house arrest for a total of 15 years over a 21-year period, on numerous occasions, since she began her political career, during which time she was prevented from meeting her party supporters and international visitors. In an interview, Suu Kyi said that while under house arrest she spent her time reading philosophy, politics and biographies that her husband had sent her. She also passed the time playing the piano, and was occasionally allowed visits from foreign diplomats as well as from her personal physician.
Although under house arrest, Suu Kyi was granted permission to leave Burma under the condition that she never return. Rather than abandon her people, Suu Kyi submitted to house arrest and decided to sacrifice a life with her husband and her two young sons, in order to stand by her people: "As a mother, the greater sacrifice was giving up my sons, but I was always aware of the fact that others had given up more than me. I never forget that my colleagues who are in prison suffer not only physically, but mentally for their families who have no security outside- in the larger prison of Burma under authoritarian rule." Her loyalty to the people of Burma and her solidarity with those imprisoned for their pro-democratic acts have earned her deep respect among the Burmese people.
The media were also prevented from visiting Suu Kyi, as occurred in 1998 when journalist Maurizio Giuliano, after photographing her, was stopped by customs officials who then confiscated all his films, tapes and some notes. In contrast, Suu Kyi did have visits from government representatives, such as during her autumn 1994 house arrest when she met the leader of Burma, General Than Shwe and General Khin Nyunt on 20 September in the first meeting since she had been placed in detention. On several occasions during Suu Kyi's house arrest, she had periods of poor health and as a result was hospitalized.
The Burmese government detained and kept Suu Kyi imprisoned because it viewed her as someone "likely to undermine the community peace and stability" of the country, and used both Article 10(a) and 10(b) of the 1975 State Protection Act (granting the government the power to imprison people for up to five years without a trial), and Section 22 of the "Law to Safeguard the State Against the Dangers of Those Desiring to Cause Subversive Acts" as legal tools against her. She continuously appealed her detention, and many nations and figures continued to call for her release and that of 2,100 other political prisoners in the country. On 12 November 2010, days after the junta-backed Union Solidarity and Development Party (USDP) won elections conducted after a gap of 20 years, the junta finally agreed to sign orders allowing Suu Kyi's release, and Suu Kyi's house arrest term came to an end on 13 November 2010.
United Nations involvement.
The United Nations (UN) has attempted to facilitate dialogue between the junta and Suu Kyi. On 6 May 2002, following secret confidence-building negotiations led by the UN, the government released her; a government spokesman said that she was free to move "because we are confident that we can trust each other". Aung San Suu Kyi proclaimed "a new dawn for the country". However, on 30 May 2003 in an incident similar to the 1996 attack on her, a government-sponsored mob attacked her caravan in the northern village of Depayin, murdering and wounding many of her supporters. Aung San Suu Kyi fled the scene with the help of her driver, Kyaw Soe Lin, but was arrested upon reaching Ye-U. The government imprisoned her at Insein Prison in Rangoon. After she underwent a hysterectomy in September 2003, the government again placed her under house arrest in Rangoon.
The results from the UN facilitation have been mixed; Razali Ismail, UN special envoy to Burma, met with Aung San Suu Kyi. Ismail resigned from his post the following year, partly because he was denied re-entry to Burma on several occasions. Several years later in 2006, Ibrahim Gambari, UN Undersecretary-General (USG) of Department of Political Affairs, met with Aung San Suu Kyi, the first visit by a foreign official since 2004. He also met with Suu Kyi later the same year. On 2 October 2007 Gambari returned to talk to her again after seeing Than Shwe and other members of the senior leadership in Naypyidaw. State television broadcast Suu Kyi with Gambari, stating that they had met twice. This was Suu Kyi's first appearance in state media in the four years since her current detention began.
The United Nations Working Group for Arbitrary Detention published an Opinion that Aung San Suu Kyi's deprivation of liberty was arbitrary and in contravention of Article 9 of the Universal Declaration of Human Rights 1948, and requested that the authorities in Burma set her free, but the authorities ignored the request at that time. The U.N. report said that according to the Burmese Government's reply, "Daw Aung San Suu Kyi has not been arrested, but has only been taken into protective custody, for her own safety", and while "it could have instituted legal action against her under the country's domestic legislation ... it has preferred to adopt a magnanimous attitude, and is providing her with protection in her own interests."
Such claims were rejected by Brig-General Khin Yi, Chief of Myanmar Police Force (MPF). On 18 January 2007, the state-run paper "New Light of Myanmar" accused Suu Kyi of tax evasion for spending her Nobel Prize money outside the country. The accusation followed the defeat of a US-sponsored United Nations Security Council resolution condemning Burma as a threat to international security; the resolution was defeated because of strong opposition from China, which has strong ties with the military junta (China later voted against the resolution, along with Russia and South Africa).
In November 2007, it was reported that Suu Kyi would meet her political allies National League for Democracy along with a government minister. The ruling junta made the official announcement on state TV and radio just hours after UN special envoy Ibrahim Gambari ended his second visit to Burma. The NLD confirmed that it had received the invitation to hold talks with Suu Kyi. However, the process delivered few concrete results.
On 3 July 2009, UN Secretary General Ban Ki-moon went to Burma to pressure the junta into releasing Suu Kyi and to institute democratic reform. However, on departing from Burma, Ban Ki-moon said he was "disappointed" with the visit after junta leader Than Shwe refused permission for him to visit Suu Kyi, citing her ongoing trial. Ban said he was "deeply disappointed that they have missed a very important opportunity."
2007 anti-government protests.
Protests led by Buddhist monks began on 19 August 2007 following steep fuel price increases, and continued each day, despite the threat of a crackdown by the military.
On 22 September 2007, although still under house arrest, Suu Kyi made a brief public appearance at the gate of her residence in Yangon to accept the blessings of Buddhist monks who were marching in support of human rights. It was reported that she had been moved the following day to Insein Prison (where she had been detained in 2003), but meetings with UN envoy Ibrahim Gambari near her Rangoon home on 30 September and 2 October established that she remained under house arrest.
2009 trespass incident.
On 3 May 2009, an American man, identified as John Yettaw, swam across Inya Lake to her house uninvited and was arrested when he made his return trip three days later. He had attempted to make a similar trip two years earlier, but for unknown reasons was turned away. He later claimed at trial that he was motivated by a divine vision requiring him to notify her of an impending terrorist assassination attempt. On 13 May, Suu Kyi was arrested for violating the terms of her house arrest because the swimmer, who pleaded exhaustion, was allowed to stay in her house for two days before he attempted the swim back. Suu Kyi was later taken to Insein Prison, where she could have faced up to five years confinement for the intrusion. The trial of Suu Kyi and her two maids began on 18 May and a small number of protesters gathered outside. Diplomats and journalists were barred from attending the trial; however, on one occasion, several diplomats from Russia, Thailand and Singapore and journalists were allowed to meet Suu Kyi. The prosecution had originally planned to call 22 witnesses. It also accused John Yettaw of embarrassing the country. During the ongoing defence case, Suu Kyi said she was innocent. The defence was allowed to call only one witness (out of four), while the prosecution was permitted to call 14 witnesses. The court rejected two character witnesses, NLD members Tin Oo and Win Tin, and permitted the defence to call only a legal expert. According to one unconfirmed report, the junta was planning to, once again, place her in detention, this time in a military base outside the city. In a separate trial, Yettaw said he swam to Suu Kyi's house to warn her that her life was "in danger". The national police chief later confirmed that Yettaw was the "main culprit" in the case filed against Suu Kyi. According to aides, Suu Kyi spent her 64th birthday in jail sharing biryani rice and chocolate cake with her guards.
Her arrest and subsequent trial received worldwide condemnation by the UN Secretary General Ban Ki-moon, the United Nations Security Council, Western governments, South Africa, Japan and the Association of Southeast Asian Nations, of which Burma is a member. The Burmese government strongly condemned the statement, as it created an "unsound tradition" and criticised Thailand for meddling in its internal affairs. The Burmese Foreign Minister Nyan Win was quoted in the state-run newspaper "New Light of Myanmar" as saying that the incident "was trumped up to intensify international pressure on Burma by internal and external anti-government elements who do not wish to see the positive changes in those countries' policies toward Burma". Ban responded to an international campaign by flying to Burma to negotiate, but Than Shwe rejected all of his requests.
On 11 August 2009 the trial concluded with Suu Kyi being sentenced to imprisonment for three years with hard labour. This sentence was commuted by the military rulers to further house arrest of 18 months. On 14 August, U.S. Senator Jim Webb visited Burma, visiting with junta leader Gen. Than Shwe and later with Suu Kyi. During the visit, Webb negotiated Yettaw's release and deportation from Burma. Following the verdict of the trial, lawyers of Suu Kyi said they would appeal against the 18-month sentence. On 18 August, United States President Barack Obama asked the country's military leadership to set free all political prisoners, including Aung San Suu Kyi. In her appeal, Aung San Suu Kyi had argued that the conviction was unwarranted. However, her appeal against the August sentence was rejected by a Burmese court on 2 October 2009. Although the court accepted the argument that the 1974 constitution, under which she had been charged, was null and void, it also said the provisions of the 1975 security law, under which she has been kept under house arrest, remained in force. The verdict effectively meant that she would be unable to participate in the elections scheduled to take place in 2010 – the first in Burma in two decades. Her lawyer stated that her legal team would pursue a new appeal within 60 days.
2009: International pressure for release and 2010 Burmese general election.
It was announced prior to the Burmese general election that Aung San Suu Kyi may be released "so she can organize her party," However, Suu Kyi was not allowed to run. On 1 October 2010 the government announced that she would be released on 13 November 2010.
U.S. President Barack Obama personally advocated the release of all political prisoners, especially Aung San Suu Kyi, during the US-ASEAN Summit of 2009.
The U. S. Government hoped that successful general elections would be an optimistic indicator of the Burmese government's sincerity towards eventual democracy. The Hatoyama government which spent 2.82 billion yen in 2008, has promised more Japanese foreign aid to encourage Burma to release Aung San Suu Kyi in time for the elections; and to continue moving towards democracy and the rule of law.
In a personal letter to Suu Kyi, UK Prime Minister Gordon Brown cautioned the Burmese government of the potential consequences of rigging elections as "condemning Burma to more years of diplomatic isolation and economic stagnation".
Suu Kyi has met with many heads of state, and opened a dialog with the Minister of Labor Aung Kyi (not to be confused with Aung San Suu Kyi). She was allowed to meet with senior members of her NLD party at the State House, however these meetings took place under close supervision.
2010 release.
On the evening of 13 November 2010, Suu Kyi was released from house arrest. This was the date her detention had been set to expire according to a court ruling in August 2009 and came six days after a widely criticised general election. She appeared in front of a crowd of her supporters, who rushed to her house in Rangoon when nearby barricades were removed by the security forces. Suu Kyi had been detained for 15 of the past 21 years. The government newspaper "New Light of Myanmar" reported the release positively, saying she had been granted a pardon after serving her sentence "in good conduct". The New York Times suggested that the military government may have released Suu Kyi because it felt it was in a confident position to control her supporters after the election. The role that Suu Kyi will play in the future of democracy in Burma remains a subject of much debate.
Her son Kim Aris was granted a visa in November 2010 to see his mother shortly after her release, for the first time in 10 years. He visited again on 5 July 2011, to accompany her on a trip to Bagan, her first trip outside Yangon since 2003. Her son visited again on 8 August 2011, to accompany her on a trip to Pegu, her second trip.
Discussions were held between Suu Kyi and the Burmese government during 2011, which led to a number of official gestures to meet her demands. In October, around a tenth of Burma's political prisoners were freed in an amnesty and trade unions were legalised.
In November 2011, following a meeting of its leaders, the NLD announced its intention to re-register as a political party in order to contend 48 by-elections necessitated by the promotion of parliamentarians to ministerial rank. Following the decision, Suu Kyi held a telephone conference with U.S. President Barack Obama, in which it was agreed that Secretary of State Hillary Clinton would make a visit to Burma, a move received with caution by Burma's ally China. On 1 December 2011, Suu Kyi met with Hillary Clinton at the residence of the top-ranking US diplomat in Yangon.
On 21 December 2011, Thai Prime Minister Yingluck Shinawatra met Suu Kyi in Yangoon, becoming Suu Kyi's "first-ever meeting with the leader of a foreign country".
On 5 January 2012, British Foreign Minister William Hague met Aung San Suu Kyi and his Burmese counterpart. This represented a significant visit for Suu Kyi and Burma. Suu Kyi studied in the UK and maintains many ties there, whilst Britain is Burma's largest bilateral donor.
During Aung San Suu Kyi's visit to Europe, she visited the Swiss parliament, collected her 1991 Nobel Prize in Oslo and her honorary degree from Oxford University.
2012 by-elections.
In December 2011, there was speculation that Suu Kyi would run in the 2012 national by-elections to fill vacant seats. On 18 January 2012, Suu Kyi formally registered to contest a Pyithu Hluttaw (lower house) seat in the Kawhmu Township constituency in special parliamentary elections to be held on 1 April 2012. The seat was previously held by Soe Tint, who vacated it after being appointed Construction Deputy Minister, in the 2010 election. She ran against Union Solidarity and Development Party candidate Soe Min, a retired army physician and native of Twante Township.
On 3 March 2012, at a large campaign rally in Mandalay, Suu Kyi unexpectedly left after 15 minutes, because of exhaustion and airsickness.
In an official campaign speech broadcast on Burmese state television's MRTV on 14 March 2012, Suu Kyi publicly campaigned for reform of the 2008 Constitution, removal of restrictive laws, more adequate protections for people's democratic rights, and establishment of an independent judiciary. The speech was leaked online a day before it was broadcast. A paragraph in the speech, focusing on the Tatmadaw's repression by means of law, was censored by authorities.
Suu Kyi has also called for international media to monitor the upcoming by-elections, while publicly pointing out irregularities in official voter lists, which include deceased individuals and exclude other eligible voters in the contested constituencies. On 21 March 2012, Aung San Suu Kyi was quoted as saying "Fraud and rule violations are continuing and we can even say they are increasing."
When asked whether she would assume a ministerial post if given the opportunity, she said the following:
On 26 March 2012, Suu Kyi suspended her nationwide campaign tour early, after a campaign rally in Myeik (Mergui), a coastal town in the south, citing health problems due to exhaustion and hot weather.
On 1 April 2012, the NLD announced that Suu Kyi had won the vote for a seat in Parliament. A news broadcast on state-run MRTV, reading the announcements of the Union Election Commission, confirmed her victory, as well as her party's victory in 43 of the 45 contested seats, officially making Suu Kyi the Leader of the Opposition in the Pyidaungsu Hluttaw.
Although she and other MP-elects were expected to take office on 23 April when the Hluttaws resume session, National League for Democracy MP-elects, including Suu Kyi, said they might not take their oaths because of its wording; in its present form, parliamentarians must vow to "safeguard" the constitution. In an address on Radio Free Asia, she said "We don't mean we will not attend the parliament, we mean we will attend only after taking the oath... Changing that wording in the oath is also in conformity with the Constitution. I don't expect there will be any difficulty in doing it."
On 2 May 2012, National League for Democracy MP-elects, including Aung San Suu Kyi, took their oaths and took office, though the wording of the oath was not changed. According to the Los Angeles Times, "Suu Kyi and her colleagues decided they could do more by joining as lawmakers than maintaining their boycott on principle."
On 9 July 2012, she attended the Parliament for the first time as a lawmaker.
Response to race riots and refugees.
Some activists criticised Aung San Suu Kyi for her silence on the 2012 Rakhine State riots (later repeated during the 2015 Rohingya refugee crisis). After receiving a peace prize, she told reporters she did not know if the Rohingya could be regarded as Burmese citizens. Some describe her stance as politically motivated; however, she said that she wanted to work towards reconciliation and that she cannot take sides as "violence has been committed by both sides." According to "The Economist", her "halo has even slipped among foreign human-rights lobbyists, disappointed at her failure to make a clear stand on behalf of the Rohingya minority." However, she has spoken out "against a ban on Rohingya families near the Bangladeshi border having more than two children."
In a 2015 BBC News article, reporter Jonah Fisher suggested that Aung San Suu Kyi's silence over the Rohingya issue is due to a need to obtain support from the majority Bamar ethnicity as she is in "the middle of a general election campaign"; Adding to the international criticism of Aung San Suu Kyi's silence, in May 2015, the 14th Dalai Lama called on her to do more to help the Rohingya in Myanmar.
2015 general election.
On 6 July 2012, Suu Kyi announced on the World Economic Forum's website that she wants to run for the presidency in Myanmar's 2015 elections. The current Constitution, which came into effect in 2008, bars her from the presidency because she is the widow and mother of foreigners — provisions that appeared to be written specifically to prevent her from being eligible.
The NLD won a sweeping victory in those elections, winning at least 255 seats in the House of Representatives and 135 seats in the House of Nationalities. In addition, Suu Kyi won re-election to the House of Representatives. Under the 2008 constitution, the NLD needed to win at least a two-thirds majority in both houses to ensure that its candidate would become president. Before the elections, Suu Kyi announced that even though she is constitutionally barred from the presidency, she would hold the real power in any NLD-led government.
Political belief.
Asked what democratic models Myanmar could look to, she said: "We have many, many lessons to learn from various places, not just the Asian countries like South Korea, Taiwan, Mongolia, and Indonesia." She also cited "the eastern European countries, which made the transition from communist autocracy to democracy in the 1980s and 1990s, and the Latin American countries, which made the transition from military governments. "And we cannot of course forget South Africa, because although it wasn't a military regime, it was certainly an authoritarian regime." She added: "We wish to learn from everybody who has achieved a transition to democracy, and also ... our great strong point is that, because we are so far behind everybody else, we can also learn which mistakes we should avoid."
In a nod to the deep US political divide between Republicans led by Mitt Romney and the Democrats of Obama—then battling to win the 2012 Presidential election—she stressed with a smile, "Those of you who are familiar with American politics I'm sure understand the need for negotiated compromise."
International support.
Aung San Suu Kyi has received vocal support from Western nations in Europe, Australia and North and South America, as well as India, Israel, Japan the Philippines and South Korea. In December 2007, the US House of Representatives voted unanimously 400–0 to award Aung San Suu Kyi the Congressional Gold Medal; the Senate concurred on 25 April 2008. On 6 May 2008, President George Bush signed legislation awarding Suu Kyi the Congressional Gold Medal. She is the first recipient in American history to receive the prize while imprisoned. More recently, there has been growing criticism of her detention by Burma's neighbours in the Association of Southeast Asian Nations, particularly from Indonesia, Thailand, the Philippines and Singapore. At one point Malaysia warned Burma that it faced expulsion from ASEAN as a result of the detention of Suu Kyi. Other nations including South Africa, Bangladesh and the Maldives also called for her release. The United Nations has urged the country to move towards inclusive national reconciliation, the restoration of democracy, and full respect for human rights. In December 2008, the United Nations General Assembly passed a resolution condemning the human rights situation in Burma and calling for Suu Kyi's release—80 countries voting for the resolution, 25 against and 45 abstentions. Other nations, such as China and Russia, are less critical of the regime and prefer to cooperate only on economic matters. Indonesia has urged China to push Burma for reforms. However, Samak Sundaravej, former Prime Minister of Thailand, criticised the amount of support for Suu Kyi, saying that "Europe uses Aung San Suu Kyi as a tool. If it's not related to Aung San Suu Kyi, you can have deeper discussions with Myanmar."
Vietnam, however, did not support calls by other ASEAN member states for Myanmar to free Aung San Suu Kyi, state media reported Friday, 14 August 2009. The state-run Việt Nam News said Vietnam had no criticism of Myanmar's decision 11 August 2009 to place Suu Kyi under house arrest for the next 18 months, effectively barring her from elections scheduled for 2010. "It is our view that the Aung San Suu Kyi trial is an internal affair of Myanmar", Vietnamese government spokesman Le Dung stated on the website of the Ministry of Foreign Affairs. In contrast with other ASEAN member states, Dung said Vietnam has always supported Myanmar and hopes it will continue to implement the "roadmap to democracy" outlined by its government.
Aung San Suu Kyi was awarded the Nobel Peace Prize in 1991. The decision of the Nobel Committee mentions:
In 1995 Aung San Suu Kyi delivered the keynote address at the Fourth World Conference on Women in Beijing.
Nobel Peace Prize winners (Archbishop Desmond Tutu, the Dalai Lama, Shirin Ebadi, Adolfo Pérez Esquivel, Mairead Corrigan, Rigoberta Menchú, Prof. Elie Wiesel, U.S. President Barack Obama, Betty Williams, Jody Williams and former U.S. President Jimmy Carter) called for the rulers of Burma to release Suu Kyi in order to "create the necessary conditions for a genuine dialogue with Daw Aung San Suu Kyi and all concerned parties and ethnic groups in order to achieve an inclusive national reconciliation with the direct support of the United Nations." Some of the money she received as part of the award helps fund London-based charity Prospect Burma, which provides higher education grants to Burmese students.
On 16 June 2012, Aung San Suu Kyi was finally able to deliver her Nobel acceptance speech (Nobel lecture) at Oslo's City Hall, two decades after being awarded the peace prize.
In September 2012, Aung San Suu Kyi received in person the United States Congressional Gold Medal, which is the highest Congressional award. Although she was awarded this medal in 2008, at the time she was under house arrest, and was unable to receive the medal. Aung San Suu Kyi was greeted with bipartisan support at Congress, as part of a coast-to-coast tour in the United States. In addition, Aung San Suu Kyi met President Barack Obama at the White House. The experience was described by Aung San Suu Kyi as "one of the most moving days of my life."
As of 2014, she is listed as the 61st most powerful woman in the world by "Forbes".
Tributes.
U2's Bono wrote the song "Walk On" in tribute to Suu Kyi, and publicized her plight during the U2 360° Tour, 2009-2011.
Saxophonist Wayne Shorter composed a song titled "Aung San Suu Kyi". It appears on his albums 1 + 1 (with pianist Herbie Hancock) and Footprints Live!
Health problems.
She had surgery for a gynecological condition in September 2003 at Asia Royal Hospital during her house arrest. She underwent minor foot surgery in December 2013. Her doctor said that she had no serious health problems but weighed only 48 kg, had low blood pressure and could become weak easily.
Biographical film.
The life of Suu Kyi and her husband Michael Aris is portrayed in Luc Besson's 2011 film "The Lady", in which they are played by Michelle Yeoh and David Thewlis. Yeoh visited Suu Kyi in 2011 before the film's release in November.
|-

</doc>
<doc id="2851" url="https://en.wikipedia.org/wiki?curid=2851" title="Abraham Joshua Heschel">
Abraham Joshua Heschel

Abraham Joshua Heschel (January 11, 1907 – December 23, 1972) was a Polish-born American rabbi and one of the leading Jewish theologians and Jewish philosophers of the 20th century. Heschel, a professor of Jewish mysticism at the Jewish Theological Seminary of America, authored a number of widely read books on Jewish philosophy and was active in the American Civil Rights movement.
Biography.
Abraham Joshua Heschel was born in 1907 as the youngest of six children of Moshe Mordechai and Reizel Perlow. He was descended from preeminent European rabbis on both sides of his family. His paternal great-great-grandfather and namesake was Rebbe Avraham Yehoshua Heshel of Apt in present-day Poland. His mother was also a descendant of Avraham Yehoshua Heshel and other Hasidic dynasties. His siblings were Sarah, Dvora Miriam, Esther Sima, Gittel, and Jacob. Their father Moshe died of influenza in 1916 when Abraham was nine.
After a traditional yeshiva education and studying for Orthodox rabbinical ordination semicha, Heschel pursued his doctorate at the University of Berlin and a liberal rabbinic ordination at the Hochschule für die Wissenschaft des Judentums. There he studied under some of the finest Jewish educators of the time: Chanoch Albeck, Ismar Elbogen, Julius Guttmann, and Leo Baeck. Heschel later taught Talmud there. He joined a Yiddish poetry group, Jung Vilna, and in 1933, published a volume of Yiddish poems, "Der Shem Hamefoyrosh: Mentsch," dedicated to his father.
In late October 1938, when Heschel was living in a rented room in the home of a Jewish family in Frankfurt, he was arrested by the Gestapo and deported to Poland. He spent ten months lecturing on Jewish philosophy and Torah at Warsaw's Institute for Jewish Studies. Six weeks before the German invasion of Poland, Heschel left Warsaw for London with the help of Julian Morgenstern, president of Hebrew Union College, who had been working to obtain visas for Jewish scholars in Europe.
Heschel's sister Esther was killed in a German bombing. His mother was murdered by the Nazis, and two other sisters, Gittel and Devorah, died in Nazi concentration camps. He never returned to Germany, Austria or Poland. He once wrote, "If I should go to Poland or Germany, every stone, every tree would remind me of contempt, hatred, murder, of children killed, of mothers burned alive, of human beings asphyxiated."
Heschel arrived in New York City in March 1940. He served on the faculty of Hebrew Union College (HUC), the main seminary of Reform Judaism, in Cincinnati for five years. In 1946, he took a position at the Jewish Theological Seminary of America (JTS) in New York City, the main seminary of Conservative Judaism. He served as professor of Jewish ethics and Mysticism until his death in 1972.
Marriage and family.
Heschel married Sylvia Straus, a concert pianist, on December 10, 1946, in Los Angeles. Their daughter, Susannah Heschel, became a Jewish scholar in her own right. Heschel's papers are held in the Rubenstein Rare Book & Manuscript Library at Duke University.
Ideology.
Heschel explicated many facets of Jewish thought, including studies on medieval Jewish philosophy, Kabbalah, and Hasidism. According to some scholars, he was more interested in spirituality than in critical text study; the latter was a specialty of many scholars at JTS. He was not given a graduate assistant for many years and was relegated to teach mainly in the education school or Rabbinical school, not in the academic graduate program. Heschel became quite friendly with his colleague Mordecai Kaplan. Though they differed in their approach to Judaism, they had a very cordial relationship and visited each other's homes from time to time.
Heschel believed the teachings of the Hebrew prophets were a clarion call for social action in the United States and worked for African Americans' civil rights and against the Vietnam War.
He also specifically criticized what he called "pan-halakhism", or an exclusive focus upon religiously compatible behavior to the neglect of the non-legalistic dimension of rabbinic tradition.
Influence outside Judaism.
Heschel is a widely read Jewish theologian whose most influential works include "Man Is Not Alone", "God in Search of Man", "The Sabbath," and "The Prophets". At the Vatican Council II, as representative of American Jews, Heschel persuaded the Roman Catholic Church to eliminate or modify passages in its liturgy that demeaned the Jews, or referred to an expected conversion to Christianity. His theological works argued that religious experience is a fundamentally human impulse, not just a Jewish one. He believed that no religious community could claim a monopoly on religious truth.
Published works.
"The Sabbath" (1951).
"The Sabbath: Its Meaning for Modern Man" is a work on the nature and celebration of Shabbat, the Jewish Sabbath. This work is rooted in the thesis that Judaism is a religion of time, not space, and that the Sabbath symbolizes the sanctification of time.
"Man Is Not Alone" (1951).
"Man Is Not Alone: A Philosophy of Religion" offers Heschel's views on how people can comprehend God. Judaism views God as being radically different from humans, so Heschel explores the ways that Judaism teaches that a person may have an encounter with the ineffable. A recurring theme in this work is the radical amazement that people feel when experiencing the presence of the Divine. Heschel then goes on to explore the problems of doubts and faith; what Judaism means by teaching that God is one; the essence of humanity and the problem of human needs; the definition of religion in general and of Judaism in particular; and human yearning for spirituality. He offers his views as to Judaism being a pattern for life.
"God in Search of Man" (1955).
"God in Search of Man: A Philosophy of Judaism" is a companion volume to "Man Is Not Alone". In this book Heschel discusses the nature of religious thought, how thought becomes faith, and how faith creates responses in the believer. He discusses ways that people can seek God's presence, and the radical amazement that we receive in return. He offers a criticism of nature worship; a study of humanity's metaphysical loneliness, and his view that we can consider God to be in search of humanity. The first section concludes with a study of Jews as a chosen people. Section two deals with the idea of revelation, and what it means for one to be a prophet. This section gives us his idea of revelation as an event, as opposed to a process. This relates to Israel's commitment to God. Section three discusses his views of how a Jew should understand the nature of Judaism as a religion. He discusses and rejects the idea that mere faith (without law) alone is enough, but then cautions against rabbis he sees as adding too many restrictions to Jewish law. He discusses the need to correlate ritual observance with spirituality and love, the importance of Kavanah (intention) when performing mitzvot. He engages in a discussion of religious behaviorism—when people strive for external compliance with the law, yet disregard the importance of inner devotion.
"The Prophets" (1962).
This work started out as his Ph.D. thesis in German, which he later expanded and translated into English. Originally published in a two-volume edition, this work studies the books of the Hebrew prophets. It covers their lives and the historical context that their missions were set in, summarizes their work, and discusses their psychological state. In it Heschel puts forward what would become a central idea in his theology: that the prophetic (and, ultimately, Jewish) view of God is best understood not as anthropomorphic (that God takes human form) but rather as anthropopathic—that God has human feelings.
In his book "The Prophets", Abraham Joshua Heschel describes the unique aspect of the Jewish prophets as compared to other similar figures. Whereas other nations have soothsayers and diviners who attempt to discover the will of their gods, according to Heschel the Hebrew prophets are characterized by their experience of what he calls theotropism—God turning towards humanity. Heschel argues for the view of Hebrew prophets as receivers of the "Divine Pathos", of the wrath and sorrow of God over his nation that has forsaken him. In this view, prophets do not speak for God so much as they remind their audience of God's voice for the voiceless, the poor and oppressed.
He writes:
"Torah min HaShamayim" (1962).
Many consider Heschel's "Torah min HaShamayim BeAspaklariya shel HaDorot", ("Torah from Heaven in the mirror of the generations") to be his masterwork. The three volumes of this work are a study of classical rabbinic theology and aggadah, as opposed to halakha (Jewish law.) It explores the views of the rabbis in the Mishnah, Talmud and Midrash about the nature of Torah, the revelation of God to mankind, prophecy, and the ways that Jews have used scriptural exegesis to expand and understand these core Jewish texts. In this work, Heschel views the 2nd century sages Rabbis Akiva ben Yosef and Ishmael ben Elisha as paradigms for the two dominant world-views in Jewish theology
Two Hebrew volumes were published during his lifetime by Soncino Press, and the third Hebrew volume was published posthumously by JTS Press in the 1990s. An English translation of all three volumes, with notes, essays and appendices, was translated and edited by Rabbi Gordon Tucker, entitled "Heavenly Torah: As Refracted Through the Generations". In its own right it can be the subject of intense study and analysis, and provides insight into the relationship between God and Man beyond the world of Judaism and for all Monotheism.
"Prophetic Inspiration After the Prophets" (1966).
Heschel wrote a series of articles, originally in Hebrew, on the existence of prophecy in Judaism after the destruction of the Holy Temple in Jerusalem in 70 CE. These essays were translated into English and published as "Prophetic Inspiration After the Prophets: Maimonides and Others" by the American Judaica publisher Ktav.
The publisher of this book states, "The standard Jewish view is that prophecy ended with the ancient prophets, somewhere early in the Second Temple era. Heschel demonstrated that this view is not altogether accurate. Belief in the possibility of continued prophetic inspiration, and in its actual occurrence appear throughout much of the medieval period, and even in modern times. Heschel's work on prophetic inspiration in the Middle Ages originally appeared in two long Hebrew articles. In them he concentrated on the idea that prophetic inspiration was possible even in post-Talmudic times, and, indeed, had taken place at various times and in various schools, from the Geonim to Maimonides and beyond."
Commemoration.
Four schools have been named for Heschel, in the Upper West Side of New York City, Northridge, California, Agoura Hills, California, and Toronto, Canada. In 2009, a highway in Missouri was named "Dr. Abraham Joshua Heschel Highway" after a Springfield, Missouri area Neo-Nazi group cleaned the stretch of highway as part of an "Adopt-A-Highway" plan. Heschel's daughter, Susannah, has objected to the adoption of her father's name in this context.

</doc>
<doc id="2853" url="https://en.wikipedia.org/wiki?curid=2853" title="Aberdeen Bestiary">
Aberdeen Bestiary

The Aberdeen Bestiary (Aberdeen University Library, Univ Lib. MS 24) is a 12th-century English illuminated manuscript bestiary that was first listed in 1542 in the inventory of the Old Royal Library at the Palace of Westminster.
Information about its origins and patron are circumstantial. It probably comes from the 12th century and was owned by a wealthy ecclesiastical patron of the north or south province. The "Aberdeen Bestiary" is related to other bestiaries of the Middle Ages such as the "Ashmole Bestiary".
After folio 9 verso some leaves are missing which should have contained antelope ("Antalops"), unicorn ("Unicornis"), lynx ("Lynx"), griffin ("Gryps") and part of elephant ("Elephans").
After folio 15 verso some leaves are missing which should have contained crocodile ("Crocodilus"), manticore ("Mantichora") and part of parandrus ("Parandrus").
After folio 21 verso two leaves are missing which should have contained ox ("Bos"), camel ("Camelus"), dromedary ("Dromedarius"), ass ("Asinus"), onager ("Onager") and part of horse ("Equus").

</doc>
<doc id="2856" url="https://en.wikipedia.org/wiki?curid=2856" title="Latin American Integration Association">
Latin American Integration Association

The Latin American Integration Association / Asociación Latinoamericana de Integración / Associação Latino-Americana de Integração (LAIA / ALADI) is an international and regional scope organization. It was created on 12 August 1980 by the 1980 Montevideo Treaty, replacing the Latin American Free Trade Association (LAFTA / ALALC). Currently, it has 13 member countries, and any of the Latin American States may apply for accession.
Objectives.
The development of the integration process developed within the framework of the ALADI aims at promoting the harmonious and balanced socio-economic development of the region, and its long-term objective is the gradual and progressive establishment of a Latin-American Common Market.
Integration Mechanisms.
The ALADI promotes the establishment of an area of economic preferences within the region, in order to create a Latin-American common market, through three mechanisms:
The Relatively Less Economically Developed Countries of the region (Bolivia, Ecuador and Paraguay) benefit from a preferential system, through the lists of markets opening offered by the countries in favor of the Relatively Less Economically Developed Countries; special programs of cooperation (business rounds, pre-investment, financing, technological support); and countervailing measures in favor of the land-locked countries, the full participation of such countries in the integration process is sought.
The ALADI includes in its legal structure the strongest sub-regional, plurilateral and bilateral integration agreements arising in growing numbers in the continent. As a result, the ALADI – as an institutional and legal framework or “umbrella” of the regional integration- develops actions in order to support and foster these efforts for the progressive establishment of a common economic space.
Accession of other Latin-American countries.
The 1980 Montevideo Treaty is open to the accession of any Latin-American country. 
On 26 August 1999, the first accession to the 1980 Montevideo Treaty was executed, with the incorporation of the Republic of Cuba as a member country of the ALADI. 
On 10 May 2012, the Republic of Panama became the thirteenth member country of the ALADI. 
Likewise, the accession of the Republic of Nicaragua was accepted in the Sixteenth Meeting of the Council of Ministers (Resolution 75 (XVI)), held on 11 August 2011. Currently, Nicaragua moves towards the fulfillment of conditions for becoming a member country of the ALADI.
The ALADI opens its field of actions for the rest of Latin America through multilateral links or partial agreements with other countries and integration areas of the continent (Article 25).
The Latin-American Integration Association also contemplates the horizontal cooperation with other integration movements in the world and partial actions with third developing countries or their respective integration areas (Article 27).
The Council of Ministers is the supreme body of the ALADI, and adopts the decisions for the superior political management of the integration process. 
Institutional Structure.
It is constituted by the Ministers of Foreign Affairs of the member countries. Notwithstanding, when one of such member countries assigns the competence of the integration affairs to a different Minister or Secretary of State, the member countries may be represented, with full powers, by the respective Minister or Secretary. It is convened by the Committee of Representatives, meets and makes decisions with the presence of all the member countries.
It is in charge, among others, of analyzing the functioning of the integration process in all its aspects, promoting the convergence of the partial scope agreements seeking their progressive multilateralization, and promoting greater scope actions as regards economic integration. It is made up of Plenipotentiaries of the member countries.
It is the permanent political body and negotiating forum of the ALADI, where all the initiatives for the fulfillment of the objectives established by the 1980 Montevideo Treaty are analyzed and agreed on. It is composed of a Permanent Representative of each member country with right to one vote and an Alternate Representative. It meets regularly every 15 days and its Resolutions are adopted by the affirmative vote of two thirds of the member countries.
It is the technical body of the ALADI, and it may propose, evaluate, study and manage for the fulfillment of the objectives of the ALADI. It is composed of technical and administrative personnel, and directed by a Secretary-General, who has the support of two Undersecretaries, elected for a three-year period, renewable for the same term.

</doc>
<doc id="2858" url="https://en.wikipedia.org/wiki?curid=2858" title="Aircraft spotting">
Aircraft spotting

Aircraft spotting or plane spotting is the observation, photographing, and logging of the registration numbers of aircraft, which includes gliders, balloons, airships, helicopters, and microlights.
History and evolution.
Aviation enthusiasts have been watching airplanes and other aircraft ever since they were invented. However, plane spotting was not considered a distinct hobby until the second half of the 20th century.
The development of technology and global resources enabled a revolution in spotting. Point and shoot cameras, DSLRs & walkie talkies significantly changed the hobby. With the help of the internet, websites, such as FlightAware, have made it possible for spotters to track and locate specific aircraft from all across the world. Websites, such as PlaneLogger.com, allow spotters to record their sightings and upload their shots or see pictures of aircraft spotted by other people from all over the world.
Techniques.
When spotting aircraft, observers generally notice the key attributes of an aircraft, such as a distinctive noise from its engine or the number of vapour trails it is leaving. Observers assess the size of the aircraft and the number, type and position of its engines. Another distinctive attribute is the position of wings relative to the fuselage and the degree to which they are swept rearwards. The wings may be above the fuselage, below it, or fixed at midpoint. The number of wings indicate whether it is a monoplane, biplane, or triplane. The position of the tailplane relative to the fin(s) and the shape of the fin are other attributes. The configuration of the landing gear can be distinctive, as well.
Other features include the speed, cockpit placement, colour scheme or special equipment that changes the silhouette of the aircraft. Taken together these traits will enable the identification of an aircraft. If the observer is familiar with the airfield being used by the aircraft and its normal traffic patterns, he or she is more likely to leap quickly to a decision about the aircraft's identity - they may have seen the same type of aircraft from the same angle many times. This is particularly prevalent if the aircraft spotter is spotting commercial aircraft, operated by airlines that have a limited fleet. 
Spotters use equipment such as ADS-B decoders to track the movements of aircraft. The two most famous devices used are the AirNav Systems RadarBox and Kinetic Avionics SBS series. Both of them read and process the radar data and show the movements on a computer screen. Most of the decoders also allow the exporting of logs from a certain route or airport.
Spotting styles.
Some spotters will note and compile the markings, a national insignia or airline livery or logo, a squadron badge or code letters in the case of a military aircraft. Published manuals allow more information to be deduced, such as the delivery date or the manufacturer's construction number. Camouflage markings differ, depending on the surroundings in which that aircraft is expected to operate.
In general, most spotters attempt to see as many aircraft of a given type, a particular airline, or a particular subset of aircraft such as business jets, commercial airliners, military and/or general aviation aircraft. Some spotters attempt to see every airframe and are known as "frame spotters." Others are keen to see every registration worn by each aircraft. 
Ancillary activities might include listening-in to air traffic control transmissions (using radio scanners, where that is legal), liaising with other "spotters" to clear up uncertainties as to what aircraft have been seen at specific times or in particular places. Several internet mailing list groups have been formed to help communicate aircraft seen at airports, queries and anomalies. These groups can cater to certain regions, certain aircraft types, or may appeal to a wider audience. Many of these groups originated from the original Oxford.vax group which pioneered this type of communication. The result is that information on aircraft movements can be delivered worldwide in a real-time fashion to spotters.
The hobbyist might travel long distances to visit different airports, to see an unusual aircraft, or to view the remains of aircraft withdrawn from use. Some aircraft may be placed in the care of museums (see Aviation archaeology) - or perhaps be cannibalized in order to repair a similar aircraft already preserved.
Aircraft registrations can be found in books, with online resources, or in monthly magazines from enthusiast groups. Most spotters maintained books of different aircraft fleets and would underline or check each aircraft seen. Each year, a revised version of the books would be published and the spotter would need to re-underline every aircraft seen. With the development of commercial aircraft databases spotters were finally able to record their sightings in an electronic database and produce reports that emulated the underlined books.
During hostilities.
During World War II and the subsequent Cold War some countries encouraged their citizens to become "plane spotters" in an "observation corps" or similar public body for reasons of public security. Britain had the Royal Observer Corps which operated between 1925 and 1995. A journal called The Aeroplane Spotter was published in January 1940. The publication included a glossary that was refined in 2010 and published online.
Air shows.
Air shows usually draw large numbers of spotters as it is a chance to enter airfields and air bases worldwide that are usually closed to the public and to see displayed aircraft at close range.
Legal ramifications.
The legal repercussions of the hobby were dramatically shown in November 2001 when fourteen aircraft spotters (twelve British, two Dutch) were arrested by Greek police after being observed at an open day at the Greek Air Force base at Kalamata. They were charged with espionage, and faced a possible 20-year prison sentence if found guilty. After being held for six weeks, they were eventually released on £9,000 bail, and the charges reduced to the misdemeanor charge of illegal information collection. Confident of their innocence they returned for their trial in April 2002 and were stunned to be found guilty, with eight of the group sentenced to three years, the rest for one year. At their appeal a year later all were acquitted. 
Fight against terrorism.
In the wake of the targeting of airports by terrorists, enthusiasts' organizations and police in the UK have cooperated in creating a code of conduct for plane spotters. By asking enthusiasts to contact police if spotters believe they see or hear something suspicious, this is an attempt to allow enthusiasts to continue their hobby while increasing security around airports. Birmingham and Stansted pioneered this approach in England and prior to the 2012 London Olympics, RAF Northolt introduced a "Flightwatch" scheme based on the same cooperative principles. These changes are also being made abroad in countries like Australia, where aviation enthusiasts are reporting suspicious or malice actions to police.
The organization of such groups has now been echoed in parts of North America. For example, the Bensenville Illinois Police Department have sponsored an "Airport Watch" group at the Chicago O'Hare Airport. Members are issued identification cards and given training to accurately record and report unusual activities around the airport perimeter (members are not permitted airside). Meetings are attended and supported by the FBI, Chicago Department of Aviation and the TSA who also provide regular training to group members. The Bensenville program was modeled on similar programs in Toronto, Ottawa and Minneapolis.
Extraordinary rendition.
Following the events of 9/11, information collected by planespotters helped uncover what is known as "extraordinary rendition" by the CIA. Information on unusual movements of rendition aircraft provided data which led first to news reports and then to a number of governmental and inter-governmental investigations.

</doc>
<doc id="2861" url="https://en.wikipedia.org/wiki?curid=2861" title="Advertising">
Advertising

Advertising (or advertizing) is a form of marketing communication used to promote or sell something, usually a business's product or service.
In Latin, "ad vertere" means "to turn toward". The purpose of advertising may also be to reassure employees or shareholders that a company is viable or successful. Advertising messages are usually paid for by sponsors and viewed via various old media; including mass media such as newspaper, magazines, television advertisement, radio advertisement, outdoor advertising or direct mail; or new media such as blogs, websites or text messages.
Commercial ads seek to generate increased consumption of their products or services through "branding," which associates a product name or image with certain qualities in the minds of consumers. Non-commercial advertisers who spend money to advertise items other than a consumer product or service include political parties, interest groups, religious organizations and governmental agencies. Non-profit organizations may use free modes of persuasion, such as a public service announcement.
Modern advertising was created with the techniques introduced with tobacco advertising in the 1920s, most significantly with the campaigns of Edward Bernays, considered the founder of modern, "Madison Avenue" advertising.
In 2015, the world will spend about on advertising. Internationally, the largest ("big four") advertising conglomerates are Interpublic, Omnicom, Publicis, and WPP.
History.
Egyptians used papyrus to make sales messages and wall posters. Commercial messages and political campaign displays have been found in the ruins of Pompeii and ancient Arabia. Lost and found advertising on papyrus was common in Ancient Greece and Ancient Rome. Wall or rock painting for commercial advertising is another manifestation of an ancient advertising form, which is present to this day in many parts of Asia, Africa, and South America. The tradition of wall painting can be traced back to Indian rock art paintings that date back to 4000 BC.
In ancient China, the earliest advertising known was oral, as recorded in the Classic of Poetry (11th to 7th centuries BC) of bamboo flutes played to sell candy. Advertisement usually takes in the form of calligraphic signboards and inked papers. A copper printing plate dated back to the Song dynasty used to print posters in the form of a square sheet of paper with a rabbit logo with "Jinan Liu's Fine Needle Shop" and "We buy high-quality steel rods and make fine-quality needles, to be ready for use at home in no time" written above and below is considered the world's earliest identified printed advertising medium.
In Europe, as the towns and cities of the Middle Ages began to grow, and the general populace was unable to read, instead of signs that read "cobbler", "miller", "tailor", or "blacksmith" would use an image associated with their trade such as a boot, a suit, a hat, a clock, a diamond, a horse shoe, a candle or even a bag of flour. Fruits and vegetables were sold in the city square from the backs of carts and wagons and their proprietors used street callers (town criers) to announce their whereabouts for the convenience of the customers. The first compilation of such advertisements was gathered in "Les Crieries de Paris", a thirteenth-century poem by Guillaume de la Villeneuve.
In the 18th century advertisements started to appear in weekly newspapers in England. These early print advertisements were used mainly to promote books and newspapers, which became increasingly affordable with advances in the printing press; and medicines, which were increasingly sought after as disease ravaged Europe. However, false advertising and so-called "quack" advertisements became a problem, which ushered in the regulation of advertising content.
19th century.
Thomas J. Barratt from London has been called "the father of modern advertising". Working for the Pears Soap company, Barratt created an effective advertising campaign for the company products, which involved the use of targeted slogans, images and phrases. One of his slogans, "Good morning. Have you used Pears' soap?" was famous in its day and into the 20th century.
Barratt introduced many of the crucial ideas that lie behind successful advertising and these were widely circulated in his day. He constantly stressed the importance of a strong and exclusive brand image for Pears and of emphasizing the product's availability through saturation campaigns. He also understood the importance of constantly reevaluating the market for changing tastes and mores, stating in 1907 that "tastes change, fashions change, and the advertiser has to change with them. An idea that was effective a generation ago would fall flat, stale, and unprofitable if presented to the public today. Not that the idea of today is always better than the older idea, but it is different – it hits the present taste."
As the economy expanded across the world during the 19th century, advertising grew alongside. In the United States, the success of this advertising format eventually led to the growth of mail-order advertising.
In June 1836, French newspaper "La Presse" was the first to include paid advertising in its pages, allowing it to lower its price, extend its readership and increase its profitability and the formula was soon copied by all titles. Around 1840, Volney B. Palmer established the roots of the modern day advertising agency in Philadelphia. In 1842 Palmer bought large amounts of space in various newspapers at a discounted rate then resold the space at higher rates to advertisers. The actual ad – the copy, layout, and artwork – was still prepared by the company wishing to advertise; in effect, Palmer was a space broker. The situation changed in the late 19th century when the advertising agency of N.W. Ayer & Son was founded. Ayer and Son offered to plan, create, and execute complete advertising campaigns for its customers. By 1900 the advertising agency had become the focal point of creative planning, and advertising was firmly established as a profession.
20th century.
Advertising increased dramatically in the United States as industrialization expanded the supply of manufactured products. In order to profit from this higher rate of production, industry needed to recruit workers as consumers of factory products. It did so through the invention of mass marketing designed to influence the population's economic behavior on a larger scale. In the 1910s and 1920s, advertisers in the U.S. adopted the doctrine that human instincts could be targeted and harnessed – "sublimated" into the desire to purchase commodities. Edward Bernays, a nephew of Sigmund Freud, became associated with the method and is sometimes called the founder of modern advertising and public relations.
In the 1920s, under Secretary of Commerce Herbert Hoover, the American government promoted advertising. Hoover himself delivered an address to the Associated Advertising Clubs of the World in 1925 called 'Advertising Is a Vital Force in Our National Life." In October 1929, the head of the U.S. Bureau of Foreign and Domestic Commerce, Julius Klein, stated "Advertising is the key to world prosperity." This was part of the "unparalleled" collaboration between business and government in the 1920s, according to a 1933 European economic journal.
The tobacco companies became major advertisers in order to sell packaged cigarettes. The tobacco companies pioneered the new advertising techniques when they hired Bernays to create positive associations with tobacco smoking.
Advertising was also used as a vehicle for cultural assimilation, encouraging workers to exchange their traditional habits and community structure in favor of a shared "modern" lifestyle. An important tool for influencing immigrant workers was the American Association of Foreign Language Newspapers (AAFLN). The AAFLN was primarily an advertising agency but also gained heavily centralized control over much of the immigrant press.
At the turn of the 20th century, there were few career choices for women in business; however, advertising was one of the few. Since women were responsible for most of the purchasing done in their household, advertisers and agencies recognized the value of women's insight during the creative process. In fact, the first American advertising to use a sexual sell was created by a woman – for a soap product. Although tame by today's standards, the advertisement featured a couple with the message "A skin you love to touch".
In the 1920s psychologists Walter D. Scott and John B. Watson contributed applied psychological theory to the field of advertising. Scott said, "Man has been called the reasoning animal but he could with greater truthfulness be called the creature of suggestion. He is reasonable, but he is to a greater extent suggestible". He demonstrated this through his advertising technique of a direct command to the consumer.
On the radio from the 1920s.
In the early 1920s, the first radio stations were established by radio equipment manufacturers and retailers who offered programs in order to sell more radios to consumers. As time passed, many non-profit organizations followed suit in setting up their own radio stations, and included: schools, clubs and civic groups.
When the practice of sponsoring programs was popularized, each individual radio program was usually sponsored by a single business in exchange for a brief mention of the business' name at the beginning and end of the sponsored shows. However, radio station owners soon realized they could earn more money by selling sponsorship rights in small time allocations to multiple businesses throughout their radio station's broadcasts, rather than selling the sponsorship rights to single businesses per show.
Commercial television in the 1950s.
In the early 1950s, the DuMont Television Network began the modern practice of selling advertisement time to multiple sponsors. Previously, DuMont had trouble finding sponsors for many of their programs and compensated by selling smaller blocks of advertising time to several businesses. This eventually became the standard for the commercial television industry in the United States. However, it was still a common practice to have single sponsor shows, such as The United States Steel Hour. In some instances the sponsors exercised great control over the content of the show – up to and including having one's advertising agency actually writing the show. The single sponsor model is much less prevalent now, a notable exception being the Hallmark Hall of Fame.
Cable television from the 1980s.
The late 1980s and early 1990s saw the introduction of cable television and particularly MTV. Pioneering the concept of the music video, MTV ushered in a new type of advertising: the consumer tunes in "for" the advertising message, rather than it being a by-product or afterthought. As cable and satellite television became increasingly prevalent, specialty channels emerged, including channels entirely devoted to advertising, such as QVC, Home Shopping Network, and ShopTV Canada.
On the Internet from the 1990s.
With the advent of the ad server, online advertising grew, contributing to the "dot-com" boom of the 1990s. Entire corporations operated solely on advertising revenue, offering everything from coupons to free Internet access. At the turn of the 21st century, some websites, including the search engine Google, changed online advertising by personalizing ads based on web browsing behavior. This has led to other similar efforts and an increase in interactive advertising.
The share of advertising spending relative to GDP has changed little across large changes in media since 1925. In 1925, the main advertising media in America were newspapers, magazines, signs on streetcars, and outdoor posters. Advertising spending as a share of GDP was about 2.9 percent. By 1998, television and radio had become major advertising media. Nonetheless, advertising spending as a share of GDP was slightly lower – about 2.4 percent.
Guerrilla marketing involves unusual approaches such as staged encounters in public places, giveaways of products such as cars that are covered with brand messages, and interactive advertising where the viewer can respond to become part of the advertising message. This type of advertising is unpredictable, which causes consumers to buy the product or idea. This reflects an increasing trend of interactive and "embedded" ads, such as via product placement, having consumers vote through text messages, and various campaigns utilizing social network services such as Facebook or Twitter.
The advertising business model has also been adapted in recent years. In media for equity, advertising is not sold, but provided to start-up companies in return for equity. If the company grows and is sold, the media companies receive cash for their shares.
Domain name registrants (usually those who register and renew domains as an investment) sometimes "park" their domains and allow advertising companies to place ads on their sites in return for per-click payments. These ads are typically driven by pay per click search engines like Google or Yahoo, but ads can sometimes be placed directly on targeted domain names through a domain lease or by making contact with the registrant of a domain name that describes a product. Domain name registrants are generally easy to identify through WHOIS records that are publicly available at registrar websites.
Advertising theory.
Hierarchy-of-effects models.
Various competing models of hierarchies of effects attempt to provide a theoretical underpinning to advertising practice.
Marketing mix.
The marketing mix was proposed by professor E. Jerome McCarthy in the 1960s. It consists of four basic elements called the "four Ps". Product is the first P representing the actual product. Price represents the process of determining the value of a product. Place represents the variables of getting the product to the consumer such as distribution channels, market coverage and movement organization. The last P stands for Promotion which is the process of reaching the target market and convincing them to buy the product.
In the 1990s, the concept of four Cs was introduced as a more customer-driven replacement of four P's. There are two theories based on four Cs: Lauterborn's four Cs ("consumer", "cost", "communication", "convenience")
Types of advertising.
Virtually any medium can be used for advertising. Commercial advertising media can include wall paintings, billboards, street furniture components, printed flyers and rack cards, radio, cinema and television adverts, web banners, mobile telephone screens, shopping carts, web popups, skywriting, bus stop benches, human billboards and forehead advertising, magazines, newspapers, town criers, sides of buses, banners attached to or sides of airplanes ("logojets"), in-flight advertisements on seatback tray tables or overhead storage bins, taxicab doors, roof mounts and passenger screens, musical stage shows, subway platforms and trains, elastic bands on disposable diapers, doors of bathroom stalls, stickers on apples in supermarkets, shopping cart handles (grabertising), the opening section of streaming audio and video, posters, and the backs of event tickets and supermarket receipts. Any place an "identified" sponsor pays to deliver their message through a medium is advertising.
Purpose of advertising.
Advertising is at the front of delivering the proper message to customers and prospective customers. The purpose of advertising is to convince customers that a company's services or products are the best, enhance the image of the company, point out and create a need for products or services, demonstrate new uses for established products, announce new products and programs, reinforce the salespeople's individual messages, draw customers to the business, and to hold existing customers.
Sales promotions and brand loyalty.
Sales promotions are another way to advertise. Sales promotions are double purposed because they are used to gather information about what type of customers one draws in and where they are, and to jump start sales. Sales promotions include things like contests and games, sweepstakes, product giveaways, samples coupons, loyalty programs, and discounts. The ultimate goal of sales promotions is to stimulate potential customers to action.
One way to create brand loyalty is to reward consumers for spending time interacting with the brand. This method may come in many forms like rewards card, rewards programs and sampling.
Media and advertising approaches.
Increasingly, other media are overtaking many of the "traditional" media such as television, radio and newspaper because of a shift toward the usage of the Internet for news and music as well as devices like digital video recorders (DVRs) such as TiVo.
Advertising on the World Wide Web is a recent phenomenon. Prices of Web-based advertising space are dependent on the "relevance" of the surrounding web content and the traffic that the website receives.
In online display advertising, display ads generate awareness quickly. Unlike search, which requires someone to be aware of a need, display advertising can drive awareness of something new and without previous knowledge. Display works well for direct response. Display is not only used for generating awareness, it's used for direct response campaigns that link to a landing page with a clear 'call to action'.
E-mail advertising is another recent phenomenon. Unsolicited bulk E-mail advertising is known as "e-mail spam". Spam has been a problem for e-mail users for many years.
As the mobile phone became a new mass medium in 1998 when the first paid downloadable content appeared on mobile phones in Finland, mobile advertising followed, also first launched in Finland in 2000. By 2007 the value of mobile advertising had reached $2 billion and providers such as Admob delivered billions of mobile ads.
More advanced mobile ads include banner ads, coupons, Multimedia Messaging Service picture and video messages, advergames and various engagement marketing campaigns. A particular feature driving mobile ads is the 2D barcode, which replaces the need to do any typing of web addresses, and uses the camera feature of modern phones to gain immediate access to web content. 83 percent of Japanese mobile phone users already are active users of 2D barcodes.
Some companies have proposed placing messages or corporate logos on the side of booster rockets and the International Space Station.
Unpaid advertising (also called "publicity advertising"), can include personal recommendations ("bring a friend", "sell it"), spreading buzz, or achieving the feat of equating a brand with a common noun (in the United States, "Xerox" = "photocopier", "Kleenex" = tissue, "Vaseline" = petroleum jelly, "Hoover" = vacuum cleaner, and "Band-Aid" = adhesive bandage). However, some companies oppose the use of their brand name to label an object. Equating a brand with a common noun also risks turning that brand into a generic trademark – turning it into a generic term which means that its legal protection as a trademark is lost.
From time to time, The CW Television Network airs short programming breaks called "Content Wraps", to advertise one company's product during an entire commercial break. The CW pioneered "content wraps" and some products featured were Herbal Essences, Crest, Guitar Hero II, CoverGirl, and recently Toyota.
A new promotion concept has appeared, "ARvertising", advertising on Augmented Reality technology.
Controversy exists on the effectiveness of subliminal advertising (see mind control), and the pervasiveness of mass messages (see propaganda).
Rise in new media.
With the Internet came many new advertising opportunities. Popup, Flash, banner, Popunder, advergaming, and email advertisements (all of which are often unwanted or spam in the case of email) are now commonplace. Particularly since the rise of "entertaining" advertising, some people may like an advertisement enough to wish to watch it later or show a friend. In general, the advertising community has not yet made this easy, although some have used the Internet to widely distribute their ads to anyone willing to see or hear them. In the last three-quarters of 2009 mobile and internet advertising grew by 18% and 9% respectively. Older media advertising saw declines: −10.1% (TV), −11.7% (radio), −14.8% (magazines) and −18.7% (newspapers).
Niche marketing.
Another significant trend regarding future of advertising is the growing importance of the niche market using niche or targeted ads. Also brought about by the Internet and the theory of The Long Tail, advertisers will have an increasing ability to reach specific audiences. In the past, the most efficient way to deliver a message was to blanket the largest mass market audience possible. However, usage tracking, customer profiles and the growing popularity of niche content brought about by everything from blogs to social networking sites, provide advertisers with audiences that are smaller but much better defined, leading to ads that are more relevant to viewers and more effective for companies' marketing products. Among others, Comcast Spotlight is one such advertiser employing this method in their video on demand menus. These advertisements are targeted to a specific group and can be viewed by anyone wishing to find out more about a particular business or practice, from their home. This causes the viewer to become proactive and actually choose what advertisements they want to view.
Google AdSense is an example of niche marketing. Google calculates the primary purpose of a website and adjusts ads accordingly; it uses key words on the page (or even in emails) to find the general ideas of topics disused and places ads that will most likely be clicked on by viewers of the email account or website visitors.
Crowdsourcing.
The concept of crowdsourcing has given way to the trend of user-generated advertisements. User-generated ads are created by people, as opposed to an advertising agency or the company themselves, often resulting from brand sponsored advertising competitions. For the 2007 Super Bowl, the Frito-Lays division of PepsiCo held the "Crash the Super Bowl" contest, allowing people to create their own Doritos commercial. Chevrolet held a similar competition for their Tahoe line of SUVs. Due to the success of the Doritos user-generated ads in the 2007 Super Bowl, Frito-Lays relaunched the competition for the 2009 and 2010 Super Bowl. The resulting ads were among the most-watched and most-liked Super Bowl ads. In fact, the winning ad that aired in the 2009 Super Bowl was ranked by the USA Today Super Bowl Ad Meter as the top ad for the year while the winning ads that aired in the 2010 Super Bowl were found by Nielsen's BuzzMetrics to be the "most buzzed-about". Another example of companies using crowdsourcing successfully is the beverage company Jones Soda that encourages consumers to participate in the label design themselves.
This trend has given rise to several online platforms that host user-generated advertising competitions on behalf of a company. Founded in 2007, Zooppa has launched ad competitions for brands such as Google, Nike, Hershey's, General Mills, Microsoft, NBC Universal, Zinio, and Mini Cooper. Crowdsourced remains controversial, as the long-term impact on the advertising industry is still unclear.
Global advertising.
Advertising has gone through five major stages of development: domestic, export, international, multi-national, and global. For global advertisers, there are four, potentially competing, business objectives that must be balanced when developing worldwide advertising: building a brand while speaking with one voice, developing economies of scale in the creative process, maximising local effectiveness of ads, and increasing the company's speed of implementation. Born from the evolutionary stages of global marketing are the three primary and fundamentally different approaches to the development of global advertising executions: exporting executions, producing local executions, and importing ideas that travel.
Advertising research is key to determining the success of an ad in any country or region. The ability to identify which elements and/or moments of an ad contribute to its success is how economies of scale are maximized. Once one knows what works in an ad, that idea or ideas can be imported by any other market. Market research measures, such as , and provide insight into what is working in an ad in any country or region because the measures are based on the visual, not verbal, elements of the ad.
Foreign public messaging.
Foreign governments, particularly those that own marketable commercial products or services, often promote their interests and positions through the advertising of those goods because the target audience is not only largely unaware of the forum as a vehicle for foreign messaging but also willing to receive the message while in a mental state of absorbing information from advertisements during television commercial breaks, while reading a periodical, or while passing by billboards in public spaces. A prime example of this messaging technique is advertising campaigns to promote international travel. While advertising foreign destinations and services may stem from the typical goal of increasing revenue by drawing more tourism, some travel campaigns carry the additional or alternative intended purpose of promoting good sentiments or improving existing ones among the target audience towards a given nation or region. It is common for advertising promoting foreign countries to be produced and distributed by the tourism ministries of those countries, so these ads often carry political statements and/or depictions of the foreign government's desired international public perception. Additionally, a wide range of foreign airlines and travel-related services which advertise separately from the destinations, themselves, are owned by their respective governments; examples include, though are not limited to, the Emirates airline (Dubai), Singapore Airlines (Singapore), Qatar Airways (Qatar), China Airlines (Taiwan/Republic of China), and Air China (People's Republic of China). By depicting their destinations, airlines, and other services in a favorable and pleasant light, countries market themselves to populations abroad in a manner that could mitigate prior public impressions.
Diversification.
In the realm of advertising agencies, continued industry diversification has seen observers note that "big global clients don't need big global agencies any more". This is reflected by the growth of non-traditional agencies in various global markets, such as Canadian business TAXI and SMART in Australia and has been referred to as "a revolution in the ad world".
New technology.
The ability to record shows on digital video recorders (such as TiVo) allow watchers to record the programs for later viewing, enabling them to fast forward through commercials. Additionally, as more seasons of pre-recorded box sets are offered for sale of television programs; fewer people watch the shows on TV. However, the fact that these sets are sold, means the company will receive additional profits from the these sets.
To counter this effect, a variety of strategies have been employed. Many advertisers have opted for product placement on TV shows like Survivor. Other strategies include integrating advertising with internet-connected EPGs, advertising on companion devices (like smartphones and tablets) during the show, and creating TV apps. Additionally, some like brands have opted for social television sponsorship.
Advertising education.
Advertising education has become popular with bachelor, master and doctorate degrees becoming available in the emphasis. A surge in advertising interest is typically attributed to the strong relationship advertising plays in cultural and technological changes, such as the advance of online social networking. A unique model for teaching advertising is the student-run advertising agency, where advertising students create campaigns for real companies. Organizations such as the American Advertising Federation establish companies with students to create these campaigns.
Criticisms.
While advertising can be seen as necessary for economic growth, it is not without social costs. Unsolicited commercial e-mail and other forms of spam have become so prevalent as to have become a major nuisance to users of these services, as well as being a financial burden on internet service providers. Advertising is increasingly invading public spaces, such as schools, which some critics argue is a form of child exploitation.
One of the most controversial criticisms of advertisement in the present day is that of the predominance of advertising of foods high in sugar, fat, and salt specifically to children. Critics claim that food advertisements targeting children are exploitive and are not sufficiently balanced with proper nutritional education to help children understand the consequences of their food choices. Additionally, children may not understand that they are being sold something, and are therefore more impressionable. Michelle Obama has criticized large food companies for advertising unhealthy foods largely towards children and has requested that food companies either limit their advertising to children or advertise foods that are more in line with dietary guidelines.
Regulation.
There have been increasing efforts to protect the public interest by regulating the content and the influence of advertising. Some examples are: the ban on television tobacco advertising imposed in many countries, and the total ban of advertising to children under 12 imposed by the Swedish government in 1991. Though that regulation continues in effect for broadcasts originating within the country, the European Court of Justice ruled that Sweden was obliged to accept foreign programming, including those from neighboring countries or via satellite. Greece's regulations are of a similar nature, "banning advertisements for children's toys between 7 am and 10 pm and a total ban on advertisement for war toys".
In Europe and elsewhere, there is a vigorous debate on whether (or how much) advertising to children should be regulated. This debate was exacerbated by a report released by the Kaiser Family Foundation in February 2004 which suggested fast food advertising that targets children was an important factor in the epidemic of childhood obesity in the United States.
In New Zealand, South Africa, Pakistan, Afghanistan, Canada, and many European countries, the advertising industry operates a system of self-regulation. Advertisers, advertising agencies and the media agree on a code of advertising standards that they attempt to uphold. The general aim of such codes is to ensure that any advertising is 'legal, decent, honest and truthful'. Some self-regulatory organizations are funded by the industry, but remain independent, with the intent of upholding the standards or codes like the Advertising Standards Authority in the UK.
In the UK, most forms of outdoor advertising such as the display of billboards is regulated by the UK Town and County Planning system. Currently, the display of an advertisement without consent from the Planning Authority is a criminal offense liable to a fine of £2,500 per offense. All of the major outdoor billboard companies in the UK have convictions of this nature.
In the US, many communities believe that many forms of outdoor advertising blight the public realm. As long ago as the 1960s in the US there were attempts to ban billboard advertising in the open countryside. Cities such as São Paulo have introduced an outright ban with London also having specific legislation to control unlawful displays.
Many advertisers employ a wide-variety of linguistic devices to bypass regulatory laws (e.g. In France, printing English words in bold and French translations in fine print to deal with the Article 120 of the 1994 Toubon Law limiting the use of English). The advertisement of controversial products such as cigarettes and condoms are subject to government regulation in many countries. For instance, the tobacco industry is required by law in most countries to display warnings cautioning consumers about the health hazards of their products. Linguistic variation is often used by advertisers as a creative device to reduce the impact of such requirements.
Advertising research.
Advertising research is a specialized form of research that works to improve the effectiveness and efficiency of advertising. It entails numerous forms of research which employ different methodologies. Advertising research includes pre-testing (also known as copy testing) and post-testing of ads and/or campaigns – pre-testing is done before an ad airs to gauge how well it will perform and post-testing is done after an ad airs to determine the in-market impact of the ad or campaign. Continuous ad tracking and the Communicus System are competing examples of post-testing advertising research types.
Semiotics.
Meanings between consumers and marketers depict signs and symbols that are encoded in everyday objects. Semiotics is the study of signs and how they are interpreted. Advertising has many hidden signs and meanings within brand names, logos, package designs, print advertisements, and television advertisements. Semiotics aims to study and interpret the message being conveyed in (for example) advertisements. Logos and advertisements can be interpreted at two levels - known as the surface level and the underlying level. The surface level uses signs creatively to create an image or personality for a product. These signs can be images, words, fonts, colors, or slogans. The underlying level is made up of hidden meanings. The combination of images, words, colors, and slogans must be interpreted by the audience or consumer. The "key to advertising analysis" is the signifier and the signified. The signifier is the object and the signified is the mental concept. A product has a signifier and a signified. The signifier is the color, brand name, logo design, and technology. The signified has two meanings known as denotative and connotative. The denotative meaning is the meaning of the product. A television's denotative meaning might be that it is high definition. The connotative meaning is the product's deep and hidden meaning. A connotative meaning of a television would be that it is top-of-the-line.
Apple's commercials used a black silhouette of a person that was the age of Apple's target market. They placed the silhouette in front of a blue screen so that the picture behind the silhouette could be constantly changing. However, the one thing that stays the same in these ads is that there is music in the background and the silhouette is listening to that music on a white iPod through white headphones. Through advertising, the white color on a set of earphones now signifies that the music device is an iPod. The white color signifies almost all of Apple's products.
The semiotics of gender plays a key influence on the way in which signs are interpreted. When considering gender roles in advertising, individuals are influenced by three categories. Certain characteristics of stimuli may enhance or decrease the elaboration of the message (if the product is perceived as feminine or masculine). Second, the characteristics of individuals can affect attention and elaboration of the message (traditional or non-traditional gender role orientation). Lastly, situational factors may be important to influence the elaboration of the message.
There are two types of marketing communication claims-objective and subjective. Objective claims stem from the extent to which the claim associates the brand with a tangible product or service feature. For instance, a camera may have auto-focus features. Subjective claims convey emotional, subjective, impressions of intangible aspects of a product or service. They are non-physical features of a product or service that cannot be directly perceived, as they have no physical reality. For instance the brochure has a beautiful design. Males tend to respond better to objective marketing-communications claims while females tend to respond better to subjective marketing communications claims.
Voiceovers are commonly used in advertising. Most voiceovers are done by men, with figures of up to 94% having been reported. There have been more female voiceovers in recent years, but mainly for food, household products, and feminine-care products.
Gender effects in the processing of advertising.
According to a 1977 study by David Statt, females process information comprehensively, while males process information through heuristic devices such as procedures, methods or strategies for solving problems, which could have an effect on how they interpret advertising. According to this study, men prefer to have available and apparent cues to interpret the message where females engage in more creative, associative, imagery-laced interpretation. Later research by a Danish team found that advertising attempts to persuade men to improve their appearance or performance, whereas its approach to women is aimed at transformation toward an impossible ideal of female presentation. Advertising's manipulation of women's aspiration to these ideal types, as they are portrayed in film, in erotic art, in advertising, on stage, music video, and other media exposures, requires at least a conditioned rejection of female reality, and thereby takes on a highly ideological cast. Not everyone agrees: one critic viewed this monologic, gender-specific interpretation of advertising as excessively skewed and politicized.
More recently, research by Martin (2003) reveals that males and females differ in how they react to advertising depending on their mood at the time of exposure to the ads, and the affective tone of the advertising. When feeling sad, males prefer happy ads to boost their mood. In contrast, females prefer happy ads when they are feeling happy. The television programs in which the ads are embedded are shown to influence a viewer's mood state.
References.
Notes

</doc>
<doc id="2862" url="https://en.wikipedia.org/wiki?curid=2862" title="AI-complete">
AI-complete

In the field of artificial intelligence, the most difficult problems are informally known as AI-complete or AI-hard, implying that the difficulty of these computational problems is equivalent to that of solving the central artificial intelligence problem—making computers as intelligent as people, or strong AI. To call a problem AI-complete reflects an attitude that it would not be solved by a simple specific algorithm. 
AI-complete problems are hypothesised to include computer vision, natural language understanding, and dealing with unexpected circumstances while solving any real world problem.
Currently, AI-complete problems cannot be solved with modern computer technology alone, but would also require human computation. This property can be useful, for instance to test for the presence of humans as with CAPTCHAs, and for computer security to circumvent brute-force attacks.
History.
The term was coined by Fanya Montalvo by analogy with NP-complete and NP-hard in complexity theory, which formally describes the most famous class of difficult problems. Early uses of the term are in Erik Mueller's 1987 Ph.D. dissertation and in Eric Raymond's 1991 Jargon File.
AI-complete problems.
AI-complete problems are hypothesised to include:
Machine translation.
To translate accurately, a machine must be able to understand the text. It must be able to follow the author's argument, so it must have some ability to reason. It must have extensive world knowledge so that it knows what is being discussed — it must at least be familiar with all the same commonsense facts that the average human translator knows. Some of this knowledge is in the form of facts that can be explicitly represented, but some knowledge is unconscious and closely tied to the human body: for example, the machine may need to understand how an ocean makes one "feel" to accurately translate a specific metaphor in the text. It must also model the authors' goals, intentions, and emotional states to accurately reproduce them in a new language. In short, the machine is required to have wide variety of human intellectual skills, including reason, commonsense knowledge and the intuitions that underlie motion and manipulation, perception, and social intelligence. Machine translation, therefore, is believed to be AI-complete: it may require strong AI to be done as well as humans can do it.
Software brittleness.
Current AI systems can solve very simple restricted versions of AI-complete problems, but never in their full generality. When AI researchers attempt to "scale up" their systems to handle more complicated, real world situations, the programs tend to become excessively brittle without commonsense knowledge or a rudimentary understanding of the situation: they fail as unexpected circumstances outside of its original problem context begin to appear. When human beings are dealing with new situations in the world, they are helped immensely by the fact that they know what to expect: they know what all things around them are, why they are there, what they are likely to do and so on. They can recognize unusual situations and adjust accordingly. A machine without strong AI has no other skills to fall back on.
Formalization.
Computational complexity theory deals with the relative computational difficulty of computable functions. By definition it does not cover problems whose solution is unknown or has not been characterised formally. Since many AI problems have no formalisation yet, conventional complexity theory does not allow the definition of AI-completeness.
To address this problem, a complexity theory for AI has been proposed. It is based on a model of computation that splits the computational burden between a computer and a human: one part is solved by computer and the other part solved by human. This is formalised by a human-assisted Turing machine. The formalisation defines algorithm complexity, problem complexity and reducibility which in turn allows equivalence classes to be defined.
The complexity of executing an algorithm with a human-assisted Turing machine is given by a pair formula_1, where the first element represents the complexity of the human's part and the second element is the complexity of the machine's part.
Results.
The complexity of solving the following problems with a human-assisted Turing machine is:

</doc>
<doc id="2864" url="https://en.wikipedia.org/wiki?curid=2864" title="Archaeoastronomy">
Archaeoastronomy

Archaeoastronomy (also spelled archeoastronomy) is the study of how people in the past "have understood the phenomena in the sky, how they used these phenomena and what role the sky played in their cultures." Clive Ruggles argues it is misleading to consider archaeoastronomy to be the study of ancient astronomy, as modern astronomy is a scientific discipline, while archaeoastronomy considers symbolically rich cultural interpretations of phenomena in the sky by other cultures. It is often twinned with "ethnoastronomy", the anthropological study of skywatching in contemporary societies. Archaeoastronomy is also closely associated with historical astronomy, the use of historical records of heavenly events to answer astronomical problems and the history of astronomy, which uses written records to evaluate past astronomical practice.
Archaeoastronomy uses a variety of methods to uncover evidence of past practices including archaeology, anthropology, astronomy, statistics and probability, and history. Because these methods are diverse and use data from such different sources, integrating them into a coherent argument has been a long-term difficulty for archaeoastronomers. Archaeoastronomy fills complementary niches in landscape archaeology and cognitive archaeology. Material evidence and its connection to the sky can reveal how a wider landscape can be integrated into beliefs about the cycles of nature, such as Mayan astronomy and its relationship with agriculture. Other examples which have brought together ideas of cognition and landscape include studies of the cosmic order embedded in the roads of settlements.
Archaeoastronomy can be applied to all cultures and all time periods. The meanings of the sky vary from culture to culture; nevertheless there are scientific methods which can be applied across cultures when examining ancient beliefs. It is perhaps the need to balance the social and scientific aspects of archaeoastronomy which led Clive Ruggles to describe it as: "... field with academic work of high quality at one end but uncontrolled speculation bordering on lunacy at the other."
History of archaeoastronomy.
Two hundred years before Michell wrote the above, there were no archaeoastronomers and there were no professional archaeologists, but there were astronomers and antiquarians. Some of their works are considered precursors of archaeoastronomy; antiquarians interpreted the astronomical orientation of the ruins that dotted the English countryside as William Stukeley did of Stonehenge in 1740, while John Aubrey in 1678 and Henry Chauncy in 1700 sought similar astronomical principles underlying the orientation of churches. Late in the nineteenth century astronomers such as Richard Proctor and Charles Piazzi Smyth investigated the astronomical orientations of the pyramids.
The term "archaeoastronomy" was first used by Elizabeth Chesley Baity (at the suggestion of Euan MacKie) in 1973, but as a topic of study it may be much older, depending on how archaeoastronomy is defined. Clive Ruggles says that Heinrich Nissen, working in the mid-nineteenth century was arguably the first archaeoastronomer. Rolf Sinclair says that Norman Lockyer, working in the late 19th and early 20th centuries, could be called the 'father of archaeoastronomy.' Euan MacKie would place the origin even later, stating: "...the genesis and modern flowering of archaeoastronomy must surely lie in the work of Alexander Thom in Britain between the 1930s and the 1970s."
In the 1960s the work of the engineer Alexander Thom and that of the astronomer Gerald Hawkins, who proposed that Stonehenge was a Neolithic computer, inspired new interest in the astronomical features of ancient sites. The claims of Hawkins were largely dismissed, but this was not the case for Alexander Thom's work, whose survey results of megalithic sites hypothesized widespread practice of accurate astronomy in the British Isles. Euan MacKie, recognizing that Thom's theories needed to be tested, excavated at the Kintraw standing stone site in Argyllshire in 1970 and 1971 to check whether the latter's prediction of an observation platform on the hill slope above the stone was correct. There was an artificial platform there and this apparent verification of Thom's long alignment hypothesis (Kintraw was diagnosed as an accurate winter solstice site) led him to check Thom's geometrical theories at the Cultoon stone circle in Islay, also with a positive result. MacKie therefore broadly accepted Thom's conclusions and published new prehistories of Britain. In contrast a re-evaluation of Thom's fieldwork by Clive Ruggles argued that Thom's claims of high accuracy astronomy were not fully supported by the evidence. Nevertheless, Thom's legacy remains strong, Krupp wrote in 1979, "Almost singlehandedly he has established the standards for archaeo-astronomical fieldwork and interpretation, and his amazing results have stirred controversy during the last three decades." His influence endures and practice of statistical testing of data remains one of the methods of archaeoastronomy.
The approach in the New World, where anthropologists began to consider more fully the role of astronomy in Amerindian civilizations, was markedly different. They had access to sources that the prehistory of Europe lacks such as ethnographies and the historical records of the early colonizers. Following the pioneering example of Anthony Aveni, this allowed New World archaeoastronomers to make claims for motives which in the Old World would have been mere speculation. The concentration on historical data led to some claims of high accuracy that were comparatively weak when compared to the statistically led investigations in Europe.
This came to a head at a meeting sponsored by the International Astronomical Union (IAU) in Oxford in 1981. The methodologies and research questions of the participants were considered so different that the conference proceedings were published as two volumes. Nevertheless, the conference was considered a success in bringing researchers together and Oxford conferences have continued every four or five years at locations around the world. The subsequent conferences have resulted in a move to more interdisciplinary approaches with researchers aiming to combine the contextuality of archaeological research, which broadly describes the state of archaeoastronomy today, rather than merely establishing the existence of ancient astronomies, archaeoastronomers seek to explain why people would have an interest in the night sky.
Relations to other disciplines.
Archaeoastronomy has long been seen as an interdisciplinary field that uses written and unwritten evidence to study the astronomies of other cultures. As such, it can be seen as connecting other disciplinary approaches for investigating ancient astronomy: astroarchaeology (an obsolete term for studies that draw astronomical information from the alignments of ancient architecture and landscapes), history of astronomy (which deals primarily with the written textual evidence), and ethnoastronomy (which draws on the ethnohistorical record and contemporary ethnographic studies).
Reflecting Archaeoastronomy's development as an interdisciplinary subject, research in the field is conducted by investigators trained in a wide range of disciplines. Authors of recent doctoral dissertations have described their work as concerned with the fields of archaeology and cultural anthropology; with various fields of history including the history of specific regions and periods, the history of science and the history of religion; and with the relation of astronomy to art, literature and religion. Only rarely did they describe their work as astronomical, and then only as a secondary category.
Both practicing archaeoastronomers and observers of the discipline approach it from different perspectives. George Gummerman and Miranda Warburton view archaeoastronomy as part of an archaeology informed by cultural anthropology and aimed at understanding a "group's conception of themselves in relation to the heavens', in a word, its cosmology. Todd Bostwick argued that "archaeoastronomy is anthropology – the study of human behavior in the past and present." Paul Bahn has described archaeoastronomy as an area of cognitive archaeology. Other researchers relate archaeoastronomy to the history of science, either as it relates to a culture's observations of nature and the conceptual framework they devised to impose an order on those observations or as it relates to the political motives which drove particular historical actors to deploy certain astronomical concepts or techniques. Art historian Richard Poss took a more flexible approach, maintaining that the astronomical rock art of the North American Southwest should be read employing "the hermeneutic traditions of western art history and art criticism" Astronomers, however, raise different questions, seeking to provide their students with identifiable precursors of their discipline, and are especially concerned with the important question of how to confirm that specific sites are, indeed, intentionally astronomical.
The reactions of professional archaeologists to archaeoastronomy have been decidedly mixed. Some expressed incomprehension or even hostility, varying from a rejection by the archaeological mainstream of what they saw as an archaeoastronomical fringe to an incomprehension between the cultural focus of archaeologists and the quantitative focus of early archaeoastronomers. Yet archaeologists have increasingly come to incorporate many of the insights from archaeoastronomy into archaeology textbooks and, as mentioned above, some students wrote archaeology dissertations on archaeoastronomical topics.
Since archaeoastronomers disagree so widely on the characterization of the discipline, they even dispute its name. All three major international scholarly associations relate archaeoastronomy to the study of culture, using the term "Astronomy in Culture" or a translation. Michael Hoskin sees an important part of the discipline as fact-collecting, rather than theorizing, and proposed to label this aspect of the discipline "Archaeotopography." Ruggles and Saunders proposed "Cultural Astronomy" as a unifying term for the various methods of studying folk astronomies. Others have argued that astronomy is an inaccurate term, what are being studied are cosmologies and people who object to the use of logos have suggested adopting the Spanish "cosmovisión".
When debates polarise between techniques, the methods are often referred to by a colour code, based on the colours of the bindings of the two volumes from the first Oxford Conference, where the approaches were first distinguished. Green (Old World) archaeoastronomers rely heavily on statistics and are sometimes accused of missing the cultural context of what is a social practice. Brown (New World) archaeoastronomers in contrast have abundant ethnographic and historical evidence and have been described as 'cavalier' on matters of measurement and statistical analysis. Finding a way to integrate various approaches has been a subject of much discussion since the early 1990s.
Methodology.
There is no one way to do Archaeoastronomy. The divisions between archaeoastronomers tend not to be between the physical scientists and the social scientists. Instead it tends to depend on the location of kind of data available to the researcher. In the Old World, there is little data but the sites themselves; in the New World, the sites were supplemented by ethnographic and historic data. The effects of the isolated development of archaeoastronomy in different places can still often be seen in research today. Research methods can be classified as falling into one of two approaches, though more recent projects often use techniques from both categories.
Green archaeoastronomy.
Green Archaeoastronomy is named after the cover of the book "Archaeoastronomy in the Old World". It is based primarily on statistics and is particularly apt for prehistoric sites where the social evidence is relatively scant compared to the historic period. The basic methods were developed by Alexander Thom during his extensive surveys of British megalithic sites.
Thom wished to examine whether or not prehistoric peoples used high-accuracy astronomy. He believed that by using horizon astronomy, observers could make estimates of dates in the year to a specific day. The observation required finding a place where on a specific date the sun set into a notch on the horizon. A common theme is a mountain which blocked the Sun, but on the right day would allow the tiniest fraction to re-emerge on the other side for a 'double sunset'. The animation below shows two sunsets at a hypothetical site, one the day before the summer solstice and one at the summer solstice, which has a double sunset. Horizon astronomy is arguably inaccurate, due to variations in refraction.
To test this idea he surveyed hundreds of stone rows and circles. Any individual alignment could indicate a direction by chance, but he planned to show that together the distribution of alignments was non-random, showing that there was an astronomical intent to the orientation of at least some of the alignments. His results indicated the existence of eight, sixteen, or perhaps even thirty-two approximately equal divisions of the year. The two solstices, the two equinoxes and four cross-quarter days, days half-way between a solstice and the equinox were associated with the medieval Celtic calendar. While not all these conclusions have been accepted, it has had an enduring influence on archaeoastronomy, especially in Europe.
Euan MacKie has supported Thom's analysis, to which he added an archaeological context by comparing Neolithic Britain to the Mayan civilization to argue for a stratified society in this period. To test his ideas he conducted a couple of excavations at proposed prehistoric observatories in Scotland. Kintraw is a site notable for its four-meter high standing stone. Thom proposed that this was a foresight to a point on the distant horizon between Beinn Shianaidh and Beinn o'Chaolias on Jura. This, Thom argued, was a notch on the horizon where a double sunset would occur at midwinter. However, from ground level, this sunset would be obscured by a ridge in the landscape, and the viewer would need to be raised by two meters: another observation platform was needed. This was identified across a gorge where a platform was formed from small stones. The lack of artifacts caused concern for some archaeologists and the petrofabric analysis was inconclusive, but further research at Maes Howe and on the Bush Barrow Lozenge led MacKie to conclude that while the term 'science' may be anachronistic, Thom was broadly correct upon the subject of high-accuracy alignments.
In contrast Clive Ruggles has argued that there are problems with the selection of data in Thom's surveys. A deeper criticism of Green archaeoastronomy is that while it can answer "whether" there was likely to be an interest in astronomy in past times, its lack of a social element means that it struggles to answer "why" people would be interested, which makes it of limited use to people asking questions about the society of the past. Keith Kintigh wrote: "To put it bluntly, in many cases it doesn't matter much to the progress of anthropology whether a particular archaeoastronomical claim is right or wrong because the information doesn’t inform the current interpretive questions." Nonetheless the study of alignments remains a staple of archaeoastronomical research, especially in Europe.
Brown archaeoastronomy.
In contrast to the largely alignment-oriented statistically led methods of Green archaeoastronomy, Brown archaeoastronomy has been identified as being closer to the history of astronomy or to cultural history, insofar as it draws on historical and ethnographic records to enrich its understanding of early astronomies and their relations to calendars and ritual. The many records of native customs and beliefs made by the Spanish chroniclers means that Brown archaeoastronomy is most often associated with studies of astronomy in the Americas.
One famous site where historical records have been used to interpret sites is Chichen Itza. Rather than analysing the site and seeing which targets appear popular, archaeoastronomers have instead examined the ethnographic records to see what features of the sky were important to the Mayans and then sought archaeological correlates. One example which could have been overlooked without historical records is the Mayan interest in the planet Venus. This interest is attested to by the Dresden codex which contains tables with information about the Venus's appearances in the sky. These cycles would have been of astrological and ritual significance as Venus was associated with Quetzalcoatl or Xolotl. Associations of architectural features with settings of Venus can be found in Chichen Itza.
The Temple of the Warriors bears iconography depicting feathered serpents associated with Quetzalcoatl or Kukulcan. This means that the building's alignment towards the place on the horizon where Venus first appears in the evening sky (when it coincides with the rainy season) may be meaningful. Aveni claims that another building associated with the planet Venus in the form of Kukulcan, and the rainy season at Chichen Itza is the Caracol. This is a building with circular tower and doors facing the cardinal directions. The base faces the most northerly setting of Venus. Additionally the pillars of a stylobate on the building's upper platform were painted black and red. These are colours associated with Venus as an evening and morning star. However the windows in the tower seem to have been little more than slots, making them poor at letting light in, but providing a suitable place to view out.
Aveni states that one of the strengths of the Brown methodology is that it can explore astronomies invisible to statistical analysis and offers the astronomy of the Incas as another example. The empire of the Incas was conceptually divided using "ceques" radial routes emanating from the capital at Cusco. Thus there are alignments in all directions which would suggest there is little of astronomical significance, However, ethnohistorical records show that the various directions do have cosmological and astronomical significance with various points in the landscape being significant at different times of the year. In eastern Asia archaeoastronomy has developed from the History of Astronomy and much archaeoastronomy is searching for material correlates of the historical record. This is due to the rich historical record of astronomical phenomena which, in China, stretches back into the Han dynasty, in the second century BC.
A criticism of this method is that it can be statistically weak. Schaefer in particular has questioned how robust the claimed alignments in the Caracol are. Because of the wide variety of evidence, which can include artefacts as well as sites, there is no one way to practice archaeoastronomy. Despite this it is accepted that archaeoastronomy is not a discipline that sits in isolation. Because archaeoastronomy is an interdisciplinary field, whatever is being investigated should make sense both archaeologically and astronomically. Studies are more likely to be considered sound if they use theoretical tools found in archaeology like analogy and homology and if they can demonstrate an understanding of accuracy and precision found in astronomy.
Source materials.
Because archaeoastronomy is about the many and various ways people interacted with the sky, there are a diverse range of sources giving information about astronomical practices.
Alignments.
A common source of data for archaeoastronomy is the study of alignments. This is based on the assumption that the axis of alignment of an archaeological site is meaningfully oriented towards an astronomical target. Brown archaeoastronomers may justify this assumption through reading historical or ethnographic sources, while Green archaeoastronomers tend to prove that alignments are unlikely to be selected by chance, usually by demonstrating common patterns of alignment at multiple sites.
An alignment is calculated by measuring the azimuth, the angle from north, of the structure and the altitude of the horizon it faces The azimuth is usually measured using a theodolite or a compass. A compass is easier to use, though the deviation of the Earth's magnetic field from true north, known as its magnetic declination must be taken into account. Compasses are also unreliable in areas prone to magnetic interference, such as sites being supported by scaffolding. Additionally a compass can only measure the azimuth to a precision of a half a degree.
A theodolite can be considerably more accurate if used correctly, but it is also considerably more difficult to use correctly. There is no inherent way to align a theodolite with North and so the scale has to be calibrated using astronomical observation, usually the position of the Sun. Because the position of celestial bodies changes with the time of day due to the Earth's rotation, the time of these calibration observations must be accurately known, or else there will be a systematic error in the measurements. Horizon altitudes can be measured with a theodolite or a clinometer.
Artifacts.
For artifacts such as the Sky Disc of Nebra, alleged to be a Bronze Age artefact depicting the cosmos, the analysis would be similar to typical post-excavation analysis as used in other sub-disciplines in archaeology. An artefact is examined and attempts are made to draw analogies with historical or ethnographical records of other peoples. The more parallels that can be found, the more likely an explanation is to be accepted by other archaeologists.
A more mundane example is the presence of astrological symbols found on some shoes and sandals from the Roman Empire. The use of shoes and sandals is well known, but Carol van Driel-Murray has proposed that astrological symbols etched onto sandals gave the footwear spiritual or medicinal meanings. This is supported through citation of other known uses of astrological symbols and their connection to medical practice and with the historical records of the time.
Another well-known artefact with an astronomical use is the Antikythera mechanism. In this case analysis of the artefact, and reference to the description of similar devices described by Cicero, would indicate a plausible use for the device. The argument is bolstered by the presence of symbols on the mechanism, allowing the disc to be read.
Art and inscriptions.
Art and inscriptions may not be confined to artefacts, but also appear painted or inscribed on an archaeological site. Sometimes inscriptions are helpful enough to give instructions to a site's use. For example, a Greek inscription on a stele (from Itanos) has been translated as:"Patron set this up for Zeus Epopsios. Winter solstice. Should anyone wish to know: off ‘the little pig’ and the stele the sun turns." From Mesoamerica come Mayan and Aztec codices. These are folding books made from Amatl, processed tree bark on which are glyphs in Mayan or Aztec script. The Dresden codex contains information regarding the Venus cycle, confirming its importance to the Mayans.
More problematic are those cases where the movement of the Sun at different times and seasons causes light and shadow interactions with petroglyphs. A widely known example is the Sun Dagger of Fajada Butte at which a glint of sunlight passes over a spiral petroglyph. The location of a dagger of light on the petroglyph varies throughout the year. At the summer solstice a dagger can be seen through the heart of the spiral; at the winter solstice two daggers appear to either side of it. It is proposed that this petroglyph was created to mark these events. Recent studies have identified many similar sites in the US Southwest and Northwestern Mexico. It has been argued that the number of solstitial markers at these sites provides statistical evidence that they were intended to mark the solstices. The Sun Dagger site on Fajada Butte in Chaco Canyon, New Mexico, stands out for its explicit light markings that record all the key events of both the solar and lunar cycles: summer solstice, winter solstice, equinox, and the major and minor lunar standstills of the moon’s 18.6 year cycle. In addition at two other sites on Fajada Butte, there are five light markings on petroglyphs recording the summer and winter solstices, equinox and solar noon. Numerous buildings and interbuilding alignments of the great houses of Chaco Canyon and outlying areas are oriented to the same solar and lunar directions that are marked at the Sun Dagger site.
If no ethnographic nor historical data are found which can support this assertion then acceptance of the idea relies upon whether or not there are enough petroglyph sites in North America that such a correlation could occur by chance. It is helpful when petroglyphs are associated with existing peoples. This allows ethnoastronomers to question informants as to the meaning of such symbols.
Ethnographies.
As well as the materials left by peoples themselves, there are also the reports of other who have encountered them. The historical records of the Conquistadores are a rich source of information about the pre-Columbian Americans. Ethnographers also provide material about many other peoples.
Aveni uses the importance of zenith passages as an example of the importance of ethnography. For peoples living between the tropics of Cancer and Capricorn there are two days of the year when the noon Sun passes directly overhead and casts no shadow. In parts of Mesoamerica this was considered a significant day as it would herald the arrival of rains, and so play a part in the cycle of agriculture. This knowledge is still considered important amongst Mayan Indians living in Central America today. The ethnographic records suggested to archaeoastronomers that this day may have been important to the ancient Mayans. There are also shafts known as 'zenith tubes' which illuminate subterranean rooms when the sun passes overhead found at places like Monte Albán and Xochicalco. It is only through the ethnography that we can speculate that the timing of the illumination was considered important in Mayan society. Alignments to the sunrise and sunset on the day of the zenith passage have been claimed to exist at several sites. However, it has been shown that, since there are very few orientations that can be related to these phenomena, they likely have different explanations.
Ethnographies also caution against over-interpretation of sites. At a site in Chaco Canyon can be found a pictograph with a star, crescent and hand. It has been argued by some astronomers that this is a record of the 1054 Supernova. However recent reexaminations of related 'supernova petroglyphs' raises questions about such sites in general and anthropological evidence suggests other inrepretations. The Zuni people, who claim a strong ancestral affiliation with Chaco, marked their sun-watching station with a crescent, star, hand and sundisc, similar to those found at the Chaco site.
Ethnoastronomy is also an important field outside of the Americas. For example, anthropological work with Aboriginal Australians is producing much information about their Indigenous astronomies and about their interaction with the modern world.
Recreating the ancient sky.
Once the researcher has data to test, it is often necessary to attempt to recreate ancient sky conditions to place the data in its historical environment.
Declination.
To calculate what astronomical features a structure faced a coordinate system is needed. The stars provide such a system. If you were to go outside on a clear night you would observe the stars spinning around the celestial pole. This point is +90° if you are watching the North Celestial Pole or −90° if you are observing the Southern Celestial Pole. The concentric circles the stars trace out are lines of celestial latitude, known as "declination". The arc connecting the points on the horizon due East and due West (if the horizon is flat) and all points midway between the Celestial Poles is the Celestial Equator which has a declination of 0°. The visible declinations vary depending where you are on the globe. Only an observer on the North Pole of Earth would be unable to see any stars from the Southern Celestial Hemisphere at night (see diagram below). Once a declination has been found for the point on the horizon that a building faces it is then possible to say whether a specific body can be seen in that direction.
Solar positioning.
While the stars are fixed to their declinations the Sun is not. The rising point of the Sun varies throughout the year. It swings between two limits marked by the solstices a bit like a pendulum, slowing as it reaches the extremes, but passing rapidly through the midpoint. If an archaeoastronomer can calculate from the azimuth and horizon height that a site was built to view a declination of +23.5° then he or she need not wait until 21 June to confirm the site does indeed face the summer solstice. For more information see History of solar observation.
Lunar positioning.
The Moon's appearance is considerably more complex. Its motion, like the Sun, is between two limits — known as "luni"stices rather than "sol"stices. However, its travel between lunistices is considerably faster. It takes a sidereal month to complete its cycle rather than the year-long trek of the Sun. This is further complicated as the lunistices marking the limits of the Moon's movement move on an 18.6 year cycle. For slightly over nine years the extreme limits of the moon are outside the range of sunrise. For the remaining half of the cycle the Moon never exceeds the limits of the range of sunrise. However, much lunar observation was concerned with the "phase" of the Moon. The cycle from one New Moon to the next runs on an entirely different cycle, the Synodic month. Thus when examining sites for lunar significance the data can appear sparse due the extremely variable nature of the moon. See Moon for more details.
Stellar positioning.
Finally there is often a need to correct for the apparent movement of the stars. On the timescale of human civilisation the stars have largely maintained the same position relative to each other. Each night they appear to rotate around the celestial poles due to the Earth's rotation about its axis. However, the Earth spins rather like a spinning top. Not only does the Earth rotate, it wobbles. The Earth's axis takes around 25,800 years to complete one full wobble. The effect to the archaeoastronomer is that stars did not rise over the horizon in the past in the same places as they do today. Nor did the stars rotate around Polaris as they do now. In the case of the Egyptian pyramids, it has been shown they were aligned towards Thuban, a faint star in the constellation of Draco. The effect can be substantial over relatively short lengths of time, historically speaking. For instance a person born on 25 December in Roman times would have been born with the sun in the constellation Capricorn. In the modern period a person born on the same date would have the sun in Sagittarius due to the precession of the equinoxes.
Transient phenomena.
Additionally there are often transient phenomena, events which do not happen on an annual cycle. Most predictable are events like eclipses. In the case of solar eclipses these can be used to date events in the past. A solar eclipse mentioned by Herodotus enables us to date a battle between the Medes and the Lydians, which following the eclipse failed to happen, to 28 May, 585 BC. Other easily calculated events are supernovae whose remains are visible to astronomers and therefore their positions and magnitude can be accurately calculated.
Some comets are predictable, most famously Halley's Comet. Yet as a class of object they remain unpredictable and can appear at any time. Some have extremely lengthy orbital periods which means their past appearances and returns cannot be predicted. Others may have only ever passed through the Solar System once and so are inherently unpredictable.
Meteor showers should be predictable, but some meteors are cometary debris and so require calculations of orbits which are currently impossible to complete. Other events noted by ancients include aurorae, sun dogs and rainbows all of which are as impossible to predict as the ancient weather, but nevertheless may have been considered important phenomena.
Major topics of archaeoastronomical research.
The use of calendars.
A common justification for the need for astronomy is the need to develop an accurate calendar for agricultural reasons. Ancient texts like Hesiod's Works and Days, an ancient farming manual, would appear to contradict this. Instead astronomical observations are used in combination with ecological signs, such as bird migrations to determine the seasons. Ethnoastronomical work with the Mursi of Ethiopia shows that haphazard astronomy continued until recent times in some parts of the world. All the same, calendars appear to be an almost universal phenomenon in societies as they provide tools for the regulation of communal activities.
An example of a non-agricultural calendar is the "Tzolk'in" calendar of the Maya civilization of pre-Columbian Mesoamerica, which is a cycle of 260 days. This count is based on an earlier calendar and is found throughout Mesoamerica. This formed part of a more comprehensive system of Maya calendars which combined a series of astronomical observations and ritual cycles.
Other peculiar calendars include ancient Greek calendars. These were nominally lunar, starting with the New Moon. In reality the calendar could pause or skip days with confused citizens inscribing dates by both the civic calendar and "ton theoi", by the moon. The lack of any universal calendar for ancient Greece suggests that coordination of panhellenic events such as games or rituals could be difficult and that astronomical symbolism may have been used as a politically neutral form of timekeeping. Orientation measurements in Greek temples and Byzantine churches have been associated to deity's name day, festivities, and special events.
Myth and cosmology.
Another motive for studying the sky is to understand and explain the universe. In these cultures myth was a tool for achieving this and the explanations, while not reflecting the standards of modern science, are cosmologies.
The Incas arranged their empire to demonstrate their cosmology. The capital, Cusco, was at the centre of the empire and connected to it by means of ceques, conceptually straight lines radiating out from the centre. These ceques connected the centre of the empire to the four "suyus", which were regions defined by their direction from Cusco. The notion of a quartered cosmos is common across the Andes. Gary Urton, who has conducted fieldwork in the Andean villagers of Misminay, has connected this quartering with the appearance of the Milky Way in the night sky. In one season it will bisect the sky and in another bisect it in a perpendicular fashion.
The importance of observing cosmological factors is also seen on the other side of the world. The Forbidden City in Beijing is laid out to follow cosmic order though rather than observing four directions. The Chinese system was composed of five directions: North, South, East, West and Centre. The Forbidden City occupied the centre of ancient Beijing. One approaches the Emperor from the south, thus placing him in front of the circumpolar stars. This creates the situation of the heavens revolving around the person of the Emperor. The Chinese cosmology is now better known through its export as feng shui.
There is also much information about how the universe was thought to work stored in the mythology of the constellations. The Barasana of the Amazon plan part of their annual cycle based on observation of the stars. When their constellation of the Caterpillar-Jaguar (roughly equivalent to the modern Scorpius) falls they prepare to catch the pupating caterpillars of the forest as they fall from the trees. The caterpillars provide food at a season when other foods are scarce.
A more well-known source of constellation myth are the texts of the Greeks and Romans. The origin of their constellations remains a matter of vigorous and occasionally fractious debate.
The loss of one of the sisters, Merope, in some Greek myths may reflect an astronomical event wherein one of the stars in the Pleiades disappeared from view by the naked eye.
Giorgio de Santillana, professor of the History of Science in the School of Humanities at the Massachusetts Institute of Technology, along with Hertha von Dechend believed that the old mythological stories handed down from antiquity were not random fictitious tales but were accurate depictions of celestial cosmology clothed in tales to aid their oral transmission. The chaos, monsters and violence in ancient myths are representative of the forces that shape each age. They believed that ancient myths are the remains of preliterate astronomy that became lost with the rise of the Greco-Roman civilization. Santillana and von Dechend in their book "Hamlet's Mill, An Essay on Myth and the Frame of Time" (1969) clearly state that ancient myths have no historical or factual basis other than a cosmological one encoding astronomical phenomena, especially the precession of the equinoxes. Santillana and von Dechend's approach is not widely accepted.
Displays of power.
By including celestial motifs in clothing it becomes possible for the wearer to make claims the power on Earth is drawn from above. It has been said that the Shield of Achilles described by Homer is also a catalogue of constellations. In North America shields depicted in Comanche petroglyphs appear to include Venus symbolism.
Solsticial alignments also can be seen as displays of power. When viewed from a ceremonial plaza on the Island of the Sun (the mythical origin place of the Sun) in Lake Titicaca, the Sun was seen to rise at the June solstice between two towers on a nearby ridge. The sacred part of the island was separated from the remainder of it by a stone wall and ethnographic records indicate that access to the sacred space was restricted to members of the Inca ruling elite. Ordinary pilgrims stood on a platform outside the ceremonial area to see the solstice Sun rise between the towers.
In Egypt the temple of Amun-Re at Karnak has been the subject of much study. Evaluation of the site, taking into account the change over time of the obliquity of the ecliptic show that the Great Temple was aligned on the rising of the midwinter sun. The length of the corridor down which sunlight would travel would have limited illumination at other times of the year.
In a later period the Serapeum in Alexandria was also said to have contained a solar alignment so that, on a specific sunrise, a shaft of light would pass across the lips of the statue of Serapis thus symbolising the Sun saluting the god.
Major sites of archaeoastronomical interest.
Clive Ruggles and Michel Cotte recently edited a book on heritage sites of astronomy and archaeoastronomy that provides a list of the main sites around the world.
Newgrange.
Newgrange is a passage tomb in the Republic of Ireland dating from around 3,300 to 2,900 BC For a few days around the Winter Solstice light shines along the central passageway into the heart of the tomb. What makes this notable is not that light shines in the passageway, but that it does not do so through the main entrance. Instead it enters via a hollow box above the main doorway discovered by Michael O'Kelly. It is this roofbox which strongly indicates that the tomb was built with an astronomical aspect in mind. Clive Ruggles notes:
Egypt.
Since the first modern measurements of the precise cardinal orientations of the pyramids by Flinders Petrie, various astronomical methods have been proposed for the original establishment of these orientations. It was recently proposed that this was done by observing the positions of two stars in the Plough / Big Dipper which was known to Egyptians as the thigh. It is thought that a vertical alignment between these two stars checked with a plumb bob was used to ascertain where north lay. The deviations from true north using this model reflect the accepted dates of construction.
Some have argued that the pyramids were laid out as a map of the three stars in the belt of Orion, although this theory has been criticized by reputable astronomers.
The astronomical ceiling of the tomb of Senenmut (ca 1470 BC) contains the Celestial Diagram depicting circumpolar constellations in the form of discs. Each disc is divided into 24 sections suggesting a 24-hour time period. Constellations are portrayed as sacred deities of Egypt. The observation of lunar cycles is also evident.
El Castillo.
El Castillo, also known as Kukulcán's Pyramid, is a Mesoamerican step-pyramid built in the centre of Mayan center of Chichen Itza in Mexico. Several architectural features have suggested astronomical elements. Each of the stairways built into the sides of the pyramid has 91 steps. Along with the extra one for the platform at the top, this totals 365 steps, which is possibly one for each day of the year (365.25) or the number of lunar orbits in 10,000 rotations (365.01).
A visually striking effect is seen every March and September as an unusual shadow occurs on the equinoxes. A shadow appears to descend the west balustrade of the northern stairway. The visual effect is of a serpent descending the stairway, with its head at the base in light. Additionally the western face points to sunset around 25 May, traditionally the date of transition from the dry to the rainy season.
Stonehenge.
Many astronomical alignments have been claimed for Stonehenge, a complex of megaliths and earthworks in the Salisbury Plain of England. The most famous of these is the midsummer alignment, where the Sun rises over the Heel Stone. However, this interpretation has been challenged by some archaeologists who argue that the midwinter alignment, where the viewer is outside Stonehenge and sees the sun setting in the henge, is the more significant alignment, and the midsummer alignment may be a coincidence due to local topography.
As well as solar alignments, there are proposed lunar alignments. The four station stones mark out a rectangle. The short sides point towards the midsummer sunrise and midwinter sunset. The long sides if viewed towards the south-east, face the most southerly rising of the moon. Aveni notes that these lunar alignments have never gained the acceptance that the solar alignments have received. The Heel Stone azimuth is one-seventh of circumference, matching the latitude of Avebury, while summer solstice sunrise azimuth is no longer equal to the construction era direction.
Maeshowe.
This is an architecturally outstanding Neolithic chambered tomb on the Mainland of Orkney, Scotland – probably dating to the early 3rd millennium BC, and where the setting sun at midwinter shines down the entrance passage into the central chamber (see Newgrange). In the 1990s further investigations were carried out to discover whether this was an accurate or an approximate solar alignment. Several new aspects of the site were discovered. In the first place the entrance passage faces the hills of the island Hoy, about 10 miles away. Secondly, it consists of two straight lengths, angled at a few degrees to each other. Thirdly, the outer part is aligned towards the midwinter sunset position on a level horizon just to the left of Ward Hill on Hoy. Fourthly the inner part points directly at the Barnhouse standing stone about 400m away and then to the right end of the summit of Ward Hill, just before it dips down to the notch between it at Cuilags to the right. This indicated line points to sunset on the first Sixteenths of the solar year (according to A. Thom) before and after the winter solstice and the notch at the base of the right slope of the Hill is at the same declination. Fourthly a similar 'double sunset' phenomenon is seen at the right end of Cuilags, also on Hoy; here the date is the first Eighth of the year before and after the winter solstice, at the beginning of November and February respectively – the Old Celtic festivals of Samhain and Imbolc. This alignment is not indicated by an artificial structure but gains plausibility from the other two indicated lines. Maeshowe is thus an extremely sophisticated calendar site which must have been positioned carefully in order to use the horizon foresights in the ways described.
Uxmal.
Uxmal is a Mayan city in the Puuc Hills of Yucatán Peninsula, Mexico. The Governor's Palace at Uxmal is often used as an exemplar of why it is important to combine ethnographic and alignment data. The palace is aligned with an azimuth of 118° on the pyramid of Cehtzuc. This alignment corresponds approximately to the southernmost rising and, with a much greater precision, to the northernmost setting of Venus; both phenomena occur once every eight years. By itself this would not be sufficient to argue for a meaningful connection between the two events. The palace has to be aligned in one direction or another and why should the rising of Venus be any more important than the rising of the Sun, Moon, other planets, Sirius "et cetera"? The answer given is that not only does the palace point towards significant points of Venus, it is also covered in glyphs which stand for Venus and Mayan zodiacal constellations. Moreover, the great northerly extremes of Venus always occur in late April or early May, coinciding with the onset of the rainy season. The Venus glyphs placed in the cheeks of the Maya rain god Chac, most likely referring to the concomitance of these phenomena, support the west-working orientation scheme.
Chaco Canyon.
In Chaco Canyon, the center of the ancient Pueblo culture in the American Southwest, numerous solar and lunar light markings and architectural and road alignments have been documented. These findings date to the 1977 discovery of the Sun Dagger site by Anna Sofaer. Three large stone slabs leaning against a cliff channel light and shadow markings onto two spiral petroglyphs on the cliff wall, marking the solstices, equinoxes and the lunar standstills of the 18.6 year cycle of the moon. Subsequent research by the Solstice Project and others demonstrated that numerous building and interbuilding alignments of the great houses of Chaco Canyon are oriented to solar, lunar and cardinal directions. In addition, research shows that the Great North Road, a thirty-five mile engineered “road”, was constructed not for utilitarian purposes but rather to connect the ceremonial center of Chaco Canyon with the direction north.
Lascaux Cave.
In recent years, new research has suggested that the Lascaux cave paintings in France may incorporate prehistoric star charts. Michael Rappenglueck of the University of Munich argues that some of the non-figurative dot clusters and dots within some of the figurative images correlate with the constellations of Taurus, the Pleiades and the grouping known as the "Summer Triangle". Based on her own study of the astronomical significance of Bronze Age petroglyphs in the Vallée des Merveilles and her extensive survey of other prehistoric cave painting sites in the region—most of which appear to have been selected because the interiors are illuminated by the setting sun on the day of the winter solstice—French researcher Chantal Jègues-Wolkiewiez has further proposed that the gallery of figurative images in the Great Hall represents an extensive star map and that key points on major figures in the group correspond to stars in the main constellations as they appeared in the Paleolithic. Appliying phylogenetics to myths of the Cosmic Hunt, Julien d'Huy suggested that the palaeolithic version of this story could be the following: there is an animal that is a horned herbivore, especially an elk. One human pursues this ungulate. The hunt locates or get to the sky. The animal is alive when it is transformed into a constellation. It forms the Big Dipper. This story may be represented in the famous Lascaux shaft ‘scene’ 
Fringe archaeoastronomy.
Archaeoastronomy owes something of this poor reputation among scholars to its occasional misuse to advance a range of pseudo-historical accounts. During the 1930s, Otto S. Reuter compiled a study entitled "Germanische Himmelskunde", or "Teutonic Skylore". The astronomical orientations of ancient monuments claimed by Reuter and his followers would place the ancient Germanic peoples ahead of the Ancient Near East in the field of astronomy, demonstrating the intellectual superiority of the "Aryans" (Indo-Europeans) over the Semites.
Since the 19th century, numerous scholars have sought to use archaeoastronomical calculations to demonstrate the antiquity of Ancient Indian Vedic culture, computing the dates of astronomical observations ambiguously described in ancient poetry to as early as 4000 BCE. David Pingree, a historian of Indian astronomy, condemned "the scholars who perpetrate wild theories of prehistoric science and call themselves archaeoastronomers."
More recently Gallagher, Pyle, and Fell interpreted inscriptions in West Virginia as a description in Celtic Ogham alphabet of the supposed winter solstitial marker at the site. The controversial translation was supposedly validated by a problematic archaeoastronomical indication in which the winter solstice sun shone on an inscription of the sun at the site. Subsequent analyses criticized its cultural inappropriateness, as well as its linguistic and archeaoastronomical claims, to describe it as an example of "cult archaeology".
Archaeoastronomy is sometimes related to the fringe discipline of Archaeocryptography, when its followers attempt to find underlying mathematical orders beneath the proportions, size, and placement of archaeoastronomical sites such as Stonehenge and the Pyramid of Kukulcán at Chichen Itza.
Archaeoastronomical organisations and publications.
There are currently three academic organisations for scholars of archaeoastronomy. ISAAC—the International Society for Archaeoastronomy and Astronomy in Culture—was founded in 1995 and now sponsors the Oxford conferences and "Archaeoastronomy — the Journal of Astronomy in Culture". SEAC— La Société Européenne pour l’Astronomie dans la Culture—is slightly older; it was created in 1992. SEAC holds annual conferences in Europe and publishes refereed conference proceedings on an annual basis. There is also SIAC— La Sociedad Interamericana de Astronomía en la Cultura, primarily a Latin American organisation which was founded in 2003. Two new organisations focused on regional archaeoastronomy were founded in 2013: ASIA - the Australian Society for Indigenous Astronomy in Australia and SMART - the Society of Māori Astronomy Research and Traditions in New Zealand.
Additionally the "Journal for the History of Astronomy" publishes many archaeoastronomical papers. For twenty-seven volumes (from 1979 to 2002) it published an annual supplement "Archaeoastronomy". The "Journal of Astronomical History and Heritage" (National Astronomical Research Institute of Thailand), "Culture & Cosmos" (University of Wales, UK) and "Mediterranean Archaeology and Archaeometry" (University of Aegean, Greece) also publish papers on archaeoastronomy.
Various national archaeoastronomical projects have been undertaken. Among them is the program at the Tata Institute of Fundamental Research named "Archaeo Astronomy in Indian Context" that has made interesting findings in this field.

</doc>
<doc id="2865" url="https://en.wikipedia.org/wiki?curid=2865" title="Andrzej Sapkowski">
Andrzej Sapkowski

Andrzej Sapkowski (; born 21 June 1948) is a Polish fantasy writer and former economist. He is best known for his best-selling book series "The Witcher".
In 2012 Sapkowski was awarded the Medal for Merit to Culture – Gloria Artis.
Biography.
Sapkowski studied economics, and before turning to writing, he had worked as a senior sales representative for a foreign trade company. He started his literary career as a translator, in particular, of science fiction. He says he wrote his first short story, "The Witcher" ("Wiedźmin",also translated "The Hexer" or "Spellmaker") on a whim, in order to enter a contest by Polish science fiction and fantasy magazine "Fantastyka". Being an expert in marketing, he says he knew how to sell, and indeed, he won the 3rd prize. The story was published in "Fantastyka" in 1986 and was enormously successful both with readers and critics. Sapkowski has created a cycle of tales based on the world of "The Witcher", comprising three collections of short stories and five novels. This cycle and his many other works have made him one of the best-known fantasy authors in Poland in the 1990s.
The main character of "The Witcher" is Geralt, a mutant hunter who has been trained since childhood to hunt down and destroy monsters. Geralt exists in a morally ambiguous universe, yet manages to maintain his own coherent code of ethics. At the same time cynical and noble, Geralt has been compared to Raymond Chandler's signature character Philip Marlowe. The world in which these adventures take place is heavily influenced by Slavic mythology.
Sapkowski has won five Zajdel Awards, including three for short stories "Mniejsze zło" ("Lesser Evil") (1990), "Miecz przeznaczenia" ("Sword of Destiny") (1992) and "W leju po bombie" ("In a Bomb Crater") (1993), and two for the novels, "Krew elfów" ("Blood of Elves") (1994) and "Narrenturm" (2002). He also won the Spanish Ignotus Award, best anthology, for "The Last Wish" in 2003, and for "Muzykanci" ("The Musicians"), best foreign short story, same year.
In 1997, Sapkowski won the prestigious Polityka's Passport award, which is awarded annually to artists who have strong prospects for international success.
In 2001, a television series based on the "Witcher" cycle was released in Poland and internationally, entitled "Wiedźmin" ("The Hexer"). A film by the same title was compiled from excerpts of the television series but both have been critical and box office failures.
Sapkowski's books have been translated into Czech, Hungarian, Russian, Lithuanian, German, Spanish, French, Ukrainian, Portuguese, Finnish, Slovak, Bulgarian, Serbian, English, Italian, Dutch, Estonian and Swedish. An English translation of "The Last Wish" short story collection was published by Gollancz in 2007. From 2008, the Witcher saga is published by Gollancz. The English translation of Sapkowski's novel "Blood of Elves" won the David Gemmell Legend Award in 2009.
The Polish game developer, CD Projekt RED, created a role-playing game series based on "The Witcher" universe. The first game, titled simply "The Witcher", was first released in October 2007. The sequel, ' was released in 2011. The third and final game in the trilogy, ', was released in May 2015.
Awards.
Sapkowski is a recipient of numerous awards from Polish fandom, as well as two European Science Fiction Society awards (1996, 2010), The David Gemmell Legend Award for Fantasy (2009), and several Russian fandom awards,

</doc>
<doc id="2866" url="https://en.wikipedia.org/wiki?curid=2866" title="Ammeter">
Ammeter

An ammeter is a measuring instrument used to measure the current in a circuit. Electric currents are measured in amperes (A), hence the name. Instruments used to measure smaller currents, in the milliampere or microampere range, are designated as "milliammeters" or "microammeters". Early ammeters were laboratory instruments which relied on the Earth's magnetic field for operation. By the late 19th century, improved instruments were designed which could be mounted in any position and allowed accurate measurements in electric power systems.
History.
The relation between electric current, magnetic fields and physical forces was first noted by Hans Christian Ørsted who, in 1820, observed a compass needle was deflected from pointing North when a current flowed in an adjacent wire. The tangent galvanometer was used to measure currents using this effect, where the restoring force returning the pointer to the zero position was provided by the Earth's magnetic field. This made these instruments usable only when aligned with the Earth's field. Sensitivity of the instrument was increased by using additional turns of wire to multiply the effect – the instruments were called "multipliers".
Types.
Moving-coil.
The D'Arsonval galvanometer is a moving coil ammeter. It uses magnetic deflection, where current passing through a coil causes the coil to move in a magnetic field. The modern form of this instrument was developed by Edward Weston, and uses two spiral springs to provide the restoring force. The uniform air gap between the iron core and the permanent magnet poles make the deflection of the meter linearly proportional to current. These meters have linear scales. Basic meter movements can have full-scale deflection for currents from about 25 microamperes to 10 milliamperes.
Because the magnetic field is polarised, the meter needle acts in opposite directions for each direction of current. A DC ammeter is thus sensitive to which way round it is connected; most are marked with a positive terminal, but some have centre-zero mechanisms and can display currents in either direction. A moving coil meter indicates the average (mean) of a varying current through it, which is zero for AC. For this reason moving-coil meters are only usable directly for DC, not AC.
This type of meter movement is extremely common for both ammeters and other meters derived from them, such as voltmeters and ohmmeters. Although their use has become less common in recent decades, this type of basic movement was once the standard indicator mechanism for any analogue displays involving electrical machinery.
Moving magnet.
Moving magnet ammeters operate on essentially the same principle as moving coil, except that the coil is mounted in the meter case, and a permanent magnet moves the needle. Moving magnet Ammeters are able to carry larger currents than moving coil instruments, often several tens of Amperes, because the coil can be made of thicker wire and the current does not have to be carried by the hairsprings.
Indeed, some Ammeters of this type do not have hairsprings at all, instead using a fixed permanent magnet to provide the restoring force.
Electrodynamic.
An electrodynamic movement uses an electromagnet instead of the permanent magnet of the d'Arsonval movement. This instrument can respond to both alternating and direct current and also indicates true RMS for AC. See Wattmeter for an alternative use for this instrument.
Moving-iron.
Moving iron ammeters use a piece of iron which moves when acted upon by the electromagnetic force of a fixed coil of wire. This type of meter responds to both direct and alternating currents (as opposed to the moving-coil ammeter, which works on direct current only). The iron element consists of a moving vane attached to a pointer, and a fixed vane, surrounded by a coil. As alternating or direct current flows through the coil and induces a magnetic field in both vanes, the vanes repel each other and the moving vane deflects against the restoring force provided by fine helical springs. The deflection of a moving iron meter is proportional to the square of the current. Consequently, such meters would normally have a non linear scale, but the iron parts are usually modified in shape to make the scale fairly linear over most of its range. Moving iron instruments indicate the RMS value of any AC waveform applied.
The moving-iron meter was invented by Austrian engineer Friedrich Drexler in 1884.
Hot-wire.
In a hot-wire ammeter, a current passes through a wire which expands as it heats. Although these instruments have slow response time and low accuracy, they were sometimes used in measuring radio-frequency current. These also measure true RMS for an applied AC current.
Digital.
In much the same way as the analogue ammeter formed the basis for a wide variety of derived meters, including voltmeters, the basic mechanism for a digital meter is a digital voltmeter mechanism, and other types of meter are built around this.
Digital ammeter designs use a shunt resistor to produce a calibrated voltage proportional to the current flowing. This voltage is then measured by a digital voltmeter, through use of an analog to digital converter (ADC); the digital display is calibrated to display the current through the shunt. Such instruments are often calibrated to indicate the RMS value for a sine wave only, but many designs will indicate true RMS within limitations of the wave crest factor.
Integrating.
There is also a range of devices referred to as integrating ammeters. In these ammeters the current is summed over time, giving as a result the product of current and time; which is proportional to the energy transferred with that current. These can be used for energy meters (watt-hour meters) or for estimating the charge of a battery or capacitor.
Picoammeter.
A picoammeter, or pico ammeter, measures very low electric current, usually from the picoampere range at the lower end to the milliampere range at the upper end. Picoammeters are used for sensitive measurements where the current being measured is below the theoretical limits of sensitivity of other devices, such as Multimeters.
Most picoammeters use a "virtual short" technique and have several different measurement ranges that must be switched between to cover multiple decades of measurement. Other modern picoammeters use log compression and a "current sink" method that eliminates range switching and associated voltage spikes. Special design and usage considerations must be observed in order to reduce leakage current which may swamp measurements such as special insulators and driven shields, triaxial cable is often used for probe connections.
Application.
The majority of ammeters are either connected in series with the circuit carrying the current to be measured (for small fractional amperes), or have their shunt resistors connected similarly in series. In either case, the current passes through the meter or (mostly) through its shunt. Ammeters must not be connected directly across a voltage source since their internal resistance is very low and excess current would flow. Ammeters are designed for a low voltage drop across their terminals, much less than one volt; the extra circuit losses produced by the ammeter are called its "burden" on the measured circuit. 
Ordinary Weston-type meter movements can measure only milliamperes at most, because the springs and practical coils can carry only limited currents. To measure larger currents, a resistor called a "shunt" is placed in parallel with the meter. The resistances of shunts is in the integer to fractional milliohm range. Nearly all of the current flows through the shunt, and only a small fraction flows through the meter. This allows the meter to measure large currents. Traditionally, the meter used with a shunt has a full-scale deflection (FSD) of , so shunts are typically designed to produce a voltage drop of when carrying their full rated current.
Zero-center ammeters are used for applications requiring current to be measured with both polarities, common in scientific and industrial equipment. Zero-center ammeters are also commonly placed in series with a battery. In this application, the charging of the battery deflects the needle to one side of the scale (commonly, the right side) and the discharging of the battery deflects the needle to the other side. A special type of zero-center ammeter for testing high currents in cars and trucks has a pivoted bar magnet that moves the pointer, and a fixed bar magnet to keep the pointer centered with no current. The magnetic field around the wire carrying current to be measured deflects the moving magnet.
Since the ammeter shunt has a very low resistance, mistakenly wiring the ammeter in parallel with a voltage source will cause a short circuit, at best blowing a fuse, possibly damaging the instrument and wiring, and exposing an observer to injury.
In AC circuits, a current transformer converts the magnetic field around a conductor into a small AC current, typically either or at full rated current, that can be easily read by a meter. In a similar way, accurate AC/DC non-contact ammeters have been constructed using Hall effect magnetic field sensors. A portable hand-held clamp-on ammeter is a common tool for maintenance of industrial and commercial electrical equipment, which is temporarily clipped over a wire to measure current. Some recent types have a parallel pair of magnetically soft probes that are placed on either side of the conductor.

</doc>
<doc id="2868" url="https://en.wikipedia.org/wiki?curid=2868" title="Amanda Hesser">
Amanda Hesser

Amanda Hesser (born 1971) is an American food writer, editor, cookbook author and entrepreneur. Most notably, she was the food editor of "The New York Times Magazine", the editor of "T Living", a quarterly publication of "The New York Times", author of The Essential New York Times Cookbook which was a "New York Times" bestseller, and co-founder and CEO of Food52.
After finishing her first book, in 1997, Hesser was hired as a food reporter for "The New York Times" where she wrote more than 750 stories. While at the "Times" Hesser wrote about the influence of Costco on the wine industry, uncovered the politics behind the New York City Greenmarket and was among the first to write about Ferran Adria of El Bulli in a major American publication.
Hesser was involved in two cases of conflict of interest while working at the "Times". In 2004, she awarded the restaurant Spice Market a three-star rating without disclosing that the year before, the restaurant’s owner, Jean-Georges Vongerichten, had provided a complimentary jacket blurb for her book "Cooking for Mr. Latte". In 2007, Hesser published a favorable review of "Vegetable Harvest" by Patricia Wells, without noting that in 1999, Wells had provided a jacket blurb for Hesser’s book "The Cook and the Gardener". In both cases, the "Times" subsequently pointed out the conflicts of interest with editors’ notes.
While Hesser left the "Times" in March 2008 to focus on the development of Food52 she continued to write the "Recipe Redux" feature for the "Times" magazine until February 27, 2011.
As co-founder and CEO of Food52 she has raised two rounds of investment from parties including Lerer Hippeau Ventures and Bertelsmann Digital Media Investments. Food52 has won numerous notable awards including the James Beard Award for Publication of the Year (2012) and the IACP Award for Best Website (2013).
Hesser was featured in "Food & Wine"'s "40 under 40" list, was named one of the 50 most influential women in food by "Gourmet" Magazine, and had a cameo as herself in the film "Julie & Julia".
Hesser lives in Brooklyn Heights with her husband, Tad Friend, a staff writer for "The New Yorker", and their two children.

</doc>
<doc id="2869" url="https://en.wikipedia.org/wiki?curid=2869" title="Anxiolytic">
Anxiolytic

An anxiolytic (also antipanic or antianxiety agent) is a medication or other intervention that inhibits anxiety. This effect is in contrast to anxiogenic agents, which increase anxiety. Together these categories of psychoactive compounds or interventions may be referred to as anxiotropic compounds/agents. Some recreational drugs such as ethanol (alcohol) induce anxiolysis initially, however studies show that many of these drugs are anxiogenic. Anxiolytic medications have been used for the treatment of anxiety and its related psychological and physical symptoms. Anxiolytics have been shown to be useful in the treatment of anxiety disorders. Light therapy and other interventions have also been found to have an anxiolytic effect.
Beta-receptor blockers such as propranolol and oxprenolol, although not anxiolytics, can be used to combat the somatic symptoms of anxiety, as tachycardia and palpitations.
Anxiolytics are also known as minor tranquilizers. The term is less common in modern texts, and was originally derived from a dichotomy with major tranquilizers, also known as neuroleptics or antipsychotics.
Alternatives to medication.
Psychotherapeutic treatment can be an effective alternative to medication. Exposure therapy is the recommended treatment for phobic anxiety disorders. Cognitive behavioral therapy (CBT) has been found to be effective treatment for panic disorder, social anxiety disorder, generalized anxiety disorder, and obsessive-compulsive disorder. Healthcare providers can also help by educating sufferers about anxiety disorders and referring individuals to self-help resources. CBT has been shown to be effective in the treatment of generalized anxiety disorder, and possibly more effective than pharmacological treatments in the long term. Sometimes medication is combined with psychotherapy, but research has not found a benefit of combined pharmacotherapy and psychotherapy versus monotherapy.
However, even with CBT being a viable treatment option, it can still be ineffective for many individuals. Both the Canadian and American medical associations then suggest the use of a strong but long lasting benzodiazepine such as clonazepam and alprazolam and an antidepressant, usually Prozac for its effectiveness.
Note that adolescent anxiety once the patient becomes pubescent can often turn into depression, at which time other treatments may be required.
Transcendental Meditation technique shows marked efficacy in treating anxiety disorders says a meta-analysis of randomized controlled trials, "TM practice is more effective than treatment as usual and most alternative treatments, with greatest effects observed in individuals with high anxiety"
And a meta-analysis says: "Differential effects of relaxation techniques on trait anxiety: a meta-analysis. Effect sizes for the different treatments (e.g., Progressive Relaxation, EMG Biofeedback, various forms of meditation, etc.) were calculated. Most of the treatments produced similar effect sizes except that Transcendental Meditation had significantly larger effect size (p less than .005)"
Regular practice of Transcendental Meditation enables some active duty service members battling post-traumatic stress disorder to reduce or even eliminate their psychotropic medication and get better control of their often-debilitating symptoms, researchers report in the journal Military Medicine.
Medications.
Barbiturates.
Barbiturates exert an anxiolytic effect linked to the sedation they cause. The risk of abuse and addiction is high. Many experts consider these drugs obsolete for treating anxiety but valuable for the short-term treatment of severe insomnia, though only after benzodiazepines or non-benzodiazepines have failed.
Benzodiazepines.
Benzodiazepines are prescribed for short-term relief of severe and disabling anxiety. Benzodiazepines may also be indicated to cover the latent periods associated with the medications prescribed to treat an underlying anxiety disorder. They are used to treat a wide variety of conditions and symptoms and are usually a first choice when short-term CNS sedation is needed. Longer-term uses include treatment for severe anxiety. 
If benzodiazepines are discontinued rapidly after being taken daily for two or more weeks there is a risk of benzodiazepine withdrawal and rebound syndrome, and tolerance and dependence may also occur, but may be clinically acceptable. There is also the added problem of the accumulation of drug metabolites and adverse effects. Benzodiazepines include:
Benzodiazepines exert their anxiolytic properties at moderate dosage. At higher dosage hypnotic properties occur.
Antidepressants.
Serotonergic antidepressants.
Selective serotonin reuptake inhibitors or serotonin-specific reuptake inhibitor (SSRIs) are a class of compounds typically used as antidepressants in the treatment of depression, anxiety disorders, and some personality disorders. SSRIs are primarily classified as antidepressants and typically higher dosages are required to be effective against anxiety disorders than to be effective against depression; nevertheless, most SSRIs have anxiolytic properties. They can, however, be anxiogenic early on in the course of treatment due to negative feedback through the serotonergic autoreceptors. For this reason in some individuals a low dose concurrent benzodiazepine therapy might be beneficial during the early stages of serotonergic therapy to counteract the initial anxiogenic effects current serotonergics antidepressants have.
Serotonin–norepinephrine reuptake inhibitor.
Serotonin–norepinephrine reuptake inhibitor include venlafaxine and duloxetine drugs. Venlafaxine, in extended release form, and duloxetine, are indicated for the treatment of GAD. SSNRIs are as effective as SSRIs in the treatment of anxiety disorders.
Tricyclic antidepressant.
Older tricyclic antidepressants (TCAs) are anxiolytic too; however, their side effects are often more severe in nature. Examples include imipramine, doxepin, amitriptyline, and the unrelated trazodone.
Tetracyclic antidepressant.
Mirtazapine has demonstrated anxiolytic effects with a better side effect profile to all other classes of antidepressants, for example it rarely causes or exacerbates anxiety. However, it in many countries (such as USA and Australia) it is not specifically approved for anxiety disorders and is only used off label.
Monoamine oxidase inhibitors.
Monoamine oxidase inhibitors (MAOIs) are very effective for anxiety, but due to drug dangers, are rarely prescribed. Examples include: phenelzine, isocarboxazid and tranylcypromine. A reversible MAOI, which has none of the dietary restrictions associated with classic MAOI's, moclobemide is used in Canada and the UK as ′Manerix′ and in Australia as ′Aurorix′ which have none of the more severe SSRI's and SNRI's caused SSRI discontinuation syndrome, an often overlooked and damaging syndrome which is objectively and subjectively as bad or, for some, even worse than Benzodiazepine withdrawal syndrome.
Beta blockers.
Although not officially approved for this purpose, Beta blockers also can have an antianxiety effect.
Miscellaneous.
Alpha-adrenergic agonist.
Alpha 2A receptor agonists Clonidine and Guanfacine has demonstrated both anxiolytic and anxiogenic effects.
Mebicar.
Mebicar (mebicarum) is an anxiolytic produced in Latvia and used in Eastern Europe. Mebicar has an effect on the structure of limbic-reticular activity, particularly on hypothalamus emotional zone, as well as on all 4 basic neuromediator systems – γ aminobutyric acid (GABA), choline, serotonin and adrenergic activity. Mebicar decreases the brain noradrenaline level, exerts no effect on the dopaminergic systems, and increases the brain serotonin level.
Fabomotizole.
Fabomotizole (brand name Afobazole) is an anxiolytic drug launched in Russia in the early 2000s. Its mechanism of action remains poorly defined, with GABAergic, NGF and BDNF release promoting, MT1 receptor antagonism, MT3 receptor antagonism, and sigma agonism all thought to have some involvement. It has yet to find clinical use outside of Russia.
Selank.
Selank is an anxiolytic peptide based drug developed by the Institute of Molecular Genetics of the Russian academy of sciences. Selank is a heptapeptide with the sequence Thr-Lys-Pro-Arg-Pro-Gly-Pro. It is a synthetic analog of a human tetrapeptide tuftsin. As such, it mimics many of its effects. It has been shown to modulate the expression of interleukin-6 (IL-6) and affect the balance of T helper cell cytokines. There is evidence that it may also modulate the expression of brain-derived neurotropic factor in rats.
Bromantane.
Bromantane is a stimulant drug with anxiolytic properties developed in Russia during the late 1980s, which acts mainly by inhibiting the reuptake of both dopamine and serotonin in the brain, although it also has anticholinergic effects at very high doses. Study results suggest that the combination of psychostimulant and anxiolytic actions in the spectrum of psychotropic activity of bromantane is effective in treating asthenic disorders compared to placebo.
Emoxypine.
Emoxypine is an antioxidant that is also an anxiolytic. Its chemical structure resembles that of pyridoxine, a type of vitamin B.
Azapirones.
Azapirones are a class of 5-HT receptor agonists. Currently approved azapirones include buspirone (Buspar) and tandospirone (Sediel).
Hydroxyzine.
Hydroxyzine (Atarax) is an old antihistamine originally approved for clinical use by the FDA in 1956. It possesses anxiolytic properties in addition to its antihistamine properties and is also licensed for the treatment of anxiety and tension. It is also used for its sedative properties as a premed before anesthesia or to induce sedation after anesthesia. It has been shown to be as effective as benzodiazepines in the treatment of generalized anxiety disorder, while producing fewer side-effects.
Pregabalin.
Pregabalin's therapeutic effect appears after 1 week of use and is similar in effectiveness to lorazepam, alprazolam, and venlafaxine, but pregabalin has demonstrated superiority by producing more consistent therapeutic effects for psychic and somatic anxiety symptoms. Long-term trials have shown continued effectiveness without the development of tolerance, and, in addition, unlike benzodiazepines, it does not disrupt sleep architecture and produces less severe cognitive and psychomotor impairment; it also has a low potential for abuse and dependence and may be preferred over the benzodiazepines for these reasons.
Menthyl isovalerate.
Menthyl isovalerate is a flavoring food additive which is marketed as a sedative and anxiolytic drug in Russia under the name "Validol". Sublingual administration of "Validol" produces a sedative effect, and has moderate reflex and vascular dilative action caused by stimulation of sensory nerve receptors of the oral mucosa followed by the release of endorphins. "Validol" is typically administered "as needed" for symptom relief.
Cannabidiol.
Cannabidiol (CBD) is a cannabinoid produced by "Cannabis sativa" and "Cannabis indica", and in marginal quantities by "Cannabis ruderalis". It is available in the United States in states where cannabis has been legalized for medical and general use. No lethal dose (or LD50) has been established from cannabidiol . In feral strains of cannabis, cannabidiol is produced in large quantities alongside the psychoactive cannabinoid tetrahydrocannabinol. Special strains of cannabis have been bred to yield high amounts of cannabidiol with significantly lowered synthesis of THC. Specific formulations for anxiety with a CBD to THC ratio of 18:1 are available in the US markets .
Tetrahydrocannabinol.
Tetrahydrocannabinol appears to be capable of both, having anxiolytic effect(s) and having anxiogenic effect(s).
Racetams.
Some racetam based drugs such as aniracetam can have an antianxiety effect.
Herbal treatments.
Certain natural substances are reputed to have anxiolytic properties, including the following:
Supplements and over-the-counter pharmaceutical drugs.
Picamilon is a prodrug formed by combining niacin with GABA that is able to cross the blood–brain barrier and is then hydrolyzed into GABA and niacin. It is theorized that the GABA released in this process activates GABA receptors, with potential to produce an anxiolytic response.
Picamilon is sold in the United States as a dietary supplement, while in Russia it is sold as a prescription drug.
Chlorpheniramine (Chlor-Trimeton) and diphenhydramine (Benadryl) have hypnotic and sedative effects with mild anxiolytic-like properties (off-label use). These drugs are approved by the FDA for allergies, rhinitis, and urticaria.
Melatonin has anxiolytic properties, likely mediated by the benzodiazepine/GABAergic system. It has been used experimentally as an effective premedicant for general anesthesia in surgical procedures.
Inositol: In a double-blind, controlled trial, "myo"-inositol (18 grams daily) was superior to fluvoxamine for decreasing the number of panic attacks and had fewer side-effects.
Future drugs.
Due to deficits with existing anxiolytics (either in terms of efficacy or side-effect profile), research into novel anxiolytics is active. Possible candidates for future drugs include:
Common drugs.
Prescription-free drugs are often poor anxiolytics and often worsen the symptoms over time. However, they are often used for self-medication because of their wide availability (e.g. alcoholic beverages).
Alcohol.
Ethanol is used as an anxiolytic, sometimes by self-medication. fMRI can measure the anxiolytic effects of alcohol in the human brain. The British National Formulary states, "Alcohol is a poor hypnotic because its diuretic action interferes with sleep during the latter part of the night." Alcohol is also known to induce alcohol-related sleep disorders.
Inhalants.
The anxiolytic effects of solvents act as positive modulators of GABAA receptors (Bowen and colleagues 2006).

</doc>
<doc id="2870" url="https://en.wikipedia.org/wiki?curid=2870" title="Antipsychotic">
Antipsychotic

Antipsychotics are a class of psychiatric medication primarily used to manage psychosis (including delusions, hallucinations, or disordered thought), principally for schizophrenia and bipolar disorder, and are increasingly being used in the management of non-psychotic disorders (ATC code N05A). The terms "neuroleptic" and "major tranquilizer", used for older antipsychotic drugs, have been dropped from contemporary use. Neuroleptic, which originates from the Greek word νεῦρον "neuron" ("nerve") and λῆψις "lepsis" ("seizure" or "fit"), was a reference to neurological side effects.
First-generation antipsychotics, known as typical antipsychotics, neuroleptics or major tranquilizers, were discovered in the 1950s. Most second-generation drugs, known as atypical antipsychotics, have been developed more recently, although the first atypical antipsychotic, clozapine, was discovered in the 1960s and introduced clinically in the 1970s. Both generations of medication tend to block receptors in the brain's dopamine pathways, but atypicals tend to act on serotonin receptors as well.
Antipsychotics are more effective than placebo in treating symptoms of psychosis, but some people do not respond fully or even partly to treatment. Their use is associated with significant side effects, most notably movement disorders and weight gain.
Medical uses.
Antipsychotics are most frequently used for the following conditions:
They are not recommended for dementia or insomnia unless other treatments have not worked. They are not recommended in children unless other treatments are not effective or unless the child has psychosis.
Schizophrenia.
Antipsychotic drug treatment is a key component of schizophrenia treatment algorithms recommended by the National Institute of Health and Clinical Excellence (NICE), the American Psychiatric Association, and the British Society for Psychopharmacology. The main effect of treatment with antipsychotics is to reduce the so-called "positive" symptoms, including delusions and hallucinations. There is mixed evidence to support a significant impact of antipsychotic use on negative symptoms (such as apathy, lack of emotional affect, and lack of interest in social interactions) or on the cognitive symptoms (disordered thinking, reduced ability to plan and execute tasks) of schizophrenia. In general, the efficacy of antipsychotic treatment in reducing both positive and negative symptoms appears to increase with increasing severity of baseline symptoms.
Applications of antipsychotic drugs in the treatment of schizophrenia include prophylaxis in those showing symptoms that suggest that they are at high risk of developing psychosis, treatment of first episode psychosis, maintenance therapy, and treatment of recurrent episodes of acute psychosis.
Prevention of psychosis and symptom improvement.
Test batteries such as the PACE (Personal Assessment and Crisis Evaluation Clinic) and COPS (Criteria of Prodromal Syndromes), which measure low level psychotic symptoms, and others focused on cognitive disturbances (Basic symptoms"), are used to evaluate people with early, low level symptoms of psychosis. Used in combination with family history information, these tests can identify a "high risk" group having a 20–40% risk of progression to frank psychosis within 2 years. These patients are often treated with low doses of antipsychotic drugs with the goal of reducing their symptoms and preventing progression to frank psychosis. While generally useful for reducing symptoms, the clinical trials performed to date provide little evidence that early use of antipsychotics, alone or in combination with cognitive-behavioral therapy, provides improved long term outcomes in those with prodromal symptoms.
First episode psychosis.
NICE recommends that all persons presenting with a first episode of frank psychosis be treated with both an antipsychotic drug and cognitive-behavioral therapy (CBT). NICE further recommends that those expressing a preference for CBT alone be informed that combination treatment is more efficacious. A diagnosis of schizophrenia is not normally made at this time, as up to 25% of those presenting with first episode psychosis are eventually found to suffer from bipolar disorder instead. The goals of treatment of these patients include reducing symptoms and potentially improving long-term treatment outcomes. Randomized clinical trials have provided strong evidence for the efficacy of antipsychotic drugs in achieving the former goal, with first-generation and second generation antipsychotics showing about equal efficacy. Evidence that early treatment has a favorable effect on long term outcomes is equivocal.
Recurrent psychotic episodes.
Placebo-controlled trials of both first and second generation antipsychotic drugs consistently demonstrate the superiority of active drug to placebo in suppressing psychotic symptoms. A large meta analysis of 38 trials of antipsychotic drugs in schizophrenia acute psychotic episodes showed an effect size of about 0.5. There is little or no difference in efficacy among approved antipsychotic drugs, including both first- and second-generation agents. The efficacy of such drugs is suboptimal. Few patients achieve complete resolution of symptoms. Response rates, calculated using various cutoff values for symptom reduction, are low and their interpretation is complicated by high placebo response rates and selective publication of clinical trial results.
Maintenance therapy.
The majority of patients treated with an antipsychotic drug will experience a response within 4 weeks. The goals of continuing treatment are to maintain suppression of symptoms, prevent relapse, improve quality of life, and support engagement in psychosocial therapy.
Maintenance therapy with antipsychotic drugs is clearly superior to placebo in preventing relapse, but is associated with weight gain, movement disorders, and high dropout rates. A 3-year trial following persons receiving maintenance therapy after an acute psychotic episode found that 33% obtained long-lasting symptom reduction, 13% achieved remission, and only 27% experienced satisfactory quality of life. The effect of relapse prevention on long term outcomes is uncertain, as historical studies show little difference in long term outcomes before and after the introduction of antipsychotic drugs.
A significant challenge in the use of antipsychotic drugs for the prevention of relapse is the poor rate of compliance. In spite of the relatively high rates of adverse effects associated with these drugs, some evidence, including higher dropout rates in placebo arms compared to treatment arms in randomized clinical trials, suggest that most patients who discontinue treatment do so because of suboptimal efficacy.
Bipolar disorder.
Antipsychotics are routinely used, often in conjunction with mood stabilisers such as lithium/valproate, as a first-line treatment for manic and mixed episodes associated with bipolar disorder. The reason for this combination is the therapeutic delay of the aforementioned mood stabilisers (for valproate therapeutic effects are usually seen around five days after treatment is commenced whereas lithium usually takes at least a week before the full therapeutic effects are seen) and the comparatively rapid antimanic effects of antipsychotic drugs. The antipsychotics have a documented efficacy when used alone in acute mania/mixed episodes.
Three atypical antipsychotics (lurasidone, olanzapine and quetiapine) have also been found to possess efficacy in the treatment of bipolar depression as a monotherapy. Whereas only olanzapine and quetiapine have been proven to be effective broad-spectrum (i.e. against all three types of relapse— manic, mixed and depressive) prophylactic (or "maintenance") treatments in patients with bipolar disorder. A recent Cochrane review also found that olanzapine had a less favourable risk/benefit ratio than lithium as a maintenance treatment for bipolar disorder.
The American Psychiatric Association and the UK National Institute for Health and Care Excellence recommend antipsychotics for managing acute psychotic episodes in schizophrenia or bipolar disorder, and as a longer-term maintenance treatment for reducing the likelihood of further episodes. They state that response to any given antipsychotic can be variable so that trials may be necessary, and that lower doses are to be preferred where possible. A number of studies have looked at levels of "compliance" or "adherence" with antipsychotic regimes and found that discontinuation (stopping taking them) by patients is associated with higher rates of relapse, including hospitalization.
Dementia.
As assessment for an underlying cause of behavior is needed before prescribing antipsychotic medication for symptoms of dementia. Antipsychotics in old age dementia showed a modest benefit compared to placebo in managing aggression or psychosis, but this is combined with a fairly large increase in serious adverse events. Thus, antipsychotics should not be used routinely to treat dementia with aggression or psychosis, but may be an option in a few cases where there is severe distress or risk of physical harm to others. Psychosocial interventions may reduce the need for antipsychotics.
Unipolar depression.
A number of atypical antipsychotics have some benefits when used in addition to other treatments in major depressive disorder. Aripiprazole, quetiapine, and olanzapine (when used in conjunction with fluoxetine) have received the Food and Drug Administration (FDA) labelling for this indication. There is, however, a greater risk of side effects with their use.
Other.
Besides the above uses antipsychotics may be used for obsessive-compulsive disorder, posttraumatic stress disorder, personality disorders, Tourette syndrome, autism and agitation in those with dementia. Evidence however does not support the use of atypical antipsychotics in eating disorders or personality disorder. Risperidone may be useful for obsessive compulsive disorder. The use of low doses of antipsychotics for insomnia, while common, is not recommended as there is little evidence of benefit and concerns regarding adverse effects. Low dose antipsychotics may also be used in treatment of impulse-behavioural and cognitive-perceptual symptoms of borderline personality disorder.
In children they may be used in those with disruptive behavior disorders, mood disorders and pervasive developmental disorders or intellectual disability. Antipsychotics are only weakly recommended for Tourette syndrome, because although they are effective, side effects are common. The situation is similar for those on the autism spectrum.
Much of the evidence for the off-label use of antipsychotics (for example, for dementia, OCD, PTSD, Personality Disorders, Tourette's) was of insufficient scientific quality to support such use, especially as there was strong evidence of increased risks of stroke, tremors, significant weight gain, sedation, and gastrointestinal problems. A UK review of unlicensed usage in children and adolescents reported a similar mixture of findings and concerns. A survey of children with pervasive developmental disorder found that 16.5% were taking an antipsychotic drug, most commonly for irritability, aggression, and agitation. Risperidone has been approved by the US FDA for the treatment of irritability in autistic children and adolescents.
Aggressive challenging behavior in adults with intellectual disability is often treated with antipsychotic drugs despite lack of an evidence base. A recent randomized controlled trial, however, found no benefit over placebo and recommended that the use of antipsychotics in this way should no longer be regarded as an acceptable routine treatment.
Typicals versus atypicals.
It is unclear whether the atypical (second-generation) antipsychotics offer advantages over older, first generation antipsychotics. Amisulpride, olanzapine, risperidone and clozapine may be more effective but are associated with greater side effects. Typical antipsychotics have equal drop-out and symptom relapse rates to atypicals when used at low to moderate dosages.
Clozapine is an effective treatment for those who respond poorly to other drugs ("treatment-resistant" or "refractory" schizophrenia), but it has the potentially serious side effect of agranulocytosis (lowered white blood cell count) in less than 4% of people.
Due to bias in the research the accuracy of comparisons of atypical antipsychotics is a concern.
In 2005, a US government body, the National Institute of Mental Health published the results of a major independent study (the CATIE project). No other atypical studied (risperidone, quetiapine, and ziprasidone) did better than the typical perphenazine on the measures used, nor did they produce fewer adverse effects than the typical antipsychotic perphenazine, although more patients discontinued perphenazine owing to extrapyramidal effects compared to the atypical agents (8% vs. 2% to 4%).
Compliance has not been shown to be different between the two types.
Many researchers question the first-line prescribing of atypicals over typicals, and some even question the distinction between the two classes. In contrast, other researchers point to the significantly higher risk of tardive dyskinesia and extrapyramidal symptoms with the typicals and for this reason alone recommend first-line treatment with the atypicals, notwithstanding a greater propensity for metabolic adverse effects in the latter. The UK government organization NICE recently revised its recommendation favoring atypicals, to advise that the choice should be an individual one based on the particular profiles of the individual drug and on the patient's preferences.
The re-evaluation of the evidence has not necessarily slowed the bias toward prescribing the atypicals.
Adverse effects.
More than one antipsychotic drug should not be used at a time except under unusual circumstances. Among the reasons for this are the increased number and harm from adverse effects of the drug when multiple drugs are used.
Some studies have found decreased life expectancy associated with the use of antipsychotics, and argued that more studies are needed. Antipsychotics may also increase the risk of early death in individuals with dementia. Antipsychotics typically worsen symptoms in people who suffer from depersonalisation disorder. Antipsychotic polypharmacy (prescribing two or more antipsychotics at the same time for an individual) is a common practice but not evidence-based or recommended, and there are initiatives to curtail it. Similarly, the use of excessively high doses (often the result of polypharmacy) continues despite clinical guidelines and evidence indicating that it is usually no more effective but is usually more harmful.
Other.
Loss of grey matter and other brain structural changes over time are observed in schizophrenia. Meta analyses of the effects of antipsychotic treatment on the course of grey matter loss and structural changes have reached conflicting conclusions. A 2012 meta analysis concluded that grey matter loss is greater in patients treated with first generation antipsychotics relative to those treated with atypicals, and hypothesized a protective effect of atypicals as one possible explanation. A second meta analyses suggested that treatment with antipsychotics was associated with increased grey matter loss.
Subtle, long-lasting forms of akathisia are often overlooked or confused with post-psychotic depression, in particular when they lack the extra pyramidal aspect that psychiatrists have been taught to expect when looking for signs of akathisia.
Withdrawal.
Withdrawal symptoms from antipsychotics may emerge during dosage reduction and discontinuation. Withdrawal symptoms can include nausea, emesis, anorexia, diarrhea, rhinorrhea, diaphoresis, myalgia, paresthesia, anxiety, agitation, restlessness, and insomnia. The psychological withdrawal symptoms can include psychosis, and can be mistaken for a relapse of the underlying disorder. Better management of the withdrawal syndrome may improve the ability of individuals to discontinue antipsychotics.
Tardive dyskinesia may abate during withdrawal from the antispsychotic agent, or it may persist.
Withdrawal effects may also occur when switching a person from one antipsychotic to another, (it is presumed due to variations of potency and receptor activity). Such withdrawal effects can include cholinergic rebound, an activation syndrome, and motor syndromes including dyskinesias. These adverse effects are more likely during rapid changes between antipsychotic agents, so making a gradual change between antipsychotics minimises these withdrawal effects. The British National Formulary recommends a gradual withdrawal when discontinuing antipsychotic treatment to avoid acute withdrawal syndrome or rapid relapse. The process of cross-titration involves gradually increasing the dose of the new medication while gradually decreasing the dose of the old medication.
List of agents.
Clinically used antipsychotic medications are listed below by drug group. Trade names appear in parentheses.
Notes:
"† indicates drugs that are no longer marketed in English-speaking countries. "
"‡ denotes drugs that are no longer (or were never to begin with) marketed in the United States. Some antipsychotics are not firmly placed in either first-generation or second-generation classes."
"# denotes drugs that have been withdrawn worldwide."
Disputed/unknown.
This category is for drugs that have been called both first and second-generation, depending on the literature being used.
Mechanism of action.
All antipsychotic drugs tend to block D receptors in the dopamine pathways of the brain. This means that dopamine released in these pathways has less effect. Excess release of dopamine in the mesolimbic pathway has been linked to psychotic experiences. It has also been proven less dopamine released in the prefrontal cortex in the brain, and excess dopamine released from all other pathways, has also been linked to psychotic experiences, caused by abnormal dopaminergic function as a result of patients suffering from schizophrenia or bipolar disorder. Various neuroleptics such as haloperidol and chlorpromazine suppress dopamine chemicals throughout its pathways, in order for dopamine receptors to function normally.
In addition of the antagonistic effects of dopamine, antipsychotics (in particular atypical neuroleptics) also antagonize 5-HT receptors. Different alleles of the 5-HT receptor have been associated with schizophrenia and other psychoses, including depression. Higher concentrations of 5-HT receptors in cortical and subcortical areas, in particular in the right caudate nucleus have been historically recorded. This is the same receptor that psychedelic drugs agonize to various degrees,
which explains the correlation between psychedelic drugs and schizophrenia.
Typical antipsychotics are not particularly selective and also block dopamine receptors in the mesocortical pathway, tuberoinfundibular pathway, and the nigrostriatal pathway. Blocking D receptors in these other pathways is thought to produce some unwanted side effects that the typical antipsychotics can produce (see above). They were commonly classified on a spectrum of low potency to high potency, where potency referred to the ability of the drug to bind to dopamine receptors, and not to the effectiveness of the drug. High-potency antipsychotics such as haloperidol, in general, have doses of a few milligrams and cause less sleepiness and calming effects than low-potency antipsychotics such as chlorpromazine and thioridazine, which have dosages of several hundred milligrams. The latter have a greater degree of anticholinergic and antihistaminergic activity, which can counteract dopamine-related side-effects.
Atypical antipsychotic drugs have a similar blocking effect on D receptors, however, most also act on serotonin receptors, especially 5-HT and 5-HT receptors. Both clozapine and quetiapine appear to bind just long enough to elicit antipsychotic effects but not long enough to induce extrapyramidal side effects and prolactin hypersecretion. 5-HT antagonism increases dopaminergic activity in the nigrostriatal pathway, leading to a lowered extrapyramidal side effect liability among the atypical antipsychotics.
History.
The original antipsychotic drugs were happened upon largely by chance and then tested for their effectiveness. The first, chlorpromazine, was developed as a surgical anesthetic. It was first used on psychiatric patients because of its powerful calming effect; at the time it was regarded as a non-permanent "pharmacological lobotomy". Lobotomy at the time was used to treat many behavioral disorders, including psychosis, although its effect was to markedly reduce behavior and mental functioning of all types. However, chlorpromazine proved to reduce the effects of psychosis in a more effective and specific manner than lobotomy, even though it was known to be capable of causing severe sedation. The underlying neurochemistry involved has since been studied in detail, and subsequent antipsychotic drugs have been discovered by an approach that incorporates this sort of information.
The discovery of chlorpromazine's psychoactive effects in 1952 led to greatly reduced use of restraint, seclusion, and sedation in the management of agitated patients, and also led to further research that resulted in the development of antidepressants, anxiolytics, and the majority of other drugs now used in the management of psychiatric conditions. In 1952, Henri Laborit described chlorpromazine only as inducing indifference towards what was happening around them in nonpsychotic, nonmanic patients, and Jean Delay and Pierre Deniker described it as controlling manic or psychotic agitation. The former claimed to have discovered a treatment for agitation in anyone, and the latter team claimed to have discovered a treatment for psychotic illness.
Until the 1970s there was considerable debate within psychiatry on the most appropriate term to use to describe the new drugs. In the late 1950s the most widely used term was "neuroleptic", followed by "major tranquilizer" and then "ataraxic". The first recorded use of the term tranquilizer dates from the early nineteenth century. In 1953 Frederik F. Yonkman, a chemist at the Swiss-based Cibapharmaceutical company, first used the term tranquilizer to differentiate reserpine from the older sedatives. The word"neuroleptic" was derived from the ("neuron", originally meaning "sinew" but today referring to the nerves) and "λαμβάνω" ("lambanō", meaning "take hold of"). Thus, the word means "taking hold of one's nerves". This may refer to common side effects such as reduced activity in general, as well as lethargy and impaired motor control. Although these effects are unpleasant and in some cases harmful, they were at one time, along with akathisia, considered a reliable sign that the drug was working. The term "ataraxy" was coined by the neurologist Howard Fabing and the classicist Alister Cameron to describe the observed effect of psychic indifference and detachment in patients treated with chlorpromazine. This term derived from the Greek adjective "ἀτάρακτος" ("ataraktos"), which means "not disturbed, not excited, without confusion, steady, calm". In the use of the terms "tranquilizer" and "ataractic", medical practitioners distinguished between the "major tranquilizers" or "major ataractics", which referred to drugs used to treat psychoses, and the "minor tranquilizers" or "minor ataractics", which referred to drugs used to treat neuroses. While popular during the 1950s, these terms are infrequently used today. They are being abandoned in favor of "antipsychotic", which refers to the drug's desired effects. Today, "minor tranquilizer" can refer to anxiolytic and/or hypnotic drugs such as the benzodiazepines and nonbenzodiazepines, which have some antipsychotic properties and are recommended for concurrent use with antipsychotics, and are useful for insomnia or drug-induced psychosis. They are powerful (and potentially addictive) sedatives.
Antipsychotics are broadly divided into two groups, the typical or first-generation antipsychotics and the atypical or second-generation antipsychotics. The typical antipsychotics are classified according to their chemical structure while the atypical antipsychotics are classified according to their pharmacological properties. These include serotonin-dopamine antagonists (see dopamine antagonist and serotonin antagonist), multi-acting receptor-targeted antipsychotics (MARTA, those targeting several systems), and dopamine partial agonists, which are often categorized as atypicals.
Society and culture.
Sales.
Antipsychotics were once among the biggest selling and most profitable of all drugs, generating $22 billion in global sales in 2008. By 2003 in the US, an estimated 3.21 million patients received antipsychotics, worth an estimated $2.82 billion. Over 2/3 of prescriptions were for the newer, more expensive atypicals, each costing on average $164 per year, compared to $40 for the older types. By 2008, sales in the US reached $14.6 billion, the biggest selling drugs in the US by therapeutic class.
Formulations.
Antipsychotics are sometimes administered as part of compulsory psychiatric treatment via inpatient (hospital) commitment or outpatient commitment. They may be administered orally or, in some cases, through long-acting (depot) injections administered in the dorsgluteal, ventrogluteal or deltoid muscle.
Controversy.
Joanna Moncrieff has argued that antipsychotic drug treatment is often undertaken as a means of control rather than to treat specific symptoms experienced by the patient. Moncreiff has further argued that the evidence for antipsychotics from discontinuation-relapse studies may be flawed, because they do not take into account that antipsychotics may sensitize the brain and provoke psychosis if discontinued, which may then be wrongly interpreted as a relapse of the original condition.
Use of this class of drugs has a history of criticism in residential care. As the drugs used can make patients calmer and more compliant, critics claim that the drugs can be overused. Outside doctors can feel under pressure from care home staff. In an official review commissioned by UK government ministers it was reported that the needless use of antipsychotic medication in dementia care was widespread and was linked to 1800 deaths per year. In the US, the government has initiated legal action against the pharmaceutical company Johnson & Johnson for allegedly paying kickbacks to Omnicare to promote its antipsychotic risperidone (Risperdal) in nursing homes.
There has also been controversy about the role of pharmaceutical companies in marketing and promoting antipsychotics, including allegations of downplaying or covering up adverse effects, expanding the number of conditions or illegally promoting off-label usage; influencing drug trials (or their publication) to try to show that the expensive and profitable newer atypicals were superior to the older cheaper typicals that were out of patent. Following charges of illegal marketing, settlements by two large pharmaceutical companies in the US set records for the largest criminal fines ever imposed on corporations. One case involved Eli Lilly and Company's antipsychotic Zyprexa, and the other involved Bextra. In the Bextra case, the government also charged Pfizer with illegally marketing another antipsychotic, Geodon. In addition, Astrazeneca faces numerous personal-injury lawsuits from former users of Seroquel (quetiapine), amidst federal investigations of its marketing practices. By expanding the conditions for which they were indicated, Astrazeneca's Seroquel and Eli Lilly's Zyprexa had become the biggest selling antipsychotics in 2008 with global sales of $5.5 billion and $5.4 billion respectively.
Harvard medical professor Joseph Biederman conducted research on bipolar disorder in children that led to an increase in such diagnoses. A 2008 Senate investigation found that Biederman also received $1.6 million in speaking and consulting fees between 2000 and 2007 — some of them undisclosed to Harvard — from companies including makers of antipsychotic drugs prescribed for children with bipolar disorder. Johnson & Johnson gave more than $700,000 to a research center that was headed by Biederman from 2002 to 2005, where research was conducted, in part, on Risperdal, the company's antipsychotic drug. Biederman has responded saying that the money did not influence him and that he did not promote a specific diagnosis or treatment.
Pharmaceutical companies have also been accused of attempting to set the mental health agenda through activities such as funding consumer advocacy groups.
Special populations.
It is recommended that persons with dementia who exhibit behavioral and psychological symptoms should not be given antipsychotics before trying other treatments. When taking antipsychotics this population has increased risk of cerebrovascular effects, parkinsonism or extrapyramidal symptoms, sedation, confusion and other cognitive adverse effects, weight gain, and increased mortality. Physicians and caretakers of persons with dementia should try to address symptoms including agitation, aggression, apathy, anxiety, depression, irritability, and psychosis with alternative treatments whenever antipsychotic use can be replaced or reduced. Elderly persons often have their dementia treated first with antipsychotics and this is not best.

</doc>
<doc id="2871" url="https://en.wikipedia.org/wiki?curid=2871" title="Akita">
Akita


</doc>
<doc id="2875" url="https://en.wikipedia.org/wiki?curid=2875" title="Archduke Charles, Duke of Teschen">
Archduke Charles, Duke of Teschen

Archduke Charles of Austria, Duke of Teschen (Karl Ludwig Johann Josef Lorenz of Austria; 5 September 1771 – 30 April 1847) was an Austrian field-marshal, the third son of Emperor Leopold II and his wife, Maria Luisa of Spain. He was also the younger brother of Francis II, Holy Roman Emperor. Despite being epileptic, Charles achieved respect both as a commander and as a reformer of the Austrian army. He was considered one of Napoleon's most formidable opponents.
He began his career fighting the revolutionary armies of France. Early in the wars of the First Coalition, he saw victory at Neerwinden in 1793, before tasting defeat at Wattignies 1793 and Fleurus 1794. In 1796, as chief of all Austrian forces on the Rhine, Charles out-generaled Jean-Baptiste Jourdan at Amberg and Würzburg, and forced Jean Victor Marie Moreau to withdraw across the Rhine, and followed these victories with others at Zürich, Ostrach, Stockach, and Messkirch in 1799. He reformed Austria's armies to adopt the nation at arms principle; in 1809, he went into the War of the Fifth Coalition with confidence and inflicted Napoleon's first major setback at Aspern-Essling, before suffering a defeat at the bloody Battle of Wagram. Following Wagram, Charles saw no more significant action in the Napoleonic Wars.
As a military strategist, historians compare him to Arthur Wellesley, 1st Duke of Wellington, conservative, cautious, and competent. Charles was a study in contrasts. As a practitioner, he was flawless in executing complex and risky maneuvers of troops in the heat of battle, achieving brilliant victories in the face of almost certain defeat. Yet, as a theoretician, his devotion to ground and caution led his contemporary, Carl von Clausewitz, to criticize his rigidity and adherence to geographic strategy. Regardless, he remains among Austria's pantheon of heroes of the French Revolutionary and Napoleonic wars.
Youth and early career.
Charles was born in Florence, Tuscany. His father, then Grand Duke of Tuscany, generously permitted Charles's childless aunt Archduchess Marie Christine of Austria and her husband Albert of Saxe-Teschen to adopt and raise the boy in Vienna. Charles spent his youth in Tuscany, at Vienna and in the Austrian Netherlands, where he began his career of military service in the wars of the French Revolution. He commanded a brigade at the Battle of Jemappes (1792), and in the campaign of 1793 distinguished himself at the Action of Aldenhoven and the Battle of Neerwinden. In this year he became Governor of the Habsburg Netherlands, an office he lost with the occupation of the Low Countries by the French revolutionaries in 1794. The year he became Governor he also received the army rank of Lieutenant Field Marshal. Shortly thereafter another promotion saw him made "Feldzeugmeister" (equivalent of Lieutenant General). In the remainder of the war in the Low Countries he held high commands, and was present at the Battle of Fleurus (1794).
In 1795 he served on the Rhine, and in the following year was entrusted with chief control of all the Austrian forces on that river. His conduct of the operations against Jourdan and Moreau in 1796 marked him out at once as one of the greatest generals in Europe. At first falling back carefully and avoiding a decision, he finally marched away, leaving a mere screen in front of Moreau. Falling upon Jourdan, he beat him in the battles of Amberg (August) and Würzburg (September), and drove him over the Rhine with great loss. He then turned upon Moreau's army, which he defeated and forced out of Germany (Battle of Emmendingen, October).
Napoleonic Wars.
In 1797 he was sent to arrest the victorious march of General Bonaparte in Italy, and he conducted the retreat of the over-matched Austrians with the highest skill. In the campaign of 1799 he once more opposed Jourdan, whom he defeated in the battles of Ostrach and Stockach, following up his success by invading Switzerland and defeating Masséna in the First Battle of Zurich, after which he re-entered Germany and drove the French once more over the Rhine.
Ill-health, however, forced him to retire to Bohemia, but he was soon recalled to undertake the task of checking Moreau's advance on Vienna. The result of the Battle of Hohenlinden had, however, foredoomed the attempt, and the archduke had to make the armistice of Steyr. His popularity was now such that the Perpetual Diet of Regensburg, which met in 1802, resolved to erect a statue in his honor and to give him the title of savior of his country, but Charles refused both distinctions.
In the short and disastrous war of 1805 Archduke Charles commanded what was intended to be the main army in Italy, but events made Germany the decisive theatre of operations; Austria sustained defeat on the Danube, and the archduke was defeated by Massena in the Battle of Caldiero. With the conclusion of peace he began his active work of army reorganization, which was first tested on the field in 1809.
In 1806 Francis II (now Francis I of Austria) named the Archduke Charles, already a field marshal, as Commander in Chief of the Austrian army and Head of the Council of War. Supported by the prestige of being the only general who had proved capable of defeating the French, he promptly initiated a far-reaching scheme of reform, which replaced the obsolete methods of the 18th century. The chief characteristics of the new order were the adoption of the nation in arms principle and the adoption of French war organization and tactics. The army reforms were not yet completed by the war of 1809, in which Charles acted as commander in chief, yet even so it proved a far more formidable opponent than the old and was only defeated after a desperate struggle involving Austrian victories and large loss of life on both sides.
Its initial successes were neutralized by the reverses of Abensberg, Landshut and Eckmühl but, after the evacuation of Vienna, the archduke won a strong victory at the Battle of Aspern-Essling but soon afterwards lost at the Battle of Wagram. At the end of the campaign the archduke gave up all his military offices.
Later life.
When Austria joined the ranks of the allies during the War of the Sixth Coalition, Charles was not given a command and the post of commander-in-chief of the allied Grand Army of Bohemia went to the Prince of Schwarzenberg. Charles spent the rest of his life in retirement, except for a short time in 1815 when he was military governor of the Fortress Mainz. In 1822 he succeeded to the duchy of Saxe-Teschen.
On 15 September/17 September 1815 in Weilburg, Charles married Princess Henrietta of Nassau-Weilburg (1797–1829). She was a daughter of Frederick William of Nassau-Weilburg (1768–1816) and his wife Burgravine Louise Isabelle of Kirchberg.
Frederick William was the eldest surviving son of Karl Christian of Nassau-Weilburg and Princess Wilhelmine Carolina of Orange-Nassau.
Wilhelmine Carolina was a daughter of William IV, Prince of Orange and Anne, Princess Royal and Princess of Orange. Anne was in turn the eldest daughter of George II of Great Britain and Caroline of Ansbach.
Charles died at Vienna on 30 April 1847. He is buried in tomb 122 in the New Vault of the Imperial Crypt in Vienna. An equestrian statue was erected to his memory on the Heldenplatz in Vienna in 1860.
Assessment of his achievements.
The caution which the archduke preached so earnestly in his strategic works, he displayed in practice only when the situation seemed to demand it, though his education certainly prejudiced him in favor of the defensive at all costs. He was at the same time capable of forming and executing the most daring offensive strategy, and his tactical skill in the handling of troops, whether in wide turning movements, as at Würzburg and Zürich, or in masses, as at Aspern and Wagram, was certainly equal to that of any leader of his time, with only a few exceptions.
His campaign of 1796 is considered almost faultless. That he sustained defeat in 1809 was due in part to the great numerical superiority of the French and their allies, and in part to the condition of his newly reorganized troops. His six weeks' inaction after the victory of Aspern is, however, open to unfavorable criticism. As a military writer, his position in the evolution of the art of war is very important, and his doctrines had naturally the greatest weight. Nevertheless they cannot but be considered antiquated even in 1806. Caution and the importance of strategic points are the chief features of his system. The rigidity of his geographical strategy may be gathered from the prescription that this principle is never to be departed from.
Again and again he repeats the advice that nothing should be hazarded unless one's army is completely secure, a rule which he himself neglected with such brilliant results in 1796. Strategic points, he says, not the defeat of the enemy's army, decide the fate of one's own country, and must constantly remain the general's main concern, a maxim which was never more remarkably disproved than in the war of 1809. The editor of the archduke's work is able to make but a feeble defense against Clausewitz's reproach that Charles attached more value to ground than to the annihilation of the foe. In his tactical writings the same spirit is conspicuous. His reserve in battle is designed to cover a retreat.
The baneful influence of these antiquated principles was clearly shown in the maintenance of Königgrätz-Josefstadt in 1866 as a strategic point, which was preferred to the defeat of the separated Prussian armies, and in the strange plans produced in Vienna for the campaign of 1859, and in the almost unintelligible Battle of Montebello in the same year. The theory and the practice of Archduke Charles form one of the most curious contrasts in military history. In the one he is unreal, in the other he displayed, along with the greatest skill, a vivid activity which made him for long the most formidable opponent of Napoleon.
He was the 831st Knight of the Order of the Golden Fleece in Austria.

</doc>
<doc id="2877" url="https://en.wikipedia.org/wiki?curid=2877" title="Augustine of Canterbury">
Augustine of Canterbury

Augustine of Canterbury (first third of the 6th century – probably 26 May 604) was a Benedictine monk who became the first Archbishop of Canterbury in the year 597. He is considered the "Apostle to the English" and a founder of the English Church.
Augustine was the prior of a monastery in Rome when Pope Gregory the Great chose him in 595 to lead a mission, usually known as the Gregorian mission, to Britain to Christianize King Æthelberht and his Kingdom of Kent from Anglo-Saxon paganism. Kent was probably chosen because Æthelberht had married a Christian princess, Bertha, daughter of Charibert I the King of Paris, who was expected to exert some influence over her husband. Before reaching Kent the missionaries had considered turning back but Gregory urged them on, and in 597 Augustine landed on the Isle of Thanet and proceeded to Æthelberht's main town of Canterbury.
King Æthelberht converted to Christianity and allowed the missionaries to preach freely, giving them land to found a monastery outside the city walls. Augustine was consecrated as a bishop and converted many of the king's subjects, including thousands during a mass baptism on Christmas Day in 597. Pope Gregory sent more missionaries in 601, along with encouraging letters and gifts for the churches, although attempts to persuade the native Celtic bishops to submit to Augustine's authority failed. Roman bishops were established at London and Rochester in 604, and a school was founded to train Anglo-Saxon priests and missionaries. Augustine also arranged the consecration of his successor, Laurence of Canterbury. The archbishop probably died in 604 and was soon revered as a saint.
Background to the mission.
After the withdrawal of the Roman legions from their province of Britannia in 410, the inhabitants were left to defend themselves against the attacks of the Saxons. Before the Roman withdrawal Britannia had been converted to Christianity and produced the ascetic Pelagius. Britain sent three bishops to the Council of Arles in 314, and a Gaulish bishop went to the island in 396 to help settle disciplinary matters. Material remains testify to a growing presence of Christians, at least until around 360. After the Roman legions departed, pagan tribes settled the southern parts of the island while western Britain, beyond the Anglo-Saxon kingdoms, remained Christian. This native British Church developed in isolation from Rome under the influence of missionaries from Ireland and was centred on monasteries instead of bishoprics. Other distinguishing characteristics were its calculation of the date of Easter and the style of the tonsure haircut that clerics wore. Evidence for the survival of Christianity in the eastern part of Britain during this time includes the survival of the cult of Saint Alban and the occurrence in place names of "eccles", derived from the Latin "ecclesia", meaning "church". There is no evidence that these native Christians tried to convert the Anglo-Saxons. The invasions destroyed most remnants of Roman civilisation in the areas held by the Saxons and related tribes, including the economic and religious structures .
It was against this background that Pope Gregory I decided to send a mission, often called the Gregorian mission, to convert the Anglo-Saxons to Christianity in 595. The Kingdom of Kent was ruled by Æthelberht, who married a Christian princess named Bertha before 588, and perhaps earlier than 560. Bertha was the daughter of Charibert I, one of the Merovingian kings of the Franks. As one of the conditions of her marriage, she brought a bishop named Liudhard with her to Kent. Together in Canterbury, they restored a church that dated to Roman times—possibly the current St Martin's Church. Æthelberht was a pagan at this point but allowed his wife freedom of worship. One biographer of Bertha states that under his wife's influence, Æthelberht asked Pope Gregory to send missionaries. The historian Ian Wood feels that the initiative came from the Kentish court as well as the queen. Other historians, however, believe that Gregory initiated the mission, although the exact reasons remain unclear. Bede, an 8th-century monk who wrote a history of the English church, recorded a famous story in which Gregory saw fair-haired Saxon slaves from Britain in the Roman slave market and was inspired to try to convert their people. More practical matters, such as the acquisition of new provinces acknowledging the primacy of the papacy, and a desire to influence the emerging power of the Kentish kingdom under Æthelberht, were probably involved. The mission may have been an outgrowth of the missionary efforts against the Lombards who, as pagans and Arian Christians, were not on good relations with the Catholic church in Rome.
Aside from Æthelberht's granting of freedom of worship to his wife, the choice of Kent was probably dictated by a number of other factors. Kent was the dominant power in southeastern Britain. Since the eclipse of King Ceawlin of Wessex in 592, Æthelberht was the leading Anglo-Saxon ruler; Bede refers to Æthelberht as having imperium (overlordship) south of the River Humber. Trade between the Franks and Æthelberht's kingdom was well established, and the language barrier between the two regions was apparently only a minor obstacle, as the interpreters for the mission came from the Franks. Lastly, Kent's proximity to the Franks allowed support from a Christian area. There is some evidence, including Gregory's letters to Frankish kings in support of the mission, that some of the Franks felt that they had a claim to overlordship over some of the southern British kingdoms at this time. The presence of a Frankish bishop could also have lent credence to claims of overlordship, if Bertha's Bishop Liudhard was felt to be acting as a representative of the Frankish church and not merely as a spiritual advisor to the queen. Frankish influence was not merely political; archaeological remains attest to a cultural influence as well.
In 595, Gregory chose Augustine, who was the prior of the Abbey of St Andrew's in Rome, to head the mission to Kent. The pope selected monks to accompany Augustine and sought support from the Frankish royalty and clergy in a series of letters, of which some copies survive in Rome. He wrote to King Theuderic II of Burgundy and to King Theudebert II of Austrasia, as well as their grandmother Brunhild, seeking aid for the mission. Gregory thanked King Chlothar II of Neustria for aiding Augustine. Besides hospitality, the Frankish bishops and kings provided interpreters and Frankish priests to accompany the mission. By soliciting help from the Frankish kings and bishops, Gregory helped to assure a friendly reception for Augustine in Kent, as Æthelbert was unlikely to mistreat a mission which visibly had the support of his wife's relatives and people. Moreover, the Franks appreciated the chance to participate in mission that would extend their influence in Kent. Chlothar, in particular, needed a friendly realm across the Channel to help guard his kingdom's flanks against his fellow Frankish kings.
Sources make no mention of why Pope Gregory chose a monk to head the mission. Pope Gregory once wrote to Æthelberht complimenting Augustine's knowledge of the Bible, so Augustine was evidently well educated. Other qualifications included administrative ability, for Gregory was the abbot of St Andrews as well as being pope, which left the day-to-day running of the abbey to Augustine, the prior.
Arrival and first efforts.
Augustine was accompanied by Laurence of Canterbury, his eventual successor to the archbishopric, and a group of about 40 companions, some of whom were monks. Soon after leaving Rome, the missionaries halted, daunted by the nature of the task before them. They sent Augustine back to Rome to request papal permission to return. Gregory refused and sent Augustine back with letters encouraging the missionaries to persevere. In 597, Augustine and his companions landed in Kent. They achieved some initial success soon after their arrival: Æthelberht permitted the missionaries to settle and preach in his capital of Canterbury where they used the church of St Martin's for services. Neither Bede nor Gregory mentions the date of Æthelberht's conversion, but it probably took place in 597. In the early medieval period, large-scale conversions required the ruler's conversion first, and Augustine is recorded as making large numbers of converts within a year of his arrival in Kent. Also, by 601, Gregory was writing to both Æthelberht and Bertha, calling the king his son and referring to his baptism. A late medieval tradition, recorded by the 15th-century chronicler Thomas Elmham, gives the date of the king's conversion as Whit Sunday, or 2 June 597; there is no reason to doubt this date, although there is no other evidence for it. Against a date in 597 is a letter of Gregory's to Patriarch Eulogius of Alexandria in June 598, which mentions the number of converts made by Augustine, but does not mention any baptism of the king. However, it is clear that by 601 the king had been converted. His baptism likely took place at Canterbury.
Augustine established his episcopal see at Canterbury. It is not clear when and where Augustine was consecrated as a bishop. Bede, writing about a century later, states that Augustine was consecrated by the Frankish Archbishop Ætherius of Arles after the conversion of Æthelberht. Contemporary letters from Pope Gregory, however, refer to Augustine as a bishop before he arrived in England. A letter of Gregory's from September 597 calls Augustine a bishop, and one dated ten months later says Augustine had been consecrated on Gregory's command by bishops of the German lands. The historian R. A. Markus discusses the various theories of when and where Augustine was consecrated, and suggests he was consecrated before arriving in England, but argues the evidence does not permit deciding exactly where this took place.
Soon after his arrival, Augustine founded the monastery of Saints Peter and Paul, which later became St Augustine's Abbey, on land donated by the king. This foundation has often been claimed as the first Benedictine abbey outside Italy, and that by founding it, Augustine introduced the Rule of St. Benedict into England, but there is no evidence the abbey followed the Benedictine Rule at the time of its foundation. In a letter Gregory wrote to the patriarch of Alexandria in 598, he claimed that more than 10,000 Christians had been baptised; the number may be exaggerated but there is no reason to doubt that a mass conversion took place. However, there were probably some Christians already in Kent before Augustine arrived, remnants of the Christians who lived in Britain in the later Roman Empire. Little literary traces remain of them, however. One other effect of the king's conversion by Augustine's mission was that the Frankish influence on the southern kingdoms of Britain was decreased.
After these conversions, Augustine sent Laurence back to Rome with a report of his success, along with questions about the mission. Bede records the letter and Gregory's replies in chapter 27 of his "Historia ecclesiastica gentis Anglorum"; this section of the "History" is usually known as the "Libellus responsionum". Augustine asked for Gregory's advice on a number of issues, including how to organise the church, the punishment for church robbers, guidance on who was allowed to marry whom, and the consecration of bishops. Other topics were relations between the churches of Britain and Gaul, childbirth and baptism, and when it was lawful for people to receive communion and for a priest to celebrate mass.
Further missionaries were sent from Rome in 601. They brought a pallium for Augustine and a present of sacred vessels, vestments, relics, and books. The pallium was the symbol of metropolitan status, and signified that Augustine was now an archbishop unambiguously associated with the Holy See. Along with the pallium, a letter from Gregory directed the new archbishop to ordain 12 suffragan bishops as soon as possible and to send a bishop to York. Gregory's plan was that there would be two metropolitans, one at York and one at London, with 12 suffragan bishops under each archbishop. As part of this plan, Augustine was expected to transfer his archiepiscopal see to London from Canterbury. The move from Canterbury to London never happened; no contemporary sources give the reason, but it was probably because London was not part of Æthelberht's domains. Instead, London was part of the kingdom of Essex, ruled by Æthelberht's nephew Saebert of Essex, who converted to Christianity in 604. The historian S. Brechter has suggested that the metropolitan see was indeed moved to London, and that it was only with the abandonment of London as a see after the death of Æthelberht that Canterbury became the archiepiscopal see. This theory contradicts Bede's version of events, however.
Additional work.
In 604, Augustine founded two more bishoprics in Britain. Two men who had come to Britain with him in 601 were consecrated, Mellitus as Bishop of London and Justus as Bishop of Rochester. Bede relates that Augustine, with the help of the king, "recovered" a church built by Roman Christians in Canterbury. It is not clear if Bede meant that Augustine rebuilt the church or that Augustine merely reconsecrated a building that had been used for pagan worship. Archaeological evidence seems to support the latter interpretation; in 1973 the remains of an aisled building dating from the Romano-British period were uncovered just south of the present Canterbury Cathedral. The historian Ian Wood argues that the existence of the "Libellus" points to more contact between Augustine and the native Christians because the topics covered in the work are not restricted to conversion from paganism, but also dealt with relations between differing styles of Christianity.
Augustine failed to extend his authority to the Christians in Wales and Dumnonia to the west. Gregory had decreed that these Christians should submit to Augustine and that their bishops should obey him, apparently believing that more of the Roman governmental and ecclesiastical organisation survived in Britain than was actually the case. According to the narrative of Bede, the Britons in these regions viewed Augustine with uncertainty, and their suspicion was compounded by a diplomatic misjudgement on Augustine's part. In 603, Augustine and Æthelberht summoned the British bishops to a meeting south of the Severn. These guests retired early to confer with their people, who, according to Bede, advised them to judge Augustine based upon the respect he displayed at their next meeting. When Augustine failed to rise from his seat on the entrance of the British bishops, they refused to recognise him as their archbishop. There were, however, deep differences between Augustine and the British church that perhaps played a more significant role in preventing an agreement. At issue were the tonsure, the observance of Easter, and practical and deep-rooted differences in approach to asceticism, missionary endeavours, and how the church itself was organised. Some historians believe that Augustine had no real understanding of the history and traditions of the British church, damaging his relations with their bishops. Also, there were political dimensions involved, as Augustine's efforts were sponsored by the Kentish king, and at this period the Wessex and Mercian kingdoms were expanding to the west, into areas held by the Britons.
Further success.
Gregory also instructed Augustine on other matters. Temples were to be consecrated for Christian use, and feasts, if possible, moved to days celebrating Christian martyrs. One religious site was revealed to be a shrine of a local St Sixtus, whose worshippers were unaware of details of the martyr's life or death. They may have been native Christians, but Augustine did not treat them as such. When Gregory was informed, he told Augustine to stop the cult and use the shrine for the Roman St Sixtus.
Gregory legislated on the behaviour of the laity and the clergy. He placed the new mission directly under papal authority and made it clear that English bishops would have no authority over Frankish counterparts nor vice versa. Other directives dealt with the training of native clergy and the missionaries' conduct.
The King's School, Canterbury claims Augustine as its founder, which would make it the world's oldest existing school, but the first documentary records of the school date from the 16th century. Augustine did establish a school, and soon after his death Canterbury was able to send teachers out to support the East Anglian mission. Augustine received liturgical books from the pope, but their exact contents are unknown. They may have been some of the new mass books that were being written at this time. The exact liturgy that Augustine introduced to England remains unknown, but it would have been a form of the Latin language liturgy in use at Rome.
Death and legacy.
Before his death, Augustine consecrated Laurence of Canterbury as his successor to the archbishopric, probably to ensure an orderly transfer of office. Although at the time of Augustine's death, 26 May 604, the mission barely extended beyond Kent, his undertaking introduced a more active missionary style into the British Isles. Despite the earlier presence of Christians in Ireland and Wales, no efforts had been made to try to convert the Saxon invaders. Augustine was sent to convert the descendants of those invaders, and eventually became the decisive influence in Christianity in the British Isles. Much of his success came about because of Augustine's close relationship with Æthelberht, which gave the archbishop time to establish himself. Augustine's example also influenced the great missionary efforts of the Anglo-Saxon Church.
Augustine's body was originally buried in the portico of what is now St Augustine's, Canterbury, but it was later exhumed and placed in a tomb within the abbey church, which became a place of pilgrimage and veneration. After the Norman Conquest the cult of St Augustine was actively promoted. After the Conquest, his shrine in St Augustine's Abbey held a central position in one of the axial chapels, flanked by the shrines of his successors Laurence and Mellitus. King Henry I of England granted St. Augustine's Abbey a six-day fair around the date on which Augustine's relics were translated to his new shrine, from 8 September through 13 September.
A life of Augustine was written by Goscelin around 1090, but this life portrays Augustine in a different light than Bede's account. Goscelin's account has little new historical content, mainly being filled with miracles and imagined speeches. Building on this account, later medieval writers continued to add new miracles and stories to Augustine's life, often quite fanciful. These authors included William of Malmesbury, who claimed that Augustine founded Cerne Abbey, the author (generally believed to be John Brompton) of a late medieval chronicle containing invented letters from Augustine, and a number of medieval writers who included Augustine in their romances. Another problem with investigating Augustine's saintly cult is the confusion resulting because most medieval liturgical documents mentioning Augustine do not distinguish between Augustine of Canterbury and Augustine of Hippo, a fourth-century saint. Medieval Scandinavian liturgies feature Augustine of Canterbury quite often, however. During the English Reformation, Augustine's shrine was destroyed and his relics were lost.
Augustine's shrine was re-established in March 2012 at the church of St. Augustine in Ramsgate, Kent, very close to the mission's landing site. St Augustine's Cross, a Celtic cross erected in 1884, marks the spot in Ebbsfleet, Thanet, East Kent, where Augustine is said to have landed.

</doc>
<doc id="2881" url="https://en.wikipedia.org/wiki?curid=2881" title="Alexander of Hales">
Alexander of Hales

Alexander of Hales, O.F.M., (c. 118521 August 1245) (also Halensis, Alensis, Halesius, Alesius) also called "Doctor Irrefragibilis" (by Pope Alexander IV in the "Bull De Fontibus Paradisi") and "Theologorum Monarcha" was a theologian and philosopher important in the development of Scholasticism and of the Franciscan School.
Life.
Alexander was born at Hales, Shropshire (today Halesowen, West Midlands), England, between 1180 and 1186. He came from a rather wealthy country family. He studied at the University of Paris and became a master of arts sometime before 1210. He began to read theology in 1212 or 1213, and became a regent master in 1220 or 1221. He introduced the Sentences of Peter Lombard as the basic textbook for the study of theology. During the University strike of 1229, Alexander participated in an embassy to Rome to discuss the place of Aristotle in the curriculum. Having held a prebend at Holborn (prior to 1229) and a canonry of St. Paul’s in London (1226-1229), He visited England in 1230 and received a canonry and an archdeaconry in Coventry and Lichfield, his native diocese. He taught at Paris in the academic year 1232-33, but was appointed to a delegation by Henry III of England in 1235, along with Simon Langton and Fulk Basset, to negotiate for the renewal of the peace between England and France.
In 1236 or 1237, aged about 50, Alexander made the surprising step of entering the Franciscan Order, thus becoming the first Franciscan friar to hold a University chair. His doctrinal positions became the starting point for the Franciscan school of theology. He continued to teach and to represent the University, and participated in the First Council of Lyon in the winter of 1245.
After returning to Paris, Alexander fell ill, probably due to an epidemic then sweeping the city. Shortly before his death, he passed his chair on to John of La Rochelle, setting the precedent for that chair to be held by a Franciscan. Alexander died at Paris on 21 August 1245.
As the first Franciscan to hold a chair at the University of Paris, Alexander had many significant disciples. He was called "Doctor Irrefragibilis" (Irrefutable Teacher) and "Doctor Doctorum" (Teacher of Teachers). The latter title is especially suggestive of his role in forming several Franciscans who later became influential thinkers in the faculty, among them Saint Bonaventure, John of La Rochelle, Odo Rigaldus, William of Middleton and Richard Rufus of Cornwall. Bonaventure, who may not have sat under Alexander directly, nevertheless referred to Alexander as his "father and master" and wished to "follow in his footsteps."
Works.
Alexander is known for reflecting the works of several other Middle Age thinkers, especially those of Saint Anselm, and Saint Augustine. He is also known to quote thinkers such as Saint Bernard, and Richard of Saint-Victor. He differs from those in his genre as he is known to reflect his own interests and those of his generation. When using the works of his authorities Alexander does not only review their reasoning but also gives conclusions, expands on them, and offers his agreements and disagreement with them. He was also different in that he appeals to Pre-Lombardian figures, and his use of Anselm of Canterbury and Bernard of Clairvaux, whose works were not cited as frequently by other 12th-century scholastics. Aristotle is also quite frequently quoted in Alexander's works. Alexander was fascinated by Pseudo-Dionysian hierarchy of angels and in how their nature can be understood, given Aristotelian metaphysics.
Among the doctrines which were specially developed and, so to speak, fixed by Alexander of Hales, are the "thesaurus supererogationis perfectorum" (treasury of supererogatory merits) and the "character indelibilis" (sacramental character) of baptism, confirmation, and ordination. That doctrine had been written about much earlier by Augustine of Hippo and was eventually defined a dogma by the Council of Trent. He also posed an important question about the cause of the Incarnation: would Christ have been incarnated if humanity had never sinned? The question eventually became the focal point for a philosophical issue (the theory of possible worlds) and a theological topic on the distinction between God's absolute power ("potentia absoluta") and His ordained power ("potentia ordinata").
Summa Universae Theologiae.
He had written the summary/commentary of Peter Lombard's four books of the "Sentences". It had exposed the trinitarian theology of the Greeks. This had been the most important writing that Alexander had claimed, and had been the earliest in genre. While it is common for scholars to state that Alexander was the first to write a commentary on the "Sentences" of Peter Lombard, it is not quite accurate. Authorship is more contentious for this work; although he started this work, he died before it could be finished, and most likely was more a product of people other than Alexander. There were a number of "commentaries" on the "Sentences", but Alexander appears to have been the first magisterial commentary. Although it was Alexanders most significant writing, it had not been completed, therefore leaving historians left with many questions on the reliability and quality of the writing. This was taken into consideration when the "Summa" had been examined by Father Victorin Doucet for different editions of them. The sources has seem to be the resulting problem of the "Summa", "counted there were 4814 explicit quotations and 1372 implicit quotations from Augustine, more than one quarter of texts were cited in the body of the "Summa".
Of Alexander, the "Doctor Irrefragabilis" of the Franciscans, whose "Summa" was on one occasion proclaimed by an assembly of seventy doctors to be infallible, Roger Bacon declares that the "Summa" in question, though it was as heavy as the weight of a horse, was full of errors and displayed ignorance of physics, of metaphysics, and even of logic.
Other historical works.
Alexander also influenced and sometimes is confused with Alexander Carpenter, Latinized as "Fabricius" (fl. 1429), who was the author of the "Destructorium viciorum", a religious work popular in the 15th and 16th centuries. Carpenter also authored other works, such as "Homiliae eruditae" ("Learned Sermons").
Historiographical contribution.
Alexander was said to have been among the earliest scholastics to engage with Aristotle's newly translated writings. Between 1220 and 1227, he wrote "Glossa in quatuor libros Sententiarum Petri Lombardi" ("A Gloss on the Four Books of the Sentences of Peter Lombard") (composed in the mid-12th century), which was particularly important because it was the first time that a book other than the Bible was used as a basic text for theological study. This steered the development of scholasticism in a more systematic direction, inaugurating an important tradition of writing commentaries on the "Sentences" as a fundamental step in the training of master theologians.
A medieval scholastic.
In doing so, he elevated Lombard's work from a mere theological resource to the basic framework of questions and problems from which masters could teach. The commentary (or more correctly titled a "Gloss") survived in student reports from Alexander's teaching in the classroom and so it provides a major insight into the way theologians taught their discipline in the 1220s. As is the case with "Glossa" and "Quaestiones Disputatae", much of his work is probably written in the form of notes on his oral teachings by students, though the content is definitely his.
For his contemporaries, however, Alexander's fame was his inexhaustible interest in disputation. His disputations prior to his becoming a Franciscan cover over 1,600 pages in their modern edition. His disputed questions after 1236 remain unpublished. Alexander was also one of the first scholastics to participate in the "Quodlibetal", a university event in which a master had to respond to any question posed by any student or master over a period of three days. Alexander's "Quodlibetal questions" also remain unedited.
Theologian.
At the beginning of 1236, he entered the Franciscan order (he was at least 50) and was the first Franciscan to hold a chair at the University of Paris. He held this post until shortly before his death in Paris in 1245. When he became a Franciscan and thus created a formal Franciscan school of theology at Paris, it was soon clear that his students lacked some of the basic tools for the discipline. Alexander responded by beginning a "Summa theologiae" that is now known as the "Summa fratris Alexandri". Alexander drew mainly from his own disputations, but also selected ideas, arguments and sources from his contemporaries. It treats in its first part the doctrines of God and his attributes; in its second, those of creation and sin; in its third, those of redemption and atonement; and, in its fourth and last, those of the sacraments. This massive text, which Roger Bacon would later sarcastically describe as weighing as much as a horse, was unfinished at his death; his students, William of Middleton and John of Rupella, were charged with its completion. It was certainly read by the Franciscans at Paris, including Bonaventure.
Alexander was an innovative theologian. He was part of the generation that first grappled with the writings of Aristotle. While there was a ban on using Aristotle's works as teaching texts, theologians like Alexander continued to exploit his ideas in their theology. Two other uncommon sources were promoted by Alexander: Anselm of Canterbury, whose writings had been ignored for almost a century gained an important advocate in Alexander and he used Anselm's works extensively in his teaching on Christology and soteriology; and, Pseudo-Dionysius the Areopagite, whom Alexander used in his examination of the theology of Orders and ecclesiastical structures.
Though he also continued the tradition of Aristotle- and Augustine-focused thought in the Franciscan school, he did so through an Anselm-directed lens. In fact, Alexander was one of the major influences for the advancement of Anselmian thought in the 13th century. One such example is the idea of original sin as a lack of justice. Alexander believed that original sin is both a punishment as well as a cause for punishment. That is to say, the body is corrupt, but the soul is clean. Alexander advances the idea that it is would not be God’s fault to create a being that would bind the ‘corrupt’ with the ‘clean’. He advanced a highly original response that the soul naturally desires the body. Consequently, God is both merciful in giving the soul what it wants, as well as just in punishing the soul for binding with the corrupt flesh. Either the soul knew that the body was corrupt, or it did not (in which case it would be “laboring under ignorance”); both of these considerations are cause for divine punishment.
Alexander is also known for rejecting the idea that there are many things in God’s mind, instead claiming that it is more perfect to know just one thing. He did not start off with this view, though. In the "Glossa" he openly suggests the idea of the multiplicity of divine ideas. In his later work, "Quaestio disputata antequam erat Frater 46", he finally rejects the plurality of divine ideas, and this theme continues through the rest of his works. Specifically, in one of his last works, "De scientia divina", he concludes that the idea of plurality itself is strictly temporal, a human notion.
One of his more famous works, the "Summa", is important because of its system for determining if a war is just. There are six requirements for determining this: authority and attitude (in reference to who declares the war), intention and condition (in reference to the soldiers), merit (of the enemy) and just cause. Just cause becomes the overarching moral principle for declaring war in three ways: the relief of good people, coercion of the wicked, and peace for all. It is important to note that Alexander put ‘peace for all’ at the end of the list to amplify its importance.

</doc>
<doc id="2883" url="https://en.wikipedia.org/wiki?curid=2883" title="Active Server Pages">
Active Server Pages

Active Server Pages (ASP), later known as Classic ASP or ASP Classic, is Microsoft's first server-side script engine for dynamically generated web pages. ASP.NET, first released in January 2002, has superseded ASP.
History.
Initially released as an add-on to Internet Information Services (IIS) via the Windows NT 4.0 Option Pack (ca. 1996), it is included as a free component of Windows Server (since the initial release of Windows 2000 Server). There have been three versions of ASP, each introduced with different versions of IIS:
ASP 2.0 provides six built-in objects: Application, ASPError, Request, Response, Server, and Session. codice_1 object, for example, represents a session that maintains the state of variables from page to page. The Active Scripting engine's support of the Component Object Model (COM) enables ASP websites to access functionality in compiled libraries such as DLLs.
ASP 3.0 does not differ greatly from ASP 2.0 but it does offer some additional enhancements such as Server.Transfer method, Server.Execute method, and an enhanced ASPError object. ASP 3.0 also enables buffering by default and optimized the engine for better performance.
ASP remains supported until 14 January 2020 on Windows 7. The use of ASP pages will be supported on Windows 8 for a minimum of 10 years from the Windows 8 release date.
Architecture.
ASP use server-side scripting to generate contents that would be sent to the visitor's web browser. The ASP interpreter reads and executes all script code between <% and %> tags, the result of which is content generation. These scripts are written using VBScript, JScript and PerlScript. The codice_2 directive, the syntax or server configuration can be used to select the language. In the example below, Response.Write Now() is in an HTML page; it would be dynamically replaced by the current time of the server.
Web pages with the ".asp" filename extension use ASP, although some web sites disguise their choice of scripting language for security purposes by using the more common ".htm" or ".html" extensions. Pages with the ".aspx" extension use compiled ASP.NET; however, ASP.NET pages may still include some ASP scripting. The introduction of ASP.NET led to use of the term "Classic ASP" for the original technology.
ASP runs only on Windows. A number of products emulate some of the functionality of Classic ASP on non-Microsoft web servers. Apache::ASP for example ports Classic ASP to the Apache Web Server, but can only interpret PerlScript.
Sun Java System ASP (formerly ChiliSoft ASP) was a popular and reportedly complete emulator, but it has been discontinued.
The Request object.
Allows data to be read that was sent by the client browser: Form, Querystring, and HTTP Cookie. It also provides information on the server, the client browser, and retrieve HTTP Cookie stored on the visitor's machine. Can retrieve data from a form using both methods HTTP:
Request.Form reads data sent by POST.
Request.QueryString reads data sent by GET.
The Response object.
Can send information to the client, such as the writing of the text on a page or HTTP Cookie.
The Server object.
Allows connections to databases (ADO), filesystem, and use of components installed on the server.
The Application object.
Stores global variables.
The Session object.
Stores variables accessible only to a single visitor.
The Err object.
Allows for the management of errors.

</doc>
<doc id="2885" url="https://en.wikipedia.org/wiki?curid=2885" title="Amoxicillin">
Amoxicillin

Amoxicillin, also spelled amoxycillin and amox, is an antibiotic useful for the treatment of a number of bacterial infections. It is the first line treatment for middle ear infections. It may also be used for strep throat, pneumonia, skin infections, and urinary tract infections among others. It is taken by mouth.
Common side effects include nausea and rash. It may also increase the risk of yeast infections and, when used in combination with clavulanic acid, diarrhea. It should not be used in those who are allergic to penicillin. While usable in those with kidney problems, the dose may need to be decreased. Its use in pregnancy and breastfeeding does not appear to be harmful.
Amoxicillin first became available in 1972. It is on the World Health Organization's List of Essential Medicines, the most important medications needed in a basic health system. It is one of the most commonly prescribed antibiotics in children. Amoxicillin is available as a generic medication. It has a wholesale costs between 0.02 and 0.05 USD per pill. In the United States ten days of treatment costs about 16 USD.
Medical uses.
Amoxicillin is used in the treatment of a number of infections, including acute otitis media, streptococcal pharyngitis, pneumonia, skin infections, urinary tract infections, "Salmonella" infections, Lyme disease, and chlamydia infections.
Respiratory infections.
Amoxicillin and amoxicillin-clavulanate have been recommended by guidelines as the drug of choice for bacterial sinusitis, but most sinusitis is caused by viruses, for which amoxicillin and amoxicillin-clavulanate are ineffective, and the small benefit gained by Amoxicillin may be overridden by the adverse effects. 
Amoxicillin is recommended as the preferred first-line treatment for community-acquired pneumonia in adults by the National Institute for Health and Care Excellence, either alone (mild to moderate severity disease) or in combination with a macrolide. The World Health Organization recommends amoxicillin as first-line treatment for pneumonia that is not "severe".
Skin infections.
Amoxicillin is occasionally used for the treatment of skin infections, such as acne vulgaris. It is often an effective treatment for cases of acne vulgaris that have responded poorly to other antibiotics, such as doxycycline and minocycline.
Infections in infants in resource-limited settings.
Amoxicillin is recommended by the World Health Organization for the treatment of infants with signs and symptoms of pneumonia in resource-limited situations when the parents are unable or unwilling to accept hospitalization of the child. Amoxicillin in combination with gentamicin is recommended for the treatment of infants with signs of other severe infections when hospitalization is not an option.
Prevention of bacterial endocarditis.
It is also used to prevent bacterial endocarditis in high-risk people having dental work done, to prevent "Streptococcus pneumoniae" and other encapsulated bacterial infections in those without spleens, such as people with sickle-cell disease, and for both the prevention and the treatment of anthrax. The United Kingdom recommends against its use for infectious endocarditis prophylaxis. These recommendations do not appear to have changed the rates of infection for infectious endocarditis.
Combination treatment.
Amoxicillin is susceptible to degradation by β-lactamase-producing bacteria, which are resistant to a narrow spectrum of β-lactam antibiotics, such as penicillin. For this reason, it may be combined with clavulanic acid, a β-lactamase inhibitor. This drug combination is commonly called co-amoxiclav.
Spectrum of activity.
It is a moderate-spectrum, bacteriolytic, β-Lactam antibiotic in the aminopenicillin family used to treat susceptible Gram-positive and Gram-negative bacteria. It is usually the drug of choice within the class because it is better-absorbed, following oral administration, than other β-lactam antibiotics. 
In general, "Streptococcus, Bacillus subtilis, Enterococcus, Haemophilus, Helicobacter," and "Moraxella" are susceptible to amoxicillin, whereas "Citrobacter, Klebsiella" and "Pseudomonas aeruginosa" are resistant to it. Some "E. coli" and most clinical strains of "Staphylococcus aureus" have developed resistance to amoxicillin to varying degrees.
Adverse effects.
Side effects are similar to those for other β-lactam antibiotics, including nausea, vomiting, rashes, and antibiotic-associated colitis. Loose bowel movements (diarrhea) may also occur. Rarer side effects include mental changes, lightheadedness, insomnia, confusion, anxiety, sensitivity to lights and sounds, and unclear thinking. Immediate medical care is required upon the first signs of these side effects.
The onset of an allergic reaction to amoxicillin can be very sudden and intense; emergency medical attention must be sought as quickly as possible. The initial phase of such a reaction often starts with a change in mental state, skin rash with intense itching (often beginning in fingertips and around groin area and rapidly spreading), and sensations of fever, nausea, and vomiting. Any other symptoms that seem even remotely suspicious must be taken very seriously. However, more mild allergy symptoms, such as a rash, can occur at any time during treatment, even up to a week after treatment has ceased. For some people allergic to amoxicillin, the side effects can be fatal due to anaphylaxis.
Use of the amoxicillin/clavulanic acid combination for more than one week has caused mild hepatitis in some patients. Young children having ingested acute overdoses of amoxicillin manifested lethargy, vomiting, and renal dysfunction.
Nonallergic rash.
Between 3 and 10% of children taking amoxicillin (or ampicillin) show a late-developing (>72 hours after beginning medication and having never taken penicillin-like medication previously) rash, which is sometimes referred to as the "amoxicillin rash". The rash can also occur in adults.
The rash is described as maculopapular or morbilliform (measles-like; therefore, in medical literature, it is called "amoxicillin-induced morbilliform rash".) It starts on the trunk and can spread from there. This rash is unlikely to be a true allergic reaction, and is not a contraindication for future amoxicillin usage, nor should the current regimen necessarily be stopped. However, this common amoxicillin rash and a dangerous allergic reaction cannot easily be distinguished by inexperienced persons, so a healthcare professional is often required to distinguish between the two.
A nonallergic amoxicillin rash may also be an indicator of infectious mononucleosis. Some studies indicate about 80-90% of patients with acute Epstein Barr virus infection treated with amoxicillin or ampicillin develop such a rash.
Interaction.
Amoxicillin may interact with these drugs:
Mechanism of actions.
This drug acts by inhibiting the synthesis of bacterial cell walls. It inhibits cross-linkage between the linear peptidoglycan polymer chains that make up a major component of the cell wall of Gram-positive and a minor component of Gram-negative bacteria. Gram negative bacteria are not generally susceptible to Beta-lactam antibiotics.
It has two ionizable groups in the physiological range (the amino group in alpha-position to the amide carbonyl group and the carboxyl group).
History.
Amoxicillin was one of several semisynthetic derivatives of 6-aminopenicillanic acid (6-APA) developed at Beecham, England in the 1960s. It became available in 1972, and was the second aminopenicillin to reach the market (after ampicillin in 1961). Co-amoxiclav became available in 1981.
Society and culture.
Modes of delivery.
Pharmaceutical manufacturers make amoxicillin in trihydrate form, for oral use available as capsules, chewable and dispersible tablets, syrup and pediatric suspension for oral use, and as the sodium salt for intravenous administration. Amoxicillin is most commonly taken orally. The liquid forms are helpful where the patient might find it difficult to take tablets or capsules.
Intravenous form is not sold in USA
Research with mice indicated successful delivery using intraperitoneally injected amoxicillin-bearing microparticles.
Names.
"Amoxicillin" is the INN, BAN, and USAN, while "amoxycillin" is the AAN.
Amoxicillin is one of the semisynthetic penicillins discovered by Beecham scientists. The patent for amoxicillin has expired, thus amoxicillin and co-amoxiclav preparations are marketed under many trade names and/or have several synonyms across the world, such as:
Names without individual reference are referenced on the drugs.com website.

</doc>
<doc id="2889" url="https://en.wikipedia.org/wiki?curid=2889" title="Amorphous solid">
Amorphous solid

In condensed matter physics and materials science, an amorphous (from the Greek "a", without, "morphé", shape, form) or non-crystalline solid is a solid that lacks the long-range order characteristic of a crystal. In some older books, the term has been used synonymously with glass. Nowadays, "amorphous solid" is considered to be the overarching concept, and glass the more special case: A glass is an amorphous solid that exhibits a glass transition. Polymers are often amorphous. Other types of amorphous solids include gels, thin films, and nanostructured materials such as glass.
Amorphous materials have an internal structure made of interconnected structural blocks. Whether a material is liquid or solid depends primarily on the connectivity between its elementary building blocks so that solids are characterized by a high degree of connectivity whereas structural blocks in fluids have lower connectivity (see figure on amorphous material states).
Nano-structured materials.
Even amorphous materials have some shortrange order at the atomic length scale due to the nature of chemical bonding (see structure of liquids and glasses for more information on non-crystalline material structure). Furthermore, in very small crystals a large fraction of the atoms are
the crystal; relaxation of the surface and interfacial effects distort the atomic positions, decreasing the structural order. Even the most advanced structural characterization techniques, such as x-ray diffraction and transmission electron microscopy, have difficulty in distinguishing between amorphous and crystalline structures on these length scales.
Amorphous thin films.
Amorphous phases are important constituents of thin films, which are solid layers of a few nm to some tens of µm thickness deposited upon a substrate. So-called structure zone models were developed to describe the micro structure and ceramics of thin films as a function of the homologous temperature "T" that is the ratio of deposition temperature over melting temperature. According to these models, a necessary (but not sufficient) condition for the occurrence of amorphous phases is that "T" has to be smaller than 0.3, that is the deposition temperature must be below 30% of the melting temperature. For higher values, the surface diffusion of deposited atomic species would allow for the formation of crystallites with long range atomic order.
Regarding their applications, amorphous metallic layers played an important role in the discussion of a suspected superconductivity in amorphous metals. Today, optical coatings made from TiO, SiO, TaO etc. and combinations of them in most cases consist of amorphous phases of these compounds. Much research is carried out into thin amorphous films as a gas separating membrane layer. The technologically most important thin amorphous film is probably represented by few nm thin SiO layers serving as isolator above the conducting channel of a metal-oxide semiconductor field-effect transistor (MOSFET). Also, hydrogenated amorphous silicon, a-Si:H in short, is of technical significance for thin film solar cells. In case of a-Si:H the missing long-range order between silicon atoms is partly induced by the presence by hydrogen in the percent range.
The occurrence of amorphous phases turned out as a phenomenon of particular interest for studying thin film growth. Remarkably, the growth of polycrystalline films is often used and preceded by an initial amorphous layer, the thickness of which may amount to only a few nm. The most investigated example is represented by thin multicrystalline silicon films, where such as the unoriented molecule. An initial amorphous layer was observed in many studies. Wedge-shaped polycrystals were identified by transmission electron microscopy to grow out of the amorphous phase only after the latter has exceeded a certain thickness, the precise value of which depends on deposition temperature, background pressure and various other process parameters. The phenomenon has been interpreted in the framework of Ostwald's rule of stages that predicts the formation of phases to proceed with increasing condensation time towards increasing stability. Experimental studies of the phenomenon require a clearly defined state of the substrate surface and its contaminant density etc., upon which the thin film is deposited.

</doc>
<doc id="2890" url="https://en.wikipedia.org/wiki?curid=2890" title="A Wizard of Earthsea">
A Wizard of Earthsea

A Wizard of Earthsea is a young-adult fantasy novel written by the American author Ursula K. Le Guin, first published by the small press Parnassus in 1968. Set in the fictional archipelago of Earthsea, the story follows the education of a young mage named Ged who joins the school of wizardry. "A Wizard of Earthsea" is widely regarded as a classic of fantasy and young-adult literature and was one of the final recipients of the Lewis Carroll Shelf Award, an award that recognized outstanding children's literature. Le Guin would later write five subsequent books that, together with "A Wizard of Earthsea", are referred to as the Earthsea Cycle: "The Tombs of Atuan" (1971), "The Farthest Shore" (1972), "Tehanu" (1990), "The Other Wind" (2001), and "Tales from Earthsea" (2001).
Margaret Atwood has called "A Wizard of Earthsea" one of the "wellsprings" of fantasy literature, illustrating Le Guin's influence within the genre. "A Wizard of Earthsea" has been compared to major fantasy works such as J.R.R. Tolkien's "The Lord of the Rings" and L. Frank Baum's "The Wonderful Wizard of Oz". Modern writers have credited "A Wizard of Earthsea" for introducing the idea of a "wizard school," which would later be made famous by the "Harry Potter" series of books.
Background.
Early concepts for the Earthsea setting were developed in two short stories, "The Rule of Names" (1964) and "The Word of Unbinding" (1964), both published in "Fantastic". These stories introduced important concepts, such as Le Guin's treatment of magic, but do not include any characters that would appear in "A Wizard of Earthsea." In 1967, Herman Schein (the publisher of Parnassus Press and the husband of Ruth Robbins, the illustrator of the book) asked Le Guin to try writing a book "for older kids," giving her complete freedom for the subject and the approach. Drawing from her short stories, Le Guin began work on "A Wizard of Earthsea". Le Guin has said that the book was in part a response to the image of wizards as ancient and wise, and to her wondering where they come from.
Plot summary.
Ged, originally known as Duny ( the name his mother gave him before she died ) and nicknamed Sparrowhawk, lives in a mountain village on the island of Gont. His aunt, the village witch, begins training him in magic. Sparrowhawk uses his magic to save his village from Kargish invaders by summoning fog to conceal his village and distract the attackers. Sparrowhawk is discovered by Ogion the Silent, a powerful mage who takes Sparrowhawk as his apprentice. On Sparrowhawk's thirteenth birthday, as a rite of passage, he is given his "true name"—Ged. Ogion attempts to teach Ged about the "Balance," the concept that magic can upset the natural order of the world if used improperly. In an attempt to impress a girl who doubts his abilities, Ged searches Ogion's spell-books and inadvertently summons a strange shadow, which is banished by Ogion. Ogion eventually invites Ged to attend a school for wizards on the island of Roke.
At the school, Ged’s skill inspires admiration and envy from other students, and he befriends another student named Vetch. Ged also shows his affinity with nature when, as he is returning alone from an isolated tower, a small wild animal called an otak becomes his companion. However, Ged studies magic beyond his level and ignores warnings about respecting the Balance. Moreover, he begins a rivalry with an older student named Jasper. This rivalry culminates in a duel where Ged casts a powerful spell which goes awry. A rip in the fabric of the world opens to the realm of the dead, and a shadow creature passes through, attacking Ged and scarring his face. The Archmage Nemmerle drives off the shadow and restores Balance, though it costs him all of his power and he dies soon after.
Ged spends months healing before resuming his studies. The new Archmage, Gensher, refuses Ged’s oath of fealty because he suspects he may be evil. Warning Ged that only Roke’s magical barriers protect him from the shadow, Gensher describes the creature as an ancient and nameless evil that wishes to possess Ged’s body. Years later, Ged graduates from the Roke school at age 18 and takes a job protecting poor villagers of the Ninety Isles from a feared attack by dragons. While traveling, Ged learns that he is being pursued by the shadow creature he summoned on Roke. Sailing to Pendor, Ged kills five young dragons and exacts a binding promise from an adult dragon that he and his brood will never threaten the archipelago.
Chased by the shadow, Ged tries to return to Roke but is blocked by the island’s protective magic. Taking the advice to seek help at the Court of the Terrenon in Osskil, Ged flees north. On Osskil, he realises that his guide has been possessed by the shadow. Fleeing in terror, Ged stumbles through a castle gate as the creature destroys his staff and kills his pet otak. Ged passes out and wakes to find himself in the castle of Benderesk, who is the lord of the Terranon, a stone locked in the castle’s depths. Benderesk’s wife, Lady Serret, shows Ged the stone and tempts him to speak to it, claiming it can give him limitless knowledge and power. Believing the stone harbors an ancient and evil spirit, Ged refuses. When Serret tries to tempt Ged again, he sees Benderesk eavesdropping and realizes they wish to enslave him to use his power. Ged ultimately escapes Osskil by transforming into a falcon and flying away.
Ged returns to Gont and meets Ogion. After hearing of Ged’s experiences, Ogion advises him to confront the shadow creature. Ged pursues it across the sea until it lures him into a fog where his boat is wrecked on a reef. While marooned on an islet, Ged recovers with the help of an elderly couple who were apparently abandoned on the island as child heirs of a defeated Kargish royal family. As a gift the woman gives Ged part of a broken bracelet, which he later learns is half of the lost Ring of Erreth-Akbe.
Ged escapes the island and continues his pursuit, eventually meeting and traveling with his friend Vetch. They ultimately reach a dark shore and Ged confronts the shadow. They embrace and merge, with Ged and Vetch realizing that the shadow was part of Ged's spirit, and that Ged could only reunite with it by understanding and accepting it as part of himself.
Adaptations.
A condensed, illustrated version of the first chapter was printed by World Books in the third volume of Childcraft in 1989.
BBC Radio produced a radioplay version in 1996 narrated by Judi Dench.
An original mini-series titled Legend of Earthsea was broadcast in 2005 on the Sci Fi Channel. It is based very loosely on "A Wizard of Earthsea" and "The Tombs of Atuan". Le Guin has stated that she was not pleased with the result, which included "whitewashing Earthsea."
Studio Ghibli released an adaptation of the series in 2006 titled Tales from Earthsea. The film very loosely combines elements of the first, third, and fourth books into a new story. Le Guin has commented with displeasure on the results.
BBC Radio produced a six part series adapting the Earthsea novels in 2015, broadcast on Radio 4 Extra.

</doc>
<doc id="2893" url="https://en.wikipedia.org/wiki?curid=2893" title="Alex Lifeson">
Alex Lifeson

Aleksandar Živojinović, (born August 27, 1953), better known by his stage name Alex Lifeson, is a Canadian musician, best known as the guitarist of the Canadian rock band Rush. In 1968, Lifeson co-founded the band that would become Rush, with drummer John Rutsey and bassist and singer Jeff Jones. Jones was replaced by Geddy Lee a month later, and Rutsey was replaced by Neil Peart in 1974; the band's lineup has remained the same ever since.
With Rush, Lifeson plays electric and acoustic guitars, as well as other stringed instruments such as mandola, mandolin, and bouzouki. He also performs backing vocals in live performances, and occasionally plays keyboards and bass pedal synthesizers. Like the other members of Rush, Lifeson performs real-time on-stage triggering of sampled instruments, concurrently with his guitar playing.
The bulk of Lifeson's work in music has been with Rush, although Lifeson has contributed to a body of work outside of the band as well. Aside from music, Lifeson is part-owner of The Orbit Room, a bar and restaurant located in Toronto, a painter, and a licensed aircraft pilot.
Along with his bandmates Geddy Lee and Neil Peart, Lifeson was made an Officer of the Order of Canada on May 9, 1996. The trio was the first rock band to be so honoured, as a group.
Lifeson was ranked 98th on "Rolling Stone"'s list of the 100 greatest guitarists of all time, and third (after Eddie Van Halen and Brian May) in a "Guitar World" readers poll also listing the 100 greatest guitarists.
Biography.
Early life.
Lifeson was born as Aleksandar Živojinović in Fernie, British Columbia, to Serbian immigrants, Nenad and Melanija Zivojinovich (from Serbian: Живојиновић, "Živojinović"), and raised in Toronto, Ontario. His stage name of "Lifeson" is a semi-literal translation of the name "Zivojinovich", which means "son of life" in Serbian. His first exposure to formal music training came in the form of the viola, which he renounced for the guitar at the age of 12. His first guitar was a Christmas gift from his father, a six-string Kent classical acoustic which was later upgraded to an electric Japanese model. During his adolescent years, he was influenced primarily by Jimi Hendrix, Pete Townshend, Jeff Beck, Eric Clapton, Jimmy Page, Steve Hackett and Allan Holdsworth; he explained in 2011 that "Clapton's solos seemed a little easier and more approachable. I remember sitting at my record player and moving the needle back and forth to get the solo in 'Spoonful.' But there was nothing I could do with Hendrix." In 1963 Lifeson met future Rush drummer John Rutsey in school. Both interested in music, they decided to form a band. Lifeson was primarily a self-taught guitarist with the only formal instruction coming from a high school friend in 1971 who taught classical guitar lessons. This training lasted for roughly a year and a half.
Lifeson recalls what inspired him to play guitar in a 2008 interview:
Lifeson's first girlfriend, Charlene, gave birth to their eldest son, Justin, in October 1970, and they married in 1975. Their second son, Adrian, was born two years later. Adrian is also involved in music, and performed on two tracks from Lifeson's 1996 solo project, "Victor".
Rush.
Lifeson's neighbour John Rutsey began experimenting on a rented drum kit. In 1963, Lifeson and Rutsey formed The Projection, which eventually became Rush in August 1968 following the recruitment of original bassist and vocalist Jeff Jones. Geddy Lee, a high school friend of Lifeson's, assumed this role soon after.
Instrumentally, Lifeson is renowned for his signature riffing, electronic effects and processing, unorthodox chord structures, and the copious arsenal of equipment he has used over the years.
Rush was on hiatus for several years starting in 1997 owing to , and Lifeson had not picked up a guitar for at least a year following those events. However, after some work in his home studio and on various side projects, Lifeson returned to the studio with Rush to begin work on 2002's "Vapor Trails". "Vapor Trails" is the first Rush album since the 1970s to lack keyboards—as such, Lifeson used over 50 different guitars in what Shawn Hammond of "Guitar Player" called "his most rabid and experimental playing ever." Geddy Lee was amenable to leaving keyboards off the album due in part to Lifeson's ongoing concern about their use. Lifeson's approach to the guitar tracks for the album eschewed traditional guitar riffs and solos in favour of "tonality and harmonic quality."
During live performances, he is still responsible for cuing various guitar effects, the use of bass pedal synthesizers, and backing vocals.
"Victor".
While the bulk of Lifeson's work in music has been with Rush, Lifeson's first major outside work was his solo project, "Victor", released in 1996. "Victor" was attributed as a self-titled work (i.e. "Victor" is attributed as the "artist" as well as the "album title"). This was done deliberately as an alternative to issuing the album explicitly under Lifeson's name. The title track is from the W.H. Auden poem, also entitled "Victor". Both son Adrian and wife Charlene also contributed to the album. A follow-up album, possibly including vocals by Sarah McLachlan, was rumored in the late 1990s, but was apparently shelved due to Atlantic Records' lack of support for the first album.
Side projects.
Lifeson has also contributed to a body of work outside of his involvement with the band in the form of instrumental contributions to other musical outfits. He made a guest appearance on the 1985 Platinum Blonde album "Alien Shores" performing guitar solos on the songs "Crying Over You" and "Holy Water". Later, in 1990, he appeared on Lawrence Gowan's album, "Lost Brotherhood" to play guitar. In 1995, he guested on two tracks on Tom Cochrane's "Ragged Ass Road" album and then in 1996 on I Mother Earth's "Like a Girl" from the "Scenery and Fish" album. In 1997 he appeared on the "Merry Axemas: A Guitar Christmas" album. Lifeson played "the Little Drummer Boy" which was released as track 9 on the album. In 2006, Lifeson founded The Big Dirty Band, which he created for the purpose of providing original soundtrack material for "". Lifeson jammed regularly with The Dexters (The Orbit Room house band from 1994 to 2004). Lifeson made a guest appearance on the 2007 album "Fear of a Blank Planet" by UK progressive rock band, Porcupine Tree, contributing a solo during the song "Anesthetize". He also appeared on the 2008 album "Fly Paper" by Detroit progressive rockers Tiles. He plays on the track "Sacred and Mundane". Outside of band related endeavours, Lifeson composed the theme for the first season of the science-fiction TV series "Andromeda". He also produced 3 songs from the album "Away from the Sun" by 3 Doors Down.
Television and film appearances.
Lifeson made his film debut as himself under his birth name in the 1972 Canadian documentary film "Come on Children".
In a 2003 episode of the Canadian mockumentary "Trailer Park Boys", titled "Closer to the Heart", Lifeson plays a partly fictional version of himself. In the story, he is kidnapped by Ricky and held as punishment for his inability (or refusal) to provide the main characters with free tickets to a Rush concert. In the end of the episode, Alex reconciles with the characters, and performs a duet of "Closer to the Heart" with Bubbles at the trailer park. In 2006, Lifeson appeared in ' as a traffic cop in the opening scene and in 2009 he appeared in their follow up movie, ', as an undercover vice cop in drag.
In 2008, Lifeson and the rest of Rush played "Tom Sawyer" at the end of an episode of "The Colbert Report". According to Colbert, this was their first appearance on American television as a band in 33 years.
In 2009, he and the rest of the band appeared as themselves in the comedy "I Love You, Man".
Alex Lifeson appears as the border guard in the 2009 movie "Suck".
The role of Dr. Funtime in "The Drunk and On Drugs Happy Funtime Hour" was originally written with Alex Lifeson in mind, but due to scheduling conflicts the role was given to Maury Chaykin instead.
The Naples incident.
On New Year's Eve 2003, Lifeson, his son, and his daughter-in-law were arrested at the Ritz-Carlton hotel in Naples, Florida. Lifeson, after intervening in an altercation between his son and police, was accused of assaulting a sheriff's deputy in what was described as a drunken brawl. In addition to suffering a broken nose at the hands of the officers, Lifeson was tased six times. His son was also tased repeatedly.
On April 21, 2005, Lifeson and his son agreed to a plea deal with the local prosecutor for the State's Attorney office to avoid jail time by pleading no contest to a first-degree misdemeanor charge of resisting arrest without violence. As part of the plea agreement Lifeson and his son were each sentenced to 12 months of probation with the adjudication of that probation suspended. Lifeson acknowledged his subsequent legal action against both the Ritz-Carlton and the Collier County Sheriff's Office for "their incredibly discourteous, arrogant and aggressive behaviour of which I had never experienced in thirty years of travel." Although both actions were initially dismissed in April 2007, legal claims against the Ritz-Carlton were reinstated upon appeal, and ultimately settled out of court in August 2008, with Lifeson and his son agreeing to a confidential settlement from Ritz-Carlton.
In his journal-based book "Roadshow", Peart relates the band's perspective on the events of that New Year's Eve.
Guitar equipment.
Early Rush (1970s).
In Rush's early career, Lifeson used a Gibson ES-335 for the first tour, and in 1976 bought a 1974 Gibson Les Paul; he used those two guitars until the late 1970s. He had a Fender Stratocaster with a Bill Lawrence humbucker and Floyd Rose vibrato bridge as backup "and for a different sound." For the "A Farewell to Kings" sessions, Lifeson began using a Gibson EDS-1275 for songs like "Xanadu" and his main guitar became a white Gibson ES-355. During this period Lifeson used Hiwatt amplifiers. He played a twelve-string Gibson B-45 on songs like "Closer to the Heart."
1980s and 1990s.
From 1980 to 1986, Lifeson used four identically modified Stratocasters, all of them equipped with the Floyd Rose bridge. As a joke, he called these Hentor Sportscasters – a made-up name inspired by Peter Henderson's name, who was the producer of "Grace Under Pressure". He also played a Gibson Howard Roberts Fusion. By 1987, Lifeson switched to Signature guitars (Canadian-made) which, while "awful to play—very uncomfortable--...had a particular sound I liked." Lifeson primarily used PRS guitars in the later-half of the 1990 Presto tour, and again during the recording of "Roll The Bones" in 1990/1991. He would continue to play PRS for the next sixteen years through the recording and touring of "Counterparts", "Test for Echo" and "Vapor Trails" as well as the R30 tour.
2000s onward: Return to Gibson guitars.
In 2011, Lifeson said that for the past few years he "...used Gibson almost exclusively. There's nothing like having a low-slung Les Paul over my shoulder." 
Gibson "Alex Lifeson Axcess".
In early 2011, Gibson introduced the "Alex Lifeson Axcess", a guitar specially designed for him. These are custom made Les Pauls with Floyd Rose tremolo systems and piezoacoustic pickups. He used these two custom Les Pauls on the Time Machine Tour. These guitars are also available through Gibson, in a viceroy Brown or Crimson color. Lifeson used these two guitars heavily on the tour. 
For the 2012-2013 Clockwork Angels tour, Gibson built an Alex Lifeson Axcess model in black which became Lifeson's primary guitar for much of the show. For all acoustic work, he played one of his Axcess guitars using the piezo pick-ups; no acoustic guitars were used at all in the Clockwork Angels show.
Paul Reed Smith acoustic signature guitar.
For the 2015 R40 Tour, Lifeson used his signature acoustic guitar model by Paul Reed Smith. The guitar is currently available for private stock order.
Gibson R40 Signature Les Paul Axcess.
Gibson introduced an Alex Lifeson R40 Les Paul Axcess signature guitar in June 2015. This is a limited edition with 50 guitars signed and played by Lifeson, and another 250 available without the signature.
Amplification.
In 2005, Hughes & Kettner introduced an Alex Lifeson signature series amplifier; Lifeson donates his royalties from the sale of these signature models to UNICEF.
In 2012, Lifeson abandoned his signature Triamps in favor for custom-built Lerxst Omega Silver Jubilee clones, handmade by Mojotone in Burgaw, NC and Mesa/Boogie Mark V heads. He still uses the Hughes & Kettner Coreblades.
Effects.
For effects, Lifeson is known to use chorus, phase shifting, and flanging. Throughout his career, he has used well-known pedals such as the Electro-Harmonix Electric Mistress flanger, the BOSS CE-1 chorus, the Dunlop crybaby wah, among others.
Lifeson and Lifeson's guitar technician Scott Appleton have discussed in interviews Lifeson's use of Fractal Audio's Axe-FX, Apple Inc.'s MainStage, and Native Instruments' Guitar Rig.
Other instruments played.
Stringed instruments.
In addition to acoustic and electric guitars, Lifeson has also played mandola, mandolin and bouzouki on recent Rush studio albums, including "Test for Echo", "Vapor Trails" and "Snakes & Arrows". 
Electronic instruments.
During live Rush performances, Lifeson uses MIDI controllers that enables him to use his free hands and feet to trigger sounds from digital samplers and synthesizers, without taking his hands off his guitar. (Prior to this, Lifeson used Moog Taurus Bass Pedals before they were replaced by Korg MIDI pedals in the 1980s.) Lifeson and his bandmates share a desire to accurately depict songs from their albums when playing live performances. Toward this goal, beginning in the late 1980s the band equipped their live performances with a capacious rack of samplers. The band members use these samplers in real-time to recreate the sounds of non-traditional instruments, accompaniments, vocal harmonies, and other sound "events" that are familiarly heard on the studio versions of the songs. In live performances, the band members share duties throughout most songs, with each member triggering certain sounds with his available limbs, while playing his primary instrument(s).

</doc>
<doc id="2894" url="https://en.wikipedia.org/wiki?curid=2894" title="AZ">
AZ

AZ (or similar) may refer to:

</doc>
<doc id="2899" url="https://en.wikipedia.org/wiki?curid=2899" title="ArgoUML">
ArgoUML

ArgoUML is an UML diagramming application written in Java and released under the open source Eclipse Public License. By virtue of being a Java application, it is available on any platform supported by Java.
History.
ArgoUML was originally developed at UC Irvine by Jason E. Robbins, leading to his Ph.D. It is now an open source project hosted by Tigris.org. The ArgoUML project now includes more than 19,000 registered users and over 150 developers.
In 2003, ArgoUML won the Software Development Magazine's annual Readers' Choice Award in the “Design and Analysis Tools” category.
ArgoUML development has suffered from lack of manpower. For example, "Undo" has been a perpetually requested feature since 2003 but has not been implemented yet.
Features.
According to the official feature list, ArgoUML is capable of the following: 

</doc>
<doc id="2900" url="https://en.wikipedia.org/wiki?curid=2900" title="File archiver">
File archiver

A file archiver is a computer program that combines a number of files together into one archive file, or a series of archive files, for easier transportation or storage. File archivers may employ lossless data compression in their archive formats to reduce the size of the archive.
Basic archivers just take a list of files and concatenate their contents sequentially into archives. The archive files need to store metadata, at least the names and lengths of the original files, if proper reconstruction is possible. More advanced archivers store additional metadata, such as the original timestamps, file attributes or access control lists.
The process of making an archive file is called "archiving" or "packing". Reconstructing the original files from the archive is termed "unarchiving", "unpacking" or "extracting".
History.
An early archiver was the Multics command "archive", descended from the CTSS command of the same name, which was a basic archiver and performed no compression. Multics also had a "tape_archiver" command, abbreviated "ta", which was perhaps the forerunner of unix' "tar".
Unix archivers.
The Unix tools "ar", "tar", "cpio" act as archivers but not compressors. Users of the Unix tools use additional compression tools, such as gzip, bzip2, or xz, to compress the archive file after packing or remove compression before unpacking the archive file. The filename extensions are successively added at each step of this process. For example, archiving a collection of files with "tar" and then compressing the resulting archive file with "gzip" results a file with codice_1 extension.
This approach has two goals:
This approach, however, has disadvantages too:
Windows archivers.
The built-in archiver of Microsoft Windows as well as third-party archiving software, such as WinRAR and 7-zip, often use a graphical user interface. They also offer an optional command-line interface, while Windows itself does not. Windows archivers perform both archiving and compression. Solid compression may or may not be offered, depending on the product: Windows itself does not support it; WinRAR and 7-zip offer it as an option that can be turned on or off.

</doc>
<doc id="2905" url="https://en.wikipedia.org/wiki?curid=2905" title="Artemis">
Artemis

Artemis (; , "Ártemis", ) was one of the most widely venerated of the Ancient Greek deities. Her Roman equivalent is Diana. Some scholars believe that the name, and indeed the goddess herself, was originally pre-Greek. Homer refers to her as "Artemis Agrotera, Potnia Theron": "Artemis of the wildland, Mistress of Animals". The Arcadians believed she was the daughter of Demeter.
In the classical period of Greek mythology, Artemis was often described as the daughter of Zeus and Leto, and the twin sister of Apollo. She was the Hellenic goddess of the hunt, wild animals, wilderness, childbirth, virginity and protector of young girls, bringing and relieving disease in women; she often was depicted as a huntress carrying a bow and arrows. The deer and the cypress were sacred to her. In later Hellenistic times, she even assumed the ancient role of Eileithyia in aiding childbirth.
Etymology.
The name Artemis ("noun", "feminine") is of unknown or uncertain origin and etymology although various ones have been proposed.
For example, according to Jablonski, the name is also Phrygian and could be "compared with the royal appellation "Artemas" of Xenophon. According to Charles Anthon the primitive root of the name is probably of Persian origin from *"arta", *"art", *"arte", all meaning "great, excellent, holy," thus Artemis "becomes identical with the great mother of Nature, even as she was worshipped at Ephesus". Anton Goebel "suggests the root στρατ or ῥατ, "to shake," and makes Artemis mean the thrower of the dart or the shooter". Babiniotis, while accepting that the etymology is unknown, states that the name is already attested in Mycenean Greek and is possibly of pre-Hellenic origin.
The name could also be possibly related to Greek "árktos" "bear" (from PIE *"h₂ŕ̥tḱos"), supported by the bear cult that the goddess had in Attica (Brauronia) and the Neolithic remains at the Arkoudiotissa Cave, as well as the story about Callisto, which was originally about Artemis (Arcadian epithet "kallisto"); this cult was a survival of very old totemic and shamanistic rituals and formed part of a larger bear cult found further afield in other Indo-European cultures (e.g., Gaulish Artio). It is believed that a precursor of Artemis was worshiped in Minoan Crete as the goddess of mountains and hunting, Britomartis. While connection with Anatolian names has been suggested, the earliest attested forms of the name "Artemis" are the Mycenaean Greek , "a-te-mi-to" /Artemitos/ and , "a-ti-mi-te" /Artimitei/, written in Linear B at Pylos. R. S. P. Beekes suggested that the "e"/"i" interchange points to a Pre-Greek origin. Artemis was venerated in Lydia as "Artimus".
Ancient Greek writers, by way of folk etymology, and some modern scholars, have linked Artemis (Doric "Artamis") to ἄρταμος, "artamos", i.e. "butcher" or, like Plato did in "Cratylus", to , "artemḗs", i.e. "safe", "unharmed", "uninjured", "pure", "the stainless maiden".
Artemis in mythology.
Birth.
Various conflicting accounts are given in Classical Greek mythology of the birth of Artemis and her twin brother, Apollo. All accounts agree, however, that she was the daughter of Zeus and Leto and that she was the twin sister of Apollo.
An account by Callimachus has it that Hera forbade Leto to give birth on either terra firma (the mainland) or on an island. Hera was angry with Zeus, her husband, because he had impregnated Leto. But the island of Delos (or Ortygia in the Homeric Hymn to Artemis) disobeyed Hera, and Leto gave birth there.
In ancient Cretan history Leto was worshipped at Phaistos and in Cretan mythology Leto gave birth to Apollo and Artemis at the islands known today as the Paximadia.
A "scholium" of Servius on "Aeneid" iii. 72 accounts for the island's archaic name Ortygia by asserting that Zeus transformed Leto into a quail ("ortux") in order to prevent Hera from finding out his infidelity, and Kenneth McLeish suggested further that in quail form Leto would have given birth with as few birth-pains as a mother quail suffers when it lays an egg.
The myths also differ as to whether Artemis was born first, or Apollo. Most stories depict Artemis as born first, becoming her mother's mid-wife upon the birth of her brother Apollo.
Childhood.
The childhood of Artemis is not fully related in any surviving myth. The "Iliad" reduced the figure of the dread goddess to that of a girl, who, having been thrashed by Hera, climbs weeping into the lap of Zeus. A poem of Callimachus to the goddess "who amuses herself on mountains with archery" imagines some charming vignettes: according to Callimachus, at the age of three years, Artemis, while sitting on the knee of her father, Zeus, asked him to grant her six wishes: to remain always a virgin; to have many names to set her apart from her brother Apollo; to be the Phaesporia or Light Bringer; to have a bow and arrow and a knee-length tunic so that she could hunt; to have sixty "daughters of Okeanos", all nine years of age, to be her choir; and for twenty Amnisides Nymphs as handmaidens to watch her dogs and bow while she rested. She wished for no city dedicated to her, but to rule the mountains, and for the ability to help women in the pains of childbirth.
Artemis believed that she had been chosen by the Fates to be a midwife, particularly since she had assisted her mother in the delivery of her twin brother, Apollo. All of her companions remained virgins, and Artemis closely guarded her own chastity. Her symbols included the golden bow and arrow, the hunting dog, the stag, and the moon. Callimachus tells how Artemis spent her girlhood seeking out the things that she would need to be a huntress, how she obtained her bow and arrows from the isle of Lipara, where Hephaestus and the Cyclops worked.
Okeanus' daughters were filled with fear, but the young Artemis bravely approached and asked for bow and arrows. Callimachus then tells how Artemis visited Pan, the god of the forest, who gave her seven bitches and six dogs. She then captured six golden-horned deer to pull her chariot. Artemis practiced with her bow first by shooting at trees and then at wild beasts.
Intimacy.
As a virgin, Artemis had interested many gods and men, but only her hunting companion, Orion, won her heart. Orion was accidentally killed either by Artemis or by Gaia.
Alpheus, a river god, was in love with Artemis, but he realizes that he can do nothing to win her heart. So he decides to capture her. Artemis, who is with her companions at Letrenoi, goes to Alpheus, but, suspicious of his motives, she covers her face with mud so that the river god does not recognize her. In another story, Alphaeus tries to rape Artemis' attendant Arethusa. Artemis pities Arethusa and saves her by transforming Arethusa into a spring in Artemis' temple, Artemis Alphaea in Letrini, where the goddess and her attendant drink.
Bouphagos, the son of the Titan Iapetos, sees Artemis and thinks about raping her. Reading his sinful thoughts, Artemis strikes him at Mount Pholoe.
Sipriotes is a boy, who, either because he accidentally sees Artemis bathing or because he attempts to rape her, is turned into a girl by the goddess.
Actaeon.
Multiple versions of the Actaeon myth survive, though many are fragmentary. The details vary but at the core they involve a great hunter, Actaeon who Artemis turns into a stag for a transgression and who is then killed by hunting dogs. Usually the dogs are his own, who no longer recognize their master. Sometimes they are Artemis' hounds.
According to the standard modern text on the work, Lamar Ronald Lacey's "The Myth of Aktaion: Literary and Iconographic Studies", the most likely original version of the myth is that Actaeon was the hunting companion of the goddess who, seeing her naked in her sacred spring, attempts to force himself on her. For this hubris he is turned into a stag and devoured by his own hounds. However, in some surviving versions Actaeon is a stranger who happens upon her. Different tellings also diverge in the hunter's transgression, which is sometimes merely seeing the virgin goddess naked, sometimes boasting he is a better hunter than she, or even merely being a rival of Zeus for the affections of Semele.
Adonis.
In some versions of the story of Adonis, who was a late addition to Greek mythology during the Hellenistic period, Artemis sent a wild boar to kill Adonis as punishment for his hubristic boast that he was a better hunter than she.
In other versions, Artemis killed Adonis for revenge. In later myths, Adonis had been related as a favorite of Aphrodite, and Aphrodite was responsible for the death of Hippolytus, who had been a favorite of Artemis. Therefore, Artemis killed Adonis to avenge Hippolytus’s death.
In yet another version, Adonis was not killed by Artemis, but by Ares, as punishment for being with Aphrodite.
Orion.
Orion was Artemis' hunting companion. In some versions, he is killed by Artemis, while in others he is killed by a scorpion sent by Gaia. In some versions, Orion tries to seduce Opis, one of Artemis' followers, and she kills him. In a version by Aratus, Orion takes hold of Artemis' robe and she kills him in self-defense.
In yet another version, Apollo sends the scorpion. According to Hyginus Artemis once loved Orion (in spite of the late source, this version appears to be a rare remnant of her as the pre-Olympian goddess, who took consorts, as Eos did), but was tricked into killing him by her brother Apollo, who was "protective" of his sister's maidenhood.
The Aloadae.
These twin sons of Iphidemia and Poseidon, Otos and Ephialtes, grew enormously at a young age. They were aggressive, great hunters, and could not be killed unless they killed each other. The growth of the Aloadae never stopped, and they boasted that as soon as they could reach heaven, they would kidnap Artemis and Hera and take them as wives. The gods were afraid of them, except for Artemis who captured a fine deer (or in another version of the story, she changed herself into a doe) and jumped out between them. The Aloadae threw their spears and so mistakenly killed each other.
Callisto.
Callisto was the daughter of Lycaon, King of Arcadia and also was one of Artemis's hunting attendants. As a companion of Artemis, she took a vow of chastity. Zeus appeared to her disguised as Artemis, or in some stories Apollo, gained her confidence, then took advantage of her (or raped her, according to Ovid). As a result of this encounter she conceived a son, Arcas.
Enraged, Hera or Artemis (some accounts say both) changed her into a bear. Arcas almost killed the bear, but Zeus stopped him just in time. Out of pity, Zeus placed Callisto the bear into the heavens, thus the origin of Callisto the Bear as a constellation. Some stories say that he placed both Arcas and Callisto into the heavens as bears, forming the Ursa Minor and Ursa Major constellations.
Iphigenia and the Taurian Artemis.
Artemis punished Agamemnon after he killed a sacred stag in a sacred grove and boasted that he was a better hunter than the goddess. When the Greek fleet was preparing at Aulis to depart for Troy to begin the Trojan War, Artemis becalmed the winds. The seer Calchas advised Agamemnon that the only way to appease Artemis was to sacrifice his daughter Iphigenia. Artemis then snatched Iphigenia from the altar and substituted a deer. Various myths have been told around what happened after Artemis took her. Either she was brought to Tauros and led the priests there, or became Artemis' immortal companion.
Niobe.
A Queen of Thebes and wife of Amphion, Niobe boasted of her superiority to Leto because while she had fourteen children (Niobids), seven boys and seven girls, Leto had only one of each. When Artemis and Apollo heard this impiety, Apollo killed her sons as they practiced athletics, and Artemis shot her daughters, who died instantly without a sound. Apollo and Artemis used poisoned arrows to kill them, though according to some versions two of the Niobids were spared, one boy and one girl. Amphion, at the sight of his dead sons, killed himself. A devastated Niobe and her remaining children were turned to stone by Artemis as they wept. The gods themselves entombed them.
Chione.
Chione was a princess of Pokis. She was beloved by two gods, Hermes and Apollo, and boasted that she was prettier than Artemis because she made two gods fall in love with her at once. Artemis was furious and killed Chione with her arrow or struck her dumb by shooting off her tongue. However, some versions of this myth say Apollo and Hermes protected her from Artemis' wrath.
Atalanta, Oeneus and the Meleagrids.
Artemis saved the infant Atalanta from dying of exposure after her father abandoned her. She sent a female bear to suckle the baby, who was then raised by hunters. But she later sent a bear to hurt Atalanta because people said Atalanta was a better hunter. This is in some stories.
Among other adventures, Atalanta participated in the hunt for the Calydonian Boar, which Artemis had sent to destroy Calydon because King Oeneus had forgotten her at the harvest sacrifices. In the hunt, Atalanta drew the first blood, and was awarded the prize of the skin. She hung it in a sacred grove at Tegea as a dedication to Artemis.
Meleager was a hero of Aetolia. King Oeneus had him gather heroes from all over Greece to hunt the Calydonian Boar. After the death of Meleager, Artemis turned his grieving sisters, the Meleagrids into guineafowl that Artemis loved very much.
Aura.
In Nonnus "Dionysiaca", Aura was Greek goddess of breezes and cool air, daughter of Lelantos and Periboia. She was a virgin huntress, just like Artemis and proud of her maidenhood. One day, she claimed that the body of Artemis was too womanly and she doubted her virginity. Artemis asked Nemesis for help to avenge her dignity and caused the rape of Aura by Dionysus. Aura became a mad and dangerous killer. When she bore twin sons, she ate one of them while the other one, Iakhos, was saved by Artemis. Iakhos later became an attendant of Demeter and the leader of Eleusinian Mysteries.
Polyphonte.
Polyphonte was a young woman who fled home preferring the idea of a virginal life with Artemis to the conventional life of marriage and children favoured by Aphrodite. As a punishment Aphrodite cursed her, causing her to have children by a bear. The resulting offspring, Agrius and Oreius, were wild cannibals who incurred the hatred of Zeus. Ultimately the whole family were transformed into birds and more specifically ill portents for mankind.
Trojan War.
Artemis may have been represented as a supporter of Troy because her brother Apollo was the patron god of the city and she herself was widely worshipped in western Anatolia in historical times. In the "Iliad" she came to blows with Hera, when the divine allies of the Greeks and Trojans engaged each other in conflict. Hera struck Artemis on the ears with her own quiver, causing the arrows to fall out. As Artemis fled crying to Zeus, Leto gathered up the bow and arrows.
Artemis played quite a large part in this war. Like her mother and brother, who was widely worshiped at Troy, Artemis took the side of the Trojans. At the Greek's journey to Troy, Artemis becalmed the sea and stopped the journey until an oracle came and said they could win the goddess' heart by sacrificing Iphigenia, Agamemnon's daughter. Agamemnon once promised the goddess he would sacrifice the dearest thing to him, which was Iphigenia, but broke the promise. Other sources said he boasted about his hunting ability and provoked the goddess' anger. Artemis saved Iphigenia because of her bravery. In some versions of the myth, Artemis made Iphigenia her attendant or turned her into Hecate, goddess of night, witchcraft, and the underworld.
Aeneas was helped by Artemis, Leto, and Apollo. Apollo found him wounded by Diomedes and lifted him to heaven. There, the three of them secretly healed him in a great chamber.
Worship of Artemis.
Artemis, the goddess of forests and hills, was worshipped throughout ancient Greece. Her best known cults were on the island of Delos
(her birthplace), in Attica at Brauron and Mounikhia (near Piraeus), and in Sparta. She was often depicted in paintings and statues in a forest setting, carrying a bow and arrows, and accompanied by a deer.
The ancient Spartans used to sacrifice to her as one of their patron goddesses before starting a new military campaign.
Athenian festivals in honor of Artemis included Elaphebolia, Mounikhia, Kharisteria, and Brauronia. The festival of Artemis Orthia was observed in Sparta.
Pre-pubescent and adolescent Athenian girls were sent to the sanctuary of Artemis at Brauron to serve the Goddess for one year. During this time, the girls were known as "arktoi", or little she-bears. A myth explaining this servitude states that a bear had formed the habit of regularly visiting the town of Brauron, and the people there fed it, so that, over time, the bear became tame. A girl teased the bear, and, in some versions of the myth, it killed her, while, in other versions, it clawed out her eyes. Either way, the girl's brothers killed the bear, and Artemis was enraged. She demanded that young girls "act the bear" at her sanctuary in atonement for the bear's death.
Virginal Artemis was worshipped as a fertility/childbirth goddess in some places, assimilating Ilithyia, since, according to some myths, she assisted her mother in the delivery of her twin. During the Classical period in Athens, she was identified with Hecate. Artemis also assimilated Caryatis (Carya).
Epithets.
As Aeginaea, she was worshiped in Sparta; the name means either huntress of chamois, or the wielder of the javelin ().
Also in Sparta, Artemis "Lygodesma" was worshipped. This epithet means "willow-bound" from the Gr. "lygos" (λυγός, willow) and "desmos" (δεσμός, bond). The willow tree appears in several ancient Greek myths and rituals.
She was worshipped at Naupactus as Aetole; in her temple in that town there was a statue of white marble representing her throwing a javelin. This "Aetolian Artemis" would not have been introduced at Naupactus, anciently a place of Ozolian Locris, until it was awarded to the Aetolians by Philip II of Macedon. Strabo records another precinct of "Aetolian Artemos" at the head of the Adriatic. As Agoraea she was the protector of the agora.
As Agrotera, she was especially associated as the patron goddess of hunters. In Athens Artemis was often associated with the local Aeginian goddess, Aphaea. As Potnia Theron, she was the patron of wild animals; Homer used this title. As Kourotrophos, she was the nurse of youths. As Locheia, she was the goddess of childbirth and midwives.
She was sometimes known as Cynthia, from her birthplace on Mount Cynthus on Delos, or Amarynthia from a festival in her honor originally held at Amarynthus in Euboea.
She was sometimes identified by the name Phoebe, the feminine form of her brother Apollo's solar epithet Phoebus.
Alphaea, Alpheaea, or Alpheiusa (Gr. , , or ) was an epithet that Artemis derived from the river god Alpheius, who was said to have been in love with her. It was under this name that she was worshiped at Letrini in Elis, and in Ortygia. Artemis Alphaea was associated with the wearing of masks, largely because of the legend that while fleeing the advances of Alpheius, she and her nymphs escaped him by covering their faces.
As (Artemis) Anaitis, the 'Persian Artemis' was identified with Anahita. As Apanchomene, she was worshipped as a hanged goddess.
Festivals.
Artemis was born at the sixth day, the reason why it was sacred for her.
Artemis in art.
The oldest representations of Artemis in Greek Archaic art portray her as "Potnia Theron" ("Queen of the Beasts"): a winged goddess holding a stag and leopard in her hands, or sometimes a leopard and a lion. This winged Artemis lingered in ex-votos as Artemis Orthia, with a sanctuary close by Sparta.
In Greek classical art she is usually portrayed as a maiden huntress, young, tall and slim, clothed in a girl's short skirt, with hunting boots, a quiver, a bow and arrows. Often, she is shown in the shooting pose, and is accompanied by a hunting dog or stag. When portrayed as a moon goddess, Artemis wore a long robe and sometimes a veil covered her head. Her darker side is revealed in some vase paintings, where she is shown as the death-bringing goddess whose arrows fell young maidens and women, such as the daughters of Niobe.
Artemis was sometimes represented in Classical art with the crown of the crescent moon, such as also found on Luna and others.
On June 7, 2007, a Roman era bronze sculpture of "Artemis and the Stag" was sold at Sotheby's auction house in New York state by the Albright-Knox Art Gallery for $25.5 million.
According to the Homeric Hymn to Artemis, she had golden bow and arrows, as her epithet was Khryselakatos, "of the Golden Shaft", and Iokheira (Showered by Arrows). The arrows of Artemis could also bring sudden death and disease to girls and women. Artemis got her bow and arrow for the first time from The Kyklopes, as the one she asked from her father. The bow of Artemis also became the witness of Callisto's oath of her virginity. In later cult, the bow became the symbol of waxing moon.
Artemis' chariot was made of gold and was pulled by four golden horned deer (Elaphoi Khrysokeroi). The bridles of her chariot were also made of gold.
Although quite seldom, Artemis is sometimes portrayed with a hunting spear. Her cult in Aetolia, the Artemis Aetolian, showed her with a hunting spear. The description about Artemis' spear can be found in Ovid's Metamorphosis, while Artemis with a fishing spear connected with her cult as a patron goddess of fishing.
Attributes.
As a goddess of maiden dances and songs, Artemis is often portrayed with a lyre.
Deer were the only animals held sacred to Artemis herself. On seeing a deer larger than a bull with horns shining, she fell in love with these creatures and held them sacred. Deer were also the first animals she captured. She caught five golden horned deer called Elaphoi Khrysokeroi and harnessed them to her chariot. The third labour of Heracles, commanded by Eurystheus, consisted in catching the Cerynitian Hind alive. Heracles begged Artemis for forgiveness and promised to return it alive. Artemis forgave him but targeted Eurystheus for her wrath.
Artemis got her hunting dogs from Pan in the forest of Arcadia. Pan gave Artemis two black-and-white dogs, three reddish ones, and one spotted one - these dogs were able to hunt even lions. Pan also gave Artemis seven bitches of the finest Arcadian race. However, Artemis only ever brought seven dogs hunting with her at any one time.
The sacrifice of a bear for Artemis started with the Brauron cult. Every year a girl between five and ten years of age was sent to Artemis' temple at Brauron. The Byzantine writer Suidos relayed the legend in Arktos e Brauroniois. A bear was tamed by Artemis and introduced to the people of Athens. They touched it and played with it until one day a group of girls poked the bear until it attacked them. A brother of one of the girls killed the bear, so Artemis sent a plague in revenge. The Athenians consulted an oracle to understand how to end the plague. The oracle suggested that, in payment for the bear's blood, no Athenian virgin should be allowed to marry until she had served Artemis in her temple ('played the bear for the goddess').
The boar is one of the favorite animals of the hunters, and also hard to tame. In honor of Artemis' skill, they sacrificed it to her. Oineus and Adonis were both killed by Artemis' boar.
Artemis felt pity for the Meleagrids as they mourned for their lost brother, Meleagor, so she transformed them into Guinea Fowl to be her favorite animals.
Hawks were the favored birds of many of the gods, Artemis included.
Flora.
Palm and Cypress were issued to be her birthplace. Other plants sacred to Artemis are Amaranth and Asphodel.
Artemis as "the Lady of Ephesus".
At Ephesus in Ionia, Turkey, her temple became one of the Seven Wonders of the World. It was probably the best known center of her worship except for Delos. There the Lady whom the Ionians associated with Artemis through "interpretatio graeca" was worshiped primarily as a mother goddess, akin to the Phrygian goddess Cybele, in an ancient sanctuary where her cult image depicted the "Lady of Ephesus" adorned with multiple rounded breast-like protuberances on her chest. They have been variously interpreted as multiple accessory breasts, as eggs, grapes, acorns, or even bull testes. Excavation at the site of the "Artemision" in 1987-88 identified a multitude of tear-shaped amber beads that had adorned the ancient wooden "xoanon". In Acts of the Apostles, Ephesian metalsmiths who felt threatened by Saint Paul's preaching of Christianity, jealously rioted in her defense, shouting “"Great is Artemis of the Ephesians!"” Of the 121 columns of her temple, only one composite, made up of fragments, still stands as a marker of the temple's location. The rest were used for making churches, roads, and forts.
Artemis in astronomy.
A minor planet, 105 Artemis; a lunar crater; the Artemis Chasma and the Artemis Corona have all been named for her.
Artemis is the acronym for "Architectures de bolometres pour des Telescopes a grand champ de vue dans le domaine sub-Millimetrique au Sol", a large bolometer camera in the submillimeter range that was installed in 2010 at the Atacama Pathfinder Experiment (APEX), located in the Atacama Desert in northern Chile.

</doc>
<doc id="2906" url="https://en.wikipedia.org/wiki?curid=2906" title="Arbeit macht frei">
Arbeit macht frei

"" () is a German phrase meaning "work sets you free." The slogan is known for appearing on the entrance of Auschwitz and other death camps. 
Origin.
The expression comes from the title of a novel by German philologist Lorenz Diefenbach, "Arbeit macht frei: Erzählung von Lorenz Diefenbach" (1873), in which gamblers and fraudsters find the path to virtue through labour. The phrase was also used in French ("le travail rend libre!") by Auguste Forel, a Swiss entomologist, neuroanatomist and psychiatrist, in his "Fourmis de la Suisse" quot;Ants of Switzerland&quot (1920). In 1922, the Deutsche Schulverein of Vienna, an ethnic nationalist "protective" organization of Germans within the Austrian empire, printed membership stamps with the phrase "Arbeit macht frei".
Use by the Nazis.
The slogan "Arbeit macht frei" was placed at the entrances to a number of Nazi concentration camps. The slogan's use in this instance was ordered by SS General Theodor Eicke, inspector of concentration camps and second commandant of Dachau Concentration Camp.
The slogan can still be seen at several sites, including over the entrance to Auschwitz I where, according to BBC historian Laurence Rees in his "Auschwitz: a New History", the sign was erected by order of commandant Rudolf Höss. This particular sign was made by prisoner-labourers including Jan Liwacz. The sign features an upside-down 'B', which has been interpreted as an act of defiance by the prisoners who made it.
In 1933 the first political prisoners were being rounded up for an indefinite period without charges. They were held in a number of places in Germany. The slogan was first used over the gate of a "wild camp" in the city of Oranienburg, which was set up in an abandoned brewery in March 1933 (it was later rebuilt in 1936 as Sachsenhausen). It can also be seen at the Dachau concentration camp, Gross-Rosen concentration camp, and the Theresienstadt Ghetto-Camp, as well as at Fort Breendonk in Belgium. It has been claimed that the slogan was placed over entrance gates to Auschwitz III / Buna/Monowitz. The slogan appeared at the Flossenbürg camp on the left gate post at the camp entry. The original gate posts survive in another part of the camp, but the slogan sign no longer exists. Primo Levi describes seeing the words illuminated over a doorway (as distinct from a gate) in Auschwitz III/Buna Monowitz.
At Buchenwald, "Jedem das Seine" (literally, "to each his own", but idiomatically "everyone gets what he deserves") was used.
In 1938 the Austrian political cabaret writer Jura Soyfer and the composer Herbert Zipper, while prisoners at Dachau Concentration Camp, wrote the "Dachaulied" (The Dachau Song). They had spent weeks marching in and out of the camp's gate to daily forced labour, and considered the motto "Arbeit macht frei" over the gate an insult. The song repeats the phrase cynically as a "lesson" taught by Dachau. (The first verse is translated in the article on Jura Soyfer.)
In "The Kingdom of Auschwitz", Otto Friedrich wrote about Rudolf Höss, regarding his decision to display the motto so prominently at the Auschwitz entrance:
Considering the role played by the Auschwitz prisons during the Holocaust as well as the individual prisoner's knowledge that once they entered the camp freedom was not likely to be obtained by any means other than death, the cruel comedy of the slogan becomes strikingly clear. The psychological impact it wrought on those who passed through the gates of each of the camps where it was seen was incredibly powerful.
Thefts of "Arbeit Macht Frei" Signs.
Signs displaying the slogan at the interpretive centers which now occupy the former Nazi concentration camps have repeatedly been targeted by thieves. Motivation for the thefts was originally thought to be for financial gain, however when the individuals responsible for the theft were identified it was revealed that in at least one instance the thieves themselves were affiliated with the Neo-Nazi movement. What political goals that they hoped to achieve through stealing the signs is unclear.
The sign over Auschwitz was stolen in December 2009 and later recovered by authorities in three pieces. Anders Högström, a Swedish neo-Nazi former leader, and two Poles were jailed as a result. The original sign is now in storage at the Auschwitz-Birkenau State Museum and a replica was put over the gate in its place.
Five years later, the sign over the Dachau gate was stolen by unknown thieves. The November 2014 theft of the Dachau sign remains unsolved and the artifact has never been recovered.

</doc>
<doc id="2907" url="https://en.wikipedia.org/wiki?curid=2907" title="Axayacatl">
Axayacatl

Axayacatl (; , ; , ; meaning "face of water"; c. 1449-1481) was the sixth "tlatoani" of the "altepetl" of Tenochtitlan and ruler of the Aztec Triple Alliance. During his youth, his military prowess gained him the favor influential figures such as Nezahualcoyotl and Tlacaelel I, and thus, upon the death of Moctezuma I in 1469, he was chosen to ascend to the throne, much to the displeasure of his two older brothers, Tizoc and Ahuitzotl. Axayacatl largely dedicated his twelve-year reign to consolidating his militaristic repute: he led successful campaigns against the neighboring "altepetl" of Tlatelolco in 1473 and the Matlatzinca of the Toluca Valley in 1474, but was finally defeated by the Tarascans of Michoacán in 1476. Despite some subsequent minor triumphs, Axayacatl's defeat at the hands of the Tarascans irreversibly marred his image, as it constituted the only major defeat suffered by the Aztecs up to that moment. In spite of his young age, he fell gravely ill in 1480, passing away a mere year later, in 1481, whereupon he was succeeded by his brother Tizoc.
Biography.
Axayacatl was a son of the princess Atotoztli II and her cousin, prince Tezozomoc. He was a grandson of the Emperors Moctezuma I and Itzcoatl. He was a descendant of the king Cuauhtototzin.
He was a successor of Moctezuma and his brothers were Emperors Tizoc and Ahuitzotl and his sister was the Queen Chalchiuhnenetzin. He was an uncle of the Emperor Cuauhtémoc and father of Emperors Moctezuma II and Cuitláhuac.
Using as a pretext the insulting behavior of a few Tlatelolcan citizens, Axayacatl invaded his neighbor, killed its ruler, Moquihuix, and replaced him with a military governor. The Tlatelolcans lost any voice they had in forming Aztec policy. It is also important that the Great Sun Stone, also known as the Aztec Calendar, was carved under his leadership. In the year 1475 there was a major earthquake that destroyed many homes in Temochtitlán.
He was followed on the throne by his brother Tizoc in 1481.
External links.
 

</doc>
<doc id="2908" url="https://en.wikipedia.org/wiki?curid=2908" title="Ahuitzotl">
Ahuitzotl

Ahuitzotl (, ) was the eighth Aztec ruler, the "Hueyi Tlatoani" of the city of Tenochtitlan, son of princess Atotoztli II. He was responsible for much of the expansion of the Mexica domain, and consolidated the empire's power after emulating his predecessor. He took power as tlatoani in the year 7 Rabbit (1486), after the death of his predecessor and brother, Tizoc.
His sons were kings Chimalpilli II and Cuauhtémoc and he also had one daughter.
Biography.
Perhaps the greatest known military leader of Pre-Columbian Mesoamerica, Ahuizotl began his reign by suppressing a Huastec rebellion, and then swiftly more than doubled the size of lands under Aztec dominance. He conquered the Mixtec, Zapotec, and other peoples from Pacific Coast of Mexico down to the western part of Guatemala. Ahuizotl also supervised a major rebuilding of Tenochtitlan on a grander scale including the expansion of the Great Pyramid or Templo Mayor in the year 8 Reed (1487).
He presided over the introduction of the great-tailed grackle into the Valley of Mexico, the earliest documented case of human-mediated bird introduction in the Western Hemisphere.
Ahuizotl died in the year 10 Rabbit (1502) and was succeeded by his nephew, Moctezuma II.
Ahuizotl took his name from the animal ahuizotl, which the Aztecs considered to be a legendary creature in its own right rather than a mere mythical representation of the king.
Tomb.
On 3 August 2007, Mexican archaeologists announced discovery of what is believed to be the tomb of Ahuizotl beneath a sculpture of Tlaltecuhtli near the Zócalo in Mexico City.
External links.
 

</doc>
<doc id="2909" url="https://en.wikipedia.org/wiki?curid=2909" title="Albinism">
Albinism

Albinism in humans (from the Latin "albus", "white"; "see extended etymology", also called achromia, achromasia, or achromatosis) is a congenital disorder characterized by the complete or partial absence of pigment in the skin, hair and eyes due to absence or defect of tyrosinase, a copper-containing enzyme involved in the production of melanin. It is the opposite of melanism. Unlike humans, other animals have multiple pigments and for these, albinism is considered to be a hereditary condition characterised by the absence of melanin in particular, in the eyes, skin, hair, scales, feathers or cuticle.
Albinism results from inheritance of recessive gene alleles and is known to affect all vertebrates, including humans. While an organism with complete absence of melanin is called an albino (, or ) an organism with only a diminished amount of melanin is described as leucistic or albinoid.
Albinism is associated with a number of vision defects, such as photophobia, nystagmus and amblyopia. Lack of skin pigmentation makes for more susceptibility to sunburn and skin cancers. In rare cases such as Chédiak–Higashi syndrome, albinism may be associated with deficiencies in the transportation of melanin granules. This also affects essential granules present in immune cells leading to increased susceptibility to infection.
Signs and symptoms.
In humans, there are two principal types of albinism: oculocutaneous, affecting the eyes, skin and hair, and ocular affecting the eyes only.
Most people with oculocutaneous albinism appear white or very pale, as the melanin pigments responsible for brown, black, and some yellow colorations are not present. Ocular albinism results in light blue eyes, and may require genetic testing to diagnose.
Because individuals with albinism have skin that entirely lacks the dark pigment melanin, which helps protect the skin from the sun's ultraviolet radiation, their skin can burn more easily from overexposure.
The human eye normally produces enough pigment to color the iris blue, green or brown and lend opacity to the eye. In photographs, those with albinism are more likely to demonstrate "red eye," due to the red of retina being visible through the iris. Lack of pigment in the eyes also results in problems with vision, both related and unrelated to photosensitivity.
Those afflicted with albinism are generally as healthy as the rest of the population (but see related disorders below), with growth and development occurring as normal, and albinism by itself does not cause mortality, although the lack of pigment blocking ultraviolet radiation increases the risk of melanomas (skin cancers) and other problems.
Visual problems.
Development of the optical system is highly dependent on the presence of melanin, and the reduction or absence of this pigment in sufferers of albinism may lead to:
Eye conditions common in albinism include:
Some of the visual problems associated with albinism arise from a poorly developed retinal pigment epithelium (RPE) due to the lack of melanin. This degenerate RPE causes foveal hypoplasia (a failure in the development of normal foveae), which results in eccentric fixation and lower visual acuity, and often a minor level of strabismus.
The iris is a sphincter formed from pigmented tissue that contracts when the eye is exposed to bright light, to protect the retina by limiting the amount of light passing through the pupil. In low light conditions, the iris relaxes to allow more light to enter the eye. In albinistic subjects, the iris does not have enough pigment to block the light, thus the decrease in pupil diameter is only partially successful in reducing the amount of light entering the eye. Additionally, the improper development of the RPE, which in normal eyes absorbs most of the reflected sunlight, further increases glare due to light scattering within the eye. The resulting sensitivity (photophobia) generally leads to discomfort in bright light, but this can be reduced by the use of sunglasses and/or brimmed hats.
Genetics.
Oculocutaneous albinism is generally the result of the biological inheritance of genetically recessive alleles (genes) passed from both parents of an individual for example OCA1 and OCA2. A mutation in the human TRP-1 gene may result in the deregulation of melanocyte tyrosinase enzymes, a change that is hypothesized to promote brown versus black melanin synthesis, resulting in a third oculocutaneous albinism (OCA) genotype, ″OCA3″. Some rare forms are inherited from only one parent. There are other genetic mutations which are proven to be associated with albinism. All alterations, however, lead to changes in melanin production in the body. Some of these are associated with increased risk of skin cancer (see list of such genetic variations).
The chance of offspring with albinism resulting from the pairing of an organism with albinism and one without albinism is low. However, because organisms (including humans) can be carriers of genes for albinism without exhibiting any traits, albinistic offspring can be produced by two non-albinistic parents. Albinism usually occurs with equal frequency in both sexes. An exception to this is ocular albinism, which it is passed on to offspring through X-linked inheritance. Thus, ocular albinism occurs more frequently in males as they have a single X and Y chromosome, unlike females, whose genetics are characterized by two X chromosomes.
There are two different forms of albinism: a partial lack of the melanin is known as hypomelanism, or hypomelanosis, and the total absence of melanin is known as amelanism or amelanosis.
Enzyme.
The enzyme defect responsible for OCA1-type albinism is tyrosine 3-monooxygenase (tyrosinase), which synthesizes melanin from the amino acid tyrosine.
Evolutionary theories.
It is suggested that the early hominin evolved in East Africa around 3 million years ago. The dramatic phenotypic change from primate to early hominin is hypothesized to have involved the extreme loss of body hair – except for areas most exposed to UV radiation, such as the head – to allow for more efficient thermoregulation in the early hunter-gatherers. The skin that would have been exposed upon general body hair loss in these early hominins would have most likely been non-pigmented, reflecting the pale skin underlying the hair of our chimpanzee relatives. A positive advantage would have been conferred to early hominids inhabiting the African continent that were capable of producing darker skin – those who first expressed the eumelanin-producing MC1R allele – which protected them from harmful epithelium-damaging ultraviolet rays. Over time, the advantage conferred to those with darker skin may have led to the prevalence of darker skin on the continent. The positive advantage, however, would have had to be strong enough so as to produce a significantly higher reproductive fitness in those who produced more melanin. The cause of a selective pressure strong enough to cause this shift is an area of much debate. Some hypotheses include the existence of significantly lower reproductive fitness in people with less melanin due to lethal skin cancer, lethal kidney disease due excess vitamin D formation in the skin of people with less melanin, or simply natural selection due to mate preference and sexual selection.
When comparing the prevalence of albinism in Africa to its prevalence in other parts of the world, such as Europe and the United States, the potential evolutionary effects of skin cancer as a selective force due to its effect on these populations may not be insignificant. The prevalence of albinism in some ethnic groups in sub-Saharan Africa is around 1 in 5,000, while in Europe and the US it is 1 in 20,000. It would follow, then, that there would be stronger selective forces acting on albino populations in Africa than on albino populations in Europe and the US. Rates as high as 1 in 1,000 have been reported for some populations in Zimbabwe and other parts of Southern Africa. In two separate studies in Nigeria, people suffering from albinism were found to be of reproductively significant age more often than not. One study found that 89% of people diagnosed with albinism are between 0 and 30 years of age, while the other found that 77% of albinos were under the age of 20.
Diagnosis.
Genetic testing can confirm albinism and what variety it is, but offers no medical benefits except in the cases of non-OCA disorders that cause albinism "along with" other medical problems which may be treatable. There is no 'cure' for Albinism. The "symptoms" of albinism can be assisted by various methods.
Treatment.
As there is no cure for albinism, it is managed through lifestyle adjustments. People with albinism need to take care not to sunburn and should have regular healthy skin checks by a dermatologist.
For the most part, treatment of the eye conditions consists of visual rehabilitation. Surgery is possible on the extra-ocular muscles to decrease strabismus. Nystagmus-damping surgery can also be performed, to reduce the "shaking" of the eyes back and forth. The effectiveness of all these procedures varies greatly and depends on individual circumstances.
Glasses and other vision aids, large-print materials as well as bright but angled reading lights, can help individuals with albinism, even though their vision cannot be corrected completely. Some people with albinism do well using bifocals (with a strong reading lens), prescription reading glasses, and/or hand-held devices such as magnifiers or monoculars.
Albinism is often associated with the absence of an iris in the eye. Contact lenses may be colored to block light transmission through the aniridic eye. Some use bioptics, glasses which have small telescopes mounted on, in, or behind their regular lenses, so that they can look through either the regular lens or the telescope. Newer designs of bioptics use smaller light-weight lenses. Some US states allow the use of bioptic telescopes for driving motor vehicles. (See also NOAH bulletin "Low Vision Aids".)
To support those with albinism, and their families, the National Organization for Albinism and Hypopigmentation was set up to provide a network of resources and information.
Epidemiology.
Albinism affects people of all ethnic backgrounds; its frequency worldwide is estimated to be approximately one in 17,000. Prevalence of the different forms of albinism varies considerably by population, and is highest overall in people of sub-Saharan African descent.
Society and culture.
In physical terms, humans with albinism commonly have visual problems and need sun protection. They often face social and cultural challenges (even threats), as the condition is often a source of ridicule, discrimination, or even fear and violence. It is especially socially deterring to African people. A study conducted in Nigeria on albino children stated that"..they experienced alienation, avoided social interactions and were less emotionally stable.Furthermore, affected individuals were less likely to complete schooling, find employment, and find partners". Many cultures around the world have developed beliefs regarding people with albinism.
In African countries such as Tanzania and Burundi, there has been an unprecedented rise in witchcraft-related killings of people with albinism in recent years, because their body parts are used in potions sold by witchdoctors. Numerous authenticated incidents have occurred in Africa during the 21st Century. For example, in Tanzania, in September 2009, three men were convicted of killing a 14-year-old albino boy and severing his legs in order to sell them for witchcraft purposes. Again in Tanzania and Burundi in 2010, the murder and dismemberment of a kidnapped albino child was reported from the courts, as part of a continuing problem. National Geographic estimates that in Tanzania a complete set of albino body parts is worth $75,000.
Another harmful and false belief is that sex with an albinistic woman will cure a man of HIV. This has led, for example in Zimbabwe, to rapes (and subsequent HIV infection).
Certain ethnic groups and populations in isolated areas exhibit heightened susceptibility to albinism, presumably due to genetic factors. These include notably the Native American Kuna, Zuni and Hopi nations (respectively of Panama, New Mexico and Arizona); Japan, in which one particular form of albinism is unusually common; and Ukerewe Island, the population of which shows a very high incidence of albinism.
Famous people with albinism include historical figures such as Oxford don William Archibald Spooner; actor-comedian Victor Varnado; musicians such as Johnny and Edgar Winter, Salif Keita, Winston "Yellowman" Foster, Brother Ali, Sivuca, Willie "Piano Red" Perryman; and fashion models Connie Chiu and Shaun Ross. Emperor Seinei of Japan is thought to have been an albino because he was said to have been born with white hair.
Other organisms.
Albinism and other types of pigment mutations also occur in the animal and plant kingdoms.

</doc>
<doc id="2911" url="https://en.wikipedia.org/wiki?curid=2911" title="Amr Diab">
Amr Diab

Amr Abd El-Basset Abd El-Azeez Diab (  ; born 11 October 1961) is an Egyptian pop singer and songwriter. He is widely considered the god father of Mediterranean music and the best selling Middle Eastern artist of all time. He has been awarded the World Music Award for Best Selling Middle Eastern Artist four times: 1996 for album "Nour El Ain", 2001 for album "Akter Wahed", 2007 for album "El Lillady" and 2013 for "El Leila" album. He has also won (Best Egyptian Artist, Best Male Arab Artist and World's Best Arab Male Artist Voted Online) at the World Music Awards 2014. Amr Diab is the only Middle Eastern artist to have received 7 World Music Awards. He also won The African Music Awards 2009 as Artist Of The Year, Song Of The Year, Video Of The Year And Best Male Act, and won The 2010 African Music Awards as best male act and best artist of North Africa. He is the only African artist to have received 6 African Music Awards in his career. He has had five platinum records:"Matkhafiesh" (1990), "Habiby" (1991), "Ayyamna" (1992),"Ya Omrena" (1993) and "Nour El Ain" (1997, triple platinum). Diab won Big Apple Music Awards 2009 as Lifetime Achievements Awards and Best Singer of The Year and also won The Global Icon Award, Most Popular Artist and Best Arabic Male Artist in 2014.
Early life.
Amr Diab was born on October 11, 1961 in Port Said, Egypt into an artistic family. His father, Abdul Basset Diab, worked for the Suez Canal Corporation and was the chairman of Marine Construction & Shipbuilding in the canal. Diab's father played a huge role in igniting the early sparks of musical inspiration towards Diab's early stages in his professional music career. Diab, at the age of six, had his first shot at fame when he sang the Egyptian National Anthem "Bilady, Bilady, Bilady" at the annual July 23 Festival in Port Said. As a result he was rewarded with a guitar from the governor of Port Said, and began to become recognised nationally. Diab graduated with a bachelor's degree in Arabic Music from the Cairo Academy of Arts in 1986.
Career.
Diab released his first album entitled "Ya Tareeq" in 1981. Diab's second album, "Ghanny Men Albak" (1984), was the first of a series of records he released with Delta Sound, including "Hala Hala" (1986), "Khalseen" (1987), "Mayyal" (1988), "Shawa'na" (1989), "Matkhafesh" (1990), "Habibi" (1991), "Ayyamna" (1992), "Ya Omrena" (1993), "Weylomony" (1994), and Rag'een (1995). In 1996 Diab released his first album with Alam El Phan entitled "Nour El Ain", which proved an international success and gained Diab recognition beyond the Arabic speaking world. Diab recorded four more albums on the Alam El Phan label including Amarain (1999) on which he collaborated with Khaled (on the song "Alby") and with Angela Dimitriou (on the song "Bahebbak Aktar").
In the summer of 2004 Diab, having left Alam El Phan, released his first album with Rotana Records, "Leily Nehary," which he followed up with the hugely successful "Kammel Kalamak" (2005), and "El Lilady" (2007). September 2011 saw the release of his album "Banadeek Taala", produced by Rotana. On February 2011, Amr Diab released his hit single "Masr Allet" (Egypt spoke). In 2012, Diab hosted the first Google Hangout in the Middle East during his performance in Dubai. In October 2014, Amr Diab released his album "Shoft El Ayam" which topped his last album "El Leila" and again became the best selling album in Egypt in iTunes and Rotana. In July 2015, Amr Diab released the music video from his song "Gamalo" from his album "Shoft El Ayam."
Musical style.
Diab is known as the father of Mediterranean Music. He has created his own style which is often termed "Mediterranean Music" or "Mediterranean Sound", a blend of Western and Egyptian rhythms. David Cooper and Kevin Dawe refer to his music as "the new breed of Mediterranean music". According to author Michael Frishkopf, Diab has produced a new concept of Mediterranean music, especially with his international hit, "Nour El Ain".
By 1992, he became the first Arabic artist to start making high-tech music videos.
Personal life.
Diab is an active fitness enthusiast. Diab is well known for his intense body building. Diab was married to Shereen Reda, from 1989–1992, ending in a divorce. They have one daughter, Nour, who became known through the song, "Habibi Ya Nour El Ain." Diab is currently married to Zeina Ashour, with whom he has three children: Abdallah, Kinzy, and Jana.
Albums.
"Tamally Maaak".
"Tamally Maak", meaning "Always with you", is written by Ahmed Ali Moussa and the music for the song was composed by Sherif Tag. Original arrangement was by Tarek Madkour. The video was filmed in Czech Republic and the instrumentation prominently included the classic guitar.
"Wayah" (2009).
The world music award of for the best-selling album in the Middle East 2009, "Wayah" (With Her) was released for sale on the internet on 27 June; however, the album was leaked online and was downloaded illegally amid complaints of slow download speed on the official site. Diab's fans initiated a massive boycott of the sites with the illegal copies.
On 18 October 2009 Amr Diab won four 2009 African Music Awards in the following categories: best artist, best album, best vocalist and best song for "Wayah"; Amr Diab had been nominated by the Big Apple Music Awards.
Music videos.
Diab is one of the first singers to popularize music videos in the Arab world and the first Egyptian singer to appear in music videos.
Film career.
Diab's fame in the music industry has led him to experiment with other forms of media, such as film. Amr played himself in his first film, "El Afareet", which was released in 1989. It also starred Madiha Kamel. His second film "Ice Cream in Gleam" ("Ays Krim fi Glym"), in which Diab starred in 1992, was chosen as one of the best five Egyptian musical films by the UCLA School of Theater, Film and Television. The film was featured in the UCLA Film and Television Archive's new program "Music on the Nile: Fifty Years of Egyptian Musical Films" at James Bridges Theater at UCLA on 6, 8 and 10 April 1999. David Chute of the "Los Angeles Weekly" termed it "observant" and "a big leap". His third movie was released in 1993, and was named "Deahk We La'ab" ("Laughter and Fun"). The film premiered in the Egyptian Film Festival in 1993. Amr played alongside international Egyptian movie star Omar Sharif ("Lawrence of Arabia", "Doctor Zhivago") and Yousra. Overall, Diab did not experience the same level of success in film that he had with his music career. Since 1993, Diab has focused on his singing career.
Egyptian Revolution.
During the 2011 uprising, some protesters criticized Diab for staying silent, and for fleeing Egypt for London. A few days after former President Hosni Mubarak stepped down, Amr Diab composed and sang a memorial song, "Masr A'let" (Egypt Said Its Word), and released it in conjunction with a music video showing pictures of the martyrs who died in the uprising. He initiated a charity campaign "Masry Begad" ("Truly Egyptian"), a social national program aimed at serving and rebuilding Egyptian society. His online radio station Diab FM often presents talks and discussions about what the Diab FM team can offer to the community as well as applying it practically by being present in different sites across Egypt with a new humanitarian project each week.
Amr Diab in movies.
Amr Diab's songs have appeared in several films, including:
Discography.
Official Albums
Unofficial Albums

</doc>
<doc id="2916" url="https://en.wikipedia.org/wiki?curid=2916" title="Belgian hip hop">
Belgian hip hop

Belgian hip hop music has a few rappers stemming from Africa and Italy. Belgium, like France, controlled African countries like the Democratic Republic of the Congo (formerly Zaire), Rwanda, and Burundi until the early 1960s. Like in France, immigrants from these countries started to study and live in Belgium.
The Belgian hip hop scene started in the late 1980s with a U.S.-based techno/hip hop group called Technotronic. In the group was an emcee named Ya Kid K from the Democratic Republic of the Congo who later led the group into international fame with hits like "Pump up the Jam" and "Shake That Body". In 1990, she also joined the group Hi-Tek 3 who were heard on the "Teenage Mutant Ninja Turtles" movie soundtrack. 
However, the first major pop rapper from Belgium was Benny B, who had a very mainstream and commercial sound. According to the European Music Office's report on "Music in Europe", this was the first of many pop acts that helped inspire a backlash and the creation of an underground hip hop scene.
Also in the late 1990s in the Walloon south of the country, French speaking/rapping Starflam was the biggest name in hip hop. In the Flemish north Dutch speaking/rapping groups like 't Hof van Commerce, Krapoel In Axe, St Andries MC's, and ABN were popular, rapping in their regional dialects. 
To find out more about today's Belgian hip hop scene, check out The Belgian Hip Hop Channel and vlaamserap.be

</doc>
<doc id="2917" url="https://en.wikipedia.org/wiki?curid=2917" title="Dutch hip hop">
Dutch hip hop

Dutch hip hop or Nederhop is hip hop music created by musicians in the Netherlands and Flanders.
History.
1980s.
Between 1980 and 1985 a few Dutch Hip Hop records had already been released, but in 1986 Dutch rap duo MC Miker G & DJ Sven (Lucien Witteveen and Sven van Veen) had a major top 10 hit (often #1) across Europe with their "Holiday Rap", which sampled Madonna's "Holiday". That same year Dutch rapper Extince released his first record: Rap Around The Clock. Another 1980s group was the Osdorp Posse, who first started to record tracks in Dutch. But there is disagreement about who started rapping in Dutch between Blonnie B, Alex and the CityCrew, Dynamic Rockers, Def Rhymes and Osdorp Posse.
Notable in the late 1980s were All Star Fresh of King Bee topping charts with: "Back by Dope Demand" in early 1990 and Rudeboy of Urban Dance Squad who, at the time, were arguably more widely known in New York City than the Netherlands. DJ and Producer All Star Fresh Started as a Pro in 1979. After winning the Dutch Mixing Championships (DMC) in 1988, he was invited for The World Mix Championships in the London Royal Hall and won third place in a fierce competition. He was invited by Dave Funkenklein to enter the lions hole in New York. He made history in the Big Apple of Hiphop by being the first non -American to fly into the finals of The World Supremacy Battle of DJs. He gained the highly respected second place of this prestigious DJ contest). The impression that he made that year, resulted in many invitations to perform with world known artists like Public Enemy, Stetsasonic, Ice T and Ultra Magnetic MCs.
All Star Fresh. As performer and producer he is very well known as KING BEE. With his second floor filler Back By Dope Demand he scored one of the biggest hiphop hits. In the Netherlands it resulted in a Top 3 position. Best Dance Product by The Edison Awards in the Netherlands. (The Edison Awards is an award by the Dutch Music Industry.) This also meant that with this title, he was the first black artist to win this award in the Netherlands. After that he appeared as supporting act for Madonnas show in the Netherlands. All Star Fresh kept entering the dance floors. The last titles mentioned were also worldwide hits, selling over 2.4 million copies. He didn't only work within projects like King Bee or Capella, but also was featuring famous production teams like Snap (I Got the Power). This teamwork resulted in the single Lets Get Busy (Clubland Quarts feat Snap King Bee). This record ended up No 01 in the Billboard Dance Charts (United States). Other productions were Deepzone "It's Gonna Be All right", a straight up club anthem even until today. Kellee- my love, Ty Holden- you're my Inspiration and His Royal Freshness- They don't understand are a couple of other productions in this line.
Urban Dance Squad was a Dutch rap rock band formed after what was originally intended as a one-time jam-session at a festival in Utrecht on 20 December, 1986. Band members were rapper Rudeboy Remmington (Patrick Tilon), guitarist Tres Manos (René van Barneveld), bassist Sil (Silvano Matadin), drummer Magic Stick (Michel Schoots) and DJ DNA (DoNotAsk) (Arjen de Vreede). The band's music is described as a blend of genres, including hard rock, funk, soul, hip hop, reggae, jazz and ska and is often compared to that of Rage Against the Machine, the Red Hot Chili Peppers and Fishbone. They are widely known for their hit single "Deeper Shade of Soul", which charted at number 21 in the United States on Billboard Hot 100. It is a well known fact that Rage Against the Machine was inspired by the Urban Dance Squad.
1990s.
In 1992, Osdorp Posse released their debut album "Osdorp Stijl", which was the first-ever Dutch hip hop . They started out translating N.W.A songs to Dutch, though later wrote their own rhymes in Dutch. Their beats, created by producer Seda on Amiga 500 with Protracker, have a familiar heavy sound and are similar to U.S. old-school hip hop. Frontman Def-P describes it as hardcore rap. In the 17 years of de Osdorp Posse's existence, the crew hasn't changed their style and are still making hardcore hip hop.
After the first Osdorp Posse demo cassette they toured around the Netherlands. In Deventer they found the first followers and the first Dutch language hip hop scene. The first hip hop groups after Osdorp Posse were Zuid-Oost Posse and Maasstraat Mannen. These groups did concerts all over the Netherlands. Maasstraat became famous as the first group combining reggae with Dutch lyrics, inspiring acts like Postmen, for example.
Another Dutch-language rapper is Extince, who in 1995 took Nederhop to a new commercial level. With two of his singles "Spraakwater" and "Kaal of Kammen" being major hits in the mid-1990s, Extince was the first Dutch rapper making the MegaCharts. Other notable acts include Ali B (who has been featured on other artists' tracks, most significantly with Marco Borsato on the song "Wat zou je doen?" for the charity War Child who achieved solo success with "Leipe mocro flavour". Together with his cousin Yes-R he made an international remix of "Ghetto" together with Akon.; the duo Lange Frans & Baas B with their patriotic but introspective "Het Land Van"; and Yes-R. Other notable groups are "Opgezwolle" (consisting of rapper Sticky Steez, rapper Phreaco Rico and DJ Delic) and Brainpower.
There were two styles dominating the Dutch hip hop landscape: Extince, known for his easy flows, catchy songs and funky tunes, while hardcore performers like Westklan and Osdorp Posse found their own niche group of fans.
In the mid-1990s The Postmen were topping the charts with their rap/reggae mix.
2000s.
In the early 2000s the MC fronted band Relax got much airplay, as did de Spookrijders.
A combination of these two styles gave birth to de Spookrijders, a three-man hip-hop group founded in 1996. With MCs Stefan and Clyde rapping about their personal lives and life in Amsterdam as a black man, de Spookrijders even gained respect from non-hip-hop musicians and fans. Most people admired the work of producer/DJ Cliff 'the Jazz' Nille after releasing Spookrijders debut album "De Echte Shit". In 1999 de Spookrijders hit the charts twice with the hits "Klokkenluiders" and "Ik ben de man." Both these songs appeared on the second album, "Klokkenluiders van Amsterdam". After some personal arguments among the three crewmembers, de Spookrijders split up in 2003, after releasing their and final third album "Hee... Spookies!!"
Opgezwolle, a group from Zwolle's latest album, "Eigen Wereld" (Own World) appeared in the 'Album Top 100' at number 4; the highest notation of a Dutch rap album ever. Opgezwolle split up on 30 November 2007. Members Rico & Sticks formed a new group, Fakkelbrigade with MC Typhoon, Mick 2dope Murray, MC James and beatmaker ART. In 2009, they released the album "Colucci Era".
In the mid-2000s Cilvaringz, Ali B and Raymzter have commercially been successful and Lange Frans & Baas B have had multiple No. 1 hits. In 2005, De Jeugd van Tegenwoordig ("The youth of today") were successful with "Watskeburt?!" ("Wuzhappenin?!").
Rapper Jawat won the "Grote Prijs van Nederland" 2006.
Another Dutch hip-hop duo are Pete Philly and Perquisite who are already well known in the Netherlands, Germany, and even in Japan.
A famous Dutch rapper outside the Netherlands is Salah Edin. His album Nederlands Grootste Nachtmerrie (Biggest Nightmare of the Netherlands) won Best Album Award in 2007 and was fully produced by Dr. Dre's right-hand man Focus. He also shot three of the most expensive music videos ever in the history of Dutch Hip Hop and through a management deal with Cilvaringz, performed in 34 countries worldwide.
2010s.
The year 2010 is considered an important year for Dutch hip-hop, with many albums and mixtapes released from the biggest Dutch rappers.
Also Mc Battles are having a large amount of popularity.
Nederhop is growing fast. So are the recently Nederhop blogs as Nederhopofficial.nl (Owner Dennis Strooband) and Puna.nl (Owner Thomas Abera) growing fastly.
Conflicts.
The Dutch hip-hop scene also saw many conflicts between rappers, followed by diss tracks. The following were the biggest Dutch feuds ever in hip-hop:
T.H.C . Vs Negativ, Kempi Vs Nino, Brainpower Vs Extince, Yukkie B Vs Negativ, T.H.C. Vs Lexxxus, Baas B Vs Kimo, Kempi Vs Mini, Kempi Vs Bloedserieus, Heist Rockah Vs Negativ, and Regga Vs Lexxxus.
The feud between T.H.C. and Lexxxus resulted in a fistfight on a hip-hop event, when T.H.C. frontman rocks got into an argument with Lexxxus and then started the fistfight. Also many Dutch rappers got shot/stabbed, wounding or killing them. Bloedserieus rapper Sane got in a fight over drugs and was fatally stabbed at Eindhoven Central Station. Kane (another rapper of Bloedserieus and the twinbrother of Sane) made a song about this called "Jonko voor Sane" (Joint for Sane). Amsterdam rappers Lexxxus, Flex of T.H.C. and Mr. Probz got shot.
Genres in Dutch hip hop.
Gangsta.
Dutch gangsta hip hop is currently a large scene together with underground hip-hop. Among the most notable groups are THC, Heinek'n, Keizer, Kempi, Steen, Hef, Crooks, Adonis and Negativ. The rhythms are influenced by the American rap scene, and the lyrics are often about crime, drugs,money,women and many criminal things.
All coming from Dutch Ghettos,they say what they see in their area.
Dutch gangsta hip hop mostly comes from Amsterdam, Den Haag, Rotterdam, Utrecht and Eindhoven.
Commercial success.
The commercial success of Dutch hip hop is largely made by Brainpower, Yes-R, Ali B, Lange Frans & Baas B and Extince. For a large part of the Dutch hip hop community Yes-R, Ali B and Lange Frans & Baas B are sometimes considered fake because they do a lot of work for children TV stations. Brainpower and Extince however both enjoy a great respect for bringing up hip hop in their native Dutch. Other commercial rappers are De Jeugd van Tegenwoordig, and one of the more popular artists in the Netherlands, Partysquad or The Partysquad. They are a 2-man group, having had success with hits such as "Stuk" (Broken), and "Dat is Die Shit" (That's the shit), with other popular songs in the background such as "Non Stop" ft. Brainpower, "We Gaan Los" (we're going crazy {because of highness or drunkenness}) with Kempi, and "Wat Wil Je Doen" (Whut u gonna do?).
Dutch oldskool.
The Dutch oldskool exists out of three primary artists, LTH, Osdorp Posse, Extince, Sugacane and Duvelduvel. Osdorp Posse make to what they themselves call hardcore rap and use beats that have much in common with N.W.A. Their lyrics are about racism, prostitution (not always negatively), police and other social subjects. Extince uses very different, more funky kind of beats than Osdorp Posse and uses a completely different rapstyle. Duvelduvel is known as a conceptual hip hop group.
Notable artists.
The Dutch hip hop scene is roughly divided by the Netherlands' larger cities.

</doc>
<doc id="2919" url="https://en.wikipedia.org/wiki?curid=2919" title="Anaïs Nin">
Anaïs Nin

Anaïs Nin (; born Angela Anaïs Juana Antolina Rosa Edelmira Nin y Culmell; February 21, 1903 – January 14, 1977) was an essayist and memoirist born to Cuban parents in France, where she was also raised. She spent some time in Spain and Cuba but lived most of her life in the United States where she became an established author. She wrote journals (which span more than 60 years, beginning when she was 11 years old and ending shortly before her death), novels, critical studies, essays, short stories, and erotica. A great deal of her work, including "Delta of Venus" and "Little Birds", was published posthumously.
Early life.
Anaïs Nin was born in Neuilly, France, to artistic parents. Her father, Joaquín Nin, was a Cuban pianist and composer, when he met her mother Rosa Culmell, a classically trained Cuban singer of French and Danish descent. Her father's grandfather had fled France during the Revolution, going first to Saint-Domingue, then New Orleans, and finally to Cuba where he helped build that country's first railway.
Nin was raised a Roman Catholic and spent her childhood and early life in Europe. After her parents separated, her mother moved Anaïs and her two brothers, Thorvald Nin and Joaquín Nin-Culmell, to Barcelona, and then to New York City. According to her diaries, "Volume One, 1931–1934", Nin abandoned formal schooling at the age of sixteen years and later began working as an artist's model. After being in America for several years, Nin had forgotten how to speak Spanish, but retained her French and became fluent in English.
On March 3, 1923, in Havana, Cuba, Nin married her first husband, Hugh Parker Guiler (1898–1985), a banker and artist, later known as "Ian Hugo" when he became a maker of experimental films in the late 1940s. The couple moved to Paris the following year, where Guiler pursued his banking career and Nin began to pursue her interest in writing; in her diaries she also mentions having trained as a flamenco dancer in Paris in the mid-to-late 1920s. Her first published work was a critical evaluation of D. H. Lawrence called "", which she wrote in sixteen days.
She was transformed by her therapy with Otto Rank, who eventually became her lover. On her second visit to Rank, Nin reflects on her desire to be "re-born" as a woman and artist. Rank, she observes, helped her move back and forth between what she could verbalize in her journals and what remained unarticulated. She discovered the quality and depth of her feelings in the wordless transitions between what she could say and what she could not say. "As he talked, I thought of my difficulties with writing, my struggles to articulate feelings not easily expressed. Of my struggles to find a language for intuition, feeling, instincts which are, in themselves, elusive, subtle, and wordless".
In the late summer of 1939, when residents from overseas were urged to leave France due to the approaching war, Nin left Paris and returned to New York City with her husband. (Guiler was, according to his own wishes, all but edited out of the diaries published during Nin's lifetime; his role in her life is therefore difficult to gauge.) During the war, Nin sent her books to Frances Steloff of the Gotham Book Mart in New York for safekeeping.
Personal life.
According to her diaries, "Vol.1, 1931–1934", Nin shared a bohemian lifestyle with Henry Miller during her time in Paris. Her husband Guiler is not mentioned anywhere in the published edition of the 1930s parts of her diary (Vol. 1–2) although the opening of Vol. 1 makes it clear that she is married, and the introduction suggests her husband refused to be included in the published diaries. The diaries edited by her second husband, after her death, tell that her union with Henry Miller was very passionate and physical, and that she believed that it was a pregnancy by him that she aborted in 1934.
In 1947, at the age of 44, she met former actor Rupert Pole in a Manhattan elevator on her way to a party. The two ended up dating and traveled to California together; Pole was sixteen years her junior. On March 17, 1955, while still married to Guiler, she married Pole at Quartzsite, Arizona, returning with him to live in California. Guiler remained in New York City and was unaware of Nin's second marriage until after her death in 1977, though biographer Deirdre Bair alleges that Guiler knew what was happening while Nin was in California, but consciously "chose not to know".
Nin referred to her simultaneous marriages as her "bicoastal trapeze". According to Deidre Bair: 
In 1966, Nin had her marriage with Pole annulled, due to the legal issues arising from both Guiler and Pole trying to claim her as a dependent on their federal tax returns. Though the marriage was annulled, Nin and Pole continued to live together as if they were married, up until her death in 1977. According to Barbara Kraft, prior to her death Anais had written to Hugh Guiler asking for his forgiveness. He responded writing how meaningful his life had been because of her.
After Guiler's death in 1985, the unexpurgated versions of her journals were commissioned by Pole. Five volumes have appeared ("Henry and June", ', ', "Nearer the Moon", and ""). Pole died in July 2006.
Nin often cited authors Djuna Barnes and D. H. Lawrence as inspirations. She states in Volume One of her diaries that she drew inspiration from Marcel Proust, André Gide, Jean Cocteau, Paul Valéry, and Arthur Rimbaud.
Nin once worked at Lawrence R. Maxwell Books, located at 45 Christopher Street in New York City. In addition to her work as a writer, Nin appeared in the Kenneth Anger film "Inauguration of the Pleasure Dome" (1954) as Astarte; in the Maya Deren film "Ritual in Transfigured Time" (1946); and in "Bells of Atlantis" (1952), a film directed by Guiler under the name "Ian Hugo" with a soundtrack of electronic music by Louis and Bebe Barron.
Literary career.
Journals.
Anaïs Nin's most important works, in the judgment of both herself and scholars, are her diaries or journals. The journals, which span several decades, provide a deeply explorative insight into her personal life and relationships. Nin was acquainted, often quite intimately, with a number of prominent authors, artists, psychoanalysts, and other figures, and wrote of them often, especially Otto Rank. Moreover, as a female author describing a primarily masculine constellation of celebrities, Nin's journals have acquired importance as a counterbalancing perspective.
Previously unpublished works are coming to light in "A Café in Space, the Anaïs Nin Literary Journal", which includes "Anaïs Nin and Joaquín Nin y Castellanos: Prelude to a Symphony—Letters between a father and daughter."
So far sixteen volumes of her journals have been published. All but the last five of her adult journals are in expurgated form.
Erotic writings.
Nin is hailed by many critics as one of the finest writers of female erotica. She was one of the first women known to explore fully the realm of erotic writing, and certainly the first prominent woman in the modern West known to write erotica. Before her, erotica acknowledged to be written by women was rare, with a few notable exceptions, such as the work of Kate Chopin.
According to Volume I of her diaries, 1931–1934, published in 1966 (Stuhlmann), Nin first came across erotica when she returned to Paris with her husband, mother and two brothers in her late teens. They rented the apartment of an American man who was away for the summer, and Nin came across a number of French paperbacks: "One by one, I read these books, which were completely new to me. I had never read erotic literature in America… They overwhelmed me. I was innocent before I read them, but by the time I had read them all, there was nothing I did not know about sexual exploits… I had my degree in erotic lore."
Faced with a desperate need for money, Nin, Henry Miller and some of their friends began in the 1940s to write erotic and pornographic narratives for an anonymous "collector" for a dollar a page, somewhat as a joke. (It is not clear whether Miller actually wrote these stories or merely allowed his name to be used.) Nin considered the characters in her erotica to be extreme caricatures and never intended the work to be published, but changed her mind in the early 1970s and allowed them to be published as "Delta of Venus" and "Little Birds".
Nin was a friend, and in some cases lover, of many leading literary figures, including Henry Miller, John Steinbeck, Antonin Artaud, Edmund Wilson, Gore Vidal, James Agee, James Leo Herlihy, and Lawrence Durrell. Her passionate love affair and friendship with Miller strongly influenced her both sexually and as an author. Nin wrote about her infatuation with the Surrealist artist Bridget Bate Tichenor in her diaries. Claims that Nin was bisexual were given added circulation by the Philip Kaufman film "Henry & June" about Henry Miller and his second wife June Miller. The first unexpurgated portion of Nin's journal to be published, "Henry and June", makes it clear that Nin was stirred by June to the point of saying (paraphrasing), "I have become June," though it is unclear whether she consummated her feelings for her sexually. To both Anaïs and Henry, June was a femme fatale—irresistible, cunning, erotic. Nin gave June money, jewelry, clothes, often leaving herself broke.
In the third volume of her unexpurgated journal, "Incest", she wrote about her father candidly and graphically (207–15). When Nin's father learned of the title of her first book of fiction, "House of Incest", he feared that the nature of the abuse would be revealed, when, in fact, it was heavily veiled in Nin's text.
Later life and legacy.
The explosion of the feminist movement in the 1960s gave feminist perspectives on Nin's writings of the past twenty years, which made Nin a popular lecturer at various universities; contrarily, Nin disassociated herself from the political activism of the movement.
In 1973 Anaïs Nin received an honorary doctorate from the Philadelphia College of Art. She was elected to the United States National Institute of Arts and Letters in 1974. In 1976 she was presented with a Los Angeles Times Woman of the Year award. She died in Los Angeles on January 14, 1977, three years after being diagnosed with cancer. Her body was cremated, and her ashes were scattered over Santa Monica Bay in Mermaid Cove. Her first husband, Hugh Guiler, died in 1985, and his ashes were scattered in the cove as well. Rupert Pole was named Nin's literary executor, and he arranged to have new, unexpurgated editions of Nin's books and diaries published between 1985 and his death in 2006. Large portions of the diaries are still available only in the expurgated form. The originals are located in the UCLA library.
Philip Kaufman directed the 1990 film "Henry & June" based on Nin's novel "Henry and June: From the Unexpurgated Diary of Anaïs Nin". She was portrayed in the film by Maria de Medeiros.
In February 2008, Los Angeles poet Steven Reigns organized Anaïs Nin @ 105 at the Hammer Museum. Reigns said, “Nin bonded and formed very deep friendships with women and men decades younger than her. Some of them are still living in Los Angeles and I thought it’d be wonderful to have them share their experiences with (Nin),”. Bebe Barron, electronic music pioneer and longtime friend of Nin, made her last public appearance at Anaïs Nin @ 105.
Reigns also combed through Nin’s original diaries to investigate the validity of Bern Porter’s claims of his sexual relationship in the 1930s with Anaïs Nin, which were published as a series of interviews in the 1990s. Reigns’ essay refuting Porter’s claims, "Bern Porter’s Wild Sexual Life with Anais Nin or Wild Imaginings?" was published in Café in Space and Thinking of Anaïs Nin (February 2014).
On September 27, 2013, screenwriter and author Kim Krizan published an article in "The Huffington Post" revealing she had found a previously unpublished love letter written by Gore Vidal to Nin. This letter contradicts Gore Vidal's previous characterization of his relationship with Nin, showing that Vidal did have feelings for Nin that he later heavily disavowed in his autobiography, "Palimpsest". Krizan did this research in the run up to the release of the latest volume of Anaïs Nin's uncensored diary, "Mirages", for which Krizan provided the foreword.
References.
Notes
Bibliography

</doc>
<doc id="2923" url="https://en.wikipedia.org/wiki?curid=2923" title="AOL Instant Messenger">
AOL Instant Messenger

AOL Instant Messenger (AIM) is an instant messaging and presence computer program which uses the proprietary OSCAR instant messaging protocol and the TOC protocol to allow registered users to communicate in real time.
AIM became incredibly popular in the early 2000s in North America, and was the leading instant messaging application in that region. AIM's popularity steeply degraded at the end of the decade, and its fall has often been compared with other once-mighty internet services such as MySpace.
History.
AOL Instant Messenger was released by America Online (AOL) in May 1997 for Microsoft Windows. The software, maintained by AOL, Inc., at one time had the largest share of the instant messaging market in North America, especially in the United States (with 52% of the total reported ). This does not include other instant messaging software related to or developed by AOL, such as ICQ and iChat.
Its main competitors during its heyday were ICQ, Yahoo! Messenger and MSN Messenger. AOL particularly had a rivalry or 'chat war' with rival Microsoft starting in 1999. There were several attempts from Microsoft to simultaneously log into their own and AIM's protocol servers. AOL were not happy about this and started blocking MSN Messenger from being able to access AIM.
AIM went officially mobile in early 2008 when the application was released for Windows Mobile devices. However AIM could already be used on various devices beforehand with third-party applications, and as early as 2002 on a Sidekick.
Since 2012, stand-alone official AIM client software includes advertisements and is available for Microsoft Windows, Windows Mobile, Mac OS, Mac OS X, Android, iOS, BlackBerry OS.
Usage decline.
Around 2009 AIM started to lose popularity rapidly, partly because many people started purely moving onto social networking websites for instant messaging.
, one source reported AOL Instant Messenger market share had collapsed to 0.73%. However, this number only reflects installed IM applications, and not active users. The engineers responsible for AIM claimed that they were unable to convince AOL management that free was the future.
On March 3, 2012, AOL got rid of all the developing staff for AIM, effectively ending development of the application after 15 years. However the service is still active and help support is still provided.
The 'Running Man'.
The AIM mascot was designed by JoRoan Lazaro and was implemented in the first release in 1997. This was a yellow stickman-like figure, often called the 'Running Man'. The mascot appeared on all AIM logos and most wordmarks, and always appeared at the top of the buddy list. AIM's incredible popularity in the late 1990s and the 2000s led to the Running Man becoming a familiar brand on the internet. After over 14 years, the iconic logo was finally disappeared as part of the AIM rebranding in 2011. However, in August 2013 the Running Man once again returned.
In 2014, an editor of the site Complex.com called it a 'symbol of America'. In April 2015 the Running Man was officially featured in the Virgin London Marathon, dressed by a person for the AOL-partnered Free The Children charity.
Protocol.
The standard protocol that AIM clients use to communicate is called Open System for CommunicAtion in Realtime (OSCAR). Most AOL-produced versions of AIM and popular third party AIM clients use this protocol. However, AOL also created a simpler protocol called TOC that lacks many of OSCAR's features but is sometimes used for clients that only require basic chat functionality. The TOC/TOC2 protocol specifications were made available by AOL, while OSCAR is a closed protocol that third parties have had to reverse-engineer.
In January 2008, AOL introduced experimental Extensible Messaging and Presence Protocol (XMPP) support for AIM, allowing AIM users to communicate using the standardized, open-source XMPP. However, in March 2008, this service was discontinued. As of May 2011, AOL offers limited XMPP support.
Privacy.
For privacy regulations, AIM has strict age restrictions. AIM accounts are available only for people over the age of 13; children younger than that are not permitted access to AIM.
Under the AIM Privacy Policy, AOL has no rights to read or monitor any private communications between users. The profile of the user has no privacy.
If public content is accessed. it can be used for online, print or even broadcast advertising. etc. This is outlined in the policy and terms of service: "... you grant AOL, its parent, affiliates, subsidiaries, assigns, agents and licensees the irrevocable, perpetual, worldwide right to reproduce, display, perform, distribute, adapt and promote this Content in any medium". This allows anything one posts to be used without a separate request for permission.
The issue of AIM's security has been called into question. AOL states that it has taken great steps to insure that personal information will not be accessed by unauthorized members, but that it cannot guarantee that that will not happen.
AIM is different from other clients, such as Yahoo! Messenger, in that it does not require approval from one buddy to be added to another's buddy list. As a result, it is possible for users to keep other unsuspecting users on their buddy list to see when they are online, read their status and away messages, and read their profiles. In fact, there is a Web API to display one's status and away message as a widget on one's Web page. However, one can block another user from communicating and seeing one's status, but this does not prevent the user from creating a new account that is not blocked and therefore can still track the first user's status. A more complete privacy option is to select a menu option allowing communication only with those on one's buddy list; this causes blocking (thus appearing offline to) all users who are not on one's buddy list.
Chat robots.
AOL and various other companies supply robots on AIM that can receive messages and send a response based on the bot's purpose. For example, bots can help with studying, like StudyBuddy. Some are made to relate to children and teenagers, like Spleak, others give advice, and others are for more general purposes, such as SmarterChild. The more useful chat bots have features like the ability to play games, get sport scores, weather forecasts or financial stock information. Users were able to talk to automated chat bots that could respond to natural human language. They were primarily put into place as a marketing strategy and for unique advertising options. It was used by advertisers to market products or build better consumer relations.
Before the inclusions of such bots, the other bots DoorManBot and AIMOffline provided features that are provided today by AOL for those who needed it. ZolaOnAOL and ZoeOnAOL were short lived bots that ultimately retired their features in favor of SmarterChild. As of November 18, 2008, the SmarterChild bot for AIM was retired and is no longer offering any services.
URI scheme.
AOL Instant Messenger's installation process automatically installs an extra URI scheme ("protocol") handler into some Web browsers, so URIs beginning "aim:" can open a new AIM window with specified parameters. This is similar in function to the mailto: URI scheme, which creates a new e-mail message using the system's default mail program. For instance, a Web page might include a link like the following in its HTML source to open a window for sending a message to the AIM user "notarealuser":
To specify a message body, the codice_2 parameter is used, so the link location might look like this:
To specify an away message, the message parameter is used, so the link location might look like this:
When placing this inside a URL link, an AIM user could click on the URL link and the away message "Hello, my name is Bill" would instantly become their away message.
To add a buddy, the addbuddy message is used, with the screenname parameter
This type of link is commonly found on forum profiles, to easily add contacts
Vulnerabilities.
AIM has security weaknesses that have enabled exploits to be created that use third-party software to perform malicious acts on users' computers. Although most are relatively harmless, such as being kicked off the AIM service, others perform potentially dangerous actions such as sending viruses. Some of these exploits rely on social engineering to spread by automatically sending instant messages that contain a URL accompanied by text suggesting the receiving user click on it, an action which leads to infection. These messages can easily be mistaken as coming from a friend and contain a link to a Web address that installs software on the user's computer to restart the cycle.
Users have also reported sudden additions of toolbars and advertisements from third parties in the newer version of AIM. Multiple complaints about the lack of control of third party involvement have caused many users to stop using the service.
Extra features.
iPhone application.
On March 6, 2008, during Apple Inc.'s iPhone SDK event, AOL announced that they would be releasing an AIM application for iPhone and iPod Touch users. The application is available for free from the App Store, but the company also provides a paid version, which displays no advertisements. Both are available from the App Store. The AIM client for iPhone and iPod Touch supports standard AIM accounts as well as MobileMe accounts. There is also an express version of AIM accessible through the Safari browser on the iPhone and iPod Touch.
In 2011 AOL launched a massive overhaul of their Instant Messaging service. Included in the update was a brand new iOS application for iPhone and iPod Touch which incorporated all the latest features. A brand new icon was used for the application, featuring the new cursive logo for AIM. The user-interface was entirely redone for the features including: a new buddy list, group messaging, in-line photos and videos, as well as improved file-sharing.
Currently the application is in version 5.0.5, which was updated as of March 2012. In the latest iteration, it supports more social stream features, much like Facebook and Twitter, as well as the ability to send voice messages up to 60 seconds long.
iPad application.
On April 3, 2010 Apple released the first generation iPad. Along with this newly released device AOL released the AIM application for iPad. It was built entirely from scratch for the new version iOS with a specialized user-interface for the device. It supports geo location, Facebook status updates and chat, MySpace, Twitter, YouTube, Foursquare and many social networking platforms.
AIM Express.
AIM Express runs in a pop-up browser window. It is intended for use by people who are unwilling or unable to install a standalone application or those at computers that lack the AIM application. AIM Express supports many of the standard features included in the stand-alone client, but does not provide advanced features like file transfer, audio chat, video conferencing, or buddy info. It is implemented in Adobe Flash. It is an upgrade to the prior AOL Quick Buddy, which was later available for older systems that cannot handle Express before being discontinued. Express and Quick Buddy are similar to MSN Web Messenger and Yahoo! Web Messenger.
AIM Pages.
AIM Pages was released in May 2006, allowing the 63 million AIM users to create an online, dynamic profile. The buddy list serves as the basis for the AIM Page social networking service. An AIM Page is built using modules following the ModuleT microformat. AIM Pages was discontinued in late 2007.
AIM for Mac.
AOL released an all-new AIM for the Macintosh on September 29, 2008 and the final build on December 15, 2008. The redesigned AIM for Mac is a full universal binary Cocoa API application that supports both Tiger and Leopard – Mac OS X 10.4.8 (and above) or Mac OS X 10.5.3 (and above). On October 1, 2009, AOL released AIM 2.0 for Mac.
AIM real-time IM.
This feature is available for AIM 7 and allows for a user to see what the other is typing as it is being done. It was developed and built with assistance from Trace Research and Development Centre at University of Wisconsin-Madison and Gallaudet University. The application provides visually impaired users the ability to convert messages from text (words) to speech. For the application to work users must have AIM 6.8 or higher, as it is not compatible with older versions of AIM software, AIM for Mac or iChat.
AIM to mobile (messaging to phone numbers).
This feature allows text messaging to a phone number (text messaging is less functional than instant messaging).
Discontinued features.
AIM for Phoneline.
AIM Phoneline was a Voice over IP PC-PC, PC-Phone and Phone-to-PC service provided via the AOL Instant Messenger (AIM) application. It was also known to work with Apple's iChat Client.
Launched on May 16, 2006, AIM Phoneline provided users the ability to have several local numbers, allowing AIM users to receive free incoming calls. The service allowed users to make calls to landlines and mobile devices through the use of a computer. The service, however, was only free for receiving and AOL charged users $14.95 a month for unlimited calling plan.
In order to use AIM Phoneline users had to install the latest free version of AIM Triton software and needed a good set of headphones with a boom microphone. It could take several days after a user signed up before it started working.
The service provided users with many interfaces such as Auto Action APIs, Ringback Tone APIs and Screen Name Services API that made the AIM Phoneline a great service.
On January 13, 2009, the service was officially closed. The closing of the free service caused the number associated with the service to be disabled and not transferrable for a different service.
AIM Call Out.
AIM Call Out is a discontinued Voice over IP PC-PC, PC-Phone and Phone-to-PC service provided by AOL via its AOL Instant Messenger (AIM) application that replaced the defunct AIM Phoneline service in November 2007. It did not depend on the AIM client and could be used with only an AIM screenname via the WebConnect feature or a dedicated SIP device. The AIM Call Out service was shut down on March 25, 2009.
Security.
On November 4, 2014, AIM scored 1 out of 7 points on the Electronic Frontier Foundation's secure messaging scorecard. AIM received a point for encryption during transit but lost points because communications are not encrypted with a key the provider doesn't have access to (i.e. the communications are not end-to-end encrypted), users can't verify contacts' identities, past messages are not secure if the encryption keys are stolen (i.e. the service does not provide forward secrecy), the code is not open to independent review (i.e. the code is not open-source), the security design is not properly documented, and there has not been a recent independent security audit. BlackBerry Messenger, Ebuddy XMS, Hushmail, Kik Messenger, Skype, Viber, and Yahoo Messenger also scored 1 out of 7 points.

</doc>
<doc id="2925" url="https://en.wikipedia.org/wiki?curid=2925" title="Ackermann function">
Ackermann function

In computability theory, the Ackermann function, named after Wilhelm Ackermann, is one of the simplest and earliest-discovered examples of a total computable function that is not primitive recursive. All primitive recursive functions are total and computable, but the Ackermann function illustrates that not all total computable functions are primitive recursive.
After Ackermann's publication of his function (which had three nonnegative integer arguments), many authors modified it to suit various purposes, so that today "the Ackermann function" may refer to any of numerous variants of the original function. One common version, the two-argument Ackermann–Péter function, is defined as follows for nonnegative integers "m" and "n":
Its value grows rapidly, even for small inputs. For example, "A"(4,2) is an integer of 19,729 decimal digits.
History.
In the late 1920s, the mathematicians Gabriel Sudan and Wilhelm Ackermann, students of David Hilbert, were studying the foundations of computation. Both Sudan and Ackermann are credited with discovering total computable functions (termed simply "recursive" in some references) that are not primitive recursive. Sudan published the lesser-known Sudan function, then shortly afterwards and independently, in 1928, Ackermann published his function formula_2. Ackermann's three-argument function, formula_3, is defined such that for "p" = 0, 1, 2, it reproduces the basic operations of addition, multiplication, and exponentiation as
and for "p" > 2 it extends these basic operations in a way that can be compared to the hyperoperations:
In "On the Infinite", David Hilbert hypothesized that the Ackermann function was not primitive recursive, but it was Ackermann, Hilbert’s personal secretary and former student, who actually proved the hypothesis in his paper "On Hilbert’s Construction of the Real Numbers".
Rózsa Péter and Raphael Robinson later developed a two-variable version of the Ackermann function that became preferred by many authors.
Definition and properties.
Ackermann's original three-argument function formula_3 is defined recursively as follows for nonnegative integers "m", "n", and "p":
Of the various two-argument versions, the one developed by Péter and Robinson (called "the" Ackermann function by some authors) is defined for nonnegative integers "m" and "n" as follows:
It may not be immediately obvious that the evaluation of formula_10 always terminates. However, the recursion is bounded because in each recursive application either "m" decreases, or "m" remains the same and "n" decreases. Each time that "n" reaches zero, "m" decreases, so "m" eventually reaches zero as well. (Expressed more technically, in each case the pair ("m", "n") decreases in the lexicographic order on pairs, which is a well-ordering, just like the ordering of single non-negative integers; this means one cannot go down in the ordering infinitely many times in succession.) However, when "m" decreases there is no upper bound on how much "n" can increase—and it will often increase greatly.
The Péter-Ackermann function can also be expressed in terms of various other versions of the Ackermann function:
For small values of "m" like 1, 2, or 3, the Ackermann function grows relatively slowly with respect to "n" (at most exponentially). For "m" ≥ 4, however, it grows much more quickly; even "A"(4, 2) is about 2, and the decimal expansion of "A"(4, 3) is very large by any typical measure.
Logician Harvey Friedman defines a version of the Ackermann function as follows:
He also defines a single-argument version A(n) = A(n, n).
A single-argument version A(k) = A(k, k) that increases both "m" and "n" at the same time dwarfs every primitive recursive function, including very fast-growing functions such as the exponential function, the factorial function, multi- and superfactorial functions, and even functions defined using Knuth's up-arrow notation (except when the indexed up-arrow is used). It can be seen that A(n) is roughly comparable to f(n) in the fast-growing hierarchy.
This extreme growth can be exploited to show that "f", which is obviously computable on a machine with infinite memory such as a Turing machine and so is a computable function, grows faster than any primitive recursive function and is therefore not primitive recursive. In a category with exponentials, using the isomorphism formula_17 (in computer science, this is called currying), the Ackermann function may be defined via primitive recursion over higher-order functionals as follows:
where "Succ" is the usual successor function and "Iter" is defined by primitive recursion as well:
One interesting aspect of the Ackermann function is that the only arithmetic operations it ever uses are addition and subtraction of 1. Its properties come solely from the power of unlimited recursion. This also implies that its running time is at least proportional to its output, and so is also extremely huge. In actuality, for most cases the running time is far larger than the output; see below.
Table of values.
Computing the Ackermann function can be restated in terms of an infinite table. We place the natural numbers along the top row. To determine a number in the table, take the number immediately to the left, then look up the required number in the previous row, at the position given by the number just taken. If there is no number to its left, simply look at the column headed "1" in the previous row. Here is a small upper-left portion of the table:
! "m"\"n"
! 0
! 1
! 2
! 3
! 4
! "n"
! 0
! 1
! 2
! 3
! 4
This inverse appears in the time complexity of some algorithms, such as the disjoint-set data structure and Chazelle's algorithm for minimum spanning trees. Sometimes Ackermann's original function or other variations are used in these settings, but they all grow at similarly high rates. In particular, some modified functions simplify the expression by eliminating the "−3" and similar terms.
A two-parameter variation of the inverse Ackermann function can be defined as follows, where formula_32 is the floor function:
This function arises in more precise analyses of the algorithms mentioned above, and gives a more refined time bound. In the disjoint-set data structure, "m" represents the number of operations while "n" represents the number of elements; in the minimum spanning tree algorithm, "m" represents the number of edges while "n" represents the number of vertices.
Several slightly different definitions of α("m", "n") exist; for example, log "n" is sometimes replaced by "n", and the floor function is sometimes replaced by a ceiling.
Other studies might define an inverse function of one where m is set to a constant, such that the inverse applies to a particular row.
Use as benchmark.
The Ackermann function, due to its definition in terms of extremely deep recursion, can be used as a benchmark of a compiler's ability to optimize recursion. The first published use of Ackermann's function in this way was in 1971 by Yngve Sundblad.
Sundblad's seminal paper was taken up by Brian Wichmann (co-author of the Whetstone benchmark) in a trilogy of papers written between 1975 and 1982.

</doc>
<doc id="2926" url="https://en.wikipedia.org/wiki?curid=2926" title="Antarctic">
Antarctic

The Antarctic (US English , UK English or and or ) is a polar region, specifically the region around the Earth's South Pole, opposite the Arctic region around the North Pole. The Antarctic comprises the continent of Antarctica and the ice shelves, waters, and island territories in the Southern Ocean situated south of the Antarctic Convergence. The region covers some 20% of the Southern Hemisphere, of which 5.5% (14 million km) is the surface area of the Antarctic continent itself.
Geography.
The maritime part of the region constitutes the area of application of the international Convention for the Conservation of Antarctic Marine Living Resources (CCAMLR), where for technical reasons the Convention uses an approximation of the Convergence line by means of a line joining specified points along parallels of latitude and meridians of longitude. The implementation of the Convention is managed through an international Commission headquartered in Hobart, Australia, by an efficient system of annual fishing quotas, licenses and international inspectors on the fishing vessels, as well as satellite surveillance.
Most of the Antarctic region is situated south of 60°S latitude parallel, and is governed in accordance with the international legal regime of the Antarctic Treaty System. The Treaty area covers the continent itself and its immediately adjacent islands, as well as the archipelagos of the South Orkney Islands, South Shetland Islands, Peter I Island, Scott Island and Balleny Islands.
The islands situated between 60°S latitude parallel to the south and the Antarctic Convergence to the north, and their respective Exclusive Economic Zones fall under the national jurisdiction of the countries that possess them: South Georgia and the South Sandwich Islands (United Kingdom; also an EU Overseas territory), Bouvet Island (Norway), and Heard and McDonald Islands (Australia).
Kerguelen Islands (France; also an EU Overseas territory) are situated in the Antarctic Convergence area, while the Falkland Islands, Isla de los Estados, Hornos Island with Cape Horn, Diego Ramírez Islands, Campbell Island, Macquarie Island, Amsterdam and Saint Paul Islands, Crozet Islands, Prince Edward Islands, and Gough Island and Tristan da Cunha group remain north of the Convergence and thus outside the Antarctic region.
Wildlife.
A variety of animals live in Antarctica for at least some of the year, including:
Most of the Antarctic continent is permanently covered by ice and snow; less than 1% of the land is exposed. There are only two species of flowering plant, Antarctic hair grass and Antarctic pearlwort, but a range of mosses, liverworts, lichens and macrofungi.
People.
The first Antarctic land discovered was the island of South Georgia, visited by the English merchant Anthony de la Roché in 1675. Although myths and speculation about a "Terra Australis" ("Southern Land") date back to antiquity, the first confirmed sighting of the continent of Antarctica is commonly accepted to have occurred in 1820 by the Russian expedition of Fabian Gottlieb von Bellingshausen and Mikhail Lazarev on "Vostok" and "Mirny". The first human born in the Antarctic was Solveig Gunbjørg Jacobsen born on 8 October 1913 in Grytviken, South Georgia.
The Antarctic region had no indigenous population when first discovered, and its present inhabitants comprise a few thousand transient scientific and other personnel working on tours of duty at the several dozen research stations maintained by various countries. However, the region is visited by more than 40,000 tourists annually, the most popular destinations being the Antarctic Peninsula area (especially the South Shetland Islands) and South Georgia Island.
In December 2009, the growth of tourism, with consequences for both the ecology and the safety of the travellers in its great and remote wilderness, was noted at a conference in New Zealand by experts from signatories to the Antarctic Treaty. The definitive results of the conference would be presented at the Antarctic Treaty states' meeting in Uruguay in May 2010.
Conservation.
The Antarctic hosts the world largest protected area comprising 1.07 million km, the South Georgia and the South Sandwich Islands Marine Protection Area created in 2012.
Time zones.
Because Antarctica surrounds the South Pole, it is theoretically located in all time zones. For practical purposes, time zones are usually based on territorial claims or the time zone of a station's owner country or supply base.
Islands:

</doc>
<doc id="2927" url="https://en.wikipedia.org/wiki?curid=2927" title="Albanians">
Albanians

Albanians () are defined as an ethnic group native to Albania and neighboring countries. The term is also used sometimes to refer to the citizens of the Republic of Albania. Ethnic Albanians speak the Albanian language and more than half of ethnic Albanians live in Albania and Kosovo. A large Albanian population lives in the Republic of Macedonia, with smaller Albanian populations located in Serbia and Montenegro. Albanians produced many prominent figures such as Skanderbeg, leader of the medieval Albanian resistance to the Ottoman conquest and others during the Albanian National Awakening seeking self-determination. Following the Ottoman conquest of the Balkans in the 15th century, the majority of Albanians converted to Islam. Muslim Albanians occupied many important positions in the Ottoman Empire, and were the main pillars of Ottoman Porte's policy in the Balkans. Albania gained its independence in 1912 and between 1945-1992, Albanians lived under a repressive communist regime. Albanians within Yugoslavia underwent periods of discrimination and eventual self-determination that concluded with the breakup of that state in the early 1990s culminating with Albanians living in new countries and Kosovo. Outside the southwestern Balkans of where Albanians have traditionally been located, Albanian populations through the course of history have formed new communities contributing to the cultural, economic, social and political life of their host populations and countries while also at times assimilating too.
Between the 11th and 18th centuries, sizable numbers of Albanians migrated from the area of contemporary Albania to escape either various socio-political difficulties and/or the Ottoman conquest. One population which became the Arvanites settled down in southern Greece who starting from the 16th century though mainly during the 19th century onwards assimilated and today self identify as Greeks. Another population, who became the Arbëreshë settled in southern Italy and form the oldest continuous Albanian diaspora producing influential and many prominent figures. Smaller populations dating to migrations during the 18th century are located on Croatia’s Dalmatian coast and scattered communities across southern Ukraine.
The Albanian diaspora also exists in a number of other countries. The largest of these is located in Turkey. It was formed during the Ottoman era through economic migration and early years of the Turkish republic through migration due to sociopolitical discrimination and violence experienced by Albanians in Balkan countries. Due to the Ottoman legacy, smaller populations of Albanians also exist in Egypt and the Levant, in particular Syria. In Western countries, a large and influential Albanian population exists in the United States formed from continuous emigration dating back to the 19th century. Other Albanians populations due to emigration between the 19th and 21th centuries are located in Australia, New Zealand, Canada, Germany, Belgium, United Kingdom, France, Sweden, Switzerland, Slovenia, Croatia, Slovenia, Italy, Finland, Denmark, Norway, Austria, Netherlands, Bulgaria, Greece and Romania.
Ethnonym.
The ethnonym "Albanians" is believed to be derived from Albanoi, an Illyrian tribe mentioned by Ptolemy in the city of Albanopolis. While the exonym "Albania" for the general region inhabited by the Albanians does hark back to Classical Antiquity, the Albanian language employs a different ethnonym, with modern Albanians referring to themselves as "shqipëtarë" and to their country as "Shqipëria". Two etymologies have been conjectured for this ethnonym: one, associated with Maximilian Lambertz, derives the etymology from the Albanian for eagle ("shqipe", var.,"shqiponjë"), perhaps denoting denizens of a mountainous region. In Albanian folk etymology, this word denotes a bird totem dating from the times of Skanderbeg, as displayed on the Albanian flag. The other suggestion connects it to the verb 'to speak' ("me shqiptue"). If the latter conjecture were correct, the Albanian endonym, like "Slav" and others, would originally have been a term for "those who speak ntelligibly, the same languag".
In "History" written in 1079–1080, the Byzantine historian Michael Attaliates referred to the "Albanoi" as having taken part in a revolt against Constantinople in 1043 and to the "Arbanitai" as subjects of the duke of Dyrrachium. It is disputed, however, whether that refers to Albanians in an ethnic sense. However a later reference to Albanians from the same Attaliates, regarding the participation of Albanians in a rebellion around 1078, is undisputed. In later Byzantine usage, the terms "Arbanitai" and "Albanoi", with a range of variants, were used interchangeably, while sometimes the same groups were also called by the classicising name Illyrians. The first reference to the Albanian language dates to the later 13th century (around 1285).
Names of the Albanians.
The Albanians are and have been referred to by other terms as well. Some of them are:
History.
Studies in genetic anthropology show that the Albanians share the same ancestry as most other European peoples.
Albanians in the Middle Ages.
What is possibly the earliest written reference to the Albanians is that to be found in an old Bulgarian text compiled around the beginning of the 11th century. It was discovered in a Serbian manuscript dated 1628 and was first published in 1934 by Radoslav Grujic. This fragment of a legend from the time of Tsar Samuel endeavours, in a catechismal 'question and answer' form, to explain the origins of peoples and languages. It divides the world into seventy-two languages and three religious categories: Orthodox, half-believers (i.e. non-Orthodox Christians) and non-believers. The Albanians find their place among the nations of half-believers. If the dating of Grujic is accepted, which is based primarily upon the contents of the text as a whole, this would be the earliest written document referring to the Albanians as a people or language group.
It can be seen that there are various languages on earth. Of them, there are five Orthodox languages: Bulgarian, Greek, Syrian, Iberian (Georgian) and Russian. Three of these have Orthodox alphabets: Greek, Bulgarian and Iberian. There are twelve languages of half-believers: Alamanians, Franks, Magyars (Hungarians), Indians, Jacobites, Armenians, Saxons, Lechs (Poles), Arbanasi (Albanians), Croatians, Hizi, Germans.
The first undisputed mention of Albanians in the historical record is attested in Byzantine source for the first time in 1079–1080, in a work titled "History" by Byzantine historian Michael Attaliates, who referred to the "Albanoi" as having taken part in a revolt against Constantinople in 1043 and to the "Arbanitai" as subjects of the duke of Dyrrachium. It is disputed, however, whether the "Albanoi" of the events of 1043 refers to Albanians in an ethnic sense or whether "Albanoi" is a reference to Normans from Sicily under an archaic name (there was also tribe of Italy by the name of "Albanoi"). However a later reference to Albanians from the same Attaleiates, regarding the participation of Albanians in a rebellion around 1078, is undisputed. At this point, they are already fully Christianized, although Albanian mythology and folklore are part of the Paleo-Balkan pagan mythology, in particular showing Greek influence.
From the late 11th century the Albanians were called Arbën/Arbër and their country as Arbanon, a mountainous area to the west of Lake Ochrida and the upper valley of the river Shkumbin. It was in 1190, when the rulers of Arbanon (local Albanian noble called Progon and his sons Dhimitër and Gjin) created their principality with its capital at Krujë. After the fall of Progon Dynasty in 1216, the principality came under Grigor Kamona and Gulam of Albania. Finally the Principality was dissolved in 1255. Around 1230 the two main centers of Albanian settlements, one around Devoll river in what is now central Albania, and the other around the region which was known with the name Arbanon.
In 1271 Charles of Anjou created the Kingdom of Albania, after he captured a part of the Despotate of Epirus. A major attempt to advance further in direction of Constantinople failed at the Siege of Berat (1280–1281). A Byzantine counteroffensive soon ensued, which drove the Angevins out of the interior by 1281. The Sicilian Vespers further weakened the position of Charles, and the Kingdom was soon reduced by the Epirotes to a small area around Durrës. The kingdom however held out until 1368, when the city was captured by Karl Thopia.The presence of the kingdom reinforced the influence of Catholicism and the conversion to its rite, not only in the region of Durrës but also in other parts of the country. A new wave of Catholic dioceses, churches and monasteries were founded, a number of different religious orders began spreading into the country, and papal missionaries also reached the territories of the Kingdom of Albania. Those who were not Catholic in Central and North Albania converted and a great number of Albanian clerics and monks were present in the Dalmatian Catholic institutions.
In the 14th century a number of Albanian principalities were created.These included Principality of Kastrioti,Principality of Dukagjini,Princedom of Albania,Principality of Gjirokastër etc.n the beginning of the 15th century that these principalities became stronger, especially because of the fall of the Serbian Empire. Some of these principalities were united in 1444 under the military alliance called League of Lezha.
Albanians under the Ottoman Empire.
At the dawn of the establishment of the Ottoman Empire in Southeast Europe, the geopolitical landscape was marked by scattered kingdoms of small principalities. The Ottomans erected their garrisons throughout southern Albania by 1415 and established formal jurisdiction over most of Albania by 1431. However, in 1443 a great and longstanding revolt broke under the lead of the Albanian national hero Skanderbeg, which lasted until 1479, many times defeating major Ottoman armies led by sultans Murad II and Mehmed II. Skanderbeg united initially the Albanian princes and later established a centralized authority over most of the non-conquered territories, becoming Lord of Albania. He also tried relentlessly but rather unsuccessfully to create a European coalition against the Ottomans. He frustrated every attempt by the Turks to regain Albania, which they envisioned as a springboard for the invasion of Italy and western Europe. His unequal fight against the mightiest power of the time won the esteem of Europe as well as some support in the form of money and military aid from Naples, the papacy, Venice, and Ragusa. Finally after decades of resistance, Ottomans captured Shkodër in 1479 and Durrës in 1501. Skanderbeg’s long struggle to keep Albania free became highly significant to the Albanian people, as it strengthened their solidarity, made them more conscious of their national identity, and served later as a great source of inspiration in their struggle for national unity, freedom, and independence. The invasion triggered a several waves of migration of Albanians from Albania, Epirus and Peloponnese to the south of Italy, constituting an Arbereshe community. Albanians were recruited all over Europe as a light cavalry known as stratioti. The stratioti were pioneers of light cavalry tactics during this era. In the early 16th century heavy cavalry in the European armies was principally remodeled after Albanian stradioti of the Venetian army, Hungarian hussars and German mercenary cavalry units (Schwarzreitern).
By the 16th century, Ottoman rule over Southeast Europe was largely secure. The Ottomans proceeded in stages, first appointing a qadi along with governors and then military retainers in the cities. Timar holders, not necessarily converts to Islam, would occasionally rebel, the most famous case of which is Skanderbeg. His figure would be used later in the 19th century as a central component of Albanian national identity. Ottoman control over the Albanian territories was secured in 1571 when Ulcinj, presently in Montenegro, was captured. The most significant impact on the Albanians was the gradual Islamisation process of a large majority of the population- although such a process only became widespread in the 17th century. Mainly Catholics converted in the 17th century, while the Orthodox Albanians became Muslim mainly in the following century. Initially confined to the main city centres of Elbasan and Shkodër, by this time the countryside was also embracing the new religion. In Elbasan Muslims made up just over half the population in 1569–70 whereas in Shkodër this was almost 90% and in Berat closer to 60%. In the 17th century, however, Catholic conversion to Islam increased, even in the countryside. The motives for conversion according to scholars were diverse, depending on the context. The lack of source-material does not help when investigating such issues. Albanians could also be found across the empire, in Egypt, Algeria, and across the Maghreb as vital military and administrative retainers.
Albanian national awakening.
By the 1870s, the Sublime Porte's reforms aimed at checking the Ottoman Empire's disintegration had clearly failed. The image of the "Turkish yoke" had become fixed in the nationalist mythologies and psyches of the empire's Balkan peoples, and their march toward independence quickened. The Albanians, because of the higher degree of Islamic influence, their internal social divisions, and the fear that they would lose their Albanian-populated lands to the emerging Balkan states—Serbia, Montenegro, Bulgaria, and Greece—were the last of the Balkan peoples to desire division from the Ottoman Empire. The Albanian national awakening as a coherent political movement began after the Treaty of San Stefano, according to which Albanian-inhabited areas were to be ceded to other states of the Balkans, and focused on preventing that partition. The Treaty of San Stefano was the impetus for the nation-building movement, which was based more on fear of partition than national identity. Even after Albania became independent in 1912, Albanian national identity was fragmented and possible non-existent in much of the new country. The state of disunity and fragmentation would remain until the communist period following World War II, when the communist nation-building project would achieve greater success in nation-building and reach more people than any previous regime, thus creating Albanian national communist identity.
Distribution.
Southeast Europe.
Approximately 7 million Albanians are to be found within the Balkan peninsula with about half this number residing in Albania and the other divided between Kosovo, Montenegro, Serbia, the Republic of Macedonia, Greece and to a much smaller extent Bosnia, Bulgaria, Croatia, Romania, and Slovenia. An estimated 2.2 million Albanians live in the territory of Former Yugoslavia, the greater part (close to two million) in Kosovo. Rights to use the Albanian language in education and government were given and guaranteed by the 1974 Constitution of SFRY and were widely utilized in Macedonia and in Montenegro before the Dissolution of Yugoslavia.
Albania.
Albania has an estimated 3 million inhabitants, with ethnic Albanians comprising approximately 95% of the total.
Kosovo.
The Albanian presence in Kosovo and in the adjacent Toplica and Morava regions is recorded since the medieval period. As the Serbs expelled a large number of Albanians from the wider Toplica and Morava regions in southern Serbia, which the Congress of Berlin of 1878 had given to the Belgrade Principality, a large number of them settled in Kosovo.In Kosovo they and their descendants are known as "muhaxher" (meaning "the exiled", from the Arabic muhajir) During the First Balkan War of 1912-13, Serbia and Montenegro - after expelling the Ottoman forces in present-day Albania and Kosovo - committed numerous war crimes against the Albanian population, which were reported by the European, American and Serbian opposition press. During the Kosovo war,Serbian paramilitary forces committed war crimes in Kosovo, although the Serbian government claims that the army was only going after suspected Albanian terrorists. This triggered a 78-day NATO campaign in 1999.Now Albanians in Kosovo constitute the majority with 1,616,869. The most widespread religion among Albanians in Kosovo is Islam (mostly Sunni. The other religion Kosovar Albanians practice is Roman Catholicism). Culturally, Albanians in Kosovo are very closely related to Albanians in Albania. Traditions and customs differ even from town to town in Kosovo itself. The spoken dialect is Gheg, typical of northern Albanians. The language of state institutions, education, books, media and newspapers is the standard dialect of Albanian, which is closer to the Tosk dialect.
Greece.
An estimated 275,000–600,000 Albanians live in Greece, forming the largest immigrant community in the country. They are economic migrants whose migration began in 1991, following the collapse of the Socialist People's Republic of Albania.
The Arvanites and Albanian-speakers of Western Thrace are a group descended from Tosks who migrated to southern and central Greece between the 13th and 16th centuries. They are Greek Orthodox Christians, and though they traditionally speak a dialect of Tosk Albanian known as Arvanitika, they have fully assimilated into the Greek nation and do not identify as Albanians. Arvanitika is in a state of attrition due to language shift towards Greek and large-scale internal migration to the cities and subsequent intermingling of the population during the 20th century.
The Cham Albanians were a group that formerly inhabited a region of Epirus known as Chameria, nowadays Thesprotia in northwestern Greece. Most Cham Albanians converted to Islam during the Ottoman era. Muslim Chams were expelled from Greece during World War II, by an anti-communist resistance group, as a result of their participation in a communist resistance group and the collaboration with the Axis occupation, while Orthodox Chams have largely assimilated into the Greek nation.
Diaspora.
Italy.
Italy has a historical Albanian minority of 260,000 which are scattered across Southern Italy. The majority of Albanians in Italy arrived in 1991 and have since surpassed the older populations of Arbëreshë.
There is an Albanian community in southern Italy, known as Arbëreshë, who had settled in the country in the 15th and the 16th century, displaced by the changes brought about by the expansion of the Ottoman Empire. Some managed to escape and were offered refuge from the repression by the Kingdom of Naples and Kingdom of Sicily (both under Aragonese rule), where the Arbëreshë were given their own villages and protected.
The Albani were an aristocratic Roman family, members of which attained the highest dignities in the Roman Catholic Church, one,Clement XI, having been Pope. They were ethnic Albanians who originally moved to Urbino from the region of Malësi e Madhe in Albania.
After the breakdown of the communist regime in Albania in 1990, Italy had been the main immigration target for Albanians leaving their country. This was because Italy had been a symbol of the West for many Albanians during the communist period, because of its geographic proximity.
The Arbëreshë speak "Arbërisht", an old variant of Albanian spoken in southern Albania, known as Tosk Albanian. The Arbëresh language is of particular interest to students of the modern Albanian language as it represents the sounds, grammar, and vocabulary of pre-Ottoman Albania. In Italy the Arbëreshë language is protected by Law n. 482/99, concerning the protection of the historic linguistic minorities. The Arbëreshë are scattered throughout southern Italy and Sicily, and in small numbers also in other parts of Italy. They are in great numbers in North and Latin America, especially in the USA, Brazil, Argentina, Chile, Uruguay and Canada. The Arbereshe constitute one of the largest minorities in Italy.
Turkey.
The Ottoman period that followed in Albania after the end of Skanderbeg's resistance was characterized by a great change.Many Albanians gained prominent positions in the Ottoman government such as: Iljaz Hoxha, Hamza Kastrioti, Koca Davud Pasha, Zağanos Pasha, Köprülü Mehmed Pasha (head of the Köprülü family of Grand Viziers), the Bushati family, Sulejman Pasha, Edhem Pasha, Nezim Frakulla, Haxhi Shekreti, Hasan Zyko Kamberi, Ali Pasha of Gucia, Muhammad Ali of Egypt and Ali Pasha of Tepelena who rose to become one of the most powerful Muslim Albanian rulers in western Rumelia.There has been a considerable presence of Albanians since the Ottoman administration.
The Albanian diaspora in Turkey was formed during the Ottoman era through economic migration and early years of the Turkish republic through migration due to sociopolitical discrimination and violence experienced by Albanians in Balkan countries. According to a 2008 report prepared for the National Security Council of Turkey by academics of three Turkish universities in eastern Anatolia, there were approximately 1,300,000 people of Albanian descent living in Turkey. According to that study, more than 500,000 Albanian descendants still recognize their ancestry and or their language, culture and traditions. There are also other estimates regarding the Albanian population in Turkey that range from being 3-4 million people up to a total of 5 million in number, although most of these are Turkish citizens of partial Albanian ancestry and no longer fluent in Albanian (cf. German Americans). This was due to various degrees of either linguistic and or cultural assimilation occurring amongst the Albanian diaspora in Turkey. Nonetheless, a sizable proportion of the Albanian community in Turkey, such as that of Istanbul, has maintained its distinct Albanian identity. Albanians are active in the civic life of Turkey. For example, after the Turks and Kurds, Albanians are the third most represented ethnic group of parliamentarians in the Turkish parliament, though belonging to different political parties.
The Albanian diaspora in Turkey lobbied the Turkish government for recognition of Kosovo's independence by Turkey. State relations of Albania and Kosovo with Turkey are friendly and close, due to the Albanian population of Turkey maintaining close links with Albanians of the Balkans and vice versa and also Turkey maintaining close socio-political, cultural, economic and military ties with Albania and Kosovo. Turkey has been supportive of Albanian geopolitical interests within the Balkans. The current AKP Turkish political leadership has acknowledged that there are large numbers of people with Albanian origins within Turkey, more so than in Albania and Kosovo combined and are aware of their influence and impact on domestic Turkish politics. In Gallup polls conducted in recent times, Turkey is viewed as a "friendly country" with a positive image amongst a large majority of people in Albania, Kosovo and the Republic of Macedonia which contains a sizable Albanian minority.
Europe.
Approximately 1 million are dispersed throughout the rest of Europe.These are mainly refugees from Kosovo that migrated during the Kosovo war.
During the Kosovo war in 1999, many Kosovo Albanians sought asylum in the Federal Republic of Germany. By the end of 1999, the
number of Kosovo
Albanians in Germany was about 480,000, about 100,000 had returned voluntarily after the war in their homeland or been forcibly removed.the cities with the largest population of Germans of Albanian descent are the metropolitan regions of Berlin, Hamburg, Munich and Stuttgart. In Berlin in 1999, there were about 25,000 Albanians, the number dropped because of remigration and Germany's general population decline.
In Sweden Albanians number approximately 54,000.
There is an Albanian minority in Ukraine known as Albantsi, Ukrainian: Албанці.They descend from Albanian warriors who fought against the Ottoman Empire in the Russo-Turkish wars and were allowed to settle in the Russian Empire in the 18th century.
As of 2011 there are approximately 100,000 Albanians living in the United Kingdom.
The actual number of the Albanian population in Romania is unofficially estimated at around 10,000 persons.Most members of the community live in Bucharest, while the rest mainly live in larger urban centers such as Timișoara, Iași, Constanțaand Cluj-Napoca.
Most families are Orthodox and trace their origins to the area around Korçë.
Egypt.
In Egypt there are 18,000 Albanians, mostly Tosk speakers. Many are descendants of the Janissary of Muhammad Ali Pasha, an Albanian who became Wāli, and self-declared Khedive of Egypt and Sudan. In addition to the dynasty that he established, a large part of the former Egyptian and Sudanese aristocracy was of Albanian origin. The Albanian Bektashi community had its own "tekke" in Egypt, the famed "Magauri tekke" on the outskirts of Cairo, which was headed by Baba Ahmet Sirri Glina of Përmet. Albanian Sunnis, Bektashis and Orthodox Christians were all represented in this diaspora, whose members at some point included major Renaissance figures ("Rilindasit"), including Fan Noli who lived in Egypt for a time. Nationalist figures and writers such as Thimi Mitko, Spiro Dine, Filip Shiroka, Jani Vruho, Nikolla Naço, Anastas Avramidhi, Thoma Kreini, Thoma Avrami, Thanas Tashko, Stefan Zurani, Andon Zako Çajupi, Mihal Zallari, Milo Duçi, Loni Logori, Fan Noli, Aleksander Xhuvani, George Adamidis Frashëri and many others were all active in Egypt at some point in their careers. Some of them used it as temporary solution before moving to US or elsewhere, while some other settled permanently.In 1907, with the initiative of Mihal Turtulli, Jani Vruho, and Thanas Tashko, the Albanian community send a promemorium to the Second Hague Conference for Peace, demanding support for the civic rights of the Albanian population under the oppression of Abdul Hamid II. Thanas Tashko would represent the community in the Congress of Manastir of 1908. while Loni Logori in the Congress of Elbasan of 1909.With the ascension of Gamal Abdel Nasser in Egypt and rise of Arab nationalism, the last remnants of Albanian community there were forced to leave.
Overseas.
According to the 2010 American Community Survey, there are 193,813 Albanian Americans (American citizens of full or partial Albanian descent).
In Australia and New Zealand there are a total of 22,000 Albanians. Albanians are also known to reside in China, India, Iran, Japan, Korea, Malaysia, Pakistan and Singapore, but the numbers are generally small. Albanians have been present in Arab countries such as Iraq, Jordan, Lebanon and Syria for about five centuries as a legacy of Ottoman Turkish rule.
Language.
The Albanian language forms a separate branch of the Indo-European languages family tree. A traditional view, based mainly on the territory where the languages were spoken, links the origin of Albanian with Illyrian. Not enough Illyrian archaeological evidence is left behind however, to come to a definite conclusion. Another theory links the Albanian as originating from the Thracian language: however this theory takes exception to the territory, since the Thracian language was spoken in an area distinct from Albania, and no significant population movements have been recorded in the period when the shift from one language to the other is supposed to have occurred.
Albanian in a revised form of the Tosk dialect is the official language of Albania and Kosovo; and is official in the municipalities where there are more than 20% ethnic Albanian inhabitants in the Republic of Macedonia. It is also an official language of Montenegro where it is spoken in the municipalities with ethnic Albanian populations.
Religion.
The Albanians first appear in the historical record in Byzantine sources of the late 11th century. At this point, they were already fully Christianized. All Albanians were Orthodox Christians until the middle of the 13th century when the Ghegs were converted to Catholicism as a mean to resist the Slavs. Christianity was later overtaken by Islam, which kept the scepter of the major religion during the period of Ottoman Turkish rule from the 15th century until 1912. Eastern Orthodox Christianity and Roman Catholicism continued to be practiced with less frequency.
During the 20th century the monarchy and later the totalitarian state followed a systematic secularization of the nation and the national culture. This policy was chiefly applied within the borders of the current Albanian state. It produced a secular majority in the population. All forms of Christianity, Islam and other religious practices were prohibited except for old non-institutional pagan practices in the rural areas, which were seen as identifying with the national culture. The current Albanian state has revived some pagan festivals, such as the Spring festival () held yearly on March 14 in the city of Elbasan. It is a national holiday.
According to 2011 census, 58.79% of Albania adheres to Islam, making it the largest religion in the country. The majority of Albanian Muslims are Secular Sunni with a significant Bektashi Shia minority. Christianity is practiced by 16.99% of the population, making it the second largest religion in the country. The remaining population is either irreligious or belongs to other religious groups. Before World War II, there was given a distribution of 70% Muslims, 20% Eastern Orthodox, and 10% Roman Catholics. Today, Gallup Global Reports 2010 shows that religion plays a role in the lives of only 39% of Albanians, and ranks Albania the thirteenth least religious country in the world.
The results of the 2011 census, however, have been criticized as questionable on a number of grounds, and have been said to drastically underrepresent the number of Orthodox, Bektashi and irreligious Albanians, with problems including whole communities reporting that they had not been contacted, workers filling out questions without even asking the respondents and a drastic difference between the final results and the preliminary results with regard to religion (which showed over 70% declining to answer the question about religion).
The Communist regime that took control of Albania after World War II persecuted and suppressed religious observance and institutions and entirely banned religion to the point where Albania was officially declared to be the world's first atheist state. Religious freedom has returned to Albania since the regime's change in 1992. Albanian Muslim populations (mainly secular and of the Sunni branch) are found throughout the country whereas Albanian Orthodox Christians as well as Bektashis are concentrated in the south; Roman Catholics are found primarily in the north of the country.
For part of its history, Albania has also had a Jewish community. Members of the Jewish community were saved by a group of Albanians during the Nazi occupation. Many left for Israel c. 1990 – 1992 after borders were open due to fall of communist regime in Albania, while in modern times about 200 Albanian Jews still live in Albania.
Culture.
Albanian folk music displays a variety of influences. Albanian folk music traditions differ by region, with major stylistic differences between the traditional music of the Ghegs in the north and Tosks in the south. Modern popular music has developed around the centers of Korca, Shkodër and Tirana. Since the 1920s, some composers such as Fan S. Noli have also produced works of Albanian classical music.

</doc>
<doc id="2928" url="https://en.wikipedia.org/wiki?curid=2928" title="Association for Computing Machinery">
Association for Computing Machinery

The Association for Computing Machinery (ACM) is an international learned society for computing. It was founded in 1947 and is the world's largest scientific and educational computing society. It is a not-for-profit professional membership group. Its membership is more than 100,000 as of 2011. Its headquarters are in New York City.
The ACM and the IEEE Computer Society are the umbrella organizations for US academic and scholarly interests in computing. Unlike the IEEE, the ACM is solely dedicated to computing.
Activities.
ACM is organized into over 171 local chapters and 37 Special Interest Groups (SIGs), through which it conducts most of its activities. Additionally, there are over 500 college and university chapters. The first student chapter was founded in 1961 at the University of Louisiana at Lafayette.
Many of the SIGs, like SIGGRAPH, SIGPLAN, SIGCSE and SIGCOMM, sponsor regular conferences which have become famous as the dominant venue for presenting innovations in certain fields. The groups also publish a large number of specialized journals, magazines, and newsletters.
ACM also sponsors other computer science related events such as the worldwide ACM International Collegiate Programming Contest (ICPC), and has sponsored some other events such as the chess match between Garry Kasparov and the IBM Deep Blue computer.
Services.
Publications.
ACM publishes several journals and magazines with ACM Communications and ACM Queue as mouthpieces.
ACM publishes a prestigious academic journal, "Journal of the ACM", and general magazines for computer professionals, "Communications of the ACM" (also known as "Communications" or "CACM") and "Queue". Other publications of the ACM include:
Although "Communications" no longer publishes primary research, and is not considered a prestigious venue, many of the great debates and results in computing history have been published in its pages.
ACM has made almost all of its publications available to paid subscribers online at its Digital Library and also has a Guide to Computing Literature. Individual members additionally have access to Safari Books Online and Books24x7. ACM also offers insurance, online courses, and other services to its members.
In 1997, ACM Press published "Wizards and Their Wonders: Portraits in Computing" (ISBN 0897919602), written by Christopher Morgan, with new photographs by Louis Fabian Bachrach. The book is a collection of historic and current portrait photographs of figures from the computer industry.
Portal and Digital Library.
The ACM Portal is an online service of the ACM. 
Its core are two main sections: ACM Digital Library and the ACM Guide to Computing Literature.
The ACM Digital Library is the full-text collection of all articles published by the ACM in its articles, magazines and conference proceedings. The Guide is a bibliography in computing with over one million entries.
The ACM Digital Library contains a comprehensive archive starting in the 1950s of the organization's journals, magazines, newsletters and conference proceedings. Online services include a forum called Ubiquity and Tech News digest. There is an extensive underlying bibliographic database containing key works of all genres from all major publishers of computing literature. This secondary database is a rich discovery service known as The ACM Guide to Computing Literature.
ACM adopted a hybrid Open Access (OA) publishing model in 2013. Authors who do not choose to pay the OA fee must grant ACM publishing rights by either a copyright transfer agreement or a publishing license agreement.
ACM was a "green" publisher before the term was invented. Authors may post documents on their own websites and in their institutional repositories with a link back to the ACM Digital Library's permanently maintained Version of Record.
All metadata in the Digital Library is open to the world, including abstracts, linked references and citing works, citation and usage statistics, as well as all functionality and services. Other than the free articles, the full-texts are accessed by subscription.
Competition.
ACM's primary historical competitor has been the IEEE Computer Society, which is the largest subgroup of the Institute of Electrical and Electronics Engineers. The IEEE focuses more on hardware and standardization issues than theoretical computer science, but there is considerable overlap with ACM's agenda. They occasionally cooperate on projects like developing computing curricula. Some of the major awards in Computer science are given jointly by ACM and the IEEE–CS.
There is also a mounting challenge to the ACM's publication practices coming from the open access movement. Some authors see a centralized peer–review process as less relevant and publish on their home pages or on unreviewed sites like arXiv. Other organizations have sprung up which do their peer review entirely free and online, such as Journal of Artificial Intelligence Research (JAIR), Journal of Machine Learning Research (JMLR) and the Journal of Research and Practice in Information Technology.
Membership grades.
In addition to student and regular members, ACM has several advanced membership grades to recognize those with multiple years of membership and "demonstrated performance that sets them apart from their peers".
Fellows.
The ACM Fellows Program was established by Council of the Association for Computing Machinery in 1993 "to recognize and honor outstanding ACM members for their achievements in computer science and information technology and for their significant contributions to the mission of the ACM."
There are presently about 958 Fellows out of about 75,000 professional members.
Distinguished Members.
In 2006 ACM began recognizing two additional membership grades, one which was called Distinguished Members. Distinguished Members (Distinguished Engineers, Distinguished Scientists, and Distinguished Educators) have at least 15 years of professional experience and 5 years of continuous ACM membership and "have made a significant impact on the computing field". Note that in 2006 when the Distinguished Members first came out, one of the three levels was called "Distinguished Member" and was changed about two years later to "Distinguished Educator". Those who already had the Distinguished Member title had their titles changed to one of the other three titles.
Senior Members.
Also in 2006, ACM began recognizing Senior Members. Senior Members have ten or more years of professional experience and 5 years of continuous ACM membership.
Chapters.
ACM has three kinds of chapters: Special Interest Groups, Professional Chapters, and Student Chapters.
As of 2011, ACM has professional & SIG Chapters in 56 countries.
As of 2014, there exist ACM student chapters in 41 different countries.
Conferences.
ACM sponsors numerous conferences listed below. Most of the special interest groups also have an annual conference. ACM conferences are often very popular publishing venues and are therefore very competitive. For example, the 2007 SIGGRAPH conference attracted about 30000 visitors, and CIKM only accepted 15% of the long papers that were submitted in 2005.
The ACM is a co–presenter and founding partner of the Grace Hopper Celebration of Women in Computing (GHC) with the Anita Borg Institute for Women and Technology.
There are some conferences hosted by ACM student branches; this includes Reflections Projections, which is hosted by UIUC ACM. . In addition, ACM sponsors regional conferences. Regional conferences facilitate increased opportunities for collaboration between nearby institutions and they are well attended.
Awards.
The ACM presents or co–presents a number of awards for outstanding technical and professional achievements and contributions in computer science and information technology.
Leadership.
The President of the ACM for 2014–2016 is Alexander L. Wolf of Imperial College London, UK. He is the successor of Vint Cerf (2012–2014), an American computer scientist who is recognized as one of "the fathers of the Internet"; Alain Chesnais (2010–2012), a French citizen living in Toronto, Canada, where he runs his company named Visual Transitions; and Dame Wendy Hall of the University of Southampton, UK (2008-2010).
ACM is led by a Council consisting of the President, Vice–President, Treasurer, Past President, SIG Governing Board Chair, Publications Board Chair, three representatives of the SIG Governing Board, and seven Members–At–Large. This institution is often referred to simply as "Council" in "Communications of the ACM".
Infrastructure.
ACM has five “Boards” that make up various committees and subgroups, to help Headquarters staff maintain quality services and products. These boards are as follows:
ACM Council on Women in Computing.
ACM–W, the ACM council on women in computing, supports, celebrates, and advocates internationally for the full engagement of women in computing. ACM–W's main programs are regional celebrations of women in computing, ACM-W chapters, and scholarships for women CS students to attend research conferences. In India and Europe these activities are overseen by ACM-W India and ACM-W Europe respectively. ACM-W collaborates with organizations such as the Anita Borg Institute, the National Center for Women and IT, CRA-W.
Athena Lectures.
The ACM-W gives an annual Athena Lecturer Award to honor outstanding women researchers who have made fundamental contributions to computer science. This program began in 2006. Speakers are nominated by SIG officers.

</doc>
<doc id="2934" url="https://en.wikipedia.org/wiki?curid=2934" title="Anabaptists">
Anabaptists

Anabaptism (from Neo-Latin "anabaptista", from the Greek : "re-" and "baptism") is a Christian movement which traces its origins to the Radical Reformation. Some consider this movement to be an offshoot of Protestantism, while others see it as distinct.
Anabaptists are Christians who believe in delaying baptism until the candidate confesses his or her faith in Christ, as opposed to being baptized as an infant. The Amish, Hutterites, and Mennonites are direct descendants of the movement. Schwarzenau Brethren, Bruderhof, and the Apostolic Christian Church are considered later developments among the Anabaptists.
The name "Anabaptist" means "one who baptizes again" and was given them by their persecutors in reference to the practice of re-baptizing converts who already had been baptized as infants. Anabaptists required that baptismal candidates be able to make their own confessions of faith and so rejected baptism of infants. The early members of this movement did not accept the name "Anabaptist", claiming that infant baptism was unscriptural and therefore null and void; thus, the baptizing of believers was not a re-baptism but in fact their first real baptism. Balthasar Hubmaier wrote:
Anabaptists were heavily persecuted during the 16th century and into the 17th century because of their views on the nature of baptism and other issues, by both Magisterial Protestants and Roman Catholics.
Most Anabaptists adhered to a literal interpretation of the Sermon on the Mount, which precluded taking oaths, participating in military actions, and participating in civil government. Some who practiced re-baptism, however, felt otherwise. They were thus technically Anabaptists, even though conservative Amish, Mennonites, and Hutterites and some historians tend to consider them as outside of true Anabaptism. Conrad Grebel wrote in a letter to Thomas Müntzer in 1524:
Origins.
Medieval forerunners.
Anabaptists began with the Radical Reformers in the 16th century, yet certain people and groups may still legitimately be considered their forerunners because of a similar approach to the interpretation and application of the Bible. Petr Chelčický, a 15th-century Bohemian reformer, taught most of the beliefs considered integral to Anabaptist theology. Medieval antecedents may include the Brethren of the Common Life, the Hussites, Dutch Sacramentists, and some forms of monasticism. The Waldensians also represent a faith similar to the Anabaptists.
In the following points, Anabaptists who held to a literal interpretation of the Sermon on the Mount resembled the medieval dissenters:
Zwickau prophets and the German Peasants' War.
On December 27, 1521, three "prophets" appeared in Wittenberg from Zwickau who were influenced by (and, in turn, influencing) Thomas Müntzer—Thomas Dreschel, Nicholas Storch, and Mark Thomas Stübner—preaching an apocalyptic, radical alternative to Lutheranism. Preaching such as that done by the "prophets" helped to stir the feelings concerning the social crisis which erupted in the German Peasants' War in southern Germany in 1525 as a revolt against feudal oppression. Under the leadership of Müntzer, it became a war against all constituted authorities and an attempt to establish by revolution an ideal Christian commonwealth, with absolute equality and the community of goods. The Zwickau prophets were not Anabaptists (that is, they did not practice "re-baptism"); nevertheless, the prevalent social inequities and the preaching of men such as this have been seen as laying the foundation for the Anabaptist movement. The social ideals of the Anabaptist movement coincided closely with those of the German Peasants' War, although studies have found a very low percentage of later Anabaptists to have been active participants in the peasant uprising.
Views on origins.
Research on the origins of the Anabaptists has been tainted both by the attempts of their enemies to slander them and by the attempts of their supporters to vindicate them. It was long popular to simply lump all Anabaptists as Munsterites and radicals associated with the Zwickau Prophets, Jan Matthys, John of Leiden, and Thomas Müntzer. Those desiring to correct this error tended to over-correct and deny all connections between the larger Anabaptist movement and the most radical elements.
The modern era of Anabaptist historiography arose with the work of Roman Catholic scholar Carl Adolf Cornelius' publication of "Die Geschichte des Münsterischen Aufruhrs" (The History of the Münster Uprising) in 1855. Baptist historian Albert Henry Newman (1852–1933), who Harold S. Bender said occupied "first position in the field of American Anabaptist historiography," made a major contribution with his "A History of Anti-Pedobaptism."
Though a number of theories exist concerning origins, the three main ones are:
Monogenesis.
A number of scholars ("e.g.", Harold S. Bender, William Estep, Robert Friedmann ) have seen the Anabaptist movement as radiating from the Swiss Brethren movement of Conrad Grebel, Felix Manz, George Blaurock, et al. They generally held that Anabaptism had its origins in Zürich, and that the Anabaptism of the Swiss Brethren was transmitted to southern Germany, Austria, the Netherlands, and northern Germany, where it developed into its various branches. The monogenesis theory usually rejects the Münsterites and other radicals from the category of true Anabaptists. In the monogenesis view the time of origin is January 21, 1525, when Conrad Grebel baptized George Blaurock, and Blaurock in turn baptized several others immediately. These baptisms were the first "re-baptisms" known in the movement and therefore this remains the most popular date posited for the establishment of Anabaptism.
Polygenesis.
James M. Stayer, Werner O. Packull, and Klaus Deppermann disputed the idea of a single origin of Anabaptists in a 1975 essay entitled "From Monogenesis to Polygenesis," suggesting that February 24, 1527, at Schleitheim is the proper date of the origin of Anabaptism. On this date the Swiss Brethren wrote a declaration of belief called the Schleitheim Confession. The authors of the essay noted the agreement among previous Anabaptist historians on polygenesis, even when disputing the date for a single starting point: "Hillerbrand and Bender (like Holl and Troeltsch) were in agreement that there was a single dispersion of Anabaptism ..., which certainly ran through Zurich. The only question was whether or not it went back further to Saxony." After criticizing the standard polygenetic history, the authors found six groups in early Anabaptism which could be collapsed into three originating "points of departure": "South German Anabaptism, the Swiss Brethren, and the Melchiorites." According to their polygenesis theory, South German–Austrian Anabaptism "was a diluted form of Rhineland mysticism," Swiss Anabaptism "arose out of Reformed congregationalism", and Dutch Anabaptism was formed by "Social unrest and the apocalyptic visions of Melchior Hoffman". As examples of how the Anabaptist movement was influenced from sources other than the Swiss Brethren movement, mention has been made of how Pilgram Marpeck's "Vermanung" of 1542 was deeply influenced by the "Bekenntnisse" of 1533 by Münster theologian Bernhard Rothmann. Melchior Hoffman influenced the Hutterites when they used his commentary on the Apocalypse shortly after he wrote it.
Others who have written in support of polygensis include Grete Mecenseffy and Walter Klaassen, who established links between Thomas Müntzer and Hans Hut. In another work, Gottfried Seebaß and Werner Packull showed the influence of Thomas Müntzer on the formation of South German Anabaptism. Similarly, author Steven Ozment linked Hans Denck and Hans Hut with Thomas Müntzer, Sebastian Franck, and others. Author Calvin Pater showed how Andreas Karlstadt influenced Swiss Anabaptism in various areas, including his view of Scripture, doctrine of the church, and views on baptism.
Apostolic succession.
Baptist successionists have, at times, pointed to 16th-century Anabaptists as part of an apostolic succession of churches ("church perpetuity") from the time of Christ. This view is held by some Baptists, some Mennonites, and a number of "true church" movements.
The opponents of the Baptist successionism theory emphasize that these non-Catholic groups clearly differed from each other, that they held some heretical views, or that the groups had no connection with one another and had origins that were separate both in time and in place.
A different strain of successionism is the theory that the Anabaptists are of Waldensian origin. Some hold the idea that the Waldensians are part of the apostolic succession, while others simply believe they were an independent group out of whom the Anabaptists arose. Ludwig Keller, Thomas M. Lindsay, H. C. Vedder, Delbert Grätz, John T. Christian and Thieleman J. van Braght (author of Martyrs Mirror) all held, in varying degrees, the position that the Anabaptists were of Waldensian origin.
History.
Switzerland.
Anabaptism in Switzerland began as an offshoot of the church reforms instigated by Ulrich Zwingli. As early as 1522 it became evident that Zwingli was on a path of reform preaching when he began to question or criticize such Catholic practices as tithes, the mass, and even infant baptism. Zwingli had gathered a group of reform-minded men around him, with whom he studied classical literature and the scriptures. However, some of these young men began to feel that Zwingli was not moving fast enough in his reform. The division between Zwingli and his more radical disciples became apparent in an October, 1523 disputation held in Zurich. When the discussion of the mass was about to be ended without making any actual change in practice, Conrad Grebel stood up and asked "what should be done about the mass?" Zwingli responded by saying the council would make that decision. At this point, Simon Stumpf, a radical priest from Hongg, answered saying, "The decision has already been made by the Spirit of God."
This incident illustrated clearly that Zwingli and his more radical disciples had different expectations. To Zwingli, the reforms would only go as fast as the city Council allowed them. To the radicals, the council had no right to make that decision, but rather the Bible was the final authority of church reform. Feeling frustrated, some of them began to meet on their own for Bible study. As early as 1523, William Reublin began to preach against infant baptism in villages surrounding Zurich, encouraging parents to not baptize their children.
Seeking fellowship with other reform-minded people, the radical group wrote letters to Martin Luther, Andreas Karlstadt, and Thomas Müntzer. Felix Manz began to publish some of Karlstadt's writings in Zurich in late 1524. By this time the question of infant baptism had become agitated and the Zurich council had instructed Zwingli to meet weekly with those who rejected infant baptism "until the matter could be resolved." Zwingli broke off the meetings after two sessions, and Felix Manz petitioned the Council to find a solution, since he felt Zwingli was too hard to work with. The council then called a meeting for January 17, 1525.
The Council ruled in this meeting that all who continued to refuse to baptize their infants should be expelled from Zurich if they did not have them baptized within one week. Since Conrad Grebel had refused to baptize his daughter Rachel, born on January 5, 1525, the Council decision was extremely personal to him and others who had not baptized their children. Thus, when sixteen of the radicals met on Saturday evening, January 21, 1525, the situation seemed particularly dark. The Hutterian Chronicle records the event:
After Blaurock was baptized, he in turn baptized others at the meeting. Even though some had rejected infant baptism before this date, these baptisms marked the first re-baptisms of those who had been baptized as infants and thus, technically, Swiss Anabaptism was born on that day.
Tyrol.
Anabaptism appears to have come to Tyrol through the labors of George Blaurock. Similar to the German Peasants' War, the Gasmair uprising set the stage by producing a hope for social justice. Michael Gasmair had tried to bring religious, political, and economical reform through a violent peasant uprising, but the movement was squashed. Although little hard evidence exists of a direct connection between Gasmair's uprising and Tyrolian Anabaptism, at least a few of the peasants involved in the uprising later became Anabaptists. While a connection between a violent social revolution and non-resistant Anabaptism may be hard to imagine, the common link was the desire for a radical change in the prevailing social injustices. Disappointed with the failure of armed revolt, Anabaptist ideals of an alternative peaceful, just society probably resonated on the ears of the disappointed peasants.
Before Anabaptism proper was introduced to South Tyrol, Protestant ideas had been propagated in the region by men such as Hans Vischer, a former Dominican. Some of those who participated in conventicles where Protestant ideas were presented later became Anabaptists. As well, the population in general seemed to have a favorable attitude towards reform, be it Protestant or Anabaptist. George Blaurock appears to have preached itinerantly in the Puster Valley region in 1527, which most likely was the first introduction of Anabaptist ideas in the area. Another visit through the area in 1529 reinforced these ideas, but he was captured and burned at the stake in Klausen on September 6, 1529.
Jacob Hutter was one of the early converts in South Tyrol, and later became a leader among the Hutterites, who received their name from him. Hutter made several trips between Moravia and Tyrol, and most of the Anabaptists in South Tyrol ended up emigrating to Moravia because of the fierce persecution unleashed by Ferdinand I. In November 1535, Hutter was captured near Klausen and taken to Innsbruck where he was burned at the stake on February 25, 1536. By 1540 Anabaptism in South Tyrol was beginning to die out, largely because of the emigration to Moravia of the converts because of incessant persecution.
The Low Countries.
Melchior Hoffman is credited with the introduction of Anabaptist ideas into the Low Countries. Hoffman had picked up Lutheran and Reformed ideas, but on 23 April 1530 he was "re-baptized" at Strasbourg and within two months had gone to Emden and baptized about 300 persons. For several years Hoffman preached in the Low Countries until he was arrested and imprisoned at Strasbourg, where he died about 10 years later. Hoffman's apocalyptic ideas were indirectly related to the Münster Rebellion, even though he was "of a different spirit." Obbe and Dirk Philips had been baptized by disciples of Jan Matthijs, but were opposed to the violence that occurred at Münster. Obbe later became disillusioned with Anabaptism and withdrew from the movement in about 1540, but not before ordaining David Joris, his brother Dirk, and Menno Simons, the latter from whom the Mennonites received their name. David Joris and Menno Simons parted ways, with Joris placing more emphasis on "spirit and prophecy," while Menno emphasized the authority of the Bible. For the Mennonite side, the emphasis on the "inner" and "spiritual" permitted compromise to "escape persecution," while to the Joris side, the Mennonites were under the "dead letter of the Scripture." Because of persecution and expansion, many of the Low Country Mennonites emigrated to Prussia, and from there to Ukraine (which at the time was part of Russia). In the late 1800s, many of the Russian Mennonites emigrated to the prairie states and provinces of the U.S. and Canada; to Mexico; to Belize, and to South America (especially Paraguay, Bolivia, Argentina, and Brazil) where thousands of them still live in colonies.
Moravia.
Although Moravian Anabaptism was a transplant from other areas of Europe, Moravia soon became a center for the growing movement, largely because of the greater religious tolerance found there. Hans Hut was an early evangelist in the area, with one historian crediting him with baptizing more converts in two years than all the other Anabaptist evangelists put together. The coming of Balthasar Hübmaier to Nikolsburg was a definite boost for Anabaptist ideas to the area. With the great influx of religious refugees from all over Europe, many variations of Anabaptism appeared in Moravia, with Jarold Zeman documenting at least ten slightly different versions. Soon, one-eyed Jacob Wiedemann appeared at Nikolsburg, and began to teach the pacifistic convictions of the Swiss Brethren, on which Hübmaier had been less authoritative. This eventually led to a division between the "Schwertler" (sword-bearing) and the "Stäbler" (staff-bearing). Wiedemann and those with him also promoted the practice of community of goods. With orders from the lords of Liechtenstein to leave Nikolsburg, about 200 "Stäbler" withdrew to Moravia to form a community at Austerlitz.
Persecution in South Tyrol brought many refugees to Moravia, many of whom formed into communities that practiced community of goods. Jacob Hutter was instrumental in organizing these into what became known as the Hutterites. But others came from Silesia, Switzerland, German lands, and the Low Countries. With the passing of time and persecution, all the other versions of Anabaptism eventually died out in Moravia, leaving only the Hutterites. Even the Hutterites were eventually dissipated by persecution, with a remnant fleeing to Transylvania, then to the Ukraine, and eventually to North America in 1874.
South Germany.
South German Anabaptism had its roots in German mysticism. Andreas Karlstadt, who first worked alongside Martin Luther, is seen as a forerunner of South German Anabaptism because of his reforming theology that rejected many Catholic practices, including infant baptism. However, Karlstadt is not known to have been "rebaptized", nor to have taught it. Hans Denck and Hans Hut, both with German Mystical background (in connection with Thomas Muntzer) both accepted "rebaptism", but Denck eventually backed off from the idea under pressure. Hans Hut is said to have brought more people into early Anabaptism than all the other Anabaptist evangelists of his time put together. However, there may have been confusion about what his baptism (at least some of the times it was done by making the sign of the Tau on the forehead) may have meant to the recipient. Some seem to have taken it as a sign by which they would escape the apocalyptical revenge of the Turks that Hut predicted. Hut even went so far as to predict a 1528 coming of the kingdom of God. When the prediction failed, some of his converts became discouraged and left the Anabaptist movement. The large congregation of Anabaptists at Augsburg fell apart (partly because of persecution) and those who stayed with Anabaptist ideas were absorbed into Swiss and Moravia Anabaptist congregations. Pilgram Marpeck was another notable leader in early South German Anabaptism.
Persecutions and migrations.
Roman Catholics and Protestants alike persecuted the Anabaptists, resorting to torture and execution in attempts to curb the growth of the movement. The Protestants under Zwingli were the first to persecute the Anabaptists, with Felix Manz becoming the first martyr in 1527. On May 20, 1527, Roman Catholic authorities executed Michael Sattler. King Ferdinand declared drowning (called the "third baptism") "the best antidote to Anabaptism". The Tudor regime, even the Protestant monarchs (Edward VI of England and Elizabeth I of England), persecuted Anabaptists as they were deemed too radical and therefore a danger to religious stability. The persecution of Anabaptists was condoned by ancient laws of Theodosius I and Justinian I that were passed against the Donatists, which decreed the death penalty for any who practiced rebaptism. Martyrs Mirror, by Thieleman J. van Braght, describes the persecution and execution of thousands of Anabaptists in various parts of Europe between 1525 and 1660. Continuing persecution in Europe was largely responsible for the mass emigrations to North America by Amish, Hutterites, and Mennonites.
Types.
Different types exist among the Anabaptists, although the categorizations tend to vary with the scholar's viewpoint on origins. Estep claims that in order to understand Anabaptism, one must "distinguish between the Anabaptists, inspirationists, and rationalists." He classes the likes of Blaurock, Grebel, Balthasar Hubmaier, Manz, Marpeck, and Simons as Anabaptists. He groups Müntzer, Storch, et al. as inspirationists, and anti-trinitarians such as Michael Servetus, Juan de Valdés, Sebastian Castellio, and Faustus Socinus as rationalists. Mark S. Ritchie follows this line of thought, saying, "The Anabaptists were one of several branches of 'Radical' reformers (i.e. reformers that went further than the mainstream Reformers) to arise out of the Renaissance and Reformation. Two other branches were Spirituals or Inspirationists, who believed that they had received direct revelation from the Spirit, and rationalists or anti-Trinitarians, who rebelled against traditional Christian doctrine, like Michael Servetus."
Those of the polygenesis viewpoint use "Anabaptist" to define the larger movement, and include the inspirationists and rationalists as true Anabaptists. James M. Stayer used the term "Anabaptist" for those who "rebaptized" persons already "baptized" in infancy. Walter Klaassen was perhaps the first Mennonite scholar to define "Anabaptists" that way in his 1960 Oxford dissertation. This represents a rejection of the previous standard held by Mennonite scholars such as Bender and Friedmann.
Another method of categorization acknowledges regional variations, such as Swiss Brethren (Grebel, Manz), Dutch and Frisian Anabaptism (Menno Simons, Dirk Philips), and South German Anabaptism (Hübmaier, Marpeck).
Historians and sociologists have made further distinctions between radical Anabaptists, who were prepared to use violence in their attempts to build a New Jerusalem, and their pacifist brethren, later broadly known as Mennonites. Radical Anabaptist groups included the Münsterites, who occupied and held the German city of Münster in 1534–35, and the Batenburgers, who persisted in various guises as late as the 1570s.
Spirituality.
Charismatic manifestations.
Within the inspirationist wing of the Anabaptist movement, it was not unusual for charismatic manifestations to appear, such as dancing, falling under the power of the Holy Spirit, "prophetic processions" (at Zurich in 1525, at Munster in 1534 and at Amsterdam in 1535), and speaking in tongues. In Germany some Anabaptists, "excited by mass hysteria, experienced healings, glossolalia, contortions and other manifestations of a camp-meeting revival". The Anabaptist congregations that later developed into the Mennonite and Hutterite churches tended not to promote these manifestations, but did not totally reject the miraculous. Pilgram Marpeck, for example, wrote against the exclusion of miracles: "Nor does Scripture assert this exclusion... God has a free hand even in these last days." Referring to some who had been raised from the dead, he wrote: "Many of them have remained constant, enduring tortures inflicted by sword, rope, fire and water and suffering terrible, tyrannical, unheard-of deaths and martyrdoms, all of which they could easily have avoided by recantation. Moreover one also marvels when he sees how the faithful God (Who, after all, overflows with goodness) raises from the dead several such brothers and sisters of Christ after they were hanged, drowned, or killed in other ways. Even today, they are found alive and we can hear their own testimony... Cannot everyone who sees, even the blind, say with a good conscience that such things are a powerful, unusual, and miraculous act of God? Those who would deny it must be hardened men". The Hutterite Chronicle and The Martyrs Mirror record several accounts of miraculous events, such as when a man named Martin prophesied while being led across a bridge to his execution in 1531: "...this once yet the pious are led over this bridge, but no more hereafter." Just "a short time afterwards such a violent storm and flood came that the bridge was demolished".
Holy Spirit leadership.
The Anabaptists insisted upon the "free course" of the Holy Spirit in worship, yet still maintained it all must be judged according to the Scriptures. The Swiss Anabaptist document titled "Answer of Some Who Are Called (Ana-)Baptists – Why They Do Not Attend the Churches". One reason given for not attending the state churches was that these institutions forbade the congregation to exercise spiritual gifts according to "the Christian order as taught in the gospel or the Word of God in 1 Corinthians 14." "When such believers come together, 'Everyone of you (note every one) hath a psalm, hath a doctrine, hath a revelation, hath an interpretation', and so on. When someone comes to church and constantly hears only one person speaking, and all the listeners are silent, neither speaking nor prophesying, who can or will regard or confess the same to be a spiritual congregation, or confess according to 1 Corinthians 14 that God is dwelling and operating in them through His Holy Spirit with His gifts, impelling them one after another in the above-mentioned order of speaking and prophesying."
Today.
Anabaptists.
Several existing denominational bodies may be regarded as the successors of the continental Anabaptists: Mennonites, Amish, Hutterites, Schwarzenau Brethren, River Brethren and to some extent the Bruderhof Communities. Sometimes the Apostolic Christian Church is seen as "Neutäufer" ("Neo-Anabaptist"). Some historical connections have been demonstrated for all of these spiritual descendants, though perhaps not as clearly as the noted institutionally lineal descendants.
Although many see the more well-known Anabaptist groups (Amish, Hutterites and Mennonites) as ethnic groups, only the Amish and the Hutterites today are composed almost totally of descendants of the continental Anabaptists, while among the Mennonites there are Ethnic Mennonites and others who are not. Brethren groups have mostly lost their ethnic distinctiveness.
Total worldwide membership of the Mennonite, Brethren in Christ and related churches totals 1,616,126 (as of 2009) with about 60 percent in Africa, Asia and Latin America. In 2015 there were some 300,000 Amish, more than 200,000 "Russian" Mennonites in Latin America and some 60,000 to 80.000 Old Order Mennonites, who have preserved their ethnicity, their German dialects (Pennsylvania German, Plautdietsch, Hutterisch), Plain dress and many other old traditions.
Similar groups.
The Bruderhof Communities were founded in Germany by Eberhard Arnold in 1920, establishing and organisationally joining the Hutterites in 1930. The group moved to England after the Gestapo confiscated their property in 1933, and subsequently to Paraguay to avoid military conscription, and by settlement then moved to USA after World War II. They are not recognized by more conservative Hutterites.
Groups deriving from the Schwarzenau Brethren, often called German Baptists, while not directly descended from the 16th-century Anabaptists, are usually considered Anabaptist because of an almost identical doctrine and practice. The modern-day Brethren movement is a combination of Anabaptism and Radical Pietism.
The relations between Baptists and Anabaptists were early strained. In 1624, the then five existing Baptist churches of London issued a condemnation of the Anabaptists. Puritans of England and their Baptist branch arose independently, and although they may have been informed by Anabaptist theology, they clearly differentiate themselves from Anabaptists as seen in the London Baptist Confession of Faith A.D. 1644, "Of those Churches which are commonly (though falsely) called ANABAPTISTS;"". Moreover, Baptist historian Chris Traffanstedt maintains that Anabaptists share "some similarities with the early General Baptists, but overall these similarities are slight and not always relational. In the end, we must come to say that this group of Christians does not reflect the historical teaching of the Baptists." German Baptists are not related to the English Baptist movement and were inspired by central European Anabaptists. Upon moving to the United States, they associated with Mennonites and Quakers.
Anabaptist characters exist in popular culture, most notably Chaplain Tappman in Joseph Heller's novel "Catch-22", James in Voltaire's novella "Candide", Giacomo Meyerbeer’s opera "Le prophète" (1849), and the central character in the novel "Q", by the collective known as "Luther Blissett".
Legacy.
Common Anabaptist beliefs and practices of the 16th century continue to influence modern Christianity and Western society.
The Anabaptists were early promoters of a free church and freedom of religion (sometimes associated with separation of church and state). When it was introduced by the Anabaptists in the 15th and 16th centuries, religious freedom independent of the state was unthinkable to both clerical and governmental leaders. Religious liberty was equated with anarchy; Kropotkin traces the birth of anarchist thought in Europe to these early Anabaptist communities.
According to Estep:

</doc>
<doc id="2935" url="https://en.wikipedia.org/wiki?curid=2935" title="ANS">
ANS

Ans may refer to:
As an acronym ANS may refer to:

</doc>
<doc id="2936" url="https://en.wikipedia.org/wiki?curid=2936" title="Southeast Alaska">
Southeast Alaska

Southeast Alaska, sometimes referred to as the Alaska Panhandle, is the southeastern portion of the U.S. state of Alaska, which lies west from the northern half of the Canadian province, British Columbia. The majority of Southeast Alaska's area is part of the Tongass National Forest, the United States' largest national forest. In many places, the international border runs along the crest of the Boundary Ranges of the Coast Mountains (see Alaska boundary dispute). The region is noted for its scenery and mild rainy climate.
Geography.
Southeast Alaska is the northern terminus of the Inside Passage, a protected waterway of convoluted passages between islands and fjords, beginning in Puget Sound in Washington state. This was an important travel corridor for Tlingit and Haida Native peoples, as well as gold-rush era steamships. In modern times it is an important route for Alaska Marine Highway ferries as well as cruise ships. 
Southeast Alaska has a land area of comprising seven entire boroughs and two census areas, in addition to the portion of the Yakutat Borough lying east of 141° West longitude. Although it has only 6.14 percent of Alaska's land area, it is larger than the state of Maine, and almost as large as the state of Indiana. The Southeast Alaskan coast is roughly as long as the west coast of Canada. The 2010 census population of Southeast was 71,616 inhabitants, about 45 percent of whom were concentrated in the city of Juneau.
It includes the Tongass National Forest, Glacier Bay National Park, Admiralty Island National Monument, Misty Fjords National Monument, Sitka National Historical Park, Alaska's Inside Passage, and myriad large and small islands. The largest islands are, from North to South, Chichagof Island, Admiralty Island, Baranof Island, Kupreanof Island, Revillagigedo Island and Prince of Wales Island. Major bodies of water of Southeast Alaska include Glacier Bay, Lynn Canal, Icy Strait, Chatham Strait, Stephens Passage, Frederick Sound, Sumner Strait, and Clarence Strait.
On August 20, 1902, President Theodore Roosevelt established the Alexander Archipelago Forest Reserve, which formed the heart of the Tongass National Forest that covers most of the region.
Ecology.
Southeast Alaska is a temperate rain forest within the Pacific temperate rain forest zone, as classified by the World Wildlife Fund's ecoregion system, which extends from northern California to Prince William Sound. The most common tree species are sitka spruce and western hemlock.
Wildlife includes brown bears, black bears, the endemic Alexander Archipelago wolf, Sitka black-tailed deer, humpback whales, orcas, five species of salmon, bald eagles, harlequin ducks, scoters, and marbled murrelets.
Cities and towns.
Major cities are Juneau, Ketchikan, and Sitka. Other towns are Petersburg, Wrangell, Metlakatla, Haines, Hoonah, Angoon, Kake, Craig, Klawock, Thorne Bay, Yakutat, Skagway, and Gustavus. There are also many towns and villages with +/- 100 people, such as Baranof Warm Springs, Edna Bay, Elfin Cove, Excursion Inlet, Funter Bay, Hyder, Meyers Chuck, Pelican, Port Alexander, Port Frederick, Port Protection, and Tenakee Springs.
Culture.
This area is the traditional homeland of the Tlingit, and home of a historic settling of Haida as well as a modern settlement of Tsimshian. The region is closely connected to Seattle and the American Pacific Northwest economically and culturally.
In modern times, southeastern Alaskans can often be identified by their fashion choices, notably
Xtratuf boots, and "shirtjacs" (a garment having aspects of both shirt and jacket).
Industry.
Major industries in Southeast Alaska include commercial fishing and tourism (primarily the cruise ship industry). Logging has been an important industry in the past, but has been steadily declining with competition from other areas and the closure of the region's major pulp mills.
History.
The border between the Canadian province of British Columbia and Alaska is known as the Alaska boundary dispute, where the United States, Canada and the United Kingdom and British Columbia claimed different borderlines at the Alaskan Panhandle. While the British foreign affairs were in favour of support of the Canadian argument, the event resulted in what was thought of as a betrayal, leading to alienation of the British from the new nation of Canada.
Historian Patricia Roppel authored thirteen books and more than 100 articles on the region.
Transportation.
Due to the extremely rugged, mountainous nature of Southeastern Alaska, almost all communities (with the exception of Hyder, Skagway, and Haines) have no road connections outside of their locale, so aircraft and boats are the major means of transport. The Alaska Marine Highway passes through this region.
Air transportation.
Alaska Airlines is by far the largest air carrier in the region, with Juneau's Juneau International Airport serving as the aerial hub for all of Southeast and Ketchikan's Ketchikan International Airport serving as a secondary hub for southern Southeast Alaska. Alaska's bush airlines and air taxis serve many of the smaller and more isolated communities and villages in the regions. Many communities are accessible by air only by floatplane, as proper runways are often difficult to construct on the steep island slopes.
Marine transportation.
Southeast Alaska is primarily served by the state-run Alaska Marine Highway, which links Skagway, Haines, Hoonah, Juneau, Sitka, Petersburg, Wrangell, Ketchikan and other outlying communities with Prince Rupert, BC and Bellingham, Washington; and secondarily by the Prince of Wales Island-based Inter-Island Ferry Authority, which provides the only scheduled passenger and auto ferry service to the island. A new Authority, the Rainforest Islands Ferry Authority, was created and in 2014 may possibly operate the North End route. The Authority would connect Coffman Cove with Wrangell and Petersburg. Small companies like Sitka-based Allen Marine and other independent operators in the Lynn Canal occasionally also offer marine passenger service. Ship traffic in the area is seasonally busy with cruise ships.

</doc>
<doc id="2938" url="https://en.wikipedia.org/wiki?curid=2938" title="Algemeen Nijmeegs Studentenblad">
Algemeen Nijmeegs Studentenblad

The Algemeen Nijmeegs Studentenblad is an independent student magazine for the Radboud University Nijmegen. Founded in 1985 by members of the local student union AKKU, it is now published by the Stichting Multimedia.

</doc>
<doc id="2939" url="https://en.wikipedia.org/wiki?curid=2939" title="Alaska Interior">
Alaska Interior

The Alaska Interior covers most of the U.S. state's territory. It is largely wilderness. Mountains include Denali in the Alaska Range, the Wrangell Mountains, and the Ray Mountains. The native people of the interior are Alaskan Athabaskans.
The largest city in the interior is Fairbanks, Alaska's second-largest city, in the Tanana Valley. Other towns include North Pole, just southeast of Fairbanks, Eagle, Tok, Glennallen, Delta Junction, Nenana, Anderson, Healy and Cantwell.
Climate.
Interior Alaska experiences extreme seasonal temperature variability. Winter temperatures in Fairbanks average −12 °F (−24 °C) and summer temperatures average +62 °F (+17 °C). Temperatures there have been recorded as low as −65 °F (−54 °C) in mid-winter, and as high as +99 °F (+37 °C) in summer. Both the highest and lowest temperature records for the state were set in the Interior, with 100 °F (38 °C) in Fort Yukon and −80 °F (−64 °C) in Prospect Creek. Temperatures within a given winter are highly variable as well; extended cold snaps of forty below zero can be followed by unseasonable warmth with temperatures above freezing due to chinook wind effects.
Summers can be warm and dry for extended periods creating ideal fire weather conditions. Weak thunderstorms produce mostly dry lightning, sparking wildfires that are mostly left to burn themselves out as they are often far from populated areas. The 2004 season set a new record with over burned.
The average annual precipitation in Fairbanks is 11.3 inches (28.7 cm). Most of this comes in the form of snow during the winter. Most storms in the interior of Alaska originate in the Gulf of Alaska, south of the state, though these storms often have limited precipitation due to a rain shadow effect caused by the Alaska Range.
On clear winter nights, the aurora borealis can often be seen dancing in the sky. Like all subarctic regions, the months from May to July in the summer have no night, only a twilight during the night hours. The months of November to January have little daylight. Fairbanks receives an average 21 hours of daylight between May 10 and August 2 each summer, and an average of less than four hours of daylight between November 18 and January 24 each winter.
The interior of Alaska is largely underlined by discontinuous permafrost, which grades to continuous permafrost as the Arctic Circle is approached.
Alaska Natives.
While the vast majority of indigenous Native people of Interior Alaska are Athabaskan Indians, a significant Eskimo (Yup'ik and Iñupiaq) population resides in Fairbanks.
The federally recognized tribes of Interior Alaska: 

</doc>
<doc id="2940" url="https://en.wikipedia.org/wiki?curid=2940" title="And did those feet in ancient time">
And did those feet in ancient time

"And did those feet in ancient time" is a short poem by William Blake from the preface to his epic "Milton a Poem", one of a collection of writings known as the Prophetic Books. The date of 1804 on the title page is probably when the plates were begun, but the poem was printed c. 1808. Today it is best known as the anthem "Jerusalem", with music written by Sir Hubert Parry in 1916. It is not to be confused with another poem, much longer and larger in scope, but also by Blake, called "Jerusalem The Emanation of the Giant Albion".
The poem was inspired by the apocryphal story that a young Jesus, accompanied by Joseph of Arimathea, a tin merchant, travelled to what is now England and visited Glastonbury during his unknown years. The poem's theme is linked to the Book of Revelation (3:12 and 21:2) describing a Second Coming, wherein Jesus establishes a New Jerusalem. The Christian church in general, and the English Church in particular, has long used Jerusalem as a metaphor for Heaven, a place of universal love and peace.
In the most common interpretation of the poem, Blake implies that a visit by Jesus would briefly create heaven in England, in contrast to the "dark Satanic Mills" of the Industrial Revolution. Blake's poem asks four questions rather than asserting the historical truth of Christ's visit. Thus the poem merely implies that there may, or may not, have been a divine visit, when there was briefly heaven in England.
Text.
The original text is found in the preface Blake wrote for inclusion with "Milton, a Poem", following the lines beginning "The Stolen and Perverted Writings of Homer & Ovid: of Plato & Cicero, which all Men ought to contemn: ..."
Blake's poem
"Dark Satanic Mills".
The phrase "dark Satanic Mills", which entered the English language from this poem, is often interpreted as referring to the early Industrial Revolution and its destruction of nature and human relationships.
This view has been linked to the fate of the Albion Flour Mills, which was the first major factory in London. Designed by John Rennie and Samuel Wyatt, it was built on land purchased by Wyatt in Southwark. This rotary steam-powered flour mill by Matthew Boulton and James Watt used grinding gears by Rennie to produce 6000 bushels of flour per week.
The factory could have driven independent traditional millers out of business, but it was destroyed in 1791 by fire, perhaps deliberately. London's independent millers celebrated with placards reading, "Success to the mills of ALBION but no Albion Mills." Opponents referred to the factory as satanic, and accused its owners of adulterating flour and using cheap imports at the expense of British producers. A contemporary illustration of the fire shows a devil squatting on the building. The mills were a short distance from Blake's home.
Blake's phrase resonates with a wider theme in his works, what he envisioned as a physically and spiritually repressive ideology based on a quantifiable reality. Blake saw the cotton mills and collieries of the period as a mechanism for the enslavement of millions, but the concepts underpinning the works had a wider application:
Stonehenge and other megaliths are featured in "Milton", suggesting they may relate to the oppressive power of priestcraft in general; as Peter Porter observed, many scholars argue that the "mills" "are churches and not the factories of the Industrial Revolution everyone else takes them for".
An alternative theory is that Blake is referring to a mystical concept within his own mythology related to the ancient history of England. Satan's "mills" are referred to repeatedly in the main poem, and are first described in words which suggest neither industrialism nor ancient megaliths, but rather something more abstract: "the starry Mills of Satan/ Are built beneath the earth and waters of the Mundane Shell...To Mortals thy Mills seem everything, and the Harrow of Shaddai / A scheme of human conduct invisible and incomprehensible".
"Chariot of fire".
The line from the poem "Bring me my Chariot of fire!" draws on the story of , where the Old Testament prophet Elijah is taken directly to heaven: "And it came to pass, as they still went on, and talked, that, behold, there appeared a chariot of fire, and horses of fire, and parted them both asunder; and Elijah went up by a whirlwind into heaven." The phrase has become a byword for divine energy, and inspired the title of the 1981 film "Chariots of Fire". The plural phrase "chariots of fire" refers to 2 Kings 6:16–18.
"Green and pleasant Land".
Blake lived in London for most of his life, but wrote much of "Milton" while living in the village of Felpham in Sussex. Amanda Gilroy argues that the poem is informed by Blake's "evident pleasure" in the Felpham countryside.
The phrase "green and pleasant land" has become a collocation for identifiably English landscape or society. It appears as a headline, title or sub-title in numerous articles and books. Sometimes it refers, whether with appreciation, nostalgia or critical analysis, to idyllic or enigmatic aspects of the English countryside. In other contexts it can suggest the perceived habits and aspirations of rural middle-class life. Sometimes it is used ironically, e.g. in the Dire Straits song "Iron Hand".
Revolution.
Several of Blake's poems and paintings express a notion of universal humanity: "As all men are alike (tho' infinitely various)". He retained an active interest in social and political events for all his life, but was often forced to resort to cloaking social idealism and political statements in Protestant mystical allegory. Even though the poem was written during the Napoleonic Wars, Blake was an outspoken supporter of the French Revolution, and Napoleon claimed to be continuing this revolution. The poem expressed his desire for radical change without overt sedition. (In 1803 Blake was charged at Chichester with high treason for having "uttered seditious and treasonable expressions", but was acquitted.) The poem is followed in the preface by a quotation from "Numbers" ch. 11, v. 29: "Would to God that all the Lord's people were prophets." Christopher Rowland, a Professor of Theology at Oxford University, has argued that this includes
... everyone in the task of speaking out about what they saw. Prophecy for Blake, however, was not a prediction of the end of the world, but telling the truth as best a person can about what he or she sees, fortified by insight and an "honest persuasion" that with personal struggle, things could be improved. A human being observes, is indignant and speaks out: it's a basic political maxim which is necessary for any age. Blake wanted to stir people from their intellectual slumbers, and the daily grind of their toil, to see that they were captivated in the grip of a culture which kept them thinking in ways which served the interests of the powerful.
The words of the poem "stress the importance of people taking responsibility for change and building a better society 'in Englands green and pleasant land.'"
Popularisation.
The poem, which was little known during the century which followed its writing, was included in the patriotic anthology of verse "The Spirit of Man," edited by the Poet Laureate of the United Kingdom, Robert Bridges, and published in 1916, at a time when morale had begun to decline because of the high number of casualties in World War I and the perception that there was no end in sight.
Under these circumstances, Bridges, finding the poem an appropriate hymn text to "brace the spirit of the nation accept with cheerfulness all the sacrifices necessary," asked Sir Hubert Parry to put it to music for a Fight for Right campaign meeting in London's Queen's Hall. (The aims of this organisation were "to brace the spirit of the nation, that the people of Great Britain, knowing that they are fighting for the best interests of humanity, may refuse any temptation, however insidious, to conclude a premature peace, and may accept with cheerfulness all the sacrifices necessary to bring the war to a satisfactory conclusion".) Bridges asked Parry to supply "suitable, simple music to Blake's stanzas – music that an audience could take up and join in", and added that, if Parry could not do it himself, he might delegate the task to George Butterworth.
The poem's idealistic theme or subtext accounts for its popularity across much of the political spectrum. It was used as a campaign slogan by the Labour Party in the 1945 general election; Clement Attlee said they would build "a new Jerusalem". It has been sung at conferences of the Conservative Party, at the Glee Club of the British Liberal Assembly, the Labour Party and by the Liberal Democrats.
Parry's setting of "Jerusalem".
In adapting Blake's poem as a unison song, Parry deployed a two-stanza format, each taking up eight lines of Blake's original poem. He also provided a four-bar musical introduction to each verse and a coda, echoing melodic motifs of the song. (The song is always performed with these 'extra' passages.) And the word "those" was substituted for "these" (before "dark satanic mills".)
The piece was to be conducted by Parry's former student Walford Davies, but Parry was initially reluctant to set the words, as he had doubts about the ultra-patriotism of Fight for Right, but not wanting to disappoint either Robert Bridges or Davies he agreed, writing it on 10 March 1916, and handing the manuscript to Davies with the comment, "Here's a tune for you, old chap. Do what you like with it." Davies later recalled,
Davies arranged for the vocal score to be published by Curwen in time for the concert at the Queen's Hall on 28 March and began rehearsing it. It was a success and was taken up generally.
But Parry began to have misgivings again about Fight for Right and eventually wrote to Sir Francis Younghusband withdrawing his support entirely in May 1917. There was even concern that the composer might withdraw the song, but the situation was saved by Millicent Garrett Fawcett of the National Union of Women's Suffrage Societies (NUWSS). The song had been taken up by the Suffragettes in 1917 and Millicent Fawcett asked Parry if it might be used at a Suffrage Demonstration Concert on 13 March 1918. Parry was delighted and orchestrated the piece for the concert (it had originally been for voices and organ). After the concert, Millicent Fawcett asked the composer if it might become the Women Voters' Hymn. Parry wrote back,
Accordingly, he assigned the copyright to the NUWSS. When that organisation was wound up in 1928, Parry's executors reassigned the copyright to the Women's Institutes, where it remained until it entered the public domain in 1968.
The song was first called "And Did Those Feet in Ancient Time" and the early published scores have this title. The change to 'Jerusalem' seems to have been made about the time of the 1918 Suffrage Demonstration Concert, perhaps when the orchestral score was published (Parry's manuscript of the orchestral score has the old title crossed out and 'Jerusalem' inserted in a different hand). However, Parry always referred to it by its first title. He had originally intended the first verse to be sung by a solo female voice (this is marked in the score), but this is rare in contemporary performances. Sir Edward Elgar re-scored the work for very large orchestra in 1922 for use at the Leeds Festival. Elgar's orchestration has overshadowed Parry's own, primarily because it is the version usually used now for the Last Night of the Proms (though, Sir Malcolm Sargent, who introduced it to that event in the 1950s always used Parry's version).
Use as a hymn.
Although Parry composed the music as a unison song, many churches have adopted "Jerusalem"; English cathedrals, churches and chapels frequently use it as an office or recessional hymn on St George's Day. It is also sung in some churches on Jerusalem Sunday, a day set aside to celebrate the holy city, in Anglican churches throughout the world and even in some Episcopal churches in the United States.
However, some clergy in the Church of England, according to the BBC TV programme "Jerusalem: An Anthem for England", have said that the song is not technically a hymn as it is not a prayer to God (which they claim hymns always are, though many counter-examples appear in any hymnal). Consequently, it is not sung in some churches in England. Despite this, it was sung as a hymn during the wedding of Prince William and Catherine Middleton in Westminster Abbey.
Many schools use the song, especially public schools in Great Britain (it was used as the title music for the BBC's 1979 series 'Public School' at Radley College), and several private schools in Australia, New Zealand, New England and Canada. "Jerusalem" was chosen as the opening hymn for the London Olympics 2012, although "God Save the Queen" was the anthem sung during the raising of the flag in salute to the Queen. Some attempts have also been made to increase its use elsewhere with other words, examples include the State Funeral of President Ronald Reagan in Washington National Cathedral on 11 June 2004 and the State Memorial Service for Australian Prime Minister Gough Whitlam AC QC on November 5, 2014.
Use as an anthem.
Upon hearing the orchestral version for the first time, King George V said that he preferred "Jerusalem" over "God Save the King" (the British national anthem), and "Jerusalem" is considered to be England's most popular patriotic song; "The New York Times" said it was "Fast becoming an alternative national anthem," and there have even been calls to give it official status. England has no official anthem and uses the British national anthem "God Save the Queen", also unofficial, for some national occasions, such as before English international football matches. However, some sports, including rugby league use "Jerusalem" as the English anthem. "Jerusalem" is the official hymn of the England and Wales Cricket Board, although "God Save the Queen" was the anthem sung before England's games in 2010 ICC World Twenty20 and 2010–11 Ashes series. Questions in Parliament have not clarified the situation, as answers from the relevant minister say that since there is no official national anthem, each sport must make its own decision.
As Parliament has not clarified the situation, Team England, the English Commonwealth team held a public poll in 2010 to decide which anthem should be played at medal ceremonies to celebrate an English win at the Commonwealth Games. "Jerusalem" was selected by 52% of voters over "Land of Hope and Glory" (used since 1930) and "God Save the Queen". The lyrics' explicit focus on England, without mention of other parts of the United Kingdom, renders the song unfitting as a national anthem for the entire UK.
In 2005 BBC Four produced "Jerusalem: An Anthem For England" highlighting the usages of the song/poem and a case was made for its adoption as the national anthem of England. Varied contributions come from Howard Goodall, Billy Bragg, Gary Bushell, Lord Hattersley, Ann Widdecombe and David Mellor, war proponents, war opponents, suffragettes, trade unionists, public schoolboys, the Conservatives, the Labour Party, football supporters, the British National Party, the Women's Institute, a gay choir, a gospel choir, Fat Les and naturists.
Emerson, Lake & Palmer version.
In 1973, for their "Brain Salad Surgery" album, British progressive rock band Emerson, Lake & Palmer recorded a version of the song titled "Jerusalem". The track features the debut of the prototype Moog Apollo, the first-ever polyphonic music synthesizer. The subject matter of this song indicates a nod to ELP's unabashed Englishness and simultaneously lent an air of timeless tradition and ceremony to the music. But "Jerusalem" was banned in England on the radio when it was issued as a single. The BBC would not accept it as a serious piece of music, the band claims. Drummer Carl Palmer later expressed disappointment over this decision. 
The single failed to chart.
Performances.
The popularity of Parry's setting has resulted in many hundreds of recordings being made, too numerous to list, of both traditional choral performances and new interpretations by popular music artists. Consequently, only its most notable performances are listed below.
Use in film, television and theatre.
"Bring me my chariot of fire" inspired the title of the film "Chariots of Fire". A church congregation sings "Jerusalem" at the close of the film and a performance appears on the "Chariots of Fire soundtrack" performed by the Ambrosian Singers overlaid partly by a composition by Vangelis. One unexpected touch is that "Jerusalem" is sung in four-part harmony, as if it were truly a hymn. This is not authentic: Parry's composition was a unison song (that is, all voices sing the tune – perhaps one of the things that make it so "singable" by massed crowds) and he never provided any harmonisation other than the accompaniment for organ (or orchestra). Neither does it appear in any standard hymn book in a guise other than Parry's own, so it may have been harmonised specially for the film. The film's working title was "Running" until Colin Welland saw a television programme, "Songs of Praise", featuring the hymn and decided to change the title.
The hymn has featured in many other films and television programmes including "Four Weddings and a Funeral", "How to Get Ahead in Advertising", "The Loneliness of the Long Distance Runner", "Calendar Girls", "", "Goodnight Mr. Tom", "Women in Love", "The Man Who Fell to Earth", "Shameless", and "Monty Python's Flying Circus". An extract was heard in the 2013 "Doctor Who" episode "The Crimson Horror" although that story was set in 1893, i.e., before Parry's arrangement. A punk version is heard in Derek Jarman's 1977 film "Jubilee". In "Peep Show", Jez, played by Robert Webb makes a track called "This is Outrageous" which uses the first and a version of the second line in a verse.
In the theatre it appears in "Jerusalem", "Calendar Girls" and in "Time and the Conways". Eddie Izzard discusses the hymn in his 2000 "Circle" stand-up tour. Punk band Bad Religion have borrowed the opening line of Blake's poem in their "God Song", from the 1990 album "Against the Grain".
Other composers.
Blake's lyrics have also been set to music by other composers without reference to Parry's melody. Tim Blake (synthesiser player of Gong) produced a solo album in 1978 called "Blake's New Jerusalem", including a 20-minute track with lyrics from Blake's poem. The words, with some variations, are used in the track "Jerusalem" on Bruce Dickinson's album "The Chemical Wedding", which also includes lines from book two of "Milton". Finn Coren also created a different musical setting for the poem on his album '. The Verve also referenced the song in their 2008 song "Love is Noise" from the album Forth. Lead singer and writer Richard Ashcroft said that Blake had influenced the lyric "'Will those feet in modern times from the song. This is not the first Verve song influenced by Blake, as their previous single "History" also featured the lyrics "I wandered lonely streets/Behind where the old Thames does flow/And in every face I meet", referencing Blake's "London".

</doc>
<doc id="2941" url="https://en.wikipedia.org/wiki?curid=2941" title="The Bush (Alaska)">
The Bush (Alaska)

In Alaska, the bush is any region of the State not connected to the North American road network or ready access to the State's Ferry System. A majority of Alaska's native populations live in the bush, where they make their living in similar fashion to their ancestors.
Geographically, the bush comprises the Alaska North Slope; Northwest Arctic; West, including the Baldwin Peninsula and Seward Peninsula; the Yukon-Kuskokwim Delta; Southwest Alaska; Bristol Bay; Alaska Peninsula; and remote areas of the Alaska Panhandle and Interior. 
Some of the larger communities in the bush include Bethel, Dillingham, King Salmon, Nome, Barrow, Katmai National Park, Kodiak Island, Kotzebue, and Unalaska-Dutch Harbor.
Most parts of Alaska that are off the road system can only be reached by a small bush airplane. Travel from place to place is typically accomplished by snowmobile, snow machine, boat, or dog sled.

</doc>
<doc id="2942" url="https://en.wikipedia.org/wiki?curid=2942" title="A Little Night Music">
A Little Night Music

A Little Night Music is a musical with music and lyrics by Stephen Sondheim and book by Hugh Wheeler. Inspired by the Ingmar Bergman film "Smiles of a Summer Night", it involves the romantic lives of several couples. Its title is a literal English translation of the German name for Mozart's Serenade No. 13 for strings in G major, "Eine kleine Nachtmusik". The musical includes the popular song "Send in the Clowns".
Since its original 1973 Broadway production, the musical has enjoyed professional productions in the West End, by opera companies, in a 2009 Broadway revival, and elsewhere, and it is a popular choice for regional groups. It was adapted for film in 1977, with Harold Prince directing and Elizabeth Taylor, Len Cariou, Lesley-Anne Down and Diana Rigg starring.
Synopsis.
Act One.
The setting is Sweden, around the year 1900. One by one, the Quintet – five singers who comment like a Greek chorus throughout the show – enter, tuning up. Gradually, their vocalizing becomes an overture blending fragments of "Remember," "Soon," and "The Glamorous Life," leading into the first "Night Waltz". The other characters enter waltzing, each uncomfortable with their particular partner. After they drift back off, the aging and severe Madame Armfeldt and her solemn granddaughter, Fredrika, enter. Madame Armfeldt tells the child that the summer night "smiles" three times: first on the young, second on fools, and third on the old. Fredrika vows to watch the smiles occur. Middle aged Fredrik Egerman is a successful lawyer. He has recently married an 18-year-old trophy wife, Anne, a vain girl who is in love with Fredrik, but too immature to grasp the concept of marriage. The two have been married for eleven months, but Anne still protects her virginity. Fredrik laments his inability to make love to his wife ("Now"). Meanwhile, his son Henrik, a year older than his stepmother, is feeling extremely frustrated. He is a seminary student and everyone is always teasing him, never taking him seriously or letting him talk ("Later"). Anne is intrigued by him, but fails to understand his real meaning. Anne promises her husband that she will consent to have sex shortly ("Soon"). Anne's maidservant Petra, an experienced and forthright girl, slightly older than the teen herself, offers her worldly but crass advice.
Desiree Armfeldt is a prominent and glamorous actress who is now reduced to touring in small towns. Madame Armfeldt, Desiree's mother, has taken over the care of Desiree's daughter Fredrika. Fredrika misses her mother, but Desiree continually puts off going to see her, preferring, somewhat ironically, "The Glamorous Life". She is performing near Fredrik's home, and he brings Anne to see the play. While there, Desiree notices Fredrik; the two were lovers years before. Anne, suspicious and annoyed because of Desiree's amorous glances, demands that Fredrik take her home immediately. Meanwhile, Petra has been trying to seduce Henrik.
That night, as Fredrik remembers his past with Desiree, he sneaks out to see her; the two share a happy but strained reunion, as they "Remember". They reflect on their new lives, and Fredrik tries to explain how much he loves Anne ("You Must Meet My Wife"). Desiree responds sarcastically, boasting of her own adultery, as she has been seeing the married dragoon, Count Carl-Magnus Malcolm. Upon learning that Fredrik has gone for eleven months without sex, she agrees to accommodate him as a favor for an old friend.
Madame Armfeldt offers advice to young Fredrika. The elderly woman reflects poignantly on her own checkered past, and wonders what happened to her refined "Liaisons". Back in Desiree's apartment, Count Carl-Magnus Malcolm proclaims his unannounced arrival in his typical booming voice. Fredrik and Desiree fool the gullible Count into believing that their disheveled appearance was entirely innocent, but he is still suspicious. He instantly dislikes Fredrik and returns to his wife, Countess Charlotte. Charlotte is quite aware of her husband's infidelity, but Carl-Magnus is too absorbed in his suspicions of Desiree to talk to her ("In Praise of Women"). When she persuades him to blurt out the whole story, a twist is revealed—Charlotte's little sister is a school friend of Anne's.
Charlotte visits Anne, who is talking with Petra. Charlotte describes Fredrik's meeting with Desiree; Anne reacts with shock and horror. The older woman explains to Anne that such is the lot of a wife, and that marriage brings pain ("Every Day A Little Death"). Meanwhile, Desiree asks Madame Armfeldt to host a party for Fredrik, Anne, and Henrik. Though reluctant, Madame Armfeldt agrees. She sends out a personal invitation; its receipt sends the women into a frenzy, imagining "A Weekend in the Country". Anne does not want to accept the invitation, but Charlotte convinces her to do so to heighten the contrast between the older woman and the young teenager. Meanwhile, the Count has plans of his own — as a birthday present to his wife, the pair will attend the party uninvited. Carl-Magnus plans to challenge Fredrik to a duel, while Charlotte hopes to seduce the lawyer to make her husband jealous and end his philandering. The day of the party dawns.
Act Two.
Armfeldt's country estate is bathed in the golden glow of perpetual summer sunset at this high latitude ("Night Waltz One and Two"). Everyone arrives, each carrying their own amorous purposes and desires—even Petra, who catches the eye of Armfeldt's fetching manservant, Frid. The women begin to act against each other. Fredrik is astonished to learn the name of Desiree's daughter. Henrik meets Fredrika, and confesses his deep love for Anne to her. Meanwhile, in the garden, Fredrik and Carl-Magnus reflect on how difficult it is to be annoyed with Desiree, agreeing "It Would Have Been Wonderful" had she not been quite so wonderful. Dinner is served, and the characters' "Perpetual Anticipation" enlivens that meal.
At dinner, Charlotte attempts to flirt with Fredrik, while Anne and Desiree trade insults. Soon, everyone is shouting and scolding everyone else, except for Henrik, who finally stands up for himself. He shrieks at them for being completely amoral, and flees the scene. Stunned, everyone reflects on the situation and wanders away. Fredrika tells Anne of Henrik's secret love, and the two dash off searching for him. Meanwhile, Desiree meets Fredrik and asks if he still wants to be "rescued" from his life. Fredrik answers honestly that he loves Desiree, but only as a dream. Hurt and bitter, Desiree can only reflect on the nature of her life ("Send in the Clowns"). Anne finds Henrik, who is attempting to commit suicide. The clumsy boy cannot complete the task, and Anne tells him that she has feelings for him, too. The pair begins to kiss, which leads to Anne's first sexual encounter. Meanwhile, not far away, Frid sleeps in Petra's lap. The maid thinks of the joy and freedom that she longs for before becoming trapped in marriage ("The Miller's Son"). Henrik and Anne, happy together, run away to start their new life. However, Carl-Magnus is enraged by this and attempts to shoot the lovers, but Desiree and Charlotte prevent him, while lamenting both the pains of marriage and the strange behavior of married people ("The World Won't End/Every Day a Little Death (reprise)"). With Carl-Magnus calmed, Charlotte confesses her plan to Fredrik, and the two commiserate on a bench. Carl-Magnus, preparing to romance Desiree, sees this and challenges Fredrik to Russian Roulette, at which a nervous Fredrik misfires and simply grazes his own ear. Victorious, Carl-Magnus begins to romance Charlotte, granting her wish at last.
After the Count and Countess leave, Fredrika and Madame Armfeldt discuss the chaos of the recent turns-of-events. The elderly woman then asks Fredrika a surprising question: "What is it all for?" Fredrika thinks about this, and decides that it "must be worth it". Madame Armfeldt is surprised, ruefully noting that she rejected love for material wealth at Fredrika's age. She praises her granddaughter and remembers true love's fleeting nature.
Fredrik finally confesses his love for Desiree, acknowledges that Fredrika is his daughter, and the two promise to start a new life together ("Finale"). Armfeldt sits alone with Fredrika. Fredrika tells her grandmother that she has watched carefully, but still has not seen the night smile. Armfeldt laughs and points out that the night has indeed smiled twice: first on Henrik and Anne, the young, and second on Desiree and Fredrik, the fools. As the two wait for the "third smile... on the old", it happens: Madame Armfeldt closes her eyes, and dies peacefully with Fredrika beside her.
Stage:
Screen:
Productions.
Original Broadway production.
"A Little Night Music" opened on Broadway at the Shubert Theatre on February 25, 1973, and closed on August 3, 1974, after 601 performances and 12 previews. It moved to the Majestic Theatre on September 17, 1973, where it completed its run. It was directed by Harold Prince with choreography by Patricia Birch and design by Boris Aronson. The cast included Glynis Johns (Desiree Armfeldt), Len Cariou (Fredrik Egerman), Hermione Gingold (Madame Armfeldt), Victoria Mallory (Anne Egerman), Judith Kahan (Fredrika Armfeldt), Mark Lambert (Henrik Egerman), Laurence Guittard (Carl-Magnus Malcolm), Patricia Elliott (Charlotte Malcolm), George Lee Andrews (Frid), and D. Jamin Bartlett (Petra). It won the New York Drama Critics' Circle Award and the Tony Award for Best Musical.
United States tour.
A US national tour began on February 26, 1974, at the Forrest Theatre, Philadelphia, and ended on February 13, 1975, at the Shubert Theatre, Boston. Jean Simmons as Desiree Armfeldt, George Lee Andrews as Fredrik Egerman and Margaret Hamilton as Madame Armfeldt headed the cast.
West End premiere.
The musical premiered in the West End at the Adelphi Theatre on April 15, 1975, and starred Jean Simmons, Joss Ackland, David Kernan, Liz Robertson, and Diane Langton, with Hermione Gingold reprising her role as Madame Armfeldt. It ran for 406 performances. During the run, Angela Baddeley replaced Gingold, and Virginia McKenna replaced Simmons.
1989 West End revival.
A revival opened in the West End on October 6, 1989, at the Piccadilly Theatre, directed by Ian Judge, designed by Mark Thompson, and choreographed by Anthony Van Laast. It starred Lila Kedrova as Madame Armfeldt, Dorothy Tutin as Desiree Armfeldt, Peter McEnery as Fredrick, and Susan Hampshire. The production ran for 144 performances, closing on February 17, 1990.
1995 London revival.
A revival by the Royal National Theatre opened at the Olivier Theatre on September 26, 1995. It was directed by Sean Mathias, with set design by Stephen Brimson Lewis, costumes by Nicky Gillibrand, lighting by Mark Henderson and choreography by Wayne McGregor. It starred Judi Dench (Desiree), Siân Phillips (Madame Armfeldt), Joanna Riding (Anne Egerman), Laurence Guittard (Fredrik Egerman), Patricia Hodge (Countess Charlotte) and Issy van Randwyck (Petra). The production closed on August 31, 1996. Dench received the Olivier Award for Best Actress in a Musical.
2008 London revival.
The third London revival ran at the Menier Chocolate Factory from November 22, 2008 until March 8, 2009. The production was directed by Trevor Nunn, with choreography by Lynne Page, sets and costumes by David Farley and new orchestrations by Jason Carr. The cast included Hannah Waddingham as Desiree, Alexander Hanson as Frederik, Jessie Buckley (Anne), Maureen Lipman (Mme. Armfeldt), Alistair Robins (the Count), Gabriel Vick (Henrik), Grace Link and Holly Hallam (shared role Fredrika) and Kasia Hammarlund (Petra). This critically acclaimed production transferred to the Garrick Theatre in the West End for a limited season, opening on March 28, 2009 running until July 25, 2009. This production then transferred to Broadway with a new cast.
2009 Broadway revival.
The 2008 Menier Chocolate Factory production opened on Broadway at the Walter Kerr Theatre in previews November 24, 2009 and officially December 13, 2009, with the same creative team. The cast starred Angela Lansbury as Madame Armfeldt and, in her Broadway debut, Catherine Zeta-Jones as Desiree. Also featured were Alexander Hanson as Frederik, Ramona Mallory (the daughter of original Broadway cast members Victoria Mallory and Mark Lambert) as Anne, Hunter Ryan Herdlicka as Henrik, Leigh Ann Larkin as Petra, Erin Davie as the Countess, Aaron Lazar as the Count, and Bradley Dean as Frid. Zeta-Jones was recognized as Best Leading Actress in a Musical at the 64th Tony Awards.
When the contracts of Zeta-Jones and Lansbury ended the production temporarily closed on June 20, 2010 and resumed on July 13, with new stars Bernadette Peters as Desiree Armfeldt and Elaine Stritch as Madame Armfeldt. In an interview, Peters said that Sondheim had "proposed the idea to her this spring and urged the producers of the revival to cast her." Trevor Nunn directed rehearsals with the two new stars, and the rest of the original cast remained. Peters and Stritch extended their contracts until January 9, 2011, when the production closed with 20 previews and 425 regular performances. Before the production closed it recouped its initial investment.
Europe.
Zarah Leander played Madame Armfeldt in the original Austrian staging (in 1975) as well as in the original Swedish staging in Stockholm in 1978 (here with Jan Malmsjö as Fredrik Egerman), performing "Send In The Clowns" and "Liaisons" in both stagings. The successful Stockholm-staging was directed by Stig Olin. In 2010 the musical was scheduled to return to Stockholm and the Stockholm Stadsteater. The cast included Pia Johansson, Dan Ekborg, Yvonne Lombard and Thérese Andersson.
The Théâtre du Châtelet, Paris production ran from February 15, 2010 through February 20, 2010. Lee Blakeley directed and Andrew George was the choreographer. Italian-born actress Greta Scacchi played Désirée, and Leslie Caron played Madame Armfeldt.
The Turku City Theatre staged the musical in 2011 with Kirsi Tarvainen in the role as Désirée. Tuomas Parkkinen directed and Jussi Vahvaselkä was musical director.
Opera companies.
The musical has also become part of the repertoire of a few opera companies. Michigan Opera Theatre was the first major American opera company to present the work in 1983, and again in November 2009. Light Opera Works (Evanston, IL) produced the work in August 1983. New York City Opera staged it in 1990, 1991 and 2003, the Houston Grand Opera in 1999, the Los Angeles Opera in 2004, and Hartford Opera Theater in 2014. New York City Opera's production in August 1990 and July 1991 (total of 18 performances) won the 1990 Drama Desk Award for Outstanding Revival and was telecast on the PBS show "Live at Lincoln Center" on November 7, 1990. The cast included both stage performers: Sally Ann Howes and George Lee Andrews as Desiree and Frederick and opera regular Regina Resnik as Madame Armfeldt (in 1991). The 2003 production featured a young Anna Kendrick as Fredrika Armfeldt, alongside Jeremy Irons as Frederick and Marc Kudisch as Carl-Magnus.
Opera Australia presented the piece in Melbourne in May 2009, starring Sigrid Thornton as Desiree Armfeldt and Nacye Hayes as Madame Armfeldt. The production returned in 2010 at the Sydney Opera House with Anthony Warlow taking on the role of Fredrik Egerman. The production was directed by Stuart Maunder, designed by Roger Kirk, and conducted by Andrew Greene. Opera Theatre of Saint Louis performed the musical in June 2010. Designer Isaac Mizrahi directed and designed the production, with a cast that starred Amy Irving, Siân Phillips, and Ron Raines.
The piece has also become a popular choice for amateur musical theatre and light opera companies.
Film adaptation.
In 1977, a film version of "A Little Night Music" was released, starring Elizabeth Taylor, Lesley-Anne Down and Diana Rigg, with Len Cariou, Hermione Gingold and Laurence Guittard reprising their Broadway roles. The setting for the film was moved from Sweden to Austria. Stephen Sondheim wrote lyrics for the "Night Waltz" theme ("Love Takes Time") and wrote an entirely new version of "The Glamorous Life", which has been incorporated into several subsequent productions of the stage musical. However, other songs, including "In Praise of Women", "The Miller's Son" and "Liaisons", were cut and remain heard only as background orchestrations. The film marked Broadway director Hal Prince's second time as a motion picture director. Critical reaction to the film was mostly negative, with much being made of Taylor's wildly fluctuating weight from scene to scene. Some critics talked more positively of the film, with "Variety" calling it "an elegant looking, period romantic charade". There was praise for Diana Rigg's performance, and orchestrator Jonathan Tunick received an Oscar for his work on the score. A soundtrack recording was released on LP, and a DVD release was issued in June 2007.
Music analysis.
The score for "A Little Night Music" has elements not often found in musical theater, presenting challenges for performers, with complex meters, pitch changes, polyphony, and high notes for both males and females. The difficulty is heightened when songs merge, as in "Now"/"Later"/"Soon", because all three have to be performed in the same key, limiting the ability to pick a comfortable key for each singer. Critic Rex Reed noted that "The score of 'Night Music' ...contains patter songs, contrapuntal duets and trios, a quartet, and even a dramatic double quintet to puzzle through. All this has been gorgeously orchestrated by Jonathan Tunick; there is no rhythm section, only strings and woodwinds to carry the melodies and harmonies aloft."
Sondheim's engagement with threes extends to his lyrics. He organizes trios with the singers separated, while his duets are sung together, about a third person.
The work is performed as an operetta in many professional opera companies. For example, it was added to the New York City Opera Company repertoire in 1990.
3/4 time.
Virtually all of the music in the show is written in waltz time (3/4). Some parts adopt compound meter, with a time signature such as 12/8. Passages in "Overture", "Glamorous Life", "Liaisons", and "The Miller's Son" are in duple meter.
Counterpoint and polyphony.
At several points, Sondheim has multiple performers each sing a different song simultaneously. This use of counterpoint maintains coherence even as it extends the notion of a round, familiar in songs such as the traditional "Frère Jacques", into something more complex. Sondheim said: "As for the three songs... going together well, I might as well confess. In those days I was just getting into contrapuntal and choral writing...and I wanted to develop my technique by writing a trio. What I didn't want to do is the quodlibet method...wouldn't it be nice to have three songs you don't think are going to go together, and they do go together... The trick was the little vamp on "Soon" which has five-and six-note chords." Steve Swayne comments that the "contrapuntal episodes in the extended ensembles... stand as testament to his interest in Counterpoint."
"Send In The Clowns".
The show's best-known and Sondheim's biggest hit song was almost an afterthought, written several days before the start of out of town tryouts. Sondheim initially conceived Desiree as a role for a more-or-less non-singing actress. When he discovered that the original Desiree, Glynis Johns, was able to sing (she had a "small, silvery voice") but could not "sustain a phrase", he devised the song "Send in the Clowns" for her in a way that would work around her vocal weakness, e.g., by ending lines with consonants that made for a short cut-off. "It is written in short phrases in order to be acted rather than sung...tailor-made for Glynis Johns, who lacks the vocal power to sustain long phrases."
In analyzing the text of the song, Max Cryer wrote that it "is not intended to be sung by the young in love, but by a mature performer who has seen it all before. The song remains an anthem to regret for unwise decisions in the past and recognition that there's no need to send in the clowns-they're already here."
Graham Wolfe has argued, "What Desirée is referring to in the famous song is a conventional device to cover over a moment when something has gone wrong on stage. Midway through the second Act she has deviated from her usual script by suggesting to Fredrik the possibility of being together seriously and permanently, and, having been rejected, she falters "as" a show-person, finds herself bereft of the capacity to improvise and wittily cover. If Desirée could perform at this moment – revert to the innuendos, one-liners and blithe self-referential humour that constitutes her normal character – all would be well. She cannot, and what follows is an exemplary manifestation of Sondheim’s musico-dramatic complexity, his inclination to write music that performs drama. That is, what needs to be covered over (by the clowns sung about in the song) is the very intensity, ragged emotion and utter vulnerability that comes forward through the music and singing itself, a display protracted to six minutes, wrought with exposed silences, a shocked Fredrik sitting so uncomfortably before Desirée while something much too real emerges in a realm where he – and his audience – felt assured of performance."
Influences.
There is a Mozart reference in the title—"A Little Night Music" is an occasionally used translation of "Eine kleine Nachtmusik", the nickname of Mozart's Serenade No. 13 for strings in G major, K. 525. The elegant, harmonically-advanced music in this musical pays indirect homage to the compositions of Maurice Ravel, especially his "Valses nobles et sentimentales" (whose opening chord is borrowed for the opening chord of the song "Liaisons"); part of this effect stems from the style of orchestration that Jonathan Tunick used.
Cast recordings.
In addition to the original Broadway and London cast recordings, and the motion picture soundtrack (no longer available), there are recordings of the 1990 studio cast, the 1995 Royal National Theatre revival (starring Judi Dench), and the 2001 Barcelona cast recording sung in Catalan. In 1997 an all-jazz version of the score was recorded by Terry Trotter.
The 2009 Broadway revival with Catherine Zeta-Jones and Angela Lansbury recorded a cast album on January 4, 2010 which was released on April 6.
Critical response.
In his review of the original 1973 Broadway production, Clive Barnes in the "New York Times" called the musical "heady, civilized, sophisticated and enchanting." He noted that "the real triumph belongs to Stephen Sondheim...the music is a celebration of 3/4 time, an orgy of plaintively memorable waltzes, all talking of past loves and lost worlds...There is a peasant touch here." He commented that the lyrics are "breathtaking".
In its review of the 1989 London revival, the reviewer for "The Guardian" wrote that the "production also strikes me as infinitely superior to Harold Prince's 1975 version at the Adelphi. Mr Judge's great innovation is to transform the Liebeslieder Singers from the evening-dressed, after-dinner line-up into 18th century ghosts weaving in and out of the action...But Mr Judge's other great realisation is that, in Sondheim, the lyrics are not an adornment to a song but their very essence: understand them and the show will flow. Thus Dorothy Tutin as Desiree, the touring thesp eventually reunited with her quondam lover, is not the melting romantic of previous productions but a working mother with the sharpness of a hat-pin."
The "Independent" review of the 1995 National Theatre revival praised the production, writing "For three hours of gloriously barbed bliss and bewitchment, Sean Mathias's production establishes the show as a minor miracle of astringent worldly wisdom and one that is haunted by less earthy intimations." The review went on to state that "The heart of the production, in both senses, is Judi Dench's superb Desiree Armfeldt...Her husky-voiced rendering of "Send in the Clowns" is the most moving I've ever heard."
In reviewing the 2008 Menier Chocolate Factory production, "The Telegraph" reviewer wrote that "Sondheim's lyrics are often superbly witty, his music here, mostly in haunting waltz-time, far more accessible than is sometimes the case. The score positively throbs with love, regret and desire." But of the specific production, the reviewer went on to note: "But Nunn's production, on one of those hermetic sets largely consisting of doors and tarnished mirrors that have become such a cliché in recent years, never penetrates the work's subtly erotic heart. And as is often the case with this director's work, the pace is so slow and the mood so reverent, that initial enchantment gives way to bored fidgeting."
In his "New York Times" review of the 2009 Broadway production, Ben Brantley noted that "the expression that hovers over Trevor Nunn's revival...feels dangerously close to a smirk...It is a smirk shrouded in shadows. An elegiac darkness infuses this production." The production is "sparing on furniture and heavy on shadows", with "a scaled-down orchestra at lugubriously slowed-down tempos..." He goes on to write that "this somber, less-is-more approach could be effective were the ensemble plugged into the same rueful sensibility. But there is only one moment in this production when all its elements cohere perfectly. That moment, halfway through the first act, belongs to Ms. Lansbury, who has hitherto been perfectly entertaining, playing Madame Armfeldt with the overripe aristocratic condescension of a Lady Bracknell. Then comes her one solo, "Liaisons", in which her character thinks back on the art of love as a profession in a gilded age, when sex 'was but a pleasurable means to a measurable end.' Her face, with its glamour-gorgon makeup, softens, as Madame Armfeldt seems to melt into memory itself, and the wan stage light briefly appears to borrow radiance from her. It's a lovely example of the past reaching out to the present..."
Steven Suskin, reviewing the new Broadway cast for "Variety", wrote "What a difference a diva makes. Bernadette Peters steps into the six-month-old revival of 'A Little Night Music' with a transfixing performance, playing it as if she realizes her character's onstage billing -- "the one and only Desiree Armfeldt"—is cliched hyperbole. By figuratively rolling her eyes at the hype, Peters gives us a rich, warm and comedically human Desiree, which reaches full impact when she pierces the facade with a nakedly honest, tears-on-cheek 'Send in the Clowns.'"

</doc>
